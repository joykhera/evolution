{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0055639355113266, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.12920042951271, "policy_loss": -0.0037582529884905964, "vf_loss": 6.131729990338522, "vf_explained_var": 0.0027573120972466847, "kl": 0.006143450297655104, "entropy": 1.6033009532898193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9021780813181842, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.669787450316091, "policy_loss": -0.008159995988743113, "vf_loss": 7.676043204908018, "vf_explained_var": 0.0048255431273626906, "kl": 0.009521223698849826, "entropy": 1.6001365625669086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 92.06000000000039, "episode_reward_min": -214.3700000000009, "episode_reward_mean": -36.52277777777793, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -367.84000000000015, "predator_policy": 3.0}, "policy_reward_max": {"prey_policy": 106.40000000000013, "predator_policy": 162.0}, "policy_reward_mean": {"prey_policy": -84.34472222222233, "predator_policy": 66.08333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-101.63000000000031, -24.170000000000005, -12.639999999999626, 15.03999999999999, 8.940000000000202, 60.029999999999916, 15.259999999999986, -43.18000000000036, -26.95999999999982, -120.65000000000136, 92.06000000000039, -44.9800000000003, -185.26000000000056, -123.92999999999978, -65.30000000000028, -214.3700000000009, 69.77999999999993, 44.5499999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-59.499999999999815, -225.1300000000005, 34.66999999999983, -367.84000000000015, -26.409999999999997, -26.229999999999727, 55.819999999999986, -142.7800000000001, 27.290000000000077, -68.3500000000003, -90.41999999999993, -15.549999999999999, -2.0500000000000416, -13.690000000000014, -174.1300000000008, -5.050000000000039, -207.0400000000008, 18.08, -172.87000000000094, -91.77999999999952, -108.33999999999982, 106.40000000000013, -64.32999999999947, -53.65000000000013, -210.31000000000057, -179.95, -87.69999999999995, -245.23000000000036, 2.0000000000000013, -223.30000000000052, -263.32000000000056, -125.04999999999984, -56.29000000000034, 49.069999999999986, 38.18000000000005, -61.62999999999934], "policy_predator_policy_reward": [113.0, 70.0, 152.0, 157.0, 17.0, 23.0, 35.0, 67.0, 29.0, 21.0, 74.0, 92.0, 3.0, 28.0, 53.0, 83.0, 104.0, 58.0, 91.0, 53.0, 23.0, 71.0, 40.0, 33.0, 162.0, 43.0, 123.0, 86.0, 54.0, 102.0, 22.0, 152.0, 32.0, 45.0, 11.0, 57.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4715069645948993, "mean_inference_ms": 5.056611115858666, "mean_action_processing_ms": 0.8011575725504997, "mean_env_wait_ms": 0.5582150028125161, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02313852310180664, "StateBufferConnector_ms": 0.004228618409898546, "ViewRequirementAgentConnector_ms": 0.21121568149990505}, "num_episodes": 18, "episode_return_max": 92.06000000000039, "episode_return_min": -214.3700000000009, "episode_return_mean": -36.52277777777793, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 238.00275572915774, "num_env_steps_trained_throughput_per_sec": 238.00275572915774, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 16806.535, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16806.474, "sample_time_ms": 3659.293, "learn_time_ms": 13123.191, "learn_throughput": 304.804, "synch_weights_time_ms": 13.191}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "310e1_00000", "date": "2024-08-15_00-57-37", "timestamp": 1723663657, "time_this_iter_s": 16.875954151153564, "time_total_s": 16.875954151153564, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1265310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16.875954151153564, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 70.16799999999999, "ram_util_percent": 83.788}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9756175628572544, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.048646061508744, "policy_loss": -0.00976750673258076, "vf_loss": 6.055975239112894, "vf_explained_var": -0.0033907716236417254, "kl": 0.012191630910927578, "entropy": 1.5910349213887776, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0269878964102457, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.730948552378901, "policy_loss": -0.007424548500656057, "vf_loss": 8.736606191958069, "vf_explained_var": 0.016435668739692245, "kl": 0.008834486449893932, "entropy": 1.5783976733369172, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 195.87999999999965, "episode_reward_min": -387.29000000000065, "episode_reward_mean": -38.44333333333347, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -367.84000000000015, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 141.3200000000001, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -89.94388888888892, "predator_policy": 70.72222222222223}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-101.63000000000031, -24.170000000000005, -12.639999999999626, 15.03999999999999, 8.940000000000202, 60.029999999999916, 15.259999999999986, -43.18000000000036, -26.95999999999982, -120.65000000000136, 92.06000000000039, -44.9800000000003, -185.26000000000056, -123.92999999999978, -65.30000000000028, -214.3700000000009, 69.77999999999993, 44.5499999999999, -18.21000000000003, -33.24999999999954, 91.23999999999995, -168.76000000000047, 77.21000000000022, 195.87999999999965, 28.950000000000138, -21.939999999999912, 21.709999999999827, -55.63999999999965, 19.679999999999744, -207.82000000000068, -343.8100000000002, 81.11000000000001, 57.24000000000006, 82.67000000000003, -145.5200000000006, -387.29000000000065], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-59.499999999999815, -225.1300000000005, 34.66999999999983, -367.84000000000015, -26.409999999999997, -26.229999999999727, 55.819999999999986, -142.7800000000001, 27.290000000000077, -68.3500000000003, -90.41999999999993, -15.549999999999999, -2.0500000000000416, -13.690000000000014, -174.1300000000008, -5.050000000000039, -207.0400000000008, 18.08, -172.87000000000094, -91.77999999999952, -108.33999999999982, 106.40000000000013, -64.32999999999947, -53.65000000000013, -210.31000000000057, -179.95, -87.69999999999995, -245.23000000000036, 2.0000000000000013, -223.30000000000052, -263.32000000000056, -125.04999999999984, -56.29000000000034, 49.069999999999986, 38.18000000000005, -61.62999999999934, -203.49999999999994, 15.289999999999994, -55.33000000000033, -107.92000000000002, 141.3200000000001, -197.0800000000003, -128.43999999999994, -263.3200000000006, -86.67999999999985, 63.88999999999991, 18.590000000000003, 96.29000000000015, -112.56999999999927, 52.51999999999997, -123.54999999999986, -31.389999999999873, -108.55000000000007, 75.26000000000029, 13.51999999999999, -231.16000000000065, -56.7999999999994, 11.480000000000139, -116.88999999999943, -346.92999999999995, -283.42000000000013, -277.3900000000001, 26.030000000000005, -35.920000000000215, 16.07, -71.83000000000001, 26.240000000000027, -88.56999999999991, -120.60999999999932, -290.9100000000001, -323.62000000000035, -333.6700000000003], "policy_predator_policy_reward": [113.0, 70.0, 152.0, 157.0, 17.0, 23.0, 35.0, 67.0, 29.0, 21.0, 74.0, 92.0, 3.0, 28.0, 53.0, 83.0, 104.0, 58.0, 91.0, 53.0, 23.0, 71.0, 40.0, 33.0, 162.0, 43.0, 123.0, 86.0, 54.0, 102.0, 22.0, 152.0, 32.0, 45.0, 11.0, 57.0, 52.0, 118.0, 100.0, 30.0, 61.0, 86.0, 91.0, 132.0, 15.0, 85.0, 55.0, 26.0, 57.0, 32.0, 112.0, 21.0, 55.0, 0.0, 60.0, 102.0, 22.0, 43.0, 190.0, 66.0, 173.0, 44.0, 57.0, 34.0, 33.0, 80.0, 73.0, 72.0, 181.0, 85.0, 123.0, 147.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2825118159332602, "mean_inference_ms": 4.234295678376883, "mean_action_processing_ms": 0.6711948998058335, "mean_env_wait_ms": 0.4777752752254815, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014499160978529189, "StateBufferConnector_ms": 0.003739860322740343, "ViewRequirementAgentConnector_ms": 0.15415814187791613}, "num_episodes": 18, "episode_return_max": 195.87999999999965, "episode_return_min": -387.29000000000065, "episode_return_mean": -38.44333333333347, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.887569247675, "num_env_steps_trained_throughput_per_sec": 351.887569247675, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 14086.909, "restore_workers_time_ms": 0.025, "training_step_time_ms": 14086.841, "sample_time_ms": 2532.542, "learn_time_ms": 11532.016, "learn_throughput": 346.86, "synch_weights_time_ms": 15.393}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "310e1_00000", "date": "2024-08-15_00-57-51", "timestamp": 1723663671, "time_this_iter_s": 11.409225225448608, "time_total_s": 28.285179376602173, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12d9c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 28.285179376602173, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 49.62, "ram_util_percent": 83.195}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9280053768050733, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.292260828472319, "policy_loss": -0.007071478134168992, "vf_loss": 5.29768224595085, "vf_explained_var": 0.002255689782440347, "kl": 0.008250262000510539, "entropy": 1.5705433533305213, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3114831373805091, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.114599228409864, "policy_loss": -0.005824304656643006, "vf_loss": 9.118748850040335, "vf_explained_var": 0.028560302118775707, "kl": 0.008373308913478041, "entropy": 1.5526749392665884, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 281.4, "episode_reward_min": -387.29000000000065, "episode_reward_mean": 2.0283333333332556, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -475.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.25, "predator_policy": 288.0}, "policy_reward_mean": {"prey_policy": -68.36546296296302, "predator_policy": 69.37962962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-101.63000000000031, -24.170000000000005, -12.639999999999626, 15.03999999999999, 8.940000000000202, 60.029999999999916, 15.259999999999986, -43.18000000000036, -26.95999999999982, -120.65000000000136, 92.06000000000039, -44.9800000000003, -185.26000000000056, -123.92999999999978, -65.30000000000028, -214.3700000000009, 69.77999999999993, 44.5499999999999, -18.21000000000003, -33.24999999999954, 91.23999999999995, -168.76000000000047, 77.21000000000022, 195.87999999999965, 28.950000000000138, -21.939999999999912, 21.709999999999827, -55.63999999999965, 19.679999999999744, -207.82000000000068, -343.8100000000002, 81.11000000000001, 57.24000000000006, 82.67000000000003, -145.5200000000006, -387.29000000000065, -51.5, 42.77000000000011, 247.39999999999986, 128.72999999999985, 49.44000000000006, 264.5699999999999, 147.19999999999993, 121.30000000000011, 126.22999999999999, 146.85000000000002, -42.0699999999991, -143.54000000000008, -42.70000000000004, 18.480000000000032, -46.97999999999972, 281.4, 205.73000000000002, 40.17999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-59.499999999999815, -225.1300000000005, 34.66999999999983, -367.84000000000015, -26.409999999999997, -26.229999999999727, 55.819999999999986, -142.7800000000001, 27.290000000000077, -68.3500000000003, -90.41999999999993, -15.549999999999999, -2.0500000000000416, -13.690000000000014, -174.1300000000008, -5.050000000000039, -207.0400000000008, 18.08, -172.87000000000094, -91.77999999999952, -108.33999999999982, 106.40000000000013, -64.32999999999947, -53.65000000000013, -210.31000000000057, -179.95, -87.69999999999995, -245.23000000000036, 2.0000000000000013, -223.30000000000052, -263.32000000000056, -125.04999999999984, -56.29000000000034, 49.069999999999986, 38.18000000000005, -61.62999999999934, -203.49999999999994, 15.289999999999994, -55.33000000000033, -107.92000000000002, 141.3200000000001, -197.0800000000003, -128.43999999999994, -263.3200000000006, -86.67999999999985, 63.88999999999991, 18.590000000000003, 96.29000000000015, -112.56999999999927, 52.51999999999997, -123.54999999999986, -31.389999999999873, -108.55000000000007, 75.26000000000029, 13.51999999999999, -231.16000000000065, -56.7999999999994, 11.480000000000139, -116.88999999999943, -346.92999999999995, -283.42000000000013, -277.3900000000001, 26.030000000000005, -35.920000000000215, 16.07, -71.83000000000001, 26.240000000000027, -88.56999999999991, -120.60999999999932, -290.9100000000001, -323.62000000000035, -333.6700000000003, -44.49999999999986, -202.0, -67.96, -16.270000000000152, 123.55999999999992, 116.84000000000016, -16.990000000000002, 38.719999999999864, 109.28000000000014, -182.84000000000023, 154.25000000000006, 57.31999999999996, -61.390000000000555, 108.59000000000009, -90.69999999999987, 80.0, 1.1900000000000688, -25.95999999999998, 175.25, -162.40000000000055, 16.609999999999964, -134.6800000000011, -177.64000000000016, -202.89999999999995, -126.72999999999992, -99.97, 159.38000000000002, -475.9, -247.2400000000007, 27.260000000000005, 136.39999999999995, 110.0, 10.190000000000026, 134.54000000000005, 104.17999999999996, -235.0], "policy_predator_policy_reward": [113.0, 70.0, 152.0, 157.0, 17.0, 23.0, 35.0, 67.0, 29.0, 21.0, 74.0, 92.0, 3.0, 28.0, 53.0, 83.0, 104.0, 58.0, 91.0, 53.0, 23.0, 71.0, 40.0, 33.0, 162.0, 43.0, 123.0, 86.0, 54.0, 102.0, 22.0, 152.0, 32.0, 45.0, 11.0, 57.0, 52.0, 118.0, 100.0, 30.0, 61.0, 86.0, 91.0, 132.0, 15.0, 85.0, 55.0, 26.0, 57.0, 32.0, 112.0, 21.0, 55.0, 0.0, 60.0, 102.0, 22.0, 43.0, 190.0, 66.0, 173.0, 44.0, 57.0, 34.0, 33.0, 80.0, 73.0, 72.0, 181.0, 85.0, 123.0, 147.0, 137.0, 58.0, 49.0, 78.0, 5.0, 2.0, 66.0, 41.0, 20.0, 103.0, 33.0, 20.0, 67.0, 33.0, 76.0, 56.0, 54.0, 97.0, 101.0, 33.0, 68.0, 8.0, 157.0, 80.0, 52.0, 132.0, 288.0, 47.0, 49.0, 124.0, 30.0, 5.0, 15.0, 46.0, 26.0, 145.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1657058603266055, "mean_inference_ms": 3.7547144423495156, "mean_action_processing_ms": 0.5946434848566123, "mean_env_wait_ms": 0.430487462969494, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011740569715146665, "StateBufferConnector_ms": 0.0034868717193603516, "ViewRequirementAgentConnector_ms": 0.12945157510262947}, "num_episodes": 18, "episode_return_max": 281.4, "episode_return_min": -387.29000000000065, "episode_return_mean": 2.0283333333332556, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.59880845167766, "num_env_steps_trained_throughput_per_sec": 350.59880845167766, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 13194.293, "restore_workers_time_ms": 0.021, "training_step_time_ms": 13194.232, "sample_time_ms": 2100.7, "learn_time_ms": 11074.449, "learn_throughput": 361.192, "synch_weights_time_ms": 14.152}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "310e1_00000", "date": "2024-08-15_00-58-03", "timestamp": 1723663683, "time_this_iter_s": 11.453631162643433, "time_total_s": 39.738810539245605, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12d90d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 39.738810539245605, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 52.587500000000006, "ram_util_percent": 83.03125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0395891193517302, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.910713691560049, "policy_loss": -0.009876254909036179, "vf_loss": 5.91806487860503, "vf_explained_var": 0.035468567584557506, "kl": 0.012625323102704334, "entropy": 1.5577505796043962, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6073338640429986, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.278463199655846, "policy_loss": -0.007669551959803338, "vf_loss": 9.28345018669411, "vf_explained_var": -0.0143064989614739, "kl": 0.013412727492569587, "entropy": 1.5161322246152888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 281.4, "episode_reward_min": -387.29000000000065, "episode_reward_mean": 9.383194444444397, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -475.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.25, "predator_policy": 288.0}, "policy_reward_mean": {"prey_policy": -64.10701388888894, "predator_policy": 68.79861111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-101.63000000000031, -24.170000000000005, -12.639999999999626, 15.03999999999999, 8.940000000000202, 60.029999999999916, 15.259999999999986, -43.18000000000036, -26.95999999999982, -120.65000000000136, 92.06000000000039, -44.9800000000003, -185.26000000000056, -123.92999999999978, -65.30000000000028, -214.3700000000009, 69.77999999999993, 44.5499999999999, -18.21000000000003, -33.24999999999954, 91.23999999999995, -168.76000000000047, 77.21000000000022, 195.87999999999965, 28.950000000000138, -21.939999999999912, 21.709999999999827, -55.63999999999965, 19.679999999999744, -207.82000000000068, -343.8100000000002, 81.11000000000001, 57.24000000000006, 82.67000000000003, -145.5200000000006, -387.29000000000065, -51.5, 42.77000000000011, 247.39999999999986, 128.72999999999985, 49.44000000000006, 264.5699999999999, 147.19999999999993, 121.30000000000011, 126.22999999999999, 146.85000000000002, -42.0699999999991, -143.54000000000008, -42.70000000000004, 18.480000000000032, -46.97999999999972, 281.4, 205.73000000000002, 40.17999999999999, 116.52000000000007, 42.130000000000024, -123.24999999999966, 151.44999999999987, 216.49999999999994, -71.2799999999998, -298.87000000000006, 144.63000000000022, -17.80999999999995, -63.77999999999989, 101.77000000000011, 120.34000000000009, 66.57, -124.5799999999999, -44.00000000000009, 131.37999999999977, 254.87999999999997, -36.54000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-59.499999999999815, -225.1300000000005, 34.66999999999983, -367.84000000000015, -26.409999999999997, -26.229999999999727, 55.819999999999986, -142.7800000000001, 27.290000000000077, -68.3500000000003, -90.41999999999993, -15.549999999999999, -2.0500000000000416, -13.690000000000014, -174.1300000000008, -5.050000000000039, -207.0400000000008, 18.08, -172.87000000000094, -91.77999999999952, -108.33999999999982, 106.40000000000013, -64.32999999999947, -53.65000000000013, -210.31000000000057, -179.95, -87.69999999999995, -245.23000000000036, 2.0000000000000013, -223.30000000000052, -263.32000000000056, -125.04999999999984, -56.29000000000034, 49.069999999999986, 38.18000000000005, -61.62999999999934, -203.49999999999994, 15.289999999999994, -55.33000000000033, -107.92000000000002, 141.3200000000001, -197.0800000000003, -128.43999999999994, -263.3200000000006, -86.67999999999985, 63.88999999999991, 18.590000000000003, 96.29000000000015, -112.56999999999927, 52.51999999999997, -123.54999999999986, -31.389999999999873, -108.55000000000007, 75.26000000000029, 13.51999999999999, -231.16000000000065, -56.7999999999994, 11.480000000000139, -116.88999999999943, -346.92999999999995, -283.42000000000013, -277.3900000000001, 26.030000000000005, -35.920000000000215, 16.07, -71.83000000000001, 26.240000000000027, -88.56999999999991, -120.60999999999932, -290.9100000000001, -323.62000000000035, -333.6700000000003, -44.49999999999986, -202.0, -67.96, -16.270000000000152, 123.55999999999992, 116.84000000000016, -16.990000000000002, 38.719999999999864, 109.28000000000014, -182.84000000000023, 154.25000000000006, 57.31999999999996, -61.390000000000555, 108.59000000000009, -90.69999999999987, 80.0, 1.1900000000000688, -25.95999999999998, 175.25, -162.40000000000055, 16.609999999999964, -134.6800000000011, -177.64000000000016, -202.89999999999995, -126.72999999999992, -99.97, 159.38000000000002, -475.9, -247.2400000000007, 27.260000000000005, 136.39999999999995, 110.0, 10.190000000000026, 134.54000000000005, 104.17999999999996, -235.0, -41.74000000000004, 51.26, -49.360000000000014, -7.510000000000074, -393.61000000000035, -39.639999999999944, 24.26000000000001, 49.190000000000005, 141.08000000000004, 8.420000000000076, -84.01000000000019, -85.27000000000001, -301.93, -324.94000000000005, 28.04, 15.589999999999966, -52.93000000000001, -117.87999999999994, -127.0, -118.77999999999989, 25.76, -13.990000000000002, 71.21000000000001, -22.87000000000009, -57.67000000000018, 44.240000000000016, -133.83999999999995, -185.74, 28.940000000000055, -228.94000000000005, -16.210000000000157, 81.58999999999989, 83.66000000000001, 142.22000000000003, -91.53999999999998, -148.0], "policy_predator_policy_reward": [113.0, 70.0, 152.0, 157.0, 17.0, 23.0, 35.0, 67.0, 29.0, 21.0, 74.0, 92.0, 3.0, 28.0, 53.0, 83.0, 104.0, 58.0, 91.0, 53.0, 23.0, 71.0, 40.0, 33.0, 162.0, 43.0, 123.0, 86.0, 54.0, 102.0, 22.0, 152.0, 32.0, 45.0, 11.0, 57.0, 52.0, 118.0, 100.0, 30.0, 61.0, 86.0, 91.0, 132.0, 15.0, 85.0, 55.0, 26.0, 57.0, 32.0, 112.0, 21.0, 55.0, 0.0, 60.0, 102.0, 22.0, 43.0, 190.0, 66.0, 173.0, 44.0, 57.0, 34.0, 33.0, 80.0, 73.0, 72.0, 181.0, 85.0, 123.0, 147.0, 137.0, 58.0, 49.0, 78.0, 5.0, 2.0, 66.0, 41.0, 20.0, 103.0, 33.0, 20.0, 67.0, 33.0, 76.0, 56.0, 54.0, 97.0, 101.0, 33.0, 68.0, 8.0, 157.0, 80.0, 52.0, 132.0, 288.0, 47.0, 49.0, 124.0, 30.0, 5.0, 15.0, 46.0, 26.0, 145.0, 80.0, 27.0, 62.0, 37.0, 68.0, 242.0, 34.0, 44.0, 53.0, 14.0, 76.0, 22.0, 140.0, 188.0, 41.0, 60.0, 136.0, 17.0, 50.0, 132.0, 24.0, 66.0, 18.0, 54.0, 39.0, 41.0, 82.0, 113.0, 147.0, 9.0, 30.0, 36.0, 12.0, 17.0, 153.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0879517850680411, "mean_inference_ms": 3.43859594852032, "mean_action_processing_ms": 0.5442046349370843, "mean_env_wait_ms": 0.3987613422515524, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010541412565443251, "StateBufferConnector_ms": 0.0035030974282158744, "ViewRequirementAgentConnector_ms": 0.12559973531299168}, "num_episodes": 18, "episode_return_max": 281.4, "episode_return_min": -387.29000000000065, "episode_return_mean": 9.383194444444397, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.16644963543683, "num_env_steps_trained_throughput_per_sec": 358.16644963543683, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 12687.719, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12687.662, "sample_time_ms": 1889.813, "learn_time_ms": 10779.223, "learn_throughput": 371.084, "synch_weights_time_ms": 14.346}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "310e1_00000", "date": "2024-08-15_00-58-14", "timestamp": 1723663694, "time_this_iter_s": 11.211354970932007, "time_total_s": 50.95016551017761, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14733a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 50.95016551017761, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 49.63125, "ram_util_percent": 83.45625000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.460485967725673, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.976040051727699, "policy_loss": -0.013028897717964673, "vf_loss": 7.9860234613771794, "vf_explained_var": 0.00786777867211236, "kl": 0.015227445171568427, "entropy": 1.523979388216816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.901503152758987, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.250226667192248, "policy_loss": -0.006317480708960267, "vf_loss": 9.254480337718176, "vf_explained_var": -0.04156812076215391, "kl": 0.010319156886072605, "entropy": 1.5106538526595585, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 316.77999999999986, "episode_reward_min": -387.29000000000065, "episode_reward_mean": -3.311212121212162, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -475.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.25, "predator_policy": 288.0}, "policy_reward_mean": {"prey_policy": -76.564696969697, "predator_policy": 74.9090909090909}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-101.63000000000031, -24.170000000000005, -12.639999999999626, 15.03999999999999, 8.940000000000202, 60.029999999999916, 15.259999999999986, -43.18000000000036, -26.95999999999982, -120.65000000000136, 92.06000000000039, -44.9800000000003, -185.26000000000056, -123.92999999999978, -65.30000000000028, -214.3700000000009, 69.77999999999993, 44.5499999999999, -18.21000000000003, -33.24999999999954, 91.23999999999995, -168.76000000000047, 77.21000000000022, 195.87999999999965, 28.950000000000138, -21.939999999999912, 21.709999999999827, -55.63999999999965, 19.679999999999744, -207.82000000000068, -343.8100000000002, 81.11000000000001, 57.24000000000006, 82.67000000000003, -145.5200000000006, -387.29000000000065, -51.5, 42.77000000000011, 247.39999999999986, 128.72999999999985, 49.44000000000006, 264.5699999999999, 147.19999999999993, 121.30000000000011, 126.22999999999999, 146.85000000000002, -42.0699999999991, -143.54000000000008, -42.70000000000004, 18.480000000000032, -46.97999999999972, 281.4, 205.73000000000002, 40.17999999999999, 116.52000000000007, 42.130000000000024, -123.24999999999966, 151.44999999999987, 216.49999999999994, -71.2799999999998, -298.87000000000006, 144.63000000000022, -17.80999999999995, -63.77999999999989, 101.77000000000011, 120.34000000000009, 66.57, -124.5799999999999, -44.00000000000009, 131.37999999999977, 254.87999999999997, -36.54000000000002, 132.69000000000028, -261.7800000000001, -237.59000000000006, 207.3199999999998, -102.23999999999974, 156.45000000000027, 42.75000000000003, -190.73000000000025, 71.58999999999996, 316.77999999999986, -9.389999999999796, -104.4900000000003, 107.89000000000003, 70.71000000000029, -325.94, -17.960000000000008, -41.29999999999998, -163.63000000000017, -55.82999999999998, -43.35000000000007, -10.639999999999876, -129.99000000000012, -9.58999999999999, 55.62000000000021, -190.14000000000073, -42.160000000000046, -228.4500000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-59.499999999999815, -225.1300000000005, 34.66999999999983, -367.84000000000015, -26.409999999999997, -26.229999999999727, 55.819999999999986, -142.7800000000001, 27.290000000000077, -68.3500000000003, -90.41999999999993, -15.549999999999999, -2.0500000000000416, -13.690000000000014, -174.1300000000008, -5.050000000000039, -207.0400000000008, 18.08, -172.87000000000094, -91.77999999999952, -108.33999999999982, 106.40000000000013, -64.32999999999947, -53.65000000000013, -210.31000000000057, -179.95, -87.69999999999995, -245.23000000000036, 2.0000000000000013, -223.30000000000052, -263.32000000000056, -125.04999999999984, -56.29000000000034, 49.069999999999986, 38.18000000000005, -61.62999999999934, -203.49999999999994, 15.289999999999994, -55.33000000000033, -107.92000000000002, 141.3200000000001, -197.0800000000003, -128.43999999999994, -263.3200000000006, -86.67999999999985, 63.88999999999991, 18.590000000000003, 96.29000000000015, -112.56999999999927, 52.51999999999997, -123.54999999999986, -31.389999999999873, -108.55000000000007, 75.26000000000029, 13.51999999999999, -231.16000000000065, -56.7999999999994, 11.480000000000139, -116.88999999999943, -346.92999999999995, -283.42000000000013, -277.3900000000001, 26.030000000000005, -35.920000000000215, 16.07, -71.83000000000001, 26.240000000000027, -88.56999999999991, -120.60999999999932, -290.9100000000001, -323.62000000000035, -333.6700000000003, -44.49999999999986, -202.0, -67.96, -16.270000000000152, 123.55999999999992, 116.84000000000016, -16.990000000000002, 38.719999999999864, 109.28000000000014, -182.84000000000023, 154.25000000000006, 57.31999999999996, -61.390000000000555, 108.59000000000009, -90.69999999999987, 80.0, 1.1900000000000688, -25.95999999999998, 175.25, -162.40000000000055, 16.609999999999964, -134.6800000000011, -177.64000000000016, -202.89999999999995, -126.72999999999992, -99.97, 159.38000000000002, -475.9, -247.2400000000007, 27.260000000000005, 136.39999999999995, 110.0, 10.190000000000026, 134.54000000000005, 104.17999999999996, -235.0, -41.74000000000004, 51.26, -49.360000000000014, -7.510000000000074, -393.61000000000035, -39.639999999999944, 24.26000000000001, 49.190000000000005, 141.08000000000004, 8.420000000000076, -84.01000000000019, -85.27000000000001, -301.93, -324.94000000000005, 28.04, 15.589999999999966, -52.93000000000001, -117.87999999999994, -127.0, -118.77999999999989, 25.76, -13.990000000000002, 71.21000000000001, -22.87000000000009, -57.67000000000018, 44.240000000000016, -133.83999999999995, -185.74, 28.940000000000055, -228.94000000000005, -16.210000000000157, 81.58999999999989, 83.66000000000001, 142.22000000000003, -91.53999999999998, -148.0, 33.050000000000026, 7.640000000000327, -172.77999999999997, -394.0, -249.94, -245.65000000000003, 151.04000000000002, -19.720000000000006, -110.26000000000025, -215.98000000000002, 3.829999999999988, 84.62000000000006, -7.300000000000001, -68.94999999999999, -317.8000000000002, -175.92999999999998, -42.55000000000007, -14.859999999999989, 143.53999999999996, 170.23999999999995, -33.88000000000007, -148.51000000000002, -138.82000000000016, -99.67000000000019, -24.159999999999805, 30.049999999999997, -24.790000000000006, -23.499999999999947, -322.96, -323.98, -106.99000000000001, -114.97000000000003, -56.94999999999999, -183.34999999999982, -242.68000000000023, -155.95000000000005, -115.84000000000003, -169.99, -261.7900000000002, -35.56000000000003, -92.55999999999926, -77.08000000000004, -193.0, -169.99, -27.819999999999993, -191.77000000000015, -101.3799999999999, 43.999999999999936, -336.97, -92.16999999999959, -235.9000000000001, 18.740000000000002, -166.45000000000016, -310.0], "policy_predator_policy_reward": [113.0, 70.0, 152.0, 157.0, 17.0, 23.0, 35.0, 67.0, 29.0, 21.0, 74.0, 92.0, 3.0, 28.0, 53.0, 83.0, 104.0, 58.0, 91.0, 53.0, 23.0, 71.0, 40.0, 33.0, 162.0, 43.0, 123.0, 86.0, 54.0, 102.0, 22.0, 152.0, 32.0, 45.0, 11.0, 57.0, 52.0, 118.0, 100.0, 30.0, 61.0, 86.0, 91.0, 132.0, 15.0, 85.0, 55.0, 26.0, 57.0, 32.0, 112.0, 21.0, 55.0, 0.0, 60.0, 102.0, 22.0, 43.0, 190.0, 66.0, 173.0, 44.0, 57.0, 34.0, 33.0, 80.0, 73.0, 72.0, 181.0, 85.0, 123.0, 147.0, 137.0, 58.0, 49.0, 78.0, 5.0, 2.0, 66.0, 41.0, 20.0, 103.0, 33.0, 20.0, 67.0, 33.0, 76.0, 56.0, 54.0, 97.0, 101.0, 33.0, 68.0, 8.0, 157.0, 80.0, 52.0, 132.0, 288.0, 47.0, 49.0, 124.0, 30.0, 5.0, 15.0, 46.0, 26.0, 145.0, 80.0, 27.0, 62.0, 37.0, 68.0, 242.0, 34.0, 44.0, 53.0, 14.0, 76.0, 22.0, 140.0, 188.0, 41.0, 60.0, 136.0, 17.0, 50.0, 132.0, 24.0, 66.0, 18.0, 54.0, 39.0, 41.0, 82.0, 113.0, 147.0, 9.0, 30.0, 36.0, 12.0, 17.0, 153.0, 50.0, 54.0, 38.0, 121.0, 184.0, 90.0, 168.0, 54.0, 22.0, 70.0, 154.0, 54.0, 14.0, 70.0, 49.0, 167.0, 136.0, 18.0, 111.0, 1.0, 2.0, 81.0, 92.0, 36.0, 98.0, 47.0, 55.0, 49.0, 70.0, 146.0, 175.0, 82.0, 122.0, 109.0, 90.0, 79.0, 156.0, 104.0, 126.0, 137.0, 117.0, 62.0, 97.0, 131.0, 102.0, 111.0, 99.0, 42.0, 71.0, 91.0, 148.0, 36.0, 139.0, 97.0, 151.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0108709465122812, "mean_inference_ms": 3.1298350033028366, "mean_action_processing_ms": 0.49502549535637136, "mean_env_wait_ms": 0.36739909694205153, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009486289939495048, "StateBufferConnector_ms": 0.0034957221060088186, "ViewRequirementAgentConnector_ms": 0.1224804406214242}, "num_episodes": 27, "episode_return_max": 316.77999999999986, "episode_return_min": -387.29000000000065, "episode_return_mean": -3.311212121212162, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.61616402790037, "num_env_steps_trained_throughput_per_sec": 353.61616402790037, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 12412.517, "restore_workers_time_ms": 0.018, "training_step_time_ms": 12412.462, "sample_time_ms": 1760.468, "learn_time_ms": 10634.156, "learn_throughput": 376.146, "synch_weights_time_ms": 13.928}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "310e1_00000", "date": "2024-08-15_00-58-25", "timestamp": 1723663705, "time_this_iter_s": 11.357540130615234, "time_total_s": 62.30770564079285, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14d84c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 62.30770564079285, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 49.49375, "ram_util_percent": 83.55625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5237934576613563, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.552374991916475, "policy_loss": -0.006661691334561775, "vf_loss": 8.556983269837799, "vf_explained_var": 0.015553629335272249, "kl": 0.010267118290922703, "entropy": 1.5108182191848756, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6443028865037141, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.894202468256472, "policy_loss": -0.005771278949434716, "vf_loss": 8.898300907094642, "vf_explained_var": -0.030292786712999696, "kl": 0.008364145496129054, "entropy": 1.5410480971689577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 316.77999999999986, "episode_reward_min": -387.29000000000065, "episode_reward_mean": -24.878700000000023, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -475.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.25, "predator_policy": 288.0}, "policy_reward_mean": {"prey_policy": -95.89935000000003, "predator_policy": 83.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.5499999999999, -18.21000000000003, -33.24999999999954, 91.23999999999995, -168.76000000000047, 77.21000000000022, 195.87999999999965, 28.950000000000138, -21.939999999999912, 21.709999999999827, -55.63999999999965, 19.679999999999744, -207.82000000000068, -343.8100000000002, 81.11000000000001, 57.24000000000006, 82.67000000000003, -145.5200000000006, -387.29000000000065, -51.5, 42.77000000000011, 247.39999999999986, 128.72999999999985, 49.44000000000006, 264.5699999999999, 147.19999999999993, 121.30000000000011, 126.22999999999999, 146.85000000000002, -42.0699999999991, -143.54000000000008, -42.70000000000004, 18.480000000000032, -46.97999999999972, 281.4, 205.73000000000002, 40.17999999999999, 116.52000000000007, 42.130000000000024, -123.24999999999966, 151.44999999999987, 216.49999999999994, -71.2799999999998, -298.87000000000006, 144.63000000000022, -17.80999999999995, -63.77999999999989, 101.77000000000011, 120.34000000000009, 66.57, -124.5799999999999, -44.00000000000009, 131.37999999999977, 254.87999999999997, -36.54000000000002, 132.69000000000028, -261.7800000000001, -237.59000000000006, 207.3199999999998, -102.23999999999974, 156.45000000000027, 42.75000000000003, -190.73000000000025, 71.58999999999996, 316.77999999999986, -9.389999999999796, -104.4900000000003, 107.89000000000003, 70.71000000000029, -325.94, -17.960000000000008, -41.29999999999998, -163.63000000000017, -55.82999999999998, -43.35000000000007, -10.639999999999876, -129.99000000000012, -9.58999999999999, 55.62000000000021, -190.14000000000073, -42.160000000000046, -228.4500000000002, -282.8400000000006, -214.51000000000002, -156.23000000000027, -312.90000000000003, -128.59999999999985, 26.11999999999963, -192.18, -202.19999999999987, -103.36999999999945, 30.029999999999824, -367.6000000000003, -164.80000000000038, -211.18000000000038, -78.17000000000026, -308.5999999999999, 56.83000000000021, -131.96999999999997, -119.84999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [38.18000000000005, -61.62999999999934, -203.49999999999994, 15.289999999999994, -55.33000000000033, -107.92000000000002, 141.3200000000001, -197.0800000000003, -128.43999999999994, -263.3200000000006, -86.67999999999985, 63.88999999999991, 18.590000000000003, 96.29000000000015, -112.56999999999927, 52.51999999999997, -123.54999999999986, -31.389999999999873, -108.55000000000007, 75.26000000000029, 13.51999999999999, -231.16000000000065, -56.7999999999994, 11.480000000000139, -116.88999999999943, -346.92999999999995, -283.42000000000013, -277.3900000000001, 26.030000000000005, -35.920000000000215, 16.07, -71.83000000000001, 26.240000000000027, -88.56999999999991, -120.60999999999932, -290.9100000000001, -323.62000000000035, -333.6700000000003, -44.49999999999986, -202.0, -67.96, -16.270000000000152, 123.55999999999992, 116.84000000000016, -16.990000000000002, 38.719999999999864, 109.28000000000014, -182.84000000000023, 154.25000000000006, 57.31999999999996, -61.390000000000555, 108.59000000000009, -90.69999999999987, 80.0, 1.1900000000000688, -25.95999999999998, 175.25, -162.40000000000055, 16.609999999999964, -134.6800000000011, -177.64000000000016, -202.89999999999995, -126.72999999999992, -99.97, 159.38000000000002, -475.9, -247.2400000000007, 27.260000000000005, 136.39999999999995, 110.0, 10.190000000000026, 134.54000000000005, 104.17999999999996, -235.0, -41.74000000000004, 51.26, -49.360000000000014, -7.510000000000074, -393.61000000000035, -39.639999999999944, 24.26000000000001, 49.190000000000005, 141.08000000000004, 8.420000000000076, -84.01000000000019, -85.27000000000001, -301.93, -324.94000000000005, 28.04, 15.589999999999966, -52.93000000000001, -117.87999999999994, -127.0, -118.77999999999989, 25.76, -13.990000000000002, 71.21000000000001, -22.87000000000009, -57.67000000000018, 44.240000000000016, -133.83999999999995, -185.74, 28.940000000000055, -228.94000000000005, -16.210000000000157, 81.58999999999989, 83.66000000000001, 142.22000000000003, -91.53999999999998, -148.0, 33.050000000000026, 7.640000000000327, -172.77999999999997, -394.0, -249.94, -245.65000000000003, 151.04000000000002, -19.720000000000006, -110.26000000000025, -215.98000000000002, 3.829999999999988, 84.62000000000006, -7.300000000000001, -68.94999999999999, -317.8000000000002, -175.92999999999998, -42.55000000000007, -14.859999999999989, 143.53999999999996, 170.23999999999995, -33.88000000000007, -148.51000000000002, -138.82000000000016, -99.67000000000019, -24.159999999999805, 30.049999999999997, -24.790000000000006, -23.499999999999947, -322.96, -323.98, -106.99000000000001, -114.97000000000003, -56.94999999999999, -183.34999999999982, -242.68000000000023, -155.95000000000005, -115.84000000000003, -169.99, -261.7900000000002, -35.56000000000003, -92.55999999999926, -77.08000000000004, -193.0, -169.99, -27.819999999999993, -191.77000000000015, -101.3799999999999, 43.999999999999936, -336.97, -92.16999999999959, -235.9000000000001, 18.740000000000002, -166.45000000000016, -310.0, -233.3200000000004, -285.5200000000002, -243.79000000000002, -337.72000000000025, -185.95000000000002, -204.28000000000029, -170.95, -329.95000000000005, -275.6200000000003, -71.97999999999996, -11.710000000000257, -71.17000000000016, -144.4300000000001, -229.74999999999994, -189.42999999999995, -296.7699999999999, -70.18000000000006, -231.1900000000007, -68.56000000000002, -80.40999999999919, -373.87000000000006, -345.73000000000025, -303.67000000000013, -120.12999999999957, -260.62000000000023, -227.56000000000026, -154.51, -67.65999999999983, -332.83, -296.7700000000001, 68.21000000000001, -74.37999999999917, -177.85000000000002, -223.1200000000003, -102.16000000000003, -307.6900000000002], "policy_predator_policy_reward": [11.0, 57.0, 52.0, 118.0, 100.0, 30.0, 61.0, 86.0, 91.0, 132.0, 15.0, 85.0, 55.0, 26.0, 57.0, 32.0, 112.0, 21.0, 55.0, 0.0, 60.0, 102.0, 22.0, 43.0, 190.0, 66.0, 173.0, 44.0, 57.0, 34.0, 33.0, 80.0, 73.0, 72.0, 181.0, 85.0, 123.0, 147.0, 137.0, 58.0, 49.0, 78.0, 5.0, 2.0, 66.0, 41.0, 20.0, 103.0, 33.0, 20.0, 67.0, 33.0, 76.0, 56.0, 54.0, 97.0, 101.0, 33.0, 68.0, 8.0, 157.0, 80.0, 52.0, 132.0, 288.0, 47.0, 49.0, 124.0, 30.0, 5.0, 15.0, 46.0, 26.0, 145.0, 80.0, 27.0, 62.0, 37.0, 68.0, 242.0, 34.0, 44.0, 53.0, 14.0, 76.0, 22.0, 140.0, 188.0, 41.0, 60.0, 136.0, 17.0, 50.0, 132.0, 24.0, 66.0, 18.0, 54.0, 39.0, 41.0, 82.0, 113.0, 147.0, 9.0, 30.0, 36.0, 12.0, 17.0, 153.0, 50.0, 54.0, 38.0, 121.0, 184.0, 90.0, 168.0, 54.0, 22.0, 70.0, 154.0, 54.0, 14.0, 70.0, 49.0, 167.0, 136.0, 18.0, 111.0, 1.0, 2.0, 81.0, 92.0, 36.0, 98.0, 47.0, 55.0, 49.0, 70.0, 146.0, 175.0, 82.0, 122.0, 109.0, 90.0, 79.0, 156.0, 104.0, 126.0, 137.0, 117.0, 62.0, 97.0, 131.0, 102.0, 111.0, 99.0, 42.0, 71.0, 91.0, 148.0, 36.0, 139.0, 97.0, 151.0, 108.0, 128.0, 176.0, 191.0, 124.0, 110.0, 176.0, 12.0, 155.0, 64.0, 54.0, 55.0, 175.0, 7.0, 159.0, 125.0, 77.0, 121.0, 105.0, 74.0, 174.0, 178.0, 128.0, 131.0, 118.0, 159.0, 77.0, 67.0, 172.0, 149.0, 22.0, 41.0, 134.0, 135.0, 133.0, 157.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8902297478624743, "mean_inference_ms": 2.638874353081939, "mean_action_processing_ms": 0.4170258167198302, "mean_env_wait_ms": 0.31813816565125996, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005931258201599121, "StateBufferConnector_ms": 0.0033189058303833008, "ViewRequirementAgentConnector_ms": 0.10475754737854004}, "num_episodes": 18, "episode_return_max": 316.77999999999986, "episode_return_min": -387.29000000000065, "episode_return_mean": -24.878700000000023, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.37048595064897, "num_env_steps_trained_throughput_per_sec": 354.37048595064897, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 12225.036, "restore_workers_time_ms": 0.018, "training_step_time_ms": 12224.982, "sample_time_ms": 1687.155, "learn_time_ms": 10520.232, "learn_throughput": 380.22, "synch_weights_time_ms": 14.039}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "310e1_00000", "date": "2024-08-15_00-58-37", "timestamp": 1723663717, "time_this_iter_s": 11.340474128723145, "time_total_s": 73.64817976951599, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b146fee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 73.64817976951599, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 50.14375, "ram_util_percent": 83.475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7684683456622734, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.702504207974389, "policy_loss": -0.004905888611800653, "vf_loss": 8.705540138829953, "vf_explained_var": 0.015224116252212929, "kl": 0.009349816553627533, "entropy": 1.5065393445983766, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4328913705374198, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.1930029558757, "policy_loss": -0.008855175952151143, "vf_loss": 8.19946802532862, "vf_explained_var": -0.05915411672894917, "kl": 0.011950373952681788, "entropy": 1.5521022843305396, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 316.77999999999986, "episode_reward_min": -387.29000000000065, "episode_reward_mean": -47.444200000000066, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -475.9, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 175.25, "predator_policy": 288.0}, "policy_reward_mean": {"prey_policy": -115.32710000000006, "predator_policy": 91.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-387.29000000000065, -51.5, 42.77000000000011, 247.39999999999986, 128.72999999999985, 49.44000000000006, 264.5699999999999, 147.19999999999993, 121.30000000000011, 126.22999999999999, 146.85000000000002, -42.0699999999991, -143.54000000000008, -42.70000000000004, 18.480000000000032, -46.97999999999972, 281.4, 205.73000000000002, 40.17999999999999, 116.52000000000007, 42.130000000000024, -123.24999999999966, 151.44999999999987, 216.49999999999994, -71.2799999999998, -298.87000000000006, 144.63000000000022, -17.80999999999995, -63.77999999999989, 101.77000000000011, 120.34000000000009, 66.57, -124.5799999999999, -44.00000000000009, 131.37999999999977, 254.87999999999997, -36.54000000000002, 132.69000000000028, -261.7800000000001, -237.59000000000006, 207.3199999999998, -102.23999999999974, 156.45000000000027, 42.75000000000003, -190.73000000000025, 71.58999999999996, 316.77999999999986, -9.389999999999796, -104.4900000000003, 107.89000000000003, 70.71000000000029, -325.94, -17.960000000000008, -41.29999999999998, -163.63000000000017, -55.82999999999998, -43.35000000000007, -10.639999999999876, -129.99000000000012, -9.58999999999999, 55.62000000000021, -190.14000000000073, -42.160000000000046, -228.4500000000002, -282.8400000000006, -214.51000000000002, -156.23000000000027, -312.90000000000003, -128.59999999999985, 26.11999999999963, -192.18, -202.19999999999987, -103.36999999999945, 30.029999999999824, -367.6000000000003, -164.80000000000038, -211.18000000000038, -78.17000000000026, -308.5999999999999, 56.83000000000021, -131.96999999999997, -119.84999999999995, -216.70000000000076, -81.49999999999925, -255.15000000000077, -110.80999999999953, -179.2300000000012, -214.91, -11.99000000000031, -205.59000000000015, -169.98000000000047, -178.34000000000134, -49.29000000000019, 7.830000000000048, -34.77999999999985, -279.7400000000002, -211.3000000000003, -186.6600000000006, -31.829999999999913, -141.29000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-323.62000000000035, -333.6700000000003, -44.49999999999986, -202.0, -67.96, -16.270000000000152, 123.55999999999992, 116.84000000000016, -16.990000000000002, 38.719999999999864, 109.28000000000014, -182.84000000000023, 154.25000000000006, 57.31999999999996, -61.390000000000555, 108.59000000000009, -90.69999999999987, 80.0, 1.1900000000000688, -25.95999999999998, 175.25, -162.40000000000055, 16.609999999999964, -134.6800000000011, -177.64000000000016, -202.89999999999995, -126.72999999999992, -99.97, 159.38000000000002, -475.9, -247.2400000000007, 27.260000000000005, 136.39999999999995, 110.0, 10.190000000000026, 134.54000000000005, 104.17999999999996, -235.0, -41.74000000000004, 51.26, -49.360000000000014, -7.510000000000074, -393.61000000000035, -39.639999999999944, 24.26000000000001, 49.190000000000005, 141.08000000000004, 8.420000000000076, -84.01000000000019, -85.27000000000001, -301.93, -324.94000000000005, 28.04, 15.589999999999966, -52.93000000000001, -117.87999999999994, -127.0, -118.77999999999989, 25.76, -13.990000000000002, 71.21000000000001, -22.87000000000009, -57.67000000000018, 44.240000000000016, -133.83999999999995, -185.74, 28.940000000000055, -228.94000000000005, -16.210000000000157, 81.58999999999989, 83.66000000000001, 142.22000000000003, -91.53999999999998, -148.0, 33.050000000000026, 7.640000000000327, -172.77999999999997, -394.0, -249.94, -245.65000000000003, 151.04000000000002, -19.720000000000006, -110.26000000000025, -215.98000000000002, 3.829999999999988, 84.62000000000006, -7.300000000000001, -68.94999999999999, -317.8000000000002, -175.92999999999998, -42.55000000000007, -14.859999999999989, 143.53999999999996, 170.23999999999995, -33.88000000000007, -148.51000000000002, -138.82000000000016, -99.67000000000019, -24.159999999999805, 30.049999999999997, -24.790000000000006, -23.499999999999947, -322.96, -323.98, -106.99000000000001, -114.97000000000003, -56.94999999999999, -183.34999999999982, -242.68000000000023, -155.95000000000005, -115.84000000000003, -169.99, -261.7900000000002, -35.56000000000003, -92.55999999999926, -77.08000000000004, -193.0, -169.99, -27.819999999999993, -191.77000000000015, -101.3799999999999, 43.999999999999936, -336.97, -92.16999999999959, -235.9000000000001, 18.740000000000002, -166.45000000000016, -310.0, -233.3200000000004, -285.5200000000002, -243.79000000000002, -337.72000000000025, -185.95000000000002, -204.28000000000029, -170.95, -329.95000000000005, -275.6200000000003, -71.97999999999996, -11.710000000000257, -71.17000000000016, -144.4300000000001, -229.74999999999994, -189.42999999999995, -296.7699999999999, -70.18000000000006, -231.1900000000007, -68.56000000000002, -80.40999999999919, -373.87000000000006, -345.73000000000025, -303.67000000000013, -120.12999999999957, -260.62000000000023, -227.56000000000026, -154.51, -67.65999999999983, -332.83, -296.7700000000001, 68.21000000000001, -74.37999999999917, -177.85000000000002, -223.1200000000003, -102.16000000000003, -307.6900000000002, -332.68, -197.02000000000083, -54.819999999999524, -272.6800000000003, -250.36000000000058, -276.7900000000002, -12.070000000000041, -338.7400000000001, -140.8900000000009, -267.3400000000004, -324.93999999999994, -168.97000000000003, -4.090000000000041, -64.89999999999971, -207.79000000000008, -263.80000000000007, -172.06000000000012, -170.9200000000002, -233.17000000000064, -221.1700000000007, 30.680000000000224, -363.97, -63.369999999999955, -92.8, -96.72999999999982, -8.050000000000042, -291.82000000000016, -305.92, -209.32000000000022, -260.98, -294.5800000000004, -185.0800000000002, -20.11000000000004, -244.71999999999997, -210.79000000000016, -98.49999999999994], "policy_predator_policy_reward": [123.0, 147.0, 137.0, 58.0, 49.0, 78.0, 5.0, 2.0, 66.0, 41.0, 20.0, 103.0, 33.0, 20.0, 67.0, 33.0, 76.0, 56.0, 54.0, 97.0, 101.0, 33.0, 68.0, 8.0, 157.0, 80.0, 52.0, 132.0, 288.0, 47.0, 49.0, 124.0, 30.0, 5.0, 15.0, 46.0, 26.0, 145.0, 80.0, 27.0, 62.0, 37.0, 68.0, 242.0, 34.0, 44.0, 53.0, 14.0, 76.0, 22.0, 140.0, 188.0, 41.0, 60.0, 136.0, 17.0, 50.0, 132.0, 24.0, 66.0, 18.0, 54.0, 39.0, 41.0, 82.0, 113.0, 147.0, 9.0, 30.0, 36.0, 12.0, 17.0, 153.0, 50.0, 54.0, 38.0, 121.0, 184.0, 90.0, 168.0, 54.0, 22.0, 70.0, 154.0, 54.0, 14.0, 70.0, 49.0, 167.0, 136.0, 18.0, 111.0, 1.0, 2.0, 81.0, 92.0, 36.0, 98.0, 47.0, 55.0, 49.0, 70.0, 146.0, 175.0, 82.0, 122.0, 109.0, 90.0, 79.0, 156.0, 104.0, 126.0, 137.0, 117.0, 62.0, 97.0, 131.0, 102.0, 111.0, 99.0, 42.0, 71.0, 91.0, 148.0, 36.0, 139.0, 97.0, 151.0, 108.0, 128.0, 176.0, 191.0, 124.0, 110.0, 176.0, 12.0, 155.0, 64.0, 54.0, 55.0, 175.0, 7.0, 159.0, 125.0, 77.0, 121.0, 105.0, 74.0, 174.0, 178.0, 128.0, 131.0, 118.0, 159.0, 77.0, 67.0, 172.0, 149.0, 22.0, 41.0, 134.0, 135.0, 133.0, 157.0, 161.0, 152.0, 106.0, 140.0, 132.0, 140.0, 108.0, 132.0, 110.0, 119.0, 183.0, 96.0, 49.0, 8.0, 131.0, 135.0, 69.0, 104.0, 118.0, 158.0, 110.0, 174.0, 76.0, 88.0, 38.0, 32.0, 152.0, 166.0, 120.0, 139.0, 141.0, 152.0, 136.0, 97.0, 45.0, 123.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8259810528042979, "mean_inference_ms": 2.3890674097197264, "mean_action_processing_ms": 0.3774094753383201, "mean_env_wait_ms": 0.2928993066833882, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005540966987609863, "StateBufferConnector_ms": 0.003267526626586914, "ViewRequirementAgentConnector_ms": 0.10521769523620605}, "num_episodes": 18, "episode_return_max": 316.77999999999986, "episode_return_min": -387.29000000000065, "episode_return_mean": -47.444200000000066, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.0907821274869, "num_env_steps_trained_throughput_per_sec": 355.0907821274869, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 12087.85, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12087.798, "sample_time_ms": 1626.273, "learn_time_ms": 10444.276, "learn_throughput": 382.985, "synch_weights_time_ms": 13.929}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "310e1_00000", "date": "2024-08-15_00-58-48", "timestamp": 1723663728, "time_this_iter_s": 11.319934844970703, "time_total_s": 84.9681146144867, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b146ff70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 84.9681146144867, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 46.99411764705883, "ram_util_percent": 82.95294117647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3570769807649037, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.450230798519478, "policy_loss": -0.007262191220763184, "vf_loss": 6.4550477658630045, "vf_explained_var": -0.02816744333221799, "kl": 0.012226050185025752, "entropy": 1.500976769570951, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3021454482482224, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.684513313934286, "policy_loss": -0.009460176583921547, "vf_loss": 5.692107115599214, "vf_explained_var": 0.004567710243204914, "kl": 0.009331781607551524, "entropy": 1.5537452764612025, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 316.77999999999986, "episode_reward_min": -367.6000000000003, "episode_reward_mean": -74.15640000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 170.23999999999995, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": -130.97320000000008, "predator_policy": 93.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.17999999999999, 116.52000000000007, 42.130000000000024, -123.24999999999966, 151.44999999999987, 216.49999999999994, -71.2799999999998, -298.87000000000006, 144.63000000000022, -17.80999999999995, -63.77999999999989, 101.77000000000011, 120.34000000000009, 66.57, -124.5799999999999, -44.00000000000009, 131.37999999999977, 254.87999999999997, -36.54000000000002, 132.69000000000028, -261.7800000000001, -237.59000000000006, 207.3199999999998, -102.23999999999974, 156.45000000000027, 42.75000000000003, -190.73000000000025, 71.58999999999996, 316.77999999999986, -9.389999999999796, -104.4900000000003, 107.89000000000003, 70.71000000000029, -325.94, -17.960000000000008, -41.29999999999998, -163.63000000000017, -55.82999999999998, -43.35000000000007, -10.639999999999876, -129.99000000000012, -9.58999999999999, 55.62000000000021, -190.14000000000073, -42.160000000000046, -228.4500000000002, -282.8400000000006, -214.51000000000002, -156.23000000000027, -312.90000000000003, -128.59999999999985, 26.11999999999963, -192.18, -202.19999999999987, -103.36999999999945, 30.029999999999824, -367.6000000000003, -164.80000000000038, -211.18000000000038, -78.17000000000026, -308.5999999999999, 56.83000000000021, -131.96999999999997, -119.84999999999995, -216.70000000000076, -81.49999999999925, -255.15000000000077, -110.80999999999953, -179.2300000000012, -214.91, -11.99000000000031, -205.59000000000015, -169.98000000000047, -178.34000000000134, -49.29000000000019, 7.830000000000048, -34.77999999999985, -279.7400000000002, -211.3000000000003, -186.6600000000006, -31.829999999999913, -141.29000000000013, -251.50000000000009, -96.5499999999999, -97.62999999999928, -79.83999999999978, -26.80999999999976, -211.3000000000004, -66.72999999999996, -57.830000000000545, -67.46999999999997, -77.86999999999861, -178.84000000000106, -108.54999999999875, -47.4700000000003, -49.79999999999977, -4.6599999999999735, -29.63999999999997, -197.9600000000009, 45.250000000000455], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [104.17999999999996, -235.0, -41.74000000000004, 51.26, -49.360000000000014, -7.510000000000074, -393.61000000000035, -39.639999999999944, 24.26000000000001, 49.190000000000005, 141.08000000000004, 8.420000000000076, -84.01000000000019, -85.27000000000001, -301.93, -324.94000000000005, 28.04, 15.589999999999966, -52.93000000000001, -117.87999999999994, -127.0, -118.77999999999989, 25.76, -13.990000000000002, 71.21000000000001, -22.87000000000009, -57.67000000000018, 44.240000000000016, -133.83999999999995, -185.74, 28.940000000000055, -228.94000000000005, -16.210000000000157, 81.58999999999989, 83.66000000000001, 142.22000000000003, -91.53999999999998, -148.0, 33.050000000000026, 7.640000000000327, -172.77999999999997, -394.0, -249.94, -245.65000000000003, 151.04000000000002, -19.720000000000006, -110.26000000000025, -215.98000000000002, 3.829999999999988, 84.62000000000006, -7.300000000000001, -68.94999999999999, -317.8000000000002, -175.92999999999998, -42.55000000000007, -14.859999999999989, 143.53999999999996, 170.23999999999995, -33.88000000000007, -148.51000000000002, -138.82000000000016, -99.67000000000019, -24.159999999999805, 30.049999999999997, -24.790000000000006, -23.499999999999947, -322.96, -323.98, -106.99000000000001, -114.97000000000003, -56.94999999999999, -183.34999999999982, -242.68000000000023, -155.95000000000005, -115.84000000000003, -169.99, -261.7900000000002, -35.56000000000003, -92.55999999999926, -77.08000000000004, -193.0, -169.99, -27.819999999999993, -191.77000000000015, -101.3799999999999, 43.999999999999936, -336.97, -92.16999999999959, -235.9000000000001, 18.740000000000002, -166.45000000000016, -310.0, -233.3200000000004, -285.5200000000002, -243.79000000000002, -337.72000000000025, -185.95000000000002, -204.28000000000029, -170.95, -329.95000000000005, -275.6200000000003, -71.97999999999996, -11.710000000000257, -71.17000000000016, -144.4300000000001, -229.74999999999994, -189.42999999999995, -296.7699999999999, -70.18000000000006, -231.1900000000007, -68.56000000000002, -80.40999999999919, -373.87000000000006, -345.73000000000025, -303.67000000000013, -120.12999999999957, -260.62000000000023, -227.56000000000026, -154.51, -67.65999999999983, -332.83, -296.7700000000001, 68.21000000000001, -74.37999999999917, -177.85000000000002, -223.1200000000003, -102.16000000000003, -307.6900000000002, -332.68, -197.02000000000083, -54.819999999999524, -272.6800000000003, -250.36000000000058, -276.7900000000002, -12.070000000000041, -338.7400000000001, -140.8900000000009, -267.3400000000004, -324.93999999999994, -168.97000000000003, -4.090000000000041, -64.89999999999971, -207.79000000000008, -263.80000000000007, -172.06000000000012, -170.9200000000002, -233.17000000000064, -221.1700000000007, 30.680000000000224, -363.97, -63.369999999999955, -92.8, -96.72999999999982, -8.050000000000042, -291.82000000000016, -305.92, -209.32000000000022, -260.98, -294.5800000000004, -185.0800000000002, -20.11000000000004, -244.71999999999997, -210.79000000000016, -98.49999999999994, -305.83000000000015, -270.67, -61.44999999999921, -201.1, -325.63000000000034, 2.0000000000000013, -142.6799999999999, -30.15999999999978, -160.81000000000046, 2.0000000000000013, -223.30000000000044, -199.00000000000037, -259.3000000000003, -30.43000000000001, -132.6700000000011, 2.839999999999976, -56.530000000000044, -234.94, -63.369999999999216, -98.49999999999933, -144.21999999999971, -317.62000000000035, -84.4299999999992, -157.1200000000008, -108.21999999999962, -48.25000000000035, -80.40999999999919, -43.39000000000005, -8.050000000000036, -144.61000000000035, -58.30000000000034, -48.340000000000025, -154.30000000000064, -331.66000000000025, -20.109999999999705, -24.64], "policy_predator_policy_reward": [26.0, 145.0, 80.0, 27.0, 62.0, 37.0, 68.0, 242.0, 34.0, 44.0, 53.0, 14.0, 76.0, 22.0, 140.0, 188.0, 41.0, 60.0, 136.0, 17.0, 50.0, 132.0, 24.0, 66.0, 18.0, 54.0, 39.0, 41.0, 82.0, 113.0, 147.0, 9.0, 30.0, 36.0, 12.0, 17.0, 153.0, 50.0, 54.0, 38.0, 121.0, 184.0, 90.0, 168.0, 54.0, 22.0, 70.0, 154.0, 54.0, 14.0, 70.0, 49.0, 167.0, 136.0, 18.0, 111.0, 1.0, 2.0, 81.0, 92.0, 36.0, 98.0, 47.0, 55.0, 49.0, 70.0, 146.0, 175.0, 82.0, 122.0, 109.0, 90.0, 79.0, 156.0, 104.0, 126.0, 137.0, 117.0, 62.0, 97.0, 131.0, 102.0, 111.0, 99.0, 42.0, 71.0, 91.0, 148.0, 36.0, 139.0, 97.0, 151.0, 108.0, 128.0, 176.0, 191.0, 124.0, 110.0, 176.0, 12.0, 155.0, 64.0, 54.0, 55.0, 175.0, 7.0, 159.0, 125.0, 77.0, 121.0, 105.0, 74.0, 174.0, 178.0, 128.0, 131.0, 118.0, 159.0, 77.0, 67.0, 172.0, 149.0, 22.0, 41.0, 134.0, 135.0, 133.0, 157.0, 161.0, 152.0, 106.0, 140.0, 132.0, 140.0, 108.0, 132.0, 110.0, 119.0, 183.0, 96.0, 49.0, 8.0, 131.0, 135.0, 69.0, 104.0, 118.0, 158.0, 110.0, 174.0, 76.0, 88.0, 38.0, 32.0, 152.0, 166.0, 120.0, 139.0, 141.0, 152.0, 136.0, 97.0, 45.0, 123.0, 145.0, 180.0, 64.0, 102.0, 158.0, 68.0, 23.0, 70.0, 75.0, 57.0, 91.0, 120.0, 114.0, 109.0, 5.0, 67.0, 117.0, 107.0, 51.0, 33.0, 155.0, 128.0, 51.0, 82.0, 27.0, 82.0, 15.0, 59.0, 77.0, 71.0, 56.0, 21.0, 170.0, 118.0, 43.0, 47.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7891139273253384, "mean_inference_ms": 2.2483898279461667, "mean_action_processing_ms": 0.3553313196372747, "mean_env_wait_ms": 0.27804483731115665, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004988551139831543, "StateBufferConnector_ms": 0.003207683563232422, "ViewRequirementAgentConnector_ms": 0.10535907745361328}, "num_episodes": 18, "episode_return_max": 316.77999999999986, "episode_return_min": -367.6000000000003, "episode_return_mean": -74.15640000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.35497589930793, "num_env_steps_trained_throughput_per_sec": 329.35497589930793, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 12094.988, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12094.938, "sample_time_ms": 1576.186, "learn_time_ms": 10501.476, "learn_throughput": 380.899, "synch_weights_time_ms": 13.841}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "310e1_00000", "date": "2024-08-15_00-59-00", "timestamp": 1723663740, "time_this_iter_s": 12.207855939865112, "time_total_s": 97.1759705543518, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14d83a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 97.1759705543518, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 56.28235294117648, "ram_util_percent": 83.26470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8366978235976406, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.087717826908858, "policy_loss": -0.0040943191745244556, "vf_loss": 5.090238961088595, "vf_explained_var": 0.004773443275027805, "kl": 0.007865856826782425, "entropy": 1.5038120993230708, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1972911686493606, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.50588555701826, "policy_loss": -0.003790471956340803, "vf_loss": 4.508754061012672, "vf_explained_var": 0.02280956604493358, "kl": 0.004609784162753381, "entropy": 1.5650886589257176, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 316.77999999999986, "episode_reward_min": -367.6000000000003, "episode_reward_mean": -90.8468, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.9200000000001, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 170.23999999999995, "predator_policy": 196.0}, "policy_reward_mean": {"prey_policy": -134.32840000000004, "predator_policy": 88.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [207.3199999999998, -102.23999999999974, 156.45000000000027, 42.75000000000003, -190.73000000000025, 71.58999999999996, 316.77999999999986, -9.389999999999796, -104.4900000000003, 107.89000000000003, 70.71000000000029, -325.94, -17.960000000000008, -41.29999999999998, -163.63000000000017, -55.82999999999998, -43.35000000000007, -10.639999999999876, -129.99000000000012, -9.58999999999999, 55.62000000000021, -190.14000000000073, -42.160000000000046, -228.4500000000002, -282.8400000000006, -214.51000000000002, -156.23000000000027, -312.90000000000003, -128.59999999999985, 26.11999999999963, -192.18, -202.19999999999987, -103.36999999999945, 30.029999999999824, -367.6000000000003, -164.80000000000038, -211.18000000000038, -78.17000000000026, -308.5999999999999, 56.83000000000021, -131.96999999999997, -119.84999999999995, -216.70000000000076, -81.49999999999925, -255.15000000000077, -110.80999999999953, -179.2300000000012, -214.91, -11.99000000000031, -205.59000000000015, -169.98000000000047, -178.34000000000134, -49.29000000000019, 7.830000000000048, -34.77999999999985, -279.7400000000002, -211.3000000000003, -186.6600000000006, -31.829999999999913, -141.29000000000013, -251.50000000000009, -96.5499999999999, -97.62999999999928, -79.83999999999978, -26.80999999999976, -211.3000000000004, -66.72999999999996, -57.830000000000545, -67.46999999999997, -77.86999999999861, -178.84000000000106, -108.54999999999875, -47.4700000000003, -49.79999999999977, -4.6599999999999735, -29.63999999999997, -197.9600000000009, 45.250000000000455, -5.260000000000078, -85.34000000000009, -10.260000000000076, 2.739999999999972, -77.9999999999987, -67.84999999999866, -362.890000000001, -248.8700000000007, -21.310000000000002, -33.599999999999866, 3.460000000000037, -30.690000000000165, -62.580000000000126, -130.37999999999977, -1.4100000000000315, -78.96999999999888, -52.82, -115.37999999999874, -1.9199999999999748, -7.640000000000072, -7.1300000000000825, -33.37999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [151.04000000000002, -19.720000000000006, -110.26000000000025, -215.98000000000002, 3.829999999999988, 84.62000000000006, -7.300000000000001, -68.94999999999999, -317.8000000000002, -175.92999999999998, -42.55000000000007, -14.859999999999989, 143.53999999999996, 170.23999999999995, -33.88000000000007, -148.51000000000002, -138.82000000000016, -99.67000000000019, -24.159999999999805, 30.049999999999997, -24.790000000000006, -23.499999999999947, -322.96, -323.98, -106.99000000000001, -114.97000000000003, -56.94999999999999, -183.34999999999982, -242.68000000000023, -155.95000000000005, -115.84000000000003, -169.99, -261.7900000000002, -35.56000000000003, -92.55999999999926, -77.08000000000004, -193.0, -169.99, -27.819999999999993, -191.77000000000015, -101.3799999999999, 43.999999999999936, -336.97, -92.16999999999959, -235.9000000000001, 18.740000000000002, -166.45000000000016, -310.0, -233.3200000000004, -285.5200000000002, -243.79000000000002, -337.72000000000025, -185.95000000000002, -204.28000000000029, -170.95, -329.95000000000005, -275.6200000000003, -71.97999999999996, -11.710000000000257, -71.17000000000016, -144.4300000000001, -229.74999999999994, -189.42999999999995, -296.7699999999999, -70.18000000000006, -231.1900000000007, -68.56000000000002, -80.40999999999919, -373.87000000000006, -345.73000000000025, -303.67000000000013, -120.12999999999957, -260.62000000000023, -227.56000000000026, -154.51, -67.65999999999983, -332.83, -296.7700000000001, 68.21000000000001, -74.37999999999917, -177.85000000000002, -223.1200000000003, -102.16000000000003, -307.6900000000002, -332.68, -197.02000000000083, -54.819999999999524, -272.6800000000003, -250.36000000000058, -276.7900000000002, -12.070000000000041, -338.7400000000001, -140.8900000000009, -267.3400000000004, -324.93999999999994, -168.97000000000003, -4.090000000000041, -64.89999999999971, -207.79000000000008, -263.80000000000007, -172.06000000000012, -170.9200000000002, -233.17000000000064, -221.1700000000007, 30.680000000000224, -363.97, -63.369999999999955, -92.8, -96.72999999999982, -8.050000000000042, -291.82000000000016, -305.92, -209.32000000000022, -260.98, -294.5800000000004, -185.0800000000002, -20.11000000000004, -244.71999999999997, -210.79000000000016, -98.49999999999994, -305.83000000000015, -270.67, -61.44999999999921, -201.1, -325.63000000000034, 2.0000000000000013, -142.6799999999999, -30.15999999999978, -160.81000000000046, 2.0000000000000013, -223.30000000000044, -199.00000000000037, -259.3000000000003, -30.43000000000001, -132.6700000000011, 2.839999999999976, -56.530000000000044, -234.94, -63.369999999999216, -98.49999999999933, -144.21999999999971, -317.62000000000035, -84.4299999999992, -157.1200000000008, -108.21999999999962, -48.25000000000035, -80.40999999999919, -43.39000000000005, -8.050000000000036, -144.61000000000035, -58.30000000000034, -48.340000000000025, -154.30000000000064, -331.66000000000025, -20.109999999999705, -24.64, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -291.3400000000002, 2.0000000000000013, -50.260000000000346, 34.24999999999975, -100.50999999999948, -38.319999999999865, -134.6800000000011, -41.320000000000334, -104.52999999999929, -383.9200000000001, -192.9700000000009, -341.7100000000001, -222.1600000000006, -148.74999999999943, 36.43999999999972, -96.4900000000001, -20.109999999999705, -4.450000000000026, -16.089999999999705, -75.39999999999918, -17.28999999999975, -207.03999999999976, -10.53999999999982, 24.44000000000021, -357.8200000000001, -56.29000000000034, 13.879999999999969, -166.83999999999958, -24.129999999999708, -97.50999999999995, -60.310000000000336, -83.55999999999952, -162.82000000000107, -91.62999999999938, 30.7100000000001, -25.38999999999975, -48.25000000000035, 2.0000000000000013, -24.129999999999708, -14.080000000000041, -58.300000000000026], "policy_predator_policy_reward": [54.0, 22.0, 70.0, 154.0, 54.0, 14.0, 70.0, 49.0, 167.0, 136.0, 18.0, 111.0, 1.0, 2.0, 81.0, 92.0, 36.0, 98.0, 47.0, 55.0, 49.0, 70.0, 146.0, 175.0, 82.0, 122.0, 109.0, 90.0, 79.0, 156.0, 104.0, 126.0, 137.0, 117.0, 62.0, 97.0, 131.0, 102.0, 111.0, 99.0, 42.0, 71.0, 91.0, 148.0, 36.0, 139.0, 97.0, 151.0, 108.0, 128.0, 176.0, 191.0, 124.0, 110.0, 176.0, 12.0, 155.0, 64.0, 54.0, 55.0, 175.0, 7.0, 159.0, 125.0, 77.0, 121.0, 105.0, 74.0, 174.0, 178.0, 128.0, 131.0, 118.0, 159.0, 77.0, 67.0, 172.0, 149.0, 22.0, 41.0, 134.0, 135.0, 133.0, 157.0, 161.0, 152.0, 106.0, 140.0, 132.0, 140.0, 108.0, 132.0, 110.0, 119.0, 183.0, 96.0, 49.0, 8.0, 131.0, 135.0, 69.0, 104.0, 118.0, 158.0, 110.0, 174.0, 76.0, 88.0, 38.0, 32.0, 152.0, 166.0, 120.0, 139.0, 141.0, 152.0, 136.0, 97.0, 45.0, 123.0, 145.0, 180.0, 64.0, 102.0, 158.0, 68.0, 23.0, 70.0, 75.0, 57.0, 91.0, 120.0, 114.0, 109.0, 5.0, 67.0, 117.0, 107.0, 51.0, 33.0, 155.0, 128.0, 51.0, 82.0, 27.0, 82.0, 15.0, 59.0, 77.0, 71.0, 56.0, 21.0, 170.0, 118.0, 43.0, 47.0, 24.0, 19.0, 111.0, 93.0, 26.0, 12.0, 48.0, 21.0, 23.0, 72.0, 25.0, 53.0, 18.0, 196.0, 153.0, 162.0, 35.0, 56.0, 47.0, 36.0, 6.0, 18.0, 40.0, 22.0, 61.0, 94.0, 25.0, 178.0, 23.0, 18.0, 41.0, 71.0, 25.0, 80.0, 94.0, 37.0, 42.0, 17.0, 28.0, 38.0, 13.0, 2.0, 8.0, 31.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7638517150834029, "mean_inference_ms": 2.1379193836362593, "mean_action_processing_ms": 0.34122549884804576, "mean_env_wait_ms": 0.267788345719791, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004156827926635742, "StateBufferConnector_ms": 0.003449082374572754, "ViewRequirementAgentConnector_ms": 0.10316908359527588}, "num_episodes": 22, "episode_return_max": 316.77999999999986, "episode_return_min": -367.6000000000003, "episode_return_mean": -90.8468, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.5090285020797, "num_env_steps_trained_throughput_per_sec": 352.5090285020797, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 12011.904, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12011.852, "sample_time_ms": 1550.306, "learn_time_ms": 10443.863, "learn_throughput": 383.0, "synch_weights_time_ms": 13.713}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "310e1_00000", "date": "2024-08-15_00-59-12", "timestamp": 1723663752, "time_this_iter_s": 11.377488136291504, "time_total_s": 108.55345869064331, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12d9160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 108.55345869064331, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 51.081250000000004, "ram_util_percent": 83.65625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4568529023379875, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6880391400957864, "policy_loss": -0.0063345875485095555, "vf_loss": 3.692759248945448, "vf_explained_var": 0.019890332158911166, "kl": 0.008072420688900368, "entropy": 1.4925542972705983, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3796129542841482, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.715852590717335, "policy_loss": -0.006285674250118001, "vf_loss": 4.721481860125507, "vf_explained_var": 0.013059954763089538, "kl": 0.006564127282730132, "entropy": 1.554493980748313, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 97.89000000000146, "episode_reward_min": -367.6000000000003, "episode_reward_mean": -103.47179999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.9200000000001, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 68.21000000000001, "predator_policy": 196.0}, "policy_reward_mean": {"prey_policy": -133.20590000000004, "predator_policy": 81.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-228.4500000000002, -282.8400000000006, -214.51000000000002, -156.23000000000027, -312.90000000000003, -128.59999999999985, 26.11999999999963, -192.18, -202.19999999999987, -103.36999999999945, 30.029999999999824, -367.6000000000003, -164.80000000000038, -211.18000000000038, -78.17000000000026, -308.5999999999999, 56.83000000000021, -131.96999999999997, -119.84999999999995, -216.70000000000076, -81.49999999999925, -255.15000000000077, -110.80999999999953, -179.2300000000012, -214.91, -11.99000000000031, -205.59000000000015, -169.98000000000047, -178.34000000000134, -49.29000000000019, 7.830000000000048, -34.77999999999985, -279.7400000000002, -211.3000000000003, -186.6600000000006, -31.829999999999913, -141.29000000000013, -251.50000000000009, -96.5499999999999, -97.62999999999928, -79.83999999999978, -26.80999999999976, -211.3000000000004, -66.72999999999996, -57.830000000000545, -67.46999999999997, -77.86999999999861, -178.84000000000106, -108.54999999999875, -47.4700000000003, -49.79999999999977, -4.6599999999999735, -29.63999999999997, -197.9600000000009, 45.250000000000455, -5.260000000000078, -85.34000000000009, -10.260000000000076, 2.739999999999972, -77.9999999999987, -67.84999999999866, -362.890000000001, -248.8700000000007, -21.310000000000002, -33.599999999999866, 3.460000000000037, -30.690000000000165, -62.580000000000126, -130.37999999999977, -1.4100000000000315, -78.96999999999888, -52.82, -115.37999999999874, -1.9199999999999748, -7.640000000000072, -7.1300000000000825, -33.37999999999999, 97.89000000000146, 1.4199999999999988, -19.379999999999484, -26.299999999999923, -78.8799999999984, -59.24000000000048, -140.02, -353.0400000000008, -207.6000000000003, -298.9500000000008, 16.299999999999983, -11.230000000000075, -115.36999999999941, -93.97999999999927, -139.91000000000082, 3.799999999999954, -117.50999999999888, -116.28999999999867, -27.89000000000028, -55.449999999999676, 16.770000000000056, 47.49999999999956, 6.589999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-166.45000000000016, -310.0, -233.3200000000004, -285.5200000000002, -243.79000000000002, -337.72000000000025, -185.95000000000002, -204.28000000000029, -170.95, -329.95000000000005, -275.6200000000003, -71.97999999999996, -11.710000000000257, -71.17000000000016, -144.4300000000001, -229.74999999999994, -189.42999999999995, -296.7699999999999, -70.18000000000006, -231.1900000000007, -68.56000000000002, -80.40999999999919, -373.87000000000006, -345.73000000000025, -303.67000000000013, -120.12999999999957, -260.62000000000023, -227.56000000000026, -154.51, -67.65999999999983, -332.83, -296.7700000000001, 68.21000000000001, -74.37999999999917, -177.85000000000002, -223.1200000000003, -102.16000000000003, -307.6900000000002, -332.68, -197.02000000000083, -54.819999999999524, -272.6800000000003, -250.36000000000058, -276.7900000000002, -12.070000000000041, -338.7400000000001, -140.8900000000009, -267.3400000000004, -324.93999999999994, -168.97000000000003, -4.090000000000041, -64.89999999999971, -207.79000000000008, -263.80000000000007, -172.06000000000012, -170.9200000000002, -233.17000000000064, -221.1700000000007, 30.680000000000224, -363.97, -63.369999999999955, -92.8, -96.72999999999982, -8.050000000000042, -291.82000000000016, -305.92, -209.32000000000022, -260.98, -294.5800000000004, -185.0800000000002, -20.11000000000004, -244.71999999999997, -210.79000000000016, -98.49999999999994, -305.83000000000015, -270.67, -61.44999999999921, -201.1, -325.63000000000034, 2.0000000000000013, -142.6799999999999, -30.15999999999978, -160.81000000000046, 2.0000000000000013, -223.30000000000044, -199.00000000000037, -259.3000000000003, -30.43000000000001, -132.6700000000011, 2.839999999999976, -56.530000000000044, -234.94, -63.369999999999216, -98.49999999999933, -144.21999999999971, -317.62000000000035, -84.4299999999992, -157.1200000000008, -108.21999999999962, -48.25000000000035, -80.40999999999919, -43.39000000000005, -8.050000000000036, -144.61000000000035, -58.30000000000034, -48.340000000000025, -154.30000000000064, -331.66000000000025, -20.109999999999705, -24.64, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -291.3400000000002, 2.0000000000000013, -50.260000000000346, 34.24999999999975, -100.50999999999948, -38.319999999999865, -134.6800000000011, -41.320000000000334, -104.52999999999929, -383.9200000000001, -192.9700000000009, -341.7100000000001, -222.1600000000006, -148.74999999999943, 36.43999999999972, -96.4900000000001, -20.109999999999705, -4.450000000000026, -16.089999999999705, -75.39999999999918, -17.28999999999975, -207.03999999999976, -10.53999999999982, 24.44000000000021, -357.8200000000001, -56.29000000000034, 13.879999999999969, -166.83999999999958, -24.129999999999708, -97.50999999999995, -60.310000000000336, -83.55999999999952, -162.82000000000107, -91.62999999999938, 30.7100000000001, -25.38999999999975, -48.25000000000035, 2.0000000000000013, -24.129999999999708, -14.080000000000041, -58.300000000000026, 48.529999999999696, 35.35999999999973, -54.58000000000028, 2.0000000000000013, -74.37999999999917, 2.0000000000000013, -22.119999999999717, -34.18000000000008, -66.45999999999921, -79.41999999999919, -134.68000000000097, -17.559999999999782, -118.59999999999975, -315.4200000000001, -252.40000000000052, -327.6400000000003, -253.33000000000033, -253.2700000000001, -313.4500000000003, -307.50000000000045, -57.34000000000033, 16.64, 1.939999999999992, -32.16999999999995, -46.24000000000035, -225.13000000000028, -138.70000000000076, -54.28000000000004, -193.9900000000004, -198.92000000000087, 2.0000000000000013, -11.200000000000014, -156.82000000000096, -85.6899999999994, -166.76000000000113, -104.5299999999993, -113.73999999999936, 16.85000000000005, -142.36000000000053, -16.089999999999705, 6.769999999999962, 2.0000000000000013, -6.040000000000042, 47.53999999999978, -10.390000000000034, -2.0200000000000253], "policy_predator_policy_reward": [97.0, 151.0, 108.0, 128.0, 176.0, 191.0, 124.0, 110.0, 176.0, 12.0, 155.0, 64.0, 54.0, 55.0, 175.0, 7.0, 159.0, 125.0, 77.0, 121.0, 105.0, 74.0, 174.0, 178.0, 128.0, 131.0, 118.0, 159.0, 77.0, 67.0, 172.0, 149.0, 22.0, 41.0, 134.0, 135.0, 133.0, 157.0, 161.0, 152.0, 106.0, 140.0, 132.0, 140.0, 108.0, 132.0, 110.0, 119.0, 183.0, 96.0, 49.0, 8.0, 131.0, 135.0, 69.0, 104.0, 118.0, 158.0, 110.0, 174.0, 76.0, 88.0, 38.0, 32.0, 152.0, 166.0, 120.0, 139.0, 141.0, 152.0, 136.0, 97.0, 45.0, 123.0, 145.0, 180.0, 64.0, 102.0, 158.0, 68.0, 23.0, 70.0, 75.0, 57.0, 91.0, 120.0, 114.0, 109.0, 5.0, 67.0, 117.0, 107.0, 51.0, 33.0, 155.0, 128.0, 51.0, 82.0, 27.0, 82.0, 15.0, 59.0, 77.0, 71.0, 56.0, 21.0, 170.0, 118.0, 43.0, 47.0, 24.0, 19.0, 111.0, 93.0, 26.0, 12.0, 48.0, 21.0, 23.0, 72.0, 25.0, 53.0, 18.0, 196.0, 153.0, 162.0, 35.0, 56.0, 47.0, 36.0, 6.0, 18.0, 40.0, 22.0, 61.0, 94.0, 25.0, 178.0, 23.0, 18.0, 41.0, 71.0, 25.0, 80.0, 94.0, 37.0, 42.0, 17.0, 28.0, 38.0, 13.0, 2.0, 8.0, 31.0, 4.0, 10.0, 16.0, 38.0, 15.0, 38.0, 12.0, 18.0, 45.0, 22.0, 25.0, 68.0, 138.0, 156.0, 180.0, 47.0, 134.0, 165.0, 138.0, 184.0, 31.0, 26.0, 10.0, 9.0, 26.0, 130.0, 98.0, 1.0, 121.0, 132.0, 4.0, 9.0, 44.0, 81.0, 108.0, 47.0, 51.0, 18.0, 10.0, 93.0, 6.0, 2.0, 4.0, 2.0, 17.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.742009695260745, "mean_inference_ms": 2.0645795731087153, "mean_action_processing_ms": 0.3268713807150456, "mean_env_wait_ms": 0.2586883910330938, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038510560989379883, "StateBufferConnector_ms": 0.003396749496459961, "ViewRequirementAgentConnector_ms": 0.10529112815856934}, "num_episodes": 23, "episode_return_max": 97.89000000000146, "episode_return_min": -367.6000000000003, "episode_return_mean": -103.47179999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.9604985520373, "num_env_steps_trained_throughput_per_sec": 350.9604985520373, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 11950.444, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11950.393, "sample_time_ms": 1518.937, "learn_time_ms": 10412.725, "learn_throughput": 384.145, "synch_weights_time_ms": 14.961}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "310e1_00000", "date": "2024-08-15_00-59-23", "timestamp": 1723663763, "time_this_iter_s": 11.482687950134277, "time_total_s": 120.03614664077759, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1482ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 120.03614664077759, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 53.7625, "ram_util_percent": 83.425}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2028850237528483, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.574974703914905, "policy_loss": -0.007331632380496967, "vf_loss": 4.580803514031506, "vf_explained_var": 0.036246219829276755, "kl": 0.00751410917955526, "entropy": 1.4722103772970734, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5841543457180105, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.3977265250745905, "policy_loss": -0.00861614915374765, "vf_loss": 5.404834783644903, "vf_explained_var": 0.019657146047662805, "kl": 0.015078806923275522, "entropy": 1.555719770703997, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 97.89000000000146, "episode_reward_min": -362.890000000001, "episode_reward_mean": -80.23079999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -437.99, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 60.41, "predator_policy": 232.0}, "policy_reward_mean": {"prey_policy": -111.78040000000004, "predator_policy": 71.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-119.84999999999995, -216.70000000000076, -81.49999999999925, -255.15000000000077, -110.80999999999953, -179.2300000000012, -214.91, -11.99000000000031, -205.59000000000015, -169.98000000000047, -178.34000000000134, -49.29000000000019, 7.830000000000048, -34.77999999999985, -279.7400000000002, -211.3000000000003, -186.6600000000006, -31.829999999999913, -141.29000000000013, -251.50000000000009, -96.5499999999999, -97.62999999999928, -79.83999999999978, -26.80999999999976, -211.3000000000004, -66.72999999999996, -57.830000000000545, -67.46999999999997, -77.86999999999861, -178.84000000000106, -108.54999999999875, -47.4700000000003, -49.79999999999977, -4.6599999999999735, -29.63999999999997, -197.9600000000009, 45.250000000000455, -5.260000000000078, -85.34000000000009, -10.260000000000076, 2.739999999999972, -77.9999999999987, -67.84999999999866, -362.890000000001, -248.8700000000007, -21.310000000000002, -33.599999999999866, 3.460000000000037, -30.690000000000165, -62.580000000000126, -130.37999999999977, -1.4100000000000315, -78.96999999999888, -52.82, -115.37999999999874, -1.9199999999999748, -7.640000000000072, -7.1300000000000825, -33.37999999999999, 97.89000000000146, 1.4199999999999988, -19.379999999999484, -26.299999999999923, -78.8799999999984, -59.24000000000048, -140.02, -353.0400000000008, -207.6000000000003, -298.9500000000008, 16.299999999999983, -11.230000000000075, -115.36999999999941, -93.97999999999927, -139.91000000000082, 3.799999999999954, -117.50999999999888, -116.28999999999867, -27.89000000000028, -55.449999999999676, 16.770000000000056, 47.49999999999956, 6.589999999999926, 84.92000000000006, 8.559999999999992, -86.77000000000014, -28.98999999999984, -6.210000000000015, -39.91000000000027, -60.860000000000205, -174.77000000000095, 27.840000000000273, -53.43999999999992, -63.04000000000026, 10.519999999999934, 4.039999999999946, -5.410000000000075, 18.990000000000347, -107.40000000000028, -53.76000000000037, -120.82999999999979], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-102.16000000000003, -307.6900000000002, -332.68, -197.02000000000083, -54.819999999999524, -272.6800000000003, -250.36000000000058, -276.7900000000002, -12.070000000000041, -338.7400000000001, -140.8900000000009, -267.3400000000004, -324.93999999999994, -168.97000000000003, -4.090000000000041, -64.89999999999971, -207.79000000000008, -263.80000000000007, -172.06000000000012, -170.9200000000002, -233.17000000000064, -221.1700000000007, 30.680000000000224, -363.97, -63.369999999999955, -92.8, -96.72999999999982, -8.050000000000042, -291.82000000000016, -305.92, -209.32000000000022, -260.98, -294.5800000000004, -185.0800000000002, -20.11000000000004, -244.71999999999997, -210.79000000000016, -98.49999999999994, -305.83000000000015, -270.67, -61.44999999999921, -201.1, -325.63000000000034, 2.0000000000000013, -142.6799999999999, -30.15999999999978, -160.81000000000046, 2.0000000000000013, -223.30000000000044, -199.00000000000037, -259.3000000000003, -30.43000000000001, -132.6700000000011, 2.839999999999976, -56.530000000000044, -234.94, -63.369999999999216, -98.49999999999933, -144.21999999999971, -317.62000000000035, -84.4299999999992, -157.1200000000008, -108.21999999999962, -48.25000000000035, -80.40999999999919, -43.39000000000005, -8.050000000000036, -144.61000000000035, -58.30000000000034, -48.340000000000025, -154.30000000000064, -331.66000000000025, -20.109999999999705, -24.64, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -291.3400000000002, 2.0000000000000013, -50.260000000000346, 34.24999999999975, -100.50999999999948, -38.319999999999865, -134.6800000000011, -41.320000000000334, -104.52999999999929, -383.9200000000001, -192.9700000000009, -341.7100000000001, -222.1600000000006, -148.74999999999943, 36.43999999999972, -96.4900000000001, -20.109999999999705, -4.450000000000026, -16.089999999999705, -75.39999999999918, -17.28999999999975, -207.03999999999976, -10.53999999999982, 24.44000000000021, -357.8200000000001, -56.29000000000034, 13.879999999999969, -166.83999999999958, -24.129999999999708, -97.50999999999995, -60.310000000000336, -83.55999999999952, -162.82000000000107, -91.62999999999938, 30.7100000000001, -25.38999999999975, -48.25000000000035, 2.0000000000000013, -24.129999999999708, -14.080000000000041, -58.300000000000026, 48.529999999999696, 35.35999999999973, -54.58000000000028, 2.0000000000000013, -74.37999999999917, 2.0000000000000013, -22.119999999999717, -34.18000000000008, -66.45999999999921, -79.41999999999919, -134.68000000000097, -17.559999999999782, -118.59999999999975, -315.4200000000001, -252.40000000000052, -327.6400000000003, -253.33000000000033, -253.2700000000001, -313.4500000000003, -307.50000000000045, -57.34000000000033, 16.64, 1.939999999999992, -32.16999999999995, -46.24000000000035, -225.13000000000028, -138.70000000000076, -54.28000000000004, -193.9900000000004, -198.92000000000087, 2.0000000000000013, -11.200000000000014, -156.82000000000096, -85.6899999999994, -166.76000000000113, -104.5299999999993, -113.73999999999936, 16.85000000000005, -142.36000000000053, -16.089999999999705, 6.769999999999962, 2.0000000000000013, -6.040000000000042, 47.53999999999978, -10.390000000000034, -2.0200000000000253, 60.41, 5.509999999999968, -42.220000000000354, 23.780000000000207, -269.3500000000005, 19.580000000000055, 2.0000000000000013, -437.99, -50.050000000000125, -30.15999999999995, -58.66000000000009, -48.25000000000018, -31.329999999999924, -104.52999999999925, -118.59999999999943, -233.17000000000024, 55.459999999999745, -110.6199999999993, 12.739999999999963, -235.18000000000004, -48.25000000000035, -156.79000000000008, -49.479999999999336, 2.0000000000000013, -58.300000000000274, 10.34000000000005, -30.15999999999972, -0.2500000000000191, -1.5100000000000173, -14.50000000000007, -17.410000000000032, -193.98999999999955, -10.299999999999825, -291.4600000000004, -30.15999999999972, -333.6700000000001], "policy_predator_policy_reward": [133.0, 157.0, 161.0, 152.0, 106.0, 140.0, 132.0, 140.0, 108.0, 132.0, 110.0, 119.0, 183.0, 96.0, 49.0, 8.0, 131.0, 135.0, 69.0, 104.0, 118.0, 158.0, 110.0, 174.0, 76.0, 88.0, 38.0, 32.0, 152.0, 166.0, 120.0, 139.0, 141.0, 152.0, 136.0, 97.0, 45.0, 123.0, 145.0, 180.0, 64.0, 102.0, 158.0, 68.0, 23.0, 70.0, 75.0, 57.0, 91.0, 120.0, 114.0, 109.0, 5.0, 67.0, 117.0, 107.0, 51.0, 33.0, 155.0, 128.0, 51.0, 82.0, 27.0, 82.0, 15.0, 59.0, 77.0, 71.0, 56.0, 21.0, 170.0, 118.0, 43.0, 47.0, 24.0, 19.0, 111.0, 93.0, 26.0, 12.0, 48.0, 21.0, 23.0, 72.0, 25.0, 53.0, 18.0, 196.0, 153.0, 162.0, 35.0, 56.0, 47.0, 36.0, 6.0, 18.0, 40.0, 22.0, 61.0, 94.0, 25.0, 178.0, 23.0, 18.0, 41.0, 71.0, 25.0, 80.0, 94.0, 37.0, 42.0, 17.0, 28.0, 38.0, 13.0, 2.0, 8.0, 31.0, 4.0, 10.0, 16.0, 38.0, 15.0, 38.0, 12.0, 18.0, 45.0, 22.0, 25.0, 68.0, 138.0, 156.0, 180.0, 47.0, 134.0, 165.0, 138.0, 184.0, 31.0, 26.0, 10.0, 9.0, 26.0, 130.0, 98.0, 1.0, 121.0, 132.0, 4.0, 9.0, 44.0, 81.0, 108.0, 47.0, 51.0, 18.0, 10.0, 93.0, 6.0, 2.0, 4.0, 2.0, 17.0, 2.0, 4.0, 15.0, 22.0, 5.0, 28.0, 135.0, 175.0, 232.0, 33.0, 41.0, 25.0, 42.0, 54.0, 21.0, 60.0, 117.0, 30.0, 53.0, 113.0, 56.0, 63.0, 79.0, 27.0, 31.0, 14.0, 38.0, 19.0, 6.0, 18.0, 17.0, 98.0, 6.0, 140.0, 108.0, 114.0, 129.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7315913040174479, "mean_inference_ms": 2.021863853195688, "mean_action_processing_ms": 0.3194738610509311, "mean_env_wait_ms": 0.2539572488636178, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039042234420776367, "StateBufferConnector_ms": 0.003384828567504883, "ViewRequirementAgentConnector_ms": 0.10724186897277832}, "num_episodes": 18, "episode_return_max": 97.89000000000146, "episode_return_min": -362.890000000001, "episode_return_mean": -80.23079999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.34182504388895, "num_env_steps_trained_throughput_per_sec": 342.34182504388895, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 11438.215, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11438.162, "sample_time_ms": 1315.317, "learn_time_ms": 10104.597, "learn_throughput": 395.859, "synch_weights_time_ms": 14.872}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "310e1_00000", "date": "2024-08-15_00-59-35", "timestamp": 1723663775, "time_this_iter_s": 11.746161937713623, "time_total_s": 131.7823085784912, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c4940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 131.7823085784912, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 61.682352941176475, "ram_util_percent": 83.78235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3873085539176981, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.068712296687737, "policy_loss": -0.00980220255811536, "vf_loss": 5.075851944262388, "vf_explained_var": -0.005468174389430455, "kl": 0.013312801195733418, "entropy": 1.4497582834233682, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5586895598147912, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.928024695159266, "policy_loss": -0.0068006279671357734, "vf_loss": 6.933602802589457, "vf_explained_var": 0.02238027576416258, "kl": 0.012225289968968742, "entropy": 1.5160001785036117, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 97.89000000000146, "episode_reward_min": -362.890000000001, "episode_reward_mean": -66.46429999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -439.8800000000001, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 60.41, "predator_policy": 232.0}, "policy_reward_mean": {"prey_policy": -95.37215000000003, "predator_policy": 62.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-141.29000000000013, -251.50000000000009, -96.5499999999999, -97.62999999999928, -79.83999999999978, -26.80999999999976, -211.3000000000004, -66.72999999999996, -57.830000000000545, -67.46999999999997, -77.86999999999861, -178.84000000000106, -108.54999999999875, -47.4700000000003, -49.79999999999977, -4.6599999999999735, -29.63999999999997, -197.9600000000009, 45.250000000000455, -5.260000000000078, -85.34000000000009, -10.260000000000076, 2.739999999999972, -77.9999999999987, -67.84999999999866, -362.890000000001, -248.8700000000007, -21.310000000000002, -33.599999999999866, 3.460000000000037, -30.690000000000165, -62.580000000000126, -130.37999999999977, -1.4100000000000315, -78.96999999999888, -52.82, -115.37999999999874, -1.9199999999999748, -7.640000000000072, -7.1300000000000825, -33.37999999999999, 97.89000000000146, 1.4199999999999988, -19.379999999999484, -26.299999999999923, -78.8799999999984, -59.24000000000048, -140.02, -353.0400000000008, -207.6000000000003, -298.9500000000008, 16.299999999999983, -11.230000000000075, -115.36999999999941, -93.97999999999927, -139.91000000000082, 3.799999999999954, -117.50999999999888, -116.28999999999867, -27.89000000000028, -55.449999999999676, 16.770000000000056, 47.49999999999956, 6.589999999999926, 84.92000000000006, 8.559999999999992, -86.77000000000014, -28.98999999999984, -6.210000000000015, -39.91000000000027, -60.860000000000205, -174.77000000000095, 27.840000000000273, -53.43999999999992, -63.04000000000026, 10.519999999999934, 4.039999999999946, -5.410000000000075, 18.990000000000347, -107.40000000000028, -53.76000000000037, -120.82999999999979, -169.6200000000009, -65.24999999999952, -153.74000000000075, -58.359999999999005, -49.25999999999975, -35.64000000000001, 26.360000000000486, -0.4399999999999533, -139.8100000000017, -73.05999999999987, 49.840000000000146, -62.169999999999106, 61.26999999999948, -223.510000000001, -89.92999999999941, -131.33999999999892, -70.96999999999964, 32.4600000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-210.79000000000016, -98.49999999999994, -305.83000000000015, -270.67, -61.44999999999921, -201.1, -325.63000000000034, 2.0000000000000013, -142.6799999999999, -30.15999999999978, -160.81000000000046, 2.0000000000000013, -223.30000000000044, -199.00000000000037, -259.3000000000003, -30.43000000000001, -132.6700000000011, 2.839999999999976, -56.530000000000044, -234.94, -63.369999999999216, -98.49999999999933, -144.21999999999971, -317.62000000000035, -84.4299999999992, -157.1200000000008, -108.21999999999962, -48.25000000000035, -80.40999999999919, -43.39000000000005, -8.050000000000036, -144.61000000000035, -58.30000000000034, -48.340000000000025, -154.30000000000064, -331.66000000000025, -20.109999999999705, -24.64, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -291.3400000000002, 2.0000000000000013, -50.260000000000346, 34.24999999999975, -100.50999999999948, -38.319999999999865, -134.6800000000011, -41.320000000000334, -104.52999999999929, -383.9200000000001, -192.9700000000009, -341.7100000000001, -222.1600000000006, -148.74999999999943, 36.43999999999972, -96.4900000000001, -20.109999999999705, -4.450000000000026, -16.089999999999705, -75.39999999999918, -17.28999999999975, -207.03999999999976, -10.53999999999982, 24.44000000000021, -357.8200000000001, -56.29000000000034, 13.879999999999969, -166.83999999999958, -24.129999999999708, -97.50999999999995, -60.310000000000336, -83.55999999999952, -162.82000000000107, -91.62999999999938, 30.7100000000001, -25.38999999999975, -48.25000000000035, 2.0000000000000013, -24.129999999999708, -14.080000000000041, -58.300000000000026, 48.529999999999696, 35.35999999999973, -54.58000000000028, 2.0000000000000013, -74.37999999999917, 2.0000000000000013, -22.119999999999717, -34.18000000000008, -66.45999999999921, -79.41999999999919, -134.68000000000097, -17.559999999999782, -118.59999999999975, -315.4200000000001, -252.40000000000052, -327.6400000000003, -253.33000000000033, -253.2700000000001, -313.4500000000003, -307.50000000000045, -57.34000000000033, 16.64, 1.939999999999992, -32.16999999999995, -46.24000000000035, -225.13000000000028, -138.70000000000076, -54.28000000000004, -193.9900000000004, -198.92000000000087, 2.0000000000000013, -11.200000000000014, -156.82000000000096, -85.6899999999994, -166.76000000000113, -104.5299999999993, -113.73999999999936, 16.85000000000005, -142.36000000000053, -16.089999999999705, 6.769999999999962, 2.0000000000000013, -6.040000000000042, 47.53999999999978, -10.390000000000034, -2.0200000000000253, 60.41, 5.509999999999968, -42.220000000000354, 23.780000000000207, -269.3500000000005, 19.580000000000055, 2.0000000000000013, -437.99, -50.050000000000125, -30.15999999999995, -58.66000000000009, -48.25000000000018, -31.329999999999924, -104.52999999999925, -118.59999999999943, -233.17000000000024, 55.459999999999745, -110.6199999999993, 12.739999999999963, -235.18000000000004, -48.25000000000035, -156.79000000000008, -49.479999999999336, 2.0000000000000013, -58.300000000000274, 10.34000000000005, -30.15999999999972, -0.2500000000000191, -1.5100000000000173, -14.50000000000007, -17.410000000000032, -193.98999999999955, -10.299999999999825, -291.4600000000004, -30.15999999999972, -333.6700000000001, -173.5600000000004, -133.0600000000003, -112.9899999999995, -50.26000000000013, -116.58999999999985, -229.15000000000055, -62.82999999999953, -80.5299999999993, 39.61999999999996, -439.8800000000001, -47.320000000000334, -62.320000000000064, 21.80000000000028, -23.439999999999756, 29.72000000000001, -311.1599999999999, -60.789999999999935, -173.0200000000007, 20.510000000000158, -232.57000000000028, 34.28000000000002, -11.439999999999756, -120.22000000000051, -104.94999999999946, 9.919999999999968, 24.350000000000005, -194.98000000000084, -313.5300000000002, -74.37999999999988, -108.54999999999927, -235.1800000000007, -30.159999999999712, -244.36000000000038, 38.38999999999979, 16.45999999999998, 2.0000000000000013], "policy_predator_policy_reward": [45.0, 123.0, 145.0, 180.0, 64.0, 102.0, 158.0, 68.0, 23.0, 70.0, 75.0, 57.0, 91.0, 120.0, 114.0, 109.0, 5.0, 67.0, 117.0, 107.0, 51.0, 33.0, 155.0, 128.0, 51.0, 82.0, 27.0, 82.0, 15.0, 59.0, 77.0, 71.0, 56.0, 21.0, 170.0, 118.0, 43.0, 47.0, 24.0, 19.0, 111.0, 93.0, 26.0, 12.0, 48.0, 21.0, 23.0, 72.0, 25.0, 53.0, 18.0, 196.0, 153.0, 162.0, 35.0, 56.0, 47.0, 36.0, 6.0, 18.0, 40.0, 22.0, 61.0, 94.0, 25.0, 178.0, 23.0, 18.0, 41.0, 71.0, 25.0, 80.0, 94.0, 37.0, 42.0, 17.0, 28.0, 38.0, 13.0, 2.0, 8.0, 31.0, 4.0, 10.0, 16.0, 38.0, 15.0, 38.0, 12.0, 18.0, 45.0, 22.0, 25.0, 68.0, 138.0, 156.0, 180.0, 47.0, 134.0, 165.0, 138.0, 184.0, 31.0, 26.0, 10.0, 9.0, 26.0, 130.0, 98.0, 1.0, 121.0, 132.0, 4.0, 9.0, 44.0, 81.0, 108.0, 47.0, 51.0, 18.0, 10.0, 93.0, 6.0, 2.0, 4.0, 2.0, 17.0, 2.0, 4.0, 15.0, 22.0, 5.0, 28.0, 135.0, 175.0, 232.0, 33.0, 41.0, 25.0, 42.0, 54.0, 21.0, 60.0, 117.0, 30.0, 53.0, 113.0, 56.0, 63.0, 79.0, 27.0, 31.0, 14.0, 38.0, 19.0, 6.0, 18.0, 17.0, 98.0, 6.0, 140.0, 108.0, 114.0, 129.0, 7.0, 130.0, 52.0, 46.0, 83.0, 109.0, 46.0, 39.0, 134.0, 217.0, 57.0, 17.0, 14.0, 14.0, 82.0, 199.0, 92.0, 2.0, 17.0, 122.0, 8.0, 19.0, 93.0, 70.0, 14.0, 13.0, 168.0, 117.0, 48.0, 45.0, 118.0, 16.0, 133.0, 2.0, 13.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7223957588205795, "mean_inference_ms": 1.9882865212421705, "mean_action_processing_ms": 0.31344219248804833, "mean_env_wait_ms": 0.250430790067937, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037975311279296875, "StateBufferConnector_ms": 0.0033752918243408203, "ViewRequirementAgentConnector_ms": 0.10337519645690918}, "num_episodes": 18, "episode_return_max": 97.89000000000146, "episode_return_min": -362.890000000001, "episode_return_mean": -66.46429999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.6635452662601, "num_env_steps_trained_throughput_per_sec": 344.6635452662601, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 11462.039, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11461.989, "sample_time_ms": 1297.467, "learn_time_ms": 10146.307, "learn_throughput": 394.232, "synch_weights_time_ms": 14.469}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "310e1_00000", "date": "2024-08-15_00-59-47", "timestamp": 1723663787, "time_this_iter_s": 11.693189144134521, "time_total_s": 143.47549772262573, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b146f0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 143.47549772262573, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 61.747058823529414, "ram_util_percent": 83.93529411764706}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3864511744370536, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.301206737977487, "policy_loss": -0.008133854001031194, "vf_loss": 4.307403957023823, "vf_explained_var": -0.014124523142658213, "kl": 0.009683233952264824, "entropy": 1.4555402314221417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1371861934661864, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.0937476793924965, "policy_loss": -0.0060539752685972465, "vf_loss": 7.098627540043422, "vf_explained_var": 0.04814028787234473, "kl": 0.011741050728341237, "entropy": 1.5080155923883751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 105.40000000000012, "episode_reward_min": -362.890000000001, "episode_reward_mean": -55.641199999999905, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -439.8800000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.29000000000002, "predator_policy": 249.0}, "policy_reward_mean": {"prey_policy": -86.92060000000001, "predator_policy": 59.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.250000000000455, -5.260000000000078, -85.34000000000009, -10.260000000000076, 2.739999999999972, -77.9999999999987, -67.84999999999866, -362.890000000001, -248.8700000000007, -21.310000000000002, -33.599999999999866, 3.460000000000037, -30.690000000000165, -62.580000000000126, -130.37999999999977, -1.4100000000000315, -78.96999999999888, -52.82, -115.37999999999874, -1.9199999999999748, -7.640000000000072, -7.1300000000000825, -33.37999999999999, 97.89000000000146, 1.4199999999999988, -19.379999999999484, -26.299999999999923, -78.8799999999984, -59.24000000000048, -140.02, -353.0400000000008, -207.6000000000003, -298.9500000000008, 16.299999999999983, -11.230000000000075, -115.36999999999941, -93.97999999999927, -139.91000000000082, 3.799999999999954, -117.50999999999888, -116.28999999999867, -27.89000000000028, -55.449999999999676, 16.770000000000056, 47.49999999999956, 6.589999999999926, 84.92000000000006, 8.559999999999992, -86.77000000000014, -28.98999999999984, -6.210000000000015, -39.91000000000027, -60.860000000000205, -174.77000000000095, 27.840000000000273, -53.43999999999992, -63.04000000000026, 10.519999999999934, 4.039999999999946, -5.410000000000075, 18.990000000000347, -107.40000000000028, -53.76000000000037, -120.82999999999979, -169.6200000000009, -65.24999999999952, -153.74000000000075, -58.359999999999005, -49.25999999999975, -35.64000000000001, 26.360000000000486, -0.4399999999999533, -139.8100000000017, -73.05999999999987, 49.840000000000146, -62.169999999999106, 61.26999999999948, -223.510000000001, -89.92999999999941, -131.33999999999892, -70.96999999999964, 32.4600000000004, 105.40000000000012, -147.5999999999998, -166.85000000000065, -86.00000000000044, -65.37999999999997, -195.14000000000001, -70.06999999999914, 96.17000000000003, -12.130000000000027, -126.39999999999971, -117.19999999999881, 46.689999999999806, -20.83000000000014, 53.329999999999984, -99.74999999999942, 74.1499999999999, 98.74000000000072, -76.55999999999979], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-20.109999999999705, -24.64, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -291.3400000000002, 2.0000000000000013, -50.260000000000346, 34.24999999999975, -100.50999999999948, -38.319999999999865, -134.6800000000011, -41.320000000000334, -104.52999999999929, -383.9200000000001, -192.9700000000009, -341.7100000000001, -222.1600000000006, -148.74999999999943, 36.43999999999972, -96.4900000000001, -20.109999999999705, -4.450000000000026, -16.089999999999705, -75.39999999999918, -17.28999999999975, -207.03999999999976, -10.53999999999982, 24.44000000000021, -357.8200000000001, -56.29000000000034, 13.879999999999969, -166.83999999999958, -24.129999999999708, -97.50999999999995, -60.310000000000336, -83.55999999999952, -162.82000000000107, -91.62999999999938, 30.7100000000001, -25.38999999999975, -48.25000000000035, 2.0000000000000013, -24.129999999999708, -14.080000000000041, -58.300000000000026, 48.529999999999696, 35.35999999999973, -54.58000000000028, 2.0000000000000013, -74.37999999999917, 2.0000000000000013, -22.119999999999717, -34.18000000000008, -66.45999999999921, -79.41999999999919, -134.68000000000097, -17.559999999999782, -118.59999999999975, -315.4200000000001, -252.40000000000052, -327.6400000000003, -253.33000000000033, -253.2700000000001, -313.4500000000003, -307.50000000000045, -57.34000000000033, 16.64, 1.939999999999992, -32.16999999999995, -46.24000000000035, -225.13000000000028, -138.70000000000076, -54.28000000000004, -193.9900000000004, -198.92000000000087, 2.0000000000000013, -11.200000000000014, -156.82000000000096, -85.6899999999994, -166.76000000000113, -104.5299999999993, -113.73999999999936, 16.85000000000005, -142.36000000000053, -16.089999999999705, 6.769999999999962, 2.0000000000000013, -6.040000000000042, 47.53999999999978, -10.390000000000034, -2.0200000000000253, 60.41, 5.509999999999968, -42.220000000000354, 23.780000000000207, -269.3500000000005, 19.580000000000055, 2.0000000000000013, -437.99, -50.050000000000125, -30.15999999999995, -58.66000000000009, -48.25000000000018, -31.329999999999924, -104.52999999999925, -118.59999999999943, -233.17000000000024, 55.459999999999745, -110.6199999999993, 12.739999999999963, -235.18000000000004, -48.25000000000035, -156.79000000000008, -49.479999999999336, 2.0000000000000013, -58.300000000000274, 10.34000000000005, -30.15999999999972, -0.2500000000000191, -1.5100000000000173, -14.50000000000007, -17.410000000000032, -193.98999999999955, -10.299999999999825, -291.4600000000004, -30.15999999999972, -333.6700000000001, -173.5600000000004, -133.0600000000003, -112.9899999999995, -50.26000000000013, -116.58999999999985, -229.15000000000055, -62.82999999999953, -80.5299999999993, 39.61999999999996, -439.8800000000001, -47.320000000000334, -62.320000000000064, 21.80000000000028, -23.439999999999756, 29.72000000000001, -311.1599999999999, -60.789999999999935, -173.0200000000007, 20.510000000000158, -232.57000000000028, 34.28000000000002, -11.439999999999756, -120.22000000000051, -104.94999999999946, 9.919999999999968, 24.350000000000005, -194.98000000000084, -313.5300000000002, -74.37999999999988, -108.54999999999927, -235.1800000000007, -30.159999999999712, -244.36000000000038, 38.38999999999979, 16.45999999999998, 2.0000000000000013, 47.08999999999998, 34.30999999999995, -26.919999999999824, -391.67999999999984, -295.4800000000003, -72.36999999999917, -80.70999999999938, -122.29000000000057, -112.3, -95.0800000000005, -373.23, -180.91000000000003, -148.74999999999983, -11.319999999999794, 41.9300000000001, -3.7600000000000353, -291.41999999999996, 72.29000000000002, 33.32000000000002, -343.7199999999999, -192.9700000000008, -44.23000000000035, -21.640000000000054, 32.330000000000055, -145.60000000000025, 21.770000000000017, -178.90000000000012, 69.23000000000005, -212.56000000000034, -87.18999999999969, 35.65999999999993, 31.49000000000018, 51.05000000000005, 32.69000000000002, -209.56000000000012, 2.0000000000000013], "policy_predator_policy_reward": [43.0, 47.0, 24.0, 19.0, 111.0, 93.0, 26.0, 12.0, 48.0, 21.0, 23.0, 72.0, 25.0, 53.0, 18.0, 196.0, 153.0, 162.0, 35.0, 56.0, 47.0, 36.0, 6.0, 18.0, 40.0, 22.0, 61.0, 94.0, 25.0, 178.0, 23.0, 18.0, 41.0, 71.0, 25.0, 80.0, 94.0, 37.0, 42.0, 17.0, 28.0, 38.0, 13.0, 2.0, 8.0, 31.0, 4.0, 10.0, 16.0, 38.0, 15.0, 38.0, 12.0, 18.0, 45.0, 22.0, 25.0, 68.0, 138.0, 156.0, 180.0, 47.0, 134.0, 165.0, 138.0, 184.0, 31.0, 26.0, 10.0, 9.0, 26.0, 130.0, 98.0, 1.0, 121.0, 132.0, 4.0, 9.0, 44.0, 81.0, 108.0, 47.0, 51.0, 18.0, 10.0, 93.0, 6.0, 2.0, 4.0, 2.0, 17.0, 2.0, 4.0, 15.0, 22.0, 5.0, 28.0, 135.0, 175.0, 232.0, 33.0, 41.0, 25.0, 42.0, 54.0, 21.0, 60.0, 117.0, 30.0, 53.0, 113.0, 56.0, 63.0, 79.0, 27.0, 31.0, 14.0, 38.0, 19.0, 6.0, 18.0, 17.0, 98.0, 6.0, 140.0, 108.0, 114.0, 129.0, 7.0, 130.0, 52.0, 46.0, 83.0, 109.0, 46.0, 39.0, 134.0, 217.0, 57.0, 17.0, 14.0, 14.0, 82.0, 199.0, 92.0, 2.0, 17.0, 122.0, 8.0, 19.0, 93.0, 70.0, 14.0, 13.0, 168.0, 117.0, 48.0, 45.0, 118.0, 16.0, 133.0, 2.0, 13.0, 1.0, 13.0, 11.0, 40.0, 231.0, 70.0, 131.0, 60.0, 57.0, 79.0, 63.0, 110.0, 249.0, 15.0, 75.0, 24.0, 34.0, 89.0, 118.0, 172.0, 12.0, 97.0, 23.0, 30.0, 6.0, 16.0, 87.0, 80.0, 83.0, 45.0, 155.0, 4.0, 3.0, 0.0, 15.0, 51.0, 80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7177274416025616, "mean_inference_ms": 1.9712955839706126, "mean_action_processing_ms": 0.3099595968489648, "mean_env_wait_ms": 0.24929852768833413, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004012465476989746, "StateBufferConnector_ms": 0.003493189811706543, "ViewRequirementAgentConnector_ms": 0.10930144786834717}, "num_episodes": 18, "episode_return_max": 105.40000000000012, "episode_return_min": -362.890000000001, "episode_return_mean": -55.641199999999905, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 327.7031504354517, "num_env_steps_trained_throughput_per_sec": 327.7031504354517, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 11541.751, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11541.7, "sample_time_ms": 1344.593, "learn_time_ms": 10177.759, "learn_throughput": 393.014, "synch_weights_time_ms": 14.526}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "310e1_00000", "date": "2024-08-15_00-59-59", "timestamp": 1723663799, "time_this_iter_s": 12.236562013626099, "time_total_s": 155.71205973625183, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14fd550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 155.71205973625183, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 66.71176470588235, "ram_util_percent": 83.78235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.388358981394894, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.687463244811568, "policy_loss": -0.009157663405128809, "vf_loss": 4.694564747810364, "vf_explained_var": -0.005606136435554141, "kl": 0.010280793679858406, "entropy": 1.462611589419148, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6638923794188827, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.639704076070634, "policy_loss": -0.006315070456238809, "vf_loss": 7.644896575130483, "vf_explained_var": 0.07951617761263771, "kl": 0.011225864830812188, "entropy": 1.4926963884363729, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 194.8799999999993, "episode_reward_min": -353.0400000000008, "episode_reward_mean": -35.13779999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -539.86, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.6400000000001, "predator_policy": 277.0}, "policy_reward_mean": {"prey_policy": -79.58890000000001, "predator_policy": 62.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-78.8799999999984, -59.24000000000048, -140.02, -353.0400000000008, -207.6000000000003, -298.9500000000008, 16.299999999999983, -11.230000000000075, -115.36999999999941, -93.97999999999927, -139.91000000000082, 3.799999999999954, -117.50999999999888, -116.28999999999867, -27.89000000000028, -55.449999999999676, 16.770000000000056, 47.49999999999956, 6.589999999999926, 84.92000000000006, 8.559999999999992, -86.77000000000014, -28.98999999999984, -6.210000000000015, -39.91000000000027, -60.860000000000205, -174.77000000000095, 27.840000000000273, -53.43999999999992, -63.04000000000026, 10.519999999999934, 4.039999999999946, -5.410000000000075, 18.990000000000347, -107.40000000000028, -53.76000000000037, -120.82999999999979, -169.6200000000009, -65.24999999999952, -153.74000000000075, -58.359999999999005, -49.25999999999975, -35.64000000000001, 26.360000000000486, -0.4399999999999533, -139.8100000000017, -73.05999999999987, 49.840000000000146, -62.169999999999106, 61.26999999999948, -223.510000000001, -89.92999999999941, -131.33999999999892, -70.96999999999964, 32.4600000000004, 105.40000000000012, -147.5999999999998, -166.85000000000065, -86.00000000000044, -65.37999999999997, -195.14000000000001, -70.06999999999914, 96.17000000000003, -12.130000000000027, -126.39999999999971, -117.19999999999881, 46.689999999999806, -20.83000000000014, 53.329999999999984, -99.74999999999942, 74.1499999999999, 98.74000000000072, -76.55999999999979, 40.43000000000001, 86.71000000000005, -158.3799999999997, -34.949999999999946, -214.55999999999995, 194.8799999999993, -31.059999999999462, 25.900000000000063, -116.71999999999952, 72.69999999999973, 137.43000000000046, 83.37000000000006, 49.07999999999947, -10.350000000000078, 165.8799999999997, -11.670000000000067, 2.8699999999999664, -71.48000000000124, 48.44000000000006, -17.430000000000025, 80.91000000000031, 40.59999999999992, 111.88000000000011, 128.79000000000016, 27.489999999999974, 104.77000000000014, -15.789999999999786], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-66.45999999999921, -79.41999999999919, -134.68000000000097, -17.559999999999782, -118.59999999999975, -315.4200000000001, -252.40000000000052, -327.6400000000003, -253.33000000000033, -253.2700000000001, -313.4500000000003, -307.50000000000045, -57.34000000000033, 16.64, 1.939999999999992, -32.16999999999995, -46.24000000000035, -225.13000000000028, -138.70000000000076, -54.28000000000004, -193.9900000000004, -198.92000000000087, 2.0000000000000013, -11.200000000000014, -156.82000000000096, -85.6899999999994, -166.76000000000113, -104.5299999999993, -113.73999999999936, 16.85000000000005, -142.36000000000053, -16.089999999999705, 6.769999999999962, 2.0000000000000013, -6.040000000000042, 47.53999999999978, -10.390000000000034, -2.0200000000000253, 60.41, 5.509999999999968, -42.220000000000354, 23.780000000000207, -269.3500000000005, 19.580000000000055, 2.0000000000000013, -437.99, -50.050000000000125, -30.15999999999995, -58.66000000000009, -48.25000000000018, -31.329999999999924, -104.52999999999925, -118.59999999999943, -233.17000000000024, 55.459999999999745, -110.6199999999993, 12.739999999999963, -235.18000000000004, -48.25000000000035, -156.79000000000008, -49.479999999999336, 2.0000000000000013, -58.300000000000274, 10.34000000000005, -30.15999999999972, -0.2500000000000191, -1.5100000000000173, -14.50000000000007, -17.410000000000032, -193.98999999999955, -10.299999999999825, -291.4600000000004, -30.15999999999972, -333.6700000000001, -173.5600000000004, -133.0600000000003, -112.9899999999995, -50.26000000000013, -116.58999999999985, -229.15000000000055, -62.82999999999953, -80.5299999999993, 39.61999999999996, -439.8800000000001, -47.320000000000334, -62.320000000000064, 21.80000000000028, -23.439999999999756, 29.72000000000001, -311.1599999999999, -60.789999999999935, -173.0200000000007, 20.510000000000158, -232.57000000000028, 34.28000000000002, -11.439999999999756, -120.22000000000051, -104.94999999999946, 9.919999999999968, 24.350000000000005, -194.98000000000084, -313.5300000000002, -74.37999999999988, -108.54999999999927, -235.1800000000007, -30.159999999999712, -244.36000000000038, 38.38999999999979, 16.45999999999998, 2.0000000000000013, 47.08999999999998, 34.30999999999995, -26.919999999999824, -391.67999999999984, -295.4800000000003, -72.36999999999917, -80.70999999999938, -122.29000000000057, -112.3, -95.0800000000005, -373.23, -180.91000000000003, -148.74999999999983, -11.319999999999794, 41.9300000000001, -3.7600000000000353, -291.41999999999996, 72.29000000000002, 33.32000000000002, -343.7199999999999, -192.9700000000008, -44.23000000000035, -21.640000000000054, 32.330000000000055, -145.60000000000025, 21.770000000000017, -178.90000000000012, 69.23000000000005, -212.56000000000034, -87.18999999999969, 35.65999999999993, 31.49000000000018, 51.05000000000005, 32.69000000000002, -209.56000000000012, 2.0000000000000013, -16.32999999999974, -22.239999999999952, 68.78000000000006, -36.069999999999666, -140.71000000000004, -132.6700000000002, -539.86, 10.910000000000036, -321.6099999999999, -212.95, 75.86000000000003, 99.02000000000037, -42.99999999999989, -88.05999999999962, 28.789999999999957, -65.88999999999943, -361.8100000000002, 50.08999999999998, 27.350000000000136, 12.349999999999914, 105.77000000000008, 20.660000000000245, 99.5600000000001, -234.19000000000003, -44.23000000000035, 58.30999999999974, -68.34999999999917, 2.0000000000000013, 51.13999999999993, 90.74000000000011, 2.0000000000000013, -132.6700000000012, 1.9099999999999933, -6.040000000000042, -45.2199999999996, -119.26000000000026, 24.25999999999997, -30.82000000000007, -134.38000000000014, -26.049999999999894, 51.439999999999934, -35.52999999999991, 14.569999999999988, -36.96999999999984, 112.7000000000003, -186.81999999999988, 67.91000000000005, 13.879999999999995, -10.510000000000279, 2.0000000000000013, -373.87000000000006, 136.6400000000001, -111.78999999999938, 2.0000000000000013], "policy_predator_policy_reward": [45.0, 22.0, 25.0, 68.0, 138.0, 156.0, 180.0, 47.0, 134.0, 165.0, 138.0, 184.0, 31.0, 26.0, 10.0, 9.0, 26.0, 130.0, 98.0, 1.0, 121.0, 132.0, 4.0, 9.0, 44.0, 81.0, 108.0, 47.0, 51.0, 18.0, 10.0, 93.0, 6.0, 2.0, 4.0, 2.0, 17.0, 2.0, 4.0, 15.0, 22.0, 5.0, 28.0, 135.0, 175.0, 232.0, 33.0, 41.0, 25.0, 42.0, 54.0, 21.0, 60.0, 117.0, 30.0, 53.0, 113.0, 56.0, 63.0, 79.0, 27.0, 31.0, 14.0, 38.0, 19.0, 6.0, 18.0, 17.0, 98.0, 6.0, 140.0, 108.0, 114.0, 129.0, 7.0, 130.0, 52.0, 46.0, 83.0, 109.0, 46.0, 39.0, 134.0, 217.0, 57.0, 17.0, 14.0, 14.0, 82.0, 199.0, 92.0, 2.0, 17.0, 122.0, 8.0, 19.0, 93.0, 70.0, 14.0, 13.0, 168.0, 117.0, 48.0, 45.0, 118.0, 16.0, 133.0, 2.0, 13.0, 1.0, 13.0, 11.0, 40.0, 231.0, 70.0, 131.0, 60.0, 57.0, 79.0, 63.0, 110.0, 249.0, 15.0, 75.0, 24.0, 34.0, 89.0, 118.0, 172.0, 12.0, 97.0, 23.0, 30.0, 6.0, 16.0, 87.0, 80.0, 83.0, 45.0, 155.0, 4.0, 3.0, 0.0, 15.0, 51.0, 80.0, 49.0, 30.0, 51.0, 3.0, 34.0, 81.0, 277.0, 217.0, 172.0, 148.0, 7.0, 13.0, 64.0, 36.0, 0.0, 63.0, 181.0, 14.0, 19.0, 14.0, 5.0, 6.0, 97.0, 121.0, 24.0, 11.0, 35.0, 21.0, 16.0, 8.0, 64.0, 55.0, 3.0, 4.0, 82.0, 11.0, 17.0, 38.0, 56.0, 87.0, 60.0, 5.0, 28.0, 35.0, 102.0, 84.0, 14.0, 33.0, 21.0, 15.0, 167.0, 175.0, 46.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7147899251542796, "mean_inference_ms": 1.9549607728265241, "mean_action_processing_ms": 0.3066204241089715, "mean_env_wait_ms": 0.2481590379873035, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004076600074768066, "StateBufferConnector_ms": 0.003310680389404297, "ViewRequirementAgentConnector_ms": 0.11637747287750244}, "num_episodes": 27, "episode_return_max": 194.8799999999993, "episode_return_min": -353.0400000000008, "episode_return_mean": -35.13779999999998, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.7908804571954, "num_env_steps_trained_throughput_per_sec": 344.7908804571954, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 11585.076, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11585.01, "sample_time_ms": 1363.348, "learn_time_ms": 10202.23, "learn_throughput": 392.071, "synch_weights_time_ms": 14.544}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "310e1_00000", "date": "2024-08-15_01-00-11", "timestamp": 1723663811, "time_this_iter_s": 11.649020910263062, "time_total_s": 167.3610806465149, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c4790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 167.3610806465149, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 64.58823529411765, "ram_util_percent": 83.78235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1603459268177627, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.345708833043537, "policy_loss": -0.005145832670300647, "vf_loss": 4.349718989140142, "vf_explained_var": -0.0005220138837420752, "kl": 0.00567833875862782, "entropy": 1.4773324732427244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6716273919615166, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.49733942097457, "policy_loss": -0.013519225835987421, "vf_loss": 6.509093488713421, "vf_explained_var": 0.05988032237562553, "kl": 0.017651703335394255, "entropy": 1.5017501846823111, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 259.0999999999995, "episode_reward_min": -223.510000000001, "episode_reward_mean": -16.226799999999958, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -539.86, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 155.4499999999999, "predator_policy": 284.0}, "policy_reward_mean": {"prey_policy": -68.58339999999998, "predator_policy": 60.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.589999999999926, 84.92000000000006, 8.559999999999992, -86.77000000000014, -28.98999999999984, -6.210000000000015, -39.91000000000027, -60.860000000000205, -174.77000000000095, 27.840000000000273, -53.43999999999992, -63.04000000000026, 10.519999999999934, 4.039999999999946, -5.410000000000075, 18.990000000000347, -107.40000000000028, -53.76000000000037, -120.82999999999979, -169.6200000000009, -65.24999999999952, -153.74000000000075, -58.359999999999005, -49.25999999999975, -35.64000000000001, 26.360000000000486, -0.4399999999999533, -139.8100000000017, -73.05999999999987, 49.840000000000146, -62.169999999999106, 61.26999999999948, -223.510000000001, -89.92999999999941, -131.33999999999892, -70.96999999999964, 32.4600000000004, 105.40000000000012, -147.5999999999998, -166.85000000000065, -86.00000000000044, -65.37999999999997, -195.14000000000001, -70.06999999999914, 96.17000000000003, -12.130000000000027, -126.39999999999971, -117.19999999999881, 46.689999999999806, -20.83000000000014, 53.329999999999984, -99.74999999999942, 74.1499999999999, 98.74000000000072, -76.55999999999979, 40.43000000000001, 86.71000000000005, -158.3799999999997, -34.949999999999946, -214.55999999999995, 194.8799999999993, -31.059999999999462, 25.900000000000063, -116.71999999999952, 72.69999999999973, 137.43000000000046, 83.37000000000006, 49.07999999999947, -10.350000000000078, 165.8799999999997, -11.670000000000067, 2.8699999999999664, -71.48000000000124, 48.44000000000006, -17.430000000000025, 80.91000000000031, 40.59999999999992, 111.88000000000011, 128.79000000000016, 27.489999999999974, 104.77000000000014, -15.789999999999786, -83.99999999999903, -38.37999999999973, -134.38999999999953, 44.09000000000004, -161.76, 201.8199999999996, -51.77999999999996, -26.29999999999944, -73.86999999999935, 118.6400000000008, -43.830000000000084, 26.670000000000215, 45.07999999999959, 120.10000000000024, -17.659999999999823, 156.11000000000016, 259.0999999999995, -179.5300000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.390000000000034, -2.0200000000000253, 60.41, 5.509999999999968, -42.220000000000354, 23.780000000000207, -269.3500000000005, 19.580000000000055, 2.0000000000000013, -437.99, -50.050000000000125, -30.15999999999995, -58.66000000000009, -48.25000000000018, -31.329999999999924, -104.52999999999925, -118.59999999999943, -233.17000000000024, 55.459999999999745, -110.6199999999993, 12.739999999999963, -235.18000000000004, -48.25000000000035, -156.79000000000008, -49.479999999999336, 2.0000000000000013, -58.300000000000274, 10.34000000000005, -30.15999999999972, -0.2500000000000191, -1.5100000000000173, -14.50000000000007, -17.410000000000032, -193.98999999999955, -10.299999999999825, -291.4600000000004, -30.15999999999972, -333.6700000000001, -173.5600000000004, -133.0600000000003, -112.9899999999995, -50.26000000000013, -116.58999999999985, -229.15000000000055, -62.82999999999953, -80.5299999999993, 39.61999999999996, -439.8800000000001, -47.320000000000334, -62.320000000000064, 21.80000000000028, -23.439999999999756, 29.72000000000001, -311.1599999999999, -60.789999999999935, -173.0200000000007, 20.510000000000158, -232.57000000000028, 34.28000000000002, -11.439999999999756, -120.22000000000051, -104.94999999999946, 9.919999999999968, 24.350000000000005, -194.98000000000084, -313.5300000000002, -74.37999999999988, -108.54999999999927, -235.1800000000007, -30.159999999999712, -244.36000000000038, 38.38999999999979, 16.45999999999998, 2.0000000000000013, 47.08999999999998, 34.30999999999995, -26.919999999999824, -391.67999999999984, -295.4800000000003, -72.36999999999917, -80.70999999999938, -122.29000000000057, -112.3, -95.0800000000005, -373.23, -180.91000000000003, -148.74999999999983, -11.319999999999794, 41.9300000000001, -3.7600000000000353, -291.41999999999996, 72.29000000000002, 33.32000000000002, -343.7199999999999, -192.9700000000008, -44.23000000000035, -21.640000000000054, 32.330000000000055, -145.60000000000025, 21.770000000000017, -178.90000000000012, 69.23000000000005, -212.56000000000034, -87.18999999999969, 35.65999999999993, 31.49000000000018, 51.05000000000005, 32.69000000000002, -209.56000000000012, 2.0000000000000013, -16.32999999999974, -22.239999999999952, 68.78000000000006, -36.069999999999666, -140.71000000000004, -132.6700000000002, -539.86, 10.910000000000036, -321.6099999999999, -212.95, 75.86000000000003, 99.02000000000037, -42.99999999999989, -88.05999999999962, 28.789999999999957, -65.88999999999943, -361.8100000000002, 50.08999999999998, 27.350000000000136, 12.349999999999914, 105.77000000000008, 20.660000000000245, 99.5600000000001, -234.19000000000003, -44.23000000000035, 58.30999999999974, -68.34999999999917, 2.0000000000000013, 51.13999999999993, 90.74000000000011, 2.0000000000000013, -132.6700000000012, 1.9099999999999933, -6.040000000000042, -45.2199999999996, -119.26000000000026, 24.25999999999997, -30.82000000000007, -134.38000000000014, -26.049999999999894, 51.439999999999934, -35.52999999999991, 14.569999999999988, -36.96999999999984, 112.7000000000003, -186.81999999999988, 67.91000000000005, 13.879999999999995, -10.510000000000279, 2.0000000000000013, -373.87000000000006, 136.6400000000001, -111.78999999999938, 2.0000000000000013, -58.30000000000033, -168.70000000000027, -56.800000000000004, -120.58000000000027, -38.20000000000036, -253.19000000000003, 31.160000000000007, -12.070000000000041, 2.0000000000000013, -447.76, 1.3100000000000236, 119.51000000000023, -190.7800000000001, 2.0000000000000013, -32.170000000000364, -24.12999999999974, -78.39999999999918, -100.46999999999979, -24.129999999999708, 123.77000000000031, 2.0000000000000013, -164.83000000000055, 2.0000000000000013, -46.329999999999906, 66.35000000000052, -52.27000000000032, -377.64999999999986, 125.7500000000002, 2.0000000000000013, -130.65999999999985, 15.859999999999998, 88.25000000000003, 155.4499999999999, 87.65000000000016, -272.8600000000001, -69.66999999999983], "policy_predator_policy_reward": [17.0, 2.0, 4.0, 15.0, 22.0, 5.0, 28.0, 135.0, 175.0, 232.0, 33.0, 41.0, 25.0, 42.0, 54.0, 21.0, 60.0, 117.0, 30.0, 53.0, 113.0, 56.0, 63.0, 79.0, 27.0, 31.0, 14.0, 38.0, 19.0, 6.0, 18.0, 17.0, 98.0, 6.0, 140.0, 108.0, 114.0, 129.0, 7.0, 130.0, 52.0, 46.0, 83.0, 109.0, 46.0, 39.0, 134.0, 217.0, 57.0, 17.0, 14.0, 14.0, 82.0, 199.0, 92.0, 2.0, 17.0, 122.0, 8.0, 19.0, 93.0, 70.0, 14.0, 13.0, 168.0, 117.0, 48.0, 45.0, 118.0, 16.0, 133.0, 2.0, 13.0, 1.0, 13.0, 11.0, 40.0, 231.0, 70.0, 131.0, 60.0, 57.0, 79.0, 63.0, 110.0, 249.0, 15.0, 75.0, 24.0, 34.0, 89.0, 118.0, 172.0, 12.0, 97.0, 23.0, 30.0, 6.0, 16.0, 87.0, 80.0, 83.0, 45.0, 155.0, 4.0, 3.0, 0.0, 15.0, 51.0, 80.0, 49.0, 30.0, 51.0, 3.0, 34.0, 81.0, 277.0, 217.0, 172.0, 148.0, 7.0, 13.0, 64.0, 36.0, 0.0, 63.0, 181.0, 14.0, 19.0, 14.0, 5.0, 6.0, 97.0, 121.0, 24.0, 11.0, 35.0, 21.0, 16.0, 8.0, 64.0, 55.0, 3.0, 4.0, 82.0, 11.0, 17.0, 38.0, 56.0, 87.0, 60.0, 5.0, 28.0, 35.0, 102.0, 84.0, 14.0, 33.0, 21.0, 15.0, 167.0, 175.0, 46.0, 48.0, 113.0, 30.0, 29.0, 110.0, 20.0, 137.0, 7.0, 18.0, 0.0, 284.0, 41.0, 40.0, 122.0, 15.0, 2.0, 28.0, 9.0, 96.0, 13.0, 6.0, 68.0, 51.0, 60.0, 11.0, 15.0, 16.0, 190.0, 182.0, 56.0, 55.0, 29.0, 23.0, 0.0, 16.0, 160.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7128039591250477, "mean_inference_ms": 1.9528508458353455, "mean_action_processing_ms": 0.3050446522599603, "mean_env_wait_ms": 0.24872141975035159, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037375688552856445, "StateBufferConnector_ms": 0.0032461881637573242, "ViewRequirementAgentConnector_ms": 0.10793840885162354}, "num_episodes": 18, "episode_return_max": 259.0999999999995, "episode_return_min": -223.510000000001, "episode_return_mean": -16.226799999999958, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.1649416327237, "num_env_steps_trained_throughput_per_sec": 352.1649416327237, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 11589.737, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11589.671, "sample_time_ms": 1380.774, "learn_time_ms": 10189.158, "learn_throughput": 392.574, "synch_weights_time_ms": 14.802}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "310e1_00000", "date": "2024-08-15_01-00-22", "timestamp": 1723663822, "time_this_iter_s": 11.391340732574463, "time_total_s": 178.75242137908936, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b146fe50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 178.75242137908936, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 61.78125, "ram_util_percent": 83.50625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3275458480630602, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7860529079008356, "policy_loss": -0.00787951343411964, "vf_loss": 2.7921591401730894, "vf_explained_var": 0.006672372546776262, "kl": 0.008866423808670724, "entropy": 1.4426740400374882, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2468690108054528, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.874136395429177, "policy_loss": -0.014033509703431889, "vf_loss": 7.8866599012304235, "vf_explained_var": 0.15346070575335669, "kl": 0.015100027722602511, "entropy": 1.4681300170837888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 259.0999999999995, "episode_reward_min": -223.510000000001, "episode_reward_mean": 9.60260000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -539.86, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 155.4499999999999, "predator_policy": 284.0}, "policy_reward_mean": {"prey_policy": -52.7537, "predator_policy": 57.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-120.82999999999979, -169.6200000000009, -65.24999999999952, -153.74000000000075, -58.359999999999005, -49.25999999999975, -35.64000000000001, 26.360000000000486, -0.4399999999999533, -139.8100000000017, -73.05999999999987, 49.840000000000146, -62.169999999999106, 61.26999999999948, -223.510000000001, -89.92999999999941, -131.33999999999892, -70.96999999999964, 32.4600000000004, 105.40000000000012, -147.5999999999998, -166.85000000000065, -86.00000000000044, -65.37999999999997, -195.14000000000001, -70.06999999999914, 96.17000000000003, -12.130000000000027, -126.39999999999971, -117.19999999999881, 46.689999999999806, -20.83000000000014, 53.329999999999984, -99.74999999999942, 74.1499999999999, 98.74000000000072, -76.55999999999979, 40.43000000000001, 86.71000000000005, -158.3799999999997, -34.949999999999946, -214.55999999999995, 194.8799999999993, -31.059999999999462, 25.900000000000063, -116.71999999999952, 72.69999999999973, 137.43000000000046, 83.37000000000006, 49.07999999999947, -10.350000000000078, 165.8799999999997, -11.670000000000067, 2.8699999999999664, -71.48000000000124, 48.44000000000006, -17.430000000000025, 80.91000000000031, 40.59999999999992, 111.88000000000011, 128.79000000000016, 27.489999999999974, 104.77000000000014, -15.789999999999786, -83.99999999999903, -38.37999999999973, -134.38999999999953, 44.09000000000004, -161.76, 201.8199999999996, -51.77999999999996, -26.29999999999944, -73.86999999999935, 118.6400000000008, -43.830000000000084, 26.670000000000215, 45.07999999999959, 120.10000000000024, -17.659999999999823, 156.11000000000016, 259.0999999999995, -179.5300000000003, -38.310000000000386, 244.5099999999997, 190.88999999999967, 127.79000000000008, 32.26000000000018, 193.78000000000014, 16.569999999999816, 13.400000000000432, 110.88000000000044, 110.62000000000064, 64.44999999999992, 178.18999999999983, 173.77999999999952, 184.38999999999973, 96.5600000000002, 63.349999999999916, 144.57000000000008, 156.15999999999963], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-30.15999999999972, -333.6700000000001, -173.5600000000004, -133.0600000000003, -112.9899999999995, -50.26000000000013, -116.58999999999985, -229.15000000000055, -62.82999999999953, -80.5299999999993, 39.61999999999996, -439.8800000000001, -47.320000000000334, -62.320000000000064, 21.80000000000028, -23.439999999999756, 29.72000000000001, -311.1599999999999, -60.789999999999935, -173.0200000000007, 20.510000000000158, -232.57000000000028, 34.28000000000002, -11.439999999999756, -120.22000000000051, -104.94999999999946, 9.919999999999968, 24.350000000000005, -194.98000000000084, -313.5300000000002, -74.37999999999988, -108.54999999999927, -235.1800000000007, -30.159999999999712, -244.36000000000038, 38.38999999999979, 16.45999999999998, 2.0000000000000013, 47.08999999999998, 34.30999999999995, -26.919999999999824, -391.67999999999984, -295.4800000000003, -72.36999999999917, -80.70999999999938, -122.29000000000057, -112.3, -95.0800000000005, -373.23, -180.91000000000003, -148.74999999999983, -11.319999999999794, 41.9300000000001, -3.7600000000000353, -291.41999999999996, 72.29000000000002, 33.32000000000002, -343.7199999999999, -192.9700000000008, -44.23000000000035, -21.640000000000054, 32.330000000000055, -145.60000000000025, 21.770000000000017, -178.90000000000012, 69.23000000000005, -212.56000000000034, -87.18999999999969, 35.65999999999993, 31.49000000000018, 51.05000000000005, 32.69000000000002, -209.56000000000012, 2.0000000000000013, -16.32999999999974, -22.239999999999952, 68.78000000000006, -36.069999999999666, -140.71000000000004, -132.6700000000002, -539.86, 10.910000000000036, -321.6099999999999, -212.95, 75.86000000000003, 99.02000000000037, -42.99999999999989, -88.05999999999962, 28.789999999999957, -65.88999999999943, -361.8100000000002, 50.08999999999998, 27.350000000000136, 12.349999999999914, 105.77000000000008, 20.660000000000245, 99.5600000000001, -234.19000000000003, -44.23000000000035, 58.30999999999974, -68.34999999999917, 2.0000000000000013, 51.13999999999993, 90.74000000000011, 2.0000000000000013, -132.6700000000012, 1.9099999999999933, -6.040000000000042, -45.2199999999996, -119.26000000000026, 24.25999999999997, -30.82000000000007, -134.38000000000014, -26.049999999999894, 51.439999999999934, -35.52999999999991, 14.569999999999988, -36.96999999999984, 112.7000000000003, -186.81999999999988, 67.91000000000005, 13.879999999999995, -10.510000000000279, 2.0000000000000013, -373.87000000000006, 136.6400000000001, -111.78999999999938, 2.0000000000000013, -58.30000000000033, -168.70000000000027, -56.800000000000004, -120.58000000000027, -38.20000000000036, -253.19000000000003, 31.160000000000007, -12.070000000000041, 2.0000000000000013, -447.76, 1.3100000000000236, 119.51000000000023, -190.7800000000001, 2.0000000000000013, -32.170000000000364, -24.12999999999974, -78.39999999999918, -100.46999999999979, -24.129999999999708, 123.77000000000031, 2.0000000000000013, -164.83000000000055, 2.0000000000000013, -46.329999999999906, 66.35000000000052, -52.27000000000032, -377.64999999999986, 125.7500000000002, 2.0000000000000013, -130.65999999999985, 15.859999999999998, 88.25000000000003, 155.4499999999999, 87.65000000000016, -272.8600000000001, -69.66999999999983, -48.25000000000035, -185.06000000000057, 93.07999999999996, 142.43, 106.55000000000007, -61.660000000000025, 62.38999999999997, -31.599999999999838, -63.69999999999992, -6.040000000000042, 137.63000000000008, 26.14999999999985, -190.24000000000063, 92.80999999999989, 2.929999999999962, -14.530000000000253, 110.9000000000001, -2.020000000000042, 87.62000000000016, 2.0000000000000013, 28.52000000000005, -12.07000000000004, 114.86000000000041, 56.329999999999906, 94.07000000000019, 48.70999999999994, 105.76999999999997, 42.61999999999995, 51.10999999999983, -132.5500000000004, 68.03000000000017, -220.68000000000023, 100.51999999999998, -44.94999999999977, 79.13000000000008, 62.029999999999895], "policy_predator_policy_reward": [114.0, 129.0, 7.0, 130.0, 52.0, 46.0, 83.0, 109.0, 46.0, 39.0, 134.0, 217.0, 57.0, 17.0, 14.0, 14.0, 82.0, 199.0, 92.0, 2.0, 17.0, 122.0, 8.0, 19.0, 93.0, 70.0, 14.0, 13.0, 168.0, 117.0, 48.0, 45.0, 118.0, 16.0, 133.0, 2.0, 13.0, 1.0, 13.0, 11.0, 40.0, 231.0, 70.0, 131.0, 60.0, 57.0, 79.0, 63.0, 110.0, 249.0, 15.0, 75.0, 24.0, 34.0, 89.0, 118.0, 172.0, 12.0, 97.0, 23.0, 30.0, 6.0, 16.0, 87.0, 80.0, 83.0, 45.0, 155.0, 4.0, 3.0, 0.0, 15.0, 51.0, 80.0, 49.0, 30.0, 51.0, 3.0, 34.0, 81.0, 277.0, 217.0, 172.0, 148.0, 7.0, 13.0, 64.0, 36.0, 0.0, 63.0, 181.0, 14.0, 19.0, 14.0, 5.0, 6.0, 97.0, 121.0, 24.0, 11.0, 35.0, 21.0, 16.0, 8.0, 64.0, 55.0, 3.0, 4.0, 82.0, 11.0, 17.0, 38.0, 56.0, 87.0, 60.0, 5.0, 28.0, 35.0, 102.0, 84.0, 14.0, 33.0, 21.0, 15.0, 167.0, 175.0, 46.0, 48.0, 113.0, 30.0, 29.0, 110.0, 20.0, 137.0, 7.0, 18.0, 0.0, 284.0, 41.0, 40.0, 122.0, 15.0, 2.0, 28.0, 9.0, 96.0, 13.0, 6.0, 68.0, 51.0, 60.0, 11.0, 15.0, 16.0, 190.0, 182.0, 56.0, 55.0, 29.0, 23.0, 0.0, 16.0, 160.0, 3.0, 102.0, 93.0, 5.0, 4.0, 75.0, 71.0, 83.0, 14.0, 65.0, 37.0, 11.0, 19.0, 20.0, 94.0, 2.0, 23.0, 0.0, 2.0, 17.0, 4.0, 8.0, 40.0, 4.0, 3.0, 26.0, 5.0, 9.0, 27.0, 86.0, 92.0, 82.0, 134.0, 38.0, 51.0, 7.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7112975456897473, "mean_inference_ms": 1.947026164301615, "mean_action_processing_ms": 0.30364780147102904, "mean_env_wait_ms": 0.2485577099404682, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038442611694335938, "StateBufferConnector_ms": 0.004730582237243652, "ViewRequirementAgentConnector_ms": 0.10740423202514648}, "num_episodes": 18, "episode_return_max": 259.0999999999995, "episode_return_min": -223.510000000001, "episode_return_mean": 9.60260000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.5847840768584, "num_env_steps_trained_throughput_per_sec": 340.5847840768584, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 11635.425, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11635.359, "sample_time_ms": 1401.726, "learn_time_ms": 10214.189, "learn_throughput": 391.612, "synch_weights_time_ms": 14.496}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "310e1_00000", "date": "2024-08-15_01-00-34", "timestamp": 1723663834, "time_this_iter_s": 11.787883996963501, "time_total_s": 190.54030537605286, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1482940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 190.54030537605286, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 62.14375, "ram_util_percent": 83.65}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3286879143229238, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2778432330126486, "policy_loss": -0.00680372622098143, "vf_loss": 2.283448579639354, "vf_explained_var": 0.029364764406567528, "kl": 0.0059918670191479945, "entropy": 1.4564156501381487, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.116248868224482, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.403403486776604, "policy_loss": -0.011263009402457447, "vf_loss": 8.41312891188122, "vf_explained_var": 0.20765430589832326, "kl": 0.015375790249458687, "entropy": 1.4775797722831605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 259.0999999999995, "episode_reward_min": -214.55999999999995, "episode_reward_mean": 41.75960000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -539.86, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.34999999999977, "predator_policy": 284.0}, "policy_reward_mean": {"prey_policy": -29.825199999999974, "predator_policy": 50.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.4600000000004, 105.40000000000012, -147.5999999999998, -166.85000000000065, -86.00000000000044, -65.37999999999997, -195.14000000000001, -70.06999999999914, 96.17000000000003, -12.130000000000027, -126.39999999999971, -117.19999999999881, 46.689999999999806, -20.83000000000014, 53.329999999999984, -99.74999999999942, 74.1499999999999, 98.74000000000072, -76.55999999999979, 40.43000000000001, 86.71000000000005, -158.3799999999997, -34.949999999999946, -214.55999999999995, 194.8799999999993, -31.059999999999462, 25.900000000000063, -116.71999999999952, 72.69999999999973, 137.43000000000046, 83.37000000000006, 49.07999999999947, -10.350000000000078, 165.8799999999997, -11.670000000000067, 2.8699999999999664, -71.48000000000124, 48.44000000000006, -17.430000000000025, 80.91000000000031, 40.59999999999992, 111.88000000000011, 128.79000000000016, 27.489999999999974, 104.77000000000014, -15.789999999999786, -83.99999999999903, -38.37999999999973, -134.38999999999953, 44.09000000000004, -161.76, 201.8199999999996, -51.77999999999996, -26.29999999999944, -73.86999999999935, 118.6400000000008, -43.830000000000084, 26.670000000000215, 45.07999999999959, 120.10000000000024, -17.659999999999823, 156.11000000000016, 259.0999999999995, -179.5300000000003, -38.310000000000386, 244.5099999999997, 190.88999999999967, 127.79000000000008, 32.26000000000018, 193.78000000000014, 16.569999999999816, 13.400000000000432, 110.88000000000044, 110.62000000000064, 64.44999999999992, 178.18999999999983, 173.77999999999952, 184.38999999999973, 96.5600000000002, 63.349999999999916, 144.57000000000008, 156.15999999999963, -52.89999999999954, -15.829999999999602, 87.28000000000021, 173.3699999999998, 35.01000000000004, 106.64000000000021, 121.17000000000006, 109.08000000000025, 125.31000000000058, 122.29000000000009, 97.42000000000019, 230.3099999999998, 135.91000000000014, 57.60999999999992, 162.96999999999946, 133.39000000000027, 89.23000000000033, 190.97999999999962], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [16.45999999999998, 2.0000000000000013, 47.08999999999998, 34.30999999999995, -26.919999999999824, -391.67999999999984, -295.4800000000003, -72.36999999999917, -80.70999999999938, -122.29000000000057, -112.3, -95.0800000000005, -373.23, -180.91000000000003, -148.74999999999983, -11.319999999999794, 41.9300000000001, -3.7600000000000353, -291.41999999999996, 72.29000000000002, 33.32000000000002, -343.7199999999999, -192.9700000000008, -44.23000000000035, -21.640000000000054, 32.330000000000055, -145.60000000000025, 21.770000000000017, -178.90000000000012, 69.23000000000005, -212.56000000000034, -87.18999999999969, 35.65999999999993, 31.49000000000018, 51.05000000000005, 32.69000000000002, -209.56000000000012, 2.0000000000000013, -16.32999999999974, -22.239999999999952, 68.78000000000006, -36.069999999999666, -140.71000000000004, -132.6700000000002, -539.86, 10.910000000000036, -321.6099999999999, -212.95, 75.86000000000003, 99.02000000000037, -42.99999999999989, -88.05999999999962, 28.789999999999957, -65.88999999999943, -361.8100000000002, 50.08999999999998, 27.350000000000136, 12.349999999999914, 105.77000000000008, 20.660000000000245, 99.5600000000001, -234.19000000000003, -44.23000000000035, 58.30999999999974, -68.34999999999917, 2.0000000000000013, 51.13999999999993, 90.74000000000011, 2.0000000000000013, -132.6700000000012, 1.9099999999999933, -6.040000000000042, -45.2199999999996, -119.26000000000026, 24.25999999999997, -30.82000000000007, -134.38000000000014, -26.049999999999894, 51.439999999999934, -35.52999999999991, 14.569999999999988, -36.96999999999984, 112.7000000000003, -186.81999999999988, 67.91000000000005, 13.879999999999995, -10.510000000000279, 2.0000000000000013, -373.87000000000006, 136.6400000000001, -111.78999999999938, 2.0000000000000013, -58.30000000000033, -168.70000000000027, -56.800000000000004, -120.58000000000027, -38.20000000000036, -253.19000000000003, 31.160000000000007, -12.070000000000041, 2.0000000000000013, -447.76, 1.3100000000000236, 119.51000000000023, -190.7800000000001, 2.0000000000000013, -32.170000000000364, -24.12999999999974, -78.39999999999918, -100.46999999999979, -24.129999999999708, 123.77000000000031, 2.0000000000000013, -164.83000000000055, 2.0000000000000013, -46.329999999999906, 66.35000000000052, -52.27000000000032, -377.64999999999986, 125.7500000000002, 2.0000000000000013, -130.65999999999985, 15.859999999999998, 88.25000000000003, 155.4499999999999, 87.65000000000016, -272.8600000000001, -69.66999999999983, -48.25000000000035, -185.06000000000057, 93.07999999999996, 142.43, 106.55000000000007, -61.660000000000025, 62.38999999999997, -31.599999999999838, -63.69999999999992, -6.040000000000042, 137.63000000000008, 26.14999999999985, -190.24000000000063, 92.80999999999989, 2.929999999999962, -14.530000000000253, 110.9000000000001, -2.020000000000042, 87.62000000000016, 2.0000000000000013, 28.52000000000005, -12.07000000000004, 114.86000000000041, 56.329999999999906, 94.07000000000019, 48.70999999999994, 105.76999999999997, 42.61999999999995, 51.10999999999983, -132.5500000000004, 68.03000000000017, -220.68000000000023, 100.51999999999998, -44.94999999999977, 79.13000000000008, 62.029999999999895, -201.24999999999994, -38.650000000000006, -23.199999999999875, -124.62999999999931, 2.3300000000000285, 3.9499999999998794, 84.95000000000027, 17.42000000000003, -134.67999999999938, 68.69000000000001, -18.099999999999703, 93.74000000000002, -49.32999999999981, 48.50000000000002, 1.7300000000000804, 60.34999999999995, -5.259999999999753, 101.57000000000023, 88.12999999999998, -13.839999999999545, -75.48999999999998, 91.91000000000004, 94.64000000000003, 115.6700000000001, 50.570000000000014, 40.340000000000174, -45.400000000000006, 61.009999999999984, 51.289999999999786, 90.68000000000009, 5.600000000000162, 112.79000000000013, -94.47999999999934, 108.71000000000015, 165.34999999999977, -42.36999999999995], "policy_predator_policy_reward": [13.0, 1.0, 13.0, 11.0, 40.0, 231.0, 70.0, 131.0, 60.0, 57.0, 79.0, 63.0, 110.0, 249.0, 15.0, 75.0, 24.0, 34.0, 89.0, 118.0, 172.0, 12.0, 97.0, 23.0, 30.0, 6.0, 16.0, 87.0, 80.0, 83.0, 45.0, 155.0, 4.0, 3.0, 0.0, 15.0, 51.0, 80.0, 49.0, 30.0, 51.0, 3.0, 34.0, 81.0, 277.0, 217.0, 172.0, 148.0, 7.0, 13.0, 64.0, 36.0, 0.0, 63.0, 181.0, 14.0, 19.0, 14.0, 5.0, 6.0, 97.0, 121.0, 24.0, 11.0, 35.0, 21.0, 16.0, 8.0, 64.0, 55.0, 3.0, 4.0, 82.0, 11.0, 17.0, 38.0, 56.0, 87.0, 60.0, 5.0, 28.0, 35.0, 102.0, 84.0, 14.0, 33.0, 21.0, 15.0, 167.0, 175.0, 46.0, 48.0, 113.0, 30.0, 29.0, 110.0, 20.0, 137.0, 7.0, 18.0, 0.0, 284.0, 41.0, 40.0, 122.0, 15.0, 2.0, 28.0, 9.0, 96.0, 13.0, 6.0, 68.0, 51.0, 60.0, 11.0, 15.0, 16.0, 190.0, 182.0, 56.0, 55.0, 29.0, 23.0, 0.0, 16.0, 160.0, 3.0, 102.0, 93.0, 5.0, 4.0, 75.0, 71.0, 83.0, 14.0, 65.0, 37.0, 11.0, 19.0, 20.0, 94.0, 2.0, 23.0, 0.0, 2.0, 17.0, 4.0, 8.0, 40.0, 4.0, 3.0, 26.0, 5.0, 9.0, 27.0, 86.0, 92.0, 82.0, 134.0, 38.0, 51.0, 7.0, 8.0, 105.0, 82.0, 63.0, 69.0, 37.0, 44.0, 17.0, 54.0, 51.0, 50.0, 20.0, 11.0, 60.0, 62.0, 3.0, 44.0, 15.0, 14.0, 33.0, 15.0, 58.0, 23.0, 6.0, 14.0, 26.0, 19.0, 2.0, 40.0, 14.0, 7.0, 12.0, 3.0, 38.0, 37.0, 60.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7110355484457094, "mean_inference_ms": 1.943211500225003, "mean_action_processing_ms": 0.3026238315717732, "mean_env_wait_ms": 0.24844784530131336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003906726837158203, "StateBufferConnector_ms": 0.00484776496887207, "ViewRequirementAgentConnector_ms": 0.10979831218719482}, "num_episodes": 18, "episode_return_max": 259.0999999999995, "episode_return_min": -214.55999999999995, "episode_return_mean": 41.75960000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.41048844820523, "num_env_steps_trained_throughput_per_sec": 360.41048844820523, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 11618.799, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11618.732, "sample_time_ms": 1402.965, "learn_time_ms": 10195.036, "learn_throughput": 392.348, "synch_weights_time_ms": 15.89}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "310e1_00000", "date": "2024-08-15_01-00-45", "timestamp": 1723663845, "time_this_iter_s": 11.151897668838501, "time_total_s": 201.69220304489136, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1265e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 201.69220304489136, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 58.1375, "ram_util_percent": 83.53125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4389232262417122, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0937692802419106, "policy_loss": -0.007851454372291093, "vf_loss": 3.100079126143582, "vf_explained_var": 0.027278790303639004, "kl": 0.007708003038664802, "entropy": 1.4541457635385018, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9573111110894137, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.373459151686815, "policy_loss": -0.010359782162344172, "vf_loss": 8.38236531227354, "vf_explained_var": 0.09444309428886132, "kl": 0.014536345844547853, "entropy": 1.474209696401364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 284.7999999999997, "episode_reward_min": -214.55999999999995, "episode_reward_mean": 81.08210000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -539.86, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.34999999999977, "predator_policy": 284.0}, "policy_reward_mean": {"prey_policy": -4.073949999999965, "predator_policy": 44.615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.949999999999946, -214.55999999999995, 194.8799999999993, -31.059999999999462, 25.900000000000063, -116.71999999999952, 72.69999999999973, 137.43000000000046, 83.37000000000006, 49.07999999999947, -10.350000000000078, 165.8799999999997, -11.670000000000067, 2.8699999999999664, -71.48000000000124, 48.44000000000006, -17.430000000000025, 80.91000000000031, 40.59999999999992, 111.88000000000011, 128.79000000000016, 27.489999999999974, 104.77000000000014, -15.789999999999786, -83.99999999999903, -38.37999999999973, -134.38999999999953, 44.09000000000004, -161.76, 201.8199999999996, -51.77999999999996, -26.29999999999944, -73.86999999999935, 118.6400000000008, -43.830000000000084, 26.670000000000215, 45.07999999999959, 120.10000000000024, -17.659999999999823, 156.11000000000016, 259.0999999999995, -179.5300000000003, -38.310000000000386, 244.5099999999997, 190.88999999999967, 127.79000000000008, 32.26000000000018, 193.78000000000014, 16.569999999999816, 13.400000000000432, 110.88000000000044, 110.62000000000064, 64.44999999999992, 178.18999999999983, 173.77999999999952, 184.38999999999973, 96.5600000000002, 63.349999999999916, 144.57000000000008, 156.15999999999963, -52.89999999999954, -15.829999999999602, 87.28000000000021, 173.3699999999998, 35.01000000000004, 106.64000000000021, 121.17000000000006, 109.08000000000025, 125.31000000000058, 122.29000000000009, 97.42000000000019, 230.3099999999998, 135.91000000000014, 57.60999999999992, 162.96999999999946, 133.39000000000027, 89.23000000000033, 190.97999999999962, 189.97999999999945, 17.200000000000056, 109.72999999999998, 240.2699999999997, 55.3600000000001, 82.93000000000004, 49.72999999999995, 147.02000000000032, 284.7999999999997, 163.90999999999997, 108.48000000000016, 265.0999999999992, 243.36999999999955, 127.93000000000004, 61.45999999999995, 88.44000000000011, 217.23999999999984, 178.48999999999984, 110.34000000000016, 190.60000000000005, 55.82000000000017, 235.83999999999958], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-539.86, 10.910000000000036, -321.6099999999999, -212.95, 75.86000000000003, 99.02000000000037, -42.99999999999989, -88.05999999999962, 28.789999999999957, -65.88999999999943, -361.8100000000002, 50.08999999999998, 27.350000000000136, 12.349999999999914, 105.77000000000008, 20.660000000000245, 99.5600000000001, -234.19000000000003, -44.23000000000035, 58.30999999999974, -68.34999999999917, 2.0000000000000013, 51.13999999999993, 90.74000000000011, 2.0000000000000013, -132.6700000000012, 1.9099999999999933, -6.040000000000042, -45.2199999999996, -119.26000000000026, 24.25999999999997, -30.82000000000007, -134.38000000000014, -26.049999999999894, 51.439999999999934, -35.52999999999991, 14.569999999999988, -36.96999999999984, 112.7000000000003, -186.81999999999988, 67.91000000000005, 13.879999999999995, -10.510000000000279, 2.0000000000000013, -373.87000000000006, 136.6400000000001, -111.78999999999938, 2.0000000000000013, -58.30000000000033, -168.70000000000027, -56.800000000000004, -120.58000000000027, -38.20000000000036, -253.19000000000003, 31.160000000000007, -12.070000000000041, 2.0000000000000013, -447.76, 1.3100000000000236, 119.51000000000023, -190.7800000000001, 2.0000000000000013, -32.170000000000364, -24.12999999999974, -78.39999999999918, -100.46999999999979, -24.129999999999708, 123.77000000000031, 2.0000000000000013, -164.83000000000055, 2.0000000000000013, -46.329999999999906, 66.35000000000052, -52.27000000000032, -377.64999999999986, 125.7500000000002, 2.0000000000000013, -130.65999999999985, 15.859999999999998, 88.25000000000003, 155.4499999999999, 87.65000000000016, -272.8600000000001, -69.66999999999983, -48.25000000000035, -185.06000000000057, 93.07999999999996, 142.43, 106.55000000000007, -61.660000000000025, 62.38999999999997, -31.599999999999838, -63.69999999999992, -6.040000000000042, 137.63000000000008, 26.14999999999985, -190.24000000000063, 92.80999999999989, 2.929999999999962, -14.530000000000253, 110.9000000000001, -2.020000000000042, 87.62000000000016, 2.0000000000000013, 28.52000000000005, -12.07000000000004, 114.86000000000041, 56.329999999999906, 94.07000000000019, 48.70999999999994, 105.76999999999997, 42.61999999999995, 51.10999999999983, -132.5500000000004, 68.03000000000017, -220.68000000000023, 100.51999999999998, -44.94999999999977, 79.13000000000008, 62.029999999999895, -201.24999999999994, -38.650000000000006, -23.199999999999875, -124.62999999999931, 2.3300000000000285, 3.9499999999998794, 84.95000000000027, 17.42000000000003, -134.67999999999938, 68.69000000000001, -18.099999999999703, 93.74000000000002, -49.32999999999981, 48.50000000000002, 1.7300000000000804, 60.34999999999995, -5.259999999999753, 101.57000000000023, 88.12999999999998, -13.839999999999545, -75.48999999999998, 91.91000000000004, 94.64000000000003, 115.6700000000001, 50.570000000000014, 40.340000000000174, -45.400000000000006, 61.009999999999984, 51.289999999999786, 90.68000000000009, 5.600000000000162, 112.79000000000013, -94.47999999999934, 108.71000000000015, 165.34999999999977, -42.36999999999995, 129.71000000000015, 50.26999999999976, -138.25, -9.549999999999995, -119.6800000000001, 60.40999999999996, 97.40000000000009, 113.87000000000008, 6.230000000000022, -64.86999999999998, -5.259999999999959, -40.80999999999995, 40.45999999999998, -30.73000000000004, 154.2200000000001, -38.20000000000036, 142.43, 121.37000000000006, 72.58999999999999, 0.3200000000000305, 154.3400000000001, -167.86, 147.29000000000008, 104.81000000000027, 94.70000000000026, 127.66999999999999, 69.41000000000004, 16.52000000000023, 3.3800000000000523, -50.9199999999998, 2.0000000000000013, 36.439999999999934, 81.59, 105.65000000000005, 28.789999999999853, 100.70000000000009, 52.34000000000003, 2.0000000000000013, 123.14, 34.45999999999998, 30.919999999999856, -57.09999999999955, 68.41999999999992, 101.42000000000012], "policy_predator_policy_reward": [277.0, 217.0, 172.0, 148.0, 7.0, 13.0, 64.0, 36.0, 0.0, 63.0, 181.0, 14.0, 19.0, 14.0, 5.0, 6.0, 97.0, 121.0, 24.0, 11.0, 35.0, 21.0, 16.0, 8.0, 64.0, 55.0, 3.0, 4.0, 82.0, 11.0, 17.0, 38.0, 56.0, 87.0, 60.0, 5.0, 28.0, 35.0, 102.0, 84.0, 14.0, 33.0, 21.0, 15.0, 167.0, 175.0, 46.0, 48.0, 113.0, 30.0, 29.0, 110.0, 20.0, 137.0, 7.0, 18.0, 0.0, 284.0, 41.0, 40.0, 122.0, 15.0, 2.0, 28.0, 9.0, 96.0, 13.0, 6.0, 68.0, 51.0, 60.0, 11.0, 15.0, 16.0, 190.0, 182.0, 56.0, 55.0, 29.0, 23.0, 0.0, 16.0, 160.0, 3.0, 102.0, 93.0, 5.0, 4.0, 75.0, 71.0, 83.0, 14.0, 65.0, 37.0, 11.0, 19.0, 20.0, 94.0, 2.0, 23.0, 0.0, 2.0, 17.0, 4.0, 8.0, 40.0, 4.0, 3.0, 26.0, 5.0, 9.0, 27.0, 86.0, 92.0, 82.0, 134.0, 38.0, 51.0, 7.0, 8.0, 105.0, 82.0, 63.0, 69.0, 37.0, 44.0, 17.0, 54.0, 51.0, 50.0, 20.0, 11.0, 60.0, 62.0, 3.0, 44.0, 15.0, 14.0, 33.0, 15.0, 58.0, 23.0, 6.0, 14.0, 26.0, 19.0, 2.0, 40.0, 14.0, 7.0, 12.0, 3.0, 38.0, 37.0, 60.0, 8.0, 2.0, 8.0, 82.0, 83.0, 97.0, 72.0, 8.0, 21.0, 102.0, 12.0, 73.0, 56.0, 4.0, 36.0, 11.0, 20.0, 6.0, 15.0, 48.0, 43.0, 118.0, 4.0, 10.0, 3.0, 12.0, 9.0, 37.0, 5.0, 59.0, 50.0, 11.0, 39.0, 6.0, 24.0, 31.0, 18.0, 36.0, 20.0, 21.0, 12.0, 56.0, 26.0, 21.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7077605372772752, "mean_inference_ms": 1.9298367324557302, "mean_action_processing_ms": 0.3010407364886245, "mean_env_wait_ms": 0.24758790182357182, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037550926208496094, "StateBufferConnector_ms": 0.00479280948638916, "ViewRequirementAgentConnector_ms": 0.10625660419464111}, "num_episodes": 22, "episode_return_max": 284.7999999999997, "episode_return_min": -214.55999999999995, "episode_return_mean": 81.08210000000003, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.50524595531374, "num_env_steps_trained_throughput_per_sec": 364.50524595531374, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 11501.682, "restore_workers_time_ms": 0.023, "training_step_time_ms": 11501.578, "sample_time_ms": 1404.258, "learn_time_ms": 10075.281, "learn_throughput": 397.011, "synch_weights_time_ms": 17.536}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "310e1_00000", "date": "2024-08-15_01-00-56", "timestamp": 1723663856, "time_this_iter_s": 11.043669939041138, "time_total_s": 212.7358729839325, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c6790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 212.7358729839325, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 54.68125, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5329291555301223, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6534250487095465, "policy_loss": -0.010348541043679077, "vf_loss": 2.66170421662154, "vf_explained_var": 0.022323305045486127, "kl": 0.010346865094542477, "entropy": 1.3620850685412291, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9799753957639927, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.166544864291236, "policy_loss": -0.0031162231692443134, "vf_loss": 9.168485835241894, "vf_explained_var": 0.29015291626491246, "kl": 0.011752495819540637, "entropy": 1.451633847832049, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 376.2199999999998, "episode_reward_min": -179.5300000000003, "episode_reward_mean": 122.56599999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -447.76, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.09999999999994, "predator_policy": 284.0}, "policy_reward_mean": {"prey_policy": 23.168000000000028, "predator_policy": 38.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.789999999999786, -83.99999999999903, -38.37999999999973, -134.38999999999953, 44.09000000000004, -161.76, 201.8199999999996, -51.77999999999996, -26.29999999999944, -73.86999999999935, 118.6400000000008, -43.830000000000084, 26.670000000000215, 45.07999999999959, 120.10000000000024, -17.659999999999823, 156.11000000000016, 259.0999999999995, -179.5300000000003, -38.310000000000386, 244.5099999999997, 190.88999999999967, 127.79000000000008, 32.26000000000018, 193.78000000000014, 16.569999999999816, 13.400000000000432, 110.88000000000044, 110.62000000000064, 64.44999999999992, 178.18999999999983, 173.77999999999952, 184.38999999999973, 96.5600000000002, 63.349999999999916, 144.57000000000008, 156.15999999999963, -52.89999999999954, -15.829999999999602, 87.28000000000021, 173.3699999999998, 35.01000000000004, 106.64000000000021, 121.17000000000006, 109.08000000000025, 125.31000000000058, 122.29000000000009, 97.42000000000019, 230.3099999999998, 135.91000000000014, 57.60999999999992, 162.96999999999946, 133.39000000000027, 89.23000000000033, 190.97999999999962, 189.97999999999945, 17.200000000000056, 109.72999999999998, 240.2699999999997, 55.3600000000001, 82.93000000000004, 49.72999999999995, 147.02000000000032, 284.7999999999997, 163.90999999999997, 108.48000000000016, 265.0999999999992, 243.36999999999955, 127.93000000000004, 61.45999999999995, 88.44000000000011, 217.23999999999984, 178.48999999999984, 110.34000000000016, 190.60000000000005, 55.82000000000017, 235.83999999999958, 60.44999999999994, 181.70000000000005, 169.30000000000007, 98.79000000000025, 318.43, 254.21999999999994, 311.27999999999986, 275.6899999999997, 168.52999999999977, 277.63, 216.35000000000002, 216.1599999999998, 314.4199999999999, 291.47, 2.8099999999999197, 118.45000000000032, 376.2199999999998, 256.48, 245.8199999999996, 55.98000000000009, 167.1099999999997, 222.31000000000006, 315.5599999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-111.78999999999938, 2.0000000000000013, -58.30000000000033, -168.70000000000027, -56.800000000000004, -120.58000000000027, -38.20000000000036, -253.19000000000003, 31.160000000000007, -12.070000000000041, 2.0000000000000013, -447.76, 1.3100000000000236, 119.51000000000023, -190.7800000000001, 2.0000000000000013, -32.170000000000364, -24.12999999999974, -78.39999999999918, -100.46999999999979, -24.129999999999708, 123.77000000000031, 2.0000000000000013, -164.83000000000055, 2.0000000000000013, -46.329999999999906, 66.35000000000052, -52.27000000000032, -377.64999999999986, 125.7500000000002, 2.0000000000000013, -130.65999999999985, 15.859999999999998, 88.25000000000003, 155.4499999999999, 87.65000000000016, -272.8600000000001, -69.66999999999983, -48.25000000000035, -185.06000000000057, 93.07999999999996, 142.43, 106.55000000000007, -61.660000000000025, 62.38999999999997, -31.599999999999838, -63.69999999999992, -6.040000000000042, 137.63000000000008, 26.14999999999985, -190.24000000000063, 92.80999999999989, 2.929999999999962, -14.530000000000253, 110.9000000000001, -2.020000000000042, 87.62000000000016, 2.0000000000000013, 28.52000000000005, -12.07000000000004, 114.86000000000041, 56.329999999999906, 94.07000000000019, 48.70999999999994, 105.76999999999997, 42.61999999999995, 51.10999999999983, -132.5500000000004, 68.03000000000017, -220.68000000000023, 100.51999999999998, -44.94999999999977, 79.13000000000008, 62.029999999999895, -201.24999999999994, -38.650000000000006, -23.199999999999875, -124.62999999999931, 2.3300000000000285, 3.9499999999998794, 84.95000000000027, 17.42000000000003, -134.67999999999938, 68.69000000000001, -18.099999999999703, 93.74000000000002, -49.32999999999981, 48.50000000000002, 1.7300000000000804, 60.34999999999995, -5.259999999999753, 101.57000000000023, 88.12999999999998, -13.839999999999545, -75.48999999999998, 91.91000000000004, 94.64000000000003, 115.6700000000001, 50.570000000000014, 40.340000000000174, -45.400000000000006, 61.009999999999984, 51.289999999999786, 90.68000000000009, 5.600000000000162, 112.79000000000013, -94.47999999999934, 108.71000000000015, 165.34999999999977, -42.36999999999995, 129.71000000000015, 50.26999999999976, -138.25, -9.549999999999995, -119.6800000000001, 60.40999999999996, 97.40000000000009, 113.87000000000008, 6.230000000000022, -64.86999999999998, -5.259999999999959, -40.80999999999995, 40.45999999999998, -30.73000000000004, 154.2200000000001, -38.20000000000036, 142.43, 121.37000000000006, 72.58999999999999, 0.3200000000000305, 154.3400000000001, -167.86, 147.29000000000008, 104.81000000000027, 94.70000000000026, 127.66999999999999, 69.41000000000004, 16.52000000000023, 3.3800000000000523, -50.9199999999998, 2.0000000000000013, 36.439999999999934, 81.59, 105.65000000000005, 28.789999999999853, 100.70000000000009, 52.34000000000003, 2.0000000000000013, 123.14, 34.45999999999998, 30.919999999999856, -57.09999999999955, 68.41999999999992, 101.42000000000012, 22.100000000000005, -59.64999999999999, 102.38000000000002, -11.679999999999978, 85.07, 6.230000000000004, -20.0799999999998, 56.86999999999989, 106.00999999999999, 158.42000000000002, 122.06000000000002, 70.16, 74.18000000000004, 190.09999999999994, 103.55000000000017, 144.14000000000007, -90.85000000000005, 84.38000000000011, 55.460000000000235, 183.16999999999996, 101.30000000000001, 42.04999999999998, -38.52999999999979, 131.69000000000005, 186.05, 106.37000000000008, 110.21000000000002, 150.26, -18.099999999999703, 10.910000000000002, -182.92000000000098, 163.37, 187.10000000000002, 188.12000000000006, 146.32999999999998, 71.14999999999999, 122.4800000000001, 88.34000000000007, -46.26999999999981, -64.74999999999999, -22.119999999999706, 177.2299999999999, 136.10000000000002, 62.20999999999998, 153.08000000000004, 146.48000000000002], "policy_predator_policy_reward": [46.0, 48.0, 113.0, 30.0, 29.0, 110.0, 20.0, 137.0, 7.0, 18.0, 0.0, 284.0, 41.0, 40.0, 122.0, 15.0, 2.0, 28.0, 9.0, 96.0, 13.0, 6.0, 68.0, 51.0, 60.0, 11.0, 15.0, 16.0, 190.0, 182.0, 56.0, 55.0, 29.0, 23.0, 0.0, 16.0, 160.0, 3.0, 102.0, 93.0, 5.0, 4.0, 75.0, 71.0, 83.0, 14.0, 65.0, 37.0, 11.0, 19.0, 20.0, 94.0, 2.0, 23.0, 0.0, 2.0, 17.0, 4.0, 8.0, 40.0, 4.0, 3.0, 26.0, 5.0, 9.0, 27.0, 86.0, 92.0, 82.0, 134.0, 38.0, 51.0, 7.0, 8.0, 105.0, 82.0, 63.0, 69.0, 37.0, 44.0, 17.0, 54.0, 51.0, 50.0, 20.0, 11.0, 60.0, 62.0, 3.0, 44.0, 15.0, 14.0, 33.0, 15.0, 58.0, 23.0, 6.0, 14.0, 26.0, 19.0, 2.0, 40.0, 14.0, 7.0, 12.0, 3.0, 38.0, 37.0, 60.0, 8.0, 2.0, 8.0, 82.0, 83.0, 97.0, 72.0, 8.0, 21.0, 102.0, 12.0, 73.0, 56.0, 4.0, 36.0, 11.0, 20.0, 6.0, 15.0, 48.0, 43.0, 118.0, 4.0, 10.0, 3.0, 12.0, 9.0, 37.0, 5.0, 59.0, 50.0, 11.0, 39.0, 6.0, 24.0, 31.0, 18.0, 36.0, 20.0, 21.0, 12.0, 56.0, 26.0, 21.0, 45.0, 98.0, 0.0, 28.0, 63.0, 40.0, 38.0, 13.0, 49.0, 30.0, 24.0, 5.0, 57.0, 11.0, 36.0, 4.0, 24.0, 95.0, 80.0, 9.0, 30.0, 61.0, 12.0, 64.0, 59.0, 19.0, 3.0, 23.0, 8.0, 10.0, 0.0, 46.0, 92.0, 0.0, 1.0, 25.0, 14.0, 34.0, 1.0, 94.0, 73.0, 0.0, 12.0, 14.0, 10.0, 4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7072057369964148, "mean_inference_ms": 1.9265286070862992, "mean_action_processing_ms": 0.29949855943790615, "mean_env_wait_ms": 0.2466713089442675, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004429221153259277, "StateBufferConnector_ms": 0.004965543746948242, "ViewRequirementAgentConnector_ms": 0.13277959823608398}, "num_episodes": 23, "episode_return_max": 376.2199999999998, "episode_return_min": -179.5300000000003, "episode_return_mean": 122.56599999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.8706792004108, "num_env_steps_trained_throughput_per_sec": 347.8706792004108, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 11516.812, "restore_workers_time_ms": 0.023, "training_step_time_ms": 11516.71, "sample_time_ms": 1464.266, "learn_time_ms": 10029.838, "learn_throughput": 398.81, "synch_weights_time_ms": 18.75}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "310e1_00000", "date": "2024-08-15_01-01-08", "timestamp": 1723663868, "time_this_iter_s": 11.54734206199646, "time_total_s": 224.28321504592896, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1482040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 224.28321504592896, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 51.1875, "ram_util_percent": 82.76875000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5606613107459255, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.394221427453258, "policy_loss": -0.005642266384271718, "vf_loss": 2.3988219484450326, "vf_explained_var": 0.019611408660020778, "kl": 0.005208745130052173, "entropy": 1.3715971644593294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.168787444158206, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.624138700394404, "policy_loss": -0.002749227968207191, "vf_loss": 8.625970966601498, "vf_explained_var": 0.4103257278601328, "kl": 0.009169762489099433, "entropy": 1.4432851248317295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 376.2199999999998, "episode_reward_min": -179.5300000000003, "episode_reward_mean": 159.20059999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -272.8600000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.04999999999998, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": 46.865300000000026, "predator_policy": 32.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-179.5300000000003, -38.310000000000386, 244.5099999999997, 190.88999999999967, 127.79000000000008, 32.26000000000018, 193.78000000000014, 16.569999999999816, 13.400000000000432, 110.88000000000044, 110.62000000000064, 64.44999999999992, 178.18999999999983, 173.77999999999952, 184.38999999999973, 96.5600000000002, 63.349999999999916, 144.57000000000008, 156.15999999999963, -52.89999999999954, -15.829999999999602, 87.28000000000021, 173.3699999999998, 35.01000000000004, 106.64000000000021, 121.17000000000006, 109.08000000000025, 125.31000000000058, 122.29000000000009, 97.42000000000019, 230.3099999999998, 135.91000000000014, 57.60999999999992, 162.96999999999946, 133.39000000000027, 89.23000000000033, 190.97999999999962, 189.97999999999945, 17.200000000000056, 109.72999999999998, 240.2699999999997, 55.3600000000001, 82.93000000000004, 49.72999999999995, 147.02000000000032, 284.7999999999997, 163.90999999999997, 108.48000000000016, 265.0999999999992, 243.36999999999955, 127.93000000000004, 61.45999999999995, 88.44000000000011, 217.23999999999984, 178.48999999999984, 110.34000000000016, 190.60000000000005, 55.82000000000017, 235.83999999999958, 60.44999999999994, 181.70000000000005, 169.30000000000007, 98.79000000000025, 318.43, 254.21999999999994, 311.27999999999986, 275.6899999999997, 168.52999999999977, 277.63, 216.35000000000002, 216.1599999999998, 314.4199999999999, 291.47, 2.8099999999999197, 118.45000000000032, 376.2199999999998, 256.48, 245.8199999999996, 55.98000000000009, 167.1099999999997, 222.31000000000006, 315.5599999999997, 229.49999999999994, 259.7699999999999, 167.13, 54.9999999999999, 139.49000000000004, 255.24999999999997, 163.10000000000002, 132.53000000000011, 116.52000000000044, 312.3199999999997, 356.2899999999999, 309.4299999999997, 296.06999999999994, 192.5299999999999, 305.55999999999995, 147.08000000000004, 265.2099999999999, 284.52999999999975], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-272.8600000000001, -69.66999999999983, -48.25000000000035, -185.06000000000057, 93.07999999999996, 142.43, 106.55000000000007, -61.660000000000025, 62.38999999999997, -31.599999999999838, -63.69999999999992, -6.040000000000042, 137.63000000000008, 26.14999999999985, -190.24000000000063, 92.80999999999989, 2.929999999999962, -14.530000000000253, 110.9000000000001, -2.020000000000042, 87.62000000000016, 2.0000000000000013, 28.52000000000005, -12.07000000000004, 114.86000000000041, 56.329999999999906, 94.07000000000019, 48.70999999999994, 105.76999999999997, 42.61999999999995, 51.10999999999983, -132.5500000000004, 68.03000000000017, -220.68000000000023, 100.51999999999998, -44.94999999999977, 79.13000000000008, 62.029999999999895, -201.24999999999994, -38.650000000000006, -23.199999999999875, -124.62999999999931, 2.3300000000000285, 3.9499999999998794, 84.95000000000027, 17.42000000000003, -134.67999999999938, 68.69000000000001, -18.099999999999703, 93.74000000000002, -49.32999999999981, 48.50000000000002, 1.7300000000000804, 60.34999999999995, -5.259999999999753, 101.57000000000023, 88.12999999999998, -13.839999999999545, -75.48999999999998, 91.91000000000004, 94.64000000000003, 115.6700000000001, 50.570000000000014, 40.340000000000174, -45.400000000000006, 61.009999999999984, 51.289999999999786, 90.68000000000009, 5.600000000000162, 112.79000000000013, -94.47999999999934, 108.71000000000015, 165.34999999999977, -42.36999999999995, 129.71000000000015, 50.26999999999976, -138.25, -9.549999999999995, -119.6800000000001, 60.40999999999996, 97.40000000000009, 113.87000000000008, 6.230000000000022, -64.86999999999998, -5.259999999999959, -40.80999999999995, 40.45999999999998, -30.73000000000004, 154.2200000000001, -38.20000000000036, 142.43, 121.37000000000006, 72.58999999999999, 0.3200000000000305, 154.3400000000001, -167.86, 147.29000000000008, 104.81000000000027, 94.70000000000026, 127.66999999999999, 69.41000000000004, 16.52000000000023, 3.3800000000000523, -50.9199999999998, 2.0000000000000013, 36.439999999999934, 81.59, 105.65000000000005, 28.789999999999853, 100.70000000000009, 52.34000000000003, 2.0000000000000013, 123.14, 34.45999999999998, 30.919999999999856, -57.09999999999955, 68.41999999999992, 101.42000000000012, 22.100000000000005, -59.64999999999999, 102.38000000000002, -11.679999999999978, 85.07, 6.230000000000004, -20.0799999999998, 56.86999999999989, 106.00999999999999, 158.42000000000002, 122.06000000000002, 70.16, 74.18000000000004, 190.09999999999994, 103.55000000000017, 144.14000000000007, -90.85000000000005, 84.38000000000011, 55.460000000000235, 183.16999999999996, 101.30000000000001, 42.04999999999998, -38.52999999999979, 131.69000000000005, 186.05, 106.37000000000008, 110.21000000000002, 150.26, -18.099999999999703, 10.910000000000002, -182.92000000000098, 163.37, 187.10000000000002, 188.12000000000006, 146.32999999999998, 71.14999999999999, 122.4800000000001, 88.34000000000007, -46.26999999999981, -64.74999999999999, -22.119999999999706, 177.2299999999999, 136.10000000000002, 62.20999999999998, 153.08000000000004, 146.48000000000002, 155.12, -47.62000000000009, 184.12999999999997, 40.639999999999894, 154.13, 2.0000000000000013, -12.070000000000041, 43.06999999999998, -12.070000000000041, 144.55999999999995, 68.17999999999996, 127.07000000000004, -18.06999999999981, 117.17000000000006, 106.43000000000005, -67.89999999999982, -22.119999999999706, 121.64000000000003, 181.06999999999996, 97.25000000000011, 161.11999999999995, 183.16999999999996, 186.14000000000001, 72.29000000000002, 131.0, 85.07000000000001, 161.32999999999998, 3.1999999999997826, 92.50999999999999, 192.04999999999998, 49.070000000000014, -37.99000000000001, 139.10000000000002, 69.11000000000003, 71.14999999999998, 156.38000000000002], "policy_predator_policy_reward": [160.0, 3.0, 102.0, 93.0, 5.0, 4.0, 75.0, 71.0, 83.0, 14.0, 65.0, 37.0, 11.0, 19.0, 20.0, 94.0, 2.0, 23.0, 0.0, 2.0, 17.0, 4.0, 8.0, 40.0, 4.0, 3.0, 26.0, 5.0, 9.0, 27.0, 86.0, 92.0, 82.0, 134.0, 38.0, 51.0, 7.0, 8.0, 105.0, 82.0, 63.0, 69.0, 37.0, 44.0, 17.0, 54.0, 51.0, 50.0, 20.0, 11.0, 60.0, 62.0, 3.0, 44.0, 15.0, 14.0, 33.0, 15.0, 58.0, 23.0, 6.0, 14.0, 26.0, 19.0, 2.0, 40.0, 14.0, 7.0, 12.0, 3.0, 38.0, 37.0, 60.0, 8.0, 2.0, 8.0, 82.0, 83.0, 97.0, 72.0, 8.0, 21.0, 102.0, 12.0, 73.0, 56.0, 4.0, 36.0, 11.0, 20.0, 6.0, 15.0, 48.0, 43.0, 118.0, 4.0, 10.0, 3.0, 12.0, 9.0, 37.0, 5.0, 59.0, 50.0, 11.0, 39.0, 6.0, 24.0, 31.0, 18.0, 36.0, 20.0, 21.0, 12.0, 56.0, 26.0, 21.0, 45.0, 98.0, 0.0, 28.0, 63.0, 40.0, 38.0, 13.0, 49.0, 30.0, 24.0, 5.0, 57.0, 11.0, 36.0, 4.0, 24.0, 95.0, 80.0, 9.0, 30.0, 61.0, 12.0, 64.0, 59.0, 19.0, 3.0, 23.0, 8.0, 10.0, 0.0, 46.0, 92.0, 0.0, 1.0, 25.0, 14.0, 34.0, 1.0, 94.0, 73.0, 0.0, 12.0, 14.0, 10.0, 4.0, 12.0, 60.0, 62.0, 10.0, 25.0, 11.0, 0.0, 7.0, 17.0, 5.0, 2.0, 33.0, 27.0, 51.0, 13.0, 43.0, 51.0, 5.0, 12.0, 21.0, 13.0, 9.0, 3.0, 19.0, 32.0, 40.0, 40.0, 2.0, 26.0, 7.0, 14.0, 77.0, 59.0, 17.0, 40.0, 26.0, 31.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7109316500934741, "mean_inference_ms": 1.9312114783161565, "mean_action_processing_ms": 0.30030431161956295, "mean_env_wait_ms": 0.24686574649933296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005818486213684082, "StateBufferConnector_ms": 0.004943490028381348, "ViewRequirementAgentConnector_ms": 0.13454711437225342}, "num_episodes": 18, "episode_return_max": 376.2199999999998, "episode_return_min": -179.5300000000003, "episode_return_mean": 159.20059999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.0760613238059, "num_env_steps_trained_throughput_per_sec": 350.0760613238059, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 11519.693, "restore_workers_time_ms": 0.026, "training_step_time_ms": 11519.587, "sample_time_ms": 1555.67, "learn_time_ms": 9942.788, "learn_throughput": 402.302, "synch_weights_time_ms": 17.37}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "310e1_00000", "date": "2024-08-15_01-01-19", "timestamp": 1723663879, "time_this_iter_s": 11.469754934310913, "time_total_s": 235.75296998023987, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1482dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 235.75296998023987, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 49.07647058823529, "ram_util_percent": 82.68823529411763}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8221004590786323, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3007036729464456, "policy_loss": -0.00851288742863785, "vf_loss": 2.3077556661197116, "vf_explained_var": 0.016928725236307375, "kl": 0.007304477596413451, "entropy": 1.3340959916669857, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0592109452164364, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.888075420843862, "policy_loss": 0.000279993118309273, "vf_loss": 8.88648921421596, "vf_explained_var": 0.43470848546457036, "kl": 0.013062436938399006, "entropy": 1.4343612909317016, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 376.2199999999998, "episode_reward_min": -52.89999999999954, "episode_reward_mean": 183.5558, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -201.24999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.04999999999998, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 61.66790000000004, "predator_policy": 30.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [156.15999999999963, -52.89999999999954, -15.829999999999602, 87.28000000000021, 173.3699999999998, 35.01000000000004, 106.64000000000021, 121.17000000000006, 109.08000000000025, 125.31000000000058, 122.29000000000009, 97.42000000000019, 230.3099999999998, 135.91000000000014, 57.60999999999992, 162.96999999999946, 133.39000000000027, 89.23000000000033, 190.97999999999962, 189.97999999999945, 17.200000000000056, 109.72999999999998, 240.2699999999997, 55.3600000000001, 82.93000000000004, 49.72999999999995, 147.02000000000032, 284.7999999999997, 163.90999999999997, 108.48000000000016, 265.0999999999992, 243.36999999999955, 127.93000000000004, 61.45999999999995, 88.44000000000011, 217.23999999999984, 178.48999999999984, 110.34000000000016, 190.60000000000005, 55.82000000000017, 235.83999999999958, 60.44999999999994, 181.70000000000005, 169.30000000000007, 98.79000000000025, 318.43, 254.21999999999994, 311.27999999999986, 275.6899999999997, 168.52999999999977, 277.63, 216.35000000000002, 216.1599999999998, 314.4199999999999, 291.47, 2.8099999999999197, 118.45000000000032, 376.2199999999998, 256.48, 245.8199999999996, 55.98000000000009, 167.1099999999997, 222.31000000000006, 315.5599999999997, 229.49999999999994, 259.7699999999999, 167.13, 54.9999999999999, 139.49000000000004, 255.24999999999997, 163.10000000000002, 132.53000000000011, 116.52000000000044, 312.3199999999997, 356.2899999999999, 309.4299999999997, 296.06999999999994, 192.5299999999999, 305.55999999999995, 147.08000000000004, 265.2099999999999, 284.52999999999975, 317.09999999999997, 167.45, 334.39999999999986, 329.39, 278.2099999999999, 317.15, 153.09000000000003, 286.40999999999997, 274.93000000000006, 248.2, 151.36000000000007, 302.42999999999984, -43.710000000000264, 220.81999999999994, 150.06000000000012, 250.13999999999993, 182.9699999999998, 243.26999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [79.13000000000008, 62.029999999999895, -201.24999999999994, -38.650000000000006, -23.199999999999875, -124.62999999999931, 2.3300000000000285, 3.9499999999998794, 84.95000000000027, 17.42000000000003, -134.67999999999938, 68.69000000000001, -18.099999999999703, 93.74000000000002, -49.32999999999981, 48.50000000000002, 1.7300000000000804, 60.34999999999995, -5.259999999999753, 101.57000000000023, 88.12999999999998, -13.839999999999545, -75.48999999999998, 91.91000000000004, 94.64000000000003, 115.6700000000001, 50.570000000000014, 40.340000000000174, -45.400000000000006, 61.009999999999984, 51.289999999999786, 90.68000000000009, 5.600000000000162, 112.79000000000013, -94.47999999999934, 108.71000000000015, 165.34999999999977, -42.36999999999995, 129.71000000000015, 50.26999999999976, -138.25, -9.549999999999995, -119.6800000000001, 60.40999999999996, 97.40000000000009, 113.87000000000008, 6.230000000000022, -64.86999999999998, -5.259999999999959, -40.80999999999995, 40.45999999999998, -30.73000000000004, 154.2200000000001, -38.20000000000036, 142.43, 121.37000000000006, 72.58999999999999, 0.3200000000000305, 154.3400000000001, -167.86, 147.29000000000008, 104.81000000000027, 94.70000000000026, 127.66999999999999, 69.41000000000004, 16.52000000000023, 3.3800000000000523, -50.9199999999998, 2.0000000000000013, 36.439999999999934, 81.59, 105.65000000000005, 28.789999999999853, 100.70000000000009, 52.34000000000003, 2.0000000000000013, 123.14, 34.45999999999998, 30.919999999999856, -57.09999999999955, 68.41999999999992, 101.42000000000012, 22.100000000000005, -59.64999999999999, 102.38000000000002, -11.679999999999978, 85.07, 6.230000000000004, -20.0799999999998, 56.86999999999989, 106.00999999999999, 158.42000000000002, 122.06000000000002, 70.16, 74.18000000000004, 190.09999999999994, 103.55000000000017, 144.14000000000007, -90.85000000000005, 84.38000000000011, 55.460000000000235, 183.16999999999996, 101.30000000000001, 42.04999999999998, -38.52999999999979, 131.69000000000005, 186.05, 106.37000000000008, 110.21000000000002, 150.26, -18.099999999999703, 10.910000000000002, -182.92000000000098, 163.37, 187.10000000000002, 188.12000000000006, 146.32999999999998, 71.14999999999999, 122.4800000000001, 88.34000000000007, -46.26999999999981, -64.74999999999999, -22.119999999999706, 177.2299999999999, 136.10000000000002, 62.20999999999998, 153.08000000000004, 146.48000000000002, 155.12, -47.62000000000009, 184.12999999999997, 40.639999999999894, 154.13, 2.0000000000000013, -12.070000000000041, 43.06999999999998, -12.070000000000041, 144.55999999999995, 68.17999999999996, 127.07000000000004, -18.06999999999981, 117.17000000000006, 106.43000000000005, -67.89999999999982, -22.119999999999706, 121.64000000000003, 181.06999999999996, 97.25000000000011, 161.11999999999995, 183.16999999999996, 186.14000000000001, 72.29000000000002, 131.0, 85.07000000000001, 161.32999999999998, 3.1999999999997826, 92.50999999999999, 192.04999999999998, 49.070000000000014, -37.99000000000001, 139.10000000000002, 69.11000000000003, 71.14999999999998, 156.38000000000002, 106.03999999999999, 164.06, -97.81000000000016, 171.2600000000001, 149.3, 172.09999999999997, 148.19, 165.2, 158.18, -18.970000000000027, 130.13, 153.01999999999998, 139.13, -6.040000000000042, 149.21000000000004, 108.20000000000006, 173.0, 74.93000000000015, 108.11000000000001, 77.08999999999997, 101.0, -15.640000000000178, 107.38999999999997, 148.04000000000002, -78.73000000000025, -104.98000000000002, 169.15999999999997, -27.33999999999977, -38.200000000000294, 165.26, 122.06000000000003, 60.07999999999998, 181.04000000000002, -12.07000000000004, 128.21, 50.06], "policy_predator_policy_reward": [7.0, 8.0, 105.0, 82.0, 63.0, 69.0, 37.0, 44.0, 17.0, 54.0, 51.0, 50.0, 20.0, 11.0, 60.0, 62.0, 3.0, 44.0, 15.0, 14.0, 33.0, 15.0, 58.0, 23.0, 6.0, 14.0, 26.0, 19.0, 2.0, 40.0, 14.0, 7.0, 12.0, 3.0, 38.0, 37.0, 60.0, 8.0, 2.0, 8.0, 82.0, 83.0, 97.0, 72.0, 8.0, 21.0, 102.0, 12.0, 73.0, 56.0, 4.0, 36.0, 11.0, 20.0, 6.0, 15.0, 48.0, 43.0, 118.0, 4.0, 10.0, 3.0, 12.0, 9.0, 37.0, 5.0, 59.0, 50.0, 11.0, 39.0, 6.0, 24.0, 31.0, 18.0, 36.0, 20.0, 21.0, 12.0, 56.0, 26.0, 21.0, 45.0, 98.0, 0.0, 28.0, 63.0, 40.0, 38.0, 13.0, 49.0, 30.0, 24.0, 5.0, 57.0, 11.0, 36.0, 4.0, 24.0, 95.0, 80.0, 9.0, 30.0, 61.0, 12.0, 64.0, 59.0, 19.0, 3.0, 23.0, 8.0, 10.0, 0.0, 46.0, 92.0, 0.0, 1.0, 25.0, 14.0, 34.0, 1.0, 94.0, 73.0, 0.0, 12.0, 14.0, 10.0, 4.0, 12.0, 60.0, 62.0, 10.0, 25.0, 11.0, 0.0, 7.0, 17.0, 5.0, 2.0, 33.0, 27.0, 51.0, 13.0, 43.0, 51.0, 5.0, 12.0, 21.0, 13.0, 9.0, 3.0, 19.0, 32.0, 40.0, 40.0, 2.0, 26.0, 7.0, 14.0, 77.0, 59.0, 17.0, 40.0, 26.0, 31.0, 30.0, 17.0, 93.0, 1.0, 6.0, 7.0, 5.0, 11.0, 69.0, 70.0, 26.0, 8.0, 18.0, 2.0, 17.0, 12.0, 16.0, 11.0, 33.0, 30.0, 34.0, 32.0, 33.0, 14.0, 29.0, 111.0, 44.0, 35.0, 3.0, 20.0, 45.0, 23.0, 3.0, 11.0, 31.0, 34.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7155664611288662, "mean_inference_ms": 1.9365628906224162, "mean_action_processing_ms": 0.3013203920059386, "mean_env_wait_ms": 0.24717419390081774, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005626678466796875, "StateBufferConnector_ms": 0.0033855438232421875, "ViewRequirementAgentConnector_ms": 0.12988269329071045}, "num_episodes": 18, "episode_return_max": 376.2199999999998, "episode_return_min": -52.89999999999954, "episode_return_mean": 183.5558, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.5198392829252, "num_env_steps_trained_throughput_per_sec": 339.5198392829252, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 11529.404, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11529.301, "sample_time_ms": 1567.969, "learn_time_ms": 9940.71, "learn_throughput": 402.386, "synch_weights_time_ms": 17.399}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "310e1_00000", "date": "2024-08-15_01-01-31", "timestamp": 1723663891, "time_this_iter_s": 11.812623023986816, "time_total_s": 247.56559300422668, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14733a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 247.56559300422668, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 52.699999999999996, "ram_util_percent": 83.08823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.219512000884959, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5111332343368935, "policy_loss": -0.011433028008434034, "vf_loss": 3.520235629813381, "vf_explained_var": 0.10456336228935807, "kl": 0.011653176919432472, "entropy": 1.3372269159902341, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4874655171992286, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.892554192820555, "policy_loss": 5.8161303469980205e-05, "vf_loss": 8.890926781154814, "vf_explained_var": 0.3199034608861126, "kl": 0.015692722833932464, "entropy": 1.4306889701141883, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 376.2199999999998, "episode_reward_min": -43.710000000000264, "episode_reward_mean": 208.27559999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -182.92000000000098, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.04999999999998, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 75.01280000000001, "predator_policy": 29.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [190.97999999999962, 189.97999999999945, 17.200000000000056, 109.72999999999998, 240.2699999999997, 55.3600000000001, 82.93000000000004, 49.72999999999995, 147.02000000000032, 284.7999999999997, 163.90999999999997, 108.48000000000016, 265.0999999999992, 243.36999999999955, 127.93000000000004, 61.45999999999995, 88.44000000000011, 217.23999999999984, 178.48999999999984, 110.34000000000016, 190.60000000000005, 55.82000000000017, 235.83999999999958, 60.44999999999994, 181.70000000000005, 169.30000000000007, 98.79000000000025, 318.43, 254.21999999999994, 311.27999999999986, 275.6899999999997, 168.52999999999977, 277.63, 216.35000000000002, 216.1599999999998, 314.4199999999999, 291.47, 2.8099999999999197, 118.45000000000032, 376.2199999999998, 256.48, 245.8199999999996, 55.98000000000009, 167.1099999999997, 222.31000000000006, 315.5599999999997, 229.49999999999994, 259.7699999999999, 167.13, 54.9999999999999, 139.49000000000004, 255.24999999999997, 163.10000000000002, 132.53000000000011, 116.52000000000044, 312.3199999999997, 356.2899999999999, 309.4299999999997, 296.06999999999994, 192.5299999999999, 305.55999999999995, 147.08000000000004, 265.2099999999999, 284.52999999999975, 317.09999999999997, 167.45, 334.39999999999986, 329.39, 278.2099999999999, 317.15, 153.09000000000003, 286.40999999999997, 274.93000000000006, 248.2, 151.36000000000007, 302.42999999999984, -43.710000000000264, 220.81999999999994, 150.06000000000012, 250.13999999999993, 182.9699999999998, 243.26999999999998, 336.22999999999996, 147.61000000000024, 99.81000000000009, 232.17999999999995, 285.2999999999999, 346.4599999999999, 286.16999999999996, 311.54999999999995, 139.92000000000036, 276.82, 219.21999999999994, 262.3599999999999, 290.29999999999995, 165.10999999999999, 108.40999999999991, 308.30999999999995, 250.25999999999993, 280.3799999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [165.34999999999977, -42.36999999999995, 129.71000000000015, 50.26999999999976, -138.25, -9.549999999999995, -119.6800000000001, 60.40999999999996, 97.40000000000009, 113.87000000000008, 6.230000000000022, -64.86999999999998, -5.259999999999959, -40.80999999999995, 40.45999999999998, -30.73000000000004, 154.2200000000001, -38.20000000000036, 142.43, 121.37000000000006, 72.58999999999999, 0.3200000000000305, 154.3400000000001, -167.86, 147.29000000000008, 104.81000000000027, 94.70000000000026, 127.66999999999999, 69.41000000000004, 16.52000000000023, 3.3800000000000523, -50.9199999999998, 2.0000000000000013, 36.439999999999934, 81.59, 105.65000000000005, 28.789999999999853, 100.70000000000009, 52.34000000000003, 2.0000000000000013, 123.14, 34.45999999999998, 30.919999999999856, -57.09999999999955, 68.41999999999992, 101.42000000000012, 22.100000000000005, -59.64999999999999, 102.38000000000002, -11.679999999999978, 85.07, 6.230000000000004, -20.0799999999998, 56.86999999999989, 106.00999999999999, 158.42000000000002, 122.06000000000002, 70.16, 74.18000000000004, 190.09999999999994, 103.55000000000017, 144.14000000000007, -90.85000000000005, 84.38000000000011, 55.460000000000235, 183.16999999999996, 101.30000000000001, 42.04999999999998, -38.52999999999979, 131.69000000000005, 186.05, 106.37000000000008, 110.21000000000002, 150.26, -18.099999999999703, 10.910000000000002, -182.92000000000098, 163.37, 187.10000000000002, 188.12000000000006, 146.32999999999998, 71.14999999999999, 122.4800000000001, 88.34000000000007, -46.26999999999981, -64.74999999999999, -22.119999999999706, 177.2299999999999, 136.10000000000002, 62.20999999999998, 153.08000000000004, 146.48000000000002, 155.12, -47.62000000000009, 184.12999999999997, 40.639999999999894, 154.13, 2.0000000000000013, -12.070000000000041, 43.06999999999998, -12.070000000000041, 144.55999999999995, 68.17999999999996, 127.07000000000004, -18.06999999999981, 117.17000000000006, 106.43000000000005, -67.89999999999982, -22.119999999999706, 121.64000000000003, 181.06999999999996, 97.25000000000011, 161.11999999999995, 183.16999999999996, 186.14000000000001, 72.29000000000002, 131.0, 85.07000000000001, 161.32999999999998, 3.1999999999997826, 92.50999999999999, 192.04999999999998, 49.070000000000014, -37.99000000000001, 139.10000000000002, 69.11000000000003, 71.14999999999998, 156.38000000000002, 106.03999999999999, 164.06, -97.81000000000016, 171.2600000000001, 149.3, 172.09999999999997, 148.19, 165.2, 158.18, -18.970000000000027, 130.13, 153.01999999999998, 139.13, -6.040000000000042, 149.21000000000004, 108.20000000000006, 173.0, 74.93000000000015, 108.11000000000001, 77.08999999999997, 101.0, -15.640000000000178, 107.38999999999997, 148.04000000000002, -78.73000000000025, -104.98000000000002, 169.15999999999997, -27.33999999999977, -38.200000000000294, 165.26, 122.06000000000003, 60.07999999999998, 181.04000000000002, -12.07000000000004, 128.21, 50.06, 99.16999999999996, 182.06, -42.52000000000003, 115.13000000000005, 28.60999999999999, -17.79999999999994, 95.11999999999999, 89.06, 132.10999999999999, 118.19000000000001, 156.23000000000002, 177.23000000000002, 137.12, 102.05, 141.20000000000005, 153.35000000000002, 103.10000000000002, -22.179999999999996, 128.15, 97.67000000000002, 86.09, 31.130000000000038, 129.29000000000008, 85.07, 106.12999999999998, 144.17000000000002, 64.01, 25.10000000000001, -56.7999999999994, 89.20999999999998, 99.25999999999996, 177.05, 139.19000000000003, 49.06999999999999, 113.27000000000004, 126.11000000000001], "policy_predator_policy_reward": [60.0, 8.0, 2.0, 8.0, 82.0, 83.0, 97.0, 72.0, 8.0, 21.0, 102.0, 12.0, 73.0, 56.0, 4.0, 36.0, 11.0, 20.0, 6.0, 15.0, 48.0, 43.0, 118.0, 4.0, 10.0, 3.0, 12.0, 9.0, 37.0, 5.0, 59.0, 50.0, 11.0, 39.0, 6.0, 24.0, 31.0, 18.0, 36.0, 20.0, 21.0, 12.0, 56.0, 26.0, 21.0, 45.0, 98.0, 0.0, 28.0, 63.0, 40.0, 38.0, 13.0, 49.0, 30.0, 24.0, 5.0, 57.0, 11.0, 36.0, 4.0, 24.0, 95.0, 80.0, 9.0, 30.0, 61.0, 12.0, 64.0, 59.0, 19.0, 3.0, 23.0, 8.0, 10.0, 0.0, 46.0, 92.0, 0.0, 1.0, 25.0, 14.0, 34.0, 1.0, 94.0, 73.0, 0.0, 12.0, 14.0, 10.0, 4.0, 12.0, 60.0, 62.0, 10.0, 25.0, 11.0, 0.0, 7.0, 17.0, 5.0, 2.0, 33.0, 27.0, 51.0, 13.0, 43.0, 51.0, 5.0, 12.0, 21.0, 13.0, 9.0, 3.0, 19.0, 32.0, 40.0, 40.0, 2.0, 26.0, 7.0, 14.0, 77.0, 59.0, 17.0, 40.0, 26.0, 31.0, 30.0, 17.0, 93.0, 1.0, 6.0, 7.0, 5.0, 11.0, 69.0, 70.0, 26.0, 8.0, 18.0, 2.0, 17.0, 12.0, 16.0, 11.0, 33.0, 30.0, 34.0, 32.0, 33.0, 14.0, 29.0, 111.0, 44.0, 35.0, 3.0, 20.0, 45.0, 23.0, 3.0, 11.0, 31.0, 34.0, 30.0, 25.0, 47.0, 28.0, 22.0, 67.0, 6.0, 42.0, 5.0, 30.0, 6.0, 7.0, 16.0, 31.0, 11.0, 6.0, 23.0, 36.0, 24.0, 27.0, 77.0, 25.0, 21.0, 27.0, 27.0, 13.0, 7.0, 69.0, 39.0, 37.0, 25.0, 7.0, 48.0, 14.0, 27.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7195482872526562, "mean_inference_ms": 1.9419332196648065, "mean_action_processing_ms": 0.3024406285692291, "mean_env_wait_ms": 0.24757759730578713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005620479583740234, "StateBufferConnector_ms": 0.003262639045715332, "ViewRequirementAgentConnector_ms": 0.12617921829223633}, "num_episodes": 18, "episode_return_max": 376.2199999999998, "episode_return_min": -43.710000000000264, "episode_return_mean": 208.27559999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.6765505860784, "num_env_steps_trained_throughput_per_sec": 360.6765505860784, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 11477.879, "restore_workers_time_ms": 0.026, "training_step_time_ms": 11477.775, "sample_time_ms": 1567.066, "learn_time_ms": 9890.392, "learn_throughput": 404.433, "synch_weights_time_ms": 17.494}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "310e1_00000", "date": "2024-08-15_01-01-42", "timestamp": 1723663902, "time_this_iter_s": 11.135952949523926, "time_total_s": 258.7015459537506, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14fd700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 258.7015459537506, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 49.38, "ram_util_percent": 83.07333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.393212114850049, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.086119286723869, "policy_loss": -0.018225090768405054, "vf_loss": 6.101118947084618, "vf_explained_var": 0.041354048283642565, "kl": 0.016127144901732268, "entropy": 1.3899298611141386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.516516313634852, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.009153421089133, "policy_loss": -0.0013586678175088118, "vf_loss": 9.008801905818718, "vf_explained_var": 0.15938900125720515, "kl": 0.017101997490607555, "entropy": 1.4567018030181764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 376.2199999999998, "episode_reward_min": -52.68000000000066, "episode_reward_mean": 218.65729999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -263.98, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.04999999999998, "predator_policy": 129.0}, "policy_reward_mean": {"prey_policy": 78.70864999999999, "predator_policy": 30.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [318.43, 254.21999999999994, 311.27999999999986, 275.6899999999997, 168.52999999999977, 277.63, 216.35000000000002, 216.1599999999998, 314.4199999999999, 291.47, 2.8099999999999197, 118.45000000000032, 376.2199999999998, 256.48, 245.8199999999996, 55.98000000000009, 167.1099999999997, 222.31000000000006, 315.5599999999997, 229.49999999999994, 259.7699999999999, 167.13, 54.9999999999999, 139.49000000000004, 255.24999999999997, 163.10000000000002, 132.53000000000011, 116.52000000000044, 312.3199999999997, 356.2899999999999, 309.4299999999997, 296.06999999999994, 192.5299999999999, 305.55999999999995, 147.08000000000004, 265.2099999999999, 284.52999999999975, 317.09999999999997, 167.45, 334.39999999999986, 329.39, 278.2099999999999, 317.15, 153.09000000000003, 286.40999999999997, 274.93000000000006, 248.2, 151.36000000000007, 302.42999999999984, -43.710000000000264, 220.81999999999994, 150.06000000000012, 250.13999999999993, 182.9699999999998, 243.26999999999998, 336.22999999999996, 147.61000000000024, 99.81000000000009, 232.17999999999995, 285.2999999999999, 346.4599999999999, 286.16999999999996, 311.54999999999995, 139.92000000000036, 276.82, 219.21999999999994, 262.3599999999999, 290.29999999999995, 165.10999999999999, 108.40999999999991, 308.30999999999995, 250.25999999999993, 280.3799999999999, 140.34, 99.4300000000001, 187.29000000000008, 339.1499999999999, 157.24000000000007, 299.60999999999996, -52.68000000000066, 106.26999999999984, 9.41000000000001, 266.29999999999984, 82.00999999999999, 55.42999999999998, 153.44000000000003, 230.22000000000003, 277.36000000000007, 284.40000000000003, 264.43999999999977, 149.34000000000003, 271.51999999999975, 193.47999999999988, 257.48999999999995, 342.1399999999999, 130.86000000000013, 132.29999999999995, 217.2999999999999, 83.29000000000002, 286.04999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [106.00999999999999, 158.42000000000002, 122.06000000000002, 70.16, 74.18000000000004, 190.09999999999994, 103.55000000000017, 144.14000000000007, -90.85000000000005, 84.38000000000011, 55.460000000000235, 183.16999999999996, 101.30000000000001, 42.04999999999998, -38.52999999999979, 131.69000000000005, 186.05, 106.37000000000008, 110.21000000000002, 150.26, -18.099999999999703, 10.910000000000002, -182.92000000000098, 163.37, 187.10000000000002, 188.12000000000006, 146.32999999999998, 71.14999999999999, 122.4800000000001, 88.34000000000007, -46.26999999999981, -64.74999999999999, -22.119999999999706, 177.2299999999999, 136.10000000000002, 62.20999999999998, 153.08000000000004, 146.48000000000002, 155.12, -47.62000000000009, 184.12999999999997, 40.639999999999894, 154.13, 2.0000000000000013, -12.070000000000041, 43.06999999999998, -12.070000000000041, 144.55999999999995, 68.17999999999996, 127.07000000000004, -18.06999999999981, 117.17000000000006, 106.43000000000005, -67.89999999999982, -22.119999999999706, 121.64000000000003, 181.06999999999996, 97.25000000000011, 161.11999999999995, 183.16999999999996, 186.14000000000001, 72.29000000000002, 131.0, 85.07000000000001, 161.32999999999998, 3.1999999999997826, 92.50999999999999, 192.04999999999998, 49.070000000000014, -37.99000000000001, 139.10000000000002, 69.11000000000003, 71.14999999999998, 156.38000000000002, 106.03999999999999, 164.06, -97.81000000000016, 171.2600000000001, 149.3, 172.09999999999997, 148.19, 165.2, 158.18, -18.970000000000027, 130.13, 153.01999999999998, 139.13, -6.040000000000042, 149.21000000000004, 108.20000000000006, 173.0, 74.93000000000015, 108.11000000000001, 77.08999999999997, 101.0, -15.640000000000178, 107.38999999999997, 148.04000000000002, -78.73000000000025, -104.98000000000002, 169.15999999999997, -27.33999999999977, -38.200000000000294, 165.26, 122.06000000000003, 60.07999999999998, 181.04000000000002, -12.07000000000004, 128.21, 50.06, 99.16999999999996, 182.06, -42.52000000000003, 115.13000000000005, 28.60999999999999, -17.79999999999994, 95.11999999999999, 89.06, 132.10999999999999, 118.19000000000001, 156.23000000000002, 177.23000000000002, 137.12, 102.05, 141.20000000000005, 153.35000000000002, 103.10000000000002, -22.179999999999996, 128.15, 97.67000000000002, 86.09, 31.130000000000038, 129.29000000000008, 85.07, 106.12999999999998, 144.17000000000002, 64.01, 25.10000000000001, -56.7999999999994, 89.20999999999998, 99.25999999999996, 177.05, 139.19000000000003, 49.06999999999999, 113.27000000000004, 126.11000000000001, 63.019999999999996, -2.679999999999989, 2.1800000000000175, -7.750000000000007, 15.290000000000013, 53.0, 145.09999999999997, 171.04999999999995, 87.11000000000001, -40.87000000000001, 114.40999999999998, 162.2, -100.5100000000003, -32.17000000000036, 24.85999999999987, -17.590000000000046, 98.38999999999999, -263.98, 128.09, 89.2100000000001, -82.0, 34.01, 23.30000000000002, -109.86999999999999, 62.180000000000035, -5.740000000000004, 120.05000000000001, 27.169999999999995, 150.11, 82.24999999999999, 105.31999999999994, 141.07999999999998, 125.18000000000004, 93.25999999999996, -3.7900000000000063, 64.13, 132.13999999999993, 102.38, 17.18, 101.30000000000005, 137.33, 73.16000000000003, 142.09999999999997, 178.04000000000002, 85.19000000000001, -34.33000000000003, -38.019999999999975, 102.32000000000001, -4.930000000000007, 120.23000000000006, 17.089999999999993, -44.80000000000001, 111.05000000000003, 83.0], "policy_predator_policy_reward": [30.0, 24.0, 5.0, 57.0, 11.0, 36.0, 4.0, 24.0, 95.0, 80.0, 9.0, 30.0, 61.0, 12.0, 64.0, 59.0, 19.0, 3.0, 23.0, 8.0, 10.0, 0.0, 46.0, 92.0, 0.0, 1.0, 25.0, 14.0, 34.0, 1.0, 94.0, 73.0, 0.0, 12.0, 14.0, 10.0, 4.0, 12.0, 60.0, 62.0, 10.0, 25.0, 11.0, 0.0, 7.0, 17.0, 5.0, 2.0, 33.0, 27.0, 51.0, 13.0, 43.0, 51.0, 5.0, 12.0, 21.0, 13.0, 9.0, 3.0, 19.0, 32.0, 40.0, 40.0, 2.0, 26.0, 7.0, 14.0, 77.0, 59.0, 17.0, 40.0, 26.0, 31.0, 30.0, 17.0, 93.0, 1.0, 6.0, 7.0, 5.0, 11.0, 69.0, 70.0, 26.0, 8.0, 18.0, 2.0, 17.0, 12.0, 16.0, 11.0, 33.0, 30.0, 34.0, 32.0, 33.0, 14.0, 29.0, 111.0, 44.0, 35.0, 3.0, 20.0, 45.0, 23.0, 3.0, 11.0, 31.0, 34.0, 30.0, 25.0, 47.0, 28.0, 22.0, 67.0, 6.0, 42.0, 5.0, 30.0, 6.0, 7.0, 16.0, 31.0, 11.0, 6.0, 23.0, 36.0, 24.0, 27.0, 77.0, 25.0, 21.0, 27.0, 27.0, 13.0, 7.0, 69.0, 39.0, 37.0, 25.0, 7.0, 48.0, 14.0, 27.0, 14.0, 49.0, 31.0, 17.0, 88.0, 69.0, 50.0, 7.0, 16.0, 61.0, 50.0, 15.0, 8.0, 34.0, 46.0, 48.0, 51.0, 46.0, 129.0, 30.0, 19.0, 40.0, 90.0, 73.0, 69.0, 45.0, 52.0, 25.0, 58.0, 26.0, 19.0, 21.0, 17.0, 36.0, 10.0, 44.0, 45.0, 19.0, 18.0, 1.0, 74.0, 22.0, 25.0, 6.0, 16.0, 62.0, 18.0, 28.0, 40.0, 45.0, 57.0, 50.0, 61.0, 41.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7261598002413912, "mean_inference_ms": 1.9476947759548673, "mean_action_processing_ms": 0.3040477398169517, "mean_env_wait_ms": 0.24807775305332774, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006838321685791016, "StateBufferConnector_ms": 0.00398564338684082, "ViewRequirementAgentConnector_ms": 0.1438068151473999}, "num_episodes": 27, "episode_return_max": 376.2199999999998, "episode_return_min": -52.68000000000066, "episode_return_mean": 218.65729999999996, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.5978926038147, "num_env_steps_trained_throughput_per_sec": 365.5978926038147, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 11351.36, "restore_workers_time_ms": 0.026, "training_step_time_ms": 11351.257, "sample_time_ms": 1516.739, "learn_time_ms": 9815.335, "learn_throughput": 407.526, "synch_weights_time_ms": 17.453}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "310e1_00000", "date": "2024-08-15_01-01-53", "timestamp": 1723663913, "time_this_iter_s": 10.9997239112854, "time_total_s": 269.701269865036, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14df790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 269.701269865036, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 46.95625, "ram_util_percent": 82.92500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9846902630947254, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.426649582322943, "policy_loss": -0.015693438547865424, "vf_loss": 7.438823781946979, "vf_explained_var": 0.022033435011666918, "kl": 0.017596109952052703, "entropy": 1.4379578957481989, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5850802864031817, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.238412024987438, "policy_loss": -0.007884434938046431, "vf_loss": 9.244923987212005, "vf_explained_var": 0.05035819881176822, "kl": 0.013724673337901026, "entropy": 1.4287710686840078, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 356.2899999999999, "episode_reward_min": -179.94999999999996, "episode_reward_mean": 179.78719999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -263.98, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.04999999999998, "predator_policy": 145.0}, "policy_reward_mean": {"prey_policy": 53.4986, "predator_policy": 36.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [315.5599999999997, 229.49999999999994, 259.7699999999999, 167.13, 54.9999999999999, 139.49000000000004, 255.24999999999997, 163.10000000000002, 132.53000000000011, 116.52000000000044, 312.3199999999997, 356.2899999999999, 309.4299999999997, 296.06999999999994, 192.5299999999999, 305.55999999999995, 147.08000000000004, 265.2099999999999, 284.52999999999975, 317.09999999999997, 167.45, 334.39999999999986, 329.39, 278.2099999999999, 317.15, 153.09000000000003, 286.40999999999997, 274.93000000000006, 248.2, 151.36000000000007, 302.42999999999984, -43.710000000000264, 220.81999999999994, 150.06000000000012, 250.13999999999993, 182.9699999999998, 243.26999999999998, 336.22999999999996, 147.61000000000024, 99.81000000000009, 232.17999999999995, 285.2999999999999, 346.4599999999999, 286.16999999999996, 311.54999999999995, 139.92000000000036, 276.82, 219.21999999999994, 262.3599999999999, 290.29999999999995, 165.10999999999999, 108.40999999999991, 308.30999999999995, 250.25999999999993, 280.3799999999999, 140.34, 99.4300000000001, 187.29000000000008, 339.1499999999999, 157.24000000000007, 299.60999999999996, -52.68000000000066, 106.26999999999984, 9.41000000000001, 266.29999999999984, 82.00999999999999, 55.42999999999998, 153.44000000000003, 230.22000000000003, 277.36000000000007, 284.40000000000003, 264.43999999999977, 149.34000000000003, 271.51999999999975, 193.47999999999988, 257.48999999999995, 342.1399999999999, 130.86000000000013, 132.29999999999995, 217.2999999999999, 83.29000000000002, 286.04999999999995, 79.41999999999992, -38.59000000000003, 57.38000000000014, -80.39999999999961, 89.0800000000002, 0.9299999999999438, -110.23999999999984, 210.49999999999972, -42.790000000000134, -49.98000000000037, 29.21000000000008, 46.880000000000095, 143.83000000000044, 27.619999999999756, 136.58000000000044, -77.29999999999997, -39.829999999999764, -179.94999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [153.08000000000004, 146.48000000000002, 155.12, -47.62000000000009, 184.12999999999997, 40.639999999999894, 154.13, 2.0000000000000013, -12.070000000000041, 43.06999999999998, -12.070000000000041, 144.55999999999995, 68.17999999999996, 127.07000000000004, -18.06999999999981, 117.17000000000006, 106.43000000000005, -67.89999999999982, -22.119999999999706, 121.64000000000003, 181.06999999999996, 97.25000000000011, 161.11999999999995, 183.16999999999996, 186.14000000000001, 72.29000000000002, 131.0, 85.07000000000001, 161.32999999999998, 3.1999999999997826, 92.50999999999999, 192.04999999999998, 49.070000000000014, -37.99000000000001, 139.10000000000002, 69.11000000000003, 71.14999999999998, 156.38000000000002, 106.03999999999999, 164.06, -97.81000000000016, 171.2600000000001, 149.3, 172.09999999999997, 148.19, 165.2, 158.18, -18.970000000000027, 130.13, 153.01999999999998, 139.13, -6.040000000000042, 149.21000000000004, 108.20000000000006, 173.0, 74.93000000000015, 108.11000000000001, 77.08999999999997, 101.0, -15.640000000000178, 107.38999999999997, 148.04000000000002, -78.73000000000025, -104.98000000000002, 169.15999999999997, -27.33999999999977, -38.200000000000294, 165.26, 122.06000000000003, 60.07999999999998, 181.04000000000002, -12.07000000000004, 128.21, 50.06, 99.16999999999996, 182.06, -42.52000000000003, 115.13000000000005, 28.60999999999999, -17.79999999999994, 95.11999999999999, 89.06, 132.10999999999999, 118.19000000000001, 156.23000000000002, 177.23000000000002, 137.12, 102.05, 141.20000000000005, 153.35000000000002, 103.10000000000002, -22.179999999999996, 128.15, 97.67000000000002, 86.09, 31.130000000000038, 129.29000000000008, 85.07, 106.12999999999998, 144.17000000000002, 64.01, 25.10000000000001, -56.7999999999994, 89.20999999999998, 99.25999999999996, 177.05, 139.19000000000003, 49.06999999999999, 113.27000000000004, 126.11000000000001, 63.019999999999996, -2.679999999999989, 2.1800000000000175, -7.750000000000007, 15.290000000000013, 53.0, 145.09999999999997, 171.04999999999995, 87.11000000000001, -40.87000000000001, 114.40999999999998, 162.2, -100.5100000000003, -32.17000000000036, 24.85999999999987, -17.590000000000046, 98.38999999999999, -263.98, 128.09, 89.2100000000001, -82.0, 34.01, 23.30000000000002, -109.86999999999999, 62.180000000000035, -5.740000000000004, 120.05000000000001, 27.169999999999995, 150.11, 82.24999999999999, 105.31999999999994, 141.07999999999998, 125.18000000000004, 93.25999999999996, -3.7900000000000063, 64.13, 132.13999999999993, 102.38, 17.18, 101.30000000000005, 137.33, 73.16000000000003, 142.09999999999997, 178.04000000000002, 85.19000000000001, -34.33000000000003, -38.019999999999975, 102.32000000000001, -4.930000000000007, 120.23000000000006, 17.089999999999993, -44.80000000000001, 111.05000000000003, 83.0, -6.25000000000011, -16.330000000000002, -103.98999999999977, -61.59999999999998, -71.9500000000002, 20.330000000000034, -67.14999999999986, -108.24999999999983, -103.23999999999975, 54.319999999999936, -14.74000000000002, -88.32999999999987, -92.25999999999986, -200.98000000000002, 37.18999999999999, 100.30999999999997, -16.000000000000107, -123.78999999999982, -176.3499999999997, -31.629999999999853, -101.47000000000006, 12.679999999999886, -137.80000000000018, 63.68000000000001, 5.510000000000026, 54.32000000000001, -16.720000000000013, -61.659999999999314, 10.579999999999988, 64.99999999999996, -90.66999999999994, -205.62999999999997, -9.070000000000004, -195.76000000000022, -157.56999999999985, -197.3800000000001], "policy_predator_policy_reward": [4.0, 12.0, 60.0, 62.0, 10.0, 25.0, 11.0, 0.0, 7.0, 17.0, 5.0, 2.0, 33.0, 27.0, 51.0, 13.0, 43.0, 51.0, 5.0, 12.0, 21.0, 13.0, 9.0, 3.0, 19.0, 32.0, 40.0, 40.0, 2.0, 26.0, 7.0, 14.0, 77.0, 59.0, 17.0, 40.0, 26.0, 31.0, 30.0, 17.0, 93.0, 1.0, 6.0, 7.0, 5.0, 11.0, 69.0, 70.0, 26.0, 8.0, 18.0, 2.0, 17.0, 12.0, 16.0, 11.0, 33.0, 30.0, 34.0, 32.0, 33.0, 14.0, 29.0, 111.0, 44.0, 35.0, 3.0, 20.0, 45.0, 23.0, 3.0, 11.0, 31.0, 34.0, 30.0, 25.0, 47.0, 28.0, 22.0, 67.0, 6.0, 42.0, 5.0, 30.0, 6.0, 7.0, 16.0, 31.0, 11.0, 6.0, 23.0, 36.0, 24.0, 27.0, 77.0, 25.0, 21.0, 27.0, 27.0, 13.0, 7.0, 69.0, 39.0, 37.0, 25.0, 7.0, 48.0, 14.0, 27.0, 14.0, 49.0, 31.0, 17.0, 88.0, 69.0, 50.0, 7.0, 16.0, 61.0, 50.0, 15.0, 8.0, 34.0, 46.0, 48.0, 51.0, 46.0, 129.0, 30.0, 19.0, 40.0, 90.0, 73.0, 69.0, 45.0, 52.0, 25.0, 58.0, 26.0, 19.0, 21.0, 17.0, 36.0, 10.0, 44.0, 45.0, 19.0, 18.0, 1.0, 74.0, 22.0, 25.0, 6.0, 16.0, 62.0, 18.0, 28.0, 40.0, 45.0, 57.0, 50.0, 61.0, 41.0, 51.0, 70.0, 32.0, 68.0, 59.0, 63.0, 46.0, 67.0, 28.0, 32.0, 106.0, 24.0, 80.0, 51.0, 132.0, 35.0, 38.0, 29.0, 68.0, 70.0, 88.0, 61.0, 57.0, 30.0, 91.0, 54.0, 30.0, 43.0, 63.0, 8.0, 53.0, 110.0, 109.0, 63.0, 102.0, 145.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7272425348098753, "mean_inference_ms": 1.947876376526448, "mean_action_processing_ms": 0.3037970576581429, "mean_env_wait_ms": 0.24764873281331085, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006517767906188965, "StateBufferConnector_ms": 0.003651261329650879, "ViewRequirementAgentConnector_ms": 0.1093285083770752}, "num_episodes": 18, "episode_return_max": 356.2899999999999, "episode_return_min": -179.94999999999996, "episode_return_mean": 179.78719999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.4052111916224, "num_env_steps_trained_throughput_per_sec": 338.4052111916224, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 11373.252, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11373.164, "sample_time_ms": 1499.603, "learn_time_ms": 9854.758, "learn_throughput": 405.895, "synch_weights_time_ms": 17.192}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "310e1_00000", "date": "2024-08-15_01-02-05", "timestamp": 1723663925, "time_this_iter_s": 11.86552381515503, "time_total_s": 281.56679368019104, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14821f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 281.56679368019104, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 54.15294117647059, "ram_util_percent": 83.68235294117646}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.064587256233528, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.711008401648709, "policy_loss": -0.013219970376501796, "vf_loss": 8.721172606755816, "vf_explained_var": 0.004443521695162253, "kl": 0.015278703787778245, "entropy": 1.4221057264893144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.141780709116547, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.297691616179451, "policy_loss": -0.011904861600872464, "vf_loss": 9.307924315538356, "vf_explained_var": 0.011361895162592488, "kl": 0.01672142808589772, "entropy": 1.4238792289501776, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 346.4599999999999, "episode_reward_min": -285.3600000000001, "episode_reward_mean": 133.98269999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -266.80000000000007, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 182.06, "predator_policy": 145.0}, "policy_reward_mean": {"prey_policy": 19.371350000000007, "predator_policy": 47.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [284.52999999999975, 317.09999999999997, 167.45, 334.39999999999986, 329.39, 278.2099999999999, 317.15, 153.09000000000003, 286.40999999999997, 274.93000000000006, 248.2, 151.36000000000007, 302.42999999999984, -43.710000000000264, 220.81999999999994, 150.06000000000012, 250.13999999999993, 182.9699999999998, 243.26999999999998, 336.22999999999996, 147.61000000000024, 99.81000000000009, 232.17999999999995, 285.2999999999999, 346.4599999999999, 286.16999999999996, 311.54999999999995, 139.92000000000036, 276.82, 219.21999999999994, 262.3599999999999, 290.29999999999995, 165.10999999999999, 108.40999999999991, 308.30999999999995, 250.25999999999993, 280.3799999999999, 140.34, 99.4300000000001, 187.29000000000008, 339.1499999999999, 157.24000000000007, 299.60999999999996, -52.68000000000066, 106.26999999999984, 9.41000000000001, 266.29999999999984, 82.00999999999999, 55.42999999999998, 153.44000000000003, 230.22000000000003, 277.36000000000007, 284.40000000000003, 264.43999999999977, 149.34000000000003, 271.51999999999975, 193.47999999999988, 257.48999999999995, 342.1399999999999, 130.86000000000013, 132.29999999999995, 217.2999999999999, 83.29000000000002, 286.04999999999995, 79.41999999999992, -38.59000000000003, 57.38000000000014, -80.39999999999961, 89.0800000000002, 0.9299999999999438, -110.23999999999984, 210.49999999999972, -42.790000000000134, -49.98000000000037, 29.21000000000008, 46.880000000000095, 143.83000000000044, 27.619999999999756, 136.58000000000044, -77.29999999999997, -39.829999999999764, -179.94999999999996, -92.71999999999994, -285.3600000000001, 30.410000000000117, 10.54, -19.850000000000037, 11.400000000000006, 74.10000000000005, 27.659999999999915, -86.0199999999996, -31.089999999999968, -103.37999999999978, -115.12999999999997, -17.019999999999946, -95.93999999999956, 93.37999999999994, -87.2799999999999, -8.06000000000001, 132.24999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [71.14999999999998, 156.38000000000002, 106.03999999999999, 164.06, -97.81000000000016, 171.2600000000001, 149.3, 172.09999999999997, 148.19, 165.2, 158.18, -18.970000000000027, 130.13, 153.01999999999998, 139.13, -6.040000000000042, 149.21000000000004, 108.20000000000006, 173.0, 74.93000000000015, 108.11000000000001, 77.08999999999997, 101.0, -15.640000000000178, 107.38999999999997, 148.04000000000002, -78.73000000000025, -104.98000000000002, 169.15999999999997, -27.33999999999977, -38.200000000000294, 165.26, 122.06000000000003, 60.07999999999998, 181.04000000000002, -12.07000000000004, 128.21, 50.06, 99.16999999999996, 182.06, -42.52000000000003, 115.13000000000005, 28.60999999999999, -17.79999999999994, 95.11999999999999, 89.06, 132.10999999999999, 118.19000000000001, 156.23000000000002, 177.23000000000002, 137.12, 102.05, 141.20000000000005, 153.35000000000002, 103.10000000000002, -22.179999999999996, 128.15, 97.67000000000002, 86.09, 31.130000000000038, 129.29000000000008, 85.07, 106.12999999999998, 144.17000000000002, 64.01, 25.10000000000001, -56.7999999999994, 89.20999999999998, 99.25999999999996, 177.05, 139.19000000000003, 49.06999999999999, 113.27000000000004, 126.11000000000001, 63.019999999999996, -2.679999999999989, 2.1800000000000175, -7.750000000000007, 15.290000000000013, 53.0, 145.09999999999997, 171.04999999999995, 87.11000000000001, -40.87000000000001, 114.40999999999998, 162.2, -100.5100000000003, -32.17000000000036, 24.85999999999987, -17.590000000000046, 98.38999999999999, -263.98, 128.09, 89.2100000000001, -82.0, 34.01, 23.30000000000002, -109.86999999999999, 62.180000000000035, -5.740000000000004, 120.05000000000001, 27.169999999999995, 150.11, 82.24999999999999, 105.31999999999994, 141.07999999999998, 125.18000000000004, 93.25999999999996, -3.7900000000000063, 64.13, 132.13999999999993, 102.38, 17.18, 101.30000000000005, 137.33, 73.16000000000003, 142.09999999999997, 178.04000000000002, 85.19000000000001, -34.33000000000003, -38.019999999999975, 102.32000000000001, -4.930000000000007, 120.23000000000006, 17.089999999999993, -44.80000000000001, 111.05000000000003, 83.0, -6.25000000000011, -16.330000000000002, -103.98999999999977, -61.59999999999998, -71.9500000000002, 20.330000000000034, -67.14999999999986, -108.24999999999983, -103.23999999999975, 54.319999999999936, -14.74000000000002, -88.32999999999987, -92.25999999999986, -200.98000000000002, 37.18999999999999, 100.30999999999997, -16.000000000000107, -123.78999999999982, -176.3499999999997, -31.629999999999853, -101.47000000000006, 12.679999999999886, -137.80000000000018, 63.68000000000001, 5.510000000000026, 54.32000000000001, -16.720000000000013, -61.659999999999314, 10.579999999999988, 64.99999999999996, -90.66999999999994, -205.62999999999997, -9.070000000000004, -195.76000000000022, -157.56999999999985, -197.3800000000001, -82.53999999999994, -187.18000000000018, -265.6000000000002, -243.75999999999993, -101.37999999999987, -1.2100000000000026, -97.99000000000001, -98.47000000000003, -163.1199999999999, -21.730000000000004, -11.259999999999998, -135.34000000000026, -73.87000000000012, 1.969999999999903, -66.51999999999977, -24.820000000000036, -179.88999999999996, -117.12999999999957, -126.4299999999999, -76.66, -90.54999999999987, -254.83000000000015, -154.63000000000008, -191.49999999999983, -21.910000000000007, -95.10999999999989, -99.54999999999983, -187.39000000000044, -5.079999999999988, 19.460000000000072, -266.80000000000007, -85.47999999999989, -201.27999999999992, -7.780000000000001, -56.56000000000002, 95.81000000000029], "policy_predator_policy_reward": [26.0, 31.0, 30.0, 17.0, 93.0, 1.0, 6.0, 7.0, 5.0, 11.0, 69.0, 70.0, 26.0, 8.0, 18.0, 2.0, 17.0, 12.0, 16.0, 11.0, 33.0, 30.0, 34.0, 32.0, 33.0, 14.0, 29.0, 111.0, 44.0, 35.0, 3.0, 20.0, 45.0, 23.0, 3.0, 11.0, 31.0, 34.0, 30.0, 25.0, 47.0, 28.0, 22.0, 67.0, 6.0, 42.0, 5.0, 30.0, 6.0, 7.0, 16.0, 31.0, 11.0, 6.0, 23.0, 36.0, 24.0, 27.0, 77.0, 25.0, 21.0, 27.0, 27.0, 13.0, 7.0, 69.0, 39.0, 37.0, 25.0, 7.0, 48.0, 14.0, 27.0, 14.0, 49.0, 31.0, 17.0, 88.0, 69.0, 50.0, 7.0, 16.0, 61.0, 50.0, 15.0, 8.0, 34.0, 46.0, 48.0, 51.0, 46.0, 129.0, 30.0, 19.0, 40.0, 90.0, 73.0, 69.0, 45.0, 52.0, 25.0, 58.0, 26.0, 19.0, 21.0, 17.0, 36.0, 10.0, 44.0, 45.0, 19.0, 18.0, 1.0, 74.0, 22.0, 25.0, 6.0, 16.0, 62.0, 18.0, 28.0, 40.0, 45.0, 57.0, 50.0, 61.0, 41.0, 51.0, 70.0, 32.0, 68.0, 59.0, 63.0, 46.0, 67.0, 28.0, 32.0, 106.0, 24.0, 80.0, 51.0, 132.0, 35.0, 38.0, 29.0, 68.0, 70.0, 88.0, 61.0, 57.0, 30.0, 91.0, 54.0, 30.0, 43.0, 63.0, 8.0, 53.0, 110.0, 109.0, 63.0, 102.0, 145.0, 30.0, 69.0, 108.0, 89.0, 135.0, 84.0, 49.0, 95.0, 112.0, 79.0, 86.0, 87.0, 71.0, 48.0, 98.0, 52.0, 67.0, 139.0, 72.0, 45.0, 127.0, 134.0, 108.0, 92.0, 139.0, 47.0, 53.0, 127.0, 64.0, 24.0, 55.0, 141.0, 124.0, 123.0, 78.0, 71.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7240864159242841, "mean_inference_ms": 1.9366356261743738, "mean_action_processing_ms": 0.3020469912205635, "mean_env_wait_ms": 0.2465188081251889, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005514025688171387, "StateBufferConnector_ms": 0.0036672353744506836, "ViewRequirementAgentConnector_ms": 0.10887539386749268}, "num_episodes": 18, "episode_return_max": 346.4599999999999, "episode_return_min": -285.3600000000001, "episode_return_mean": 133.98269999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.0072018958043, "num_env_steps_trained_throughput_per_sec": 366.0072018958043, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 11330.295, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11330.207, "sample_time_ms": 1477.345, "learn_time_ms": 9834.506, "learn_throughput": 406.731, "synch_weights_time_ms": 16.905}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "310e1_00000", "date": "2024-08-15_01-02-16", "timestamp": 1723663936, "time_this_iter_s": 10.973335027694702, "time_total_s": 292.54012870788574, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14fd820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 292.54012870788574, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 47.55, "ram_util_percent": 83.61250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4484507444359007, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.122150119650302, "policy_loss": -0.00951817544453122, "vf_loss": 8.1283521879287, "vf_explained_var": -0.014065711807321619, "kl": 0.016580521947091763, "entropy": 1.4138300729176354, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9213545476948775, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.818353537403086, "policy_loss": -0.008936485279568288, "vf_loss": 8.825619397592293, "vf_explained_var": 0.020295762574231182, "kl": 0.01670641331013372, "entropy": 1.4064142751315283, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 346.4599999999999, "episode_reward_min": -285.3600000000001, "episode_reward_mean": 87.30639999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.6600000000003, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 182.06, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -14.171799999999994, "predator_policy": 57.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [243.26999999999998, 336.22999999999996, 147.61000000000024, 99.81000000000009, 232.17999999999995, 285.2999999999999, 346.4599999999999, 286.16999999999996, 311.54999999999995, 139.92000000000036, 276.82, 219.21999999999994, 262.3599999999999, 290.29999999999995, 165.10999999999999, 108.40999999999991, 308.30999999999995, 250.25999999999993, 280.3799999999999, 140.34, 99.4300000000001, 187.29000000000008, 339.1499999999999, 157.24000000000007, 299.60999999999996, -52.68000000000066, 106.26999999999984, 9.41000000000001, 266.29999999999984, 82.00999999999999, 55.42999999999998, 153.44000000000003, 230.22000000000003, 277.36000000000007, 284.40000000000003, 264.43999999999977, 149.34000000000003, 271.51999999999975, 193.47999999999988, 257.48999999999995, 342.1399999999999, 130.86000000000013, 132.29999999999995, 217.2999999999999, 83.29000000000002, 286.04999999999995, 79.41999999999992, -38.59000000000003, 57.38000000000014, -80.39999999999961, 89.0800000000002, 0.9299999999999438, -110.23999999999984, 210.49999999999972, -42.790000000000134, -49.98000000000037, 29.21000000000008, 46.880000000000095, 143.83000000000044, 27.619999999999756, 136.58000000000044, -77.29999999999997, -39.829999999999764, -179.94999999999996, -92.71999999999994, -285.3600000000001, 30.410000000000117, 10.54, -19.850000000000037, 11.400000000000006, 74.10000000000005, 27.659999999999915, -86.0199999999996, -31.089999999999968, -103.37999999999978, -115.12999999999997, -17.019999999999946, -95.93999999999956, 93.37999999999994, -87.2799999999999, -8.06000000000001, 132.24999999999952, -273.15999999999997, -67.94999999999979, -202.8300000000006, 71.47000000000003, 19.99999999999997, -52.370000000000196, 98.77000000000005, 159.77999999999975, -116.01999999999997, 17.680000000000014, -4.4299999999999145, 9.520000000000053, -69.22000000000001, 38.980000000000004, 6.9300000000000175, -242.3600000000002, 174.7399999999998, -32.22999999999928], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [128.21, 50.06, 99.16999999999996, 182.06, -42.52000000000003, 115.13000000000005, 28.60999999999999, -17.79999999999994, 95.11999999999999, 89.06, 132.10999999999999, 118.19000000000001, 156.23000000000002, 177.23000000000002, 137.12, 102.05, 141.20000000000005, 153.35000000000002, 103.10000000000002, -22.179999999999996, 128.15, 97.67000000000002, 86.09, 31.130000000000038, 129.29000000000008, 85.07, 106.12999999999998, 144.17000000000002, 64.01, 25.10000000000001, -56.7999999999994, 89.20999999999998, 99.25999999999996, 177.05, 139.19000000000003, 49.06999999999999, 113.27000000000004, 126.11000000000001, 63.019999999999996, -2.679999999999989, 2.1800000000000175, -7.750000000000007, 15.290000000000013, 53.0, 145.09999999999997, 171.04999999999995, 87.11000000000001, -40.87000000000001, 114.40999999999998, 162.2, -100.5100000000003, -32.17000000000036, 24.85999999999987, -17.590000000000046, 98.38999999999999, -263.98, 128.09, 89.2100000000001, -82.0, 34.01, 23.30000000000002, -109.86999999999999, 62.180000000000035, -5.740000000000004, 120.05000000000001, 27.169999999999995, 150.11, 82.24999999999999, 105.31999999999994, 141.07999999999998, 125.18000000000004, 93.25999999999996, -3.7900000000000063, 64.13, 132.13999999999993, 102.38, 17.18, 101.30000000000005, 137.33, 73.16000000000003, 142.09999999999997, 178.04000000000002, 85.19000000000001, -34.33000000000003, -38.019999999999975, 102.32000000000001, -4.930000000000007, 120.23000000000006, 17.089999999999993, -44.80000000000001, 111.05000000000003, 83.0, -6.25000000000011, -16.330000000000002, -103.98999999999977, -61.59999999999998, -71.9500000000002, 20.330000000000034, -67.14999999999986, -108.24999999999983, -103.23999999999975, 54.319999999999936, -14.74000000000002, -88.32999999999987, -92.25999999999986, -200.98000000000002, 37.18999999999999, 100.30999999999997, -16.000000000000107, -123.78999999999982, -176.3499999999997, -31.629999999999853, -101.47000000000006, 12.679999999999886, -137.80000000000018, 63.68000000000001, 5.510000000000026, 54.32000000000001, -16.720000000000013, -61.659999999999314, 10.579999999999988, 64.99999999999996, -90.66999999999994, -205.62999999999997, -9.070000000000004, -195.76000000000022, -157.56999999999985, -197.3800000000001, -82.53999999999994, -187.18000000000018, -265.6000000000002, -243.75999999999993, -101.37999999999987, -1.2100000000000026, -97.99000000000001, -98.47000000000003, -163.1199999999999, -21.730000000000004, -11.259999999999998, -135.34000000000026, -73.87000000000012, 1.969999999999903, -66.51999999999977, -24.820000000000036, -179.88999999999996, -117.12999999999957, -126.4299999999999, -76.66, -90.54999999999987, -254.83000000000015, -154.63000000000008, -191.49999999999983, -21.910000000000007, -95.10999999999989, -99.54999999999983, -187.39000000000044, -5.079999999999988, 19.460000000000072, -266.80000000000007, -85.47999999999989, -201.27999999999992, -7.780000000000001, -56.56000000000002, 95.81000000000029, -195.19000000000005, -288.97, -140.29000000000025, -175.66000000000003, -313.6600000000003, -149.17000000000027, -47.91999999999996, -9.609999999999964, -83.7100000000001, -11.2899999999999, -79.87000000000009, -122.49999999999974, 94.57999999999996, -97.8099999999999, -68.76999999999992, 103.55000000000022, -40.21000000000004, -295.8100000000002, -6.040000000000042, -45.280000000000086, -27.73000000000001, -156.70000000000027, -42.19000000000016, -98.29, -250.81, -20.409999999999947, -63.87999999999998, -26.14, 62.239999999999995, -213.31000000000046, -303.87999999999994, -250.48000000000025, 106.31000000000003, -64.56999999999988, -116.11000000000064, -40.11999999999961], "policy_predator_policy_reward": [31.0, 34.0, 30.0, 25.0, 47.0, 28.0, 22.0, 67.0, 6.0, 42.0, 5.0, 30.0, 6.0, 7.0, 16.0, 31.0, 11.0, 6.0, 23.0, 36.0, 24.0, 27.0, 77.0, 25.0, 21.0, 27.0, 27.0, 13.0, 7.0, 69.0, 39.0, 37.0, 25.0, 7.0, 48.0, 14.0, 27.0, 14.0, 49.0, 31.0, 17.0, 88.0, 69.0, 50.0, 7.0, 16.0, 61.0, 50.0, 15.0, 8.0, 34.0, 46.0, 48.0, 51.0, 46.0, 129.0, 30.0, 19.0, 40.0, 90.0, 73.0, 69.0, 45.0, 52.0, 25.0, 58.0, 26.0, 19.0, 21.0, 17.0, 36.0, 10.0, 44.0, 45.0, 19.0, 18.0, 1.0, 74.0, 22.0, 25.0, 6.0, 16.0, 62.0, 18.0, 28.0, 40.0, 45.0, 57.0, 50.0, 61.0, 41.0, 51.0, 70.0, 32.0, 68.0, 59.0, 63.0, 46.0, 67.0, 28.0, 32.0, 106.0, 24.0, 80.0, 51.0, 132.0, 35.0, 38.0, 29.0, 68.0, 70.0, 88.0, 61.0, 57.0, 30.0, 91.0, 54.0, 30.0, 43.0, 63.0, 8.0, 53.0, 110.0, 109.0, 63.0, 102.0, 145.0, 30.0, 69.0, 108.0, 89.0, 135.0, 84.0, 49.0, 95.0, 112.0, 79.0, 86.0, 87.0, 71.0, 48.0, 98.0, 52.0, 67.0, 139.0, 72.0, 45.0, 127.0, 134.0, 108.0, 92.0, 139.0, 47.0, 53.0, 127.0, 64.0, 24.0, 55.0, 141.0, 124.0, 123.0, 78.0, 71.0, 22.0, 137.0, 74.0, 126.0, 122.0, 119.0, 141.0, 66.0, 63.0, 68.0, 47.0, 47.0, 103.0, 89.0, 13.0, 64.0, 61.0, 82.0, 138.0, 36.0, 33.0, 78.0, 102.0, 59.0, 91.0, 144.0, 58.0, 70.0, 59.0, 61.0, 97.0, 161.0, 151.0, 63.0, 70.0, 67.0, 57.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7190935546512575, "mean_inference_ms": 1.9207593877565805, "mean_action_processing_ms": 0.2996773191180303, "mean_env_wait_ms": 0.24469306973886018, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006983518600463867, "StateBufferConnector_ms": 0.003766655921936035, "ViewRequirementAgentConnector_ms": 0.11103534698486328}, "num_episodes": 18, "episode_return_max": 346.4599999999999, "episode_return_min": -285.3600000000001, "episode_return_mean": 87.30639999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.22555001816244, "num_env_steps_trained_throughput_per_sec": 356.22555001816244, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 11278.728, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11278.64, "sample_time_ms": 1442.781, "learn_time_ms": 9817.369, "learn_throughput": 407.441, "synch_weights_time_ms": 16.944}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "310e1_00000", "date": "2024-08-15_01-02-28", "timestamp": 1723663948, "time_this_iter_s": 11.276445865631104, "time_total_s": 303.81657457351685, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14fd4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 303.81657457351685, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 50.08125, "ram_util_percent": 83.65}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8515017215852385, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.705619197673898, "policy_loss": -0.013059143808660486, "vf_loss": 7.7155072615890905, "vf_explained_var": -0.0736640642875086, "kl": 0.01585541547310376, "entropy": 1.3712027452610158, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.616203276631693, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.102349991268582, "policy_loss": -0.009047994896690682, "vf_loss": 8.109797026366785, "vf_explained_var": -0.008824897506249645, "kl": 0.016009580863237595, "entropy": 1.3396165008898135, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 342.1399999999999, "episode_reward_min": -285.3600000000001, "episode_reward_mean": 38.16560000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.6600000000003, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 178.04000000000002, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -46.92220000000001, "predator_policy": 66.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [339.1499999999999, 157.24000000000007, 299.60999999999996, -52.68000000000066, 106.26999999999984, 9.41000000000001, 266.29999999999984, 82.00999999999999, 55.42999999999998, 153.44000000000003, 230.22000000000003, 277.36000000000007, 284.40000000000003, 264.43999999999977, 149.34000000000003, 271.51999999999975, 193.47999999999988, 257.48999999999995, 342.1399999999999, 130.86000000000013, 132.29999999999995, 217.2999999999999, 83.29000000000002, 286.04999999999995, 79.41999999999992, -38.59000000000003, 57.38000000000014, -80.39999999999961, 89.0800000000002, 0.9299999999999438, -110.23999999999984, 210.49999999999972, -42.790000000000134, -49.98000000000037, 29.21000000000008, 46.880000000000095, 143.83000000000044, 27.619999999999756, 136.58000000000044, -77.29999999999997, -39.829999999999764, -179.94999999999996, -92.71999999999994, -285.3600000000001, 30.410000000000117, 10.54, -19.850000000000037, 11.400000000000006, 74.10000000000005, 27.659999999999915, -86.0199999999996, -31.089999999999968, -103.37999999999978, -115.12999999999997, -17.019999999999946, -95.93999999999956, 93.37999999999994, -87.2799999999999, -8.06000000000001, 132.24999999999952, -273.15999999999997, -67.94999999999979, -202.8300000000006, 71.47000000000003, 19.99999999999997, -52.370000000000196, 98.77000000000005, 159.77999999999975, -116.01999999999997, 17.680000000000014, -4.4299999999999145, 9.520000000000053, -69.22000000000001, 38.980000000000004, 6.9300000000000175, -242.3600000000002, 174.7399999999998, -32.22999999999928, 48.02999999999996, 41.07000000000001, 20.229999999999876, 39.98999999999998, 114.07000000000005, 26.15000000000004, -4.859999999999594, -36.91999999999971, -23.199999999999978, 2.9800000000003575, -28.42999999999926, 18.600000000000104, -99.99999999999955, 88.44000000000015, 78.93999999999988, 53.14, 31.560000000000024, -30.10999999999982, -13.159999999999945, -67.37000000000026, -44.399999999999956, -112.10000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [145.09999999999997, 171.04999999999995, 87.11000000000001, -40.87000000000001, 114.40999999999998, 162.2, -100.5100000000003, -32.17000000000036, 24.85999999999987, -17.590000000000046, 98.38999999999999, -263.98, 128.09, 89.2100000000001, -82.0, 34.01, 23.30000000000002, -109.86999999999999, 62.180000000000035, -5.740000000000004, 120.05000000000001, 27.169999999999995, 150.11, 82.24999999999999, 105.31999999999994, 141.07999999999998, 125.18000000000004, 93.25999999999996, -3.7900000000000063, 64.13, 132.13999999999993, 102.38, 17.18, 101.30000000000005, 137.33, 73.16000000000003, 142.09999999999997, 178.04000000000002, 85.19000000000001, -34.33000000000003, -38.019999999999975, 102.32000000000001, -4.930000000000007, 120.23000000000006, 17.089999999999993, -44.80000000000001, 111.05000000000003, 83.0, -6.25000000000011, -16.330000000000002, -103.98999999999977, -61.59999999999998, -71.9500000000002, 20.330000000000034, -67.14999999999986, -108.24999999999983, -103.23999999999975, 54.319999999999936, -14.74000000000002, -88.32999999999987, -92.25999999999986, -200.98000000000002, 37.18999999999999, 100.30999999999997, -16.000000000000107, -123.78999999999982, -176.3499999999997, -31.629999999999853, -101.47000000000006, 12.679999999999886, -137.80000000000018, 63.68000000000001, 5.510000000000026, 54.32000000000001, -16.720000000000013, -61.659999999999314, 10.579999999999988, 64.99999999999996, -90.66999999999994, -205.62999999999997, -9.070000000000004, -195.76000000000022, -157.56999999999985, -197.3800000000001, -82.53999999999994, -187.18000000000018, -265.6000000000002, -243.75999999999993, -101.37999999999987, -1.2100000000000026, -97.99000000000001, -98.47000000000003, -163.1199999999999, -21.730000000000004, -11.259999999999998, -135.34000000000026, -73.87000000000012, 1.969999999999903, -66.51999999999977, -24.820000000000036, -179.88999999999996, -117.12999999999957, -126.4299999999999, -76.66, -90.54999999999987, -254.83000000000015, -154.63000000000008, -191.49999999999983, -21.910000000000007, -95.10999999999989, -99.54999999999983, -187.39000000000044, -5.079999999999988, 19.460000000000072, -266.80000000000007, -85.47999999999989, -201.27999999999992, -7.780000000000001, -56.56000000000002, 95.81000000000029, -195.19000000000005, -288.97, -140.29000000000025, -175.66000000000003, -313.6600000000003, -149.17000000000027, -47.91999999999996, -9.609999999999964, -83.7100000000001, -11.2899999999999, -79.87000000000009, -122.49999999999974, 94.57999999999996, -97.8099999999999, -68.76999999999992, 103.55000000000022, -40.21000000000004, -295.8100000000002, -6.040000000000042, -45.280000000000086, -27.73000000000001, -156.70000000000027, -42.19000000000016, -98.29, -250.81, -20.409999999999947, -63.87999999999998, -26.14, 62.239999999999995, -213.31000000000046, -303.87999999999994, -250.48000000000025, 106.31000000000003, -64.56999999999988, -116.11000000000064, -40.11999999999961, 6.559999999999999, -74.52999999999979, -34.32999999999996, -49.60000000000004, -4.240000000000112, -134.52999999999997, -11.020000000000007, -58.98999999999991, 67.07, 2.0000000000000013, -38.20000000000036, -38.650000000000006, -38.13999999999994, -73.71999999999986, -155.91999999999996, 2.0000000000000013, -129.97, -44.23000000000035, -47.950000000000195, -0.07000000000004114, -120.52000000000015, -30.90999999999947, -101.61999999999999, -31.780000000000015, -135.88, -163.11999999999983, -18.879999999999992, -35.6799999999999, 35.57000000000002, -94.63, 2.0000000000000013, -32.859999999999964, -23.77000000000004, -69.66999999999987, -104.16999999999993, -96.93999999999998, -126.52000000000027, -78.63999999999994, -212.65000000000015, -43.71999999999982, -167.83, -103.57, -86.88999999999993, -169.21000000000006], "policy_predator_policy_reward": [7.0, 16.0, 61.0, 50.0, 15.0, 8.0, 34.0, 46.0, 48.0, 51.0, 46.0, 129.0, 30.0, 19.0, 40.0, 90.0, 73.0, 69.0, 45.0, 52.0, 25.0, 58.0, 26.0, 19.0, 21.0, 17.0, 36.0, 10.0, 44.0, 45.0, 19.0, 18.0, 1.0, 74.0, 22.0, 25.0, 6.0, 16.0, 62.0, 18.0, 28.0, 40.0, 45.0, 57.0, 50.0, 61.0, 41.0, 51.0, 70.0, 32.0, 68.0, 59.0, 63.0, 46.0, 67.0, 28.0, 32.0, 106.0, 24.0, 80.0, 51.0, 132.0, 35.0, 38.0, 29.0, 68.0, 70.0, 88.0, 61.0, 57.0, 30.0, 91.0, 54.0, 30.0, 43.0, 63.0, 8.0, 53.0, 110.0, 109.0, 63.0, 102.0, 145.0, 30.0, 69.0, 108.0, 89.0, 135.0, 84.0, 49.0, 95.0, 112.0, 79.0, 86.0, 87.0, 71.0, 48.0, 98.0, 52.0, 67.0, 139.0, 72.0, 45.0, 127.0, 134.0, 108.0, 92.0, 139.0, 47.0, 53.0, 127.0, 64.0, 24.0, 55.0, 141.0, 124.0, 123.0, 78.0, 71.0, 22.0, 137.0, 74.0, 126.0, 122.0, 119.0, 141.0, 66.0, 63.0, 68.0, 47.0, 47.0, 103.0, 89.0, 13.0, 64.0, 61.0, 82.0, 138.0, 36.0, 33.0, 78.0, 102.0, 59.0, 91.0, 144.0, 58.0, 70.0, 59.0, 61.0, 97.0, 161.0, 151.0, 63.0, 70.0, 67.0, 57.0, 34.0, 82.0, 60.0, 65.0, 86.0, 73.0, 71.0, 39.0, 14.0, 31.0, 48.0, 55.0, 80.0, 27.0, 116.0, 1.0, 71.0, 80.0, 20.0, 31.0, 55.0, 68.0, 60.0, 92.0, 96.0, 103.0, 81.0, 62.0, 59.0, 79.0, 40.0, 44.0, 68.0, 57.0, 100.0, 71.0, 81.0, 111.0, 110.0, 79.0, 100.0, 127.0, 96.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7134871655075912, "mean_inference_ms": 1.9023434269021628, "mean_action_processing_ms": 0.29744444115728846, "mean_env_wait_ms": 0.24299846492042726, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007816553115844727, "StateBufferConnector_ms": 0.0037279129028320312, "ViewRequirementAgentConnector_ms": 0.10648465156555176}, "num_episodes": 22, "episode_return_max": 342.1399999999999, "episode_return_min": -285.3600000000001, "episode_return_mean": 38.16560000000002, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.9996918823957, "num_env_steps_trained_throughput_per_sec": 361.9996918823957, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 11273.856, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11273.765, "sample_time_ms": 1446.121, "learn_time_ms": 9810.44, "learn_throughput": 407.729, "synch_weights_time_ms": 15.523}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "310e1_00000", "date": "2024-08-15_01-02-39", "timestamp": 1723663959, "time_this_iter_s": 11.098031997680664, "time_total_s": 314.9146065711975, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14fdf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 314.9146065711975, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 49.94666666666667, "ram_util_percent": 83.60666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2390491538262243, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.847945917724932, "policy_loss": -0.01565260567539741, "vf_loss": 8.859512901306152, "vf_explained_var": 0.019147275427661876, "kl": 0.02042798053193817, "entropy": 1.362146490906912, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5429252793864596, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.00773050621073, "policy_loss": -0.004700489061337615, "vf_loss": 9.011550506208309, "vf_explained_var": -0.3120185731580018, "kl": 0.00880509789474288, "entropy": 1.3458507507566422, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 286.04999999999995, "episode_reward_min": -333.2700000000002, "episode_reward_mean": -27.45109999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -327.7900000000001, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 111.05000000000003, "predator_policy": 180.0}, "policy_reward_mean": {"prey_policy": -91.68055, "predator_policy": 77.955}, "custom_metrics": {}, "hist_stats": {"episode_reward": [286.04999999999995, 79.41999999999992, -38.59000000000003, 57.38000000000014, -80.39999999999961, 89.0800000000002, 0.9299999999999438, -110.23999999999984, 210.49999999999972, -42.790000000000134, -49.98000000000037, 29.21000000000008, 46.880000000000095, 143.83000000000044, 27.619999999999756, 136.58000000000044, -77.29999999999997, -39.829999999999764, -179.94999999999996, -92.71999999999994, -285.3600000000001, 30.410000000000117, 10.54, -19.850000000000037, 11.400000000000006, 74.10000000000005, 27.659999999999915, -86.0199999999996, -31.089999999999968, -103.37999999999978, -115.12999999999997, -17.019999999999946, -95.93999999999956, 93.37999999999994, -87.2799999999999, -8.06000000000001, 132.24999999999952, -273.15999999999997, -67.94999999999979, -202.8300000000006, 71.47000000000003, 19.99999999999997, -52.370000000000196, 98.77000000000005, 159.77999999999975, -116.01999999999997, 17.680000000000014, -4.4299999999999145, 9.520000000000053, -69.22000000000001, 38.980000000000004, 6.9300000000000175, -242.3600000000002, 174.7399999999998, -32.22999999999928, 48.02999999999996, 41.07000000000001, 20.229999999999876, 39.98999999999998, 114.07000000000005, 26.15000000000004, -4.859999999999594, -36.91999999999971, -23.199999999999978, 2.9800000000003575, -28.42999999999926, 18.600000000000104, -99.99999999999955, 88.44000000000015, 78.93999999999988, 53.14, 31.560000000000024, -30.10999999999982, -13.159999999999945, -67.37000000000026, -44.399999999999956, -112.10000000000001, -44.659999999999755, -228.30999999999995, -89.94999999999962, -186.1399999999997, -23.980000000000004, -158.5399999999995, -126.6599999999999, -135.11999999999995, 70.15000000000013, -81.8199999999998, -141.65, 42.89999999999992, -21.96000000000004, -329.5700000000003, 11.429999999999954, -164.51999999999987, -125.64999999999999, 102.13000000000004, -182.4299999999999, -39.22000000000005, -108.31999999999995, -333.2700000000002, -16.189999999999404], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [111.05000000000003, 83.0, -6.25000000000011, -16.330000000000002, -103.98999999999977, -61.59999999999998, -71.9500000000002, 20.330000000000034, -67.14999999999986, -108.24999999999983, -103.23999999999975, 54.319999999999936, -14.74000000000002, -88.32999999999987, -92.25999999999986, -200.98000000000002, 37.18999999999999, 100.30999999999997, -16.000000000000107, -123.78999999999982, -176.3499999999997, -31.629999999999853, -101.47000000000006, 12.679999999999886, -137.80000000000018, 63.68000000000001, 5.510000000000026, 54.32000000000001, -16.720000000000013, -61.659999999999314, 10.579999999999988, 64.99999999999996, -90.66999999999994, -205.62999999999997, -9.070000000000004, -195.76000000000022, -157.56999999999985, -197.3800000000001, -82.53999999999994, -187.18000000000018, -265.6000000000002, -243.75999999999993, -101.37999999999987, -1.2100000000000026, -97.99000000000001, -98.47000000000003, -163.1199999999999, -21.730000000000004, -11.259999999999998, -135.34000000000026, -73.87000000000012, 1.969999999999903, -66.51999999999977, -24.820000000000036, -179.88999999999996, -117.12999999999957, -126.4299999999999, -76.66, -90.54999999999987, -254.83000000000015, -154.63000000000008, -191.49999999999983, -21.910000000000007, -95.10999999999989, -99.54999999999983, -187.39000000000044, -5.079999999999988, 19.460000000000072, -266.80000000000007, -85.47999999999989, -201.27999999999992, -7.780000000000001, -56.56000000000002, 95.81000000000029, -195.19000000000005, -288.97, -140.29000000000025, -175.66000000000003, -313.6600000000003, -149.17000000000027, -47.91999999999996, -9.609999999999964, -83.7100000000001, -11.2899999999999, -79.87000000000009, -122.49999999999974, 94.57999999999996, -97.8099999999999, -68.76999999999992, 103.55000000000022, -40.21000000000004, -295.8100000000002, -6.040000000000042, -45.280000000000086, -27.73000000000001, -156.70000000000027, -42.19000000000016, -98.29, -250.81, -20.409999999999947, -63.87999999999998, -26.14, 62.239999999999995, -213.31000000000046, -303.87999999999994, -250.48000000000025, 106.31000000000003, -64.56999999999988, -116.11000000000064, -40.11999999999961, 6.559999999999999, -74.52999999999979, -34.32999999999996, -49.60000000000004, -4.240000000000112, -134.52999999999997, -11.020000000000007, -58.98999999999991, 67.07, 2.0000000000000013, -38.20000000000036, -38.650000000000006, -38.13999999999994, -73.71999999999986, -155.91999999999996, 2.0000000000000013, -129.97, -44.23000000000035, -47.950000000000195, -0.07000000000004114, -120.52000000000015, -30.90999999999947, -101.61999999999999, -31.780000000000015, -135.88, -163.11999999999983, -18.879999999999992, -35.6799999999999, 35.57000000000002, -94.63, 2.0000000000000013, -32.859999999999964, -23.77000000000004, -69.66999999999987, -104.16999999999993, -96.93999999999998, -126.52000000000027, -78.63999999999994, -212.65000000000015, -43.71999999999982, -167.83, -103.57, -86.88999999999993, -169.21000000000006, -38.0199999999999, -201.64000000000027, -242.49999999999983, -271.8100000000002, -6.040000000000042, -285.9100000000001, -186.63999999999982, -203.50000000000043, -60.72999999999987, -48.25000000000035, -262.78, -120.7600000000002, -148.74999999999991, -165.91000000000005, -123.48999999999995, -196.63000000000002, -20.109999999999705, 0.259999999999998, -2.020000000000042, -275.8000000000001, -139.48, -197.17000000000007, -15.189999999999744, -54.90999999999998, -217.96000000000004, 2.0000000000000013, -327.7900000000001, -313.7800000000002, -40.570000000000285, 2.0000000000000013, -99.90999999999988, -291.60999999999996, -193.5400000000001, -95.11, -39.36999999999992, 39.50000000000001, -268.96, -203.47000000000003, -60.519999999999996, -147.70000000000007, -175.57000000000016, -151.75000000000023, -290.56000000000006, -296.71000000000015, -18.099999999999703, -16.0899999999997], "policy_predator_policy_reward": [41.0, 51.0, 70.0, 32.0, 68.0, 59.0, 63.0, 46.0, 67.0, 28.0, 32.0, 106.0, 24.0, 80.0, 51.0, 132.0, 35.0, 38.0, 29.0, 68.0, 70.0, 88.0, 61.0, 57.0, 30.0, 91.0, 54.0, 30.0, 43.0, 63.0, 8.0, 53.0, 110.0, 109.0, 63.0, 102.0, 145.0, 30.0, 69.0, 108.0, 89.0, 135.0, 84.0, 49.0, 95.0, 112.0, 79.0, 86.0, 87.0, 71.0, 48.0, 98.0, 52.0, 67.0, 139.0, 72.0, 45.0, 127.0, 134.0, 108.0, 92.0, 139.0, 47.0, 53.0, 127.0, 64.0, 24.0, 55.0, 141.0, 124.0, 123.0, 78.0, 71.0, 22.0, 137.0, 74.0, 126.0, 122.0, 119.0, 141.0, 66.0, 63.0, 68.0, 47.0, 47.0, 103.0, 89.0, 13.0, 64.0, 61.0, 82.0, 138.0, 36.0, 33.0, 78.0, 102.0, 59.0, 91.0, 144.0, 58.0, 70.0, 59.0, 61.0, 97.0, 161.0, 151.0, 63.0, 70.0, 67.0, 57.0, 34.0, 82.0, 60.0, 65.0, 86.0, 73.0, 71.0, 39.0, 14.0, 31.0, 48.0, 55.0, 80.0, 27.0, 116.0, 1.0, 71.0, 80.0, 20.0, 31.0, 55.0, 68.0, 60.0, 92.0, 96.0, 103.0, 81.0, 62.0, 59.0, 79.0, 40.0, 44.0, 68.0, 57.0, 100.0, 71.0, 81.0, 111.0, 110.0, 79.0, 100.0, 127.0, 96.0, 48.0, 124.0, 71.0, 180.0, 106.0, 75.0, 127.0, 95.0, 109.0, 44.0, 41.0, 126.0, 99.0, 58.0, 130.0, 96.0, 89.0, 50.0, 40.0, 101.0, 95.0, 96.0, 99.0, 51.0, 62.0, 77.0, 117.0, 168.0, 144.0, 26.0, 24.0, 89.0, 138.0, 88.0, 75.0, 47.0, 55.0, 151.0, 139.0, 89.0, 80.0, 119.0, 100.0, 152.0, 102.0, 8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7095096371778966, "mean_inference_ms": 1.895020054495221, "mean_action_processing_ms": 0.30278547972058123, "mean_env_wait_ms": 0.2414367059530933, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009051680564880371, "StateBufferConnector_ms": 0.0032993555068969727, "ViewRequirementAgentConnector_ms": 0.09498250484466553}, "num_episodes": 23, "episode_return_max": 286.04999999999995, "episode_return_min": -333.2700000000002, "episode_return_mean": -27.45109999999995, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 330.22686177192924, "num_env_steps_trained_throughput_per_sec": 330.22686177192924, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 11387.766, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11387.711, "sample_time_ms": 1550.071, "learn_time_ms": 9822.0, "learn_throughput": 407.249, "synch_weights_time_ms": 13.902}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "310e1_00000", "date": "2024-08-15_01-02-51", "timestamp": 1723663971, "time_this_iter_s": 12.173655033111572, "time_total_s": 327.0882616043091, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c6a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 327.0882616043091, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 50.7111111111111, "ram_util_percent": 83.72222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.950696181967145, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.37858470381883, "policy_loss": -0.007653412989355506, "vf_loss": 9.381939487860947, "vf_explained_var": -0.028016414654948724, "kl": 0.01432868000354795, "entropy": 1.393301404657818, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1533526635359204, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.541784277164116, "policy_loss": -0.0009507100956475057, "vf_loss": 7.5421930631001795, "vf_explained_var": -0.40379472176233927, "kl": 0.005419129839620413, "entropy": 1.3132353869695512, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 174.7399999999998, "episode_reward_min": -429.89, "episode_reward_mean": -70.44249999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.98, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 106.31000000000003, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -127.91125, "predator_policy": 92.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-179.94999999999996, -92.71999999999994, -285.3600000000001, 30.410000000000117, 10.54, -19.850000000000037, 11.400000000000006, 74.10000000000005, 27.659999999999915, -86.0199999999996, -31.089999999999968, -103.37999999999978, -115.12999999999997, -17.019999999999946, -95.93999999999956, 93.37999999999994, -87.2799999999999, -8.06000000000001, 132.24999999999952, -273.15999999999997, -67.94999999999979, -202.8300000000006, 71.47000000000003, 19.99999999999997, -52.370000000000196, 98.77000000000005, 159.77999999999975, -116.01999999999997, 17.680000000000014, -4.4299999999999145, 9.520000000000053, -69.22000000000001, 38.980000000000004, 6.9300000000000175, -242.3600000000002, 174.7399999999998, -32.22999999999928, 48.02999999999996, 41.07000000000001, 20.229999999999876, 39.98999999999998, 114.07000000000005, 26.15000000000004, -4.859999999999594, -36.91999999999971, -23.199999999999978, 2.9800000000003575, -28.42999999999926, 18.600000000000104, -99.99999999999955, 88.44000000000015, 78.93999999999988, 53.14, 31.560000000000024, -30.10999999999982, -13.159999999999945, -67.37000000000026, -44.399999999999956, -112.10000000000001, -44.659999999999755, -228.30999999999995, -89.94999999999962, -186.1399999999997, -23.980000000000004, -158.5399999999995, -126.6599999999999, -135.11999999999995, 70.15000000000013, -81.8199999999998, -141.65, 42.89999999999992, -21.96000000000004, -329.5700000000003, 11.429999999999954, -164.51999999999987, -125.64999999999999, 102.13000000000004, -182.4299999999999, -39.22000000000005, -108.31999999999995, -333.2700000000002, -16.189999999999404, -52.91000000000024, -149.35000000000093, -330.6800000000002, -108.05999999999943, -387.75999999999993, -429.89, -378.8, -97.8399999999997, -73.81999999999981, 14.180000000000113, -389.6600000000001, -312.7199999999999, -336.41000000000014, -127.09999999999985, -72.71000000000001, -74.89999999999968, -48.97000000000028, -273.39], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-157.56999999999985, -197.3800000000001, -82.53999999999994, -187.18000000000018, -265.6000000000002, -243.75999999999993, -101.37999999999987, -1.2100000000000026, -97.99000000000001, -98.47000000000003, -163.1199999999999, -21.730000000000004, -11.259999999999998, -135.34000000000026, -73.87000000000012, 1.969999999999903, -66.51999999999977, -24.820000000000036, -179.88999999999996, -117.12999999999957, -126.4299999999999, -76.66, -90.54999999999987, -254.83000000000015, -154.63000000000008, -191.49999999999983, -21.910000000000007, -95.10999999999989, -99.54999999999983, -187.39000000000044, -5.079999999999988, 19.460000000000072, -266.80000000000007, -85.47999999999989, -201.27999999999992, -7.780000000000001, -56.56000000000002, 95.81000000000029, -195.19000000000005, -288.97, -140.29000000000025, -175.66000000000003, -313.6600000000003, -149.17000000000027, -47.91999999999996, -9.609999999999964, -83.7100000000001, -11.2899999999999, -79.87000000000009, -122.49999999999974, 94.57999999999996, -97.8099999999999, -68.76999999999992, 103.55000000000022, -40.21000000000004, -295.8100000000002, -6.040000000000042, -45.280000000000086, -27.73000000000001, -156.70000000000027, -42.19000000000016, -98.29, -250.81, -20.409999999999947, -63.87999999999998, -26.14, 62.239999999999995, -213.31000000000046, -303.87999999999994, -250.48000000000025, 106.31000000000003, -64.56999999999988, -116.11000000000064, -40.11999999999961, 6.559999999999999, -74.52999999999979, -34.32999999999996, -49.60000000000004, -4.240000000000112, -134.52999999999997, -11.020000000000007, -58.98999999999991, 67.07, 2.0000000000000013, -38.20000000000036, -38.650000000000006, -38.13999999999994, -73.71999999999986, -155.91999999999996, 2.0000000000000013, -129.97, -44.23000000000035, -47.950000000000195, -0.07000000000004114, -120.52000000000015, -30.90999999999947, -101.61999999999999, -31.780000000000015, -135.88, -163.11999999999983, -18.879999999999992, -35.6799999999999, 35.57000000000002, -94.63, 2.0000000000000013, -32.859999999999964, -23.77000000000004, -69.66999999999987, -104.16999999999993, -96.93999999999998, -126.52000000000027, -78.63999999999994, -212.65000000000015, -43.71999999999982, -167.83, -103.57, -86.88999999999993, -169.21000000000006, -38.0199999999999, -201.64000000000027, -242.49999999999983, -271.8100000000002, -6.040000000000042, -285.9100000000001, -186.63999999999982, -203.50000000000043, -60.72999999999987, -48.25000000000035, -262.78, -120.7600000000002, -148.74999999999991, -165.91000000000005, -123.48999999999995, -196.63000000000002, -20.109999999999705, 0.259999999999998, -2.020000000000042, -275.8000000000001, -139.48, -197.17000000000007, -15.189999999999744, -54.90999999999998, -217.96000000000004, 2.0000000000000013, -327.7900000000001, -313.7800000000002, -40.570000000000285, 2.0000000000000013, -99.90999999999988, -291.60999999999996, -193.5400000000001, -95.11, -39.36999999999992, 39.50000000000001, -268.96, -203.47000000000003, -60.519999999999996, -147.70000000000007, -175.57000000000016, -151.75000000000023, -290.56000000000006, -296.71000000000015, -18.099999999999703, -16.0899999999997, -290.85999999999996, -8.050000000000042, -108.54999999999926, -350.80000000000007, -303.85, -293.83000000000004, -393.97, -16.0899999999997, -376.0, -339.75999999999993, -392.98, -375.91, -359.98, -339.82, -300.82000000000005, -2.0200000000000418, -318.76, -10.060000000000041, -207.81999999999996, 2.0000000000000013, -334.74999999999994, -327.9100000000001, -296.7399999999999, -395.98, -304.69000000000005, -286.72, -276.46000000000004, -81.64000000000027, -267.37, -66.33999999999916, -377.89, -0.00999999999999836, 2.0000000000000013, -276.97, -260.40999999999997, -389.98], "policy_predator_policy_reward": [145.0, 30.0, 69.0, 108.0, 89.0, 135.0, 84.0, 49.0, 95.0, 112.0, 79.0, 86.0, 87.0, 71.0, 48.0, 98.0, 52.0, 67.0, 139.0, 72.0, 45.0, 127.0, 134.0, 108.0, 92.0, 139.0, 47.0, 53.0, 127.0, 64.0, 24.0, 55.0, 141.0, 124.0, 123.0, 78.0, 71.0, 22.0, 137.0, 74.0, 126.0, 122.0, 119.0, 141.0, 66.0, 63.0, 68.0, 47.0, 47.0, 103.0, 89.0, 13.0, 64.0, 61.0, 82.0, 138.0, 36.0, 33.0, 78.0, 102.0, 59.0, 91.0, 144.0, 58.0, 70.0, 59.0, 61.0, 97.0, 161.0, 151.0, 63.0, 70.0, 67.0, 57.0, 34.0, 82.0, 60.0, 65.0, 86.0, 73.0, 71.0, 39.0, 14.0, 31.0, 48.0, 55.0, 80.0, 27.0, 116.0, 1.0, 71.0, 80.0, 20.0, 31.0, 55.0, 68.0, 60.0, 92.0, 96.0, 103.0, 81.0, 62.0, 59.0, 79.0, 40.0, 44.0, 68.0, 57.0, 100.0, 71.0, 81.0, 111.0, 110.0, 79.0, 100.0, 127.0, 96.0, 48.0, 124.0, 71.0, 180.0, 106.0, 75.0, 127.0, 95.0, 109.0, 44.0, 41.0, 126.0, 99.0, 58.0, 130.0, 96.0, 89.0, 50.0, 40.0, 101.0, 95.0, 96.0, 99.0, 51.0, 62.0, 77.0, 117.0, 168.0, 144.0, 26.0, 24.0, 89.0, 138.0, 88.0, 75.0, 47.0, 55.0, 151.0, 139.0, 89.0, 80.0, 119.0, 100.0, 152.0, 102.0, 8.0, 10.0, 152.0, 94.0, 173.0, 137.0, 172.0, 95.0, 154.0, 148.0, 138.0, 190.0, 175.0, 164.0, 187.0, 134.0, 117.0, 88.0, 135.0, 120.0, 98.0, 122.0, 182.0, 91.0, 183.0, 197.0, 117.0, 138.0, 99.0, 132.0, 147.0, 114.0, 145.0, 158.0, 98.0, 128.0, 188.0, 189.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7062730705110186, "mean_inference_ms": 1.8898980842588013, "mean_action_processing_ms": 0.3065723995961069, "mean_env_wait_ms": 0.24043068664401457, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00863194465637207, "StateBufferConnector_ms": 0.003323793411254883, "ViewRequirementAgentConnector_ms": 0.09649014472961426}, "num_episodes": 18, "episode_return_max": 174.7399999999998, "episode_return_min": -429.89, "episode_return_mean": -70.44249999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.4104329509939, "num_env_steps_trained_throughput_per_sec": 356.4104329509939, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 11360.215, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11360.159, "sample_time_ms": 1476.84, "learn_time_ms": 9868.342, "learn_throughput": 405.337, "synch_weights_time_ms": 12.794}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "310e1_00000", "date": "2024-08-15_01-03-02", "timestamp": 1723663982, "time_this_iter_s": 11.27522897720337, "time_total_s": 338.36349058151245, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14cf670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 338.36349058151245, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 52.14375, "ram_util_percent": 83.75625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.726281732856912, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.490113186205505, "policy_loss": -0.00420125365434658, "vf_loss": 9.490964249706773, "vf_explained_var": -0.03409243809483039, "kl": 0.01116739124449643, "entropy": 1.3894596752035555, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2188123380380964, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.196462705400254, "policy_loss": -0.004521918842302902, "vf_loss": 8.200148792367763, "vf_explained_var": -0.29841291147565085, "kl": 0.008358412189979517, "entropy": 1.338591316831175, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 174.7399999999998, "episode_reward_min": -429.89, "episode_reward_mean": -97.78309999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 106.31000000000003, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -152.33155, "predator_policy": 103.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [132.24999999999952, -273.15999999999997, -67.94999999999979, -202.8300000000006, 71.47000000000003, 19.99999999999997, -52.370000000000196, 98.77000000000005, 159.77999999999975, -116.01999999999997, 17.680000000000014, -4.4299999999999145, 9.520000000000053, -69.22000000000001, 38.980000000000004, 6.9300000000000175, -242.3600000000002, 174.7399999999998, -32.22999999999928, 48.02999999999996, 41.07000000000001, 20.229999999999876, 39.98999999999998, 114.07000000000005, 26.15000000000004, -4.859999999999594, -36.91999999999971, -23.199999999999978, 2.9800000000003575, -28.42999999999926, 18.600000000000104, -99.99999999999955, 88.44000000000015, 78.93999999999988, 53.14, 31.560000000000024, -30.10999999999982, -13.159999999999945, -67.37000000000026, -44.399999999999956, -112.10000000000001, -44.659999999999755, -228.30999999999995, -89.94999999999962, -186.1399999999997, -23.980000000000004, -158.5399999999995, -126.6599999999999, -135.11999999999995, 70.15000000000013, -81.8199999999998, -141.65, 42.89999999999992, -21.96000000000004, -329.5700000000003, 11.429999999999954, -164.51999999999987, -125.64999999999999, 102.13000000000004, -182.4299999999999, -39.22000000000005, -108.31999999999995, -333.2700000000002, -16.189999999999404, -52.91000000000024, -149.35000000000093, -330.6800000000002, -108.05999999999943, -387.75999999999993, -429.89, -378.8, -97.8399999999997, -73.81999999999981, 14.180000000000113, -389.6600000000001, -312.7199999999999, -336.41000000000014, -127.09999999999985, -72.71000000000001, -74.89999999999968, -48.97000000000028, -273.39, -246.36, -278.3600000000005, -59.88000000000024, -34.37000000000065, -342.83000000000004, -208.87000000000003, -53.390000000000214, -193.8599999999999, -373.75, -358.75000000000006, -223.75, -212.03000000000006, -59.37000000000004, -250.59000000000015, -175.73000000000008, -67.53000000000006, -222.68000000000012, -246.27000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-56.56000000000002, 95.81000000000029, -195.19000000000005, -288.97, -140.29000000000025, -175.66000000000003, -313.6600000000003, -149.17000000000027, -47.91999999999996, -9.609999999999964, -83.7100000000001, -11.2899999999999, -79.87000000000009, -122.49999999999974, 94.57999999999996, -97.8099999999999, -68.76999999999992, 103.55000000000022, -40.21000000000004, -295.8100000000002, -6.040000000000042, -45.280000000000086, -27.73000000000001, -156.70000000000027, -42.19000000000016, -98.29, -250.81, -20.409999999999947, -63.87999999999998, -26.14, 62.239999999999995, -213.31000000000046, -303.87999999999994, -250.48000000000025, 106.31000000000003, -64.56999999999988, -116.11000000000064, -40.11999999999961, 6.559999999999999, -74.52999999999979, -34.32999999999996, -49.60000000000004, -4.240000000000112, -134.52999999999997, -11.020000000000007, -58.98999999999991, 67.07, 2.0000000000000013, -38.20000000000036, -38.650000000000006, -38.13999999999994, -73.71999999999986, -155.91999999999996, 2.0000000000000013, -129.97, -44.23000000000035, -47.950000000000195, -0.07000000000004114, -120.52000000000015, -30.90999999999947, -101.61999999999999, -31.780000000000015, -135.88, -163.11999999999983, -18.879999999999992, -35.6799999999999, 35.57000000000002, -94.63, 2.0000000000000013, -32.859999999999964, -23.77000000000004, -69.66999999999987, -104.16999999999993, -96.93999999999998, -126.52000000000027, -78.63999999999994, -212.65000000000015, -43.71999999999982, -167.83, -103.57, -86.88999999999993, -169.21000000000006, -38.0199999999999, -201.64000000000027, -242.49999999999983, -271.8100000000002, -6.040000000000042, -285.9100000000001, -186.63999999999982, -203.50000000000043, -60.72999999999987, -48.25000000000035, -262.78, -120.7600000000002, -148.74999999999991, -165.91000000000005, -123.48999999999995, -196.63000000000002, -20.109999999999705, 0.259999999999998, -2.020000000000042, -275.8000000000001, -139.48, -197.17000000000007, -15.189999999999744, -54.90999999999998, -217.96000000000004, 2.0000000000000013, -327.7900000000001, -313.7800000000002, -40.570000000000285, 2.0000000000000013, -99.90999999999988, -291.60999999999996, -193.5400000000001, -95.11, -39.36999999999992, 39.50000000000001, -268.96, -203.47000000000003, -60.519999999999996, -147.70000000000007, -175.57000000000016, -151.75000000000023, -290.56000000000006, -296.71000000000015, -18.099999999999703, -16.0899999999997, -290.85999999999996, -8.050000000000042, -108.54999999999926, -350.80000000000007, -303.85, -293.83000000000004, -393.97, -16.0899999999997, -376.0, -339.75999999999993, -392.98, -375.91, -359.98, -339.82, -300.82000000000005, -2.0200000000000418, -318.76, -10.060000000000041, -207.81999999999996, 2.0000000000000013, -334.74999999999994, -327.9100000000001, -296.7399999999999, -395.98, -304.69000000000005, -286.72, -276.46000000000004, -81.64000000000027, -267.37, -66.33999999999916, -377.89, -0.00999999999999836, 2.0000000000000013, -276.97, -260.40999999999997, -389.98, -223.50999999999993, -366.85, -350.98, -272.3800000000005, -288.84999999999997, -4.030000000000042, -54.28000000000034, -16.089999999999744, -379.92999999999995, -316.9, -199.09000000000003, -355.7800000000001, -0.00999999999999836, -248.38, -253.27000000000004, -281.5900000000004, -386.98, -353.77000000000004, -393.97, -343.78000000000003, -265.4500000000001, -232.2999999999999, -400.0, -193.0300000000001, -16.0899999999997, -252.28000000000011, -211.80999999999995, -355.7800000000001, -224.14, -266.59000000000026, -48.49000000000003, -207.04000000000008, -213.78999999999996, -377.89000000000004, -233.32000000000025, -365.95000000000005], "policy_predator_policy_reward": [71.0, 22.0, 137.0, 74.0, 126.0, 122.0, 119.0, 141.0, 66.0, 63.0, 68.0, 47.0, 47.0, 103.0, 89.0, 13.0, 64.0, 61.0, 82.0, 138.0, 36.0, 33.0, 78.0, 102.0, 59.0, 91.0, 144.0, 58.0, 70.0, 59.0, 61.0, 97.0, 161.0, 151.0, 63.0, 70.0, 67.0, 57.0, 34.0, 82.0, 60.0, 65.0, 86.0, 73.0, 71.0, 39.0, 14.0, 31.0, 48.0, 55.0, 80.0, 27.0, 116.0, 1.0, 71.0, 80.0, 20.0, 31.0, 55.0, 68.0, 60.0, 92.0, 96.0, 103.0, 81.0, 62.0, 59.0, 79.0, 40.0, 44.0, 68.0, 57.0, 100.0, 71.0, 81.0, 111.0, 110.0, 79.0, 100.0, 127.0, 96.0, 48.0, 124.0, 71.0, 180.0, 106.0, 75.0, 127.0, 95.0, 109.0, 44.0, 41.0, 126.0, 99.0, 58.0, 130.0, 96.0, 89.0, 50.0, 40.0, 101.0, 95.0, 96.0, 99.0, 51.0, 62.0, 77.0, 117.0, 168.0, 144.0, 26.0, 24.0, 89.0, 138.0, 88.0, 75.0, 47.0, 55.0, 151.0, 139.0, 89.0, 80.0, 119.0, 100.0, 152.0, 102.0, 8.0, 10.0, 152.0, 94.0, 173.0, 137.0, 172.0, 95.0, 154.0, 148.0, 138.0, 190.0, 175.0, 164.0, 187.0, 134.0, 117.0, 88.0, 135.0, 120.0, 98.0, 122.0, 182.0, 91.0, 183.0, 197.0, 117.0, 138.0, 99.0, 132.0, 147.0, 114.0, 145.0, 158.0, 98.0, 128.0, 188.0, 189.0, 167.0, 177.0, 183.0, 162.0, 109.0, 124.0, 3.0, 33.0, 189.0, 165.0, 171.0, 175.0, 120.0, 75.0, 172.0, 169.0, 178.0, 189.0, 191.0, 188.0, 146.0, 128.0, 200.0, 181.0, 86.0, 123.0, 143.0, 174.0, 149.0, 166.0, 97.0, 91.0, 186.0, 183.0, 176.0, 177.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7034557584900102, "mean_inference_ms": 1.8853322724392654, "mean_action_processing_ms": 0.31029051998560725, "mean_env_wait_ms": 0.23942478817390928, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008305072784423828, "StateBufferConnector_ms": 0.003436446189880371, "ViewRequirementAgentConnector_ms": 0.09706032276153564}, "num_episodes": 18, "episode_return_max": 174.7399999999998, "episode_return_min": -429.89, "episode_return_mean": -97.78309999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.0144599348905, "num_env_steps_trained_throughput_per_sec": 371.0144599348905, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 11295.73, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11295.677, "sample_time_ms": 1382.025, "learn_time_ms": 9898.386, "learn_throughput": 404.106, "synch_weights_time_ms": 13.02}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "310e1_00000", "date": "2024-08-15_01-03-13", "timestamp": 1723663993, "time_this_iter_s": 10.823401927947998, "time_total_s": 349.18689250946045, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c6550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 349.18689250946045, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 47.559999999999995, "ram_util_percent": 83.32000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.951865446252167, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.189086235389508, "policy_loss": -0.0034474554516020274, "vf_loss": 9.190753921125301, "vf_explained_var": -0.02923545733330742, "kl": 0.00593250611831551, "entropy": 1.3992001750481822, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2817494740246467, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.082130353160636, "policy_loss": -0.008217344234732015, "vf_loss": 8.088971572704416, "vf_explained_var": -0.3375063799676441, "kl": 0.013761161021315575, "entropy": 1.3368852730781313, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 114.07000000000005, "episode_reward_min": -429.89, "episode_reward_mean": -117.87729999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 67.07, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -169.34365000000003, "predator_policy": 110.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.22999999999928, 48.02999999999996, 41.07000000000001, 20.229999999999876, 39.98999999999998, 114.07000000000005, 26.15000000000004, -4.859999999999594, -36.91999999999971, -23.199999999999978, 2.9800000000003575, -28.42999999999926, 18.600000000000104, -99.99999999999955, 88.44000000000015, 78.93999999999988, 53.14, 31.560000000000024, -30.10999999999982, -13.159999999999945, -67.37000000000026, -44.399999999999956, -112.10000000000001, -44.659999999999755, -228.30999999999995, -89.94999999999962, -186.1399999999997, -23.980000000000004, -158.5399999999995, -126.6599999999999, -135.11999999999995, 70.15000000000013, -81.8199999999998, -141.65, 42.89999999999992, -21.96000000000004, -329.5700000000003, 11.429999999999954, -164.51999999999987, -125.64999999999999, 102.13000000000004, -182.4299999999999, -39.22000000000005, -108.31999999999995, -333.2700000000002, -16.189999999999404, -52.91000000000024, -149.35000000000093, -330.6800000000002, -108.05999999999943, -387.75999999999993, -429.89, -378.8, -97.8399999999997, -73.81999999999981, 14.180000000000113, -389.6600000000001, -312.7199999999999, -336.41000000000014, -127.09999999999985, -72.71000000000001, -74.89999999999968, -48.97000000000028, -273.39, -246.36, -278.3600000000005, -59.88000000000024, -34.37000000000065, -342.83000000000004, -208.87000000000003, -53.390000000000214, -193.8599999999999, -373.75, -358.75000000000006, -223.75, -212.03000000000006, -59.37000000000004, -250.59000000000015, -175.73000000000008, -67.53000000000006, -222.68000000000012, -246.27000000000024, -16.470000000000077, -185.43000000000063, -362.6700000000001, -96.3999999999998, -33.25999999999983, -166.45000000000093, -209.40000000000043, -257.7399999999995, -115.05999999999989, -41.51000000000018, -17.219999999999438, -65.33000000000042, -72.66999999999963, -75.17000000000007, -331.49, -48.020000000000124, -45.94000000000018, -167.40999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-116.11000000000064, -40.11999999999961, 6.559999999999999, -74.52999999999979, -34.32999999999996, -49.60000000000004, -4.240000000000112, -134.52999999999997, -11.020000000000007, -58.98999999999991, 67.07, 2.0000000000000013, -38.20000000000036, -38.650000000000006, -38.13999999999994, -73.71999999999986, -155.91999999999996, 2.0000000000000013, -129.97, -44.23000000000035, -47.950000000000195, -0.07000000000004114, -120.52000000000015, -30.90999999999947, -101.61999999999999, -31.780000000000015, -135.88, -163.11999999999983, -18.879999999999992, -35.6799999999999, 35.57000000000002, -94.63, 2.0000000000000013, -32.859999999999964, -23.77000000000004, -69.66999999999987, -104.16999999999993, -96.93999999999998, -126.52000000000027, -78.63999999999994, -212.65000000000015, -43.71999999999982, -167.83, -103.57, -86.88999999999993, -169.21000000000006, -38.0199999999999, -201.64000000000027, -242.49999999999983, -271.8100000000002, -6.040000000000042, -285.9100000000001, -186.63999999999982, -203.50000000000043, -60.72999999999987, -48.25000000000035, -262.78, -120.7600000000002, -148.74999999999991, -165.91000000000005, -123.48999999999995, -196.63000000000002, -20.109999999999705, 0.259999999999998, -2.020000000000042, -275.8000000000001, -139.48, -197.17000000000007, -15.189999999999744, -54.90999999999998, -217.96000000000004, 2.0000000000000013, -327.7900000000001, -313.7800000000002, -40.570000000000285, 2.0000000000000013, -99.90999999999988, -291.60999999999996, -193.5400000000001, -95.11, -39.36999999999992, 39.50000000000001, -268.96, -203.47000000000003, -60.519999999999996, -147.70000000000007, -175.57000000000016, -151.75000000000023, -290.56000000000006, -296.71000000000015, -18.099999999999703, -16.0899999999997, -290.85999999999996, -8.050000000000042, -108.54999999999926, -350.80000000000007, -303.85, -293.83000000000004, -393.97, -16.0899999999997, -376.0, -339.75999999999993, -392.98, -375.91, -359.98, -339.82, -300.82000000000005, -2.0200000000000418, -318.76, -10.060000000000041, -207.81999999999996, 2.0000000000000013, -334.74999999999994, -327.9100000000001, -296.7399999999999, -395.98, -304.69000000000005, -286.72, -276.46000000000004, -81.64000000000027, -267.37, -66.33999999999916, -377.89, -0.00999999999999836, 2.0000000000000013, -276.97, -260.40999999999997, -389.98, -223.50999999999993, -366.85, -350.98, -272.3800000000005, -288.84999999999997, -4.030000000000042, -54.28000000000034, -16.089999999999744, -379.92999999999995, -316.9, -199.09000000000003, -355.7800000000001, -0.00999999999999836, -248.38, -253.27000000000004, -281.5900000000004, -386.98, -353.77000000000004, -393.97, -343.78000000000003, -265.4500000000001, -232.2999999999999, -400.0, -193.0300000000001, -16.0899999999997, -252.28000000000011, -211.80999999999995, -355.7800000000001, -224.14, -266.59000000000026, -48.49000000000003, -207.04000000000008, -213.78999999999996, -377.89000000000004, -233.32000000000025, -365.95000000000005, 2.0000000000000013, -287.47000000000014, -160.81000000000043, -266.62000000000023, -350.8299999999999, -364.84000000000015, -260.5300000000002, -43.87000000000003, -2.020000000000042, -235.24000000000052, -342.72999999999985, -130.72000000000054, -261.5500000000004, -300.8499999999999, -242.4100000000001, -262.32999999999976, -110.55999999999993, -275.5, -70.35999999999962, -28.149999999999874, -42.220000000000354, 2.0000000000000013, -68.3499999999999, -179.97999999999948, -283.48000000000036, -36.19000000000002, -188.04999999999995, -22.119999999999706, -358.84000000000003, -329.65, -290.74000000000007, -54.28000000000034, 2.0000000000000013, -360.94, -339.7, -140.70999999999998], "policy_predator_policy_reward": [67.0, 57.0, 34.0, 82.0, 60.0, 65.0, 86.0, 73.0, 71.0, 39.0, 14.0, 31.0, 48.0, 55.0, 80.0, 27.0, 116.0, 1.0, 71.0, 80.0, 20.0, 31.0, 55.0, 68.0, 60.0, 92.0, 96.0, 103.0, 81.0, 62.0, 59.0, 79.0, 40.0, 44.0, 68.0, 57.0, 100.0, 71.0, 81.0, 111.0, 110.0, 79.0, 100.0, 127.0, 96.0, 48.0, 124.0, 71.0, 180.0, 106.0, 75.0, 127.0, 95.0, 109.0, 44.0, 41.0, 126.0, 99.0, 58.0, 130.0, 96.0, 89.0, 50.0, 40.0, 101.0, 95.0, 96.0, 99.0, 51.0, 62.0, 77.0, 117.0, 168.0, 144.0, 26.0, 24.0, 89.0, 138.0, 88.0, 75.0, 47.0, 55.0, 151.0, 139.0, 89.0, 80.0, 119.0, 100.0, 152.0, 102.0, 8.0, 10.0, 152.0, 94.0, 173.0, 137.0, 172.0, 95.0, 154.0, 148.0, 138.0, 190.0, 175.0, 164.0, 187.0, 134.0, 117.0, 88.0, 135.0, 120.0, 98.0, 122.0, 182.0, 91.0, 183.0, 197.0, 117.0, 138.0, 99.0, 132.0, 147.0, 114.0, 145.0, 158.0, 98.0, 128.0, 188.0, 189.0, 167.0, 177.0, 183.0, 162.0, 109.0, 124.0, 3.0, 33.0, 189.0, 165.0, 171.0, 175.0, 120.0, 75.0, 172.0, 169.0, 178.0, 189.0, 191.0, 188.0, 146.0, 128.0, 200.0, 181.0, 86.0, 123.0, 143.0, 174.0, 149.0, 166.0, 97.0, 91.0, 186.0, 183.0, 176.0, 177.0, 136.0, 133.0, 110.0, 132.0, 163.0, 190.0, 122.0, 86.0, 108.0, 96.0, 161.0, 146.0, 197.0, 156.0, 121.0, 126.0, 137.0, 134.0, 28.0, 29.0, 1.0, 22.0, 99.0, 84.0, 137.0, 110.0, 73.0, 62.0, 174.0, 183.0, 153.0, 144.0, 149.0, 164.0, 164.0, 149.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7010980334404507, "mean_inference_ms": 1.8820708287921308, "mean_action_processing_ms": 0.3140272626676978, "mean_env_wait_ms": 0.2385130418213396, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0074176788330078125, "StateBufferConnector_ms": 0.0033870935440063477, "ViewRequirementAgentConnector_ms": 0.09636902809143066}, "num_episodes": 18, "episode_return_max": 114.07000000000005, "episode_return_min": -429.89, "episode_return_mean": -117.87729999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.2954712698985, "num_env_steps_trained_throughput_per_sec": 362.2954712698985, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 11221.666, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11221.614, "sample_time_ms": 1331.674, "learn_time_ms": 9874.304, "learn_throughput": 405.092, "synch_weights_time_ms": 12.997}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "310e1_00000", "date": "2024-08-15_01-03-24", "timestamp": 1723664004, "time_this_iter_s": 11.089091777801514, "time_total_s": 360.27598428726196, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c6940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 360.27598428726196, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 48.15, "ram_util_percent": 83.47500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4690336549092855, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.555191801717042, "policy_loss": -0.005217125905534775, "vf_loss": 8.557764033413438, "vf_explained_var": -0.007223595513237847, "kl": 0.008816304379349079, "entropy": 1.3590977377361722, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5540621302115225, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.527229519748183, "policy_loss": -0.007060929695908079, "vf_loss": 7.533111208961124, "vf_explained_var": -0.3246576535638678, "kl": 0.01179262152212465, "entropy": 1.2738953803582167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 102.13000000000004, "episode_reward_min": -429.89, "episode_reward_mean": -124.16300000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.50000000000001, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -172.2115, "predator_policy": 110.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.980000000000004, -158.5399999999995, -126.6599999999999, -135.11999999999995, 70.15000000000013, -81.8199999999998, -141.65, 42.89999999999992, -21.96000000000004, -329.5700000000003, 11.429999999999954, -164.51999999999987, -125.64999999999999, 102.13000000000004, -182.4299999999999, -39.22000000000005, -108.31999999999995, -333.2700000000002, -16.189999999999404, -52.91000000000024, -149.35000000000093, -330.6800000000002, -108.05999999999943, -387.75999999999993, -429.89, -378.8, -97.8399999999997, -73.81999999999981, 14.180000000000113, -389.6600000000001, -312.7199999999999, -336.41000000000014, -127.09999999999985, -72.71000000000001, -74.89999999999968, -48.97000000000028, -273.39, -246.36, -278.3600000000005, -59.88000000000024, -34.37000000000065, -342.83000000000004, -208.87000000000003, -53.390000000000214, -193.8599999999999, -373.75, -358.75000000000006, -223.75, -212.03000000000006, -59.37000000000004, -250.59000000000015, -175.73000000000008, -67.53000000000006, -222.68000000000012, -246.27000000000024, -16.470000000000077, -185.43000000000063, -362.6700000000001, -96.3999999999998, -33.25999999999983, -166.45000000000093, -209.40000000000043, -257.7399999999995, -115.05999999999989, -41.51000000000018, -17.219999999999438, -65.33000000000042, -72.66999999999963, -75.17000000000007, -331.49, -48.020000000000124, -45.94000000000018, -167.40999999999997, -13.170000000000082, 29.12000000000019, -56.76000000000026, -57.37000000000049, -72.37999999999971, -17.209999999999802, -102.4699999999998, -68.32999999999983, -81.28999999999951, -21.069999999999894, -28.439999999999458, -14.340000000000074, -22.400000000000034, -56.37000000000036, -19.639999999999976, -4.669999999999816, 0.969999999999981, 13.33000000000013, -107.70000000000032, -75.78999999999999, -37.44000000000015, -3.2099999999998214, -149.52999999999966, -47.6800000000004, 2.8799999999999835, -67.90999999999964, -28.33999999999988], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-60.72999999999987, -48.25000000000035, -262.78, -120.7600000000002, -148.74999999999991, -165.91000000000005, -123.48999999999995, -196.63000000000002, -20.109999999999705, 0.259999999999998, -2.020000000000042, -275.8000000000001, -139.48, -197.17000000000007, -15.189999999999744, -54.90999999999998, -217.96000000000004, 2.0000000000000013, -327.7900000000001, -313.7800000000002, -40.570000000000285, 2.0000000000000013, -99.90999999999988, -291.60999999999996, -193.5400000000001, -95.11, -39.36999999999992, 39.50000000000001, -268.96, -203.47000000000003, -60.519999999999996, -147.70000000000007, -175.57000000000016, -151.75000000000023, -290.56000000000006, -296.71000000000015, -18.099999999999703, -16.0899999999997, -290.85999999999996, -8.050000000000042, -108.54999999999926, -350.80000000000007, -303.85, -293.83000000000004, -393.97, -16.0899999999997, -376.0, -339.75999999999993, -392.98, -375.91, -359.98, -339.82, -300.82000000000005, -2.0200000000000418, -318.76, -10.060000000000041, -207.81999999999996, 2.0000000000000013, -334.74999999999994, -327.9100000000001, -296.7399999999999, -395.98, -304.69000000000005, -286.72, -276.46000000000004, -81.64000000000027, -267.37, -66.33999999999916, -377.89, -0.00999999999999836, 2.0000000000000013, -276.97, -260.40999999999997, -389.98, -223.50999999999993, -366.85, -350.98, -272.3800000000005, -288.84999999999997, -4.030000000000042, -54.28000000000034, -16.089999999999744, -379.92999999999995, -316.9, -199.09000000000003, -355.7800000000001, -0.00999999999999836, -248.38, -253.27000000000004, -281.5900000000004, -386.98, -353.77000000000004, -393.97, -343.78000000000003, -265.4500000000001, -232.2999999999999, -400.0, -193.0300000000001, -16.0899999999997, -252.28000000000011, -211.80999999999995, -355.7800000000001, -224.14, -266.59000000000026, -48.49000000000003, -207.04000000000008, -213.78999999999996, -377.89000000000004, -233.32000000000025, -365.95000000000005, 2.0000000000000013, -287.47000000000014, -160.81000000000043, -266.62000000000023, -350.8299999999999, -364.84000000000015, -260.5300000000002, -43.87000000000003, -2.020000000000042, -235.24000000000052, -342.72999999999985, -130.72000000000054, -261.5500000000004, -300.8499999999999, -242.4100000000001, -262.32999999999976, -110.55999999999993, -275.5, -70.35999999999962, -28.149999999999874, -42.220000000000354, 2.0000000000000013, -68.3499999999999, -179.97999999999948, -283.48000000000036, -36.19000000000002, -188.04999999999995, -22.119999999999706, -358.84000000000003, -329.65, -290.74000000000007, -54.28000000000034, 2.0000000000000013, -360.94, -339.7, -140.70999999999998, -8.050000000000042, -22.120000000000022, -24.880000000000123, 2.0000000000000013, -47.25999999999989, -281.50000000000045, -20.109999999999705, -251.25999999999962, -143.74000000000115, -111.63999999999986, -16.0899999999997, -22.1199999999999, -82.41999999999975, -209.04999999999967, -94.83999999999986, -96.48999999999934, -30.159999999999712, -219.12999999999988, -213.07000000000002, 2.0000000000000013, -22.119999999999724, -62.320000000000334, -26.13999999999987, -38.20000000000036, -10.059999999999999, -234.33999999999992, -62.320000000000334, -185.05000000000086, -126.6399999999993, 2.0000000000000013, -195.5500000000001, -22.119999999999706, -4.030000000000042, 2.0000000000000013, -10.930000000000131, -146.74000000000098, -225.30999999999966, -76.38999999999982, -20.109999999999705, -302.6800000000002, -46.24000000000035, -38.20000000000006, -215.08000000000084, -54.130000000000166, -140.77000000000015, -351.7600000000002, -14.080000000000041, -253.5999999999998, -22.119999999999706, 2.0000000000000013, -152.77000000000015, -26.139999999999944, -62.319999999999915, -2.020000000000042], "policy_predator_policy_reward": [44.0, 41.0, 126.0, 99.0, 58.0, 130.0, 96.0, 89.0, 50.0, 40.0, 101.0, 95.0, 96.0, 99.0, 51.0, 62.0, 77.0, 117.0, 168.0, 144.0, 26.0, 24.0, 89.0, 138.0, 88.0, 75.0, 47.0, 55.0, 151.0, 139.0, 89.0, 80.0, 119.0, 100.0, 152.0, 102.0, 8.0, 10.0, 152.0, 94.0, 173.0, 137.0, 172.0, 95.0, 154.0, 148.0, 138.0, 190.0, 175.0, 164.0, 187.0, 134.0, 117.0, 88.0, 135.0, 120.0, 98.0, 122.0, 182.0, 91.0, 183.0, 197.0, 117.0, 138.0, 99.0, 132.0, 147.0, 114.0, 145.0, 158.0, 98.0, 128.0, 188.0, 189.0, 167.0, 177.0, 183.0, 162.0, 109.0, 124.0, 3.0, 33.0, 189.0, 165.0, 171.0, 175.0, 120.0, 75.0, 172.0, 169.0, 178.0, 189.0, 191.0, 188.0, 146.0, 128.0, 200.0, 181.0, 86.0, 123.0, 143.0, 174.0, 149.0, 166.0, 97.0, 91.0, 186.0, 183.0, 176.0, 177.0, 136.0, 133.0, 110.0, 132.0, 163.0, 190.0, 122.0, 86.0, 108.0, 96.0, 161.0, 146.0, 197.0, 156.0, 121.0, 126.0, 137.0, 134.0, 28.0, 29.0, 1.0, 22.0, 99.0, 84.0, 137.0, 110.0, 73.0, 62.0, 174.0, 183.0, 153.0, 144.0, 149.0, 164.0, 164.0, 149.0, 16.0, 1.0, 34.0, 18.0, 143.0, 129.0, 116.0, 98.0, 86.0, 97.0, 11.0, 10.0, 95.0, 94.0, 50.0, 73.0, 90.0, 78.0, 93.0, 97.0, 32.0, 24.0, 28.0, 22.0, 105.0, 117.0, 98.0, 93.0, 54.0, 51.0, 109.0, 104.0, 0.0, 3.0, 76.0, 95.0, 105.0, 89.0, 118.0, 129.0, 31.0, 16.0, 139.0, 127.0, 190.0, 153.0, 119.0, 101.0, 12.0, 11.0, 49.0, 62.0, 8.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6989238758834767, "mean_inference_ms": 1.8782711344528302, "mean_action_processing_ms": 0.31884622412870395, "mean_env_wait_ms": 0.23761267626089366, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007732748985290527, "StateBufferConnector_ms": 0.0036400556564331055, "ViewRequirementAgentConnector_ms": 0.10245227813720703}, "num_episodes": 27, "episode_return_max": 102.13000000000004, "episode_return_min": -429.89, "episode_return_mean": -124.16300000000001, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.39312710145765, "num_env_steps_trained_throughput_per_sec": 357.39312710145765, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 11231.855, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11231.804, "sample_time_ms": 1354.178, "learn_time_ms": 9862.377, "learn_throughput": 405.582, "synch_weights_time_ms": 12.79}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "310e1_00000", "date": "2024-08-15_01-03-35", "timestamp": 1723664015, "time_this_iter_s": 11.242927312850952, "time_total_s": 371.5189116001129, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c64c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 371.5189116001129, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 51.01875, "ram_util_percent": 83.13125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4273445331230366, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.240543595066777, "policy_loss": -0.005761434266062838, "vf_loss": 7.243193446265327, "vf_explained_var": -0.046667423008610966, "kl": 0.010371936641268986, "entropy": 1.3830732925228342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.990130863050935, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.263625590763395, "policy_loss": -0.006691553745980537, "vf_loss": 5.269312656745709, "vf_explained_var": -0.47661356938579097, "kl": 0.010045029079729395, "entropy": 1.27265089188934, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 29.12000000000019, "episode_reward_min": -429.89, "episode_reward_mean": -109.96630000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 24.650000000000258, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -154.09315000000004, "predator_policy": 99.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.189999999999404, -52.91000000000024, -149.35000000000093, -330.6800000000002, -108.05999999999943, -387.75999999999993, -429.89, -378.8, -97.8399999999997, -73.81999999999981, 14.180000000000113, -389.6600000000001, -312.7199999999999, -336.41000000000014, -127.09999999999985, -72.71000000000001, -74.89999999999968, -48.97000000000028, -273.39, -246.36, -278.3600000000005, -59.88000000000024, -34.37000000000065, -342.83000000000004, -208.87000000000003, -53.390000000000214, -193.8599999999999, -373.75, -358.75000000000006, -223.75, -212.03000000000006, -59.37000000000004, -250.59000000000015, -175.73000000000008, -67.53000000000006, -222.68000000000012, -246.27000000000024, -16.470000000000077, -185.43000000000063, -362.6700000000001, -96.3999999999998, -33.25999999999983, -166.45000000000093, -209.40000000000043, -257.7399999999995, -115.05999999999989, -41.51000000000018, -17.219999999999438, -65.33000000000042, -72.66999999999963, -75.17000000000007, -331.49, -48.020000000000124, -45.94000000000018, -167.40999999999997, -13.170000000000082, 29.12000000000019, -56.76000000000026, -57.37000000000049, -72.37999999999971, -17.209999999999802, -102.4699999999998, -68.32999999999983, -81.28999999999951, -21.069999999999894, -28.439999999999458, -14.340000000000074, -22.400000000000034, -56.37000000000036, -19.639999999999976, -4.669999999999816, 0.969999999999981, 13.33000000000013, -107.70000000000032, -75.78999999999999, -37.44000000000015, -3.2099999999998214, -149.52999999999966, -47.6800000000004, 2.8799999999999835, -67.90999999999964, -28.33999999999988, -19.74000000000001, -12.160000000000082, 1.3000000000000131, -53.550000000000665, -33.45000000000063, -43.470000000000695, -18.42999999999963, -21.669999999999504, -5.090000000000083, -9.440000000000069, 5.749999999999913, 7.0899999999999945, 1.7799999999999903, 5.829999999999921, -32.410000000000075, -23.49999999999955, -62.93000000000006, -12.340000000000076], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-18.099999999999703, -16.0899999999997, -290.85999999999996, -8.050000000000042, -108.54999999999926, -350.80000000000007, -303.85, -293.83000000000004, -393.97, -16.0899999999997, -376.0, -339.75999999999993, -392.98, -375.91, -359.98, -339.82, -300.82000000000005, -2.0200000000000418, -318.76, -10.060000000000041, -207.81999999999996, 2.0000000000000013, -334.74999999999994, -327.9100000000001, -296.7399999999999, -395.98, -304.69000000000005, -286.72, -276.46000000000004, -81.64000000000027, -267.37, -66.33999999999916, -377.89, -0.00999999999999836, 2.0000000000000013, -276.97, -260.40999999999997, -389.98, -223.50999999999993, -366.85, -350.98, -272.3800000000005, -288.84999999999997, -4.030000000000042, -54.28000000000034, -16.089999999999744, -379.92999999999995, -316.9, -199.09000000000003, -355.7800000000001, -0.00999999999999836, -248.38, -253.27000000000004, -281.5900000000004, -386.98, -353.77000000000004, -393.97, -343.78000000000003, -265.4500000000001, -232.2999999999999, -400.0, -193.0300000000001, -16.0899999999997, -252.28000000000011, -211.80999999999995, -355.7800000000001, -224.14, -266.59000000000026, -48.49000000000003, -207.04000000000008, -213.78999999999996, -377.89000000000004, -233.32000000000025, -365.95000000000005, 2.0000000000000013, -287.47000000000014, -160.81000000000043, -266.62000000000023, -350.8299999999999, -364.84000000000015, -260.5300000000002, -43.87000000000003, -2.020000000000042, -235.24000000000052, -342.72999999999985, -130.72000000000054, -261.5500000000004, -300.8499999999999, -242.4100000000001, -262.32999999999976, -110.55999999999993, -275.5, -70.35999999999962, -28.149999999999874, -42.220000000000354, 2.0000000000000013, -68.3499999999999, -179.97999999999948, -283.48000000000036, -36.19000000000002, -188.04999999999995, -22.119999999999706, -358.84000000000003, -329.65, -290.74000000000007, -54.28000000000034, 2.0000000000000013, -360.94, -339.7, -140.70999999999998, -8.050000000000042, -22.120000000000022, -24.880000000000123, 2.0000000000000013, -47.25999999999989, -281.50000000000045, -20.109999999999705, -251.25999999999962, -143.74000000000115, -111.63999999999986, -16.0899999999997, -22.1199999999999, -82.41999999999975, -209.04999999999967, -94.83999999999986, -96.48999999999934, -30.159999999999712, -219.12999999999988, -213.07000000000002, 2.0000000000000013, -22.119999999999724, -62.320000000000334, -26.13999999999987, -38.20000000000036, -10.059999999999999, -234.33999999999992, -62.320000000000334, -185.05000000000086, -126.6399999999993, 2.0000000000000013, -195.5500000000001, -22.119999999999706, -4.030000000000042, 2.0000000000000013, -10.930000000000131, -146.74000000000098, -225.30999999999966, -76.38999999999982, -20.109999999999705, -302.6800000000002, -46.24000000000035, -38.20000000000006, -215.08000000000084, -54.130000000000166, -140.77000000000015, -351.7600000000002, -14.080000000000041, -253.5999999999998, -22.119999999999706, 2.0000000000000013, -152.77000000000015, -26.139999999999944, -62.319999999999915, -2.020000000000042, -114.67000000000016, 5.9299999999999855, -28.14999999999971, -0.00999999999999836, 2.0000000000000013, -63.69999999999967, -50.260000000000325, -53.29000000000034, -6.040000000000042, -68.4099999999992, -46.24000000000035, -44.230000000000345, 2.0000000000000013, -54.43000000000026, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -83.4399999999992, 16.550000000000058, -158.80000000000092, -110.55999999999932, 24.650000000000258, -4.180000000000039, -6.040000000000042, 2.0000000000000013, -17.169999999999728, -24.130000000000003, -54.28000000000034, -18.099999999999703, -51.40000000000018, -147.82000000000016, -20.109999999999708, -8.050000000000018, -56.29000000000034], "policy_predator_policy_reward": [8.0, 10.0, 152.0, 94.0, 173.0, 137.0, 172.0, 95.0, 154.0, 148.0, 138.0, 190.0, 175.0, 164.0, 187.0, 134.0, 117.0, 88.0, 135.0, 120.0, 98.0, 122.0, 182.0, 91.0, 183.0, 197.0, 117.0, 138.0, 99.0, 132.0, 147.0, 114.0, 145.0, 158.0, 98.0, 128.0, 188.0, 189.0, 167.0, 177.0, 183.0, 162.0, 109.0, 124.0, 3.0, 33.0, 189.0, 165.0, 171.0, 175.0, 120.0, 75.0, 172.0, 169.0, 178.0, 189.0, 191.0, 188.0, 146.0, 128.0, 200.0, 181.0, 86.0, 123.0, 143.0, 174.0, 149.0, 166.0, 97.0, 91.0, 186.0, 183.0, 176.0, 177.0, 136.0, 133.0, 110.0, 132.0, 163.0, 190.0, 122.0, 86.0, 108.0, 96.0, 161.0, 146.0, 197.0, 156.0, 121.0, 126.0, 137.0, 134.0, 28.0, 29.0, 1.0, 22.0, 99.0, 84.0, 137.0, 110.0, 73.0, 62.0, 174.0, 183.0, 153.0, 144.0, 149.0, 164.0, 164.0, 149.0, 16.0, 1.0, 34.0, 18.0, 143.0, 129.0, 116.0, 98.0, 86.0, 97.0, 11.0, 10.0, 95.0, 94.0, 50.0, 73.0, 90.0, 78.0, 93.0, 97.0, 32.0, 24.0, 28.0, 22.0, 105.0, 117.0, 98.0, 93.0, 54.0, 51.0, 109.0, 104.0, 0.0, 3.0, 76.0, 95.0, 105.0, 89.0, 118.0, 129.0, 31.0, 16.0, 139.0, 127.0, 190.0, 153.0, 119.0, 101.0, 12.0, 11.0, 49.0, 62.0, 8.0, 28.0, 41.0, 48.0, 1.0, 15.0, 23.0, 40.0, 34.0, 16.0, 4.0, 37.0, 25.0, 22.0, 13.0, 21.0, 46.0, 63.0, 4.0, 5.0, 42.0, 30.0, 71.0, 77.0, 45.0, 48.0, 8.0, 4.0, 11.0, 10.0, 25.0, 21.0, 22.0, 24.0, 32.0, 73.0, 28.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6957996503992571, "mean_inference_ms": 1.871057965617901, "mean_action_processing_ms": 0.3157798632835391, "mean_env_wait_ms": 0.23640527950013074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054509639739990234, "StateBufferConnector_ms": 0.0037107467651367188, "ViewRequirementAgentConnector_ms": 0.10398221015930176}, "num_episodes": 18, "episode_return_max": 29.12000000000019, "episode_return_min": -429.89, "episode_return_mean": -109.96630000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.37894813711466, "num_env_steps_trained_throughput_per_sec": 366.37894813711466, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 11229.523, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11229.472, "sample_time_ms": 1350.689, "learn_time_ms": 9862.991, "learn_throughput": 405.557, "synch_weights_time_ms": 12.981}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "310e1_00000", "date": "2024-08-15_01-03-46", "timestamp": 1723664026, "time_this_iter_s": 10.967159986495972, "time_total_s": 382.4860715866089, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14d8e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 382.4860715866089, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 47.4, "ram_util_percent": 82.79333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.141841012270993, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.825627941050858, "policy_loss": -0.0022151105697192845, "vf_loss": 4.824712180712867, "vf_explained_var": 0.05613851966681304, "kl": 0.010436252771883292, "entropy": 1.4345473283182377, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.609168098338697, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0928140273169866, "policy_loss": -0.008567304807843236, "vf_loss": 3.100300952807936, "vf_explained_var": -0.38243582974035273, "kl": 0.010803805526909026, "entropy": 1.3096343309160263, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 46.23999999999954, "episode_reward_min": -373.75, "episode_reward_mean": -78.66170000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 48.46999999999971, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -118.72585000000001, "predator_policy": 79.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-273.39, -246.36, -278.3600000000005, -59.88000000000024, -34.37000000000065, -342.83000000000004, -208.87000000000003, -53.390000000000214, -193.8599999999999, -373.75, -358.75000000000006, -223.75, -212.03000000000006, -59.37000000000004, -250.59000000000015, -175.73000000000008, -67.53000000000006, -222.68000000000012, -246.27000000000024, -16.470000000000077, -185.43000000000063, -362.6700000000001, -96.3999999999998, -33.25999999999983, -166.45000000000093, -209.40000000000043, -257.7399999999995, -115.05999999999989, -41.51000000000018, -17.219999999999438, -65.33000000000042, -72.66999999999963, -75.17000000000007, -331.49, -48.020000000000124, -45.94000000000018, -167.40999999999997, -13.170000000000082, 29.12000000000019, -56.76000000000026, -57.37000000000049, -72.37999999999971, -17.209999999999802, -102.4699999999998, -68.32999999999983, -81.28999999999951, -21.069999999999894, -28.439999999999458, -14.340000000000074, -22.400000000000034, -56.37000000000036, -19.639999999999976, -4.669999999999816, 0.969999999999981, 13.33000000000013, -107.70000000000032, -75.78999999999999, -37.44000000000015, -3.2099999999998214, -149.52999999999966, -47.6800000000004, 2.8799999999999835, -67.90999999999964, -28.33999999999988, -19.74000000000001, -12.160000000000082, 1.3000000000000131, -53.550000000000665, -33.45000000000063, -43.470000000000695, -18.42999999999963, -21.669999999999504, -5.090000000000083, -9.440000000000069, 5.749999999999913, 7.0899999999999945, 1.7799999999999903, 5.829999999999921, -32.410000000000075, -23.49999999999955, -62.93000000000006, -12.340000000000076, -17.32999999999995, -9.320000000000077, 19.97000000000046, 42.219999999999416, -34.38000000000071, -23.26999999999945, -49.31000000000046, -64.80999999999958, -10.140000000000082, -61.940000000000104, -29.339999999999726, 46.23999999999954, -15.199999999999564, -7.200000000000081, -22.29999999999942, -29.64999999999969, 22.670000000000524, -0.040000000000040996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-260.40999999999997, -389.98, -223.50999999999993, -366.85, -350.98, -272.3800000000005, -288.84999999999997, -4.030000000000042, -54.28000000000034, -16.089999999999744, -379.92999999999995, -316.9, -199.09000000000003, -355.7800000000001, -0.00999999999999836, -248.38, -253.27000000000004, -281.5900000000004, -386.98, -353.77000000000004, -393.97, -343.78000000000003, -265.4500000000001, -232.2999999999999, -400.0, -193.0300000000001, -16.0899999999997, -252.28000000000011, -211.80999999999995, -355.7800000000001, -224.14, -266.59000000000026, -48.49000000000003, -207.04000000000008, -213.78999999999996, -377.89000000000004, -233.32000000000025, -365.95000000000005, 2.0000000000000013, -287.47000000000014, -160.81000000000043, -266.62000000000023, -350.8299999999999, -364.84000000000015, -260.5300000000002, -43.87000000000003, -2.020000000000042, -235.24000000000052, -342.72999999999985, -130.72000000000054, -261.5500000000004, -300.8499999999999, -242.4100000000001, -262.32999999999976, -110.55999999999993, -275.5, -70.35999999999962, -28.149999999999874, -42.220000000000354, 2.0000000000000013, -68.3499999999999, -179.97999999999948, -283.48000000000036, -36.19000000000002, -188.04999999999995, -22.119999999999706, -358.84000000000003, -329.65, -290.74000000000007, -54.28000000000034, 2.0000000000000013, -360.94, -339.7, -140.70999999999998, -8.050000000000042, -22.120000000000022, -24.880000000000123, 2.0000000000000013, -47.25999999999989, -281.50000000000045, -20.109999999999705, -251.25999999999962, -143.74000000000115, -111.63999999999986, -16.0899999999997, -22.1199999999999, -82.41999999999975, -209.04999999999967, -94.83999999999986, -96.48999999999934, -30.159999999999712, -219.12999999999988, -213.07000000000002, 2.0000000000000013, -22.119999999999724, -62.320000000000334, -26.13999999999987, -38.20000000000036, -10.059999999999999, -234.33999999999992, -62.320000000000334, -185.05000000000086, -126.6399999999993, 2.0000000000000013, -195.5500000000001, -22.119999999999706, -4.030000000000042, 2.0000000000000013, -10.930000000000131, -146.74000000000098, -225.30999999999966, -76.38999999999982, -20.109999999999705, -302.6800000000002, -46.24000000000035, -38.20000000000006, -215.08000000000084, -54.130000000000166, -140.77000000000015, -351.7600000000002, -14.080000000000041, -253.5999999999998, -22.119999999999706, 2.0000000000000013, -152.77000000000015, -26.139999999999944, -62.319999999999915, -2.020000000000042, -114.67000000000016, 5.9299999999999855, -28.14999999999971, -0.00999999999999836, 2.0000000000000013, -63.69999999999967, -50.260000000000325, -53.29000000000034, -6.040000000000042, -68.4099999999992, -46.24000000000035, -44.230000000000345, 2.0000000000000013, -54.43000000000026, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -83.4399999999992, 16.550000000000058, -158.80000000000092, -110.55999999999932, 24.650000000000258, -4.180000000000039, -6.040000000000042, 2.0000000000000013, -17.169999999999728, -24.130000000000003, -54.28000000000034, -18.099999999999703, -51.40000000000018, -147.82000000000016, -20.109999999999708, -8.050000000000018, -56.29000000000034, -27.189999999999884, -26.13999999999971, -14.080000000000041, -46.240000000000336, -96.48999999999926, 4.459999999999944, 48.46999999999971, -48.25000000000035, -42.220000000000354, -30.159999999999712, -2.020000000000042, -48.25000000000034, -98.67999999999944, -37.63000000000025, -91.50999999999927, -52.30000000000033, -6.040000000000042, -18.099999999999703, -54.28000000000034, -88.65999999999931, -16.0899999999997, -48.25000000000035, 22.340000000000142, -18.099999999999703, -30.159999999999712, -6.040000000000042, -20.109999999999847, -16.0899999999997, -26.13999999999971, -27.159999999999712, -22.359999999999744, -56.29000000000034, 2.0000000000000013, 1.6700000000000013, -2.020000000000042, -2.020000000000042], "policy_predator_policy_reward": [188.0, 189.0, 167.0, 177.0, 183.0, 162.0, 109.0, 124.0, 3.0, 33.0, 189.0, 165.0, 171.0, 175.0, 120.0, 75.0, 172.0, 169.0, 178.0, 189.0, 191.0, 188.0, 146.0, 128.0, 200.0, 181.0, 86.0, 123.0, 143.0, 174.0, 149.0, 166.0, 97.0, 91.0, 186.0, 183.0, 176.0, 177.0, 136.0, 133.0, 110.0, 132.0, 163.0, 190.0, 122.0, 86.0, 108.0, 96.0, 161.0, 146.0, 197.0, 156.0, 121.0, 126.0, 137.0, 134.0, 28.0, 29.0, 1.0, 22.0, 99.0, 84.0, 137.0, 110.0, 73.0, 62.0, 174.0, 183.0, 153.0, 144.0, 149.0, 164.0, 164.0, 149.0, 16.0, 1.0, 34.0, 18.0, 143.0, 129.0, 116.0, 98.0, 86.0, 97.0, 11.0, 10.0, 95.0, 94.0, 50.0, 73.0, 90.0, 78.0, 93.0, 97.0, 32.0, 24.0, 28.0, 22.0, 105.0, 117.0, 98.0, 93.0, 54.0, 51.0, 109.0, 104.0, 0.0, 3.0, 76.0, 95.0, 105.0, 89.0, 118.0, 129.0, 31.0, 16.0, 139.0, 127.0, 190.0, 153.0, 119.0, 101.0, 12.0, 11.0, 49.0, 62.0, 8.0, 28.0, 41.0, 48.0, 1.0, 15.0, 23.0, 40.0, 34.0, 16.0, 4.0, 37.0, 25.0, 22.0, 13.0, 21.0, 46.0, 63.0, 4.0, 5.0, 42.0, 30.0, 71.0, 77.0, 45.0, 48.0, 8.0, 4.0, 11.0, 10.0, 25.0, 21.0, 22.0, 24.0, 32.0, 73.0, 28.0, 24.0, 18.0, 18.0, 28.0, 23.0, 58.0, 54.0, 17.0, 25.0, 22.0, 16.0, 2.0, 25.0, 29.0, 58.0, 48.0, 31.0, 10.0, 4.0, 29.0, 52.0, 10.0, 25.0, 23.0, 19.0, 16.0, 5.0, 10.0, 19.0, 16.0, 15.0, 29.0, 20.0, 8.0, 11.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6933059624216714, "mean_inference_ms": 1.8630232883296247, "mean_action_processing_ms": 0.31384949171167814, "mean_env_wait_ms": 0.23537671507943994, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005464434623718262, "StateBufferConnector_ms": 0.003462076187133789, "ViewRequirementAgentConnector_ms": 0.1050882339477539}, "num_episodes": 18, "episode_return_max": 46.23999999999954, "episode_return_min": -373.75, "episode_return_mean": -78.66170000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.98607190183264, "num_env_steps_trained_throughput_per_sec": 366.98607190183264, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 11137.467, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11137.417, "sample_time_ms": 1346.548, "learn_time_ms": 9775.198, "learn_throughput": 409.199, "synch_weights_time_ms": 12.905}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "310e1_00000", "date": "2024-08-15_01-03-57", "timestamp": 1723664037, "time_this_iter_s": 10.939142942428589, "time_total_s": 393.4252145290375, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14df5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 393.4252145290375, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 46.787499999999994, "ram_util_percent": 82.66875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.192858664730869, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0980087692144687, "policy_loss": -0.01026002862712457, "vf_loss": 2.1060368622421586, "vf_explained_var": 0.032133213111332486, "kl": 0.007439788838360193, "entropy": 1.4450750958982599, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.566555800103637, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.286532081939556, "policy_loss": -0.008559376785590772, "vf_loss": 2.2940236126304305, "vf_explained_var": -0.014849053867279537, "kl": 0.010678416268773982, "entropy": 1.232761592398245, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 82.77000000000089, "episode_reward_min": -362.6700000000001, "episode_reward_mean": -44.43969999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -365.95000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 48.46999999999971, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -77.63485, "predator_policy": 55.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-246.27000000000024, -16.470000000000077, -185.43000000000063, -362.6700000000001, -96.3999999999998, -33.25999999999983, -166.45000000000093, -209.40000000000043, -257.7399999999995, -115.05999999999989, -41.51000000000018, -17.219999999999438, -65.33000000000042, -72.66999999999963, -75.17000000000007, -331.49, -48.020000000000124, -45.94000000000018, -167.40999999999997, -13.170000000000082, 29.12000000000019, -56.76000000000026, -57.37000000000049, -72.37999999999971, -17.209999999999802, -102.4699999999998, -68.32999999999983, -81.28999999999951, -21.069999999999894, -28.439999999999458, -14.340000000000074, -22.400000000000034, -56.37000000000036, -19.639999999999976, -4.669999999999816, 0.969999999999981, 13.33000000000013, -107.70000000000032, -75.78999999999999, -37.44000000000015, -3.2099999999998214, -149.52999999999966, -47.6800000000004, 2.8799999999999835, -67.90999999999964, -28.33999999999988, -19.74000000000001, -12.160000000000082, 1.3000000000000131, -53.550000000000665, -33.45000000000063, -43.470000000000695, -18.42999999999963, -21.669999999999504, -5.090000000000083, -9.440000000000069, 5.749999999999913, 7.0899999999999945, 1.7799999999999903, 5.829999999999921, -32.410000000000075, -23.49999999999955, -62.93000000000006, -12.340000000000076, -17.32999999999995, -9.320000000000077, 19.97000000000046, 42.219999999999416, -34.38000000000071, -23.26999999999945, -49.31000000000046, -64.80999999999958, -10.140000000000082, -61.940000000000104, -29.339999999999726, 46.23999999999954, -15.199999999999564, -7.200000000000081, -22.29999999999942, -29.64999999999969, 22.670000000000524, -0.040000000000040996, 82.77000000000089, -4.250000000000076, -18.24999999999945, 29.580000000000506, -2.160000000000079, -36.600000000000676, 28.110000000000408, -21.259999999999415, -0.040000000000040996, 0.40000000000004493, -2.120000000000081, -90.94999999999844, -1.0900000000000614, -41.360000000000724, -45.58000000000067, 21.530000000000527, -20.239999999999437, -91.77999999999835], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-233.32000000000025, -365.95000000000005, 2.0000000000000013, -287.47000000000014, -160.81000000000043, -266.62000000000023, -350.8299999999999, -364.84000000000015, -260.5300000000002, -43.87000000000003, -2.020000000000042, -235.24000000000052, -342.72999999999985, -130.72000000000054, -261.5500000000004, -300.8499999999999, -242.4100000000001, -262.32999999999976, -110.55999999999993, -275.5, -70.35999999999962, -28.149999999999874, -42.220000000000354, 2.0000000000000013, -68.3499999999999, -179.97999999999948, -283.48000000000036, -36.19000000000002, -188.04999999999995, -22.119999999999706, -358.84000000000003, -329.65, -290.74000000000007, -54.28000000000034, 2.0000000000000013, -360.94, -339.7, -140.70999999999998, -8.050000000000042, -22.120000000000022, -24.880000000000123, 2.0000000000000013, -47.25999999999989, -281.50000000000045, -20.109999999999705, -251.25999999999962, -143.74000000000115, -111.63999999999986, -16.0899999999997, -22.1199999999999, -82.41999999999975, -209.04999999999967, -94.83999999999986, -96.48999999999934, -30.159999999999712, -219.12999999999988, -213.07000000000002, 2.0000000000000013, -22.119999999999724, -62.320000000000334, -26.13999999999987, -38.20000000000036, -10.059999999999999, -234.33999999999992, -62.320000000000334, -185.05000000000086, -126.6399999999993, 2.0000000000000013, -195.5500000000001, -22.119999999999706, -4.030000000000042, 2.0000000000000013, -10.930000000000131, -146.74000000000098, -225.30999999999966, -76.38999999999982, -20.109999999999705, -302.6800000000002, -46.24000000000035, -38.20000000000006, -215.08000000000084, -54.130000000000166, -140.77000000000015, -351.7600000000002, -14.080000000000041, -253.5999999999998, -22.119999999999706, 2.0000000000000013, -152.77000000000015, -26.139999999999944, -62.319999999999915, -2.020000000000042, -114.67000000000016, 5.9299999999999855, -28.14999999999971, -0.00999999999999836, 2.0000000000000013, -63.69999999999967, -50.260000000000325, -53.29000000000034, -6.040000000000042, -68.4099999999992, -46.24000000000035, -44.230000000000345, 2.0000000000000013, -54.43000000000026, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -83.4399999999992, 16.550000000000058, -158.80000000000092, -110.55999999999932, 24.650000000000258, -4.180000000000039, -6.040000000000042, 2.0000000000000013, -17.169999999999728, -24.130000000000003, -54.28000000000034, -18.099999999999703, -51.40000000000018, -147.82000000000016, -20.109999999999708, -8.050000000000018, -56.29000000000034, -27.189999999999884, -26.13999999999971, -14.080000000000041, -46.240000000000336, -96.48999999999926, 4.459999999999944, 48.46999999999971, -48.25000000000035, -42.220000000000354, -30.159999999999712, -2.020000000000042, -48.25000000000034, -98.67999999999944, -37.63000000000025, -91.50999999999927, -52.30000000000033, -6.040000000000042, -18.099999999999703, -54.28000000000034, -88.65999999999931, -16.0899999999997, -48.25000000000035, 22.340000000000142, -18.099999999999703, -30.159999999999712, -6.040000000000042, -20.109999999999847, -16.0899999999997, -26.13999999999971, -27.159999999999712, -22.359999999999744, -56.29000000000034, 2.0000000000000013, 1.6700000000000013, -2.020000000000042, -2.020000000000042, 10.58000000000003, 46.189999999999856, 2.0000000000000013, -48.25000000000035, -48.25000000000035, 2.0000000000000013, 16.58000000000007, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -58.30000000000034, -34.30000000000034, 20.240000000000194, -24.129999999999715, -22.119999999999706, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -32.170000000000364, -12.429999999999994, -22.119999999999706, 2.0000000000000013, -82.41999999999919, -65.52999999999925, 2.0000000000000013, -16.0899999999997, -29.19999999999984, -30.159999999999712, -28.14999999999971, -84.4299999999992, -30.159999999999716, 32.69000000000002, -2.020000000000042, -42.220000000000354, -60.310000000000336, -92.46999999999922], "policy_predator_policy_reward": [176.0, 177.0, 136.0, 133.0, 110.0, 132.0, 163.0, 190.0, 122.0, 86.0, 108.0, 96.0, 161.0, 146.0, 197.0, 156.0, 121.0, 126.0, 137.0, 134.0, 28.0, 29.0, 1.0, 22.0, 99.0, 84.0, 137.0, 110.0, 73.0, 62.0, 174.0, 183.0, 153.0, 144.0, 149.0, 164.0, 164.0, 149.0, 16.0, 1.0, 34.0, 18.0, 143.0, 129.0, 116.0, 98.0, 86.0, 97.0, 11.0, 10.0, 95.0, 94.0, 50.0, 73.0, 90.0, 78.0, 93.0, 97.0, 32.0, 24.0, 28.0, 22.0, 105.0, 117.0, 98.0, 93.0, 54.0, 51.0, 109.0, 104.0, 0.0, 3.0, 76.0, 95.0, 105.0, 89.0, 118.0, 129.0, 31.0, 16.0, 139.0, 127.0, 190.0, 153.0, 119.0, 101.0, 12.0, 11.0, 49.0, 62.0, 8.0, 28.0, 41.0, 48.0, 1.0, 15.0, 23.0, 40.0, 34.0, 16.0, 4.0, 37.0, 25.0, 22.0, 13.0, 21.0, 46.0, 63.0, 4.0, 5.0, 42.0, 30.0, 71.0, 77.0, 45.0, 48.0, 8.0, 4.0, 11.0, 10.0, 25.0, 21.0, 22.0, 24.0, 32.0, 73.0, 28.0, 24.0, 18.0, 18.0, 28.0, 23.0, 58.0, 54.0, 17.0, 25.0, 22.0, 16.0, 2.0, 25.0, 29.0, 58.0, 48.0, 31.0, 10.0, 4.0, 29.0, 52.0, 10.0, 25.0, 23.0, 19.0, 16.0, 5.0, 10.0, 19.0, 16.0, 15.0, 29.0, 20.0, 8.0, 11.0, 2.0, 2.0, 12.0, 14.0, 17.0, 25.0, 3.0, 25.0, 9.0, 2.0, 16.0, 10.0, 30.0, 26.0, 15.0, 17.0, 14.0, 13.0, 4.0, 0.0, 10.0, 35.0, 6.0, 12.0, 45.0, 12.0, 4.0, 9.0, 0.0, 18.0, 35.0, 32.0, 3.0, 16.0, 22.0, 2.0, 47.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6912646576976675, "mean_inference_ms": 1.8574512361421873, "mean_action_processing_ms": 0.3122310926778079, "mean_env_wait_ms": 0.23454541334746487, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005406737327575684, "StateBufferConnector_ms": 0.003358125686645508, "ViewRequirementAgentConnector_ms": 0.10522997379302979}, "num_episodes": 18, "episode_return_max": 82.77000000000089, "episode_return_min": -362.6700000000001, "episode_return_mean": -44.43969999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.83216857195214, "num_env_steps_trained_throughput_per_sec": 357.83216857195214, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 11162.435, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11162.385, "sample_time_ms": 1367.299, "learn_time_ms": 9779.147, "learn_throughput": 409.034, "synch_weights_time_ms": 12.983}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "310e1_00000", "date": "2024-08-15_01-04-09", "timestamp": 1723664049, "time_this_iter_s": 11.227082014083862, "time_total_s": 404.65229654312134, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c64c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 404.65229654312134, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 57.01875, "ram_util_percent": 83.1875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2104346936341948, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.265801237310682, "policy_loss": -0.008339956243123328, "vf_loss": 1.2727088441924443, "vf_explained_var": -0.026983368743664374, "kl": 0.004774497677735397, "entropy": 1.4455551004283642, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.270283257740515, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.664649885104447, "policy_loss": -0.004156960407148791, "vf_loss": 1.6681078992192708, "vf_explained_var": 0.08879872658265331, "kl": 0.006989461849137144, "entropy": 1.149667155616498, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 112.72000000000084, "episode_reward_min": -149.52999999999966, "episode_reward_mean": -15.641899999999898, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.7600000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 97.73000000000033, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -41.015949999999954, "predator_policy": 33.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-57.37000000000049, -72.37999999999971, -17.209999999999802, -102.4699999999998, -68.32999999999983, -81.28999999999951, -21.069999999999894, -28.439999999999458, -14.340000000000074, -22.400000000000034, -56.37000000000036, -19.639999999999976, -4.669999999999816, 0.969999999999981, 13.33000000000013, -107.70000000000032, -75.78999999999999, -37.44000000000015, -3.2099999999998214, -149.52999999999966, -47.6800000000004, 2.8799999999999835, -67.90999999999964, -28.33999999999988, -19.74000000000001, -12.160000000000082, 1.3000000000000131, -53.550000000000665, -33.45000000000063, -43.470000000000695, -18.42999999999963, -21.669999999999504, -5.090000000000083, -9.440000000000069, 5.749999999999913, 7.0899999999999945, 1.7799999999999903, 5.829999999999921, -32.410000000000075, -23.49999999999955, -62.93000000000006, -12.340000000000076, -17.32999999999995, -9.320000000000077, 19.97000000000046, 42.219999999999416, -34.38000000000071, -23.26999999999945, -49.31000000000046, -64.80999999999958, -10.140000000000082, -61.940000000000104, -29.339999999999726, 46.23999999999954, -15.199999999999564, -7.200000000000081, -22.29999999999942, -29.64999999999969, 22.670000000000524, -0.040000000000040996, 82.77000000000089, -4.250000000000076, -18.24999999999945, 29.580000000000506, -2.160000000000079, -36.600000000000676, 28.110000000000408, -21.259999999999415, -0.040000000000040996, 0.40000000000004493, -2.120000000000081, -90.94999999999844, -1.0900000000000614, -41.360000000000724, -45.58000000000067, 21.530000000000527, -20.239999999999437, -91.77999999999835, -5.190000000000078, -10.420000000000076, 95.00000000000117, 0.609999999999972, -34.38000000000067, -27.309999999999427, 112.72000000000084, 53.97999999999949, -27.25999999999942, 16.54000000000002, -25.66999999999978, 104.30000000000118, -29.429999999999893, 63.22999999999971, 19.24000000000037, -6.100000000000083, 2.430000000000337, -18.53999999999947, -30.449999999999562, 7.919999999999916, -41.450000000000706, 65.29000000000029], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-20.109999999999705, -251.25999999999962, -143.74000000000115, -111.63999999999986, -16.0899999999997, -22.1199999999999, -82.41999999999975, -209.04999999999967, -94.83999999999986, -96.48999999999934, -30.159999999999712, -219.12999999999988, -213.07000000000002, 2.0000000000000013, -22.119999999999724, -62.320000000000334, -26.13999999999987, -38.20000000000036, -10.059999999999999, -234.33999999999992, -62.320000000000334, -185.05000000000086, -126.6399999999993, 2.0000000000000013, -195.5500000000001, -22.119999999999706, -4.030000000000042, 2.0000000000000013, -10.930000000000131, -146.74000000000098, -225.30999999999966, -76.38999999999982, -20.109999999999705, -302.6800000000002, -46.24000000000035, -38.20000000000006, -215.08000000000084, -54.130000000000166, -140.77000000000015, -351.7600000000002, -14.080000000000041, -253.5999999999998, -22.119999999999706, 2.0000000000000013, -152.77000000000015, -26.139999999999944, -62.319999999999915, -2.020000000000042, -114.67000000000016, 5.9299999999999855, -28.14999999999971, -0.00999999999999836, 2.0000000000000013, -63.69999999999967, -50.260000000000325, -53.29000000000034, -6.040000000000042, -68.4099999999992, -46.24000000000035, -44.230000000000345, 2.0000000000000013, -54.43000000000026, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -83.4399999999992, 16.550000000000058, -158.80000000000092, -110.55999999999932, 24.650000000000258, -4.180000000000039, -6.040000000000042, 2.0000000000000013, -17.169999999999728, -24.130000000000003, -54.28000000000034, -18.099999999999703, -51.40000000000018, -147.82000000000016, -20.109999999999708, -8.050000000000018, -56.29000000000034, -27.189999999999884, -26.13999999999971, -14.080000000000041, -46.240000000000336, -96.48999999999926, 4.459999999999944, 48.46999999999971, -48.25000000000035, -42.220000000000354, -30.159999999999712, -2.020000000000042, -48.25000000000034, -98.67999999999944, -37.63000000000025, -91.50999999999927, -52.30000000000033, -6.040000000000042, -18.099999999999703, -54.28000000000034, -88.65999999999931, -16.0899999999997, -48.25000000000035, 22.340000000000142, -18.099999999999703, -30.159999999999712, -6.040000000000042, -20.109999999999847, -16.0899999999997, -26.13999999999971, -27.159999999999712, -22.359999999999744, -56.29000000000034, 2.0000000000000013, 1.6700000000000013, -2.020000000000042, -2.020000000000042, 10.58000000000003, 46.189999999999856, 2.0000000000000013, -48.25000000000035, -48.25000000000035, 2.0000000000000013, 16.58000000000007, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -58.30000000000034, -34.30000000000034, 20.240000000000194, -24.129999999999715, -22.119999999999706, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -32.170000000000364, -12.429999999999994, -22.119999999999706, 2.0000000000000013, -82.41999999999919, -65.52999999999925, 2.0000000000000013, -16.0899999999997, -29.19999999999984, -30.159999999999712, -28.14999999999971, -84.4299999999992, -30.159999999999716, 32.69000000000002, -2.020000000000042, -42.220000000000354, -60.310000000000336, -92.46999999999922, -16.0899999999997, -18.099999999999724, -12.070000000000041, -53.35000000000033, -4.030000000000038, 95.03000000000053, -4.030000000000021, -19.359999999999744, -56.29000000000034, -16.0899999999997, -28.14999999999971, -30.159999999999716, 97.73000000000033, -0.00999999999999836, -50.260000000000346, 77.24000000000063, -26.139999999999713, -22.119999999999706, -18.099999999999703, 16.64000000000008, 2.720000000000071, -76.38999999999996, -7.930000000000023, 78.23000000000063, -28.149999999999714, -39.28000000000034, -0.00999999999999836, 47.239999999999824, 2.0000000000000013, -12.76000000000024, -6.040000000000042, -10.060000000000041, -46.24000000000025, 19.670000000000023, -0.1899999999999984, -62.35000000000033, -64.32999999999917, -22.11999999999986, -6.040000000000042, 5.959999999999958, -40.210000000000356, -46.24000000000035, 56.44999999999971, -0.1599999999999986], "policy_predator_policy_reward": [116.0, 98.0, 86.0, 97.0, 11.0, 10.0, 95.0, 94.0, 50.0, 73.0, 90.0, 78.0, 93.0, 97.0, 32.0, 24.0, 28.0, 22.0, 105.0, 117.0, 98.0, 93.0, 54.0, 51.0, 109.0, 104.0, 0.0, 3.0, 76.0, 95.0, 105.0, 89.0, 118.0, 129.0, 31.0, 16.0, 139.0, 127.0, 190.0, 153.0, 119.0, 101.0, 12.0, 11.0, 49.0, 62.0, 8.0, 28.0, 41.0, 48.0, 1.0, 15.0, 23.0, 40.0, 34.0, 16.0, 4.0, 37.0, 25.0, 22.0, 13.0, 21.0, 46.0, 63.0, 4.0, 5.0, 42.0, 30.0, 71.0, 77.0, 45.0, 48.0, 8.0, 4.0, 11.0, 10.0, 25.0, 21.0, 22.0, 24.0, 32.0, 73.0, 28.0, 24.0, 18.0, 18.0, 28.0, 23.0, 58.0, 54.0, 17.0, 25.0, 22.0, 16.0, 2.0, 25.0, 29.0, 58.0, 48.0, 31.0, 10.0, 4.0, 29.0, 52.0, 10.0, 25.0, 23.0, 19.0, 16.0, 5.0, 10.0, 19.0, 16.0, 15.0, 29.0, 20.0, 8.0, 11.0, 2.0, 2.0, 12.0, 14.0, 17.0, 25.0, 3.0, 25.0, 9.0, 2.0, 16.0, 10.0, 30.0, 26.0, 15.0, 17.0, 14.0, 13.0, 4.0, 0.0, 10.0, 35.0, 6.0, 12.0, 45.0, 12.0, 4.0, 9.0, 0.0, 18.0, 35.0, 32.0, 3.0, 16.0, 22.0, 2.0, 47.0, 14.0, 18.0, 11.0, 35.0, 20.0, 0.0, 4.0, 5.0, 19.0, 29.0, 9.0, 16.0, 15.0, 5.0, 10.0, 26.0, 1.0, 16.0, 5.0, 9.0, 9.0, 35.0, 13.0, 0.0, 34.0, 23.0, 15.0, 10.0, 6.0, 0.0, 30.0, 4.0, 6.0, 24.0, 5.0, 26.0, 18.0, 33.0, 23.0, 4.0, 4.0, 24.0, 21.0, 3.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6886150679324331, "mean_inference_ms": 1.8517499020494108, "mean_action_processing_ms": 0.3095981576070169, "mean_env_wait_ms": 0.23380884756070514, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004805922508239746, "StateBufferConnector_ms": 0.003327012062072754, "ViewRequirementAgentConnector_ms": 0.10929083824157715}, "num_episodes": 22, "episode_return_max": 112.72000000000084, "episode_return_min": -149.52999999999966, "episode_return_mean": -15.641899999999898, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.63076747772294, "num_env_steps_trained_throughput_per_sec": 369.63076747772294, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 11121.712, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11121.662, "sample_time_ms": 1376.851, "learn_time_ms": 9728.746, "learn_throughput": 411.153, "synch_weights_time_ms": 13.071}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "310e1_00000", "date": "2024-08-15_01-04-20", "timestamp": 1723664060, "time_this_iter_s": 10.890527963638306, "time_total_s": 415.54282450675964, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 415.54282450675964, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 56.686666666666675, "ram_util_percent": 83.10666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.835384175922505, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4904106989739434, "policy_loss": -0.006282527059582727, "vf_loss": 1.495937117413869, "vf_explained_var": 0.016182161102849972, "kl": 0.00504074411207365, "entropy": 1.4452024891262962, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.407785828214474, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2065212046658553, "policy_loss": -0.007298268550124867, "vf_loss": 2.2125297262555077, "vf_explained_var": -0.029919220846166057, "kl": 0.012897497075395014, "entropy": 1.1787018584195899, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 112.76000000000084, "episode_reward_min": -91.77999999999835, "episode_reward_mean": -6.487799999999863, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -172.87000000000077, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 97.76000000000032, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": -22.873899999999953, "predator_policy": 19.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.33999999999988, -19.74000000000001, -12.160000000000082, 1.3000000000000131, -53.550000000000665, -33.45000000000063, -43.470000000000695, -18.42999999999963, -21.669999999999504, -5.090000000000083, -9.440000000000069, 5.749999999999913, 7.0899999999999945, 1.7799999999999903, 5.829999999999921, -32.410000000000075, -23.49999999999955, -62.93000000000006, -12.340000000000076, -17.32999999999995, -9.320000000000077, 19.97000000000046, 42.219999999999416, -34.38000000000071, -23.26999999999945, -49.31000000000046, -64.80999999999958, -10.140000000000082, -61.940000000000104, -29.339999999999726, 46.23999999999954, -15.199999999999564, -7.200000000000081, -22.29999999999942, -29.64999999999969, 22.670000000000524, -0.040000000000040996, 82.77000000000089, -4.250000000000076, -18.24999999999945, 29.580000000000506, -2.160000000000079, -36.600000000000676, 28.110000000000408, -21.259999999999415, -0.040000000000040996, 0.40000000000004493, -2.120000000000081, -90.94999999999844, -1.0900000000000614, -41.360000000000724, -45.58000000000067, 21.530000000000527, -20.239999999999437, -91.77999999999835, -5.190000000000078, -10.420000000000076, 95.00000000000117, 0.609999999999972, -34.38000000000067, -27.309999999999427, 112.72000000000084, 53.97999999999949, -27.25999999999942, 16.54000000000002, -25.66999999999978, 104.30000000000118, -29.429999999999893, 63.22999999999971, 19.24000000000037, -6.100000000000083, 2.430000000000337, -18.53999999999947, -30.449999999999562, 7.919999999999916, -41.450000000000706, 65.29000000000029, 21.110000000000458, -14.519999999999731, 0.969999999999981, 112.76000000000084, -18.010000000000225, -33.48000000000009, 19.490000000000315, -15.18999999999956, 21.680000000000526, -41.74000000000036, 17.660000000000206, 1.980000000000003, 3.4199999999999657, -75.92999999999857, 0.6299999999999887, -36.4000000000007, -80.94999999999844, -0.04000000000004011, -3.1500000000000794, -4.080000000000084, -15.199999999999635, -18.289999999999477, 34.6299999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-62.319999999999915, -2.020000000000042, -114.67000000000016, 5.9299999999999855, -28.14999999999971, -0.00999999999999836, 2.0000000000000013, -63.69999999999967, -50.260000000000325, -53.29000000000034, -6.040000000000042, -68.4099999999992, -46.24000000000035, -44.230000000000345, 2.0000000000000013, -54.43000000000026, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -83.4399999999992, 16.550000000000058, -158.80000000000092, -110.55999999999932, 24.650000000000258, -4.180000000000039, -6.040000000000042, 2.0000000000000013, -17.169999999999728, -24.130000000000003, -54.28000000000034, -18.099999999999703, -51.40000000000018, -147.82000000000016, -20.109999999999708, -8.050000000000018, -56.29000000000034, -27.189999999999884, -26.13999999999971, -14.080000000000041, -46.240000000000336, -96.48999999999926, 4.459999999999944, 48.46999999999971, -48.25000000000035, -42.220000000000354, -30.159999999999712, -2.020000000000042, -48.25000000000034, -98.67999999999944, -37.63000000000025, -91.50999999999927, -52.30000000000033, -6.040000000000042, -18.099999999999703, -54.28000000000034, -88.65999999999931, -16.0899999999997, -48.25000000000035, 22.340000000000142, -18.099999999999703, -30.159999999999712, -6.040000000000042, -20.109999999999847, -16.0899999999997, -26.13999999999971, -27.159999999999712, -22.359999999999744, -56.29000000000034, 2.0000000000000013, 1.6700000000000013, -2.020000000000042, -2.020000000000042, 10.58000000000003, 46.189999999999856, 2.0000000000000013, -48.25000000000035, -48.25000000000035, 2.0000000000000013, 16.58000000000007, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -58.30000000000034, -34.30000000000034, 20.240000000000194, -24.129999999999715, -22.119999999999706, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -32.170000000000364, -12.429999999999994, -22.119999999999706, 2.0000000000000013, -82.41999999999919, -65.52999999999925, 2.0000000000000013, -16.0899999999997, -29.19999999999984, -30.159999999999712, -28.14999999999971, -84.4299999999992, -30.159999999999716, 32.69000000000002, -2.020000000000042, -42.220000000000354, -60.310000000000336, -92.46999999999922, -16.0899999999997, -18.099999999999724, -12.070000000000041, -53.35000000000033, -4.030000000000038, 95.03000000000053, -4.030000000000021, -19.359999999999744, -56.29000000000034, -16.0899999999997, -28.14999999999971, -30.159999999999716, 97.73000000000033, -0.00999999999999836, -50.260000000000346, 77.24000000000063, -26.139999999999713, -22.119999999999706, -18.099999999999703, 16.64000000000008, 2.720000000000071, -76.38999999999996, -7.930000000000023, 78.23000000000063, -28.149999999999714, -39.28000000000034, -0.00999999999999836, 47.239999999999824, 2.0000000000000013, -12.76000000000024, -6.040000000000042, -10.060000000000041, -46.24000000000025, 19.670000000000023, -0.1899999999999984, -62.35000000000033, -64.32999999999917, -22.11999999999986, -6.040000000000042, 5.959999999999958, -40.210000000000356, -46.24000000000035, 56.44999999999971, -0.1599999999999986, 13.459999999999969, -26.349999999999742, -48.25000000000033, -4.270000000000037, -4.030000000000042, 2.0000000000000013, 97.76000000000032, 2.0000000000000013, 37.57999999999994, -116.58999999999943, -172.87000000000077, 47.38999999999972, 24.770000000000216, -54.28000000000034, -26.13999999999971, -8.050000000000042, 12.679999999999964, 2.0000000000000013, -146.74000000000086, 2.0000000000000013, 8.810000000000047, 4.849999999999989, 2.0000000000000013, -2.020000000000042, -19.419999999999757, -30.15999999999972, -109.65999999999931, -52.27000000000033, 2.0000000000000013, -72.36999999999917, -48.25000000000034, -28.14999999999972, -72.39999999999918, -78.54999999999926, 2.0000000000000013, -6.040000000000042, -0.009999999999998581, -26.13999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -38.200000000000315, 4.969999999999958, -50.26000000000033, 2.0000000000000013, 23.630000000000255], "policy_predator_policy_reward": [8.0, 28.0, 41.0, 48.0, 1.0, 15.0, 23.0, 40.0, 34.0, 16.0, 4.0, 37.0, 25.0, 22.0, 13.0, 21.0, 46.0, 63.0, 4.0, 5.0, 42.0, 30.0, 71.0, 77.0, 45.0, 48.0, 8.0, 4.0, 11.0, 10.0, 25.0, 21.0, 22.0, 24.0, 32.0, 73.0, 28.0, 24.0, 18.0, 18.0, 28.0, 23.0, 58.0, 54.0, 17.0, 25.0, 22.0, 16.0, 2.0, 25.0, 29.0, 58.0, 48.0, 31.0, 10.0, 4.0, 29.0, 52.0, 10.0, 25.0, 23.0, 19.0, 16.0, 5.0, 10.0, 19.0, 16.0, 15.0, 29.0, 20.0, 8.0, 11.0, 2.0, 2.0, 12.0, 14.0, 17.0, 25.0, 3.0, 25.0, 9.0, 2.0, 16.0, 10.0, 30.0, 26.0, 15.0, 17.0, 14.0, 13.0, 4.0, 0.0, 10.0, 35.0, 6.0, 12.0, 45.0, 12.0, 4.0, 9.0, 0.0, 18.0, 35.0, 32.0, 3.0, 16.0, 22.0, 2.0, 47.0, 14.0, 18.0, 11.0, 35.0, 20.0, 0.0, 4.0, 5.0, 19.0, 29.0, 9.0, 16.0, 15.0, 5.0, 10.0, 26.0, 1.0, 16.0, 5.0, 9.0, 9.0, 35.0, 13.0, 0.0, 34.0, 23.0, 15.0, 10.0, 6.0, 0.0, 30.0, 4.0, 6.0, 24.0, 5.0, 26.0, 18.0, 33.0, 23.0, 4.0, 4.0, 24.0, 21.0, 3.0, 6.0, 23.0, 11.0, 16.0, 22.0, 0.0, 3.0, 7.0, 6.0, 59.0, 2.0, 87.0, 5.0, 28.0, 21.0, 14.0, 5.0, 0.0, 7.0, 72.0, 31.0, 0.0, 4.0, 0.0, 2.0, 26.0, 27.0, 27.0, 59.0, 36.0, 35.0, 25.0, 15.0, 42.0, 28.0, 4.0, 0.0, 15.0, 8.0, 1.0, 7.0, 20.0, 1.0, 24.0, 3.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6861689845960668, "mean_inference_ms": 1.8441878861815604, "mean_action_processing_ms": 0.3083168010514377, "mean_env_wait_ms": 0.2325217319468626, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035904645919799805, "StateBufferConnector_ms": 0.00311124324798584, "ViewRequirementAgentConnector_ms": 0.10747671127319336}, "num_episodes": 23, "episode_return_max": 112.76000000000084, "episode_return_min": -91.77999999999835, "episode_return_mean": -6.487799999999863, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.82842418734015, "num_env_steps_trained_throughput_per_sec": 351.82842418734015, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 11153.656, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11153.609, "sample_time_ms": 1376.135, "learn_time_ms": 9761.436, "learn_throughput": 409.776, "synch_weights_time_ms": 12.906}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "310e1_00000", "date": "2024-08-15_01-04-31", "timestamp": 1723664071, "time_this_iter_s": 11.40855598449707, "time_total_s": 426.9513804912567, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 426.9513804912567, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 58.91875, "ram_util_percent": 83.28125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6377764368025713, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.196287505841129, "policy_loss": -0.007827401332429084, "vf_loss": 1.2031748810773173, "vf_explained_var": 0.0643422316621851, "kl": 0.006266832251354039, "entropy": 1.4144385341614012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2857174853483837, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7349201821776292, "policy_loss": -0.009049539797922113, "vf_loss": 2.7423458849311504, "vf_explained_var": 0.13231036738743857, "kl": 0.016238366636949855, "entropy": 1.1402868801954562, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 251.97999999999948, "episode_reward_min": -91.77999999999835, "episode_reward_mean": 4.8984000000001755, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -172.87000000000077, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 160.30999999999983, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": -14.73579999999994, "predator_policy": 17.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.340000000000076, -17.32999999999995, -9.320000000000077, 19.97000000000046, 42.219999999999416, -34.38000000000071, -23.26999999999945, -49.31000000000046, -64.80999999999958, -10.140000000000082, -61.940000000000104, -29.339999999999726, 46.23999999999954, -15.199999999999564, -7.200000000000081, -22.29999999999942, -29.64999999999969, 22.670000000000524, -0.040000000000040996, 82.77000000000089, -4.250000000000076, -18.24999999999945, 29.580000000000506, -2.160000000000079, -36.600000000000676, 28.110000000000408, -21.259999999999415, -0.040000000000040996, 0.40000000000004493, -2.120000000000081, -90.94999999999844, -1.0900000000000614, -41.360000000000724, -45.58000000000067, 21.530000000000527, -20.239999999999437, -91.77999999999835, -5.190000000000078, -10.420000000000076, 95.00000000000117, 0.609999999999972, -34.38000000000067, -27.309999999999427, 112.72000000000084, 53.97999999999949, -27.25999999999942, 16.54000000000002, -25.66999999999978, 104.30000000000118, -29.429999999999893, 63.22999999999971, 19.24000000000037, -6.100000000000083, 2.430000000000337, -18.53999999999947, -30.449999999999562, 7.919999999999916, -41.450000000000706, 65.29000000000029, 21.110000000000458, -14.519999999999731, 0.969999999999981, 112.76000000000084, -18.010000000000225, -33.48000000000009, 19.490000000000315, -15.18999999999956, 21.680000000000526, -41.74000000000036, 17.660000000000206, 1.980000000000003, 3.4199999999999657, -75.92999999999857, 0.6299999999999887, -36.4000000000007, -80.94999999999844, -0.04000000000004011, -3.1500000000000794, -4.080000000000084, -15.199999999999635, -18.289999999999477, 34.6299999999996, -7.910000000000034, -24.27999999999942, 92.76000000000013, -21.729999999999855, 10.77999999999992, 62.089999999999506, -1.0600000000000622, -17.589999999999495, 76.6000000000007, 21.330000000000457, -5.3400000000000745, 1.9799999999999849, 166.30999999999958, 91.45000000000093, -10.150000000000082, -21.24999999999943, 130.22000000000037, 251.97999999999948], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.050000000000018, -56.29000000000034, -27.189999999999884, -26.13999999999971, -14.080000000000041, -46.240000000000336, -96.48999999999926, 4.459999999999944, 48.46999999999971, -48.25000000000035, -42.220000000000354, -30.159999999999712, -2.020000000000042, -48.25000000000034, -98.67999999999944, -37.63000000000025, -91.50999999999927, -52.30000000000033, -6.040000000000042, -18.099999999999703, -54.28000000000034, -88.65999999999931, -16.0899999999997, -48.25000000000035, 22.340000000000142, -18.099999999999703, -30.159999999999712, -6.040000000000042, -20.109999999999847, -16.0899999999997, -26.13999999999971, -27.159999999999712, -22.359999999999744, -56.29000000000034, 2.0000000000000013, 1.6700000000000013, -2.020000000000042, -2.020000000000042, 10.58000000000003, 46.189999999999856, 2.0000000000000013, -48.25000000000035, -48.25000000000035, 2.0000000000000013, 16.58000000000007, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -58.30000000000034, -34.30000000000034, 20.240000000000194, -24.129999999999715, -22.119999999999706, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -32.170000000000364, -12.429999999999994, -22.119999999999706, 2.0000000000000013, -82.41999999999919, -65.52999999999925, 2.0000000000000013, -16.0899999999997, -29.19999999999984, -30.159999999999712, -28.14999999999971, -84.4299999999992, -30.159999999999716, 32.69000000000002, -2.020000000000042, -42.220000000000354, -60.310000000000336, -92.46999999999922, -16.0899999999997, -18.099999999999724, -12.070000000000041, -53.35000000000033, -4.030000000000038, 95.03000000000053, -4.030000000000021, -19.359999999999744, -56.29000000000034, -16.0899999999997, -28.14999999999971, -30.159999999999716, 97.73000000000033, -0.00999999999999836, -50.260000000000346, 77.24000000000063, -26.139999999999713, -22.119999999999706, -18.099999999999703, 16.64000000000008, 2.720000000000071, -76.38999999999996, -7.930000000000023, 78.23000000000063, -28.149999999999714, -39.28000000000034, -0.00999999999999836, 47.239999999999824, 2.0000000000000013, -12.76000000000024, -6.040000000000042, -10.060000000000041, -46.24000000000025, 19.670000000000023, -0.1899999999999984, -62.35000000000033, -64.32999999999917, -22.11999999999986, -6.040000000000042, 5.959999999999958, -40.210000000000356, -46.24000000000035, 56.44999999999971, -0.1599999999999986, 13.459999999999969, -26.349999999999742, -48.25000000000033, -4.270000000000037, -4.030000000000042, 2.0000000000000013, 97.76000000000032, 2.0000000000000013, 37.57999999999994, -116.58999999999943, -172.87000000000077, 47.38999999999972, 24.770000000000216, -54.28000000000034, -26.13999999999971, -8.050000000000042, 12.679999999999964, 2.0000000000000013, -146.74000000000086, 2.0000000000000013, 8.810000000000047, 4.849999999999989, 2.0000000000000013, -2.020000000000042, -19.419999999999757, -30.15999999999972, -109.65999999999931, -52.27000000000033, 2.0000000000000013, -72.36999999999917, -48.25000000000034, -28.14999999999972, -72.39999999999918, -78.54999999999926, 2.0000000000000013, -6.040000000000042, -0.009999999999998581, -26.13999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -38.200000000000315, 4.969999999999958, -50.26000000000033, 2.0000000000000013, 23.630000000000255, -52.270000000000344, -27.63999999999981, -30.159999999999712, -22.119999999999706, -22.119999999999706, 94.88, -22.479999999999777, -48.2499999999999, 11.89999999999996, -22.119999999999706, 58.15999999999977, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -51.520000000000294, 88.13000000000031, -44.53000000000019, -26.13999999999971, 12.469999999999969, 2.0000000000000013, -48.34000000000033, -2.020000000000011, 2.0000000000000013, 160.30999999999983, 2.0000000000000013, 105.89000000000043, -86.43999999999922, -28.149999999999757, 2.0000000000000013, -42.220000000000354, -4.030000000000042, -15.30999999999986, 117.53000000000027, 152.41999999999973, 66.55999999999996], "policy_predator_policy_reward": [28.0, 24.0, 18.0, 18.0, 28.0, 23.0, 58.0, 54.0, 17.0, 25.0, 22.0, 16.0, 2.0, 25.0, 29.0, 58.0, 48.0, 31.0, 10.0, 4.0, 29.0, 52.0, 10.0, 25.0, 23.0, 19.0, 16.0, 5.0, 10.0, 19.0, 16.0, 15.0, 29.0, 20.0, 8.0, 11.0, 2.0, 2.0, 12.0, 14.0, 17.0, 25.0, 3.0, 25.0, 9.0, 2.0, 16.0, 10.0, 30.0, 26.0, 15.0, 17.0, 14.0, 13.0, 4.0, 0.0, 10.0, 35.0, 6.0, 12.0, 45.0, 12.0, 4.0, 9.0, 0.0, 18.0, 35.0, 32.0, 3.0, 16.0, 22.0, 2.0, 47.0, 14.0, 18.0, 11.0, 35.0, 20.0, 0.0, 4.0, 5.0, 19.0, 29.0, 9.0, 16.0, 15.0, 5.0, 10.0, 26.0, 1.0, 16.0, 5.0, 9.0, 9.0, 35.0, 13.0, 0.0, 34.0, 23.0, 15.0, 10.0, 6.0, 0.0, 30.0, 4.0, 6.0, 24.0, 5.0, 26.0, 18.0, 33.0, 23.0, 4.0, 4.0, 24.0, 21.0, 3.0, 6.0, 23.0, 11.0, 16.0, 22.0, 0.0, 3.0, 7.0, 6.0, 59.0, 2.0, 87.0, 5.0, 28.0, 21.0, 14.0, 5.0, 0.0, 7.0, 72.0, 31.0, 0.0, 4.0, 0.0, 2.0, 26.0, 27.0, 27.0, 59.0, 36.0, 35.0, 25.0, 15.0, 42.0, 28.0, 4.0, 0.0, 15.0, 8.0, 1.0, 7.0, 20.0, 1.0, 24.0, 3.0, 4.0, 5.0, 51.0, 21.0, 16.0, 12.0, 3.0, 17.0, 11.0, 38.0, 12.0, 9.0, 9.0, 7.0, 6.0, 1.0, 17.0, 29.0, 31.0, 2.0, 26.0, 9.0, 13.0, 28.0, 0.0, 2.0, 3.0, 1.0, 28.0, 44.0, 6.0, 10.0, 22.0, 3.0, 21.0, 7.0, 25.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6841539824882994, "mean_inference_ms": 1.8391122537537263, "mean_action_processing_ms": 0.3068019870431865, "mean_env_wait_ms": 0.2317799297880341, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003539443016052246, "StateBufferConnector_ms": 0.005623340606689453, "ViewRequirementAgentConnector_ms": 0.10431873798370361}, "num_episodes": 18, "episode_return_max": 251.97999999999948, "episode_return_min": -91.77999999999835, "episode_return_mean": 4.8984000000001755, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.67081184038557, "num_env_steps_trained_throughput_per_sec": 361.67081184038557, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 11048.346, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11048.299, "sample_time_ms": 1272.522, "learn_time_ms": 9759.643, "learn_throughput": 409.851, "synch_weights_time_ms": 12.939}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "310e1_00000", "date": "2024-08-15_01-04-42", "timestamp": 1723664082, "time_this_iter_s": 11.114530086517334, "time_total_s": 438.06591057777405, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14f7ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 438.06591057777405, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 55.63125, "ram_util_percent": 82.79375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.435002539681379, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8449154214411185, "policy_loss": -0.010351692085159282, "vf_loss": 0.8540459743646718, "vf_explained_var": 0.02506216149481516, "kl": 0.008140923890968854, "entropy": 1.4052495108710394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0528893404536777, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3013928129559473, "policy_loss": -0.006312123617088353, "vf_loss": 2.3069814393444665, "vf_explained_var": 0.3165405774558032, "kl": 0.007234926435896964, "entropy": 1.1012590078449753, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 251.97999999999948, "episode_reward_min": -91.77999999999835, "episode_reward_mean": 11.676800000000192, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -172.87000000000077, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 160.30999999999983, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": -9.766599999999935, "predator_policy": 15.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.040000000000040996, 82.77000000000089, -4.250000000000076, -18.24999999999945, 29.580000000000506, -2.160000000000079, -36.600000000000676, 28.110000000000408, -21.259999999999415, -0.040000000000040996, 0.40000000000004493, -2.120000000000081, -90.94999999999844, -1.0900000000000614, -41.360000000000724, -45.58000000000067, 21.530000000000527, -20.239999999999437, -91.77999999999835, -5.190000000000078, -10.420000000000076, 95.00000000000117, 0.609999999999972, -34.38000000000067, -27.309999999999427, 112.72000000000084, 53.97999999999949, -27.25999999999942, 16.54000000000002, -25.66999999999978, 104.30000000000118, -29.429999999999893, 63.22999999999971, 19.24000000000037, -6.100000000000083, 2.430000000000337, -18.53999999999947, -30.449999999999562, 7.919999999999916, -41.450000000000706, 65.29000000000029, 21.110000000000458, -14.519999999999731, 0.969999999999981, 112.76000000000084, -18.010000000000225, -33.48000000000009, 19.490000000000315, -15.18999999999956, 21.680000000000526, -41.74000000000036, 17.660000000000206, 1.980000000000003, 3.4199999999999657, -75.92999999999857, 0.6299999999999887, -36.4000000000007, -80.94999999999844, -0.04000000000004011, -3.1500000000000794, -4.080000000000084, -15.199999999999635, -18.289999999999477, 34.6299999999996, -7.910000000000034, -24.27999999999942, 92.76000000000013, -21.729999999999855, 10.77999999999992, 62.089999999999506, -1.0600000000000622, -17.589999999999495, 76.6000000000007, 21.330000000000457, -5.3400000000000745, 1.9799999999999849, 166.30999999999958, 91.45000000000093, -10.150000000000082, -21.24999999999943, 130.22000000000037, 251.97999999999948, -29.32999999999945, -17.369999999999447, -0.1600000000000401, 13.79999999999992, 22.830000000000418, 0.8099999999999844, -50.570000000000604, 61.399999999999814, 127.33000000000038, -15.32999999999955, 5.719999999999922, 75.69000000000091, 24.770000000000522, 172.22999999999956, -20.359999999999477, -1.3100000000000571, 2.859999999999983, 49.39999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-2.020000000000042, -2.020000000000042, 10.58000000000003, 46.189999999999856, 2.0000000000000013, -48.25000000000035, -48.25000000000035, 2.0000000000000013, 16.58000000000007, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -58.30000000000034, -34.30000000000034, 20.240000000000194, -24.129999999999715, -22.119999999999706, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -32.170000000000364, -12.429999999999994, -22.119999999999706, 2.0000000000000013, -82.41999999999919, -65.52999999999925, 2.0000000000000013, -16.0899999999997, -29.19999999999984, -30.159999999999712, -28.14999999999971, -84.4299999999992, -30.159999999999716, 32.69000000000002, -2.020000000000042, -42.220000000000354, -60.310000000000336, -92.46999999999922, -16.0899999999997, -18.099999999999724, -12.070000000000041, -53.35000000000033, -4.030000000000038, 95.03000000000053, -4.030000000000021, -19.359999999999744, -56.29000000000034, -16.0899999999997, -28.14999999999971, -30.159999999999716, 97.73000000000033, -0.00999999999999836, -50.260000000000346, 77.24000000000063, -26.139999999999713, -22.119999999999706, -18.099999999999703, 16.64000000000008, 2.720000000000071, -76.38999999999996, -7.930000000000023, 78.23000000000063, -28.149999999999714, -39.28000000000034, -0.00999999999999836, 47.239999999999824, 2.0000000000000013, -12.76000000000024, -6.040000000000042, -10.060000000000041, -46.24000000000025, 19.670000000000023, -0.1899999999999984, -62.35000000000033, -64.32999999999917, -22.11999999999986, -6.040000000000042, 5.959999999999958, -40.210000000000356, -46.24000000000035, 56.44999999999971, -0.1599999999999986, 13.459999999999969, -26.349999999999742, -48.25000000000033, -4.270000000000037, -4.030000000000042, 2.0000000000000013, 97.76000000000032, 2.0000000000000013, 37.57999999999994, -116.58999999999943, -172.87000000000077, 47.38999999999972, 24.770000000000216, -54.28000000000034, -26.13999999999971, -8.050000000000042, 12.679999999999964, 2.0000000000000013, -146.74000000000086, 2.0000000000000013, 8.810000000000047, 4.849999999999989, 2.0000000000000013, -2.020000000000042, -19.419999999999757, -30.15999999999972, -109.65999999999931, -52.27000000000033, 2.0000000000000013, -72.36999999999917, -48.25000000000034, -28.14999999999972, -72.39999999999918, -78.54999999999926, 2.0000000000000013, -6.040000000000042, -0.009999999999998581, -26.13999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -38.200000000000315, 4.969999999999958, -50.26000000000033, 2.0000000000000013, 23.630000000000255, -52.270000000000344, -27.63999999999981, -30.159999999999712, -22.119999999999706, -22.119999999999706, 94.88, -22.479999999999777, -48.2499999999999, 11.89999999999996, -22.119999999999706, 58.15999999999977, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -51.520000000000294, 88.13000000000031, -44.53000000000019, -26.13999999999971, 12.469999999999969, 2.0000000000000013, -48.34000000000033, -2.020000000000011, 2.0000000000000013, 160.30999999999983, 2.0000000000000013, 105.89000000000043, -86.43999999999922, -28.149999999999757, 2.0000000000000013, -42.220000000000354, -4.030000000000042, -15.30999999999986, 117.53000000000027, 152.41999999999973, 66.55999999999996, -42.220000000000354, -20.10999999999983, -25.299999999999734, -12.070000000000041, 7.93999999999996, -18.099999999999707, 6.799999999999962, 2.0000000000000013, -96.48999999999923, 69.32000000000065, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -98.49999999999928, 9.919999999999959, -45.52000000000007, -50.260000000000346, 135.5899999999999, -26.139999999999713, -18.189999999999717, -24.129999999999708, 16.85000000000011, -33.22000000000033, 79.91000000000045, -0.00999999999999836, 23.780000000000257, 2.0000000000000013, 159.22999999999985, -70.35999999999916, 2.0000000000000013, -16.089999999999755, -3.220000000000038, -11.14000000000004, 2.0000000000000013, 31.400000000000023, 2.0000000000000013], "policy_predator_policy_reward": [2.0, 2.0, 12.0, 14.0, 17.0, 25.0, 3.0, 25.0, 9.0, 2.0, 16.0, 10.0, 30.0, 26.0, 15.0, 17.0, 14.0, 13.0, 4.0, 0.0, 10.0, 35.0, 6.0, 12.0, 45.0, 12.0, 4.0, 9.0, 0.0, 18.0, 35.0, 32.0, 3.0, 16.0, 22.0, 2.0, 47.0, 14.0, 18.0, 11.0, 35.0, 20.0, 0.0, 4.0, 5.0, 19.0, 29.0, 9.0, 16.0, 15.0, 5.0, 10.0, 26.0, 1.0, 16.0, 5.0, 9.0, 9.0, 35.0, 13.0, 0.0, 34.0, 23.0, 15.0, 10.0, 6.0, 0.0, 30.0, 4.0, 6.0, 24.0, 5.0, 26.0, 18.0, 33.0, 23.0, 4.0, 4.0, 24.0, 21.0, 3.0, 6.0, 23.0, 11.0, 16.0, 22.0, 0.0, 3.0, 7.0, 6.0, 59.0, 2.0, 87.0, 5.0, 28.0, 21.0, 14.0, 5.0, 0.0, 7.0, 72.0, 31.0, 0.0, 4.0, 0.0, 2.0, 26.0, 27.0, 27.0, 59.0, 36.0, 35.0, 25.0, 15.0, 42.0, 28.0, 4.0, 0.0, 15.0, 8.0, 1.0, 7.0, 20.0, 1.0, 24.0, 3.0, 4.0, 5.0, 51.0, 21.0, 16.0, 12.0, 3.0, 17.0, 11.0, 38.0, 12.0, 9.0, 9.0, 7.0, 6.0, 1.0, 17.0, 29.0, 31.0, 2.0, 26.0, 9.0, 13.0, 28.0, 0.0, 2.0, 3.0, 1.0, 28.0, 44.0, 6.0, 10.0, 22.0, 3.0, 21.0, 7.0, 25.0, 8.0, 0.0, 33.0, 10.0, 10.0, 10.0, 0.0, 5.0, 0.0, 45.0, 5.0, 19.0, 16.0, 21.0, 39.0, 58.0, 39.0, 18.0, 24.0, 15.0, 14.0, 13.0, 0.0, 9.0, 20.0, 0.0, 1.0, 5.0, 6.0, 36.0, 12.0, 9.0, 9.0, 9.0, 3.0, 6.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6821552308920872, "mean_inference_ms": 1.8339945187892488, "mean_action_processing_ms": 0.3053474432794295, "mean_env_wait_ms": 0.23108328990316518, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003545522689819336, "StateBufferConnector_ms": 0.005638003349304199, "ViewRequirementAgentConnector_ms": 0.10252928733825684}, "num_episodes": 18, "episode_return_max": 251.97999999999948, "episode_return_min": -91.77999999999835, "episode_return_mean": 11.676800000000192, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.1828391076178, "num_env_steps_trained_throughput_per_sec": 370.1828391076178, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 11006.591, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11006.546, "sample_time_ms": 1272.817, "learn_time_ms": 9718.249, "learn_throughput": 411.597, "synch_weights_time_ms": 12.817}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "310e1_00000", "date": "2024-08-15_01-04-53", "timestamp": 1723664093, "time_this_iter_s": 10.838330745697021, "time_total_s": 448.90424132347107, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14dfd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 448.90424132347107, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 56.88000000000001, "ram_util_percent": 82.80000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6581173625888017, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.752756494504434, "policy_loss": -0.010031078859089465, "vf_loss": 1.761714417530746, "vf_explained_var": 0.012607271929897329, "kl": 0.007154354849447531, "entropy": 1.3984107707543347, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.312902741962009, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7314049283032693, "policy_loss": -0.005332184418488944, "vf_loss": 3.736147347707597, "vf_explained_var": 0.11296488812991551, "kl": 0.005897764014586572, "entropy": 1.0541395255812893, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 251.97999999999948, "episode_reward_min": -80.94999999999844, "episode_reward_mean": 23.74170000000017, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -189.34000000000057, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 160.30999999999983, "predator_policy": 106.0}, "policy_reward_mean": {"prey_policy": -5.524149999999953, "predator_policy": 17.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.609999999999972, -34.38000000000067, -27.309999999999427, 112.72000000000084, 53.97999999999949, -27.25999999999942, 16.54000000000002, -25.66999999999978, 104.30000000000118, -29.429999999999893, 63.22999999999971, 19.24000000000037, -6.100000000000083, 2.430000000000337, -18.53999999999947, -30.449999999999562, 7.919999999999916, -41.450000000000706, 65.29000000000029, 21.110000000000458, -14.519999999999731, 0.969999999999981, 112.76000000000084, -18.010000000000225, -33.48000000000009, 19.490000000000315, -15.18999999999956, 21.680000000000526, -41.74000000000036, 17.660000000000206, 1.980000000000003, 3.4199999999999657, -75.92999999999857, 0.6299999999999887, -36.4000000000007, -80.94999999999844, -0.04000000000004011, -3.1500000000000794, -4.080000000000084, -15.199999999999635, -18.289999999999477, 34.6299999999996, -7.910000000000034, -24.27999999999942, 92.76000000000013, -21.729999999999855, 10.77999999999992, 62.089999999999506, -1.0600000000000622, -17.589999999999495, 76.6000000000007, 21.330000000000457, -5.3400000000000745, 1.9799999999999849, 166.30999999999958, 91.45000000000093, -10.150000000000082, -21.24999999999943, 130.22000000000037, 251.97999999999948, -29.32999999999945, -17.369999999999447, -0.1600000000000401, 13.79999999999992, 22.830000000000418, 0.8099999999999844, -50.570000000000604, 61.399999999999814, 127.33000000000038, -15.32999999999955, 5.719999999999922, 75.69000000000091, 24.770000000000522, 172.22999999999956, -20.359999999999477, -1.3100000000000571, 2.859999999999983, 49.39999999999989, 48.10999999999968, -22.259999999999426, 27.120000000000264, -14.18999999999987, 20.050000000000093, 133.6299999999991, -25.34999999999946, -13.379999999999965, -28.319999999999453, 106.20000000000087, 14.430000000000463, 246.39999999999984, 28.779999999999923, -29.339999999999737, -1.050000000000063, 189.42999999999984, 64.08999999999989, -0.7400000000000406, 120.6000000000008, 71.79000000000082, 3.979999999999959, 132.57000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-4.030000000000021, -19.359999999999744, -56.29000000000034, -16.0899999999997, -28.14999999999971, -30.159999999999716, 97.73000000000033, -0.00999999999999836, -50.260000000000346, 77.24000000000063, -26.139999999999713, -22.119999999999706, -18.099999999999703, 16.64000000000008, 2.720000000000071, -76.38999999999996, -7.930000000000023, 78.23000000000063, -28.149999999999714, -39.28000000000034, -0.00999999999999836, 47.239999999999824, 2.0000000000000013, -12.76000000000024, -6.040000000000042, -10.060000000000041, -46.24000000000025, 19.670000000000023, -0.1899999999999984, -62.35000000000033, -64.32999999999917, -22.11999999999986, -6.040000000000042, 5.959999999999958, -40.210000000000356, -46.24000000000035, 56.44999999999971, -0.1599999999999986, 13.459999999999969, -26.349999999999742, -48.25000000000033, -4.270000000000037, -4.030000000000042, 2.0000000000000013, 97.76000000000032, 2.0000000000000013, 37.57999999999994, -116.58999999999943, -172.87000000000077, 47.38999999999972, 24.770000000000216, -54.28000000000034, -26.13999999999971, -8.050000000000042, 12.679999999999964, 2.0000000000000013, -146.74000000000086, 2.0000000000000013, 8.810000000000047, 4.849999999999989, 2.0000000000000013, -2.020000000000042, -19.419999999999757, -30.15999999999972, -109.65999999999931, -52.27000000000033, 2.0000000000000013, -72.36999999999917, -48.25000000000034, -28.14999999999972, -72.39999999999918, -78.54999999999926, 2.0000000000000013, -6.040000000000042, -0.009999999999998581, -26.13999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -38.200000000000315, 4.969999999999958, -50.26000000000033, 2.0000000000000013, 23.630000000000255, -52.270000000000344, -27.63999999999981, -30.159999999999712, -22.119999999999706, -22.119999999999706, 94.88, -22.479999999999777, -48.2499999999999, 11.89999999999996, -22.119999999999706, 58.15999999999977, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -51.520000000000294, 88.13000000000031, -44.53000000000019, -26.13999999999971, 12.469999999999969, 2.0000000000000013, -48.34000000000033, -2.020000000000011, 2.0000000000000013, 160.30999999999983, 2.0000000000000013, 105.89000000000043, -86.43999999999922, -28.149999999999757, 2.0000000000000013, -42.220000000000354, -4.030000000000042, -15.30999999999986, 117.53000000000027, 152.41999999999973, 66.55999999999996, -42.220000000000354, -20.10999999999983, -25.299999999999734, -12.070000000000041, 7.93999999999996, -18.099999999999707, 6.799999999999962, 2.0000000000000013, -96.48999999999923, 69.32000000000065, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -98.49999999999928, 9.919999999999959, -45.52000000000007, -50.260000000000346, 135.5899999999999, -26.139999999999713, -18.189999999999717, -24.129999999999708, 16.85000000000011, -33.22000000000033, 79.91000000000045, -0.00999999999999836, 23.780000000000257, 2.0000000000000013, 159.22999999999985, -70.35999999999916, 2.0000000000000013, -16.089999999999755, -3.220000000000038, -11.14000000000004, 2.0000000000000013, 31.400000000000023, 2.0000000000000013, 13.189999999999975, -14.080000000000041, -38.20000000000036, -10.060000000000041, 18.410000000000135, -17.289999999999733, -34.180000000000284, -0.009999999999998581, -156.7900000000002, 8.839999999999982, -0.00999999999999836, 130.63999999999942, -25.17999999999974, -32.170000000000364, -74.37999999999917, 2.0000000000000013, -2.02000000000004, -58.30000000000034, -38.5000000000003, 97.70000000000036, 25.609999999999964, -34.18000000000036, 117.16999999999996, 87.23000000000003, 75.26000000000003, -94.47999999999922, 2.0000000000000013, -189.34000000000057, -4.030000000000042, -2.020000000000042, 62.14999999999997, 73.28, -20.109999999999705, 60.19999999999999, 14.86999999999996, -120.60999999999929, 62.32999999999988, 47.269999999999825, -28.149999999999714, 67.94000000000041, -2.020000000000042, 2.0000000000000013, 107.06, -30.489999999999764], "policy_predator_policy_reward": [5.0, 19.0, 29.0, 9.0, 16.0, 15.0, 5.0, 10.0, 26.0, 1.0, 16.0, 5.0, 9.0, 9.0, 35.0, 13.0, 0.0, 34.0, 23.0, 15.0, 10.0, 6.0, 0.0, 30.0, 4.0, 6.0, 24.0, 5.0, 26.0, 18.0, 33.0, 23.0, 4.0, 4.0, 24.0, 21.0, 3.0, 6.0, 23.0, 11.0, 16.0, 22.0, 0.0, 3.0, 7.0, 6.0, 59.0, 2.0, 87.0, 5.0, 28.0, 21.0, 14.0, 5.0, 0.0, 7.0, 72.0, 31.0, 0.0, 4.0, 0.0, 2.0, 26.0, 27.0, 27.0, 59.0, 36.0, 35.0, 25.0, 15.0, 42.0, 28.0, 4.0, 0.0, 15.0, 8.0, 1.0, 7.0, 20.0, 1.0, 24.0, 3.0, 4.0, 5.0, 51.0, 21.0, 16.0, 12.0, 3.0, 17.0, 11.0, 38.0, 12.0, 9.0, 9.0, 7.0, 6.0, 1.0, 17.0, 29.0, 31.0, 2.0, 26.0, 9.0, 13.0, 28.0, 0.0, 2.0, 3.0, 1.0, 28.0, 44.0, 6.0, 10.0, 22.0, 3.0, 21.0, 7.0, 25.0, 8.0, 0.0, 33.0, 10.0, 10.0, 10.0, 0.0, 5.0, 0.0, 45.0, 5.0, 19.0, 16.0, 21.0, 39.0, 58.0, 39.0, 18.0, 24.0, 15.0, 14.0, 13.0, 0.0, 9.0, 20.0, 0.0, 1.0, 5.0, 6.0, 36.0, 12.0, 9.0, 9.0, 9.0, 3.0, 6.0, 10.0, 22.0, 27.0, 20.0, 6.0, 20.0, 6.0, 17.0, 3.0, 81.0, 87.0, 2.0, 1.0, 17.0, 15.0, 38.0, 21.0, 2.0, 30.0, 30.0, 17.0, 5.0, 18.0, 32.0, 10.0, 0.0, 48.0, 106.0, 52.0, 3.0, 2.0, 20.0, 34.0, 7.0, 17.0, 54.0, 51.0, 9.0, 2.0, 16.0, 16.0, 2.0, 2.0, 29.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.679496650916851, "mean_inference_ms": 1.827201981845904, "mean_action_processing_ms": 0.30300668993206953, "mean_env_wait_ms": 0.23053145231441313, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003574371337890625, "StateBufferConnector_ms": 0.005721688270568848, "ViewRequirementAgentConnector_ms": 0.11193132400512695}, "num_episodes": 22, "episode_return_max": 251.97999999999948, "episode_return_min": -80.94999999999844, "episode_return_mean": 23.74170000000017, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.1109662769049, "num_env_steps_trained_throughput_per_sec": 364.1109662769049, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 11027.032, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11026.987, "sample_time_ms": 1280.983, "learn_time_ms": 9730.855, "learn_throughput": 411.064, "synch_weights_time_ms": 12.493}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "310e1_00000", "date": "2024-08-15_01-05-04", "timestamp": 1723664104, "time_this_iter_s": 11.021764993667603, "time_total_s": 459.9260063171387, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1482040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 459.9260063171387, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 56.83125, "ram_util_percent": 83.05625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0318864638212495, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8145547352139912, "policy_loss": -0.014042336487324622, "vf_loss": 2.8263911662909087, "vf_explained_var": 0.059397970305548775, "kl": 0.014706032646733171, "entropy": 1.3997411613111144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9979217723248497, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.013176629404542, "policy_loss": -0.00407596140614558, "vf_loss": 6.01660993565958, "vf_explained_var": 0.14997753273873102, "kl": 0.006426372202576805, "entropy": 0.9044878884598061, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 301.76999999999936, "episode_reward_min": -80.94999999999844, "episode_reward_mean": 44.58240000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -189.34000000000057, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.07, "predator_policy": 106.0}, "policy_reward_mean": {"prey_policy": 2.4062000000000374, "predator_policy": 19.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.010000000000225, -33.48000000000009, 19.490000000000315, -15.18999999999956, 21.680000000000526, -41.74000000000036, 17.660000000000206, 1.980000000000003, 3.4199999999999657, -75.92999999999857, 0.6299999999999887, -36.4000000000007, -80.94999999999844, -0.04000000000004011, -3.1500000000000794, -4.080000000000084, -15.199999999999635, -18.289999999999477, 34.6299999999996, -7.910000000000034, -24.27999999999942, 92.76000000000013, -21.729999999999855, 10.77999999999992, 62.089999999999506, -1.0600000000000622, -17.589999999999495, 76.6000000000007, 21.330000000000457, -5.3400000000000745, 1.9799999999999849, 166.30999999999958, 91.45000000000093, -10.150000000000082, -21.24999999999943, 130.22000000000037, 251.97999999999948, -29.32999999999945, -17.369999999999447, -0.1600000000000401, 13.79999999999992, 22.830000000000418, 0.8099999999999844, -50.570000000000604, 61.399999999999814, 127.33000000000038, -15.32999999999955, 5.719999999999922, 75.69000000000091, 24.770000000000522, 172.22999999999956, -20.359999999999477, -1.3100000000000571, 2.859999999999983, 49.39999999999989, 48.10999999999968, -22.259999999999426, 27.120000000000264, -14.18999999999987, 20.050000000000093, 133.6299999999991, -25.34999999999946, -13.379999999999965, -28.319999999999453, 106.20000000000087, 14.430000000000463, 246.39999999999984, 28.779999999999923, -29.339999999999737, -1.050000000000063, 189.42999999999984, 64.08999999999989, -0.7400000000000406, 120.6000000000008, 71.79000000000082, 3.979999999999959, 132.57000000000022, 88.14000000000004, 56.720000000000155, 184.96999999999974, 79.9400000000005, -20.27999999999945, 301.76999999999936, 67.99000000000025, 167.14000000000001, 22.270000000000405, 4.330000000000118, 153.00000000000006, 50.319999999999865, 161.40999999999997, 78.79, 41.290000000000035, 1.940000000000003, 198.0, 110.86000000000112, 72.47999999999982, 195.4600000000001, -17.219999999999427, 131.3000000000004, 279.44000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [37.57999999999994, -116.58999999999943, -172.87000000000077, 47.38999999999972, 24.770000000000216, -54.28000000000034, -26.13999999999971, -8.050000000000042, 12.679999999999964, 2.0000000000000013, -146.74000000000086, 2.0000000000000013, 8.810000000000047, 4.849999999999989, 2.0000000000000013, -2.020000000000042, -19.419999999999757, -30.15999999999972, -109.65999999999931, -52.27000000000033, 2.0000000000000013, -72.36999999999917, -48.25000000000034, -28.14999999999972, -72.39999999999918, -78.54999999999926, 2.0000000000000013, -6.040000000000042, -0.009999999999998581, -26.13999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -38.200000000000315, 4.969999999999958, -50.26000000000033, 2.0000000000000013, 23.630000000000255, -52.270000000000344, -27.63999999999981, -30.159999999999712, -22.119999999999706, -22.119999999999706, 94.88, -22.479999999999777, -48.2499999999999, 11.89999999999996, -22.119999999999706, 58.15999999999977, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -51.520000000000294, 88.13000000000031, -44.53000000000019, -26.13999999999971, 12.469999999999969, 2.0000000000000013, -48.34000000000033, -2.020000000000011, 2.0000000000000013, 160.30999999999983, 2.0000000000000013, 105.89000000000043, -86.43999999999922, -28.149999999999757, 2.0000000000000013, -42.220000000000354, -4.030000000000042, -15.30999999999986, 117.53000000000027, 152.41999999999973, 66.55999999999996, -42.220000000000354, -20.10999999999983, -25.299999999999734, -12.070000000000041, 7.93999999999996, -18.099999999999707, 6.799999999999962, 2.0000000000000013, -96.48999999999923, 69.32000000000065, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -98.49999999999928, 9.919999999999959, -45.52000000000007, -50.260000000000346, 135.5899999999999, -26.139999999999713, -18.189999999999717, -24.129999999999708, 16.85000000000011, -33.22000000000033, 79.91000000000045, -0.00999999999999836, 23.780000000000257, 2.0000000000000013, 159.22999999999985, -70.35999999999916, 2.0000000000000013, -16.089999999999755, -3.220000000000038, -11.14000000000004, 2.0000000000000013, 31.400000000000023, 2.0000000000000013, 13.189999999999975, -14.080000000000041, -38.20000000000036, -10.060000000000041, 18.410000000000135, -17.289999999999733, -34.180000000000284, -0.009999999999998581, -156.7900000000002, 8.839999999999982, -0.00999999999999836, 130.63999999999942, -25.17999999999974, -32.170000000000364, -74.37999999999917, 2.0000000000000013, -2.02000000000004, -58.30000000000034, -38.5000000000003, 97.70000000000036, 25.609999999999964, -34.18000000000036, 117.16999999999996, 87.23000000000003, 75.26000000000003, -94.47999999999922, 2.0000000000000013, -189.34000000000057, -4.030000000000042, -2.020000000000042, 62.14999999999997, 73.28, -20.109999999999705, 60.19999999999999, 14.86999999999996, -120.60999999999929, 62.32999999999988, 47.269999999999825, -28.149999999999714, 67.94000000000041, -2.020000000000042, 2.0000000000000013, 107.06, -30.489999999999764, 43.010000000000005, -112.87000000000009, -22.119999999999706, 32.83999999999983, -8.050000000000042, 183.01999999999998, 64.03999999999994, -18.099999999999703, -54.28000000000034, 2.0000000000000013, 94.70000000000036, 193.07, -32.170000000000364, 82.16, 8.0, 75.14, 40.61, -66.33999999999915, 3.4999999999999787, -32.17000000000034, 113.0, 2.0000000000000013, -46.24000000000035, 36.559999999999896, 39.20000000000019, 59.21000000000001, 12.08, -17.289999999999957, 9.469999999999999, -34.18000000000036, 2.0000000000000013, -10.060000000000041, 50.0, 62.0, 109.91000000000047, -8.050000000000042, 32.69, -58.21000000000016, 60.08000000000016, 111.37999999999994, -38.20000000000036, -2.020000000000042, 2.98999999999998, 85.30999999999997, 77.0, 156.44], "policy_predator_policy_reward": [59.0, 2.0, 87.0, 5.0, 28.0, 21.0, 14.0, 5.0, 0.0, 7.0, 72.0, 31.0, 0.0, 4.0, 0.0, 2.0, 26.0, 27.0, 27.0, 59.0, 36.0, 35.0, 25.0, 15.0, 42.0, 28.0, 4.0, 0.0, 15.0, 8.0, 1.0, 7.0, 20.0, 1.0, 24.0, 3.0, 4.0, 5.0, 51.0, 21.0, 16.0, 12.0, 3.0, 17.0, 11.0, 38.0, 12.0, 9.0, 9.0, 7.0, 6.0, 1.0, 17.0, 29.0, 31.0, 2.0, 26.0, 9.0, 13.0, 28.0, 0.0, 2.0, 3.0, 1.0, 28.0, 44.0, 6.0, 10.0, 22.0, 3.0, 21.0, 7.0, 25.0, 8.0, 0.0, 33.0, 10.0, 10.0, 10.0, 0.0, 5.0, 0.0, 45.0, 5.0, 19.0, 16.0, 21.0, 39.0, 58.0, 39.0, 18.0, 24.0, 15.0, 14.0, 13.0, 0.0, 9.0, 20.0, 0.0, 1.0, 5.0, 6.0, 36.0, 12.0, 9.0, 9.0, 9.0, 3.0, 6.0, 10.0, 22.0, 27.0, 20.0, 6.0, 20.0, 6.0, 17.0, 3.0, 81.0, 87.0, 2.0, 1.0, 17.0, 15.0, 38.0, 21.0, 2.0, 30.0, 30.0, 17.0, 5.0, 18.0, 32.0, 10.0, 0.0, 48.0, 106.0, 52.0, 3.0, 2.0, 20.0, 34.0, 7.0, 17.0, 54.0, 51.0, 9.0, 2.0, 16.0, 16.0, 2.0, 2.0, 29.0, 27.0, 62.0, 96.0, 17.0, 29.0, 4.0, 6.0, 16.0, 18.0, 28.0, 4.0, 5.0, 9.0, 17.0, 1.0, 68.0, 16.0, 34.0, 14.0, 17.0, 16.0, 23.0, 15.0, 21.0, 39.0, 12.0, 51.0, 12.0, 72.0, 61.0, 5.0, 4.0, 6.0, 17.0, 69.0, 5.0, 4.0, 60.0, 38.0, 17.0, 7.0, 12.0, 11.0, 28.0, 15.0, 34.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6778451850387118, "mean_inference_ms": 1.8182976132590982, "mean_action_processing_ms": 0.3028700449952569, "mean_env_wait_ms": 0.22963715806582474, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038744211196899414, "StateBufferConnector_ms": 0.006453037261962891, "ViewRequirementAgentConnector_ms": 0.11195933818817139}, "num_episodes": 23, "episode_return_max": 301.76999999999936, "episode_return_min": -80.94999999999844, "episode_return_mean": 44.58240000000016, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.67360626242754, "num_env_steps_trained_throughput_per_sec": 370.67360626242754, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 11002.078, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11002.032, "sample_time_ms": 1278.265, "learn_time_ms": 9708.27, "learn_throughput": 412.02, "synch_weights_time_ms": 12.628}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "310e1_00000", "date": "2024-08-15_01-05-15", "timestamp": 1723664115, "time_this_iter_s": 10.8455491065979, "time_total_s": 470.7715554237366, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c6820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 470.7715554237366, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 56.313333333333325, "ram_util_percent": 83.30666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9099736413943074, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.7849445173980065, "policy_loss": -0.01302794921926405, "vf_loss": 6.795871225235954, "vf_explained_var": 0.008319395118289524, "kl": 0.014008245793745495, "entropy": 1.3330870197563576, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.787333359115969, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.851735847463052, "policy_loss": -0.00361237532518331, "vf_loss": 6.854673841769102, "vf_explained_var": -0.20952038954174707, "kl": 0.006744000144159138, "entropy": 0.9220900286442388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 301.76999999999936, "episode_reward_min": -227.82000000000005, "episode_reward_mean": 37.46320000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.07, "predator_policy": 172.0}, "policy_reward_mean": {"prey_policy": -11.97339999999998, "predator_policy": 30.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.6299999999996, -7.910000000000034, -24.27999999999942, 92.76000000000013, -21.729999999999855, 10.77999999999992, 62.089999999999506, -1.0600000000000622, -17.589999999999495, 76.6000000000007, 21.330000000000457, -5.3400000000000745, 1.9799999999999849, 166.30999999999958, 91.45000000000093, -10.150000000000082, -21.24999999999943, 130.22000000000037, 251.97999999999948, -29.32999999999945, -17.369999999999447, -0.1600000000000401, 13.79999999999992, 22.830000000000418, 0.8099999999999844, -50.570000000000604, 61.399999999999814, 127.33000000000038, -15.32999999999955, 5.719999999999922, 75.69000000000091, 24.770000000000522, 172.22999999999956, -20.359999999999477, -1.3100000000000571, 2.859999999999983, 49.39999999999989, 48.10999999999968, -22.259999999999426, 27.120000000000264, -14.18999999999987, 20.050000000000093, 133.6299999999991, -25.34999999999946, -13.379999999999965, -28.319999999999453, 106.20000000000087, 14.430000000000463, 246.39999999999984, 28.779999999999923, -29.339999999999737, -1.050000000000063, 189.42999999999984, 64.08999999999989, -0.7400000000000406, 120.6000000000008, 71.79000000000082, 3.979999999999959, 132.57000000000022, 88.14000000000004, 56.720000000000155, 184.96999999999974, 79.9400000000005, -20.27999999999945, 301.76999999999936, 67.99000000000025, 167.14000000000001, 22.270000000000405, 4.330000000000118, 153.00000000000006, 50.319999999999865, 161.40999999999997, 78.79, 41.290000000000035, 1.940000000000003, 198.0, 110.86000000000112, 72.47999999999982, 195.4600000000001, -17.219999999999427, 131.3000000000004, 279.44000000000005, 57.01000000000048, -28.319999999999446, -176.47000000000034, -24.349999999999458, -1.99999999999999, -46.799999999999926, 27.700000000000134, 60.36999999999995, 33.580000000000005, -110.22999999999965, -99.35999999999993, -17.689999999999934, -227.82000000000005, -117.03999999999937, -34.10000000000002, -186.5200000000001, -157.42000000000058, 59.94000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, 23.630000000000255, -52.270000000000344, -27.63999999999981, -30.159999999999712, -22.119999999999706, -22.119999999999706, 94.88, -22.479999999999777, -48.2499999999999, 11.89999999999996, -22.119999999999706, 58.15999999999977, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -51.520000000000294, 88.13000000000031, -44.53000000000019, -26.13999999999971, 12.469999999999969, 2.0000000000000013, -48.34000000000033, -2.020000000000011, 2.0000000000000013, 160.30999999999983, 2.0000000000000013, 105.89000000000043, -86.43999999999922, -28.149999999999757, 2.0000000000000013, -42.220000000000354, -4.030000000000042, -15.30999999999986, 117.53000000000027, 152.41999999999973, 66.55999999999996, -42.220000000000354, -20.10999999999983, -25.299999999999734, -12.070000000000041, 7.93999999999996, -18.099999999999707, 6.799999999999962, 2.0000000000000013, -96.48999999999923, 69.32000000000065, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -98.49999999999928, 9.919999999999959, -45.52000000000007, -50.260000000000346, 135.5899999999999, -26.139999999999713, -18.189999999999717, -24.129999999999708, 16.85000000000011, -33.22000000000033, 79.91000000000045, -0.00999999999999836, 23.780000000000257, 2.0000000000000013, 159.22999999999985, -70.35999999999916, 2.0000000000000013, -16.089999999999755, -3.220000000000038, -11.14000000000004, 2.0000000000000013, 31.400000000000023, 2.0000000000000013, 13.189999999999975, -14.080000000000041, -38.20000000000036, -10.060000000000041, 18.410000000000135, -17.289999999999733, -34.180000000000284, -0.009999999999998581, -156.7900000000002, 8.839999999999982, -0.00999999999999836, 130.63999999999942, -25.17999999999974, -32.170000000000364, -74.37999999999917, 2.0000000000000013, -2.02000000000004, -58.30000000000034, -38.5000000000003, 97.70000000000036, 25.609999999999964, -34.18000000000036, 117.16999999999996, 87.23000000000003, 75.26000000000003, -94.47999999999922, 2.0000000000000013, -189.34000000000057, -4.030000000000042, -2.020000000000042, 62.14999999999997, 73.28, -20.109999999999705, 60.19999999999999, 14.86999999999996, -120.60999999999929, 62.32999999999988, 47.269999999999825, -28.149999999999714, 67.94000000000041, -2.020000000000042, 2.0000000000000013, 107.06, -30.489999999999764, 43.010000000000005, -112.87000000000009, -22.119999999999706, 32.83999999999983, -8.050000000000042, 183.01999999999998, 64.03999999999994, -18.099999999999703, -54.28000000000034, 2.0000000000000013, 94.70000000000036, 193.07, -32.170000000000364, 82.16, 8.0, 75.14, 40.61, -66.33999999999915, 3.4999999999999787, -32.17000000000034, 113.0, 2.0000000000000013, -46.24000000000035, 36.559999999999896, 39.20000000000019, 59.21000000000001, 12.08, -17.289999999999957, 9.469999999999999, -34.18000000000036, 2.0000000000000013, -10.060000000000041, 50.0, 62.0, 109.91000000000047, -8.050000000000042, 32.69, -58.21000000000016, 60.08000000000016, 111.37999999999994, -38.20000000000036, -2.020000000000042, 2.98999999999998, 85.30999999999997, 77.0, 156.44, -2.020000000000042, -18.97, -0.00999999999999836, -60.310000000000336, -149.56000000000034, -300.90999999999997, -42.220000000000354, -24.129999999999736, -172.0, 2.0000000000000013, -17.80000000000004, -202.0, -31.30000000000009, -97.0, 2.0000000000000013, 55.36999999999997, -75.96999999999998, -7.449999999999932, -44.230000000000345, -307.0, -25.36, -286.0, 12.079999999999977, -236.76999999999992, -285.82000000000016, -229.0, -134.6800000000012, -139.36, -189.96999999999997, -24.12999999999978, -273.94, -180.58000000000007, -111.75999999999937, -280.6600000000003, -60.310000000000336, 46.25000000000013], "policy_predator_policy_reward": [4.0, 5.0, 51.0, 21.0, 16.0, 12.0, 3.0, 17.0, 11.0, 38.0, 12.0, 9.0, 9.0, 7.0, 6.0, 1.0, 17.0, 29.0, 31.0, 2.0, 26.0, 9.0, 13.0, 28.0, 0.0, 2.0, 3.0, 1.0, 28.0, 44.0, 6.0, 10.0, 22.0, 3.0, 21.0, 7.0, 25.0, 8.0, 0.0, 33.0, 10.0, 10.0, 10.0, 0.0, 5.0, 0.0, 45.0, 5.0, 19.0, 16.0, 21.0, 39.0, 58.0, 39.0, 18.0, 24.0, 15.0, 14.0, 13.0, 0.0, 9.0, 20.0, 0.0, 1.0, 5.0, 6.0, 36.0, 12.0, 9.0, 9.0, 9.0, 3.0, 6.0, 10.0, 22.0, 27.0, 20.0, 6.0, 20.0, 6.0, 17.0, 3.0, 81.0, 87.0, 2.0, 1.0, 17.0, 15.0, 38.0, 21.0, 2.0, 30.0, 30.0, 17.0, 5.0, 18.0, 32.0, 10.0, 0.0, 48.0, 106.0, 52.0, 3.0, 2.0, 20.0, 34.0, 7.0, 17.0, 54.0, 51.0, 9.0, 2.0, 16.0, 16.0, 2.0, 2.0, 29.0, 27.0, 62.0, 96.0, 17.0, 29.0, 4.0, 6.0, 16.0, 18.0, 28.0, 4.0, 5.0, 9.0, 17.0, 1.0, 68.0, 16.0, 34.0, 14.0, 17.0, 16.0, 23.0, 15.0, 21.0, 39.0, 12.0, 51.0, 12.0, 72.0, 61.0, 5.0, 4.0, 6.0, 17.0, 69.0, 5.0, 4.0, 60.0, 38.0, 17.0, 7.0, 12.0, 11.0, 28.0, 15.0, 34.0, 12.0, 6.0, 72.0, 1.0, 31.0, 110.0, 164.0, 11.0, 31.0, 75.0, 93.0, 132.0, 41.0, 101.0, 55.0, 3.0, 0.0, 34.0, 83.0, 134.0, 107.0, 108.0, 104.0, 73.0, 134.0, 172.0, 115.0, 28.0, 129.0, 88.0, 92.0, 139.0, 129.0, 108.0, 127.0, 31.0, 43.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6755881600787527, "mean_inference_ms": 1.813807308875796, "mean_action_processing_ms": 0.30087224305255766, "mean_env_wait_ms": 0.22903518854059393, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003921389579772949, "StateBufferConnector_ms": 0.006510019302368164, "ViewRequirementAgentConnector_ms": 0.11314737796783447}, "num_episodes": 18, "episode_return_max": 301.76999999999936, "episode_return_min": -227.82000000000005, "episode_return_mean": 37.46320000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 345.7953327320553, "num_env_steps_trained_throughput_per_sec": 345.7953327320553, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 11039.616, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11039.568, "sample_time_ms": 1268.784, "learn_time_ms": 9755.043, "learn_throughput": 410.044, "synch_weights_time_ms": 12.681}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "310e1_00000", "date": "2024-08-15_01-05-27", "timestamp": 1723664127, "time_this_iter_s": 11.622202157974243, "time_total_s": 482.3937575817108, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 482.3937575817108, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 58.45294117647058, "ram_util_percent": 83.51176470588236}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7007322094112478, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.358938567852848, "policy_loss": -0.01022258033315656, "vf_loss": 7.367234714952096, "vf_explained_var": 0.001325901160164485, "kl": 0.012842875051382723, "entropy": 1.3161168654128987, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0084820752106016, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.941260675904612, "policy_loss": -0.007251193388192742, "vf_loss": 6.9473627219124445, "vf_explained_var": -0.17354146557510214, "kl": 0.011491419366621715, "entropy": 0.9605452532490725, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 301.76999999999936, "episode_reward_min": -333.76000000000005, "episode_reward_mean": 16.2483000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.07, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -35.16085, "predator_policy": 43.285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [251.97999999999948, -29.32999999999945, -17.369999999999447, -0.1600000000000401, 13.79999999999992, 22.830000000000418, 0.8099999999999844, -50.570000000000604, 61.399999999999814, 127.33000000000038, -15.32999999999955, 5.719999999999922, 75.69000000000091, 24.770000000000522, 172.22999999999956, -20.359999999999477, -1.3100000000000571, 2.859999999999983, 49.39999999999989, 48.10999999999968, -22.259999999999426, 27.120000000000264, -14.18999999999987, 20.050000000000093, 133.6299999999991, -25.34999999999946, -13.379999999999965, -28.319999999999453, 106.20000000000087, 14.430000000000463, 246.39999999999984, 28.779999999999923, -29.339999999999737, -1.050000000000063, 189.42999999999984, 64.08999999999989, -0.7400000000000406, 120.6000000000008, 71.79000000000082, 3.979999999999959, 132.57000000000022, 88.14000000000004, 56.720000000000155, 184.96999999999974, 79.9400000000005, -20.27999999999945, 301.76999999999936, 67.99000000000025, 167.14000000000001, 22.270000000000405, 4.330000000000118, 153.00000000000006, 50.319999999999865, 161.40999999999997, 78.79, 41.290000000000035, 1.940000000000003, 198.0, 110.86000000000112, 72.47999999999982, 195.4600000000001, -17.219999999999427, 131.3000000000004, 279.44000000000005, 57.01000000000048, -28.319999999999446, -176.47000000000034, -24.349999999999458, -1.99999999999999, -46.799999999999926, 27.700000000000134, 60.36999999999995, 33.580000000000005, -110.22999999999965, -99.35999999999993, -17.689999999999934, -227.82000000000005, -117.03999999999937, -34.10000000000002, -186.5200000000001, -157.42000000000058, 59.94000000000028, -44.97999999999999, 29.729999999999876, -290.49000000000046, 38.68000000000019, -70.14999999999996, -13.17000000000008, 3.809999999999948, 4.829999999999943, 0.8699999999999836, -333.76000000000005, -228.37000000000052, 15.310000000000038, -173.91, -217.8000000000001, -40.909999999999954, -68.00999999999999, 126.40000000000018, -280.73], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [152.41999999999973, 66.55999999999996, -42.220000000000354, -20.10999999999983, -25.299999999999734, -12.070000000000041, 7.93999999999996, -18.099999999999707, 6.799999999999962, 2.0000000000000013, -96.48999999999923, 69.32000000000065, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -98.49999999999928, 9.919999999999959, -45.52000000000007, -50.260000000000346, 135.5899999999999, -26.139999999999713, -18.189999999999717, -24.129999999999708, 16.85000000000011, -33.22000000000033, 79.91000000000045, -0.00999999999999836, 23.780000000000257, 2.0000000000000013, 159.22999999999985, -70.35999999999916, 2.0000000000000013, -16.089999999999755, -3.220000000000038, -11.14000000000004, 2.0000000000000013, 31.400000000000023, 2.0000000000000013, 13.189999999999975, -14.080000000000041, -38.20000000000036, -10.060000000000041, 18.410000000000135, -17.289999999999733, -34.180000000000284, -0.009999999999998581, -156.7900000000002, 8.839999999999982, -0.00999999999999836, 130.63999999999942, -25.17999999999974, -32.170000000000364, -74.37999999999917, 2.0000000000000013, -2.02000000000004, -58.30000000000034, -38.5000000000003, 97.70000000000036, 25.609999999999964, -34.18000000000036, 117.16999999999996, 87.23000000000003, 75.26000000000003, -94.47999999999922, 2.0000000000000013, -189.34000000000057, -4.030000000000042, -2.020000000000042, 62.14999999999997, 73.28, -20.109999999999705, 60.19999999999999, 14.86999999999996, -120.60999999999929, 62.32999999999988, 47.269999999999825, -28.149999999999714, 67.94000000000041, -2.020000000000042, 2.0000000000000013, 107.06, -30.489999999999764, 43.010000000000005, -112.87000000000009, -22.119999999999706, 32.83999999999983, -8.050000000000042, 183.01999999999998, 64.03999999999994, -18.099999999999703, -54.28000000000034, 2.0000000000000013, 94.70000000000036, 193.07, -32.170000000000364, 82.16, 8.0, 75.14, 40.61, -66.33999999999915, 3.4999999999999787, -32.17000000000034, 113.0, 2.0000000000000013, -46.24000000000035, 36.559999999999896, 39.20000000000019, 59.21000000000001, 12.08, -17.289999999999957, 9.469999999999999, -34.18000000000036, 2.0000000000000013, -10.060000000000041, 50.0, 62.0, 109.91000000000047, -8.050000000000042, 32.69, -58.21000000000016, 60.08000000000016, 111.37999999999994, -38.20000000000036, -2.020000000000042, 2.98999999999998, 85.30999999999997, 77.0, 156.44, -2.020000000000042, -18.97, -0.00999999999999836, -60.310000000000336, -149.56000000000034, -300.90999999999997, -42.220000000000354, -24.129999999999736, -172.0, 2.0000000000000013, -17.80000000000004, -202.0, -31.30000000000009, -97.0, 2.0000000000000013, 55.36999999999997, -75.96999999999998, -7.449999999999932, -44.230000000000345, -307.0, -25.36, -286.0, 12.079999999999977, -236.76999999999992, -285.82000000000016, -229.0, -134.6800000000012, -139.36, -189.96999999999997, -24.12999999999978, -273.94, -180.58000000000007, -111.75999999999937, -280.6600000000003, -60.310000000000336, 46.25000000000013, -25.0, -278.98, 2.0000000000000013, -61.27000000000002, -313.0, -183.49000000000046, -8.050000000000042, -1.2700000000001417, -85.0, -112.15000000000002, -32.17000000000006, 2.0000000000000013, -200.5000000000004, 70.31, -76.96000000000001, -40.210000000000356, -24.129999999999708, 2.0000000000000013, -249.76000000000005, -379.0, -310.9000000000001, -170.4700000000003, -174.5500000000004, -8.14000000000001, -144.90999999999997, -268.0, -187.0, -278.80000000000007, -294.91, 2.0000000000000013, -154.72000000000003, -134.2899999999999, 23.210000000000157, 76.19, -320.83000000000004, -241.90000000000003], "policy_predator_policy_reward": [25.0, 8.0, 0.0, 33.0, 10.0, 10.0, 10.0, 0.0, 5.0, 0.0, 45.0, 5.0, 19.0, 16.0, 21.0, 39.0, 58.0, 39.0, 18.0, 24.0, 15.0, 14.0, 13.0, 0.0, 9.0, 20.0, 0.0, 1.0, 5.0, 6.0, 36.0, 12.0, 9.0, 9.0, 9.0, 3.0, 6.0, 10.0, 22.0, 27.0, 20.0, 6.0, 20.0, 6.0, 17.0, 3.0, 81.0, 87.0, 2.0, 1.0, 17.0, 15.0, 38.0, 21.0, 2.0, 30.0, 30.0, 17.0, 5.0, 18.0, 32.0, 10.0, 0.0, 48.0, 106.0, 52.0, 3.0, 2.0, 20.0, 34.0, 7.0, 17.0, 54.0, 51.0, 9.0, 2.0, 16.0, 16.0, 2.0, 2.0, 29.0, 27.0, 62.0, 96.0, 17.0, 29.0, 4.0, 6.0, 16.0, 18.0, 28.0, 4.0, 5.0, 9.0, 17.0, 1.0, 68.0, 16.0, 34.0, 14.0, 17.0, 16.0, 23.0, 15.0, 21.0, 39.0, 12.0, 51.0, 12.0, 72.0, 61.0, 5.0, 4.0, 6.0, 17.0, 69.0, 5.0, 4.0, 60.0, 38.0, 17.0, 7.0, 12.0, 11.0, 28.0, 15.0, 34.0, 12.0, 6.0, 72.0, 1.0, 31.0, 110.0, 164.0, 11.0, 31.0, 75.0, 93.0, 132.0, 41.0, 101.0, 55.0, 3.0, 0.0, 34.0, 83.0, 134.0, 107.0, 108.0, 104.0, 73.0, 134.0, 172.0, 115.0, 28.0, 129.0, 88.0, 92.0, 139.0, 129.0, 108.0, 127.0, 31.0, 43.0, 105.0, 154.0, 37.0, 52.0, 30.0, 176.0, 24.0, 24.0, 67.0, 60.0, 5.0, 12.0, 53.0, 81.0, 64.0, 58.0, 13.0, 10.0, 186.0, 109.0, 98.0, 155.0, 70.0, 128.0, 137.0, 102.0, 125.0, 123.0, 98.0, 154.0, 139.0, 82.0, 6.0, 21.0, 105.0, 177.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6743484501426583, "mean_inference_ms": 1.809658101062779, "mean_action_processing_ms": 0.2998689523944359, "mean_env_wait_ms": 0.22865057598537028, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004014134407043457, "StateBufferConnector_ms": 0.003990292549133301, "ViewRequirementAgentConnector_ms": 0.15951478481292725}, "num_episodes": 18, "episode_return_max": 301.76999999999936, "episode_return_min": -333.76000000000005, "episode_return_mean": 16.2483000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 345.0307046021572, "num_env_steps_trained_throughput_per_sec": 345.0307046021572, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 11107.167, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11107.119, "sample_time_ms": 1309.953, "learn_time_ms": 9781.722, "learn_throughput": 408.926, "synch_weights_time_ms": 12.497}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "310e1_00000", "date": "2024-08-15_01-05-38", "timestamp": 1723664138, "time_this_iter_s": 11.670868873596191, "time_total_s": 494.064626455307, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14821f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 494.064626455307, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 59.79375, "ram_util_percent": 83.44375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6185198030774555, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.201370203431952, "policy_loss": -0.0065658124966950955, "vf_loss": 7.206158682152077, "vf_explained_var": 0.002459780217478515, "kl": 0.011848863489697015, "entropy": 1.261986199636308, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1034405512469156, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.081628499081526, "policy_loss": -0.012351604253447876, "vf_loss": 5.09166309038798, "vf_explained_var": -0.10071674269973917, "kl": 0.023169956669144346, "entropy": 0.9720921907475386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 301.76999999999936, "episode_reward_min": -406.9100000000001, "episode_reward_mean": -1.8404999999999228, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -385.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.07, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -58.815250000000034, "predator_policy": 57.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [49.39999999999989, 48.10999999999968, -22.259999999999426, 27.120000000000264, -14.18999999999987, 20.050000000000093, 133.6299999999991, -25.34999999999946, -13.379999999999965, -28.319999999999453, 106.20000000000087, 14.430000000000463, 246.39999999999984, 28.779999999999923, -29.339999999999737, -1.050000000000063, 189.42999999999984, 64.08999999999989, -0.7400000000000406, 120.6000000000008, 71.79000000000082, 3.979999999999959, 132.57000000000022, 88.14000000000004, 56.720000000000155, 184.96999999999974, 79.9400000000005, -20.27999999999945, 301.76999999999936, 67.99000000000025, 167.14000000000001, 22.270000000000405, 4.330000000000118, 153.00000000000006, 50.319999999999865, 161.40999999999997, 78.79, 41.290000000000035, 1.940000000000003, 198.0, 110.86000000000112, 72.47999999999982, 195.4600000000001, -17.219999999999427, 131.3000000000004, 279.44000000000005, 57.01000000000048, -28.319999999999446, -176.47000000000034, -24.349999999999458, -1.99999999999999, -46.799999999999926, 27.700000000000134, 60.36999999999995, 33.580000000000005, -110.22999999999965, -99.35999999999993, -17.689999999999934, -227.82000000000005, -117.03999999999937, -34.10000000000002, -186.5200000000001, -157.42000000000058, 59.94000000000028, -44.97999999999999, 29.729999999999876, -290.49000000000046, 38.68000000000019, -70.14999999999996, -13.17000000000008, 3.809999999999948, 4.829999999999943, 0.8699999999999836, -333.76000000000005, -228.37000000000052, 15.310000000000038, -173.91, -217.8000000000001, -40.909999999999954, -68.00999999999999, 126.40000000000018, -280.73, -29.689999999999955, 10.54000000000026, -406.9100000000001, 3.7999999999999865, -74.67999999999947, -98.00999999999955, -35.68999999999999, -76.05999999999989, 10.88000000000013, -36.910000000000615, -119.99999999999956, -47.03000000000055, -37.430000000000675, 16.690000000000015, -14.539999999999845, -0.06000000000004011, -172.69000000000025, -76.10000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.400000000000023, 2.0000000000000013, 13.189999999999975, -14.080000000000041, -38.20000000000036, -10.060000000000041, 18.410000000000135, -17.289999999999733, -34.180000000000284, -0.009999999999998581, -156.7900000000002, 8.839999999999982, -0.00999999999999836, 130.63999999999942, -25.17999999999974, -32.170000000000364, -74.37999999999917, 2.0000000000000013, -2.02000000000004, -58.30000000000034, -38.5000000000003, 97.70000000000036, 25.609999999999964, -34.18000000000036, 117.16999999999996, 87.23000000000003, 75.26000000000003, -94.47999999999922, 2.0000000000000013, -189.34000000000057, -4.030000000000042, -2.020000000000042, 62.14999999999997, 73.28, -20.109999999999705, 60.19999999999999, 14.86999999999996, -120.60999999999929, 62.32999999999988, 47.269999999999825, -28.149999999999714, 67.94000000000041, -2.020000000000042, 2.0000000000000013, 107.06, -30.489999999999764, 43.010000000000005, -112.87000000000009, -22.119999999999706, 32.83999999999983, -8.050000000000042, 183.01999999999998, 64.03999999999994, -18.099999999999703, -54.28000000000034, 2.0000000000000013, 94.70000000000036, 193.07, -32.170000000000364, 82.16, 8.0, 75.14, 40.61, -66.33999999999915, 3.4999999999999787, -32.17000000000034, 113.0, 2.0000000000000013, -46.24000000000035, 36.559999999999896, 39.20000000000019, 59.21000000000001, 12.08, -17.289999999999957, 9.469999999999999, -34.18000000000036, 2.0000000000000013, -10.060000000000041, 50.0, 62.0, 109.91000000000047, -8.050000000000042, 32.69, -58.21000000000016, 60.08000000000016, 111.37999999999994, -38.20000000000036, -2.020000000000042, 2.98999999999998, 85.30999999999997, 77.0, 156.44, -2.020000000000042, -18.97, -0.00999999999999836, -60.310000000000336, -149.56000000000034, -300.90999999999997, -42.220000000000354, -24.129999999999736, -172.0, 2.0000000000000013, -17.80000000000004, -202.0, -31.30000000000009, -97.0, 2.0000000000000013, 55.36999999999997, -75.96999999999998, -7.449999999999932, -44.230000000000345, -307.0, -25.36, -286.0, 12.079999999999977, -236.76999999999992, -285.82000000000016, -229.0, -134.6800000000012, -139.36, -189.96999999999997, -24.12999999999978, -273.94, -180.58000000000007, -111.75999999999937, -280.6600000000003, -60.310000000000336, 46.25000000000013, -25.0, -278.98, 2.0000000000000013, -61.27000000000002, -313.0, -183.49000000000046, -8.050000000000042, -1.2700000000001417, -85.0, -112.15000000000002, -32.17000000000006, 2.0000000000000013, -200.5000000000004, 70.31, -76.96000000000001, -40.210000000000356, -24.129999999999708, 2.0000000000000013, -249.76000000000005, -379.0, -310.9000000000001, -170.4700000000003, -174.5500000000004, -8.14000000000001, -144.90999999999997, -268.0, -187.0, -278.80000000000007, -294.91, 2.0000000000000013, -154.72000000000003, -134.2899999999999, 23.210000000000157, 76.19, -320.83000000000004, -241.90000000000003, -12.070000000000041, -215.62, -26.13999999999971, -35.319999999999894, -372.94000000000005, -321.97, -275.38000000000056, -15.82, -151.15000000000046, -104.52999999999925, -369.8800000000001, -24.129999999999708, 2.0000000000000013, -127.68999999999988, -10.060000000000041, -385.0, -157.0, -22.119999999999706, -34.18000000000036, -141.73000000000116, -194.68000000000023, -197.3200000000006, -184.93000000000097, -18.099999999999703, -20.109999999999715, -62.320000000000334, -257.74000000000024, -16.569999999999784, -70.35999999999936, 19.82000000000027, 2.0000000000000013, -10.060000000000041, -284.98, -242.7100000000002, -295.0, -18.099999999999998], "policy_predator_policy_reward": [6.0, 10.0, 22.0, 27.0, 20.0, 6.0, 20.0, 6.0, 17.0, 3.0, 81.0, 87.0, 2.0, 1.0, 17.0, 15.0, 38.0, 21.0, 2.0, 30.0, 30.0, 17.0, 5.0, 18.0, 32.0, 10.0, 0.0, 48.0, 106.0, 52.0, 3.0, 2.0, 20.0, 34.0, 7.0, 17.0, 54.0, 51.0, 9.0, 2.0, 16.0, 16.0, 2.0, 2.0, 29.0, 27.0, 62.0, 96.0, 17.0, 29.0, 4.0, 6.0, 16.0, 18.0, 28.0, 4.0, 5.0, 9.0, 17.0, 1.0, 68.0, 16.0, 34.0, 14.0, 17.0, 16.0, 23.0, 15.0, 21.0, 39.0, 12.0, 51.0, 12.0, 72.0, 61.0, 5.0, 4.0, 6.0, 17.0, 69.0, 5.0, 4.0, 60.0, 38.0, 17.0, 7.0, 12.0, 11.0, 28.0, 15.0, 34.0, 12.0, 6.0, 72.0, 1.0, 31.0, 110.0, 164.0, 11.0, 31.0, 75.0, 93.0, 132.0, 41.0, 101.0, 55.0, 3.0, 0.0, 34.0, 83.0, 134.0, 107.0, 108.0, 104.0, 73.0, 134.0, 172.0, 115.0, 28.0, 129.0, 88.0, 92.0, 139.0, 129.0, 108.0, 127.0, 31.0, 43.0, 105.0, 154.0, 37.0, 52.0, 30.0, 176.0, 24.0, 24.0, 67.0, 60.0, 5.0, 12.0, 53.0, 81.0, 64.0, 58.0, 13.0, 10.0, 186.0, 109.0, 98.0, 155.0, 70.0, 128.0, 137.0, 102.0, 125.0, 123.0, 98.0, 154.0, 139.0, 82.0, 6.0, 21.0, 105.0, 177.0, 74.0, 124.0, 34.0, 38.0, 159.0, 129.0, 154.0, 141.0, 111.0, 70.0, 136.0, 160.0, 57.0, 33.0, 164.0, 155.0, 88.0, 102.0, 67.0, 72.0, 137.0, 135.0, 91.0, 65.0, 13.0, 32.0, 146.0, 145.0, 36.0, 0.0, 6.0, 2.0, 173.0, 182.0, 155.0, 82.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6733315033538279, "mean_inference_ms": 1.806048187982964, "mean_action_processing_ms": 0.2989444249188164, "mean_env_wait_ms": 0.22831136543457817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039566755294799805, "StateBufferConnector_ms": 0.003929495811462402, "ViewRequirementAgentConnector_ms": 0.1587367057800293}, "num_episodes": 18, "episode_return_max": 301.76999999999936, "episode_return_min": -406.9100000000001, "episode_return_mean": -1.8404999999999228, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.82580320199196, "num_env_steps_trained_throughput_per_sec": 368.82580320199196, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 11101.73, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11101.682, "sample_time_ms": 1309.198, "learn_time_ms": 9776.838, "learn_throughput": 409.13, "synch_weights_time_ms": 12.529}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "310e1_00000", "date": "2024-08-15_01-05-49", "timestamp": 1723664149, "time_this_iter_s": 10.911746978759766, "time_total_s": 504.9763734340668, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14cf1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 504.9763734340668, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 54.8125, "ram_util_percent": 83.30000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.676385009698767, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.883522592272077, "policy_loss": -0.00744361845276284, "vf_loss": 4.8893555189566635, "vf_explained_var": 0.008139476006623928, "kl": 0.01073794534148749, "entropy": 1.1940680875980034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.441983705254459, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4139758031835, "policy_loss": -0.008697070700249502, "vf_loss": 3.420820880693103, "vf_explained_var": -0.10441734014995514, "kl": 0.012346597187293598, "entropy": 1.0758657778697038, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 301.76999999999936, "episode_reward_min": -406.9100000000001, "episode_reward_mean": -19.15719999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -385.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.07, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -79.55860000000004, "predator_policy": 69.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [132.57000000000022, 88.14000000000004, 56.720000000000155, 184.96999999999974, 79.9400000000005, -20.27999999999945, 301.76999999999936, 67.99000000000025, 167.14000000000001, 22.270000000000405, 4.330000000000118, 153.00000000000006, 50.319999999999865, 161.40999999999997, 78.79, 41.290000000000035, 1.940000000000003, 198.0, 110.86000000000112, 72.47999999999982, 195.4600000000001, -17.219999999999427, 131.3000000000004, 279.44000000000005, 57.01000000000048, -28.319999999999446, -176.47000000000034, -24.349999999999458, -1.99999999999999, -46.799999999999926, 27.700000000000134, 60.36999999999995, 33.580000000000005, -110.22999999999965, -99.35999999999993, -17.689999999999934, -227.82000000000005, -117.03999999999937, -34.10000000000002, -186.5200000000001, -157.42000000000058, 59.94000000000028, -44.97999999999999, 29.729999999999876, -290.49000000000046, 38.68000000000019, -70.14999999999996, -13.17000000000008, 3.809999999999948, 4.829999999999943, 0.8699999999999836, -333.76000000000005, -228.37000000000052, 15.310000000000038, -173.91, -217.8000000000001, -40.909999999999954, -68.00999999999999, 126.40000000000018, -280.73, -29.689999999999955, 10.54000000000026, -406.9100000000001, 3.7999999999999865, -74.67999999999947, -98.00999999999955, -35.68999999999999, -76.05999999999989, 10.88000000000013, -36.910000000000615, -119.99999999999956, -47.03000000000055, -37.430000000000675, 16.690000000000015, -14.539999999999845, -0.06000000000004011, -172.69000000000025, -76.10000000000002, -163.34000000000123, -8.400000000000077, -48.59000000000067, -84.61999999999937, -88.32999999999866, 2.76999999999996, -41.67000000000045, -0.42000000000002613, 35.10000000000011, -83.06999999999977, -36.40000000000064, -9.88000000000004, -50.230000000000146, -100.2499999999986, -20.199999999999868, -8.120000000000083, 152.46000000000006, -35.89000000000062, -43.77000000000058, -16.779999999999625, -18.140000000000008, -74.51999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [107.06, -30.489999999999764, 43.010000000000005, -112.87000000000009, -22.119999999999706, 32.83999999999983, -8.050000000000042, 183.01999999999998, 64.03999999999994, -18.099999999999703, -54.28000000000034, 2.0000000000000013, 94.70000000000036, 193.07, -32.170000000000364, 82.16, 8.0, 75.14, 40.61, -66.33999999999915, 3.4999999999999787, -32.17000000000034, 113.0, 2.0000000000000013, -46.24000000000035, 36.559999999999896, 39.20000000000019, 59.21000000000001, 12.08, -17.289999999999957, 9.469999999999999, -34.18000000000036, 2.0000000000000013, -10.060000000000041, 50.0, 62.0, 109.91000000000047, -8.050000000000042, 32.69, -58.21000000000016, 60.08000000000016, 111.37999999999994, -38.20000000000036, -2.020000000000042, 2.98999999999998, 85.30999999999997, 77.0, 156.44, -2.020000000000042, -18.97, -0.00999999999999836, -60.310000000000336, -149.56000000000034, -300.90999999999997, -42.220000000000354, -24.129999999999736, -172.0, 2.0000000000000013, -17.80000000000004, -202.0, -31.30000000000009, -97.0, 2.0000000000000013, 55.36999999999997, -75.96999999999998, -7.449999999999932, -44.230000000000345, -307.0, -25.36, -286.0, 12.079999999999977, -236.76999999999992, -285.82000000000016, -229.0, -134.6800000000012, -139.36, -189.96999999999997, -24.12999999999978, -273.94, -180.58000000000007, -111.75999999999937, -280.6600000000003, -60.310000000000336, 46.25000000000013, -25.0, -278.98, 2.0000000000000013, -61.27000000000002, -313.0, -183.49000000000046, -8.050000000000042, -1.2700000000001417, -85.0, -112.15000000000002, -32.17000000000006, 2.0000000000000013, -200.5000000000004, 70.31, -76.96000000000001, -40.210000000000356, -24.129999999999708, 2.0000000000000013, -249.76000000000005, -379.0, -310.9000000000001, -170.4700000000003, -174.5500000000004, -8.14000000000001, -144.90999999999997, -268.0, -187.0, -278.80000000000007, -294.91, 2.0000000000000013, -154.72000000000003, -134.2899999999999, 23.210000000000157, 76.19, -320.83000000000004, -241.90000000000003, -12.070000000000041, -215.62, -26.13999999999971, -35.319999999999894, -372.94000000000005, -321.97, -275.38000000000056, -15.82, -151.15000000000046, -104.52999999999925, -369.8800000000001, -24.129999999999708, 2.0000000000000013, -127.68999999999988, -10.060000000000041, -385.0, -157.0, -22.119999999999706, -34.18000000000036, -141.73000000000116, -194.68000000000023, -197.3200000000006, -184.93000000000097, -18.099999999999703, -20.109999999999715, -62.320000000000334, -257.74000000000024, -16.569999999999784, -70.35999999999936, 19.82000000000027, 2.0000000000000013, -10.060000000000041, -284.98, -242.7100000000002, -295.0, -18.099999999999998, -116.58999999999929, -325.75, -78.39999999999918, 2.0000000000000013, -28.14999999999971, -86.4399999999992, -28.14999999999971, -290.4700000000005, -175.0000000000009, -64.32999999999917, -161.20000000000073, 4.969999999999958, -106.14999999999961, -102.51999999999924, -23.16999999999998, -207.25000000000068, 25.760000000000005, -127.66000000000074, -358.0, -12.070000000000041, -4.030000000000042, -72.36999999999917, -114.87999999999954, 2.0000000000000013, -226.60000000000014, -109.6299999999993, -150.76000000000113, -96.48999999999923, -206.20000000000022, 2.0000000000000013, -14.080000000000041, -6.040000000000042, 2.0000000000000013, 148.45999999999998, -38.23000000000035, -130.6600000000012, -42.220000000000354, -63.54999999999971, -154.7800000000011, 2.0000000000000013, -145.57000000000008, -196.5700000000004, -43.27000000000034, -225.25000000000068], "policy_predator_policy_reward": [29.0, 27.0, 62.0, 96.0, 17.0, 29.0, 4.0, 6.0, 16.0, 18.0, 28.0, 4.0, 5.0, 9.0, 17.0, 1.0, 68.0, 16.0, 34.0, 14.0, 17.0, 16.0, 23.0, 15.0, 21.0, 39.0, 12.0, 51.0, 12.0, 72.0, 61.0, 5.0, 4.0, 6.0, 17.0, 69.0, 5.0, 4.0, 60.0, 38.0, 17.0, 7.0, 12.0, 11.0, 28.0, 15.0, 34.0, 12.0, 6.0, 72.0, 1.0, 31.0, 110.0, 164.0, 11.0, 31.0, 75.0, 93.0, 132.0, 41.0, 101.0, 55.0, 3.0, 0.0, 34.0, 83.0, 134.0, 107.0, 108.0, 104.0, 73.0, 134.0, 172.0, 115.0, 28.0, 129.0, 88.0, 92.0, 139.0, 129.0, 108.0, 127.0, 31.0, 43.0, 105.0, 154.0, 37.0, 52.0, 30.0, 176.0, 24.0, 24.0, 67.0, 60.0, 5.0, 12.0, 53.0, 81.0, 64.0, 58.0, 13.0, 10.0, 186.0, 109.0, 98.0, 155.0, 70.0, 128.0, 137.0, 102.0, 125.0, 123.0, 98.0, 154.0, 139.0, 82.0, 6.0, 21.0, 105.0, 177.0, 74.0, 124.0, 34.0, 38.0, 159.0, 129.0, 154.0, 141.0, 111.0, 70.0, 136.0, 160.0, 57.0, 33.0, 164.0, 155.0, 88.0, 102.0, 67.0, 72.0, 137.0, 135.0, 91.0, 65.0, 13.0, 32.0, 146.0, 145.0, 36.0, 0.0, 6.0, 2.0, 173.0, 182.0, 155.0, 82.0, 182.0, 97.0, 32.0, 36.0, 44.0, 22.0, 110.0, 124.0, 91.0, 60.0, 93.0, 66.0, 73.0, 94.0, 110.0, 120.0, 63.0, 74.0, 140.0, 147.0, 37.0, 3.0, 42.0, 61.0, 149.0, 137.0, 74.0, 73.0, 107.0, 77.0, 8.0, 4.0, 2.0, 0.0, 66.0, 67.0, 36.0, 26.0, 58.0, 78.0, 159.0, 165.0, 105.0, 89.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6722355868992284, "mean_inference_ms": 1.8016023626717432, "mean_action_processing_ms": 0.29783426913727173, "mean_env_wait_ms": 0.2278436626528265, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004087090492248535, "StateBufferConnector_ms": 0.0038323402404785156, "ViewRequirementAgentConnector_ms": 0.15523362159729004}, "num_episodes": 22, "episode_return_max": 301.76999999999936, "episode_return_min": -406.9100000000001, "episode_return_mean": -19.15719999999995, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.4912175830003, "num_env_steps_trained_throughput_per_sec": 353.4912175830003, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 11115.458, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11115.408, "sample_time_ms": 1299.368, "learn_time_ms": 9800.224, "learn_throughput": 408.154, "synch_weights_time_ms": 12.672}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "310e1_00000", "date": "2024-08-15_01-06-01", "timestamp": 1723664161, "time_this_iter_s": 11.375966787338257, "time_total_s": 516.352340221405, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12d9700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 516.352340221405, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 58.3125, "ram_util_percent": 83.29375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5868613877782116, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4022510912052537, "policy_loss": -0.0063790174050838075, "vf_loss": 3.4076032813894686, "vf_explained_var": 0.0259437190161811, "kl": 0.006845501007881658, "entropy": 1.1263724228692433, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1525045277265016, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8279613020558836, "policy_loss": -0.015608322484389184, "vf_loss": 2.841333133455307, "vf_explained_var": -0.2100790042410452, "kl": 0.01490994261774326, "entropy": 1.0003966747768342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 279.44000000000005, "episode_reward_min": -406.9100000000001, "episode_reward_mean": -45.24549999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -385.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.44, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -98.07775000000005, "predator_policy": 75.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [279.44000000000005, 57.01000000000048, -28.319999999999446, -176.47000000000034, -24.349999999999458, -1.99999999999999, -46.799999999999926, 27.700000000000134, 60.36999999999995, 33.580000000000005, -110.22999999999965, -99.35999999999993, -17.689999999999934, -227.82000000000005, -117.03999999999937, -34.10000000000002, -186.5200000000001, -157.42000000000058, 59.94000000000028, -44.97999999999999, 29.729999999999876, -290.49000000000046, 38.68000000000019, -70.14999999999996, -13.17000000000008, 3.809999999999948, 4.829999999999943, 0.8699999999999836, -333.76000000000005, -228.37000000000052, 15.310000000000038, -173.91, -217.8000000000001, -40.909999999999954, -68.00999999999999, 126.40000000000018, -280.73, -29.689999999999955, 10.54000000000026, -406.9100000000001, 3.7999999999999865, -74.67999999999947, -98.00999999999955, -35.68999999999999, -76.05999999999989, 10.88000000000013, -36.910000000000615, -119.99999999999956, -47.03000000000055, -37.430000000000675, 16.690000000000015, -14.539999999999845, -0.06000000000004011, -172.69000000000025, -76.10000000000002, -163.34000000000123, -8.400000000000077, -48.59000000000067, -84.61999999999937, -88.32999999999866, 2.76999999999996, -41.67000000000045, -0.42000000000002613, 35.10000000000011, -83.06999999999977, -36.40000000000064, -9.88000000000004, -50.230000000000146, -100.2499999999986, -20.199999999999868, -8.120000000000083, 152.46000000000006, -35.89000000000062, -43.77000000000058, -16.779999999999625, -18.140000000000008, -74.51999999999943, -14.999999999999984, -8.560000000000073, 10.439999999999928, -0.8400000000000407, -23.32999999999945, -111.16999999999997, -53.57000000000038, -27.069999999999542, -102.61999999999934, -2.060000000000084, -34.38000000000064, -13.120000000000056, -14.589999999999982, 26.840000000000227, -34.509999999999636, 23.260000000000012, 6.05999999999994, 14.169999999999934, -4.65000000000007, 8.789999999999921, -36.41000000000027, 63.31999999999994, -16.63999999999962], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [77.0, 156.44, -2.020000000000042, -18.97, -0.00999999999999836, -60.310000000000336, -149.56000000000034, -300.90999999999997, -42.220000000000354, -24.129999999999736, -172.0, 2.0000000000000013, -17.80000000000004, -202.0, -31.30000000000009, -97.0, 2.0000000000000013, 55.36999999999997, -75.96999999999998, -7.449999999999932, -44.230000000000345, -307.0, -25.36, -286.0, 12.079999999999977, -236.76999999999992, -285.82000000000016, -229.0, -134.6800000000012, -139.36, -189.96999999999997, -24.12999999999978, -273.94, -180.58000000000007, -111.75999999999937, -280.6600000000003, -60.310000000000336, 46.25000000000013, -25.0, -278.98, 2.0000000000000013, -61.27000000000002, -313.0, -183.49000000000046, -8.050000000000042, -1.2700000000001417, -85.0, -112.15000000000002, -32.17000000000006, 2.0000000000000013, -200.5000000000004, 70.31, -76.96000000000001, -40.210000000000356, -24.129999999999708, 2.0000000000000013, -249.76000000000005, -379.0, -310.9000000000001, -170.4700000000003, -174.5500000000004, -8.14000000000001, -144.90999999999997, -268.0, -187.0, -278.80000000000007, -294.91, 2.0000000000000013, -154.72000000000003, -134.2899999999999, 23.210000000000157, 76.19, -320.83000000000004, -241.90000000000003, -12.070000000000041, -215.62, -26.13999999999971, -35.319999999999894, -372.94000000000005, -321.97, -275.38000000000056, -15.82, -151.15000000000046, -104.52999999999925, -369.8800000000001, -24.129999999999708, 2.0000000000000013, -127.68999999999988, -10.060000000000041, -385.0, -157.0, -22.119999999999706, -34.18000000000036, -141.73000000000116, -194.68000000000023, -197.3200000000006, -184.93000000000097, -18.099999999999703, -20.109999999999715, -62.320000000000334, -257.74000000000024, -16.569999999999784, -70.35999999999936, 19.82000000000027, 2.0000000000000013, -10.060000000000041, -284.98, -242.7100000000002, -295.0, -18.099999999999998, -116.58999999999929, -325.75, -78.39999999999918, 2.0000000000000013, -28.14999999999971, -86.4399999999992, -28.14999999999971, -290.4700000000005, -175.0000000000009, -64.32999999999917, -161.20000000000073, 4.969999999999958, -106.14999999999961, -102.51999999999924, -23.16999999999998, -207.25000000000068, 25.760000000000005, -127.66000000000074, -358.0, -12.070000000000041, -4.030000000000042, -72.36999999999917, -114.87999999999954, 2.0000000000000013, -226.60000000000014, -109.6299999999993, -150.76000000000113, -96.48999999999923, -206.20000000000022, 2.0000000000000013, -14.080000000000041, -6.040000000000042, 2.0000000000000013, 148.45999999999998, -38.23000000000035, -130.6600000000012, -42.220000000000354, -63.54999999999971, -154.7800000000011, 2.0000000000000013, -145.57000000000008, -196.5700000000004, -43.27000000000034, -225.25000000000068, -8.050000000000042, -188.95000000000095, -3.2500000000000018, -60.31000000000027, 10.909999999999961, -83.46999999999922, 8.89999999999996, -122.73999999999936, -8.050000000000042, -45.28000000000034, 2.0000000000000013, -233.1700000000001, -68.34999999999955, -42.22000000000026, -16.0899999999997, -191.98000000000093, -164.26000000000062, -130.36000000000016, -4.030000000000042, -4.030000000000042, -2.020000000000042, -70.35999999999916, -169.06000000000074, -10.060000000000041, -24.129999999999708, -147.46000000000043, -74.10999999999972, -8.050000000000042, -74.38000000000027, -24.1299999999998, -31.690000000000023, -8.050000000000042, -111.93999999999946, 2.0000000000000013, -76.72000000000003, 0.8899999999999604, -77.64999999999962, 2.0000000000000013, 6.829999999999961, -6.040000000000042, -8.050000000000042, -244.36000000000058, 2.0000000000000013, 54.31999999999997, -0.00999999999999836, -124.6299999999993], "policy_predator_policy_reward": [34.0, 12.0, 6.0, 72.0, 1.0, 31.0, 110.0, 164.0, 11.0, 31.0, 75.0, 93.0, 132.0, 41.0, 101.0, 55.0, 3.0, 0.0, 34.0, 83.0, 134.0, 107.0, 108.0, 104.0, 73.0, 134.0, 172.0, 115.0, 28.0, 129.0, 88.0, 92.0, 139.0, 129.0, 108.0, 127.0, 31.0, 43.0, 105.0, 154.0, 37.0, 52.0, 30.0, 176.0, 24.0, 24.0, 67.0, 60.0, 5.0, 12.0, 53.0, 81.0, 64.0, 58.0, 13.0, 10.0, 186.0, 109.0, 98.0, 155.0, 70.0, 128.0, 137.0, 102.0, 125.0, 123.0, 98.0, 154.0, 139.0, 82.0, 6.0, 21.0, 105.0, 177.0, 74.0, 124.0, 34.0, 38.0, 159.0, 129.0, 154.0, 141.0, 111.0, 70.0, 136.0, 160.0, 57.0, 33.0, 164.0, 155.0, 88.0, 102.0, 67.0, 72.0, 137.0, 135.0, 91.0, 65.0, 13.0, 32.0, 146.0, 145.0, 36.0, 0.0, 6.0, 2.0, 173.0, 182.0, 155.0, 82.0, 182.0, 97.0, 32.0, 36.0, 44.0, 22.0, 110.0, 124.0, 91.0, 60.0, 93.0, 66.0, 73.0, 94.0, 110.0, 120.0, 63.0, 74.0, 140.0, 147.0, 37.0, 3.0, 42.0, 61.0, 149.0, 137.0, 74.0, 73.0, 107.0, 77.0, 8.0, 4.0, 2.0, 0.0, 66.0, 67.0, 36.0, 26.0, 58.0, 78.0, 159.0, 165.0, 105.0, 89.0, 95.0, 87.0, 29.0, 26.0, 44.0, 39.0, 58.0, 55.0, 5.0, 25.0, 3.0, 117.0, 2.0, 55.0, 91.0, 90.0, 86.0, 106.0, 2.0, 4.0, 2.0, 36.0, 87.0, 79.0, 70.0, 87.0, 56.0, 53.0, 21.0, 43.0, 28.0, 35.0, 61.0, 55.0, 42.0, 48.0, 28.0, 43.0, 4.0, 4.0, 92.0, 124.0, 2.0, 5.0, 52.0, 56.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6719222936884188, "mean_inference_ms": 1.7991830251834784, "mean_action_processing_ms": 0.29674672657255136, "mean_env_wait_ms": 0.22757173945679499, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005613207817077637, "StateBufferConnector_ms": 0.003262758255004883, "ViewRequirementAgentConnector_ms": 0.1496187448501587}, "num_episodes": 23, "episode_return_max": 279.44000000000005, "episode_return_min": -406.9100000000001, "episode_return_mean": -45.24549999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.47518338241196, "num_env_steps_trained_throughput_per_sec": 338.47518338241196, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 11215.067, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11215.018, "sample_time_ms": 1321.586, "learn_time_ms": 9877.308, "learn_throughput": 404.969, "synch_weights_time_ms": 13.152}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "310e1_00000", "date": "2024-08-15_01-06-13", "timestamp": 1723664173, "time_this_iter_s": 11.859340906143188, "time_total_s": 528.2116811275482, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 528.2116811275482, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 64.72352941176472, "ram_util_percent": 83.69411764705882}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3152385551935781, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9576359058814075, "policy_loss": -0.0070823991444533465, "vf_loss": 1.963892525024515, "vf_explained_var": 0.013121438625628356, "kl": 0.005505222671438713, "entropy": 1.1605614471057104, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3886048148233425, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8878131480128677, "policy_loss": -0.004824823187664151, "vf_loss": 1.8920156248662838, "vf_explained_var": 0.02670894356631728, "kl": 0.0041489825976119615, "entropy": 0.8686577285408343, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 152.46000000000006, "episode_reward_min": -406.9100000000001, "episode_reward_mean": -38.99880000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -385.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 148.45999999999998, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -84.66940000000004, "predator_policy": 65.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.94000000000028, -44.97999999999999, 29.729999999999876, -290.49000000000046, 38.68000000000019, -70.14999999999996, -13.17000000000008, 3.809999999999948, 4.829999999999943, 0.8699999999999836, -333.76000000000005, -228.37000000000052, 15.310000000000038, -173.91, -217.8000000000001, -40.909999999999954, -68.00999999999999, 126.40000000000018, -280.73, -29.689999999999955, 10.54000000000026, -406.9100000000001, 3.7999999999999865, -74.67999999999947, -98.00999999999955, -35.68999999999999, -76.05999999999989, 10.88000000000013, -36.910000000000615, -119.99999999999956, -47.03000000000055, -37.430000000000675, 16.690000000000015, -14.539999999999845, -0.06000000000004011, -172.69000000000025, -76.10000000000002, -163.34000000000123, -8.400000000000077, -48.59000000000067, -84.61999999999937, -88.32999999999866, 2.76999999999996, -41.67000000000045, -0.42000000000002613, 35.10000000000011, -83.06999999999977, -36.40000000000064, -9.88000000000004, -50.230000000000146, -100.2499999999986, -20.199999999999868, -8.120000000000083, 152.46000000000006, -35.89000000000062, -43.77000000000058, -16.779999999999625, -18.140000000000008, -74.51999999999943, -14.999999999999984, -8.560000000000073, 10.439999999999928, -0.8400000000000407, -23.32999999999945, -111.16999999999997, -53.57000000000038, -27.069999999999542, -102.61999999999934, -2.060000000000084, -34.38000000000064, -13.120000000000056, -14.589999999999982, 26.840000000000227, -34.509999999999636, 23.260000000000012, 6.05999999999994, 14.169999999999934, -4.65000000000007, 8.789999999999921, -36.41000000000027, 63.31999999999994, -16.63999999999962, -189.4100000000017, -28.34999999999947, 12.64000000000004, -6.840000000000064, 35.32999999999936, -6.070000000000084, 6.869999999999935, 0.9399999999999819, 26.510000000000506, -36.190000000000275, 39.51999999999937, -4.080000000000084, 44.82999999999986, -29.629999999999722, 7.77999999999992, -13.169999999999924, -0.9400000000005269, -5.090000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-60.310000000000336, 46.25000000000013, -25.0, -278.98, 2.0000000000000013, -61.27000000000002, -313.0, -183.49000000000046, -8.050000000000042, -1.2700000000001417, -85.0, -112.15000000000002, -32.17000000000006, 2.0000000000000013, -200.5000000000004, 70.31, -76.96000000000001, -40.210000000000356, -24.129999999999708, 2.0000000000000013, -249.76000000000005, -379.0, -310.9000000000001, -170.4700000000003, -174.5500000000004, -8.14000000000001, -144.90999999999997, -268.0, -187.0, -278.80000000000007, -294.91, 2.0000000000000013, -154.72000000000003, -134.2899999999999, 23.210000000000157, 76.19, -320.83000000000004, -241.90000000000003, -12.070000000000041, -215.62, -26.13999999999971, -35.319999999999894, -372.94000000000005, -321.97, -275.38000000000056, -15.82, -151.15000000000046, -104.52999999999925, -369.8800000000001, -24.129999999999708, 2.0000000000000013, -127.68999999999988, -10.060000000000041, -385.0, -157.0, -22.119999999999706, -34.18000000000036, -141.73000000000116, -194.68000000000023, -197.3200000000006, -184.93000000000097, -18.099999999999703, -20.109999999999715, -62.320000000000334, -257.74000000000024, -16.569999999999784, -70.35999999999936, 19.82000000000027, 2.0000000000000013, -10.060000000000041, -284.98, -242.7100000000002, -295.0, -18.099999999999998, -116.58999999999929, -325.75, -78.39999999999918, 2.0000000000000013, -28.14999999999971, -86.4399999999992, -28.14999999999971, -290.4700000000005, -175.0000000000009, -64.32999999999917, -161.20000000000073, 4.969999999999958, -106.14999999999961, -102.51999999999924, -23.16999999999998, -207.25000000000068, 25.760000000000005, -127.66000000000074, -358.0, -12.070000000000041, -4.030000000000042, -72.36999999999917, -114.87999999999954, 2.0000000000000013, -226.60000000000014, -109.6299999999993, -150.76000000000113, -96.48999999999923, -206.20000000000022, 2.0000000000000013, -14.080000000000041, -6.040000000000042, 2.0000000000000013, 148.45999999999998, -38.23000000000035, -130.6600000000012, -42.220000000000354, -63.54999999999971, -154.7800000000011, 2.0000000000000013, -145.57000000000008, -196.5700000000004, -43.27000000000034, -225.25000000000068, -8.050000000000042, -188.95000000000095, -3.2500000000000018, -60.31000000000027, 10.909999999999961, -83.46999999999922, 8.89999999999996, -122.73999999999936, -8.050000000000042, -45.28000000000034, 2.0000000000000013, -233.1700000000001, -68.34999999999955, -42.22000000000026, -16.0899999999997, -191.98000000000093, -164.26000000000062, -130.36000000000016, -4.030000000000042, -4.030000000000042, -2.020000000000042, -70.35999999999916, -169.06000000000074, -10.060000000000041, -24.129999999999708, -147.46000000000043, -74.10999999999972, -8.050000000000042, -74.38000000000027, -24.1299999999998, -31.690000000000023, -8.050000000000042, -111.93999999999946, 2.0000000000000013, -76.72000000000003, 0.8899999999999604, -77.64999999999962, 2.0000000000000013, 6.829999999999961, -6.040000000000042, -8.050000000000042, -244.36000000000058, 2.0000000000000013, 54.31999999999997, -0.00999999999999836, -124.6299999999993, -134.68000000000086, -144.73000000000087, -68.34999999999916, 2.0000000000000013, -34.15000000000017, -40.210000000000356, -1.4200000000000208, -82.41999999999992, -60.310000000000336, 37.639999999999674, -4.030000000000042, -6.040000000000042, 5.8999999999999595, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -16.08999999999971, 29.60000000000025, -8.050000000000042, -227.14000000000075, -18.099999999999703, 39.61999999999968, -14.080000000000041, 2.0000000000000013, -15.13000000000002, -6.040000000000042, -104.52999999999925, 11.89999999999996, 14.869999999999987, -16.089999999999705, -26.13999999999971, -4.030000000000042, -55.39000000000032, 5.4499999999997115, 2.0000000000000013, -16.0899999999997], "policy_predator_policy_reward": [31.0, 43.0, 105.0, 154.0, 37.0, 52.0, 30.0, 176.0, 24.0, 24.0, 67.0, 60.0, 5.0, 12.0, 53.0, 81.0, 64.0, 58.0, 13.0, 10.0, 186.0, 109.0, 98.0, 155.0, 70.0, 128.0, 137.0, 102.0, 125.0, 123.0, 98.0, 154.0, 139.0, 82.0, 6.0, 21.0, 105.0, 177.0, 74.0, 124.0, 34.0, 38.0, 159.0, 129.0, 154.0, 141.0, 111.0, 70.0, 136.0, 160.0, 57.0, 33.0, 164.0, 155.0, 88.0, 102.0, 67.0, 72.0, 137.0, 135.0, 91.0, 65.0, 13.0, 32.0, 146.0, 145.0, 36.0, 0.0, 6.0, 2.0, 173.0, 182.0, 155.0, 82.0, 182.0, 97.0, 32.0, 36.0, 44.0, 22.0, 110.0, 124.0, 91.0, 60.0, 93.0, 66.0, 73.0, 94.0, 110.0, 120.0, 63.0, 74.0, 140.0, 147.0, 37.0, 3.0, 42.0, 61.0, 149.0, 137.0, 74.0, 73.0, 107.0, 77.0, 8.0, 4.0, 2.0, 0.0, 66.0, 67.0, 36.0, 26.0, 58.0, 78.0, 159.0, 165.0, 105.0, 89.0, 95.0, 87.0, 29.0, 26.0, 44.0, 39.0, 58.0, 55.0, 5.0, 25.0, 3.0, 117.0, 2.0, 55.0, 91.0, 90.0, 86.0, 106.0, 2.0, 4.0, 2.0, 36.0, 87.0, 79.0, 70.0, 87.0, 56.0, 53.0, 21.0, 43.0, 28.0, 35.0, 61.0, 55.0, 42.0, 48.0, 28.0, 43.0, 4.0, 4.0, 92.0, 124.0, 2.0, 5.0, 52.0, 56.0, 16.0, 74.0, 35.0, 3.0, 57.0, 30.0, 51.0, 26.0, 31.0, 27.0, 0.0, 4.0, 2.0, 3.0, 5.0, 4.0, 4.0, 9.0, 110.0, 89.0, 8.0, 10.0, 8.0, 0.0, 27.0, 39.0, 10.0, 53.0, 9.0, 0.0, 3.0, 14.0, 32.0, 17.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6715706682959298, "mean_inference_ms": 1.7971446059027598, "mean_action_processing_ms": 0.29592494903114047, "mean_env_wait_ms": 0.22735041979667603, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0060689449310302734, "StateBufferConnector_ms": 0.0035054683685302734, "ViewRequirementAgentConnector_ms": 0.14932703971862793}, "num_episodes": 18, "episode_return_max": 152.46000000000006, "episode_return_min": -406.9100000000001, "episode_return_mean": -38.99880000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.8797466189134, "num_env_steps_trained_throughput_per_sec": 368.8797466189134, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 11162.514, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11162.459, "sample_time_ms": 1315.655, "learn_time_ms": 9830.543, "learn_throughput": 406.895, "synch_weights_time_ms": 13.476}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "310e1_00000", "date": "2024-08-15_01-06-23", "timestamp": 1723664183, "time_this_iter_s": 10.895755767822266, "time_total_s": 539.1074368953705, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b194e940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 539.1074368953705, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 56.38, "ram_util_percent": 83.14666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.923357969774771, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6730650009301604, "policy_loss": -0.006835552233039702, "vf_loss": 1.6788768354547088, "vf_explained_var": 0.06027316154626312, "kl": 0.0068247788637452855, "entropy": 1.1404144036076056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2098705297740047, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1182830064385025, "policy_loss": -0.013582828642539286, "vf_loss": 2.130299382771134, "vf_explained_var": 0.17263004221613445, "kl": 0.0208860075784585, "entropy": 0.9866700936562169, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 177.65999999999957, "episode_reward_min": -406.9100000000001, "episode_reward_mean": -25.449400000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -385.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 179.09, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": -66.44470000000003, "predator_policy": 53.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-280.73, -29.689999999999955, 10.54000000000026, -406.9100000000001, 3.7999999999999865, -74.67999999999947, -98.00999999999955, -35.68999999999999, -76.05999999999989, 10.88000000000013, -36.910000000000615, -119.99999999999956, -47.03000000000055, -37.430000000000675, 16.690000000000015, -14.539999999999845, -0.06000000000004011, -172.69000000000025, -76.10000000000002, -163.34000000000123, -8.400000000000077, -48.59000000000067, -84.61999999999937, -88.32999999999866, 2.76999999999996, -41.67000000000045, -0.42000000000002613, 35.10000000000011, -83.06999999999977, -36.40000000000064, -9.88000000000004, -50.230000000000146, -100.2499999999986, -20.199999999999868, -8.120000000000083, 152.46000000000006, -35.89000000000062, -43.77000000000058, -16.779999999999625, -18.140000000000008, -74.51999999999943, -14.999999999999984, -8.560000000000073, 10.439999999999928, -0.8400000000000407, -23.32999999999945, -111.16999999999997, -53.57000000000038, -27.069999999999542, -102.61999999999934, -2.060000000000084, -34.38000000000064, -13.120000000000056, -14.589999999999982, 26.840000000000227, -34.509999999999636, 23.260000000000012, 6.05999999999994, 14.169999999999934, -4.65000000000007, 8.789999999999921, -36.41000000000027, 63.31999999999994, -16.63999999999962, -189.4100000000017, -28.34999999999947, 12.64000000000004, -6.840000000000064, 35.32999999999936, -6.070000000000084, 6.869999999999935, 0.9399999999999819, 26.510000000000506, -36.190000000000275, 39.51999999999937, -4.080000000000084, 44.82999999999986, -29.629999999999722, 7.77999999999992, -13.169999999999924, -0.9400000000005269, -5.090000000000083, -0.2200000000000375, 177.65999999999957, -5.090000000000083, 17.670000000000222, 1.4299999999999904, -5.090000000000083, -10.70000000000007, -3.0700000000000838, 55.410000000000274, 18.670000000000407, -98.11999999999956, -1.0500000000000622, 0.9299999999999818, -6.100000000000083, 13.349999999999984, -8.259999999999588, -9.130000000000082, 14.669999999999968], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-320.83000000000004, -241.90000000000003, -12.070000000000041, -215.62, -26.13999999999971, -35.319999999999894, -372.94000000000005, -321.97, -275.38000000000056, -15.82, -151.15000000000046, -104.52999999999925, -369.8800000000001, -24.129999999999708, 2.0000000000000013, -127.68999999999988, -10.060000000000041, -385.0, -157.0, -22.119999999999706, -34.18000000000036, -141.73000000000116, -194.68000000000023, -197.3200000000006, -184.93000000000097, -18.099999999999703, -20.109999999999715, -62.320000000000334, -257.74000000000024, -16.569999999999784, -70.35999999999936, 19.82000000000027, 2.0000000000000013, -10.060000000000041, -284.98, -242.7100000000002, -295.0, -18.099999999999998, -116.58999999999929, -325.75, -78.39999999999918, 2.0000000000000013, -28.14999999999971, -86.4399999999992, -28.14999999999971, -290.4700000000005, -175.0000000000009, -64.32999999999917, -161.20000000000073, 4.969999999999958, -106.14999999999961, -102.51999999999924, -23.16999999999998, -207.25000000000068, 25.760000000000005, -127.66000000000074, -358.0, -12.070000000000041, -4.030000000000042, -72.36999999999917, -114.87999999999954, 2.0000000000000013, -226.60000000000014, -109.6299999999993, -150.76000000000113, -96.48999999999923, -206.20000000000022, 2.0000000000000013, -14.080000000000041, -6.040000000000042, 2.0000000000000013, 148.45999999999998, -38.23000000000035, -130.6600000000012, -42.220000000000354, -63.54999999999971, -154.7800000000011, 2.0000000000000013, -145.57000000000008, -196.5700000000004, -43.27000000000034, -225.25000000000068, -8.050000000000042, -188.95000000000095, -3.2500000000000018, -60.31000000000027, 10.909999999999961, -83.46999999999922, 8.89999999999996, -122.73999999999936, -8.050000000000042, -45.28000000000034, 2.0000000000000013, -233.1700000000001, -68.34999999999955, -42.22000000000026, -16.0899999999997, -191.98000000000093, -164.26000000000062, -130.36000000000016, -4.030000000000042, -4.030000000000042, -2.020000000000042, -70.35999999999916, -169.06000000000074, -10.060000000000041, -24.129999999999708, -147.46000000000043, -74.10999999999972, -8.050000000000042, -74.38000000000027, -24.1299999999998, -31.690000000000023, -8.050000000000042, -111.93999999999946, 2.0000000000000013, -76.72000000000003, 0.8899999999999604, -77.64999999999962, 2.0000000000000013, 6.829999999999961, -6.040000000000042, -8.050000000000042, -244.36000000000058, 2.0000000000000013, 54.31999999999997, -0.00999999999999836, -124.6299999999993, -134.68000000000086, -144.73000000000087, -68.34999999999916, 2.0000000000000013, -34.15000000000017, -40.210000000000356, -1.4200000000000208, -82.41999999999992, -60.310000000000336, 37.639999999999674, -4.030000000000042, -6.040000000000042, 5.8999999999999595, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -16.08999999999971, 29.60000000000025, -8.050000000000042, -227.14000000000075, -18.099999999999703, 39.61999999999968, -14.080000000000041, 2.0000000000000013, -15.13000000000002, -6.040000000000042, -104.52999999999925, 11.89999999999996, 14.869999999999987, -16.089999999999705, -26.13999999999971, -4.030000000000042, -55.39000000000032, 5.4499999999997115, 2.0000000000000013, -16.0899999999997, -39.220000000000354, 2.0000000000000013, -48.43000000000015, 179.09, 2.0000000000000013, -16.089999999999705, 8.929999999999959, -8.260000000000023, -47.50000000000028, -12.070000000000041, -16.0899999999997, 2.0000000000000013, -15.129999999999864, -85.56999999999951, -2.020000000000042, -8.050000000000042, 19.820000000000203, 27.589999999999968, 7.669999999999964, 2.0000000000000013, -223.12000000000023, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -16.599999999999998, -8.050000000000042, -36.19000000000035, 8.930000000000001, -6.040000000000042, -16.0899999999997, -16.32999999999996, 2.0000000000000013], "policy_predator_policy_reward": [105.0, 177.0, 74.0, 124.0, 34.0, 38.0, 159.0, 129.0, 154.0, 141.0, 111.0, 70.0, 136.0, 160.0, 57.0, 33.0, 164.0, 155.0, 88.0, 102.0, 67.0, 72.0, 137.0, 135.0, 91.0, 65.0, 13.0, 32.0, 146.0, 145.0, 36.0, 0.0, 6.0, 2.0, 173.0, 182.0, 155.0, 82.0, 182.0, 97.0, 32.0, 36.0, 44.0, 22.0, 110.0, 124.0, 91.0, 60.0, 93.0, 66.0, 73.0, 94.0, 110.0, 120.0, 63.0, 74.0, 140.0, 147.0, 37.0, 3.0, 42.0, 61.0, 149.0, 137.0, 74.0, 73.0, 107.0, 77.0, 8.0, 4.0, 2.0, 0.0, 66.0, 67.0, 36.0, 26.0, 58.0, 78.0, 159.0, 165.0, 105.0, 89.0, 95.0, 87.0, 29.0, 26.0, 44.0, 39.0, 58.0, 55.0, 5.0, 25.0, 3.0, 117.0, 2.0, 55.0, 91.0, 90.0, 86.0, 106.0, 2.0, 4.0, 2.0, 36.0, 87.0, 79.0, 70.0, 87.0, 56.0, 53.0, 21.0, 43.0, 28.0, 35.0, 61.0, 55.0, 42.0, 48.0, 28.0, 43.0, 4.0, 4.0, 92.0, 124.0, 2.0, 5.0, 52.0, 56.0, 16.0, 74.0, 35.0, 3.0, 57.0, 30.0, 51.0, 26.0, 31.0, 27.0, 0.0, 4.0, 2.0, 3.0, 5.0, 4.0, 4.0, 9.0, 110.0, 89.0, 8.0, 10.0, 8.0, 0.0, 27.0, 39.0, 10.0, 53.0, 9.0, 0.0, 3.0, 14.0, 32.0, 17.0, 9.0, 0.0, 21.0, 16.0, 19.0, 28.0, 9.0, 0.0, 12.0, 5.0, 25.0, 36.0, 0.0, 9.0, 50.0, 40.0, 2.0, 5.0, 3.0, 5.0, 6.0, 3.0, 90.0, 33.0, 0.0, 5.0, 4.0, 7.0, 0.0, 10.0, 26.0, 12.0, 19.0, 0.0, 4.0, 9.0, 16.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6713416733605229, "mean_inference_ms": 1.795309597956045, "mean_action_processing_ms": 0.2952132706906624, "mean_env_wait_ms": 0.22721060459670436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006596803665161133, "StateBufferConnector_ms": 0.0036253929138183594, "ViewRequirementAgentConnector_ms": 0.1093519926071167}, "num_episodes": 18, "episode_return_max": 177.65999999999957, "episode_return_min": -406.9100000000001, "episode_return_mean": -25.449400000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.22445051201544, "num_env_steps_trained_throughput_per_sec": 347.22445051201544, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 11208.528, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11208.474, "sample_time_ms": 1343.302, "learn_time_ms": 9848.661, "learn_throughput": 406.147, "synch_weights_time_ms": 13.537}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "310e1_00000", "date": "2024-08-15_01-06-35", "timestamp": 1723664195, "time_this_iter_s": 11.59311580657959, "time_total_s": 550.7005527019501, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 550.7005527019501, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 61.4125, "ram_util_percent": 83.38749999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8414406556143332, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3952668362824374, "policy_loss": -0.005904222455210786, "vf_loss": 2.400245488888372, "vf_explained_var": 0.1754433204888036, "kl": 0.006170534248091038, "entropy": 1.1584591522418632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.316002895781603, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8795367445264546, "policy_loss": -0.00864652687383116, "vf_loss": 2.886774728600941, "vf_explained_var": 0.08060440487331814, "kl": 0.012520450361680247, "entropy": 1.0060446603903694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 187.95999999999964, "episode_reward_min": -289.35000000000036, "episode_reward_mean": -11.250199999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -358.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.0, "predator_policy": 165.0}, "policy_reward_mean": {"prey_policy": -43.620100000000036, "predator_policy": 37.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-84.61999999999937, -88.32999999999866, 2.76999999999996, -41.67000000000045, -0.42000000000002613, 35.10000000000011, -83.06999999999977, -36.40000000000064, -9.88000000000004, -50.230000000000146, -100.2499999999986, -20.199999999999868, -8.120000000000083, 152.46000000000006, -35.89000000000062, -43.77000000000058, -16.779999999999625, -18.140000000000008, -74.51999999999943, -14.999999999999984, -8.560000000000073, 10.439999999999928, -0.8400000000000407, -23.32999999999945, -111.16999999999997, -53.57000000000038, -27.069999999999542, -102.61999999999934, -2.060000000000084, -34.38000000000064, -13.120000000000056, -14.589999999999982, 26.840000000000227, -34.509999999999636, 23.260000000000012, 6.05999999999994, 14.169999999999934, -4.65000000000007, 8.789999999999921, -36.41000000000027, 63.31999999999994, -16.63999999999962, -189.4100000000017, -28.34999999999947, 12.64000000000004, -6.840000000000064, 35.32999999999936, -6.070000000000084, 6.869999999999935, 0.9399999999999819, 26.510000000000506, -36.190000000000275, 39.51999999999937, -4.080000000000084, 44.82999999999986, -29.629999999999722, 7.77999999999992, -13.169999999999924, -0.9400000000005269, -5.090000000000083, -0.2200000000000375, 177.65999999999957, -5.090000000000083, 17.670000000000222, 1.4299999999999904, -5.090000000000083, -10.70000000000007, -3.0700000000000838, 55.410000000000274, 18.670000000000407, -98.11999999999956, -1.0500000000000622, 0.9299999999999818, -6.100000000000083, 13.349999999999984, -8.259999999999588, -9.130000000000082, 14.669999999999968, -5.090000000000083, 14.68999999999993, -2.5900000000000727, 1.7000000000000013, 0.9499999999999819, -289.35000000000036, -3.1000000000000822, 27.12000000000043, 187.95999999999964, 66.19, -252.23000000000036, 38.469999999999416, -15.189999999999554, 1.920000000000003, -98.07999999999939, -3.3400000000000674, -16.199999999999424, 70.19000000000038, -30.1899999999998, -3.3700000000000454, 34.12000000000026, 10.38999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.14999999999971, -290.4700000000005, -175.0000000000009, -64.32999999999917, -161.20000000000073, 4.969999999999958, -106.14999999999961, -102.51999999999924, -23.16999999999998, -207.25000000000068, 25.760000000000005, -127.66000000000074, -358.0, -12.070000000000041, -4.030000000000042, -72.36999999999917, -114.87999999999954, 2.0000000000000013, -226.60000000000014, -109.6299999999993, -150.76000000000113, -96.48999999999923, -206.20000000000022, 2.0000000000000013, -14.080000000000041, -6.040000000000042, 2.0000000000000013, 148.45999999999998, -38.23000000000035, -130.6600000000012, -42.220000000000354, -63.54999999999971, -154.7800000000011, 2.0000000000000013, -145.57000000000008, -196.5700000000004, -43.27000000000034, -225.25000000000068, -8.050000000000042, -188.95000000000095, -3.2500000000000018, -60.31000000000027, 10.909999999999961, -83.46999999999922, 8.89999999999996, -122.73999999999936, -8.050000000000042, -45.28000000000034, 2.0000000000000013, -233.1700000000001, -68.34999999999955, -42.22000000000026, -16.0899999999997, -191.98000000000093, -164.26000000000062, -130.36000000000016, -4.030000000000042, -4.030000000000042, -2.020000000000042, -70.35999999999916, -169.06000000000074, -10.060000000000041, -24.129999999999708, -147.46000000000043, -74.10999999999972, -8.050000000000042, -74.38000000000027, -24.1299999999998, -31.690000000000023, -8.050000000000042, -111.93999999999946, 2.0000000000000013, -76.72000000000003, 0.8899999999999604, -77.64999999999962, 2.0000000000000013, 6.829999999999961, -6.040000000000042, -8.050000000000042, -244.36000000000058, 2.0000000000000013, 54.31999999999997, -0.00999999999999836, -124.6299999999993, -134.68000000000086, -144.73000000000087, -68.34999999999916, 2.0000000000000013, -34.15000000000017, -40.210000000000356, -1.4200000000000208, -82.41999999999992, -60.310000000000336, 37.639999999999674, -4.030000000000042, -6.040000000000042, 5.8999999999999595, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -16.08999999999971, 29.60000000000025, -8.050000000000042, -227.14000000000075, -18.099999999999703, 39.61999999999968, -14.080000000000041, 2.0000000000000013, -15.13000000000002, -6.040000000000042, -104.52999999999925, 11.89999999999996, 14.869999999999987, -16.089999999999705, -26.13999999999971, -4.030000000000042, -55.39000000000032, 5.4499999999997115, 2.0000000000000013, -16.0899999999997, -39.220000000000354, 2.0000000000000013, -48.43000000000015, 179.09, 2.0000000000000013, -16.089999999999705, 8.929999999999959, -8.260000000000023, -47.50000000000028, -12.070000000000041, -16.0899999999997, 2.0000000000000013, -15.129999999999864, -85.56999999999951, -2.020000000000042, -8.050000000000042, 19.820000000000203, 27.589999999999968, 7.669999999999964, 2.0000000000000013, -223.12000000000023, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -16.599999999999998, -8.050000000000042, -36.19000000000035, 8.930000000000001, -6.040000000000042, -16.0899999999997, -16.32999999999996, 2.0000000000000013, 2.0000000000000013, -16.089999999999705, 8.71999999999998, -4.030000000000042, -80.46999999999922, -10.12000000000004, -16.20999999999972, 1.9100000000000015, 2.0000000000000013, -8.050000000000042, -225.16, -237.19000000000005, -2.0200000000000387, -14.080000000000041, -3.220000000000038, -1.660000000000014, 182.0, -6.040000000000042, -16.0899999999997, 73.28000000000004, -221.29000000000025, -156.94000000000023, 27.4700000000002, 2.0000000000000013, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -210.0700000000004, -26.13999999999971, -5.200000000000037, -32.170000000000364, -4.030000000000042, 38.41999999999997, 24.770000000000277, -19.239999999999796, -185.94999999999987, -18.099999999999703, -7.270000000000028, -130.66000000000014, 86.78000000000011, 7.579999999999984, -36.19000000000036], "policy_predator_policy_reward": [110.0, 124.0, 91.0, 60.0, 93.0, 66.0, 73.0, 94.0, 110.0, 120.0, 63.0, 74.0, 140.0, 147.0, 37.0, 3.0, 42.0, 61.0, 149.0, 137.0, 74.0, 73.0, 107.0, 77.0, 8.0, 4.0, 2.0, 0.0, 66.0, 67.0, 36.0, 26.0, 58.0, 78.0, 159.0, 165.0, 105.0, 89.0, 95.0, 87.0, 29.0, 26.0, 44.0, 39.0, 58.0, 55.0, 5.0, 25.0, 3.0, 117.0, 2.0, 55.0, 91.0, 90.0, 86.0, 106.0, 2.0, 4.0, 2.0, 36.0, 87.0, 79.0, 70.0, 87.0, 56.0, 53.0, 21.0, 43.0, 28.0, 35.0, 61.0, 55.0, 42.0, 48.0, 28.0, 43.0, 4.0, 4.0, 92.0, 124.0, 2.0, 5.0, 52.0, 56.0, 16.0, 74.0, 35.0, 3.0, 57.0, 30.0, 51.0, 26.0, 31.0, 27.0, 0.0, 4.0, 2.0, 3.0, 5.0, 4.0, 4.0, 9.0, 110.0, 89.0, 8.0, 10.0, 8.0, 0.0, 27.0, 39.0, 10.0, 53.0, 9.0, 0.0, 3.0, 14.0, 32.0, 17.0, 9.0, 0.0, 21.0, 16.0, 19.0, 28.0, 9.0, 0.0, 12.0, 5.0, 25.0, 36.0, 0.0, 9.0, 50.0, 40.0, 2.0, 5.0, 3.0, 5.0, 6.0, 3.0, 90.0, 33.0, 0.0, 5.0, 4.0, 7.0, 0.0, 10.0, 26.0, 12.0, 19.0, 0.0, 4.0, 9.0, 16.0, 13.0, 9.0, 0.0, 10.0, 0.0, 43.0, 45.0, 15.0, 1.0, 5.0, 2.0, 164.0, 9.0, 8.0, 5.0, 20.0, 12.0, 4.0, 8.0, 9.0, 0.0, 99.0, 27.0, 4.0, 5.0, 9.0, 10.0, 6.0, 8.0, 18.0, 94.0, 9.0, 19.0, 17.0, 3.0, 0.0, 7.0, 83.0, 92.0, 10.0, 12.0, 13.0, 65.0, 20.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6711883323674783, "mean_inference_ms": 1.7937501385588583, "mean_action_processing_ms": 0.2939290357820561, "mean_env_wait_ms": 0.22727134524880227, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0072710514068603516, "StateBufferConnector_ms": 0.0035897493362426758, "ViewRequirementAgentConnector_ms": 0.10719799995422363}, "num_episodes": 22, "episode_return_max": 187.95999999999964, "episode_return_min": -289.35000000000036, "episode_return_mean": -11.250199999999985, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.0102625588119, "num_env_steps_trained_throughput_per_sec": 365.0102625588119, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 11223.841, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11223.786, "sample_time_ms": 1355.757, "learn_time_ms": 9851.606, "learn_throughput": 406.025, "synch_weights_time_ms": 13.391}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "310e1_00000", "date": "2024-08-15_01-06-46", "timestamp": 1723664206, "time_this_iter_s": 11.007079124450684, "time_total_s": 561.7076318264008, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 561.7076318264008, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 58.724999999999994, "ram_util_percent": 82.73125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.753206089817027, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6418227526876663, "policy_loss": -0.00563068125919296, "vf_loss": 2.6468098028627023, "vf_explained_var": 0.22197505522657324, "kl": 0.004290833902550354, "entropy": 1.094213752897959, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.26476362025927, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.032530063800711, "policy_loss": -0.005694606007820872, "vf_loss": 4.0371968009484505, "vf_explained_var": 0.2139409956793306, "kl": 0.009136502016337898, "entropy": 0.9229223569234212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 194.92999999999967, "episode_reward_min": -289.35000000000036, "episode_reward_mean": 0.8715999999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -247.54000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -26.369199999999996, "predator_policy": 26.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.32999999999945, -111.16999999999997, -53.57000000000038, -27.069999999999542, -102.61999999999934, -2.060000000000084, -34.38000000000064, -13.120000000000056, -14.589999999999982, 26.840000000000227, -34.509999999999636, 23.260000000000012, 6.05999999999994, 14.169999999999934, -4.65000000000007, 8.789999999999921, -36.41000000000027, 63.31999999999994, -16.63999999999962, -189.4100000000017, -28.34999999999947, 12.64000000000004, -6.840000000000064, 35.32999999999936, -6.070000000000084, 6.869999999999935, 0.9399999999999819, 26.510000000000506, -36.190000000000275, 39.51999999999937, -4.080000000000084, 44.82999999999986, -29.629999999999722, 7.77999999999992, -13.169999999999924, -0.9400000000005269, -5.090000000000083, -0.2200000000000375, 177.65999999999957, -5.090000000000083, 17.670000000000222, 1.4299999999999904, -5.090000000000083, -10.70000000000007, -3.0700000000000838, 55.410000000000274, 18.670000000000407, -98.11999999999956, -1.0500000000000622, 0.9299999999999818, -6.100000000000083, 13.349999999999984, -8.259999999999588, -9.130000000000082, 14.669999999999968, -5.090000000000083, 14.68999999999993, -2.5900000000000727, 1.7000000000000013, 0.9499999999999819, -289.35000000000036, -3.1000000000000822, 27.12000000000043, 187.95999999999964, 66.19, -252.23000000000036, 38.469999999999416, -15.189999999999554, 1.920000000000003, -98.07999999999939, -3.3400000000000674, -16.199999999999424, 70.19000000000038, -30.1899999999998, -3.3700000000000454, 34.12000000000026, 10.38999999999995, 182.9499999999998, -6.410000000000075, 111.0700000000002, 111.60000000000096, -57.02000000000039, 149.17000000000013, 0.949999999999981, -62.70999999999981, -6.100000000000083, -52.41000000000018, 5.519999999999927, 27.54999999999995, -0.20000000000004015, 29.420000000000474, -14.379999999999777, 158.94, 194.92999999999967, -5.590000000000062, 193.76999999999964, -31.620000000000033, -13.51999999999973, 4.819999999999941, -244.47000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.050000000000042, -45.28000000000034, 2.0000000000000013, -233.1700000000001, -68.34999999999955, -42.22000000000026, -16.0899999999997, -191.98000000000093, -164.26000000000062, -130.36000000000016, -4.030000000000042, -4.030000000000042, -2.020000000000042, -70.35999999999916, -169.06000000000074, -10.060000000000041, -24.129999999999708, -147.46000000000043, -74.10999999999972, -8.050000000000042, -74.38000000000027, -24.1299999999998, -31.690000000000023, -8.050000000000042, -111.93999999999946, 2.0000000000000013, -76.72000000000003, 0.8899999999999604, -77.64999999999962, 2.0000000000000013, 6.829999999999961, -6.040000000000042, -8.050000000000042, -244.36000000000058, 2.0000000000000013, 54.31999999999997, -0.00999999999999836, -124.6299999999993, -134.68000000000086, -144.73000000000087, -68.34999999999916, 2.0000000000000013, -34.15000000000017, -40.210000000000356, -1.4200000000000208, -82.41999999999992, -60.310000000000336, 37.639999999999674, -4.030000000000042, -6.040000000000042, 5.8999999999999595, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -16.08999999999971, 29.60000000000025, -8.050000000000042, -227.14000000000075, -18.099999999999703, 39.61999999999968, -14.080000000000041, 2.0000000000000013, -15.13000000000002, -6.040000000000042, -104.52999999999925, 11.89999999999996, 14.869999999999987, -16.089999999999705, -26.13999999999971, -4.030000000000042, -55.39000000000032, 5.4499999999997115, 2.0000000000000013, -16.0899999999997, -39.220000000000354, 2.0000000000000013, -48.43000000000015, 179.09, 2.0000000000000013, -16.089999999999705, 8.929999999999959, -8.260000000000023, -47.50000000000028, -12.070000000000041, -16.0899999999997, 2.0000000000000013, -15.129999999999864, -85.56999999999951, -2.020000000000042, -8.050000000000042, 19.820000000000203, 27.589999999999968, 7.669999999999964, 2.0000000000000013, -223.12000000000023, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -16.599999999999998, -8.050000000000042, -36.19000000000035, 8.930000000000001, -6.040000000000042, -16.0899999999997, -16.32999999999996, 2.0000000000000013, 2.0000000000000013, -16.089999999999705, 8.71999999999998, -4.030000000000042, -80.46999999999922, -10.12000000000004, -16.20999999999972, 1.9100000000000015, 2.0000000000000013, -8.050000000000042, -225.16, -237.19000000000005, -2.0200000000000387, -14.080000000000041, -3.220000000000038, -1.660000000000014, 182.0, -6.040000000000042, -16.0899999999997, 73.28000000000004, -221.29000000000025, -156.94000000000023, 27.4700000000002, 2.0000000000000013, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -210.0700000000004, -26.13999999999971, -5.200000000000037, -32.170000000000364, -4.030000000000042, 38.41999999999997, 24.770000000000277, -19.239999999999796, -185.94999999999987, -18.099999999999703, -7.270000000000028, -130.66000000000014, 86.78000000000011, 7.579999999999984, -36.19000000000036, -5.050000000000042, 176.0, -20.109999999999705, -52.30000000000023, 128.57, -83.4999999999995, -20.109999999999705, 105.71000000000036, -18.099999999999703, -122.91999999999959, 29.60000000000025, 101.57000000000009, -6.040000000000042, -0.00999999999999836, -2.739999999999945, -192.9700000000003, -2.020000000000042, -14.080000000000041, -39.8200000000002, -203.59000000000037, -30.45999999999976, -2.020000000000042, 0.5600000000002439, -0.00999999999999836, 9.919999999999959, -22.119999999999706, -33.58000000000027, 2.0000000000000013, -6.040000000000042, -54.34000000000033, 137.0, -10.060000000000041, 173.0, 8.929999999999959, -38.20000000000036, -1.3900000000000199, 197.0, -44.23000000000035, -71.5299999999993, -16.0899999999999, -37.390000000000136, -24.129999999999708, -18.099999999999703, 9.919999999999959, -247.54000000000008, -145.92999999999998], "policy_predator_policy_reward": [5.0, 25.0, 3.0, 117.0, 2.0, 55.0, 91.0, 90.0, 86.0, 106.0, 2.0, 4.0, 2.0, 36.0, 87.0, 79.0, 70.0, 87.0, 56.0, 53.0, 21.0, 43.0, 28.0, 35.0, 61.0, 55.0, 42.0, 48.0, 28.0, 43.0, 4.0, 4.0, 92.0, 124.0, 2.0, 5.0, 52.0, 56.0, 16.0, 74.0, 35.0, 3.0, 57.0, 30.0, 51.0, 26.0, 31.0, 27.0, 0.0, 4.0, 2.0, 3.0, 5.0, 4.0, 4.0, 9.0, 110.0, 89.0, 8.0, 10.0, 8.0, 0.0, 27.0, 39.0, 10.0, 53.0, 9.0, 0.0, 3.0, 14.0, 32.0, 17.0, 9.0, 0.0, 21.0, 16.0, 19.0, 28.0, 9.0, 0.0, 12.0, 5.0, 25.0, 36.0, 0.0, 9.0, 50.0, 40.0, 2.0, 5.0, 3.0, 5.0, 6.0, 3.0, 90.0, 33.0, 0.0, 5.0, 4.0, 7.0, 0.0, 10.0, 26.0, 12.0, 19.0, 0.0, 4.0, 9.0, 16.0, 13.0, 9.0, 0.0, 10.0, 0.0, 43.0, 45.0, 15.0, 1.0, 5.0, 2.0, 164.0, 9.0, 8.0, 5.0, 20.0, 12.0, 4.0, 8.0, 9.0, 0.0, 99.0, 27.0, 4.0, 5.0, 9.0, 10.0, 6.0, 8.0, 18.0, 94.0, 9.0, 19.0, 17.0, 3.0, 0.0, 7.0, 83.0, 92.0, 10.0, 12.0, 13.0, 65.0, 20.0, 19.0, 4.0, 8.0, 34.0, 32.0, 18.0, 48.0, 10.0, 16.0, 44.0, 40.0, 4.0, 14.0, 4.0, 3.0, 37.0, 96.0, 2.0, 8.0, 139.0, 52.0, 17.0, 21.0, 14.0, 13.0, 12.0, 0.0, 31.0, 30.0, 16.0, 30.0, 13.0, 19.0, 9.0, 4.0, 22.0, 12.0, 18.0, 23.0, 9.0, 47.0, 27.0, 21.0, 10.0, 3.0, 28.0, 121.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6718412881387191, "mean_inference_ms": 1.791193216937382, "mean_action_processing_ms": 0.2943152439164914, "mean_env_wait_ms": 0.2270380347944838, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0076525211334228516, "StateBufferConnector_ms": 0.0036063194274902344, "ViewRequirementAgentConnector_ms": 0.10793161392211914}, "num_episodes": 23, "episode_return_max": 194.92999999999967, "episode_return_min": -289.35000000000036, "episode_return_mean": 0.8715999999999974, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.956571553745, "num_env_steps_trained_throughput_per_sec": 364.956571553745, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 11221.295, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11221.24, "sample_time_ms": 1358.834, "learn_time_ms": 9844.276, "learn_throughput": 406.328, "synch_weights_time_ms": 15.171}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "310e1_00000", "date": "2024-08-15_01-06-57", "timestamp": 1723664217, "time_this_iter_s": 11.041472911834717, "time_total_s": 572.7491047382355, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 572.7491047382355, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 55.96875, "ram_util_percent": 82.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.75202500659322, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.353596156646335, "policy_loss": -0.008076655719227221, "vf_loss": 1.361087585410113, "vf_explained_var": 0.18593475493804487, "kl": 0.007803036793663244, "entropy": 1.1364962813084718, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9595282218759023, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.685485359159096, "policy_loss": -0.005863556992225644, "vf_loss": 2.6902288264698453, "vf_explained_var": 0.26557497205557645, "kl": 0.00995637042057811, "entropy": 1.07091584070019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 195.85999999999967, "episode_reward_min": -385.0500000000002, "episode_reward_mean": 7.071200000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -284.5000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -17.739399999999982, "predator_policy": 21.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.63999999999962, -189.4100000000017, -28.34999999999947, 12.64000000000004, -6.840000000000064, 35.32999999999936, -6.070000000000084, 6.869999999999935, 0.9399999999999819, 26.510000000000506, -36.190000000000275, 39.51999999999937, -4.080000000000084, 44.82999999999986, -29.629999999999722, 7.77999999999992, -13.169999999999924, -0.9400000000005269, -5.090000000000083, -0.2200000000000375, 177.65999999999957, -5.090000000000083, 17.670000000000222, 1.4299999999999904, -5.090000000000083, -10.70000000000007, -3.0700000000000838, 55.410000000000274, 18.670000000000407, -98.11999999999956, -1.0500000000000622, 0.9299999999999818, -6.100000000000083, 13.349999999999984, -8.259999999999588, -9.130000000000082, 14.669999999999968, -5.090000000000083, 14.68999999999993, -2.5900000000000727, 1.7000000000000013, 0.9499999999999819, -289.35000000000036, -3.1000000000000822, 27.12000000000043, 187.95999999999964, 66.19, -252.23000000000036, 38.469999999999416, -15.189999999999554, 1.920000000000003, -98.07999999999939, -3.3400000000000674, -16.199999999999424, 70.19000000000038, -30.1899999999998, -3.3700000000000454, 34.12000000000026, 10.38999999999995, 182.9499999999998, -6.410000000000075, 111.0700000000002, 111.60000000000096, -57.02000000000039, 149.17000000000013, 0.949999999999981, -62.70999999999981, -6.100000000000083, -52.41000000000018, 5.519999999999927, 27.54999999999995, -0.20000000000004015, 29.420000000000474, -14.379999999999777, 158.94, 194.92999999999967, -5.590000000000062, 193.76999999999964, -31.620000000000033, -13.51999999999973, 4.819999999999941, -244.47000000000014, 3.899999999999961, 20.390000000000505, 93.63000000000008, 64.97000000000024, 0.969999999999981, -385.0500000000002, 62.95999999999982, -18.21999999999942, -48.5200000000006, -1.0700000000000622, 171.9199999999999, 195.85999999999967, 33.55999999999991, 0.9499999999999819, 161.89999999999995, -5.090000000000083, -66.84999999999839, 18.710000000000406], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.00999999999999836, -124.6299999999993, -134.68000000000086, -144.73000000000087, -68.34999999999916, 2.0000000000000013, -34.15000000000017, -40.210000000000356, -1.4200000000000208, -82.41999999999992, -60.310000000000336, 37.639999999999674, -4.030000000000042, -6.040000000000042, 5.8999999999999595, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -16.08999999999971, 29.60000000000025, -8.050000000000042, -227.14000000000075, -18.099999999999703, 39.61999999999968, -14.080000000000041, 2.0000000000000013, -15.13000000000002, -6.040000000000042, -104.52999999999925, 11.89999999999996, 14.869999999999987, -16.089999999999705, -26.13999999999971, -4.030000000000042, -55.39000000000032, 5.4499999999997115, 2.0000000000000013, -16.0899999999997, -39.220000000000354, 2.0000000000000013, -48.43000000000015, 179.09, 2.0000000000000013, -16.089999999999705, 8.929999999999959, -8.260000000000023, -47.50000000000028, -12.070000000000041, -16.0899999999997, 2.0000000000000013, -15.129999999999864, -85.56999999999951, -2.020000000000042, -8.050000000000042, 19.820000000000203, 27.589999999999968, 7.669999999999964, 2.0000000000000013, -223.12000000000023, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -16.599999999999998, -8.050000000000042, -36.19000000000035, 8.930000000000001, -6.040000000000042, -16.0899999999997, -16.32999999999996, 2.0000000000000013, 2.0000000000000013, -16.089999999999705, 8.71999999999998, -4.030000000000042, -80.46999999999922, -10.12000000000004, -16.20999999999972, 1.9100000000000015, 2.0000000000000013, -8.050000000000042, -225.16, -237.19000000000005, -2.0200000000000387, -14.080000000000041, -3.220000000000038, -1.660000000000014, 182.0, -6.040000000000042, -16.0899999999997, 73.28000000000004, -221.29000000000025, -156.94000000000023, 27.4700000000002, 2.0000000000000013, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -210.0700000000004, -26.13999999999971, -5.200000000000037, -32.170000000000364, -4.030000000000042, 38.41999999999997, 24.770000000000277, -19.239999999999796, -185.94999999999987, -18.099999999999703, -7.270000000000028, -130.66000000000014, 86.78000000000011, 7.579999999999984, -36.19000000000036, -5.050000000000042, 176.0, -20.109999999999705, -52.30000000000023, 128.57, -83.4999999999995, -20.109999999999705, 105.71000000000036, -18.099999999999703, -122.91999999999959, 29.60000000000025, 101.57000000000009, -6.040000000000042, -0.00999999999999836, -2.739999999999945, -192.9700000000003, -2.020000000000042, -14.080000000000041, -39.8200000000002, -203.59000000000037, -30.45999999999976, -2.020000000000042, 0.5600000000002439, -0.00999999999999836, 9.919999999999959, -22.119999999999706, -33.58000000000027, 2.0000000000000013, -6.040000000000042, -54.34000000000033, 137.0, -10.060000000000041, 173.0, 8.929999999999959, -38.20000000000036, -1.3900000000000199, 197.0, -44.23000000000035, -71.5299999999993, -16.0899999999999, -37.390000000000136, -24.129999999999708, -18.099999999999703, 9.919999999999959, -247.54000000000008, -145.92999999999998, -18.099999999999703, 2.0000000000000013, -16.0899999999997, -15.51999999999986, 96.77, -26.13999999999971, 30.680000000000263, 9.289999999999973, -2.020000000000042, -0.00999999999999836, -273.55000000000007, -284.5000000000001, -38.29000000000034, 76.25000000000013, -34.18000000000036, -6.040000000000042, -86.43999999999927, -14.080000000000041, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 158.0, 188.0, -2.1400000000000396, -6.040000000000042, 32.600000000000016, -8.050000000000042, 2.0000000000000013, 155.0, -18.099999999999703, -4.030000000000042, -10.060000000000041, -96.48999999999923, -55.360000000000326, 14.749999999999963, -6.040000000000042], "policy_predator_policy_reward": [52.0, 56.0, 16.0, 74.0, 35.0, 3.0, 57.0, 30.0, 51.0, 26.0, 31.0, 27.0, 0.0, 4.0, 2.0, 3.0, 5.0, 4.0, 4.0, 9.0, 110.0, 89.0, 8.0, 10.0, 8.0, 0.0, 27.0, 39.0, 10.0, 53.0, 9.0, 0.0, 3.0, 14.0, 32.0, 17.0, 9.0, 0.0, 21.0, 16.0, 19.0, 28.0, 9.0, 0.0, 12.0, 5.0, 25.0, 36.0, 0.0, 9.0, 50.0, 40.0, 2.0, 5.0, 3.0, 5.0, 6.0, 3.0, 90.0, 33.0, 0.0, 5.0, 4.0, 7.0, 0.0, 10.0, 26.0, 12.0, 19.0, 0.0, 4.0, 9.0, 16.0, 13.0, 9.0, 0.0, 10.0, 0.0, 43.0, 45.0, 15.0, 1.0, 5.0, 2.0, 164.0, 9.0, 8.0, 5.0, 20.0, 12.0, 4.0, 8.0, 9.0, 0.0, 99.0, 27.0, 4.0, 5.0, 9.0, 10.0, 6.0, 8.0, 18.0, 94.0, 9.0, 19.0, 17.0, 3.0, 0.0, 7.0, 83.0, 92.0, 10.0, 12.0, 13.0, 65.0, 20.0, 19.0, 4.0, 8.0, 34.0, 32.0, 18.0, 48.0, 10.0, 16.0, 44.0, 40.0, 4.0, 14.0, 4.0, 3.0, 37.0, 96.0, 2.0, 8.0, 139.0, 52.0, 17.0, 21.0, 14.0, 13.0, 12.0, 0.0, 31.0, 30.0, 16.0, 30.0, 13.0, 19.0, 9.0, 4.0, 22.0, 12.0, 18.0, 23.0, 9.0, 47.0, 27.0, 21.0, 10.0, 3.0, 28.0, 121.0, 10.0, 10.0, 25.0, 27.0, 0.0, 23.0, 17.0, 8.0, 1.0, 2.0, 135.0, 38.0, 12.0, 13.0, 4.0, 18.0, 8.0, 44.0, 2.0, 7.0, 20.0, 8.0, 4.0, 6.0, 3.0, 4.0, 5.0, 2.0, 10.0, 15.0, 3.0, 6.0, 39.0, 46.0, 7.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6709798137972872, "mean_inference_ms": 1.7912366945773528, "mean_action_processing_ms": 0.29316752483720876, "mean_env_wait_ms": 0.2270090110955592, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006461620330810547, "StateBufferConnector_ms": 0.0035556554794311523, "ViewRequirementAgentConnector_ms": 0.10668385028839111}, "num_episodes": 18, "episode_return_max": 195.85999999999967, "episode_return_min": -385.0500000000002, "episode_return_mean": 7.071200000000009, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.78534627086503, "num_env_steps_trained_throughput_per_sec": 370.78534627086503, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 11220.971, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11220.914, "sample_time_ms": 1379.554, "learn_time_ms": 9823.241, "learn_throughput": 407.198, "synch_weights_time_ms": 15.459}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "310e1_00000", "date": "2024-08-15_01-07-08", "timestamp": 1723664228, "time_this_iter_s": 10.870288133621216, "time_total_s": 583.6193928718567, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14df700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 583.6193928718567, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 52.76, "ram_util_percent": 82.51999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7351966150854, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.273729364518766, "policy_loss": -0.004491594554757867, "vf_loss": 2.2777581108940974, "vf_explained_var": 0.16797829251440743, "kl": 0.006171251841103611, "entropy": 1.1295241055665193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.380187285955621, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9253341821135668, "policy_loss": -0.004039476274034728, "vf_loss": 2.9283809219087873, "vf_explained_var": 0.28846198430767767, "kl": 0.008824401097584056, "entropy": 1.0443892468220342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 291.13, "episode_reward_min": -385.0500000000002, "episode_reward_mean": 15.93360000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -284.5000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -11.753199999999966, "predator_policy": 19.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.090000000000083, -0.2200000000000375, 177.65999999999957, -5.090000000000083, 17.670000000000222, 1.4299999999999904, -5.090000000000083, -10.70000000000007, -3.0700000000000838, 55.410000000000274, 18.670000000000407, -98.11999999999956, -1.0500000000000622, 0.9299999999999818, -6.100000000000083, 13.349999999999984, -8.259999999999588, -9.130000000000082, 14.669999999999968, -5.090000000000083, 14.68999999999993, -2.5900000000000727, 1.7000000000000013, 0.9499999999999819, -289.35000000000036, -3.1000000000000822, 27.12000000000043, 187.95999999999964, 66.19, -252.23000000000036, 38.469999999999416, -15.189999999999554, 1.920000000000003, -98.07999999999939, -3.3400000000000674, -16.199999999999424, 70.19000000000038, -30.1899999999998, -3.3700000000000454, 34.12000000000026, 10.38999999999995, 182.9499999999998, -6.410000000000075, 111.0700000000002, 111.60000000000096, -57.02000000000039, 149.17000000000013, 0.949999999999981, -62.70999999999981, -6.100000000000083, -52.41000000000018, 5.519999999999927, 27.54999999999995, -0.20000000000004015, 29.420000000000474, -14.379999999999777, 158.94, 194.92999999999967, -5.590000000000062, 193.76999999999964, -31.620000000000033, -13.51999999999973, 4.819999999999941, -244.47000000000014, 3.899999999999961, 20.390000000000505, 93.63000000000008, 64.97000000000024, 0.969999999999981, -385.0500000000002, 62.95999999999982, -18.21999999999942, -48.5200000000006, -1.0700000000000622, 171.9199999999999, 195.85999999999967, 33.55999999999991, 0.9499999999999819, 161.89999999999995, -5.090000000000083, -66.84999999999839, 18.710000000000406, -37.44999999999997, 138.64000000000013, 291.13, 14.589999999999925, 198.64000000000019, 127.8800000000003, 8.69000000000019, 26.410000000000444, 19.61000000000054, -0.34000000000004116, 21.640000000000516, 0.9199999999999818, -87.23999999999987, 22.750000000000238, 20.280000000000488, -0.3600000000000376, -23.27000000000006, -13.17999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -16.0899999999997, -39.220000000000354, 2.0000000000000013, -48.43000000000015, 179.09, 2.0000000000000013, -16.089999999999705, 8.929999999999959, -8.260000000000023, -47.50000000000028, -12.070000000000041, -16.0899999999997, 2.0000000000000013, -15.129999999999864, -85.56999999999951, -2.020000000000042, -8.050000000000042, 19.820000000000203, 27.589999999999968, 7.669999999999964, 2.0000000000000013, -223.12000000000023, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -16.599999999999998, -8.050000000000042, -36.19000000000035, 8.930000000000001, -6.040000000000042, -16.0899999999997, -16.32999999999996, 2.0000000000000013, 2.0000000000000013, -16.089999999999705, 8.71999999999998, -4.030000000000042, -80.46999999999922, -10.12000000000004, -16.20999999999972, 1.9100000000000015, 2.0000000000000013, -8.050000000000042, -225.16, -237.19000000000005, -2.0200000000000387, -14.080000000000041, -3.220000000000038, -1.660000000000014, 182.0, -6.040000000000042, -16.0899999999997, 73.28000000000004, -221.29000000000025, -156.94000000000023, 27.4700000000002, 2.0000000000000013, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -210.0700000000004, -26.13999999999971, -5.200000000000037, -32.170000000000364, -4.030000000000042, 38.41999999999997, 24.770000000000277, -19.239999999999796, -185.94999999999987, -18.099999999999703, -7.270000000000028, -130.66000000000014, 86.78000000000011, 7.579999999999984, -36.19000000000036, -5.050000000000042, 176.0, -20.109999999999705, -52.30000000000023, 128.57, -83.4999999999995, -20.109999999999705, 105.71000000000036, -18.099999999999703, -122.91999999999959, 29.60000000000025, 101.57000000000009, -6.040000000000042, -0.00999999999999836, -2.739999999999945, -192.9700000000003, -2.020000000000042, -14.080000000000041, -39.8200000000002, -203.59000000000037, -30.45999999999976, -2.020000000000042, 0.5600000000002439, -0.00999999999999836, 9.919999999999959, -22.119999999999706, -33.58000000000027, 2.0000000000000013, -6.040000000000042, -54.34000000000033, 137.0, -10.060000000000041, 173.0, 8.929999999999959, -38.20000000000036, -1.3900000000000199, 197.0, -44.23000000000035, -71.5299999999993, -16.0899999999999, -37.390000000000136, -24.129999999999708, -18.099999999999703, 9.919999999999959, -247.54000000000008, -145.92999999999998, -18.099999999999703, 2.0000000000000013, -16.0899999999997, -15.51999999999986, 96.77, -26.13999999999971, 30.680000000000263, 9.289999999999973, -2.020000000000042, -0.00999999999999836, -273.55000000000007, -284.5000000000001, -38.29000000000034, 76.25000000000013, -34.18000000000036, -6.040000000000042, -86.43999999999927, -14.080000000000041, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 158.0, 188.0, -2.1400000000000396, -6.040000000000042, 32.600000000000016, -8.050000000000042, 2.0000000000000013, 155.0, -18.099999999999703, -4.030000000000042, -10.060000000000041, -96.48999999999923, -55.360000000000326, 14.749999999999963, -6.040000000000042, 2.0000000000000013, -88.45000000000003, 64.22000000000003, 14.419999999999973, 49.13000000000007, 194.0, -34.18000000000036, 12.769999999999966, 19.639999999999965, 158.0, -68.34999999999921, 153.23, -9.279999999999912, -4.030000000000042, 12.43999999999997, -4.030000000000042, -19.299999999999738, 10.90999999999996, 0.7700000000000012, -20.109999999999705, 9.649999999999965, -0.00999999999999836, 2.0000000000000013, -14.080000000000041, -93.72999999999944, -100.50999999999985, 2.0000000000000013, 17.750000000000107, 29.570000000000242, -56.29000000000034, 2.0000000000000013, -37.360000000000326, -32.17000000000003, -18.099999999999703, -16.089999999999705, -16.089999999999705], "policy_predator_policy_reward": [9.0, 0.0, 21.0, 16.0, 19.0, 28.0, 9.0, 0.0, 12.0, 5.0, 25.0, 36.0, 0.0, 9.0, 50.0, 40.0, 2.0, 5.0, 3.0, 5.0, 6.0, 3.0, 90.0, 33.0, 0.0, 5.0, 4.0, 7.0, 0.0, 10.0, 26.0, 12.0, 19.0, 0.0, 4.0, 9.0, 16.0, 13.0, 9.0, 0.0, 10.0, 0.0, 43.0, 45.0, 15.0, 1.0, 5.0, 2.0, 164.0, 9.0, 8.0, 5.0, 20.0, 12.0, 4.0, 8.0, 9.0, 0.0, 99.0, 27.0, 4.0, 5.0, 9.0, 10.0, 6.0, 8.0, 18.0, 94.0, 9.0, 19.0, 17.0, 3.0, 0.0, 7.0, 83.0, 92.0, 10.0, 12.0, 13.0, 65.0, 20.0, 19.0, 4.0, 8.0, 34.0, 32.0, 18.0, 48.0, 10.0, 16.0, 44.0, 40.0, 4.0, 14.0, 4.0, 3.0, 37.0, 96.0, 2.0, 8.0, 139.0, 52.0, 17.0, 21.0, 14.0, 13.0, 12.0, 0.0, 31.0, 30.0, 16.0, 30.0, 13.0, 19.0, 9.0, 4.0, 22.0, 12.0, 18.0, 23.0, 9.0, 47.0, 27.0, 21.0, 10.0, 3.0, 28.0, 121.0, 10.0, 10.0, 25.0, 27.0, 0.0, 23.0, 17.0, 8.0, 1.0, 2.0, 135.0, 38.0, 12.0, 13.0, 4.0, 18.0, 8.0, 44.0, 2.0, 7.0, 20.0, 8.0, 4.0, 6.0, 3.0, 4.0, 5.0, 2.0, 10.0, 15.0, 3.0, 6.0, 39.0, 46.0, 7.0, 3.0, 4.0, 45.0, 26.0, 34.0, 42.0, 6.0, 18.0, 18.0, 14.0, 7.0, 5.0, 38.0, 15.0, 7.0, 3.0, 15.0, 17.0, 11.0, 8.0, 11.0, 6.0, 6.0, 5.0, 8.0, 88.0, 19.0, 3.0, 0.0, 18.0, 29.0, 21.0, 14.0, 5.0, 22.0, 11.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6715055884140568, "mean_inference_ms": 1.7924103262204392, "mean_action_processing_ms": 0.2930118780621026, "mean_env_wait_ms": 0.22706146813616124, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055005550384521484, "StateBufferConnector_ms": 0.003353595733642578, "ViewRequirementAgentConnector_ms": 0.11958050727844238}, "num_episodes": 18, "episode_return_max": 291.13, "episode_return_min": -385.0500000000002, "episode_return_mean": 15.93360000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.38014959446747, "num_env_steps_trained_throughput_per_sec": 356.38014959446747, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 11186.614, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11186.558, "sample_time_ms": 1419.795, "learn_time_ms": 9747.621, "learn_throughput": 410.357, "synch_weights_time_ms": 16.688}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "310e1_00000", "date": "2024-08-15_01-07-19", "timestamp": 1723664239, "time_this_iter_s": 11.300189971923828, "time_total_s": 594.9195828437805, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12d94c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 594.9195828437805, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 53.706250000000004, "ram_util_percent": 82.56875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.572953066592494, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0052745610948595, "policy_loss": -0.005495032570177009, "vf_loss": 2.0101412917255725, "vf_explained_var": 0.15814993898704569, "kl": 0.008377408478550497, "entropy": 1.0858101382142022, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.047856991221665, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.42831920372746, "policy_loss": -0.004577293340609503, "vf_loss": 3.4320661828631445, "vf_explained_var": 0.3223600642075614, "kl": 0.0073805380791991315, "entropy": 1.0835612446858138, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 291.13, "episode_reward_min": -385.0500000000002, "episode_reward_mean": 14.235600000000064, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.95000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -14.77719999999997, "predator_policy": 21.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.669999999999968, -5.090000000000083, 14.68999999999993, -2.5900000000000727, 1.7000000000000013, 0.9499999999999819, -289.35000000000036, -3.1000000000000822, 27.12000000000043, 187.95999999999964, 66.19, -252.23000000000036, 38.469999999999416, -15.189999999999554, 1.920000000000003, -98.07999999999939, -3.3400000000000674, -16.199999999999424, 70.19000000000038, -30.1899999999998, -3.3700000000000454, 34.12000000000026, 10.38999999999995, 182.9499999999998, -6.410000000000075, 111.0700000000002, 111.60000000000096, -57.02000000000039, 149.17000000000013, 0.949999999999981, -62.70999999999981, -6.100000000000083, -52.41000000000018, 5.519999999999927, 27.54999999999995, -0.20000000000004015, 29.420000000000474, -14.379999999999777, 158.94, 194.92999999999967, -5.590000000000062, 193.76999999999964, -31.620000000000033, -13.51999999999973, 4.819999999999941, -244.47000000000014, 3.899999999999961, 20.390000000000505, 93.63000000000008, 64.97000000000024, 0.969999999999981, -385.0500000000002, 62.95999999999982, -18.21999999999942, -48.5200000000006, -1.0700000000000622, 171.9199999999999, 195.85999999999967, 33.55999999999991, 0.9499999999999819, 161.89999999999995, -5.090000000000083, -66.84999999999839, 18.710000000000406, -37.44999999999997, 138.64000000000013, 291.13, 14.589999999999925, 198.64000000000019, 127.8800000000003, 8.69000000000019, 26.410000000000444, 19.61000000000054, -0.34000000000004116, 21.640000000000516, 0.9199999999999818, -87.23999999999987, 22.750000000000238, 20.280000000000488, -0.3600000000000376, -23.27000000000006, -13.17999999999992, -37.350000000000726, -1.3500000000000634, -9.17000000000008, 97.00000000000068, -17.34999999999946, -4.4800000000000715, -244.38, -48.89999999999986, 91.0800000000012, -91.9899999999999, 0.8099999999999435, 126.43000000000026, -3.070000000000083, 2.949999999999982, 84.54000000000018, 55.2599999999996, -2.2600000000000797, -34.37000000000071], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.32999999999996, 2.0000000000000013, 2.0000000000000013, -16.089999999999705, 8.71999999999998, -4.030000000000042, -80.46999999999922, -10.12000000000004, -16.20999999999972, 1.9100000000000015, 2.0000000000000013, -8.050000000000042, -225.16, -237.19000000000005, -2.0200000000000387, -14.080000000000041, -3.220000000000038, -1.660000000000014, 182.0, -6.040000000000042, -16.0899999999997, 73.28000000000004, -221.29000000000025, -156.94000000000023, 27.4700000000002, 2.0000000000000013, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -210.0700000000004, -26.13999999999971, -5.200000000000037, -32.170000000000364, -4.030000000000042, 38.41999999999997, 24.770000000000277, -19.239999999999796, -185.94999999999987, -18.099999999999703, -7.270000000000028, -130.66000000000014, 86.78000000000011, 7.579999999999984, -36.19000000000036, -5.050000000000042, 176.0, -20.109999999999705, -52.30000000000023, 128.57, -83.4999999999995, -20.109999999999705, 105.71000000000036, -18.099999999999703, -122.91999999999959, 29.60000000000025, 101.57000000000009, -6.040000000000042, -0.00999999999999836, -2.739999999999945, -192.9700000000003, -2.020000000000042, -14.080000000000041, -39.8200000000002, -203.59000000000037, -30.45999999999976, -2.020000000000042, 0.5600000000002439, -0.00999999999999836, 9.919999999999959, -22.119999999999706, -33.58000000000027, 2.0000000000000013, -6.040000000000042, -54.34000000000033, 137.0, -10.060000000000041, 173.0, 8.929999999999959, -38.20000000000036, -1.3900000000000199, 197.0, -44.23000000000035, -71.5299999999993, -16.0899999999999, -37.390000000000136, -24.129999999999708, -18.099999999999703, 9.919999999999959, -247.54000000000008, -145.92999999999998, -18.099999999999703, 2.0000000000000013, -16.0899999999997, -15.51999999999986, 96.77, -26.13999999999971, 30.680000000000263, 9.289999999999973, -2.020000000000042, -0.00999999999999836, -273.55000000000007, -284.5000000000001, -38.29000000000034, 76.25000000000013, -34.18000000000036, -6.040000000000042, -86.43999999999927, -14.080000000000041, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 158.0, 188.0, -2.1400000000000396, -6.040000000000042, 32.600000000000016, -8.050000000000042, 2.0000000000000013, 155.0, -18.099999999999703, -4.030000000000042, -10.060000000000041, -96.48999999999923, -55.360000000000326, 14.749999999999963, -6.040000000000042, 2.0000000000000013, -88.45000000000003, 64.22000000000003, 14.419999999999973, 49.13000000000007, 194.0, -34.18000000000036, 12.769999999999966, 19.639999999999965, 158.0, -68.34999999999921, 153.23, -9.279999999999912, -4.030000000000042, 12.43999999999997, -4.030000000000042, -19.299999999999738, 10.90999999999996, 0.7700000000000012, -20.109999999999705, 9.649999999999965, -0.00999999999999836, 2.0000000000000013, -14.080000000000041, -93.72999999999944, -100.50999999999985, 2.0000000000000013, 17.750000000000107, 29.570000000000242, -56.29000000000034, 2.0000000000000013, -37.360000000000326, -32.17000000000003, -18.099999999999703, -16.089999999999705, -16.089999999999705, -36.19000000000036, -30.159999999999712, -44.35000000000033, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, 92.00000000000028, 2.0000000000000013, -36.28000000000034, -9.070000000000041, -40.360000000000305, -22.119999999999706, -389.95000000000005, -234.43, -20.350000000000286, -108.54999999999983, -2.020000000000042, 91.10000000000056, -182.94999999999987, -6.040000000000042, -12.190000000000039, 2.0000000000000013, -112.57000000000002, 173.0, 2.0000000000000013, -12.070000000000041, -8.050000000000042, 2.0000000000000013, 17.54000000000022, 2.0000000000000013, 54.43999999999982, -10.180000000000039, -6.040000000000042, -12.220000000000036, -45.25000000000035, -22.119999999999706], "policy_predator_policy_reward": [16.0, 13.0, 9.0, 0.0, 10.0, 0.0, 43.0, 45.0, 15.0, 1.0, 5.0, 2.0, 164.0, 9.0, 8.0, 5.0, 20.0, 12.0, 4.0, 8.0, 9.0, 0.0, 99.0, 27.0, 4.0, 5.0, 9.0, 10.0, 6.0, 8.0, 18.0, 94.0, 9.0, 19.0, 17.0, 3.0, 0.0, 7.0, 83.0, 92.0, 10.0, 12.0, 13.0, 65.0, 20.0, 19.0, 4.0, 8.0, 34.0, 32.0, 18.0, 48.0, 10.0, 16.0, 44.0, 40.0, 4.0, 14.0, 4.0, 3.0, 37.0, 96.0, 2.0, 8.0, 139.0, 52.0, 17.0, 21.0, 14.0, 13.0, 12.0, 0.0, 31.0, 30.0, 16.0, 30.0, 13.0, 19.0, 9.0, 4.0, 22.0, 12.0, 18.0, 23.0, 9.0, 47.0, 27.0, 21.0, 10.0, 3.0, 28.0, 121.0, 10.0, 10.0, 25.0, 27.0, 0.0, 23.0, 17.0, 8.0, 1.0, 2.0, 135.0, 38.0, 12.0, 13.0, 4.0, 18.0, 8.0, 44.0, 2.0, 7.0, 20.0, 8.0, 4.0, 6.0, 3.0, 4.0, 5.0, 2.0, 10.0, 15.0, 3.0, 6.0, 39.0, 46.0, 7.0, 3.0, 4.0, 45.0, 26.0, 34.0, 42.0, 6.0, 18.0, 18.0, 14.0, 7.0, 5.0, 38.0, 15.0, 7.0, 3.0, 15.0, 17.0, 11.0, 8.0, 11.0, 6.0, 6.0, 5.0, 8.0, 88.0, 19.0, 3.0, 0.0, 18.0, 29.0, 21.0, 14.0, 5.0, 22.0, 11.0, 8.0, 19.0, 10.0, 17.0, 24.0, 4.0, 17.0, 3.0, 0.0, 22.0, 6.0, 38.0, 20.0, 187.0, 193.0, 20.0, 60.0, 0.0, 2.0, 70.0, 27.0, 0.0, 11.0, 9.0, 57.0, 0.0, 7.0, 4.0, 5.0, 29.0, 36.0, 8.0, 3.0, 16.0, 0.0, 9.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6727040046895288, "mean_inference_ms": 1.7949302985404147, "mean_action_processing_ms": 0.29307672542368757, "mean_env_wait_ms": 0.22738028956788234, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004952788352966309, "StateBufferConnector_ms": 0.0032831430435180664, "ViewRequirementAgentConnector_ms": 0.12017965316772461}, "num_episodes": 18, "episode_return_max": 291.13, "episode_return_min": -385.0500000000002, "episode_return_mean": 14.235600000000064, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.6660182846485, "num_env_steps_trained_throughput_per_sec": 355.6660182846485, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 11151.948, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11151.89, "sample_time_ms": 1447.793, "learn_time_ms": 9685.053, "learn_throughput": 413.008, "synch_weights_time_ms": 16.697}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "310e1_00000", "date": "2024-08-15_01-07-31", "timestamp": 1723664251, "time_this_iter_s": 11.293292999267578, "time_total_s": 606.2128758430481, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 606.2128758430481, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 54.65625, "ram_util_percent": 83.3125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7177064304313963, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7411289391694247, "policy_loss": -0.004504762918111824, "vf_loss": 2.744892324341668, "vf_explained_var": 0.17929397285299958, "kl": 0.009885013661254147, "entropy": 1.1060430147975842, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.675051232115932, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.032807718256794, "policy_loss": -0.006792208838779183, "vf_loss": 4.038248089886216, "vf_explained_var": 0.4538204454871082, "kl": 0.012016211181244945, "entropy": 0.9417433897969584, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 291.13, "episode_reward_min": -385.0500000000002, "episode_reward_mean": 24.18230000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.95000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -8.043849999999978, "predator_policy": 20.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.38999999999995, 182.9499999999998, -6.410000000000075, 111.0700000000002, 111.60000000000096, -57.02000000000039, 149.17000000000013, 0.949999999999981, -62.70999999999981, -6.100000000000083, -52.41000000000018, 5.519999999999927, 27.54999999999995, -0.20000000000004015, 29.420000000000474, -14.379999999999777, 158.94, 194.92999999999967, -5.590000000000062, 193.76999999999964, -31.620000000000033, -13.51999999999973, 4.819999999999941, -244.47000000000014, 3.899999999999961, 20.390000000000505, 93.63000000000008, 64.97000000000024, 0.969999999999981, -385.0500000000002, 62.95999999999982, -18.21999999999942, -48.5200000000006, -1.0700000000000622, 171.9199999999999, 195.85999999999967, 33.55999999999991, 0.9499999999999819, 161.89999999999995, -5.090000000000083, -66.84999999999839, 18.710000000000406, -37.44999999999997, 138.64000000000013, 291.13, 14.589999999999925, 198.64000000000019, 127.8800000000003, 8.69000000000019, 26.410000000000444, 19.61000000000054, -0.34000000000004116, 21.640000000000516, 0.9199999999999818, -87.23999999999987, 22.750000000000238, 20.280000000000488, -0.3600000000000376, -23.27000000000006, -13.17999999999992, -37.350000000000726, -1.3500000000000634, -9.17000000000008, 97.00000000000068, -17.34999999999946, -4.4800000000000715, -244.38, -48.89999999999986, 91.0800000000012, -91.9899999999999, 0.8099999999999435, 126.43000000000026, -3.070000000000083, 2.949999999999982, 84.54000000000018, 55.2599999999996, -2.2600000000000797, -34.37000000000071, 74.010000000001, -31.36000000000002, 30.340000000000156, -8.560000000000027, -7.110000000000083, -28.660000000000032, 31.260000000000467, -89.73999999999967, 200.9899999999996, -23.8899999999996, 137.93000000000023, 125.57000000000097, 25.08999999999957, 117.59000000000084, -5.310000000000022, 147.8200000000001, 80.92, -2.1300000000000825, 1.9700000000000033, -18.21999999999942, -59.05000000000007, 34.459999999999695], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.579999999999984, -36.19000000000036, -5.050000000000042, 176.0, -20.109999999999705, -52.30000000000023, 128.57, -83.4999999999995, -20.109999999999705, 105.71000000000036, -18.099999999999703, -122.91999999999959, 29.60000000000025, 101.57000000000009, -6.040000000000042, -0.00999999999999836, -2.739999999999945, -192.9700000000003, -2.020000000000042, -14.080000000000041, -39.8200000000002, -203.59000000000037, -30.45999999999976, -2.020000000000042, 0.5600000000002439, -0.00999999999999836, 9.919999999999959, -22.119999999999706, -33.58000000000027, 2.0000000000000013, -6.040000000000042, -54.34000000000033, 137.0, -10.060000000000041, 173.0, 8.929999999999959, -38.20000000000036, -1.3900000000000199, 197.0, -44.23000000000035, -71.5299999999993, -16.0899999999999, -37.390000000000136, -24.129999999999708, -18.099999999999703, 9.919999999999959, -247.54000000000008, -145.92999999999998, -18.099999999999703, 2.0000000000000013, -16.0899999999997, -15.51999999999986, 96.77, -26.13999999999971, 30.680000000000263, 9.289999999999973, -2.020000000000042, -0.00999999999999836, -273.55000000000007, -284.5000000000001, -38.29000000000034, 76.25000000000013, -34.18000000000036, -6.040000000000042, -86.43999999999927, -14.080000000000041, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 158.0, 188.0, -2.1400000000000396, -6.040000000000042, 32.600000000000016, -8.050000000000042, 2.0000000000000013, 155.0, -18.099999999999703, -4.030000000000042, -10.060000000000041, -96.48999999999923, -55.360000000000326, 14.749999999999963, -6.040000000000042, 2.0000000000000013, -88.45000000000003, 64.22000000000003, 14.419999999999973, 49.13000000000007, 194.0, -34.18000000000036, 12.769999999999966, 19.639999999999965, 158.0, -68.34999999999921, 153.23, -9.279999999999912, -4.030000000000042, 12.43999999999997, -4.030000000000042, -19.299999999999738, 10.90999999999996, 0.7700000000000012, -20.109999999999705, 9.649999999999965, -0.00999999999999836, 2.0000000000000013, -14.080000000000041, -93.72999999999944, -100.50999999999985, 2.0000000000000013, 17.750000000000107, 29.570000000000242, -56.29000000000034, 2.0000000000000013, -37.360000000000326, -32.17000000000003, -18.099999999999703, -16.089999999999705, -16.089999999999705, -36.19000000000036, -30.159999999999712, -44.35000000000033, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, 92.00000000000028, 2.0000000000000013, -36.28000000000034, -9.070000000000041, -40.360000000000305, -22.119999999999706, -389.95000000000005, -234.43, -20.350000000000286, -108.54999999999983, -2.020000000000042, 91.10000000000056, -182.94999999999987, -6.040000000000042, -12.190000000000039, 2.0000000000000013, -112.57000000000002, 173.0, 2.0000000000000013, -12.070000000000041, -8.050000000000042, 2.0000000000000013, 17.54000000000022, 2.0000000000000013, 54.43999999999982, -10.180000000000039, -6.040000000000042, -12.220000000000036, -45.25000000000035, -22.119999999999706, 40.39999999999979, 25.61000000000014, -56.289999999999765, -12.070000000000041, -26.13999999999971, 29.48000000000009, -24.129999999999708, -9.430000000000035, -4.030000000000042, -14.080000000000041, -106.54000000000025, 13.87999999999996, 18.320000000000206, -10.060000000000041, -56.29000000000003, -88.45000000000014, 200.0, -0.00999999999999836, -19.630000000000006, -50.26000000000006, -12.070000000000041, 119.0, 13.87999999999996, 101.69000000000035, -18.820000000000178, 1.909999999999994, -14.080000000000041, 115.67000000000031, -27.189999999999717, 1.8799999999999941, -34.18000000000036, 161.0, 65.93000000000015, -0.00999999999999836, -4.030000000000042, -15.099999999999865, 2.0000000000000013, -4.030000000000042, -8.050000000000042, -32.170000000000364, -32.40999999999987, -108.64, 13.879999999999981, -58.42000000000016], "policy_predator_policy_reward": [20.0, 19.0, 4.0, 8.0, 34.0, 32.0, 18.0, 48.0, 10.0, 16.0, 44.0, 40.0, 4.0, 14.0, 4.0, 3.0, 37.0, 96.0, 2.0, 8.0, 139.0, 52.0, 17.0, 21.0, 14.0, 13.0, 12.0, 0.0, 31.0, 30.0, 16.0, 30.0, 13.0, 19.0, 9.0, 4.0, 22.0, 12.0, 18.0, 23.0, 9.0, 47.0, 27.0, 21.0, 10.0, 3.0, 28.0, 121.0, 10.0, 10.0, 25.0, 27.0, 0.0, 23.0, 17.0, 8.0, 1.0, 2.0, 135.0, 38.0, 12.0, 13.0, 4.0, 18.0, 8.0, 44.0, 2.0, 7.0, 20.0, 8.0, 4.0, 6.0, 3.0, 4.0, 5.0, 2.0, 10.0, 15.0, 3.0, 6.0, 39.0, 46.0, 7.0, 3.0, 4.0, 45.0, 26.0, 34.0, 42.0, 6.0, 18.0, 18.0, 14.0, 7.0, 5.0, 38.0, 15.0, 7.0, 3.0, 15.0, 17.0, 11.0, 8.0, 11.0, 6.0, 6.0, 5.0, 8.0, 88.0, 19.0, 3.0, 0.0, 18.0, 29.0, 21.0, 14.0, 5.0, 22.0, 11.0, 8.0, 19.0, 10.0, 17.0, 24.0, 4.0, 17.0, 3.0, 0.0, 22.0, 6.0, 38.0, 20.0, 187.0, 193.0, 20.0, 60.0, 0.0, 2.0, 70.0, 27.0, 0.0, 11.0, 9.0, 57.0, 0.0, 7.0, 4.0, 5.0, 29.0, 36.0, 8.0, 3.0, 16.0, 0.0, 9.0, 24.0, 7.0, 1.0, 11.0, 26.0, 21.0, 6.0, 0.0, 25.0, 3.0, 8.0, 28.0, 36.0, 17.0, 6.0, 8.0, 47.0, 1.0, 0.0, 14.0, 32.0, 27.0, 4.0, 0.0, 10.0, 33.0, 9.0, 2.0, 14.0, 16.0, 4.0, 3.0, 18.0, 13.0, 2.0, 10.0, 7.0, 3.0, 1.0, 5.0, 17.0, 51.0, 31.0, 42.0, 37.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6757021246735377, "mean_inference_ms": 1.8010078319564673, "mean_action_processing_ms": 0.2939576224223191, "mean_env_wait_ms": 0.22805128877806757, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043561458587646484, "StateBufferConnector_ms": 0.003333568572998047, "ViewRequirementAgentConnector_ms": 0.14416944980621338}, "num_episodes": 22, "episode_return_max": 291.13, "episode_return_min": -385.0500000000002, "episode_return_mean": 24.18230000000009, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.45434902167494, "num_env_steps_trained_throughput_per_sec": 358.45434902167494, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 11183.328, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11183.27, "sample_time_ms": 1528.318, "learn_time_ms": 9636.101, "learn_throughput": 415.106, "synch_weights_time_ms": 16.707}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "310e1_00000", "date": "2024-08-15_01-07-42", "timestamp": 1723664262, "time_this_iter_s": 11.218933820724487, "time_total_s": 617.4318096637726, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a1d670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 617.4318096637726, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 56.662499999999994, "ram_util_percent": 82.96875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9574317330721194, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4771689741069047, "policy_loss": -0.007810376179724853, "vf_loss": 1.4841572905501361, "vf_explained_var": 0.16211023431606394, "kl": 0.010960800744176862, "entropy": 1.06606187605984, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.645151954983908, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9539973447562526, "policy_loss": -0.0029994253648159205, "vf_loss": 2.956485036188963, "vf_explained_var": 0.5935383988435937, "kl": 0.004548762403143149, "entropy": 0.9573960625620747, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 291.13, "episode_reward_min": -385.0500000000002, "episode_reward_mean": 23.2348000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.95000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -7.132599999999981, "predator_policy": 18.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-244.47000000000014, 3.899999999999961, 20.390000000000505, 93.63000000000008, 64.97000000000024, 0.969999999999981, -385.0500000000002, 62.95999999999982, -18.21999999999942, -48.5200000000006, -1.0700000000000622, 171.9199999999999, 195.85999999999967, 33.55999999999991, 0.9499999999999819, 161.89999999999995, -5.090000000000083, -66.84999999999839, 18.710000000000406, -37.44999999999997, 138.64000000000013, 291.13, 14.589999999999925, 198.64000000000019, 127.8800000000003, 8.69000000000019, 26.410000000000444, 19.61000000000054, -0.34000000000004116, 21.640000000000516, 0.9199999999999818, -87.23999999999987, 22.750000000000238, 20.280000000000488, -0.3600000000000376, -23.27000000000006, -13.17999999999992, -37.350000000000726, -1.3500000000000634, -9.17000000000008, 97.00000000000068, -17.34999999999946, -4.4800000000000715, -244.38, -48.89999999999986, 91.0800000000012, -91.9899999999999, 0.8099999999999435, 126.43000000000026, -3.070000000000083, 2.949999999999982, 84.54000000000018, 55.2599999999996, -2.2600000000000797, -34.37000000000071, 74.010000000001, -31.36000000000002, 30.340000000000156, -8.560000000000027, -7.110000000000083, -28.660000000000032, 31.260000000000467, -89.73999999999967, 200.9899999999996, -23.8899999999996, 137.93000000000023, 125.57000000000097, 25.08999999999957, 117.59000000000084, -5.310000000000022, 147.8200000000001, 80.92, -2.1300000000000825, 1.9700000000000033, -18.21999999999942, -59.05000000000007, 34.459999999999695, -46.630000000000614, 8.78999999999992, 160.0, -2.060000000000084, 61.33999999999992, -15.18999999999959, 69.81000000000026, -0.04000000000004011, -20.560000000000002, 6.799999999999919, -10.150000000000082, 74.84000000000044, -7.740000000000066, -8.17000000000001, -95.3299999999992, 12.129999999999967, 2.7899999999999805, -9.130000000000082, 199.97999999999962, 104.19000000000021, 76.72000000000028, 185.74000000000007, 88.24000000000021], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-247.54000000000008, -145.92999999999998, -18.099999999999703, 2.0000000000000013, -16.0899999999997, -15.51999999999986, 96.77, -26.13999999999971, 30.680000000000263, 9.289999999999973, -2.020000000000042, -0.00999999999999836, -273.55000000000007, -284.5000000000001, -38.29000000000034, 76.25000000000013, -34.18000000000036, -6.040000000000042, -86.43999999999927, -14.080000000000041, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 158.0, 188.0, -2.1400000000000396, -6.040000000000042, 32.600000000000016, -8.050000000000042, 2.0000000000000013, 155.0, -18.099999999999703, -4.030000000000042, -10.060000000000041, -96.48999999999923, -55.360000000000326, 14.749999999999963, -6.040000000000042, 2.0000000000000013, -88.45000000000003, 64.22000000000003, 14.419999999999973, 49.13000000000007, 194.0, -34.18000000000036, 12.769999999999966, 19.639999999999965, 158.0, -68.34999999999921, 153.23, -9.279999999999912, -4.030000000000042, 12.43999999999997, -4.030000000000042, -19.299999999999738, 10.90999999999996, 0.7700000000000012, -20.109999999999705, 9.649999999999965, -0.00999999999999836, 2.0000000000000013, -14.080000000000041, -93.72999999999944, -100.50999999999985, 2.0000000000000013, 17.750000000000107, 29.570000000000242, -56.29000000000034, 2.0000000000000013, -37.360000000000326, -32.17000000000003, -18.099999999999703, -16.089999999999705, -16.089999999999705, -36.19000000000036, -30.159999999999712, -44.35000000000033, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, 92.00000000000028, 2.0000000000000013, -36.28000000000034, -9.070000000000041, -40.360000000000305, -22.119999999999706, -389.95000000000005, -234.43, -20.350000000000286, -108.54999999999983, -2.020000000000042, 91.10000000000056, -182.94999999999987, -6.040000000000042, -12.190000000000039, 2.0000000000000013, -112.57000000000002, 173.0, 2.0000000000000013, -12.070000000000041, -8.050000000000042, 2.0000000000000013, 17.54000000000022, 2.0000000000000013, 54.43999999999982, -10.180000000000039, -6.040000000000042, -12.220000000000036, -45.25000000000035, -22.119999999999706, 40.39999999999979, 25.61000000000014, -56.289999999999765, -12.070000000000041, -26.13999999999971, 29.48000000000009, -24.129999999999708, -9.430000000000035, -4.030000000000042, -14.080000000000041, -106.54000000000025, 13.87999999999996, 18.320000000000206, -10.060000000000041, -56.29000000000003, -88.45000000000014, 200.0, -0.00999999999999836, -19.630000000000006, -50.26000000000006, -12.070000000000041, 119.0, 13.87999999999996, 101.69000000000035, -18.820000000000178, 1.909999999999994, -14.080000000000041, 115.67000000000031, -27.189999999999717, 1.8799999999999941, -34.18000000000036, 161.0, 65.93000000000015, -0.00999999999999836, -4.030000000000042, -15.099999999999865, 2.0000000000000013, -4.030000000000042, -8.050000000000042, -32.170000000000364, -32.40999999999987, -108.64, 13.879999999999981, -58.42000000000016, -66.33999999999915, -56.29000000000029, -24.129999999999708, 9.919999999999959, 2.0000000000000013, 113.0, -4.030000000000042, -4.030000000000042, 59.35999999999997, -2.020000000000042, -2.020000000000042, -32.170000000000336, -49.270000000000344, 93.08, 2.0000000000000013, -6.040000000000042, -27.340000000000014, -33.220000000000354, -10.060000000000041, 3.8599999999999604, 2.0000000000000013, -28.14999999999971, 17.84000000000003, 2.0000000000000013, -124.62999999999931, 12.88999999999996, -10.060000000000041, -20.10999999999995, -42.34000000000033, -196.99000000000038, -8.050000000000042, -18.819999999999865, 2.0000000000000013, -10.210000000000036, -14.080000000000041, -8.050000000000042, -2.020000000000042, 200.0, -0.00999999999999836, 57.20000000000003, 44.71999999999986, 2.0000000000000013, 0.740000000000272, 173.0, -68.52999999999926, 111.77], "policy_predator_policy_reward": [28.0, 121.0, 10.0, 10.0, 25.0, 27.0, 0.0, 23.0, 17.0, 8.0, 1.0, 2.0, 135.0, 38.0, 12.0, 13.0, 4.0, 18.0, 8.0, 44.0, 2.0, 7.0, 20.0, 8.0, 4.0, 6.0, 3.0, 4.0, 5.0, 2.0, 10.0, 15.0, 3.0, 6.0, 39.0, 46.0, 7.0, 3.0, 4.0, 45.0, 26.0, 34.0, 42.0, 6.0, 18.0, 18.0, 14.0, 7.0, 5.0, 38.0, 15.0, 7.0, 3.0, 15.0, 17.0, 11.0, 8.0, 11.0, 6.0, 6.0, 5.0, 8.0, 88.0, 19.0, 3.0, 0.0, 18.0, 29.0, 21.0, 14.0, 5.0, 22.0, 11.0, 8.0, 19.0, 10.0, 17.0, 24.0, 4.0, 17.0, 3.0, 0.0, 22.0, 6.0, 38.0, 20.0, 187.0, 193.0, 20.0, 60.0, 0.0, 2.0, 70.0, 27.0, 0.0, 11.0, 9.0, 57.0, 0.0, 7.0, 4.0, 5.0, 29.0, 36.0, 8.0, 3.0, 16.0, 0.0, 9.0, 24.0, 7.0, 1.0, 11.0, 26.0, 21.0, 6.0, 0.0, 25.0, 3.0, 8.0, 28.0, 36.0, 17.0, 6.0, 8.0, 47.0, 1.0, 0.0, 14.0, 32.0, 27.0, 4.0, 0.0, 10.0, 33.0, 9.0, 2.0, 14.0, 16.0, 4.0, 3.0, 18.0, 13.0, 2.0, 10.0, 7.0, 3.0, 1.0, 5.0, 17.0, 51.0, 31.0, 42.0, 37.0, 25.0, 51.0, 13.0, 10.0, 18.0, 27.0, 3.0, 3.0, 2.0, 2.0, 2.0, 17.0, 26.0, 0.0, 4.0, 0.0, 0.0, 40.0, 6.0, 7.0, 9.0, 7.0, 27.0, 28.0, 53.0, 51.0, 5.0, 17.0, 83.0, 61.0, 31.0, 8.0, 0.0, 11.0, 8.0, 5.0, 0.0, 2.0, 29.0, 18.0, 2.0, 28.0, 9.0, 3.0, 13.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6799138875957367, "mean_inference_ms": 1.8086372694996902, "mean_action_processing_ms": 0.29505150473267316, "mean_env_wait_ms": 0.22890258535580849, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00382077693939209, "StateBufferConnector_ms": 0.004376530647277832, "ViewRequirementAgentConnector_ms": 0.1508394479751587}, "num_episodes": 23, "episode_return_max": 291.13, "episode_return_min": -385.0500000000002, "episode_return_mean": 23.2348000000001, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.16869339899597, "num_env_steps_trained_throughput_per_sec": 360.16869339899597, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 11162.349, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11162.291, "sample_time_ms": 1570.699, "learn_time_ms": 9572.947, "learn_throughput": 417.844, "synch_weights_time_ms": 16.5}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "310e1_00000", "date": "2024-08-15_01-07-53", "timestamp": 1723664273, "time_this_iter_s": 11.151479005813599, "time_total_s": 628.5832886695862, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a1d430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 628.5832886695862, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 55.34000000000001, "ram_util_percent": 82.86}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3477491966631048, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7808756390418956, "policy_loss": -0.0049357876251821245, "vf_loss": 0.7853082664744564, "vf_explained_var": 0.08847210003585412, "kl": 0.00670880011570095, "entropy": 1.0485173684263986, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.190568016256605, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0032900923143617, "policy_loss": -0.004560955095710972, "vf_loss": 3.00736992233014, "vf_explained_var": 0.6243726080687588, "kl": 0.008553282868256741, "entropy": 0.9313534480869454, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 305.89000000000004, "episode_reward_min": -244.38, "episode_reward_mean": 33.57170000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.95000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -0.30414999999998943, "predator_policy": 17.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.710000000000406, -37.44999999999997, 138.64000000000013, 291.13, 14.589999999999925, 198.64000000000019, 127.8800000000003, 8.69000000000019, 26.410000000000444, 19.61000000000054, -0.34000000000004116, 21.640000000000516, 0.9199999999999818, -87.23999999999987, 22.750000000000238, 20.280000000000488, -0.3600000000000376, -23.27000000000006, -13.17999999999992, -37.350000000000726, -1.3500000000000634, -9.17000000000008, 97.00000000000068, -17.34999999999946, -4.4800000000000715, -244.38, -48.89999999999986, 91.0800000000012, -91.9899999999999, 0.8099999999999435, 126.43000000000026, -3.070000000000083, 2.949999999999982, 84.54000000000018, 55.2599999999996, -2.2600000000000797, -34.37000000000071, 74.010000000001, -31.36000000000002, 30.340000000000156, -8.560000000000027, -7.110000000000083, -28.660000000000032, 31.260000000000467, -89.73999999999967, 200.9899999999996, -23.8899999999996, 137.93000000000023, 125.57000000000097, 25.08999999999957, 117.59000000000084, -5.310000000000022, 147.8200000000001, 80.92, -2.1300000000000825, 1.9700000000000033, -18.21999999999942, -59.05000000000007, 34.459999999999695, -46.630000000000614, 8.78999999999992, 160.0, -2.060000000000084, 61.33999999999992, -15.18999999999959, 69.81000000000026, -0.04000000000004011, -20.560000000000002, 6.799999999999919, -10.150000000000082, 74.84000000000044, -7.740000000000066, -8.17000000000001, -95.3299999999992, 12.129999999999967, 2.7899999999999805, -9.130000000000082, 199.97999999999962, 104.19000000000021, 76.72000000000028, 185.74000000000007, 88.24000000000021, 145.32999999999953, 305.89000000000004, -10.130000000000082, 45.419999999999405, -21.310000000000063, 124.58000000000024, -75.78999999999871, -14.189999999999742, 14.75999999999992, 200.9399999999996, 188.85999999999973, -13.169999999999959, -1.1600000000000614, -54.5800000000006, -4.340000000000078, -4.180000000000081, 65.02000000000025, 183.4799999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [14.749999999999963, -6.040000000000042, 2.0000000000000013, -88.45000000000003, 64.22000000000003, 14.419999999999973, 49.13000000000007, 194.0, -34.18000000000036, 12.769999999999966, 19.639999999999965, 158.0, -68.34999999999921, 153.23, -9.279999999999912, -4.030000000000042, 12.43999999999997, -4.030000000000042, -19.299999999999738, 10.90999999999996, 0.7700000000000012, -20.109999999999705, 9.649999999999965, -0.00999999999999836, 2.0000000000000013, -14.080000000000041, -93.72999999999944, -100.50999999999985, 2.0000000000000013, 17.750000000000107, 29.570000000000242, -56.29000000000034, 2.0000000000000013, -37.360000000000326, -32.17000000000003, -18.099999999999703, -16.089999999999705, -16.089999999999705, -36.19000000000036, -30.159999999999712, -44.35000000000033, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, 92.00000000000028, 2.0000000000000013, -36.28000000000034, -9.070000000000041, -40.360000000000305, -22.119999999999706, -389.95000000000005, -234.43, -20.350000000000286, -108.54999999999983, -2.020000000000042, 91.10000000000056, -182.94999999999987, -6.040000000000042, -12.190000000000039, 2.0000000000000013, -112.57000000000002, 173.0, 2.0000000000000013, -12.070000000000041, -8.050000000000042, 2.0000000000000013, 17.54000000000022, 2.0000000000000013, 54.43999999999982, -10.180000000000039, -6.040000000000042, -12.220000000000036, -45.25000000000035, -22.119999999999706, 40.39999999999979, 25.61000000000014, -56.289999999999765, -12.070000000000041, -26.13999999999971, 29.48000000000009, -24.129999999999708, -9.430000000000035, -4.030000000000042, -14.080000000000041, -106.54000000000025, 13.87999999999996, 18.320000000000206, -10.060000000000041, -56.29000000000003, -88.45000000000014, 200.0, -0.00999999999999836, -19.630000000000006, -50.26000000000006, -12.070000000000041, 119.0, 13.87999999999996, 101.69000000000035, -18.820000000000178, 1.909999999999994, -14.080000000000041, 115.67000000000031, -27.189999999999717, 1.8799999999999941, -34.18000000000036, 161.0, 65.93000000000015, -0.00999999999999836, -4.030000000000042, -15.099999999999865, 2.0000000000000013, -4.030000000000042, -8.050000000000042, -32.170000000000364, -32.40999999999987, -108.64, 13.879999999999981, -58.42000000000016, -66.33999999999915, -56.29000000000029, -24.129999999999708, 9.919999999999959, 2.0000000000000013, 113.0, -4.030000000000042, -4.030000000000042, 59.35999999999997, -2.020000000000042, -2.020000000000042, -32.170000000000336, -49.270000000000344, 93.08, 2.0000000000000013, -6.040000000000042, -27.340000000000014, -33.220000000000354, -10.060000000000041, 3.8599999999999604, 2.0000000000000013, -28.14999999999971, 17.84000000000003, 2.0000000000000013, -124.62999999999931, 12.88999999999996, -10.060000000000041, -20.10999999999995, -42.34000000000033, -196.99000000000038, -8.050000000000042, -18.819999999999865, 2.0000000000000013, -10.210000000000036, -14.080000000000041, -8.050000000000042, -2.020000000000042, 200.0, -0.00999999999999836, 57.20000000000003, 44.71999999999986, 2.0000000000000013, 0.740000000000272, 173.0, -68.52999999999926, 111.77, 131.3299999999997, 2.0000000000000013, 191.0, 111.89, -16.0899999999997, -6.040000000000042, -14.080000000000041, 51.4999999999997, -12.070000000000041, -37.24000000000004, 121.60999999999999, -4.030000000000042, -18.099999999999838, -136.6900000000012, -22.11999999999971, -12.070000000000041, -11.200000000000035, 5.959999999999958, 197.0, 1.9400000000000013, 200.0, -26.139999999999713, -26.13999999999972, -4.030000000000042, 2.0000000000000013, -24.159999999999712, -8.050000000000042, -104.52999999999926, -0.13000000000000678, -40.210000000000356, 2.0000000000000013, -19.179999999999715, -6.040000000000042, 53.05999999999979, 155.0, 5.4799999999999685], "policy_predator_policy_reward": [7.0, 3.0, 4.0, 45.0, 26.0, 34.0, 42.0, 6.0, 18.0, 18.0, 14.0, 7.0, 5.0, 38.0, 15.0, 7.0, 3.0, 15.0, 17.0, 11.0, 8.0, 11.0, 6.0, 6.0, 5.0, 8.0, 88.0, 19.0, 3.0, 0.0, 18.0, 29.0, 21.0, 14.0, 5.0, 22.0, 11.0, 8.0, 19.0, 10.0, 17.0, 24.0, 4.0, 17.0, 3.0, 0.0, 22.0, 6.0, 38.0, 20.0, 187.0, 193.0, 20.0, 60.0, 0.0, 2.0, 70.0, 27.0, 0.0, 11.0, 9.0, 57.0, 0.0, 7.0, 4.0, 5.0, 29.0, 36.0, 8.0, 3.0, 16.0, 0.0, 9.0, 24.0, 7.0, 1.0, 11.0, 26.0, 21.0, 6.0, 0.0, 25.0, 3.0, 8.0, 28.0, 36.0, 17.0, 6.0, 8.0, 47.0, 1.0, 0.0, 14.0, 32.0, 27.0, 4.0, 0.0, 10.0, 33.0, 9.0, 2.0, 14.0, 16.0, 4.0, 3.0, 18.0, 13.0, 2.0, 10.0, 7.0, 3.0, 1.0, 5.0, 17.0, 51.0, 31.0, 42.0, 37.0, 25.0, 51.0, 13.0, 10.0, 18.0, 27.0, 3.0, 3.0, 2.0, 2.0, 2.0, 17.0, 26.0, 0.0, 4.0, 0.0, 0.0, 40.0, 6.0, 7.0, 9.0, 7.0, 27.0, 28.0, 53.0, 51.0, 5.0, 17.0, 83.0, 61.0, 31.0, 8.0, 0.0, 11.0, 8.0, 5.0, 0.0, 2.0, 29.0, 18.0, 2.0, 28.0, 9.0, 3.0, 13.0, 32.0, 0.0, 12.0, 0.0, 3.0, 9.0, 3.0, 8.0, 0.0, 6.0, 22.0, 1.0, 6.0, 3.0, 76.0, 5.0, 15.0, 9.0, 11.0, 0.0, 2.0, 14.0, 1.0, 3.0, 14.0, 14.0, 7.0, 5.0, 53.0, 17.0, 19.0, 13.0, 0.0, 4.0, 14.0, 17.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6829739371994696, "mean_inference_ms": 1.8138231642837475, "mean_action_processing_ms": 0.2958666096503811, "mean_env_wait_ms": 0.22945935163318246, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037887096405029297, "StateBufferConnector_ms": 0.004384160041809082, "ViewRequirementAgentConnector_ms": 0.1534428596496582}, "num_episodes": 18, "episode_return_max": 305.89000000000004, "episode_return_min": -244.38, "episode_return_mean": 33.57170000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.4660566741963, "num_env_steps_trained_throughput_per_sec": 365.4660566741963, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 11075.071, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11075.013, "sample_time_ms": 1543.198, "learn_time_ms": 9513.708, "learn_throughput": 420.446, "synch_weights_time_ms": 15.963}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "310e1_00000", "date": "2024-08-15_01-08-04", "timestamp": 1723664284, "time_this_iter_s": 11.002756834030151, "time_total_s": 639.5860455036163, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1967b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 639.5860455036163, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 56.5875, "ram_util_percent": 83.2125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4937789419183025, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5031025280397405, "policy_loss": -0.0059937504883954135, "vf_loss": 2.5083859384375273, "vf_explained_var": 0.10258279035961818, "kl": 0.00947123757831203, "entropy": 0.8695013371094195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9559797905424916, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.121584997606025, "policy_loss": -0.008683561344714786, "vf_loss": 5.129390264566613, "vf_explained_var": 0.5282485639292096, "kl": 0.01561404538448932, "entropy": 0.79752650383919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 332.49999999999955, "episode_reward_min": -244.38, "episode_reward_mean": 43.805000000000035, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.95000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": 3.5075000000000074, "predator_policy": 18.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.17999999999992, -37.350000000000726, -1.3500000000000634, -9.17000000000008, 97.00000000000068, -17.34999999999946, -4.4800000000000715, -244.38, -48.89999999999986, 91.0800000000012, -91.9899999999999, 0.8099999999999435, 126.43000000000026, -3.070000000000083, 2.949999999999982, 84.54000000000018, 55.2599999999996, -2.2600000000000797, -34.37000000000071, 74.010000000001, -31.36000000000002, 30.340000000000156, -8.560000000000027, -7.110000000000083, -28.660000000000032, 31.260000000000467, -89.73999999999967, 200.9899999999996, -23.8899999999996, 137.93000000000023, 125.57000000000097, 25.08999999999957, 117.59000000000084, -5.310000000000022, 147.8200000000001, 80.92, -2.1300000000000825, 1.9700000000000033, -18.21999999999942, -59.05000000000007, 34.459999999999695, -46.630000000000614, 8.78999999999992, 160.0, -2.060000000000084, 61.33999999999992, -15.18999999999959, 69.81000000000026, -0.04000000000004011, -20.560000000000002, 6.799999999999919, -10.150000000000082, 74.84000000000044, -7.740000000000066, -8.17000000000001, -95.3299999999992, 12.129999999999967, 2.7899999999999805, -9.130000000000082, 199.97999999999962, 104.19000000000021, 76.72000000000028, 185.74000000000007, 88.24000000000021, 145.32999999999953, 305.89000000000004, -10.130000000000082, 45.419999999999405, -21.310000000000063, 124.58000000000024, -75.78999999999871, -14.189999999999742, 14.75999999999992, 200.9399999999996, 188.85999999999973, -13.169999999999959, -1.1600000000000614, -54.5800000000006, -4.340000000000078, -4.180000000000081, 65.02000000000025, 183.4799999999998, 33.509999999999934, 202.05, 117.2000000000005, -35.83000000000005, 3.93999999999996, -4.320000000000078, 268.109999999999, 332.49999999999955, 185.91999999999976, 105.09000000000015, 0.8899999999999809, 230.24, -3.0700000000000838, 23.51999999999994, -7.190000000000017, 102.17000000000014, 140.2399999999999, 89.59000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.089999999999705, -16.089999999999705, -36.19000000000036, -30.159999999999712, -44.35000000000033, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, 92.00000000000028, 2.0000000000000013, -36.28000000000034, -9.070000000000041, -40.360000000000305, -22.119999999999706, -389.95000000000005, -234.43, -20.350000000000286, -108.54999999999983, -2.020000000000042, 91.10000000000056, -182.94999999999987, -6.040000000000042, -12.190000000000039, 2.0000000000000013, -112.57000000000002, 173.0, 2.0000000000000013, -12.070000000000041, -8.050000000000042, 2.0000000000000013, 17.54000000000022, 2.0000000000000013, 54.43999999999982, -10.180000000000039, -6.040000000000042, -12.220000000000036, -45.25000000000035, -22.119999999999706, 40.39999999999979, 25.61000000000014, -56.289999999999765, -12.070000000000041, -26.13999999999971, 29.48000000000009, -24.129999999999708, -9.430000000000035, -4.030000000000042, -14.080000000000041, -106.54000000000025, 13.87999999999996, 18.320000000000206, -10.060000000000041, -56.29000000000003, -88.45000000000014, 200.0, -0.00999999999999836, -19.630000000000006, -50.26000000000006, -12.070000000000041, 119.0, 13.87999999999996, 101.69000000000035, -18.820000000000178, 1.909999999999994, -14.080000000000041, 115.67000000000031, -27.189999999999717, 1.8799999999999941, -34.18000000000036, 161.0, 65.93000000000015, -0.00999999999999836, -4.030000000000042, -15.099999999999865, 2.0000000000000013, -4.030000000000042, -8.050000000000042, -32.170000000000364, -32.40999999999987, -108.64, 13.879999999999981, -58.42000000000016, -66.33999999999915, -56.29000000000029, -24.129999999999708, 9.919999999999959, 2.0000000000000013, 113.0, -4.030000000000042, -4.030000000000042, 59.35999999999997, -2.020000000000042, -2.020000000000042, -32.170000000000336, -49.270000000000344, 93.08, 2.0000000000000013, -6.040000000000042, -27.340000000000014, -33.220000000000354, -10.060000000000041, 3.8599999999999604, 2.0000000000000013, -28.14999999999971, 17.84000000000003, 2.0000000000000013, -124.62999999999931, 12.88999999999996, -10.060000000000041, -20.10999999999995, -42.34000000000033, -196.99000000000038, -8.050000000000042, -18.819999999999865, 2.0000000000000013, -10.210000000000036, -14.080000000000041, -8.050000000000042, -2.020000000000042, 200.0, -0.00999999999999836, 57.20000000000003, 44.71999999999986, 2.0000000000000013, 0.740000000000272, 173.0, -68.52999999999926, 111.77, 131.3299999999997, 2.0000000000000013, 191.0, 111.89, -16.0899999999997, -6.040000000000042, -14.080000000000041, 51.4999999999997, -12.070000000000041, -37.24000000000004, 121.60999999999999, -4.030000000000042, -18.099999999999838, -136.6900000000012, -22.11999999999971, -12.070000000000041, -11.200000000000035, 5.959999999999958, 197.0, 1.9400000000000013, 200.0, -26.139999999999713, -26.13999999999972, -4.030000000000042, 2.0000000000000013, -24.159999999999712, -8.050000000000042, -104.52999999999926, -0.13000000000000678, -40.210000000000356, 2.0000000000000013, -19.179999999999715, -6.040000000000042, 53.05999999999979, 155.0, 5.4799999999999685, 17.510000000000236, 2.0000000000000013, -41.950000000000045, 128.0, -10.060000000000041, 72.26000000000013, 2.0000000000000013, -164.83000000000044, 2.0000000000000013, -10.060000000000041, 13.87999999999996, -38.20000000000036, 84.11000000000057, 167.0, 194.0, 123.50000000000026, -2.080000000000041, 179.0, 133.45999999999998, -72.36999999999917, -2.080000000000041, -4.030000000000042, 181.07, -23.83, -8.050000000000042, -2.020000000000042, -26.13999999999971, 35.66, 2.0000000000000013, -36.18999999999971, -164.8300000000006, 176.0, 146.0, -126.76000000000005, -2.409999999999698, 2.0000000000000013], "policy_predator_policy_reward": [11.0, 8.0, 19.0, 10.0, 17.0, 24.0, 4.0, 17.0, 3.0, 0.0, 22.0, 6.0, 38.0, 20.0, 187.0, 193.0, 20.0, 60.0, 0.0, 2.0, 70.0, 27.0, 0.0, 11.0, 9.0, 57.0, 0.0, 7.0, 4.0, 5.0, 29.0, 36.0, 8.0, 3.0, 16.0, 0.0, 9.0, 24.0, 7.0, 1.0, 11.0, 26.0, 21.0, 6.0, 0.0, 25.0, 3.0, 8.0, 28.0, 36.0, 17.0, 6.0, 8.0, 47.0, 1.0, 0.0, 14.0, 32.0, 27.0, 4.0, 0.0, 10.0, 33.0, 9.0, 2.0, 14.0, 16.0, 4.0, 3.0, 18.0, 13.0, 2.0, 10.0, 7.0, 3.0, 1.0, 5.0, 17.0, 51.0, 31.0, 42.0, 37.0, 25.0, 51.0, 13.0, 10.0, 18.0, 27.0, 3.0, 3.0, 2.0, 2.0, 2.0, 17.0, 26.0, 0.0, 4.0, 0.0, 0.0, 40.0, 6.0, 7.0, 9.0, 7.0, 27.0, 28.0, 53.0, 51.0, 5.0, 17.0, 83.0, 61.0, 31.0, 8.0, 0.0, 11.0, 8.0, 5.0, 0.0, 2.0, 29.0, 18.0, 2.0, 28.0, 9.0, 3.0, 13.0, 32.0, 0.0, 12.0, 0.0, 3.0, 9.0, 3.0, 8.0, 0.0, 6.0, 22.0, 1.0, 6.0, 3.0, 76.0, 5.0, 15.0, 9.0, 11.0, 0.0, 2.0, 14.0, 1.0, 3.0, 14.0, 14.0, 7.0, 5.0, 53.0, 17.0, 19.0, 13.0, 0.0, 4.0, 14.0, 17.0, 6.0, 3.0, 11.0, 79.0, 37.0, 31.0, 24.0, 76.0, 51.0, 6.0, 6.0, 0.0, 20.0, 11.0, 6.0, 9.0, 6.0, 8.0, 1.0, 2.0, 42.0, 4.0, 3.0, 27.0, 46.0, 5.0, 2.0, 14.0, 0.0, 11.0, 16.0, 8.0, 83.0, 101.0, 20.0, 42.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6850499597161251, "mean_inference_ms": 1.8167156206075976, "mean_action_processing_ms": 0.29628299045922557, "mean_env_wait_ms": 0.22985760565828284, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003918647766113281, "StateBufferConnector_ms": 0.004333019256591797, "ViewRequirementAgentConnector_ms": 0.1376563310623169}, "num_episodes": 18, "episode_return_max": 332.49999999999955, "episode_return_min": -244.38, "episode_return_mean": 43.805000000000035, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.20113073515057, "num_env_steps_trained_throughput_per_sec": 369.20113073515057, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 11074.127, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11074.074, "sample_time_ms": 1540.832, "learn_time_ms": 9515.129, "learn_throughput": 420.383, "synch_weights_time_ms": 15.71}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "310e1_00000", "date": "2024-08-15_01-08-15", "timestamp": 1723664295, "time_this_iter_s": 10.879461288452148, "time_total_s": 650.4655067920685, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14c68b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 650.4655067920685, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 55.713333333333324, "ram_util_percent": 83.56}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6127575453627045, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6893187301657188, "policy_loss": -0.005908502421647349, "vf_loss": 0.6946991471583566, "vf_explained_var": 0.10691574427185865, "kl": 0.007041126914068852, "entropy": 0.9882648847090504, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8356355948422953, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.678989339253259, "policy_loss": -0.0037193661062884585, "vf_loss": 4.682378889643957, "vf_explained_var": 0.702401823972268, "kl": 0.005863363459811437, "entropy": 0.8677762432703896, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 358.0, "episode_reward_min": -119.21999999999858, "episode_reward_mean": 71.47700000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -196.99000000000038, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 101.0}, "policy_reward_mean": {"prey_policy": 18.37850000000001, "predator_policy": 17.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.560000000000027, -7.110000000000083, -28.660000000000032, 31.260000000000467, -89.73999999999967, 200.9899999999996, -23.8899999999996, 137.93000000000023, 125.57000000000097, 25.08999999999957, 117.59000000000084, -5.310000000000022, 147.8200000000001, 80.92, -2.1300000000000825, 1.9700000000000033, -18.21999999999942, -59.05000000000007, 34.459999999999695, -46.630000000000614, 8.78999999999992, 160.0, -2.060000000000084, 61.33999999999992, -15.18999999999959, 69.81000000000026, -0.04000000000004011, -20.560000000000002, 6.799999999999919, -10.150000000000082, 74.84000000000044, -7.740000000000066, -8.17000000000001, -95.3299999999992, 12.129999999999967, 2.7899999999999805, -9.130000000000082, 199.97999999999962, 104.19000000000021, 76.72000000000028, 185.74000000000007, 88.24000000000021, 145.32999999999953, 305.89000000000004, -10.130000000000082, 45.419999999999405, -21.310000000000063, 124.58000000000024, -75.78999999999871, -14.189999999999742, 14.75999999999992, 200.9399999999996, 188.85999999999973, -13.169999999999959, -1.1600000000000614, -54.5800000000006, -4.340000000000078, -4.180000000000081, 65.02000000000025, 183.4799999999998, 33.509999999999934, 202.05, 117.2000000000005, -35.83000000000005, 3.93999999999996, -4.320000000000078, 268.109999999999, 332.49999999999955, 185.91999999999976, 105.09000000000015, 0.8899999999999809, 230.24, -3.0700000000000838, 23.51999999999994, -7.190000000000017, 102.17000000000014, 140.2399999999999, 89.59000000000006, 174.87999999999985, 358.0, 172.9299999999999, -119.21999999999858, 168.22999999999993, 178.12999999999982, 212.4099999999995, 348.3099999999997, 347.19, 58.96999999999993, -1.1800000000000614, 149.01000000000013, -27.879999999999562, -8.120000000000083, 109.73000000000017, 86.23000000000006, -15.189999999999568, 17.40000000000019, 259.06, 147.69, 155.0899999999996, 18.740000000000407], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.129999999999708, -9.430000000000035, -4.030000000000042, -14.080000000000041, -106.54000000000025, 13.87999999999996, 18.320000000000206, -10.060000000000041, -56.29000000000003, -88.45000000000014, 200.0, -0.00999999999999836, -19.630000000000006, -50.26000000000006, -12.070000000000041, 119.0, 13.87999999999996, 101.69000000000035, -18.820000000000178, 1.909999999999994, -14.080000000000041, 115.67000000000031, -27.189999999999717, 1.8799999999999941, -34.18000000000036, 161.0, 65.93000000000015, -0.00999999999999836, -4.030000000000042, -15.099999999999865, 2.0000000000000013, -4.030000000000042, -8.050000000000042, -32.170000000000364, -32.40999999999987, -108.64, 13.879999999999981, -58.42000000000016, -66.33999999999915, -56.29000000000029, -24.129999999999708, 9.919999999999959, 2.0000000000000013, 113.0, -4.030000000000042, -4.030000000000042, 59.35999999999997, -2.020000000000042, -2.020000000000042, -32.170000000000336, -49.270000000000344, 93.08, 2.0000000000000013, -6.040000000000042, -27.340000000000014, -33.220000000000354, -10.060000000000041, 3.8599999999999604, 2.0000000000000013, -28.14999999999971, 17.84000000000003, 2.0000000000000013, -124.62999999999931, 12.88999999999996, -10.060000000000041, -20.10999999999995, -42.34000000000033, -196.99000000000038, -8.050000000000042, -18.819999999999865, 2.0000000000000013, -10.210000000000036, -14.080000000000041, -8.050000000000042, -2.020000000000042, 200.0, -0.00999999999999836, 57.20000000000003, 44.71999999999986, 2.0000000000000013, 0.740000000000272, 173.0, -68.52999999999926, 111.77, 131.3299999999997, 2.0000000000000013, 191.0, 111.89, -16.0899999999997, -6.040000000000042, -14.080000000000041, 51.4999999999997, -12.070000000000041, -37.24000000000004, 121.60999999999999, -4.030000000000042, -18.099999999999838, -136.6900000000012, -22.11999999999971, -12.070000000000041, -11.200000000000035, 5.959999999999958, 197.0, 1.9400000000000013, 200.0, -26.139999999999713, -26.13999999999972, -4.030000000000042, 2.0000000000000013, -24.159999999999712, -8.050000000000042, -104.52999999999926, -0.13000000000000678, -40.210000000000356, 2.0000000000000013, -19.179999999999715, -6.040000000000042, 53.05999999999979, 155.0, 5.4799999999999685, 17.510000000000236, 2.0000000000000013, -41.950000000000045, 128.0, -10.060000000000041, 72.26000000000013, 2.0000000000000013, -164.83000000000044, 2.0000000000000013, -10.060000000000041, 13.87999999999996, -38.20000000000036, 84.11000000000057, 167.0, 194.0, 123.50000000000026, -2.080000000000041, 179.0, 133.45999999999998, -72.36999999999917, -2.080000000000041, -4.030000000000042, 181.07, -23.83, -8.050000000000042, -2.020000000000042, -26.13999999999971, 35.66, 2.0000000000000013, -36.18999999999971, -164.8300000000006, 176.0, 146.0, -126.76000000000005, -2.409999999999698, 2.0000000000000013, 152.0, -22.119999999999724, 164.0, 161.0, 158.0, -12.070000000000041, -162.82000000000107, -78.39999999999918, -10.060000000000041, 171.29, 178.22, -16.0899999999997, 194.0, -20.58999999999978, 186.01999999999998, 147.28999999999974, 169.01, 161.18, -4.030000000000042, -10.0, 2.0000000000000013, -28.179999999999715, 123.02, -0.00999999999999836, -22.11999999999974, -114.76000000000005, -4.030000000000042, -16.0899999999997, -2.020000000000042, 101.75, 52.31, -14.080000000000041, -6.040000000000042, -28.14999999999971, -20.109999999999722, 14.50999999999997, 200.0, -51.940000000000055, 120.32, -4.630000000000273, -7.180000000000039, 146.26999999999978, 2.0000000000000013, 0.7400000000000012], "policy_predator_policy_reward": [0.0, 25.0, 3.0, 8.0, 28.0, 36.0, 17.0, 6.0, 8.0, 47.0, 1.0, 0.0, 14.0, 32.0, 27.0, 4.0, 0.0, 10.0, 33.0, 9.0, 2.0, 14.0, 16.0, 4.0, 3.0, 18.0, 13.0, 2.0, 10.0, 7.0, 3.0, 1.0, 5.0, 17.0, 51.0, 31.0, 42.0, 37.0, 25.0, 51.0, 13.0, 10.0, 18.0, 27.0, 3.0, 3.0, 2.0, 2.0, 2.0, 17.0, 26.0, 0.0, 4.0, 0.0, 0.0, 40.0, 6.0, 7.0, 9.0, 7.0, 27.0, 28.0, 53.0, 51.0, 5.0, 17.0, 83.0, 61.0, 31.0, 8.0, 0.0, 11.0, 8.0, 5.0, 0.0, 2.0, 29.0, 18.0, 2.0, 28.0, 9.0, 3.0, 13.0, 32.0, 0.0, 12.0, 0.0, 3.0, 9.0, 3.0, 8.0, 0.0, 6.0, 22.0, 1.0, 6.0, 3.0, 76.0, 5.0, 15.0, 9.0, 11.0, 0.0, 2.0, 14.0, 1.0, 3.0, 14.0, 14.0, 7.0, 5.0, 53.0, 17.0, 19.0, 13.0, 0.0, 4.0, 14.0, 17.0, 6.0, 3.0, 11.0, 79.0, 37.0, 31.0, 24.0, 76.0, 51.0, 6.0, 6.0, 0.0, 20.0, 11.0, 6.0, 9.0, 6.0, 8.0, 1.0, 2.0, 42.0, 4.0, 3.0, 27.0, 46.0, 5.0, 2.0, 14.0, 0.0, 11.0, 16.0, 8.0, 83.0, 101.0, 20.0, 42.0, 48.0, 24.0, 21.0, 23.0, 10.0, 13.0, 14.0, 82.0, 40.0, 4.0, 3.0, 9.0, 7.0, 13.0, 26.0, 8.0, 7.0, 10.0, 7.0, 70.0, 3.0, 9.0, 16.0, 25.0, 1.0, 41.0, 68.0, 3.0, 9.0, 2.0, 8.0, 9.0, 39.0, 4.0, 15.0, 15.0, 8.0, 29.0, 82.0, 8.0, 24.0, 9.0, 7.0, 7.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6859077849421444, "mean_inference_ms": 1.8163800757559216, "mean_action_processing_ms": 0.295705009301076, "mean_env_wait_ms": 0.22990675514787035, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038428306579589844, "StateBufferConnector_ms": 0.004365444183349609, "ViewRequirementAgentConnector_ms": 0.13047993183135986}, "num_episodes": 22, "episode_return_max": 358.0, "episode_return_min": -119.21999999999858, "episode_return_mean": 71.47700000000003, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.88626389205336, "num_env_steps_trained_throughput_per_sec": 295.88626389205336, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 11274.005, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11273.951, "sample_time_ms": 1510.226, "learn_time_ms": 9745.223, "learn_throughput": 410.457, "synch_weights_time_ms": 15.984}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "310e1_00000", "date": "2024-08-15_01-08-29", "timestamp": 1723664309, "time_this_iter_s": 13.616234064102173, "time_total_s": 664.0817408561707, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1968160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 664.0817408561707, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 76.49000000000001, "ram_util_percent": 83.83}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7137940113664305, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0558871356267776, "policy_loss": -0.00728548893522688, "vf_loss": 2.0624842971090285, "vf_explained_var": 0.024430095518707597, "kl": 0.009177650749064787, "entropy": 0.9237251512903385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.543836335057304, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.761659982217052, "policy_loss": -0.0071469659540092665, "vf_loss": 4.767235778122352, "vf_explained_var": 0.701017660249478, "kl": 0.02793204199614496, "entropy": 0.8863001745213908, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 358.0, "episode_reward_min": -119.21999999999858, "episode_reward_mean": 86.48949999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -196.99000000000038, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 101.0}, "policy_reward_mean": {"prey_policy": 25.964750000000013, "predator_policy": 17.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.459999999999695, -46.630000000000614, 8.78999999999992, 160.0, -2.060000000000084, 61.33999999999992, -15.18999999999959, 69.81000000000026, -0.04000000000004011, -20.560000000000002, 6.799999999999919, -10.150000000000082, 74.84000000000044, -7.740000000000066, -8.17000000000001, -95.3299999999992, 12.129999999999967, 2.7899999999999805, -9.130000000000082, 199.97999999999962, 104.19000000000021, 76.72000000000028, 185.74000000000007, 88.24000000000021, 145.32999999999953, 305.89000000000004, -10.130000000000082, 45.419999999999405, -21.310000000000063, 124.58000000000024, -75.78999999999871, -14.189999999999742, 14.75999999999992, 200.9399999999996, 188.85999999999973, -13.169999999999959, -1.1600000000000614, -54.5800000000006, -4.340000000000078, -4.180000000000081, 65.02000000000025, 183.4799999999998, 33.509999999999934, 202.05, 117.2000000000005, -35.83000000000005, 3.93999999999996, -4.320000000000078, 268.109999999999, 332.49999999999955, 185.91999999999976, 105.09000000000015, 0.8899999999999809, 230.24, -3.0700000000000838, 23.51999999999994, -7.190000000000017, 102.17000000000014, 140.2399999999999, 89.59000000000006, 174.87999999999985, 358.0, 172.9299999999999, -119.21999999999858, 168.22999999999993, 178.12999999999982, 212.4099999999995, 348.3099999999997, 347.19, 58.96999999999993, -1.1800000000000614, 149.01000000000013, -27.879999999999562, -8.120000000000083, 109.73000000000017, 86.23000000000006, -15.189999999999568, 17.40000000000019, 259.06, 147.69, 155.0899999999996, 18.740000000000407, 204.8699999999996, 161.95999999999998, 102.94000000000003, 104.63000000000014, 66.64999999999993, -5.210000000000081, -9.21000000000008, 112.94999999999999, 59.43999999999995, 8.719999999999922, 0.969999999999981, 277.76, -2.060000000000084, 209.89000000000007, 164.94999999999993, 179.90999999999974, 334.18, 154.38], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.879999999999981, -58.42000000000016, -66.33999999999915, -56.29000000000029, -24.129999999999708, 9.919999999999959, 2.0000000000000013, 113.0, -4.030000000000042, -4.030000000000042, 59.35999999999997, -2.020000000000042, -2.020000000000042, -32.170000000000336, -49.270000000000344, 93.08, 2.0000000000000013, -6.040000000000042, -27.340000000000014, -33.220000000000354, -10.060000000000041, 3.8599999999999604, 2.0000000000000013, -28.14999999999971, 17.84000000000003, 2.0000000000000013, -124.62999999999931, 12.88999999999996, -10.060000000000041, -20.10999999999995, -42.34000000000033, -196.99000000000038, -8.050000000000042, -18.819999999999865, 2.0000000000000013, -10.210000000000036, -14.080000000000041, -8.050000000000042, -2.020000000000042, 200.0, -0.00999999999999836, 57.20000000000003, 44.71999999999986, 2.0000000000000013, 0.740000000000272, 173.0, -68.52999999999926, 111.77, 131.3299999999997, 2.0000000000000013, 191.0, 111.89, -16.0899999999997, -6.040000000000042, -14.080000000000041, 51.4999999999997, -12.070000000000041, -37.24000000000004, 121.60999999999999, -4.030000000000042, -18.099999999999838, -136.6900000000012, -22.11999999999971, -12.070000000000041, -11.200000000000035, 5.959999999999958, 197.0, 1.9400000000000013, 200.0, -26.139999999999713, -26.13999999999972, -4.030000000000042, 2.0000000000000013, -24.159999999999712, -8.050000000000042, -104.52999999999926, -0.13000000000000678, -40.210000000000356, 2.0000000000000013, -19.179999999999715, -6.040000000000042, 53.05999999999979, 155.0, 5.4799999999999685, 17.510000000000236, 2.0000000000000013, -41.950000000000045, 128.0, -10.060000000000041, 72.26000000000013, 2.0000000000000013, -164.83000000000044, 2.0000000000000013, -10.060000000000041, 13.87999999999996, -38.20000000000036, 84.11000000000057, 167.0, 194.0, 123.50000000000026, -2.080000000000041, 179.0, 133.45999999999998, -72.36999999999917, -2.080000000000041, -4.030000000000042, 181.07, -23.83, -8.050000000000042, -2.020000000000042, -26.13999999999971, 35.66, 2.0000000000000013, -36.18999999999971, -164.8300000000006, 176.0, 146.0, -126.76000000000005, -2.409999999999698, 2.0000000000000013, 152.0, -22.119999999999724, 164.0, 161.0, 158.0, -12.070000000000041, -162.82000000000107, -78.39999999999918, -10.060000000000041, 171.29, 178.22, -16.0899999999997, 194.0, -20.58999999999978, 186.01999999999998, 147.28999999999974, 169.01, 161.18, -4.030000000000042, -10.0, 2.0000000000000013, -28.179999999999715, 123.02, -0.00999999999999836, -22.11999999999974, -114.76000000000005, -4.030000000000042, -16.0899999999997, -2.020000000000042, 101.75, 52.31, -14.080000000000041, -6.040000000000042, -28.14999999999971, -20.109999999999722, 14.50999999999997, 200.0, -51.940000000000055, 120.32, -4.630000000000273, -7.180000000000039, 146.26999999999978, 2.0000000000000013, 0.7400000000000012, -15.129999999999864, 200.0, 146.0, -6.040000000000042, -17.89, 84.83, -16.0899999999997, 95.72, 9.919999999999963, 1.7299999999999898, -14.170000000000039, -6.040000000000042, -6.040000000000042, -23.169999999999714, 156.23, -153.28000000000026, 2.0000000000000013, 57.44, -3.2500000000000373, -4.030000000000042, -2.020000000000042, -0.00999999999999836, 94.76, 146.0, -4.030000000000042, -4.030000000000042, 42.889999999999986, 116.0, 152.0, -8.050000000000042, 183.04999999999995, -26.139999999999752, 169.16, 141.02, 157.43, -8.050000000000042], "policy_predator_policy_reward": [42.0, 37.0, 25.0, 51.0, 13.0, 10.0, 18.0, 27.0, 3.0, 3.0, 2.0, 2.0, 2.0, 17.0, 26.0, 0.0, 4.0, 0.0, 0.0, 40.0, 6.0, 7.0, 9.0, 7.0, 27.0, 28.0, 53.0, 51.0, 5.0, 17.0, 83.0, 61.0, 31.0, 8.0, 0.0, 11.0, 8.0, 5.0, 0.0, 2.0, 29.0, 18.0, 2.0, 28.0, 9.0, 3.0, 13.0, 32.0, 0.0, 12.0, 0.0, 3.0, 9.0, 3.0, 8.0, 0.0, 6.0, 22.0, 1.0, 6.0, 3.0, 76.0, 5.0, 15.0, 9.0, 11.0, 0.0, 2.0, 14.0, 1.0, 3.0, 14.0, 14.0, 7.0, 5.0, 53.0, 17.0, 19.0, 13.0, 0.0, 4.0, 14.0, 17.0, 6.0, 3.0, 11.0, 79.0, 37.0, 31.0, 24.0, 76.0, 51.0, 6.0, 6.0, 0.0, 20.0, 11.0, 6.0, 9.0, 6.0, 8.0, 1.0, 2.0, 42.0, 4.0, 3.0, 27.0, 46.0, 5.0, 2.0, 14.0, 0.0, 11.0, 16.0, 8.0, 83.0, 101.0, 20.0, 42.0, 48.0, 24.0, 21.0, 23.0, 10.0, 13.0, 14.0, 82.0, 40.0, 4.0, 3.0, 9.0, 7.0, 13.0, 26.0, 8.0, 7.0, 10.0, 7.0, 70.0, 3.0, 9.0, 16.0, 25.0, 1.0, 41.0, 68.0, 3.0, 9.0, 2.0, 8.0, 9.0, 39.0, 4.0, 15.0, 15.0, 8.0, 29.0, 82.0, 8.0, 24.0, 9.0, 7.0, 7.0, 9.0, 10.0, 10.0, 22.0, 0.0, 13.0, 23.0, 10.0, 15.0, 31.0, 24.0, 4.0, 11.0, 15.0, 5.0, 20.0, 90.0, 0.0, 0.0, 6.0, 10.0, 2.0, 1.0, 28.0, 9.0, 3.0, 3.0, 14.0, 37.0, 16.0, 5.0, 6.0, 17.0, 13.0, 11.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6870626586411812, "mean_inference_ms": 1.8179313019155563, "mean_action_processing_ms": 0.29630632121694767, "mean_env_wait_ms": 0.22994792619115423, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004047751426696777, "StateBufferConnector_ms": 0.0044291019439697266, "ViewRequirementAgentConnector_ms": 0.11969292163848877}, "num_episodes": 18, "episode_return_max": 358.0, "episode_return_min": -119.21999999999858, "episode_return_mean": 86.48949999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.6290137535785, "num_env_steps_trained_throughput_per_sec": 298.6290137535785, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 11517.6, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11517.546, "sample_time_ms": 1594.786, "learn_time_ms": 9903.831, "learn_throughput": 403.884, "synch_weights_time_ms": 16.284}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "310e1_00000", "date": "2024-08-15_01-08-42", "timestamp": 1723664322, "time_this_iter_s": 13.432938814163208, "time_total_s": 677.5146796703339, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1967af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 677.5146796703339, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 79.01578947368421, "ram_util_percent": 82.35263157894738}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6814422404166882, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.452006191109854, "policy_loss": -0.006700433563027117, "vf_loss": 1.4580164819167405, "vf_explained_var": 0.0020646814946775082, "kl": 0.009201867493261956, "entropy": 0.8834586765400316, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4660564398324047, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.454357818951682, "policy_loss": -0.005224042818585913, "vf_loss": 4.458954234854885, "vf_explained_var": 0.7595401744993906, "kl": 0.007438608780106894, "entropy": 0.8672558428433838, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 358.0, "episode_reward_min": -119.21999999999858, "episode_reward_mean": 103.47419999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -164.8300000000006, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 101.0}, "policy_reward_mean": {"prey_policy": 35.19710000000002, "predator_policy": 16.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.24000000000021, 145.32999999999953, 305.89000000000004, -10.130000000000082, 45.419999999999405, -21.310000000000063, 124.58000000000024, -75.78999999999871, -14.189999999999742, 14.75999999999992, 200.9399999999996, 188.85999999999973, -13.169999999999959, -1.1600000000000614, -54.5800000000006, -4.340000000000078, -4.180000000000081, 65.02000000000025, 183.4799999999998, 33.509999999999934, 202.05, 117.2000000000005, -35.83000000000005, 3.93999999999996, -4.320000000000078, 268.109999999999, 332.49999999999955, 185.91999999999976, 105.09000000000015, 0.8899999999999809, 230.24, -3.0700000000000838, 23.51999999999994, -7.190000000000017, 102.17000000000014, 140.2399999999999, 89.59000000000006, 174.87999999999985, 358.0, 172.9299999999999, -119.21999999999858, 168.22999999999993, 178.12999999999982, 212.4099999999995, 348.3099999999997, 347.19, 58.96999999999993, -1.1800000000000614, 149.01000000000013, -27.879999999999562, -8.120000000000083, 109.73000000000017, 86.23000000000006, -15.189999999999568, 17.40000000000019, 259.06, 147.69, 155.0899999999996, 18.740000000000407, 204.8699999999996, 161.95999999999998, 102.94000000000003, 104.63000000000014, 66.64999999999993, -5.210000000000081, -9.21000000000008, 112.94999999999999, 59.43999999999995, 8.719999999999922, 0.969999999999981, 277.76, -2.060000000000084, 209.89000000000007, 164.94999999999993, 179.90999999999974, 334.18, 154.38, 269.45, 280.64, 0.8099999999999844, -10.170000000000082, -4.110000000000081, 15.84999999999992, 159.92, 89.04000000000005, 335.03, 147.42000000000007, 193.98999999999967, -0.160000000000041, -34.299999999999976, -9.130000000000082, -12.160000000000078, 128.75000000000017, 259.4, 140.08000000000018, 175.93999999999983, 152.97000000000008, 125.01000000000025, -34.300000000000736, 111.09000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-68.52999999999926, 111.77, 131.3299999999997, 2.0000000000000013, 191.0, 111.89, -16.0899999999997, -6.040000000000042, -14.080000000000041, 51.4999999999997, -12.070000000000041, -37.24000000000004, 121.60999999999999, -4.030000000000042, -18.099999999999838, -136.6900000000012, -22.11999999999971, -12.070000000000041, -11.200000000000035, 5.959999999999958, 197.0, 1.9400000000000013, 200.0, -26.139999999999713, -26.13999999999972, -4.030000000000042, 2.0000000000000013, -24.159999999999712, -8.050000000000042, -104.52999999999926, -0.13000000000000678, -40.210000000000356, 2.0000000000000013, -19.179999999999715, -6.040000000000042, 53.05999999999979, 155.0, 5.4799999999999685, 17.510000000000236, 2.0000000000000013, -41.950000000000045, 128.0, -10.060000000000041, 72.26000000000013, 2.0000000000000013, -164.83000000000044, 2.0000000000000013, -10.060000000000041, 13.87999999999996, -38.20000000000036, 84.11000000000057, 167.0, 194.0, 123.50000000000026, -2.080000000000041, 179.0, 133.45999999999998, -72.36999999999917, -2.080000000000041, -4.030000000000042, 181.07, -23.83, -8.050000000000042, -2.020000000000042, -26.13999999999971, 35.66, 2.0000000000000013, -36.18999999999971, -164.8300000000006, 176.0, 146.0, -126.76000000000005, -2.409999999999698, 2.0000000000000013, 152.0, -22.119999999999724, 164.0, 161.0, 158.0, -12.070000000000041, -162.82000000000107, -78.39999999999918, -10.060000000000041, 171.29, 178.22, -16.0899999999997, 194.0, -20.58999999999978, 186.01999999999998, 147.28999999999974, 169.01, 161.18, -4.030000000000042, -10.0, 2.0000000000000013, -28.179999999999715, 123.02, -0.00999999999999836, -22.11999999999974, -114.76000000000005, -4.030000000000042, -16.0899999999997, -2.020000000000042, 101.75, 52.31, -14.080000000000041, -6.040000000000042, -28.14999999999971, -20.109999999999722, 14.50999999999997, 200.0, -51.940000000000055, 120.32, -4.630000000000273, -7.180000000000039, 146.26999999999978, 2.0000000000000013, 0.7400000000000012, -15.129999999999864, 200.0, 146.0, -6.040000000000042, -17.89, 84.83, -16.0899999999997, 95.72, 9.919999999999963, 1.7299999999999898, -14.170000000000039, -6.040000000000042, -6.040000000000042, -23.169999999999714, 156.23, -153.28000000000026, 2.0000000000000013, 57.44, -3.2500000000000373, -4.030000000000042, -2.020000000000042, -0.00999999999999836, 94.76, 146.0, -4.030000000000042, -4.030000000000042, 42.889999999999986, 116.0, 152.0, -8.050000000000042, 183.04999999999995, -26.139999999999752, 169.16, 141.02, 157.43, -8.050000000000042, 131.0, 80.44999999999999, 173.0, 67.64, -36.19000000000036, 2.0000000000000013, -28.14999999999971, -2.020000000000042, -10.060000000000041, -8.050000000000042, 2.0000000000000013, 10.84999999999996, 127.12999999999997, 7.789999999999962, -0.00999999999999836, 84.04999999999998, 134.0, 167.03, 150.5, -14.080000000000041, 14.719999999999963, 173.26999999999998, -2.020000000000042, -8.14000000000004, -14.080000000000041, -105.22, -2.020000000000042, -20.109999999999705, 2.0000000000000013, -30.159999999999737, 26.750000000000274, -1.0, 87.34999999999994, 129.05, -25.239999999999725, 132.32, -10.060000000000041, 167.0, 0.9500000000000014, 126.02, 101.08999999999997, -14.080000000000041, -28.14999999999971, -28.14999999999971, -11.260000000000037, 99.34999999999994], "policy_predator_policy_reward": [13.0, 32.0, 0.0, 12.0, 0.0, 3.0, 9.0, 3.0, 8.0, 0.0, 6.0, 22.0, 1.0, 6.0, 3.0, 76.0, 5.0, 15.0, 9.0, 11.0, 0.0, 2.0, 14.0, 1.0, 3.0, 14.0, 14.0, 7.0, 5.0, 53.0, 17.0, 19.0, 13.0, 0.0, 4.0, 14.0, 17.0, 6.0, 3.0, 11.0, 79.0, 37.0, 31.0, 24.0, 76.0, 51.0, 6.0, 6.0, 0.0, 20.0, 11.0, 6.0, 9.0, 6.0, 8.0, 1.0, 2.0, 42.0, 4.0, 3.0, 27.0, 46.0, 5.0, 2.0, 14.0, 0.0, 11.0, 16.0, 8.0, 83.0, 101.0, 20.0, 42.0, 48.0, 24.0, 21.0, 23.0, 10.0, 13.0, 14.0, 82.0, 40.0, 4.0, 3.0, 9.0, 7.0, 13.0, 26.0, 8.0, 7.0, 10.0, 7.0, 70.0, 3.0, 9.0, 16.0, 25.0, 1.0, 41.0, 68.0, 3.0, 9.0, 2.0, 8.0, 9.0, 39.0, 4.0, 15.0, 15.0, 8.0, 29.0, 82.0, 8.0, 24.0, 9.0, 7.0, 7.0, 9.0, 10.0, 10.0, 22.0, 0.0, 13.0, 23.0, 10.0, 15.0, 31.0, 24.0, 4.0, 11.0, 15.0, 5.0, 20.0, 90.0, 0.0, 0.0, 6.0, 10.0, 2.0, 1.0, 28.0, 9.0, 3.0, 3.0, 14.0, 37.0, 16.0, 5.0, 6.0, 17.0, 13.0, 11.0, 5.0, 0.0, 31.0, 27.0, 11.0, 29.0, 19.0, 16.0, 5.0, 15.0, 5.0, 9.0, 2.0, 1.0, 20.0, 5.0, 1.0, 4.0, 19.0, 15.0, 6.0, 5.0, 1.0, 5.0, 8.0, 2.0, 9.0, 76.0, 2.0, 11.0, 1.0, 15.0, 58.0, 45.0, 13.0, 30.0, 17.0, 16.0, 3.0, 16.0, 23.0, 3.0, 19.0, 19.0, 7.0, 15.0, 0.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6874195478537368, "mean_inference_ms": 1.8191074131948972, "mean_action_processing_ms": 0.29620280114004655, "mean_env_wait_ms": 0.23010774182707422, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006096005439758301, "StateBufferConnector_ms": 0.003867030143737793, "ViewRequirementAgentConnector_ms": 0.13604295253753662}, "num_episodes": 23, "episode_return_max": 358.0, "episode_return_min": -119.21999999999858, "episode_return_mean": 103.47419999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.19235562419556, "num_env_steps_trained_throughput_per_sec": 357.19235562419556, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 11541.424, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11541.37, "sample_time_ms": 1606.492, "learn_time_ms": 9917.744, "learn_throughput": 403.318, "synch_weights_time_ms": 14.434}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "310e1_00000", "date": "2024-08-15_01-08-54", "timestamp": 1723664334, "time_this_iter_s": 11.251530170440674, "time_total_s": 688.7662098407745, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19c59d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 688.7662098407745, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 61.55625, "ram_util_percent": 83.6375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.407021231452624, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.488274199748165, "policy_loss": -0.008434611715366521, "vf_loss": 2.496014315930624, "vf_explained_var": 0.02416179445054796, "kl": 0.009259993985399229, "entropy": 0.8051980724095037, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8212992181538272, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.695537420681545, "policy_loss": -0.002032324190438779, "vf_loss": 4.697214052916834, "vf_explained_var": 0.6272942419089969, "kl": 0.0042155665647982685, "entropy": 0.8707054421699867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 358.0, "episode_reward_min": -119.21999999999858, "episode_reward_mean": 112.4365, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -231.16000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 36.973250000000014, "predator_policy": 19.245}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.4799999999998, 33.509999999999934, 202.05, 117.2000000000005, -35.83000000000005, 3.93999999999996, -4.320000000000078, 268.109999999999, 332.49999999999955, 185.91999999999976, 105.09000000000015, 0.8899999999999809, 230.24, -3.0700000000000838, 23.51999999999994, -7.190000000000017, 102.17000000000014, 140.2399999999999, 89.59000000000006, 174.87999999999985, 358.0, 172.9299999999999, -119.21999999999858, 168.22999999999993, 178.12999999999982, 212.4099999999995, 348.3099999999997, 347.19, 58.96999999999993, -1.1800000000000614, 149.01000000000013, -27.879999999999562, -8.120000000000083, 109.73000000000017, 86.23000000000006, -15.189999999999568, 17.40000000000019, 259.06, 147.69, 155.0899999999996, 18.740000000000407, 204.8699999999996, 161.95999999999998, 102.94000000000003, 104.63000000000014, 66.64999999999993, -5.210000000000081, -9.21000000000008, 112.94999999999999, 59.43999999999995, 8.719999999999922, 0.969999999999981, 277.76, -2.060000000000084, 209.89000000000007, 164.94999999999993, 179.90999999999974, 334.18, 154.38, 269.45, 280.64, 0.8099999999999844, -10.170000000000082, -4.110000000000081, 15.84999999999992, 159.92, 89.04000000000005, 335.03, 147.42000000000007, 193.98999999999967, -0.160000000000041, -34.299999999999976, -9.130000000000082, -12.160000000000078, 128.75000000000017, 259.4, 140.08000000000018, 175.93999999999983, 152.97000000000008, 125.01000000000025, -34.300000000000736, 111.09000000000009, -18.610000000000014, -29.329999999999472, 323.2, -5.930000000000039, 325.31, 122.93000000000028, 84.53000000000004, 191.99999999999972, -7.150000000000082, 53.970000000000304, 107.76000000000025, 122.15000000000036, 51.179999999999495, 155.36, 201.7399999999996, 83.94000000000008, 32.530000000000136, 80.84000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [155.0, 5.4799999999999685, 17.510000000000236, 2.0000000000000013, -41.950000000000045, 128.0, -10.060000000000041, 72.26000000000013, 2.0000000000000013, -164.83000000000044, 2.0000000000000013, -10.060000000000041, 13.87999999999996, -38.20000000000036, 84.11000000000057, 167.0, 194.0, 123.50000000000026, -2.080000000000041, 179.0, 133.45999999999998, -72.36999999999917, -2.080000000000041, -4.030000000000042, 181.07, -23.83, -8.050000000000042, -2.020000000000042, -26.13999999999971, 35.66, 2.0000000000000013, -36.18999999999971, -164.8300000000006, 176.0, 146.0, -126.76000000000005, -2.409999999999698, 2.0000000000000013, 152.0, -22.119999999999724, 164.0, 161.0, 158.0, -12.070000000000041, -162.82000000000107, -78.39999999999918, -10.060000000000041, 171.29, 178.22, -16.0899999999997, 194.0, -20.58999999999978, 186.01999999999998, 147.28999999999974, 169.01, 161.18, -4.030000000000042, -10.0, 2.0000000000000013, -28.179999999999715, 123.02, -0.00999999999999836, -22.11999999999974, -114.76000000000005, -4.030000000000042, -16.0899999999997, -2.020000000000042, 101.75, 52.31, -14.080000000000041, -6.040000000000042, -28.14999999999971, -20.109999999999722, 14.50999999999997, 200.0, -51.940000000000055, 120.32, -4.630000000000273, -7.180000000000039, 146.26999999999978, 2.0000000000000013, 0.7400000000000012, -15.129999999999864, 200.0, 146.0, -6.040000000000042, -17.89, 84.83, -16.0899999999997, 95.72, 9.919999999999963, 1.7299999999999898, -14.170000000000039, -6.040000000000042, -6.040000000000042, -23.169999999999714, 156.23, -153.28000000000026, 2.0000000000000013, 57.44, -3.2500000000000373, -4.030000000000042, -2.020000000000042, -0.00999999999999836, 94.76, 146.0, -4.030000000000042, -4.030000000000042, 42.889999999999986, 116.0, 152.0, -8.050000000000042, 183.04999999999995, -26.139999999999752, 169.16, 141.02, 157.43, -8.050000000000042, 131.0, 80.44999999999999, 173.0, 67.64, -36.19000000000036, 2.0000000000000013, -28.14999999999971, -2.020000000000042, -10.060000000000041, -8.050000000000042, 2.0000000000000013, 10.84999999999996, 127.12999999999997, 7.789999999999962, -0.00999999999999836, 84.04999999999998, 134.0, 167.03, 150.5, -14.080000000000041, 14.719999999999963, 173.26999999999998, -2.020000000000042, -8.14000000000004, -14.080000000000041, -105.22, -2.020000000000042, -20.109999999999705, 2.0000000000000013, -30.159999999999737, 26.750000000000274, -1.0, 87.34999999999994, 129.05, -25.239999999999725, 132.32, -10.060000000000041, 167.0, 0.9500000000000014, 126.02, 101.08999999999997, -14.080000000000041, -28.14999999999971, -28.14999999999971, -11.260000000000037, 99.34999999999994, -86.55999999999977, 6.949999999999959, -64.32999999999937, 2.0000000000000013, 139.01, 148.19, -71.86, -12.070000000000041, 58.31, 200.0, -20.109999999999705, 100.03999999999999, -149.47, 101.0, 176.0, 2.0000000000000013, -10.09000000000004, -10.060000000000041, 25.969999999999807, 2.0000000000000013, 2.0000000000000013, 85.76000000000022, -24.27999999999984, 112.43000000000006, -6.040000000000042, 40.21999999999976, -153.64000000000033, 185.0, 27.74000000000026, 161.0, 32.0, -10.060000000000041, -0.009999999999998581, -30.460000000000036, 194.0, -231.16000000000025], "policy_predator_policy_reward": [17.0, 6.0, 3.0, 11.0, 79.0, 37.0, 31.0, 24.0, 76.0, 51.0, 6.0, 6.0, 0.0, 20.0, 11.0, 6.0, 9.0, 6.0, 8.0, 1.0, 2.0, 42.0, 4.0, 3.0, 27.0, 46.0, 5.0, 2.0, 14.0, 0.0, 11.0, 16.0, 8.0, 83.0, 101.0, 20.0, 42.0, 48.0, 24.0, 21.0, 23.0, 10.0, 13.0, 14.0, 82.0, 40.0, 4.0, 3.0, 9.0, 7.0, 13.0, 26.0, 8.0, 7.0, 10.0, 7.0, 70.0, 3.0, 9.0, 16.0, 25.0, 1.0, 41.0, 68.0, 3.0, 9.0, 2.0, 8.0, 9.0, 39.0, 4.0, 15.0, 15.0, 8.0, 29.0, 82.0, 8.0, 24.0, 9.0, 7.0, 7.0, 9.0, 10.0, 10.0, 22.0, 0.0, 13.0, 23.0, 10.0, 15.0, 31.0, 24.0, 4.0, 11.0, 15.0, 5.0, 20.0, 90.0, 0.0, 0.0, 6.0, 10.0, 2.0, 1.0, 28.0, 9.0, 3.0, 3.0, 14.0, 37.0, 16.0, 5.0, 6.0, 17.0, 13.0, 11.0, 5.0, 0.0, 31.0, 27.0, 11.0, 29.0, 19.0, 16.0, 5.0, 15.0, 5.0, 9.0, 2.0, 1.0, 20.0, 5.0, 1.0, 4.0, 19.0, 15.0, 6.0, 5.0, 1.0, 5.0, 8.0, 2.0, 9.0, 76.0, 2.0, 11.0, 1.0, 15.0, 58.0, 45.0, 13.0, 30.0, 17.0, 16.0, 3.0, 16.0, 23.0, 3.0, 19.0, 19.0, 7.0, 15.0, 0.0, 23.0, 35.0, 26.0, 33.0, 0.0, 12.0, 24.0, 31.0, 47.0, 36.0, 31.0, 8.0, 35.0, 56.0, 77.0, 6.0, 8.0, 7.0, 6.0, 26.0, 0.0, 13.0, 7.0, 18.0, 16.0, 4.0, 13.0, 94.0, 30.0, 0.0, 13.0, 20.0, 42.0, 38.0, 25.0, 116.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6880055858016295, "mean_inference_ms": 1.8209372930770078, "mean_action_processing_ms": 0.2962591805615245, "mean_env_wait_ms": 0.23034840810852447, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006130576133728027, "StateBufferConnector_ms": 0.0038156509399414062, "ViewRequirementAgentConnector_ms": 0.1389232873916626}, "num_episodes": 18, "episode_return_max": 358.0, "episode_return_min": -119.21999999999858, "episode_return_mean": 112.4365, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.2523901112032, "num_env_steps_trained_throughput_per_sec": 351.2523901112032, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 11601.415, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11601.362, "sample_time_ms": 1612.402, "learn_time_ms": 9971.811, "learn_throughput": 401.131, "synch_weights_time_ms": 14.737}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "310e1_00000", "date": "2024-08-15_01-09-05", "timestamp": 1723664345, "time_this_iter_s": 11.438928842544556, "time_total_s": 700.2051386833191, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19c5790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 700.2051386833191, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 61.0375, "ram_util_percent": 83.73125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4722542449595437, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5855061859050124, "policy_loss": -0.0066261343925294505, "vf_loss": 3.5915844371079135, "vf_explained_var": 0.020288491942895153, "kl": 0.007305019479999898, "entropy": 0.8587866420152956, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.263460000419112, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.0010741148045454, "policy_loss": -0.004784508531903306, "vf_loss": 5.005187694862406, "vf_explained_var": 0.7955410261633535, "kl": 0.015903456416142804, "entropy": 0.7960468988569956, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 358.0, "episode_reward_min": -119.21999999999858, "episode_reward_mean": 109.0861, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -231.16000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 35.05805000000002, "predator_policy": 19.485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.59000000000006, 174.87999999999985, 358.0, 172.9299999999999, -119.21999999999858, 168.22999999999993, 178.12999999999982, 212.4099999999995, 348.3099999999997, 347.19, 58.96999999999993, -1.1800000000000614, 149.01000000000013, -27.879999999999562, -8.120000000000083, 109.73000000000017, 86.23000000000006, -15.189999999999568, 17.40000000000019, 259.06, 147.69, 155.0899999999996, 18.740000000000407, 204.8699999999996, 161.95999999999998, 102.94000000000003, 104.63000000000014, 66.64999999999993, -5.210000000000081, -9.21000000000008, 112.94999999999999, 59.43999999999995, 8.719999999999922, 0.969999999999981, 277.76, -2.060000000000084, 209.89000000000007, 164.94999999999993, 179.90999999999974, 334.18, 154.38, 269.45, 280.64, 0.8099999999999844, -10.170000000000082, -4.110000000000081, 15.84999999999992, 159.92, 89.04000000000005, 335.03, 147.42000000000007, 193.98999999999967, -0.160000000000041, -34.299999999999976, -9.130000000000082, -12.160000000000078, 128.75000000000017, 259.4, 140.08000000000018, 175.93999999999983, 152.97000000000008, 125.01000000000025, -34.300000000000736, 111.09000000000009, -18.610000000000014, -29.329999999999472, 323.2, -5.930000000000039, 325.31, 122.93000000000028, 84.53000000000004, 191.99999999999972, -7.150000000000082, 53.970000000000304, 107.76000000000025, 122.15000000000036, 51.179999999999495, 155.36, 201.7399999999996, 83.94000000000008, 32.530000000000136, 80.84000000000005, 64.01999999999997, 135.2200000000002, 139.51000000000016, 3.769999999999959, -11.25000000000008, 165.67999999999995, 1.9500000000000028, 4.829999999999928, 102.33000000000014, -41.65000000000006, -6.140000000000082, 221.79000000000002, 119.65000000000022, 139.17000000000002, 213.5199999999998, 188.94999999999976, -0.06000000000004011, 102.12000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-2.409999999999698, 2.0000000000000013, 152.0, -22.119999999999724, 164.0, 161.0, 158.0, -12.070000000000041, -162.82000000000107, -78.39999999999918, -10.060000000000041, 171.29, 178.22, -16.0899999999997, 194.0, -20.58999999999978, 186.01999999999998, 147.28999999999974, 169.01, 161.18, -4.030000000000042, -10.0, 2.0000000000000013, -28.179999999999715, 123.02, -0.00999999999999836, -22.11999999999974, -114.76000000000005, -4.030000000000042, -16.0899999999997, -2.020000000000042, 101.75, 52.31, -14.080000000000041, -6.040000000000042, -28.14999999999971, -20.109999999999722, 14.50999999999997, 200.0, -51.940000000000055, 120.32, -4.630000000000273, -7.180000000000039, 146.26999999999978, 2.0000000000000013, 0.7400000000000012, -15.129999999999864, 200.0, 146.0, -6.040000000000042, -17.89, 84.83, -16.0899999999997, 95.72, 9.919999999999963, 1.7299999999999898, -14.170000000000039, -6.040000000000042, -6.040000000000042, -23.169999999999714, 156.23, -153.28000000000026, 2.0000000000000013, 57.44, -3.2500000000000373, -4.030000000000042, -2.020000000000042, -0.00999999999999836, 94.76, 146.0, -4.030000000000042, -4.030000000000042, 42.889999999999986, 116.0, 152.0, -8.050000000000042, 183.04999999999995, -26.139999999999752, 169.16, 141.02, 157.43, -8.050000000000042, 131.0, 80.44999999999999, 173.0, 67.64, -36.19000000000036, 2.0000000000000013, -28.14999999999971, -2.020000000000042, -10.060000000000041, -8.050000000000042, 2.0000000000000013, 10.84999999999996, 127.12999999999997, 7.789999999999962, -0.00999999999999836, 84.04999999999998, 134.0, 167.03, 150.5, -14.080000000000041, 14.719999999999963, 173.26999999999998, -2.020000000000042, -8.14000000000004, -14.080000000000041, -105.22, -2.020000000000042, -20.109999999999705, 2.0000000000000013, -30.159999999999737, 26.750000000000274, -1.0, 87.34999999999994, 129.05, -25.239999999999725, 132.32, -10.060000000000041, 167.0, 0.9500000000000014, 126.02, 101.08999999999997, -14.080000000000041, -28.14999999999971, -28.14999999999971, -11.260000000000037, 99.34999999999994, -86.55999999999977, 6.949999999999959, -64.32999999999937, 2.0000000000000013, 139.01, 148.19, -71.86, -12.070000000000041, 58.31, 200.0, -20.109999999999705, 100.03999999999999, -149.47, 101.0, 176.0, 2.0000000000000013, -10.09000000000004, -10.060000000000041, 25.969999999999807, 2.0000000000000013, 2.0000000000000013, 85.76000000000022, -24.27999999999984, 112.43000000000006, -6.040000000000042, 40.21999999999976, -153.64000000000033, 185.0, 27.74000000000026, 161.0, 32.0, -10.060000000000041, -0.009999999999998581, -30.460000000000036, 194.0, -231.16000000000025, -51.97, -0.00999999999999836, 2.0000000000000013, 97.22000000000003, -16.0899999999997, 140.6, -0.00999999999999836, -12.220000000000034, -19.179999999999715, -12.070000000000041, -14.71, 110.38999999999993, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -146.17000000000002, -22.119999999999706, 86.45, -22.119999999999706, -104.52999999999977, -22.119999999999706, -2.020000000000042, 112.34, 62.44999999999993, -12.070000000000041, 122.71999999999998, -58.11999999999989, 123.28999999999999, 151.2199999999998, -3.6999999999998465, -8.050000000000042, 182.0, -10.060000000000041, 2.0000000000000013, 58.16, -6.040000000000042], "policy_predator_policy_reward": [42.0, 48.0, 24.0, 21.0, 23.0, 10.0, 13.0, 14.0, 82.0, 40.0, 4.0, 3.0, 9.0, 7.0, 13.0, 26.0, 8.0, 7.0, 10.0, 7.0, 70.0, 3.0, 9.0, 16.0, 25.0, 1.0, 41.0, 68.0, 3.0, 9.0, 2.0, 8.0, 9.0, 39.0, 4.0, 15.0, 15.0, 8.0, 29.0, 82.0, 8.0, 24.0, 9.0, 7.0, 7.0, 9.0, 10.0, 10.0, 22.0, 0.0, 13.0, 23.0, 10.0, 15.0, 31.0, 24.0, 4.0, 11.0, 15.0, 5.0, 20.0, 90.0, 0.0, 0.0, 6.0, 10.0, 2.0, 1.0, 28.0, 9.0, 3.0, 3.0, 14.0, 37.0, 16.0, 5.0, 6.0, 17.0, 13.0, 11.0, 5.0, 0.0, 31.0, 27.0, 11.0, 29.0, 19.0, 16.0, 5.0, 15.0, 5.0, 9.0, 2.0, 1.0, 20.0, 5.0, 1.0, 4.0, 19.0, 15.0, 6.0, 5.0, 1.0, 5.0, 8.0, 2.0, 9.0, 76.0, 2.0, 11.0, 1.0, 15.0, 58.0, 45.0, 13.0, 30.0, 17.0, 16.0, 3.0, 16.0, 23.0, 3.0, 19.0, 19.0, 7.0, 15.0, 0.0, 23.0, 35.0, 26.0, 33.0, 0.0, 12.0, 24.0, 31.0, 47.0, 36.0, 31.0, 8.0, 35.0, 56.0, 77.0, 6.0, 8.0, 7.0, 6.0, 26.0, 0.0, 13.0, 7.0, 18.0, 16.0, 4.0, 13.0, 94.0, 30.0, 0.0, 13.0, 20.0, 42.0, 38.0, 25.0, 116.0, 2.0, 50.0, 66.0, 24.0, 12.0, 9.0, 6.0, 12.0, 4.0, 14.0, 6.0, 42.0, 28.0, 3.0, 5.0, 81.0, 68.0, 16.0, 22.0, 23.0, 62.0, 6.0, 12.0, 45.0, 2.0, 7.0, 2.0, 43.0, 31.0, 58.0, 8.0, 11.0, 4.0, 6.0, 2.0, 29.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.688601725474754, "mean_inference_ms": 1.8227210956739455, "mean_action_processing_ms": 0.2963450857315596, "mean_env_wait_ms": 0.23062951135305432, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0060503482818603516, "StateBufferConnector_ms": 0.006691932678222656, "ViewRequirementAgentConnector_ms": 0.14172756671905518}, "num_episodes": 18, "episode_return_max": 358.0, "episode_return_min": -119.21999999999858, "episode_return_mean": 109.0861, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.41168718207734, "num_env_steps_trained_throughput_per_sec": 349.41168718207734, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 11623.799, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11623.747, "sample_time_ms": 1560.405, "learn_time_ms": 10047.353, "learn_throughput": 398.115, "synch_weights_time_ms": 13.517}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "310e1_00000", "date": "2024-08-15_01-09-17", "timestamp": 1723664357, "time_this_iter_s": 11.488554954528809, "time_total_s": 711.6936936378479, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12d9700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 711.6936936378479, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 60.69375, "ram_util_percent": 83.6625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.640332832995546, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1699035122911767, "policy_loss": -0.0067775109065844425, "vf_loss": 2.176026125622805, "vf_explained_var": 0.038164958405116245, "kl": 0.00873207269591312, "entropy": 0.7810003450307896, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.942546179764485, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.253212566098208, "policy_loss": -0.0029096607322109834, "vf_loss": 5.255864363751083, "vf_explained_var": 0.5593242410314146, "kl": 0.006112284065475734, "entropy": 0.7857840134037866, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 335.03, "episode_reward_min": -199.26999999999936, "episode_reward_mean": 102.02520000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -231.16000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 31.35260000000001, "predator_policy": 19.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.740000000000407, 204.8699999999996, 161.95999999999998, 102.94000000000003, 104.63000000000014, 66.64999999999993, -5.210000000000081, -9.21000000000008, 112.94999999999999, 59.43999999999995, 8.719999999999922, 0.969999999999981, 277.76, -2.060000000000084, 209.89000000000007, 164.94999999999993, 179.90999999999974, 334.18, 154.38, 269.45, 280.64, 0.8099999999999844, -10.170000000000082, -4.110000000000081, 15.84999999999992, 159.92, 89.04000000000005, 335.03, 147.42000000000007, 193.98999999999967, -0.160000000000041, -34.299999999999976, -9.130000000000082, -12.160000000000078, 128.75000000000017, 259.4, 140.08000000000018, 175.93999999999983, 152.97000000000008, 125.01000000000025, -34.300000000000736, 111.09000000000009, -18.610000000000014, -29.329999999999472, 323.2, -5.930000000000039, 325.31, 122.93000000000028, 84.53000000000004, 191.99999999999972, -7.150000000000082, 53.970000000000304, 107.76000000000025, 122.15000000000036, 51.179999999999495, 155.36, 201.7399999999996, 83.94000000000008, 32.530000000000136, 80.84000000000005, 64.01999999999997, 135.2200000000002, 139.51000000000016, 3.769999999999959, -11.25000000000008, 165.67999999999995, 1.9500000000000028, 4.829999999999928, 102.33000000000014, -41.65000000000006, -6.140000000000082, 221.79000000000002, 119.65000000000022, 139.17000000000002, 213.5199999999998, 188.94999999999976, -0.06000000000004011, 102.12000000000016, 13.129999999999942, 117.91000000000021, 161.1, 117.41000000000025, 87.41000000000025, -199.26999999999936, 120.9300000000003, -40.50000000000046, 80.09, 1.900000000000003, -82.02999999999908, -0.04000000000004011, 153.06000000000006, 97.81000000000012, 217.0900000000002, 236.78000000000003, 212.39000000000019, 261.34000000000026, 223.9400000000001, 177.8299999999998, 194.15000000000015, 2.739999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, 0.7400000000000012, -15.129999999999864, 200.0, 146.0, -6.040000000000042, -17.89, 84.83, -16.0899999999997, 95.72, 9.919999999999963, 1.7299999999999898, -14.170000000000039, -6.040000000000042, -6.040000000000042, -23.169999999999714, 156.23, -153.28000000000026, 2.0000000000000013, 57.44, -3.2500000000000373, -4.030000000000042, -2.020000000000042, -0.00999999999999836, 94.76, 146.0, -4.030000000000042, -4.030000000000042, 42.889999999999986, 116.0, 152.0, -8.050000000000042, 183.04999999999995, -26.139999999999752, 169.16, 141.02, 157.43, -8.050000000000042, 131.0, 80.44999999999999, 173.0, 67.64, -36.19000000000036, 2.0000000000000013, -28.14999999999971, -2.020000000000042, -10.060000000000041, -8.050000000000042, 2.0000000000000013, 10.84999999999996, 127.12999999999997, 7.789999999999962, -0.00999999999999836, 84.04999999999998, 134.0, 167.03, 150.5, -14.080000000000041, 14.719999999999963, 173.26999999999998, -2.020000000000042, -8.14000000000004, -14.080000000000041, -105.22, -2.020000000000042, -20.109999999999705, 2.0000000000000013, -30.159999999999737, 26.750000000000274, -1.0, 87.34999999999994, 129.05, -25.239999999999725, 132.32, -10.060000000000041, 167.0, 0.9500000000000014, 126.02, 101.08999999999997, -14.080000000000041, -28.14999999999971, -28.14999999999971, -11.260000000000037, 99.34999999999994, -86.55999999999977, 6.949999999999959, -64.32999999999937, 2.0000000000000013, 139.01, 148.19, -71.86, -12.070000000000041, 58.31, 200.0, -20.109999999999705, 100.03999999999999, -149.47, 101.0, 176.0, 2.0000000000000013, -10.09000000000004, -10.060000000000041, 25.969999999999807, 2.0000000000000013, 2.0000000000000013, 85.76000000000022, -24.27999999999984, 112.43000000000006, -6.040000000000042, 40.21999999999976, -153.64000000000033, 185.0, 27.74000000000026, 161.0, 32.0, -10.060000000000041, -0.009999999999998581, -30.460000000000036, 194.0, -231.16000000000025, -51.97, -0.00999999999999836, 2.0000000000000013, 97.22000000000003, -16.0899999999997, 140.6, -0.00999999999999836, -12.220000000000034, -19.179999999999715, -12.070000000000041, -14.71, 110.38999999999993, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -146.17000000000002, -22.119999999999706, 86.45, -22.119999999999706, -104.52999999999977, -22.119999999999706, -2.020000000000042, 112.34, 62.44999999999993, -12.070000000000041, 122.71999999999998, -58.11999999999989, 123.28999999999999, 151.2199999999998, -3.6999999999998465, -8.050000000000042, 182.0, -10.060000000000041, 2.0000000000000013, 58.16, -6.040000000000042, -31.78, -16.0899999999997, -94.47999999999955, 161.39, 2.0000000000000013, 118.1, 38.5099999999997, 56.900000000000006, 52.429999999999914, -2.020000000000042, -145.03, -217.2399999999996, 89.0, -12.070000000000041, 2.0000000000000013, -98.49999999999936, 71.08999999999997, 2.0000000000000013, 5.959999999999958, -10.060000000000041, -188.95000000000078, 9.919999999999959, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 119.05999999999999, 2.0000000000000013, 83.81000000000012, 200.0, -45.91, 122.78, 53.0, 99.07999999999998, 76.30999999999995, 187.01, 68.33, 194.0, -31.060000000000002, 185.0, -32.170000000000314, 70.81999999999998, 83.32999999999996, -8.050000000000042, -13.210000000000033], "policy_predator_policy_reward": [7.0, 9.0, 10.0, 10.0, 22.0, 0.0, 13.0, 23.0, 10.0, 15.0, 31.0, 24.0, 4.0, 11.0, 15.0, 5.0, 20.0, 90.0, 0.0, 0.0, 6.0, 10.0, 2.0, 1.0, 28.0, 9.0, 3.0, 3.0, 14.0, 37.0, 16.0, 5.0, 6.0, 17.0, 13.0, 11.0, 5.0, 0.0, 31.0, 27.0, 11.0, 29.0, 19.0, 16.0, 5.0, 15.0, 5.0, 9.0, 2.0, 1.0, 20.0, 5.0, 1.0, 4.0, 19.0, 15.0, 6.0, 5.0, 1.0, 5.0, 8.0, 2.0, 9.0, 76.0, 2.0, 11.0, 1.0, 15.0, 58.0, 45.0, 13.0, 30.0, 17.0, 16.0, 3.0, 16.0, 23.0, 3.0, 19.0, 19.0, 7.0, 15.0, 0.0, 23.0, 35.0, 26.0, 33.0, 0.0, 12.0, 24.0, 31.0, 47.0, 36.0, 31.0, 8.0, 35.0, 56.0, 77.0, 6.0, 8.0, 7.0, 6.0, 26.0, 0.0, 13.0, 7.0, 18.0, 16.0, 4.0, 13.0, 94.0, 30.0, 0.0, 13.0, 20.0, 42.0, 38.0, 25.0, 116.0, 2.0, 50.0, 66.0, 24.0, 12.0, 9.0, 6.0, 12.0, 4.0, 14.0, 6.0, 42.0, 28.0, 3.0, 5.0, 81.0, 68.0, 16.0, 22.0, 23.0, 62.0, 6.0, 12.0, 45.0, 2.0, 7.0, 2.0, 43.0, 31.0, 58.0, 8.0, 11.0, 4.0, 6.0, 2.0, 29.0, 21.0, 21.0, 40.0, 6.0, 45.0, 23.0, 18.0, 5.0, 17.0, 2.0, 35.0, 47.0, 116.0, 36.0, 8.0, 32.0, 24.0, 0.0, 7.0, 0.0, 6.0, 95.0, 2.0, 4.0, 0.0, 15.0, 17.0, 1.0, 11.0, 27.0, 36.0, 19.0, 42.0, 6.0, 31.0, 2.0, 4.0, 42.0, 19.0, 5.0, 20.0, 20.0, 20.0, 12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6895283615397244, "mean_inference_ms": 1.824928713656394, "mean_action_processing_ms": 0.2965081365635261, "mean_env_wait_ms": 0.23097045600583307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00806570053100586, "StateBufferConnector_ms": 0.007331728935241699, "ViewRequirementAgentConnector_ms": 0.1523967981338501}, "num_episodes": 22, "episode_return_max": 335.03, "episode_return_min": -199.26999999999936, "episode_return_mean": 102.02520000000003, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.5789025553573, "num_env_steps_trained_throughput_per_sec": 364.5789025553573, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 11596.304, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11596.255, "sample_time_ms": 1497.826, "learn_time_ms": 10082.599, "learn_throughput": 396.723, "synch_weights_time_ms": 13.466}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "310e1_00000", "date": "2024-08-15_01-09-28", "timestamp": 1723664368, "time_this_iter_s": 11.010414838790894, "time_total_s": 722.7041084766388, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14cf160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 722.7041084766388, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 61.36875, "ram_util_percent": 83.23750000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1229214827535015, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4006135374149946, "policy_loss": -0.0027642018658173067, "vf_loss": 2.4029573806379205, "vf_explained_var": 0.08957885935823753, "kl": 0.005604794297554517, "entropy": 0.756565562631718, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.6115712286303285, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.025910952482274, "policy_loss": -0.010045773885828793, "vf_loss": 6.034916808617809, "vf_explained_var": 0.7271119405037512, "kl": 0.024650082017222893, "entropy": 0.7550393388384864, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 386.0799999999999, "episode_reward_min": -199.26999999999936, "episode_reward_mean": 100.38960000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -275.38000000000056, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 130.0}, "policy_reward_mean": {"prey_policy": 28.509800000000013, "predator_policy": 21.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.110000000000081, 15.84999999999992, 159.92, 89.04000000000005, 335.03, 147.42000000000007, 193.98999999999967, -0.160000000000041, -34.299999999999976, -9.130000000000082, -12.160000000000078, 128.75000000000017, 259.4, 140.08000000000018, 175.93999999999983, 152.97000000000008, 125.01000000000025, -34.300000000000736, 111.09000000000009, -18.610000000000014, -29.329999999999472, 323.2, -5.930000000000039, 325.31, 122.93000000000028, 84.53000000000004, 191.99999999999972, -7.150000000000082, 53.970000000000304, 107.76000000000025, 122.15000000000036, 51.179999999999495, 155.36, 201.7399999999996, 83.94000000000008, 32.530000000000136, 80.84000000000005, 64.01999999999997, 135.2200000000002, 139.51000000000016, 3.769999999999959, -11.25000000000008, 165.67999999999995, 1.9500000000000028, 4.829999999999928, 102.33000000000014, -41.65000000000006, -6.140000000000082, 221.79000000000002, 119.65000000000022, 139.17000000000002, 213.5199999999998, 188.94999999999976, -0.06000000000004011, 102.12000000000016, 13.129999999999942, 117.91000000000021, 161.1, 117.41000000000025, 87.41000000000025, -199.26999999999936, 120.9300000000003, -40.50000000000046, 80.09, 1.900000000000003, -82.02999999999908, -0.04000000000004011, 153.06000000000006, 97.81000000000012, 217.0900000000002, 236.78000000000003, 212.39000000000019, 261.34000000000026, 223.9400000000001, 177.8299999999998, 194.15000000000015, 2.739999999999982, 66.03000000000029, 131.45000000000022, 219.25999999999928, 140.7300000000002, 102.08000000000011, 121.94000000000028, -1.1100000000000632, 159.68, 76.95000000000002, -28.329999999999714, 10.569999999999924, -20.159999999999652, 283.0, 132.49999999999994, 12.86999999999992, 145.68000000000018, -71.37999999999923, 131.56000000000023, -30.050000000000384, 46.38999999999993, 161.66, 386.0799999999999, 346.2299999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, -8.050000000000042, 2.0000000000000013, 10.84999999999996, 127.12999999999997, 7.789999999999962, -0.00999999999999836, 84.04999999999998, 134.0, 167.03, 150.5, -14.080000000000041, 14.719999999999963, 173.26999999999998, -2.020000000000042, -8.14000000000004, -14.080000000000041, -105.22, -2.020000000000042, -20.109999999999705, 2.0000000000000013, -30.159999999999737, 26.750000000000274, -1.0, 87.34999999999994, 129.05, -25.239999999999725, 132.32, -10.060000000000041, 167.0, 0.9500000000000014, 126.02, 101.08999999999997, -14.080000000000041, -28.14999999999971, -28.14999999999971, -11.260000000000037, 99.34999999999994, -86.55999999999977, 6.949999999999959, -64.32999999999937, 2.0000000000000013, 139.01, 148.19, -71.86, -12.070000000000041, 58.31, 200.0, -20.109999999999705, 100.03999999999999, -149.47, 101.0, 176.0, 2.0000000000000013, -10.09000000000004, -10.060000000000041, 25.969999999999807, 2.0000000000000013, 2.0000000000000013, 85.76000000000022, -24.27999999999984, 112.43000000000006, -6.040000000000042, 40.21999999999976, -153.64000000000033, 185.0, 27.74000000000026, 161.0, 32.0, -10.060000000000041, -0.009999999999998581, -30.460000000000036, 194.0, -231.16000000000025, -51.97, -0.00999999999999836, 2.0000000000000013, 97.22000000000003, -16.0899999999997, 140.6, -0.00999999999999836, -12.220000000000034, -19.179999999999715, -12.070000000000041, -14.71, 110.38999999999993, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -146.17000000000002, -22.119999999999706, 86.45, -22.119999999999706, -104.52999999999977, -22.119999999999706, -2.020000000000042, 112.34, 62.44999999999993, -12.070000000000041, 122.71999999999998, -58.11999999999989, 123.28999999999999, 151.2199999999998, -3.6999999999998465, -8.050000000000042, 182.0, -10.060000000000041, 2.0000000000000013, 58.16, -6.040000000000042, -31.78, -16.0899999999997, -94.47999999999955, 161.39, 2.0000000000000013, 118.1, 38.5099999999997, 56.900000000000006, 52.429999999999914, -2.020000000000042, -145.03, -217.2399999999996, 89.0, -12.070000000000041, 2.0000000000000013, -98.49999999999936, 71.08999999999997, 2.0000000000000013, 5.959999999999958, -10.060000000000041, -188.95000000000078, 9.919999999999959, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 119.05999999999999, 2.0000000000000013, 83.81000000000012, 200.0, -45.91, 122.78, 53.0, 99.07999999999998, 76.30999999999995, 187.01, 68.33, 194.0, -31.060000000000002, 185.0, -32.170000000000314, 70.81999999999998, 83.32999999999996, -8.050000000000042, -13.210000000000033, -4.030000000000042, 50.05999999999999, 2.0000000000000013, 113.45000000000007, 125.0, 66.26000000000057, -52.27000000000034, 149.0, -182.92000000000036, 176.0, 89.0, -10.060000000000041, -16.0899999999997, -2.020000000000042, 185.0, -62.320000000000135, -8.050000000000042, 20.0, 2.0000000000000013, -64.32999999999966, -34.180000000000334, 26.750000000000274, 2.8399999999999825, -142.0, 143.0, 110.0, 15.85999999999996, 106.64000000000016, 2.0000000000000013, 5.86999999999996, 92.0, -41.32000000000005, -275.38000000000056, 2.0000000000000013, 2.0000000000000013, 108.56000000000009, -88.44999999999936, -10.60000000000003, 37.39999999999997, -0.00999999999999836, 5.659999999999966, 104.0, 194.0, 189.07999999999993, 145.06999999999994, 184.15999999999985], "policy_predator_policy_reward": [5.0, 9.0, 2.0, 1.0, 20.0, 5.0, 1.0, 4.0, 19.0, 15.0, 6.0, 5.0, 1.0, 5.0, 8.0, 2.0, 9.0, 76.0, 2.0, 11.0, 1.0, 15.0, 58.0, 45.0, 13.0, 30.0, 17.0, 16.0, 3.0, 16.0, 23.0, 3.0, 19.0, 19.0, 7.0, 15.0, 0.0, 23.0, 35.0, 26.0, 33.0, 0.0, 12.0, 24.0, 31.0, 47.0, 36.0, 31.0, 8.0, 35.0, 56.0, 77.0, 6.0, 8.0, 7.0, 6.0, 26.0, 0.0, 13.0, 7.0, 18.0, 16.0, 4.0, 13.0, 94.0, 30.0, 0.0, 13.0, 20.0, 42.0, 38.0, 25.0, 116.0, 2.0, 50.0, 66.0, 24.0, 12.0, 9.0, 6.0, 12.0, 4.0, 14.0, 6.0, 42.0, 28.0, 3.0, 5.0, 81.0, 68.0, 16.0, 22.0, 23.0, 62.0, 6.0, 12.0, 45.0, 2.0, 7.0, 2.0, 43.0, 31.0, 58.0, 8.0, 11.0, 4.0, 6.0, 2.0, 29.0, 21.0, 21.0, 40.0, 6.0, 45.0, 23.0, 18.0, 5.0, 17.0, 2.0, 35.0, 47.0, 116.0, 36.0, 8.0, 32.0, 24.0, 0.0, 7.0, 0.0, 6.0, 95.0, 2.0, 4.0, 0.0, 15.0, 17.0, 1.0, 11.0, 27.0, 36.0, 19.0, 42.0, 6.0, 31.0, 2.0, 4.0, 42.0, 19.0, 5.0, 20.0, 20.0, 20.0, 12.0, 12.0, 6.0, 14.0, 14.0, 2.0, 10.0, 18.0, 17.0, 27.0, 92.0, 17.0, 30.0, 13.0, 9.0, 8.0, 5.0, 32.0, 59.0, 6.0, 32.0, 2.0, 0.0, 18.0, 114.0, 5.0, 0.0, 30.0, 0.0, 10.0, 2.0, 3.0, 46.0, 49.0, 130.0, 72.0, 12.0, 9.0, 24.0, 45.0, 1.0, 8.0, 18.0, 34.0, 2.0, 1.0, 12.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6890544613148328, "mean_inference_ms": 1.8212176798638842, "mean_action_processing_ms": 0.2964019650995421, "mean_env_wait_ms": 0.23075096328169092, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00670015811920166, "StateBufferConnector_ms": 0.007173418998718262, "ViewRequirementAgentConnector_ms": 0.1350853443145752}, "num_episodes": 23, "episode_return_max": 386.0799999999999, "episode_return_min": -199.26999999999936, "episode_return_mean": 100.38960000000004, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.9446762987597, "num_env_steps_trained_throughput_per_sec": 365.9446762987597, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 11573.463, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11573.414, "sample_time_ms": 1419.848, "learn_time_ms": 10137.405, "learn_throughput": 394.578, "synch_weights_time_ms": 13.548}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "310e1_00000", "date": "2024-08-15_01-09-39", "timestamp": 1723664379, "time_this_iter_s": 10.970672130584717, "time_total_s": 733.6747806072235, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a1d5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 733.6747806072235, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 60.54666666666667, "ram_util_percent": 83.36666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.369222832829864, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6697200748024796, "policy_loss": -0.007335141583508442, "vf_loss": 2.6764018426496516, "vf_explained_var": 0.04843523685263578, "kl": 0.008711742687381887, "entropy": 0.790220954683092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9806798349297234, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.723623309059748, "policy_loss": -0.0026427041245230213, "vf_loss": 5.726049648012434, "vf_explained_var": 0.6224833113175852, "kl": 0.003419036586995981, "entropy": 0.6792538849922715, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 386.0799999999999, "episode_reward_min": -199.26999999999936, "episode_reward_mean": 99.26110000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -275.38000000000056, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 130.0}, "policy_reward_mean": {"prey_policy": 24.76055, "predator_policy": 24.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [111.09000000000009, -18.610000000000014, -29.329999999999472, 323.2, -5.930000000000039, 325.31, 122.93000000000028, 84.53000000000004, 191.99999999999972, -7.150000000000082, 53.970000000000304, 107.76000000000025, 122.15000000000036, 51.179999999999495, 155.36, 201.7399999999996, 83.94000000000008, 32.530000000000136, 80.84000000000005, 64.01999999999997, 135.2200000000002, 139.51000000000016, 3.769999999999959, -11.25000000000008, 165.67999999999995, 1.9500000000000028, 4.829999999999928, 102.33000000000014, -41.65000000000006, -6.140000000000082, 221.79000000000002, 119.65000000000022, 139.17000000000002, 213.5199999999998, 188.94999999999976, -0.06000000000004011, 102.12000000000016, 13.129999999999942, 117.91000000000021, 161.1, 117.41000000000025, 87.41000000000025, -199.26999999999936, 120.9300000000003, -40.50000000000046, 80.09, 1.900000000000003, -82.02999999999908, -0.04000000000004011, 153.06000000000006, 97.81000000000012, 217.0900000000002, 236.78000000000003, 212.39000000000019, 261.34000000000026, 223.9400000000001, 177.8299999999998, 194.15000000000015, 2.739999999999982, 66.03000000000029, 131.45000000000022, 219.25999999999928, 140.7300000000002, 102.08000000000011, 121.94000000000028, -1.1100000000000632, 159.68, 76.95000000000002, -28.329999999999714, 10.569999999999924, -20.159999999999652, 283.0, 132.49999999999994, 12.86999999999992, 145.68000000000018, -71.37999999999923, 131.56000000000023, -30.050000000000384, 46.38999999999993, 161.66, 386.0799999999999, 346.2299999999998, 104.4100000000002, 50.47999999999981, 49.489999999999434, -18.420000000000528, 46.23999999999982, 8.119999999999976, 9.789999999999926, 287.0, -43.83000000000048, 186.11999999999978, 206.38, 193.71999999999963, -7.120000000000083, 98.00000000000017, 108.27000000000002, 269.48, 12.929999999999618, 155.32999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.260000000000037, 99.34999999999994, -86.55999999999977, 6.949999999999959, -64.32999999999937, 2.0000000000000013, 139.01, 148.19, -71.86, -12.070000000000041, 58.31, 200.0, -20.109999999999705, 100.03999999999999, -149.47, 101.0, 176.0, 2.0000000000000013, -10.09000000000004, -10.060000000000041, 25.969999999999807, 2.0000000000000013, 2.0000000000000013, 85.76000000000022, -24.27999999999984, 112.43000000000006, -6.040000000000042, 40.21999999999976, -153.64000000000033, 185.0, 27.74000000000026, 161.0, 32.0, -10.060000000000041, -0.009999999999998581, -30.460000000000036, 194.0, -231.16000000000025, -51.97, -0.00999999999999836, 2.0000000000000013, 97.22000000000003, -16.0899999999997, 140.6, -0.00999999999999836, -12.220000000000034, -19.179999999999715, -12.070000000000041, -14.71, 110.38999999999993, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -146.17000000000002, -22.119999999999706, 86.45, -22.119999999999706, -104.52999999999977, -22.119999999999706, -2.020000000000042, 112.34, 62.44999999999993, -12.070000000000041, 122.71999999999998, -58.11999999999989, 123.28999999999999, 151.2199999999998, -3.6999999999998465, -8.050000000000042, 182.0, -10.060000000000041, 2.0000000000000013, 58.16, -6.040000000000042, -31.78, -16.0899999999997, -94.47999999999955, 161.39, 2.0000000000000013, 118.1, 38.5099999999997, 56.900000000000006, 52.429999999999914, -2.020000000000042, -145.03, -217.2399999999996, 89.0, -12.070000000000041, 2.0000000000000013, -98.49999999999936, 71.08999999999997, 2.0000000000000013, 5.959999999999958, -10.060000000000041, -188.95000000000078, 9.919999999999959, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 119.05999999999999, 2.0000000000000013, 83.81000000000012, 200.0, -45.91, 122.78, 53.0, 99.07999999999998, 76.30999999999995, 187.01, 68.33, 194.0, -31.060000000000002, 185.0, -32.170000000000314, 70.81999999999998, 83.32999999999996, -8.050000000000042, -13.210000000000033, -4.030000000000042, 50.05999999999999, 2.0000000000000013, 113.45000000000007, 125.0, 66.26000000000057, -52.27000000000034, 149.0, -182.92000000000036, 176.0, 89.0, -10.060000000000041, -16.0899999999997, -2.020000000000042, 185.0, -62.320000000000135, -8.050000000000042, 20.0, 2.0000000000000013, -64.32999999999966, -34.180000000000334, 26.750000000000274, 2.8399999999999825, -142.0, 143.0, 110.0, 15.85999999999996, 106.64000000000016, 2.0000000000000013, 5.86999999999996, 92.0, -41.32000000000005, -275.38000000000056, 2.0000000000000013, 2.0000000000000013, 108.56000000000009, -88.44999999999936, -10.60000000000003, 37.39999999999997, -0.00999999999999836, 5.659999999999966, 104.0, 194.0, 189.07999999999993, 145.06999999999994, 184.15999999999985, 34.2500000000001, -10.840000000000018, 2.509999999999989, -4.030000000000042, 37.48999999999971, 2.0000000000000013, -94.42000000000053, -25.0, -40.57000000000036, 20.81000000000028, 11.509999999999991, -85.39000000000001, -1.2100000000000206, 2.0000000000000013, 95.0, 86.0, -164.83000000000106, 2.0000000000000013, 2.0000000000000013, 182.12, 164.0, -89.62, 170.0, 5.719999999999963, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -13.0, -24.760000000000048, -0.9699999999999989, 152.0, 92.47999999999993, -46.05999999999952, -0.00999999999999836, -4.030000000000042, 134.36], "policy_predator_policy_reward": [0.0, 23.0, 35.0, 26.0, 33.0, 0.0, 12.0, 24.0, 31.0, 47.0, 36.0, 31.0, 8.0, 35.0, 56.0, 77.0, 6.0, 8.0, 7.0, 6.0, 26.0, 0.0, 13.0, 7.0, 18.0, 16.0, 4.0, 13.0, 94.0, 30.0, 0.0, 13.0, 20.0, 42.0, 38.0, 25.0, 116.0, 2.0, 50.0, 66.0, 24.0, 12.0, 9.0, 6.0, 12.0, 4.0, 14.0, 6.0, 42.0, 28.0, 3.0, 5.0, 81.0, 68.0, 16.0, 22.0, 23.0, 62.0, 6.0, 12.0, 45.0, 2.0, 7.0, 2.0, 43.0, 31.0, 58.0, 8.0, 11.0, 4.0, 6.0, 2.0, 29.0, 21.0, 21.0, 40.0, 6.0, 45.0, 23.0, 18.0, 5.0, 17.0, 2.0, 35.0, 47.0, 116.0, 36.0, 8.0, 32.0, 24.0, 0.0, 7.0, 0.0, 6.0, 95.0, 2.0, 4.0, 0.0, 15.0, 17.0, 1.0, 11.0, 27.0, 36.0, 19.0, 42.0, 6.0, 31.0, 2.0, 4.0, 42.0, 19.0, 5.0, 20.0, 20.0, 20.0, 12.0, 12.0, 6.0, 14.0, 14.0, 2.0, 10.0, 18.0, 17.0, 27.0, 92.0, 17.0, 30.0, 13.0, 9.0, 8.0, 5.0, 32.0, 59.0, 6.0, 32.0, 2.0, 0.0, 18.0, 114.0, 5.0, 0.0, 30.0, 0.0, 10.0, 2.0, 3.0, 46.0, 49.0, 130.0, 72.0, 12.0, 9.0, 24.0, 45.0, 1.0, 8.0, 18.0, 34.0, 2.0, 1.0, 12.0, 5.0, 40.0, 41.0, 3.0, 49.0, 5.0, 5.0, 84.0, 17.0, 0.0, 66.0, 45.0, 37.0, 8.0, 1.0, 53.0, 53.0, 83.0, 36.0, 2.0, 0.0, 63.0, 69.0, 12.0, 6.0, 7.0, 6.0, 71.0, 38.0, 63.0, 71.0, 0.0, 25.0, 50.0, 9.0, 13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.687734799227726, "mean_inference_ms": 1.819539098935885, "mean_action_processing_ms": 0.29526103356483324, "mean_env_wait_ms": 0.23036509350279252, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005621671676635742, "StateBufferConnector_ms": 0.0071305036544799805, "ViewRequirementAgentConnector_ms": 0.11406111717224121}, "num_episodes": 18, "episode_return_max": 386.0799999999999, "episode_return_min": -199.26999999999936, "episode_return_mean": 99.26110000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.0601018836546, "num_env_steps_trained_throughput_per_sec": 373.0601018836546, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 11535.086, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11535.037, "sample_time_ms": 1370.083, "learn_time_ms": 10148.754, "learn_throughput": 394.137, "synch_weights_time_ms": 13.592}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "310e1_00000", "date": "2024-08-15_01-09-50", "timestamp": 1723664390, "time_this_iter_s": 10.77211618423462, "time_total_s": 744.4468967914581, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b194edc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 744.4468967914581, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 57.15333333333333, "ram_util_percent": 83.12666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4328096239182053, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.08932116649769, "policy_loss": -0.00526867314222116, "vf_loss": 2.094138033490963, "vf_explained_var": 0.0460638303605337, "kl": 0.006024067209110493, "entropy": 0.7710927788227323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7889853758155985, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.951445146086355, "policy_loss": -0.001506428061319249, "vf_loss": 5.952181812821242, "vf_explained_var": 0.7684663680810777, "kl": 0.02432848689878091, "entropy": 0.6349264233200639, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 386.0799999999999, "episode_reward_min": -199.26999999999936, "episode_reward_mean": 103.45900000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -275.38000000000056, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 130.0}, "policy_reward_mean": {"prey_policy": 26.394500000000004, "predator_policy": 25.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.84000000000005, 64.01999999999997, 135.2200000000002, 139.51000000000016, 3.769999999999959, -11.25000000000008, 165.67999999999995, 1.9500000000000028, 4.829999999999928, 102.33000000000014, -41.65000000000006, -6.140000000000082, 221.79000000000002, 119.65000000000022, 139.17000000000002, 213.5199999999998, 188.94999999999976, -0.06000000000004011, 102.12000000000016, 13.129999999999942, 117.91000000000021, 161.1, 117.41000000000025, 87.41000000000025, -199.26999999999936, 120.9300000000003, -40.50000000000046, 80.09, 1.900000000000003, -82.02999999999908, -0.04000000000004011, 153.06000000000006, 97.81000000000012, 217.0900000000002, 236.78000000000003, 212.39000000000019, 261.34000000000026, 223.9400000000001, 177.8299999999998, 194.15000000000015, 2.739999999999982, 66.03000000000029, 131.45000000000022, 219.25999999999928, 140.7300000000002, 102.08000000000011, 121.94000000000028, -1.1100000000000632, 159.68, 76.95000000000002, -28.329999999999714, 10.569999999999924, -20.159999999999652, 283.0, 132.49999999999994, 12.86999999999992, 145.68000000000018, -71.37999999999923, 131.56000000000023, -30.050000000000384, 46.38999999999993, 161.66, 386.0799999999999, 346.2299999999998, 104.4100000000002, 50.47999999999981, 49.489999999999434, -18.420000000000528, 46.23999999999982, 8.119999999999976, 9.789999999999926, 287.0, -43.83000000000048, 186.11999999999978, 206.38, 193.71999999999963, -7.120000000000083, 98.00000000000017, 108.27000000000002, 269.48, 12.929999999999618, 155.32999999999987, 224.58000000000004, 386.0, 140.0000000000001, -122.02999999999906, 287.02, 213.10000000000002, 59.63999999999995, 90.19000000000015, 169.9999999999999, 32.179999999999964, 138.8500000000002, 333.0, 187.95999999999975, -15.1899999999996, -44.02999999999965, 3.85999999999996, 58.329999999999984, 182.99999999999977], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [194.0, -231.16000000000025, -51.97, -0.00999999999999836, 2.0000000000000013, 97.22000000000003, -16.0899999999997, 140.6, -0.00999999999999836, -12.220000000000034, -19.179999999999715, -12.070000000000041, -14.71, 110.38999999999993, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -146.17000000000002, -22.119999999999706, 86.45, -22.119999999999706, -104.52999999999977, -22.119999999999706, -2.020000000000042, 112.34, 62.44999999999993, -12.070000000000041, 122.71999999999998, -58.11999999999989, 123.28999999999999, 151.2199999999998, -3.6999999999998465, -8.050000000000042, 182.0, -10.060000000000041, 2.0000000000000013, 58.16, -6.040000000000042, -31.78, -16.0899999999997, -94.47999999999955, 161.39, 2.0000000000000013, 118.1, 38.5099999999997, 56.900000000000006, 52.429999999999914, -2.020000000000042, -145.03, -217.2399999999996, 89.0, -12.070000000000041, 2.0000000000000013, -98.49999999999936, 71.08999999999997, 2.0000000000000013, 5.959999999999958, -10.060000000000041, -188.95000000000078, 9.919999999999959, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 119.05999999999999, 2.0000000000000013, 83.81000000000012, 200.0, -45.91, 122.78, 53.0, 99.07999999999998, 76.30999999999995, 187.01, 68.33, 194.0, -31.060000000000002, 185.0, -32.170000000000314, 70.81999999999998, 83.32999999999996, -8.050000000000042, -13.210000000000033, -4.030000000000042, 50.05999999999999, 2.0000000000000013, 113.45000000000007, 125.0, 66.26000000000057, -52.27000000000034, 149.0, -182.92000000000036, 176.0, 89.0, -10.060000000000041, -16.0899999999997, -2.020000000000042, 185.0, -62.320000000000135, -8.050000000000042, 20.0, 2.0000000000000013, -64.32999999999966, -34.180000000000334, 26.750000000000274, 2.8399999999999825, -142.0, 143.0, 110.0, 15.85999999999996, 106.64000000000016, 2.0000000000000013, 5.86999999999996, 92.0, -41.32000000000005, -275.38000000000056, 2.0000000000000013, 2.0000000000000013, 108.56000000000009, -88.44999999999936, -10.60000000000003, 37.39999999999997, -0.00999999999999836, 5.659999999999966, 104.0, 194.0, 189.07999999999993, 145.06999999999994, 184.15999999999985, 34.2500000000001, -10.840000000000018, 2.509999999999989, -4.030000000000042, 37.48999999999971, 2.0000000000000013, -94.42000000000053, -25.0, -40.57000000000036, 20.81000000000028, 11.509999999999991, -85.39000000000001, -1.2100000000000206, 2.0000000000000013, 95.0, 86.0, -164.83000000000106, 2.0000000000000013, 2.0000000000000013, 182.12, 164.0, -89.62, 170.0, 5.719999999999963, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -13.0, -24.760000000000048, -0.9699999999999989, 152.0, 92.47999999999993, -46.05999999999952, -0.00999999999999836, -4.030000000000042, 134.36, -53.46999999999997, 186.05, 182.0, 194.0, 107.0, 2.0000000000000013, -88.44999999999979, -114.57999999999947, 120.02, 119.0, 91.93999999999998, 88.16, 2.0000000000000013, -46.36, -12.759999999999998, -8.050000000000042, 2.0000000000000013, 152.0, -26.13999999999971, 3.3200000000000003, 104.0, -4.150000000000039, 155.0, 152.0, 185.0, -6.040000000000042, -28.14999999999971, -6.040000000000042, -4.030000000000042, -196.0, -3.13000000000004, -0.00999999999999836, -132.6699999999999, 86.0, 170.0, 2.0000000000000013], "policy_predator_policy_reward": [116.0, 2.0, 50.0, 66.0, 24.0, 12.0, 9.0, 6.0, 12.0, 4.0, 14.0, 6.0, 42.0, 28.0, 3.0, 5.0, 81.0, 68.0, 16.0, 22.0, 23.0, 62.0, 6.0, 12.0, 45.0, 2.0, 7.0, 2.0, 43.0, 31.0, 58.0, 8.0, 11.0, 4.0, 6.0, 2.0, 29.0, 21.0, 21.0, 40.0, 6.0, 45.0, 23.0, 18.0, 5.0, 17.0, 2.0, 35.0, 47.0, 116.0, 36.0, 8.0, 32.0, 24.0, 0.0, 7.0, 0.0, 6.0, 95.0, 2.0, 4.0, 0.0, 15.0, 17.0, 1.0, 11.0, 27.0, 36.0, 19.0, 42.0, 6.0, 31.0, 2.0, 4.0, 42.0, 19.0, 5.0, 20.0, 20.0, 20.0, 12.0, 12.0, 6.0, 14.0, 14.0, 2.0, 10.0, 18.0, 17.0, 27.0, 92.0, 17.0, 30.0, 13.0, 9.0, 8.0, 5.0, 32.0, 59.0, 6.0, 32.0, 2.0, 0.0, 18.0, 114.0, 5.0, 0.0, 30.0, 0.0, 10.0, 2.0, 3.0, 46.0, 49.0, 130.0, 72.0, 12.0, 9.0, 24.0, 45.0, 1.0, 8.0, 18.0, 34.0, 2.0, 1.0, 12.0, 5.0, 40.0, 41.0, 3.0, 49.0, 5.0, 5.0, 84.0, 17.0, 0.0, 66.0, 45.0, 37.0, 8.0, 1.0, 53.0, 53.0, 83.0, 36.0, 2.0, 0.0, 63.0, 69.0, 12.0, 6.0, 7.0, 6.0, 71.0, 38.0, 63.0, 71.0, 0.0, 25.0, 50.0, 9.0, 13.0, 12.0, 58.0, 34.0, 4.0, 6.0, 0.0, 31.0, 5.0, 76.0, 20.0, 28.0, 1.0, 32.0, 54.0, 50.0, 65.0, 46.0, 4.0, 12.0, 31.0, 24.0, 6.0, 33.0, 16.0, 10.0, 5.0, 4.0, 15.0, 4.0, 127.0, 29.0, 6.0, 1.0, 102.0, 3.0, 10.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6865350576849424, "mean_inference_ms": 1.8160520426334035, "mean_action_processing_ms": 0.29457302164621557, "mean_env_wait_ms": 0.2299466638678658, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005623459815979004, "StateBufferConnector_ms": 0.007636666297912598, "ViewRequirementAgentConnector_ms": 0.10800838470458984}, "num_episodes": 18, "episode_return_max": 386.0799999999999, "episode_return_min": -199.26999999999936, "episode_return_mean": 103.45900000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.95214961814406, "num_env_steps_trained_throughput_per_sec": 364.95214961814406, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 11536.627, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11536.578, "sample_time_ms": 1376.812, "learn_time_ms": 10143.32, "learn_throughput": 394.348, "synch_weights_time_ms": 13.712}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "310e1_00000", "date": "2024-08-15_01-10-01", "timestamp": 1723664401, "time_this_iter_s": 11.008875608444214, "time_total_s": 755.4557723999023, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14cf160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 755.4557723999023, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 56.356249999999996, "ram_util_percent": 82.76875000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8363885502651256, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1612512649051725, "policy_loss": -0.00529997957175568, "vf_loss": 2.1659013060665635, "vf_explained_var": 0.22952907006576578, "kl": 0.008665818805397144, "entropy": 0.7434849668116796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.374679653606718, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.325681679337113, "policy_loss": -0.003281430451189557, "vf_loss": 6.328700480133137, "vf_explained_var": 0.4681369305287719, "kl": 0.005533571011849154, "entropy": 0.5642754785440586, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 398.01, "episode_reward_min": -199.26999999999936, "episode_reward_mean": 122.04029999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -275.38000000000056, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 130.0}, "policy_reward_mean": {"prey_policy": 36.380149999999986, "predator_policy": 24.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [117.41000000000025, 87.41000000000025, -199.26999999999936, 120.9300000000003, -40.50000000000046, 80.09, 1.900000000000003, -82.02999999999908, -0.04000000000004011, 153.06000000000006, 97.81000000000012, 217.0900000000002, 236.78000000000003, 212.39000000000019, 261.34000000000026, 223.9400000000001, 177.8299999999998, 194.15000000000015, 2.739999999999982, 66.03000000000029, 131.45000000000022, 219.25999999999928, 140.7300000000002, 102.08000000000011, 121.94000000000028, -1.1100000000000632, 159.68, 76.95000000000002, -28.329999999999714, 10.569999999999924, -20.159999999999652, 283.0, 132.49999999999994, 12.86999999999992, 145.68000000000018, -71.37999999999923, 131.56000000000023, -30.050000000000384, 46.38999999999993, 161.66, 386.0799999999999, 346.2299999999998, 104.4100000000002, 50.47999999999981, 49.489999999999434, -18.420000000000528, 46.23999999999982, 8.119999999999976, 9.789999999999926, 287.0, -43.83000000000048, 186.11999999999978, 206.38, 193.71999999999963, -7.120000000000083, 98.00000000000017, 108.27000000000002, 269.48, 12.929999999999618, 155.32999999999987, 224.58000000000004, 386.0, 140.0000000000001, -122.02999999999906, 287.02, 213.10000000000002, 59.63999999999995, 90.19000000000015, 169.9999999999999, 32.179999999999964, 138.8500000000002, 333.0, 187.95999999999975, -15.1899999999996, -44.02999999999965, 3.85999999999996, 58.329999999999984, 182.99999999999977, 263.6599999999998, 278.0, 398.01, 133.4600000000002, 233.57999999999925, 231.57999999999916, 382.0, -176.2300000000007, 106.24999999999989, 323.41, 276.54999999999995, 40.67999999999979, 240.41999999999962, 25.66000000000056, 302.36, 183.23000000000036, 236.24999999999906, 167.38000000000002, 159.0, 33.59999999999993, 116.00000000000041, -180.3300000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [38.5099999999997, 56.900000000000006, 52.429999999999914, -2.020000000000042, -145.03, -217.2399999999996, 89.0, -12.070000000000041, 2.0000000000000013, -98.49999999999936, 71.08999999999997, 2.0000000000000013, 5.959999999999958, -10.060000000000041, -188.95000000000078, 9.919999999999959, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 119.05999999999999, 2.0000000000000013, 83.81000000000012, 200.0, -45.91, 122.78, 53.0, 99.07999999999998, 76.30999999999995, 187.01, 68.33, 194.0, -31.060000000000002, 185.0, -32.170000000000314, 70.81999999999998, 83.32999999999996, -8.050000000000042, -13.210000000000033, -4.030000000000042, 50.05999999999999, 2.0000000000000013, 113.45000000000007, 125.0, 66.26000000000057, -52.27000000000034, 149.0, -182.92000000000036, 176.0, 89.0, -10.060000000000041, -16.0899999999997, -2.020000000000042, 185.0, -62.320000000000135, -8.050000000000042, 20.0, 2.0000000000000013, -64.32999999999966, -34.180000000000334, 26.750000000000274, 2.8399999999999825, -142.0, 143.0, 110.0, 15.85999999999996, 106.64000000000016, 2.0000000000000013, 5.86999999999996, 92.0, -41.32000000000005, -275.38000000000056, 2.0000000000000013, 2.0000000000000013, 108.56000000000009, -88.44999999999936, -10.60000000000003, 37.39999999999997, -0.00999999999999836, 5.659999999999966, 104.0, 194.0, 189.07999999999993, 145.06999999999994, 184.15999999999985, 34.2500000000001, -10.840000000000018, 2.509999999999989, -4.030000000000042, 37.48999999999971, 2.0000000000000013, -94.42000000000053, -25.0, -40.57000000000036, 20.81000000000028, 11.509999999999991, -85.39000000000001, -1.2100000000000206, 2.0000000000000013, 95.0, 86.0, -164.83000000000106, 2.0000000000000013, 2.0000000000000013, 182.12, 164.0, -89.62, 170.0, 5.719999999999963, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -13.0, -24.760000000000048, -0.9699999999999989, 152.0, 92.47999999999993, -46.05999999999952, -0.00999999999999836, -4.030000000000042, 134.36, -53.46999999999997, 186.05, 182.0, 194.0, 107.0, 2.0000000000000013, -88.44999999999979, -114.57999999999947, 120.02, 119.0, 91.93999999999998, 88.16, 2.0000000000000013, -46.36, -12.759999999999998, -8.050000000000042, 2.0000000000000013, 152.0, -26.13999999999971, 3.3200000000000003, 104.0, -4.150000000000039, 155.0, 152.0, 185.0, -6.040000000000042, -28.14999999999971, -6.040000000000042, -4.030000000000042, -196.0, -3.13000000000004, -0.00999999999999836, -132.6699999999999, 86.0, 170.0, 2.0000000000000013, 158.4199999999998, 53.24000000000002, 65.0, 164.0, 200.0, 196.01, 2.0000000000000013, 109.46000000000006, 200.0, 28.580000000000236, 187.01, 38.5699999999998, 167.0, 200.0, -203.2300000000007, -103.0, -55.0, 76.25, 132.41000000000008, 173.0, 149.18000000000004, 94.37, -18.099999999999753, 14.77999999999998, 146.41999999999962, -13.0, 11.86999999999996, 7.789999999999962, 176.21, 95.15, -31.869999999999422, 136.0999999999999, 173.0, 49.24999999999977, 120.11000000000006, -21.730000000000132, 2.0000000000000013, 125.0, 2.0000000000000013, 14.599999999999968, 65.0, 2.0000000000000013, -121.0, -166.33000000000058], "policy_predator_policy_reward": [5.0, 17.0, 2.0, 35.0, 47.0, 116.0, 36.0, 8.0, 32.0, 24.0, 0.0, 7.0, 0.0, 6.0, 95.0, 2.0, 4.0, 0.0, 15.0, 17.0, 1.0, 11.0, 27.0, 36.0, 19.0, 42.0, 6.0, 31.0, 2.0, 4.0, 42.0, 19.0, 5.0, 20.0, 20.0, 20.0, 12.0, 12.0, 6.0, 14.0, 14.0, 2.0, 10.0, 18.0, 17.0, 27.0, 92.0, 17.0, 30.0, 13.0, 9.0, 8.0, 5.0, 32.0, 59.0, 6.0, 32.0, 2.0, 0.0, 18.0, 114.0, 5.0, 0.0, 30.0, 0.0, 10.0, 2.0, 3.0, 46.0, 49.0, 130.0, 72.0, 12.0, 9.0, 24.0, 45.0, 1.0, 8.0, 18.0, 34.0, 2.0, 1.0, 12.0, 5.0, 40.0, 41.0, 3.0, 49.0, 5.0, 5.0, 84.0, 17.0, 0.0, 66.0, 45.0, 37.0, 8.0, 1.0, 53.0, 53.0, 83.0, 36.0, 2.0, 0.0, 63.0, 69.0, 12.0, 6.0, 7.0, 6.0, 71.0, 38.0, 63.0, 71.0, 0.0, 25.0, 50.0, 9.0, 13.0, 12.0, 58.0, 34.0, 4.0, 6.0, 0.0, 31.0, 5.0, 76.0, 20.0, 28.0, 1.0, 32.0, 54.0, 50.0, 65.0, 46.0, 4.0, 12.0, 31.0, 24.0, 6.0, 33.0, 16.0, 10.0, 5.0, 4.0, 15.0, 4.0, 127.0, 29.0, 6.0, 1.0, 102.0, 3.0, 10.0, 1.0, 32.0, 20.0, 4.0, 45.0, 1.0, 1.0, 7.0, 15.0, 5.0, 0.0, 2.0, 4.0, 11.0, 4.0, 21.0, 109.0, 85.0, 0.0, 9.0, 9.0, 0.0, 33.0, 42.0, 2.0, 51.0, 56.0, 4.0, 2.0, 9.0, 22.0, 23.0, 56.0, 13.0, 1.0, 40.0, 29.0, 25.0, 7.0, 9.0, 8.0, 35.0, 14.0, 107.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6850531810091883, "mean_inference_ms": 1.8116362793528311, "mean_action_processing_ms": 0.29322169081965277, "mean_env_wait_ms": 0.22954175201662977, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005966663360595703, "StateBufferConnector_ms": 0.0045233964920043945, "ViewRequirementAgentConnector_ms": 0.11659157276153564}, "num_episodes": 22, "episode_return_max": 398.01, "episode_return_min": -199.26999999999936, "episode_return_mean": 122.04029999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.8657330092347, "num_env_steps_trained_throughput_per_sec": 364.8657330092347, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 11549.5, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11549.451, "sample_time_ms": 1378.533, "learn_time_ms": 10154.184, "learn_throughput": 393.926, "synch_weights_time_ms": 13.789}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "310e1_00000", "date": "2024-08-15_01-10-12", "timestamp": 1723664412, "time_this_iter_s": 11.023702144622803, "time_total_s": 766.4794745445251, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a1d940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 766.4794745445251, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 55.50625, "ram_util_percent": 83.04374999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8229183934353017, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.765389032086367, "policy_loss": -0.001691281067443982, "vf_loss": 3.766740556368752, "vf_explained_var": 0.15928094746574523, "kl": 0.0045301566421837676, "entropy": 0.5933607945839564, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4736946333337713, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.559682071272028, "policy_loss": -0.0007938643111773427, "vf_loss": 5.560187380149881, "vf_explained_var": 0.07186639245855746, "kl": 0.006079571896963135, "entropy": 0.7239385477764897, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 398.01, "episode_reward_min": -201.03000000000037, "episode_reward_mean": 119.38159999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 31.33579999999998, "predator_policy": 28.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.739999999999982, 66.03000000000029, 131.45000000000022, 219.25999999999928, 140.7300000000002, 102.08000000000011, 121.94000000000028, -1.1100000000000632, 159.68, 76.95000000000002, -28.329999999999714, 10.569999999999924, -20.159999999999652, 283.0, 132.49999999999994, 12.86999999999992, 145.68000000000018, -71.37999999999923, 131.56000000000023, -30.050000000000384, 46.38999999999993, 161.66, 386.0799999999999, 346.2299999999998, 104.4100000000002, 50.47999999999981, 49.489999999999434, -18.420000000000528, 46.23999999999982, 8.119999999999976, 9.789999999999926, 287.0, -43.83000000000048, 186.11999999999978, 206.38, 193.71999999999963, -7.120000000000083, 98.00000000000017, 108.27000000000002, 269.48, 12.929999999999618, 155.32999999999987, 224.58000000000004, 386.0, 140.0000000000001, -122.02999999999906, 287.02, 213.10000000000002, 59.63999999999995, 90.19000000000015, 169.9999999999999, 32.179999999999964, 138.8500000000002, 333.0, 187.95999999999975, -15.1899999999996, -44.02999999999965, 3.85999999999996, 58.329999999999984, 182.99999999999977, 263.6599999999998, 278.0, 398.01, 133.4600000000002, 233.57999999999925, 231.57999999999916, 382.0, -176.2300000000007, 106.24999999999989, 323.41, 276.54999999999995, 40.67999999999979, 240.41999999999962, 25.66000000000056, 302.36, 183.23000000000036, 236.24999999999906, 167.38000000000002, 159.0, 33.59999999999993, 116.00000000000041, -180.3300000000006, 127.93999999999944, 379.15, -17.649999999999977, 358.32000000000005, -19.269999999999683, 180.9999999999998, 118.85000000000026, -201.03000000000037, -32.18999999999964, 153.47, -95.98000000000002, 178.19999999999948, 0.939999999999981, 199.84000000000003, 84.11000000000129, 185.56, -16.739999999999977, 9.899999999999919], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.050000000000042, -13.210000000000033, -4.030000000000042, 50.05999999999999, 2.0000000000000013, 113.45000000000007, 125.0, 66.26000000000057, -52.27000000000034, 149.0, -182.92000000000036, 176.0, 89.0, -10.060000000000041, -16.0899999999997, -2.020000000000042, 185.0, -62.320000000000135, -8.050000000000042, 20.0, 2.0000000000000013, -64.32999999999966, -34.180000000000334, 26.750000000000274, 2.8399999999999825, -142.0, 143.0, 110.0, 15.85999999999996, 106.64000000000016, 2.0000000000000013, 5.86999999999996, 92.0, -41.32000000000005, -275.38000000000056, 2.0000000000000013, 2.0000000000000013, 108.56000000000009, -88.44999999999936, -10.60000000000003, 37.39999999999997, -0.00999999999999836, 5.659999999999966, 104.0, 194.0, 189.07999999999993, 145.06999999999994, 184.15999999999985, 34.2500000000001, -10.840000000000018, 2.509999999999989, -4.030000000000042, 37.48999999999971, 2.0000000000000013, -94.42000000000053, -25.0, -40.57000000000036, 20.81000000000028, 11.509999999999991, -85.39000000000001, -1.2100000000000206, 2.0000000000000013, 95.0, 86.0, -164.83000000000106, 2.0000000000000013, 2.0000000000000013, 182.12, 164.0, -89.62, 170.0, 5.719999999999963, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -13.0, -24.760000000000048, -0.9699999999999989, 152.0, 92.47999999999993, -46.05999999999952, -0.00999999999999836, -4.030000000000042, 134.36, -53.46999999999997, 186.05, 182.0, 194.0, 107.0, 2.0000000000000013, -88.44999999999979, -114.57999999999947, 120.02, 119.0, 91.93999999999998, 88.16, 2.0000000000000013, -46.36, -12.759999999999998, -8.050000000000042, 2.0000000000000013, 152.0, -26.13999999999971, 3.3200000000000003, 104.0, -4.150000000000039, 155.0, 152.0, 185.0, -6.040000000000042, -28.14999999999971, -6.040000000000042, -4.030000000000042, -196.0, -3.13000000000004, -0.00999999999999836, -132.6699999999999, 86.0, 170.0, 2.0000000000000013, 158.4199999999998, 53.24000000000002, 65.0, 164.0, 200.0, 196.01, 2.0000000000000013, 109.46000000000006, 200.0, 28.580000000000236, 187.01, 38.5699999999998, 167.0, 200.0, -203.2300000000007, -103.0, -55.0, 76.25, 132.41000000000008, 173.0, 149.18000000000004, 94.37, -18.099999999999753, 14.77999999999998, 146.41999999999962, -13.0, 11.86999999999996, 7.789999999999962, 176.21, 95.15, -31.869999999999422, 136.0999999999999, 173.0, 49.24999999999977, 120.11000000000006, -21.730000000000132, 2.0000000000000013, 125.0, 2.0000000000000013, 14.599999999999968, 65.0, 2.0000000000000013, -121.0, -166.33000000000058, 78.1099999999999, 9.829999999999961, 191.0, 185.15, -28.990000000000002, -130.65999999999957, 185.0, 168.32, -48.250000000000206, -2.020000000000042, 181.19, -36.19000000000036, 106.04, -36.19000000000017, -4.030000000000042, -400.0, -106.30000000000064, -107.89, -400.0, 153.47, -241.84000000000015, -2.1400000000000396, 168.19999999999982, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, 95.83999999999997, 35.0, 15.679999999999964, 58.42999999999974, 76.4, 58.16, -4.030000000000042, -140.71000000000004, 2.0000000000000013, 5.8999999999999595], "policy_predator_policy_reward": [12.0, 12.0, 6.0, 14.0, 14.0, 2.0, 10.0, 18.0, 17.0, 27.0, 92.0, 17.0, 30.0, 13.0, 9.0, 8.0, 5.0, 32.0, 59.0, 6.0, 32.0, 2.0, 0.0, 18.0, 114.0, 5.0, 0.0, 30.0, 0.0, 10.0, 2.0, 3.0, 46.0, 49.0, 130.0, 72.0, 12.0, 9.0, 24.0, 45.0, 1.0, 8.0, 18.0, 34.0, 2.0, 1.0, 12.0, 5.0, 40.0, 41.0, 3.0, 49.0, 5.0, 5.0, 84.0, 17.0, 0.0, 66.0, 45.0, 37.0, 8.0, 1.0, 53.0, 53.0, 83.0, 36.0, 2.0, 0.0, 63.0, 69.0, 12.0, 6.0, 7.0, 6.0, 71.0, 38.0, 63.0, 71.0, 0.0, 25.0, 50.0, 9.0, 13.0, 12.0, 58.0, 34.0, 4.0, 6.0, 0.0, 31.0, 5.0, 76.0, 20.0, 28.0, 1.0, 32.0, 54.0, 50.0, 65.0, 46.0, 4.0, 12.0, 31.0, 24.0, 6.0, 33.0, 16.0, 10.0, 5.0, 4.0, 15.0, 4.0, 127.0, 29.0, 6.0, 1.0, 102.0, 3.0, 10.0, 1.0, 32.0, 20.0, 4.0, 45.0, 1.0, 1.0, 7.0, 15.0, 5.0, 0.0, 2.0, 4.0, 11.0, 4.0, 21.0, 109.0, 85.0, 0.0, 9.0, 9.0, 0.0, 33.0, 42.0, 2.0, 51.0, 56.0, 4.0, 2.0, 9.0, 22.0, 23.0, 56.0, 13.0, 1.0, 40.0, 29.0, 25.0, 7.0, 9.0, 8.0, 35.0, 14.0, 107.0, 0.0, 3.0, 37.0, 0.0, 3.0, 66.0, 76.0, 5.0, 0.0, 14.0, 17.0, 17.0, 19.0, 30.0, 19.0, 200.0, 3.0, 137.0, 45.0, 200.0, 200.0, 6.0, 142.0, 4.0, 4.0, 4.0, 5.0, 55.0, 14.0, 4.0, 6.0, 0.0, 51.0, 60.0, 68.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6839916293943992, "mean_inference_ms": 1.8087420809103338, "mean_action_processing_ms": 0.29310265496278065, "mean_env_wait_ms": 0.22903145546406517, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004310250282287598, "StateBufferConnector_ms": 0.0039331912994384766, "ViewRequirementAgentConnector_ms": 0.11125552654266357}, "num_episodes": 18, "episode_return_max": 398.01, "episode_return_min": -201.03000000000037, "episode_return_mean": 119.38159999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.26540774139426, "num_env_steps_trained_throughput_per_sec": 359.26540774139426, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 11311.012, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11310.966, "sample_time_ms": 1384.253, "learn_time_ms": 9910.992, "learn_throughput": 403.592, "synch_weights_time_ms": 13.15}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "310e1_00000", "date": "2024-08-15_01-10-23", "timestamp": 1723664423, "time_this_iter_s": 11.184255123138428, "time_total_s": 777.6637296676636, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a1d670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 777.6637296676636, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 58.11333333333334, "ram_util_percent": 83.20666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.732051896638971, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1523952766701027, "policy_loss": -0.004468208351344974, "vf_loss": 3.156441881164672, "vf_explained_var": 0.1387366912352345, "kl": 0.011242794549088792, "entropy": 0.6073058009620697, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.513387600486241, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.223373912881922, "policy_loss": -0.0012260153492981637, "vf_loss": 5.224043350244956, "vf_explained_var": 0.4212820700236729, "kl": 0.011726944464403588, "entropy": 0.6912804308076385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 398.01, "episode_reward_min": -553.0, "episode_reward_mean": 108.76889999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 20.969449999999988, "predator_policy": 33.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [346.2299999999998, 104.4100000000002, 50.47999999999981, 49.489999999999434, -18.420000000000528, 46.23999999999982, 8.119999999999976, 9.789999999999926, 287.0, -43.83000000000048, 186.11999999999978, 206.38, 193.71999999999963, -7.120000000000083, 98.00000000000017, 108.27000000000002, 269.48, 12.929999999999618, 155.32999999999987, 224.58000000000004, 386.0, 140.0000000000001, -122.02999999999906, 287.02, 213.10000000000002, 59.63999999999995, 90.19000000000015, 169.9999999999999, 32.179999999999964, 138.8500000000002, 333.0, 187.95999999999975, -15.1899999999996, -44.02999999999965, 3.85999999999996, 58.329999999999984, 182.99999999999977, 263.6599999999998, 278.0, 398.01, 133.4600000000002, 233.57999999999925, 231.57999999999916, 382.0, -176.2300000000007, 106.24999999999989, 323.41, 276.54999999999995, 40.67999999999979, 240.41999999999962, 25.66000000000056, 302.36, 183.23000000000036, 236.24999999999906, 167.38000000000002, 159.0, 33.59999999999993, 116.00000000000041, -180.3300000000006, 127.93999999999944, 379.15, -17.649999999999977, 358.32000000000005, -19.269999999999683, 180.9999999999998, 118.85000000000026, -201.03000000000037, -32.18999999999964, 153.47, -95.98000000000002, 178.19999999999948, 0.939999999999981, 199.84000000000003, 84.11000000000129, 185.56, -16.739999999999977, 9.899999999999919, 52.13000000000013, 173.22999999999988, -198.00000000000034, 190.9699999999996, 28.010000000000034, 216.0, -196.99000000000035, 104.20000000000009, -11.110000000000083, 117.25, 192.40999999999977, 0.9999999999999805, 123.37000000000027, 248.06, 19.520000000000003, 46.409999999999535, -17.81, -553.0, 108.64000000000016, 137.56999999999996, 143.05000000000013, -77.04000000000043, 271.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [145.06999999999994, 184.15999999999985, 34.2500000000001, -10.840000000000018, 2.509999999999989, -4.030000000000042, 37.48999999999971, 2.0000000000000013, -94.42000000000053, -25.0, -40.57000000000036, 20.81000000000028, 11.509999999999991, -85.39000000000001, -1.2100000000000206, 2.0000000000000013, 95.0, 86.0, -164.83000000000106, 2.0000000000000013, 2.0000000000000013, 182.12, 164.0, -89.62, 170.0, 5.719999999999963, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -13.0, -24.760000000000048, -0.9699999999999989, 152.0, 92.47999999999993, -46.05999999999952, -0.00999999999999836, -4.030000000000042, 134.36, -53.46999999999997, 186.05, 182.0, 194.0, 107.0, 2.0000000000000013, -88.44999999999979, -114.57999999999947, 120.02, 119.0, 91.93999999999998, 88.16, 2.0000000000000013, -46.36, -12.759999999999998, -8.050000000000042, 2.0000000000000013, 152.0, -26.13999999999971, 3.3200000000000003, 104.0, -4.150000000000039, 155.0, 152.0, 185.0, -6.040000000000042, -28.14999999999971, -6.040000000000042, -4.030000000000042, -196.0, -3.13000000000004, -0.00999999999999836, -132.6699999999999, 86.0, 170.0, 2.0000000000000013, 158.4199999999998, 53.24000000000002, 65.0, 164.0, 200.0, 196.01, 2.0000000000000013, 109.46000000000006, 200.0, 28.580000000000236, 187.01, 38.5699999999998, 167.0, 200.0, -203.2300000000007, -103.0, -55.0, 76.25, 132.41000000000008, 173.0, 149.18000000000004, 94.37, -18.099999999999753, 14.77999999999998, 146.41999999999962, -13.0, 11.86999999999996, 7.789999999999962, 176.21, 95.15, -31.869999999999422, 136.0999999999999, 173.0, 49.24999999999977, 120.11000000000006, -21.730000000000132, 2.0000000000000013, 125.0, 2.0000000000000013, 14.599999999999968, 65.0, 2.0000000000000013, -121.0, -166.33000000000058, 78.1099999999999, 9.829999999999961, 191.0, 185.15, -28.990000000000002, -130.65999999999957, 185.0, 168.32, -48.250000000000206, -2.020000000000042, 181.19, -36.19000000000036, 106.04, -36.19000000000017, -4.030000000000042, -400.0, -106.30000000000064, -107.89, -400.0, 153.47, -241.84000000000015, -2.1400000000000396, 168.19999999999982, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, 95.83999999999997, 35.0, 15.679999999999964, 58.42999999999974, 76.4, 58.16, -4.030000000000042, -140.71000000000004, 2.0000000000000013, 5.8999999999999595, 47.21000000000007, -14.080000000000041, -6.040000000000042, 173.26999999999998, 2.0000000000000013, -400.0, -2.1100000000000403, 186.07999999999993, -22.989999999999995, 2.0000000000000013, 119.0, -4.0, -2.020000000000042, -393.97, 131.54, -66.33999999999915, -6.040000000000042, -12.070000000000041, -209.76999999999992, 198.01999999999998, 76.79000000000012, 99.62000000000009, 2.0000000000000013, -400.0, -4.030000000000042, 106.4, -28.0, 194.06, -67.47999999999992, 2.0000000000000013, 30.410000000000178, 2.0000000000000013, 181.19, -400.0, -355.0, -400.0, 98.69, -8.050000000000042, 67.52, -41.94999999999999, -50.26000000000019, 166.31000000000003, -156.96999999999946, -12.070000000000041, 161.0, 53.0], "policy_predator_policy_reward": [12.0, 5.0, 40.0, 41.0, 3.0, 49.0, 5.0, 5.0, 84.0, 17.0, 0.0, 66.0, 45.0, 37.0, 8.0, 1.0, 53.0, 53.0, 83.0, 36.0, 2.0, 0.0, 63.0, 69.0, 12.0, 6.0, 7.0, 6.0, 71.0, 38.0, 63.0, 71.0, 0.0, 25.0, 50.0, 9.0, 13.0, 12.0, 58.0, 34.0, 4.0, 6.0, 0.0, 31.0, 5.0, 76.0, 20.0, 28.0, 1.0, 32.0, 54.0, 50.0, 65.0, 46.0, 4.0, 12.0, 31.0, 24.0, 6.0, 33.0, 16.0, 10.0, 5.0, 4.0, 15.0, 4.0, 127.0, 29.0, 6.0, 1.0, 102.0, 3.0, 10.0, 1.0, 32.0, 20.0, 4.0, 45.0, 1.0, 1.0, 7.0, 15.0, 5.0, 0.0, 2.0, 4.0, 11.0, 4.0, 21.0, 109.0, 85.0, 0.0, 9.0, 9.0, 0.0, 33.0, 42.0, 2.0, 51.0, 56.0, 4.0, 2.0, 9.0, 22.0, 23.0, 56.0, 13.0, 1.0, 40.0, 29.0, 25.0, 7.0, 9.0, 8.0, 35.0, 14.0, 107.0, 0.0, 3.0, 37.0, 0.0, 3.0, 66.0, 76.0, 5.0, 0.0, 14.0, 17.0, 17.0, 19.0, 30.0, 19.0, 200.0, 3.0, 137.0, 45.0, 200.0, 200.0, 6.0, 142.0, 4.0, 4.0, 4.0, 5.0, 55.0, 14.0, 4.0, 6.0, 0.0, 51.0, 60.0, 68.0, 2.0, 0.0, 8.0, 11.0, 4.0, 2.0, 0.0, 200.0, 2.0, 5.0, 31.0, 18.0, 66.0, 35.0, 197.0, 2.0, 5.0, 34.0, 0.0, 7.0, 129.0, 0.0, 16.0, 0.0, 199.0, 200.0, 21.0, 0.0, 22.0, 60.0, 49.0, 36.0, 4.0, 10.0, 200.0, 1.0, 200.0, 2.0, 10.0, 8.0, 13.0, 99.0, 26.0, 1.0, 7.0, 85.0, 8.0, 49.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6826817773291193, "mean_inference_ms": 1.8053358399121533, "mean_action_processing_ms": 0.29232399147340776, "mean_env_wait_ms": 0.22860697378906664, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006608247756958008, "StateBufferConnector_ms": 0.004979252815246582, "ViewRequirementAgentConnector_ms": 0.1453157663345337}, "num_episodes": 23, "episode_return_max": 398.01, "episode_return_min": -553.0, "episode_return_mean": 108.76889999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.70051896200755, "num_env_steps_trained_throughput_per_sec": 358.70051896200755, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 11086.694, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11086.648, "sample_time_ms": 1301.758, "learn_time_ms": 9769.23, "learn_throughput": 409.449, "synch_weights_time_ms": 13.237}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "310e1_00000", "date": "2024-08-15_01-10-34", "timestamp": 1723664434, "time_this_iter_s": 11.213597059249878, "time_total_s": 788.8773267269135, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b14f73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 788.8773267269135, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 56.456250000000004, "ram_util_percent": 82.95625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6270750099704379, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.166963161740984, "policy_loss": -0.003981897940307304, "vf_loss": 3.170680734026369, "vf_explained_var": 0.0579453585324464, "kl": 0.007048641624663486, "entropy": 0.5354241185875797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.594063244925605, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.1792832734092835, "policy_loss": -0.0017909181407756276, "vf_loss": 4.180680420159032, "vf_explained_var": -0.2477495896122443, "kl": 0.008296783353597618, "entropy": 0.8675593569795922, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 398.01, "episode_reward_min": -553.0, "episode_reward_mean": 85.01199999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 4.675999999999999, "predator_policy": 37.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [155.32999999999987, 224.58000000000004, 386.0, 140.0000000000001, -122.02999999999906, 287.02, 213.10000000000002, 59.63999999999995, 90.19000000000015, 169.9999999999999, 32.179999999999964, 138.8500000000002, 333.0, 187.95999999999975, -15.1899999999996, -44.02999999999965, 3.85999999999996, 58.329999999999984, 182.99999999999977, 263.6599999999998, 278.0, 398.01, 133.4600000000002, 233.57999999999925, 231.57999999999916, 382.0, -176.2300000000007, 106.24999999999989, 323.41, 276.54999999999995, 40.67999999999979, 240.41999999999962, 25.66000000000056, 302.36, 183.23000000000036, 236.24999999999906, 167.38000000000002, 159.0, 33.59999999999993, 116.00000000000041, -180.3300000000006, 127.93999999999944, 379.15, -17.649999999999977, 358.32000000000005, -19.269999999999683, 180.9999999999998, 118.85000000000026, -201.03000000000037, -32.18999999999964, 153.47, -95.98000000000002, 178.19999999999948, 0.939999999999981, 199.84000000000003, 84.11000000000129, 185.56, -16.739999999999977, 9.899999999999919, 52.13000000000013, 173.22999999999988, -198.00000000000034, 190.9699999999996, 28.010000000000034, 216.0, -196.99000000000035, 104.20000000000009, -11.110000000000083, 117.25, 192.40999999999977, 0.9999999999999805, 123.37000000000027, 248.06, 19.520000000000003, 46.409999999999535, -17.81, -553.0, 108.64000000000016, 137.56999999999996, 143.05000000000013, -77.04000000000043, 271.0, 154.23000000000002, -5.619999999999981, -126.90999999999968, 134.36000000000018, 123.84000000000026, -182.9700000000002, -50.540000000000624, -16.0, -114.87999999999947, 2.989999999999981, -532.0, 332.28, 67.77000000000007, -188.9200000000003, -149.56999999999988, -197.08000000000033, 283.72, -3.100000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-4.030000000000042, 134.36, -53.46999999999997, 186.05, 182.0, 194.0, 107.0, 2.0000000000000013, -88.44999999999979, -114.57999999999947, 120.02, 119.0, 91.93999999999998, 88.16, 2.0000000000000013, -46.36, -12.759999999999998, -8.050000000000042, 2.0000000000000013, 152.0, -26.13999999999971, 3.3200000000000003, 104.0, -4.150000000000039, 155.0, 152.0, 185.0, -6.040000000000042, -28.14999999999971, -6.040000000000042, -4.030000000000042, -196.0, -3.13000000000004, -0.00999999999999836, -132.6699999999999, 86.0, 170.0, 2.0000000000000013, 158.4199999999998, 53.24000000000002, 65.0, 164.0, 200.0, 196.01, 2.0000000000000013, 109.46000000000006, 200.0, 28.580000000000236, 187.01, 38.5699999999998, 167.0, 200.0, -203.2300000000007, -103.0, -55.0, 76.25, 132.41000000000008, 173.0, 149.18000000000004, 94.37, -18.099999999999753, 14.77999999999998, 146.41999999999962, -13.0, 11.86999999999996, 7.789999999999962, 176.21, 95.15, -31.869999999999422, 136.0999999999999, 173.0, 49.24999999999977, 120.11000000000006, -21.730000000000132, 2.0000000000000013, 125.0, 2.0000000000000013, 14.599999999999968, 65.0, 2.0000000000000013, -121.0, -166.33000000000058, 78.1099999999999, 9.829999999999961, 191.0, 185.15, -28.990000000000002, -130.65999999999957, 185.0, 168.32, -48.250000000000206, -2.020000000000042, 181.19, -36.19000000000036, 106.04, -36.19000000000017, -4.030000000000042, -400.0, -106.30000000000064, -107.89, -400.0, 153.47, -241.84000000000015, -2.1400000000000396, 168.19999999999982, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, 95.83999999999997, 35.0, 15.679999999999964, 58.42999999999974, 76.4, 58.16, -4.030000000000042, -140.71000000000004, 2.0000000000000013, 5.8999999999999595, 47.21000000000007, -14.080000000000041, -6.040000000000042, 173.26999999999998, 2.0000000000000013, -400.0, -2.1100000000000403, 186.07999999999993, -22.989999999999995, 2.0000000000000013, 119.0, -4.0, -2.020000000000042, -393.97, 131.54, -66.33999999999915, -6.040000000000042, -12.070000000000041, -209.76999999999992, 198.01999999999998, 76.79000000000012, 99.62000000000009, 2.0000000000000013, -400.0, -4.030000000000042, 106.4, -28.0, 194.06, -67.47999999999992, 2.0000000000000013, 30.410000000000178, 2.0000000000000013, 181.19, -400.0, -355.0, -400.0, 98.69, -8.050000000000042, 67.52, -41.94999999999999, -50.26000000000019, 166.31000000000003, -156.96999999999946, -12.070000000000041, 161.0, 53.0, 200.0, -152.77000000000112, 2.0000000000000013, -53.619999999999784, -288.90999999999997, 2.0000000000000013, 70.5799999999999, 23.78000000000028, 167.3, -90.45999999999935, -8.050000000000042, -368.92, -10.060000000000041, -94.47999999999922, -400.0, 176.0, -360.88, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -400.0, -340.0, 131.0, 172.28, 16.85000000000011, 21.91999999999984, -10.060000000000041, -371.86, 46.42999999999977, -400.0, -400.0, -14.080000000000041, 122.09000000000002, 137.63, -14.080000000000041, -2.020000000000042], "policy_predator_policy_reward": [13.0, 12.0, 58.0, 34.0, 4.0, 6.0, 0.0, 31.0, 5.0, 76.0, 20.0, 28.0, 1.0, 32.0, 54.0, 50.0, 65.0, 46.0, 4.0, 12.0, 31.0, 24.0, 6.0, 33.0, 16.0, 10.0, 5.0, 4.0, 15.0, 4.0, 127.0, 29.0, 6.0, 1.0, 102.0, 3.0, 10.0, 1.0, 32.0, 20.0, 4.0, 45.0, 1.0, 1.0, 7.0, 15.0, 5.0, 0.0, 2.0, 4.0, 11.0, 4.0, 21.0, 109.0, 85.0, 0.0, 9.0, 9.0, 0.0, 33.0, 42.0, 2.0, 51.0, 56.0, 4.0, 2.0, 9.0, 22.0, 23.0, 56.0, 13.0, 1.0, 40.0, 29.0, 25.0, 7.0, 9.0, 8.0, 35.0, 14.0, 107.0, 0.0, 3.0, 37.0, 0.0, 3.0, 66.0, 76.0, 5.0, 0.0, 14.0, 17.0, 17.0, 19.0, 30.0, 19.0, 200.0, 3.0, 137.0, 45.0, 200.0, 200.0, 6.0, 142.0, 4.0, 4.0, 4.0, 5.0, 55.0, 14.0, 4.0, 6.0, 0.0, 51.0, 60.0, 68.0, 2.0, 0.0, 8.0, 11.0, 4.0, 2.0, 0.0, 200.0, 2.0, 5.0, 31.0, 18.0, 66.0, 35.0, 197.0, 2.0, 5.0, 34.0, 0.0, 7.0, 129.0, 0.0, 16.0, 0.0, 199.0, 200.0, 21.0, 0.0, 22.0, 60.0, 49.0, 36.0, 4.0, 10.0, 200.0, 1.0, 200.0, 2.0, 10.0, 8.0, 13.0, 99.0, 26.0, 1.0, 7.0, 85.0, 8.0, 49.0, 77.0, 30.0, 8.0, 38.0, 0.0, 160.0, 20.0, 20.0, 1.0, 46.0, 2.0, 192.0, 48.0, 6.0, 200.0, 8.0, 120.0, 124.0, 1.0, 0.0, 200.0, 8.0, 23.0, 6.0, 18.0, 11.0, 6.0, 187.0, 200.0, 4.0, 200.0, 17.0, 10.0, 14.0, 8.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6817919394751459, "mean_inference_ms": 1.8029674407140623, "mean_action_processing_ms": 0.2918295023867532, "mean_env_wait_ms": 0.22833284296858067, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007010102272033691, "StateBufferConnector_ms": 0.004602551460266113, "ViewRequirementAgentConnector_ms": 0.15040314197540283}, "num_episodes": 18, "episode_return_max": 398.01, "episode_return_min": -553.0, "episode_return_mean": 85.01199999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.71782134374166, "num_env_steps_trained_throughput_per_sec": 364.71782134374166, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 11063.587, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11063.541, "sample_time_ms": 1291.098, "learn_time_ms": 9756.444, "learn_throughput": 409.985, "synch_weights_time_ms": 13.423}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "310e1_00000", "date": "2024-08-15_01-10-45", "timestamp": 1723664445, "time_this_iter_s": 11.016309976577759, "time_total_s": 799.8936367034912, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19c5700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 799.8936367034912, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 56.525, "ram_util_percent": 83.01875000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9712123363737075, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.121395410431756, "policy_loss": -0.0037407250909834468, "vf_loss": 3.1249365540408585, "vf_explained_var": 0.1646016895455658, "kl": 0.005322213571165025, "entropy": 0.6378172703205593, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2232872773415195, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3123333111641897, "policy_loss": -0.00474183343944667, "vf_loss": 3.316657885672554, "vf_explained_var": 0.13904584088022748, "kl": 0.008791657477519985, "entropy": 1.0401836268800908, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 398.01, "episode_reward_min": -553.0, "episode_reward_mean": 67.59729999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -5.516350000000016, "predator_policy": 39.315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [182.99999999999977, 263.6599999999998, 278.0, 398.01, 133.4600000000002, 233.57999999999925, 231.57999999999916, 382.0, -176.2300000000007, 106.24999999999989, 323.41, 276.54999999999995, 40.67999999999979, 240.41999999999962, 25.66000000000056, 302.36, 183.23000000000036, 236.24999999999906, 167.38000000000002, 159.0, 33.59999999999993, 116.00000000000041, -180.3300000000006, 127.93999999999944, 379.15, -17.649999999999977, 358.32000000000005, -19.269999999999683, 180.9999999999998, 118.85000000000026, -201.03000000000037, -32.18999999999964, 153.47, -95.98000000000002, 178.19999999999948, 0.939999999999981, 199.84000000000003, 84.11000000000129, 185.56, -16.739999999999977, 9.899999999999919, 52.13000000000013, 173.22999999999988, -198.00000000000034, 190.9699999999996, 28.010000000000034, 216.0, -196.99000000000035, 104.20000000000009, -11.110000000000083, 117.25, 192.40999999999977, 0.9999999999999805, 123.37000000000027, 248.06, 19.520000000000003, 46.409999999999535, -17.81, -553.0, 108.64000000000016, 137.56999999999996, 143.05000000000013, -77.04000000000043, 271.0, 154.23000000000002, -5.619999999999981, -126.90999999999968, 134.36000000000018, 123.84000000000026, -182.9700000000002, -50.540000000000624, -16.0, -114.87999999999947, 2.989999999999981, -532.0, 332.28, 67.77000000000007, -188.9200000000003, -149.56999999999988, -197.08000000000033, 283.72, -3.100000000000083, 167.6599999999999, -27.780000000000083, -48.54000000000069, 197.41000000000003, 0.9399999999999819, 19.010000000000197, 106.35000000000018, -16.949999999999875, 2.4099999999999917, -12.54999999999977, -152.6700000000012, 189.02999999999975, -456.87, 190.0799999999997, 208.14000000000004, 3.9699999999999593, 157.31000000000012, 30.370000000000292], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.0, 2.0000000000000013, 158.4199999999998, 53.24000000000002, 65.0, 164.0, 200.0, 196.01, 2.0000000000000013, 109.46000000000006, 200.0, 28.580000000000236, 187.01, 38.5699999999998, 167.0, 200.0, -203.2300000000007, -103.0, -55.0, 76.25, 132.41000000000008, 173.0, 149.18000000000004, 94.37, -18.099999999999753, 14.77999999999998, 146.41999999999962, -13.0, 11.86999999999996, 7.789999999999962, 176.21, 95.15, -31.869999999999422, 136.0999999999999, 173.0, 49.24999999999977, 120.11000000000006, -21.730000000000132, 2.0000000000000013, 125.0, 2.0000000000000013, 14.599999999999968, 65.0, 2.0000000000000013, -121.0, -166.33000000000058, 78.1099999999999, 9.829999999999961, 191.0, 185.15, -28.990000000000002, -130.65999999999957, 185.0, 168.32, -48.250000000000206, -2.020000000000042, 181.19, -36.19000000000036, 106.04, -36.19000000000017, -4.030000000000042, -400.0, -106.30000000000064, -107.89, -400.0, 153.47, -241.84000000000015, -2.1400000000000396, 168.19999999999982, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, 95.83999999999997, 35.0, 15.679999999999964, 58.42999999999974, 76.4, 58.16, -4.030000000000042, -140.71000000000004, 2.0000000000000013, 5.8999999999999595, 47.21000000000007, -14.080000000000041, -6.040000000000042, 173.26999999999998, 2.0000000000000013, -400.0, -2.1100000000000403, 186.07999999999993, -22.989999999999995, 2.0000000000000013, 119.0, -4.0, -2.020000000000042, -393.97, 131.54, -66.33999999999915, -6.040000000000042, -12.070000000000041, -209.76999999999992, 198.01999999999998, 76.79000000000012, 99.62000000000009, 2.0000000000000013, -400.0, -4.030000000000042, 106.4, -28.0, 194.06, -67.47999999999992, 2.0000000000000013, 30.410000000000178, 2.0000000000000013, 181.19, -400.0, -355.0, -400.0, 98.69, -8.050000000000042, 67.52, -41.94999999999999, -50.26000000000019, 166.31000000000003, -156.96999999999946, -12.070000000000041, 161.0, 53.0, 200.0, -152.77000000000112, 2.0000000000000013, -53.619999999999784, -288.90999999999997, 2.0000000000000013, 70.5799999999999, 23.78000000000028, 167.3, -90.45999999999935, -8.050000000000042, -368.92, -10.060000000000041, -94.47999999999922, -400.0, 176.0, -360.88, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -400.0, -340.0, 131.0, 172.28, 16.85000000000011, 21.91999999999984, -10.060000000000041, -371.86, 46.42999999999977, -400.0, -400.0, -14.080000000000041, 122.09000000000002, 137.63, -14.080000000000041, -2.020000000000042, -68.34999999999916, 199.01, -104.77000000000002, -0.00999999999999836, -32.29000000000034, -39.25000000000035, -23.32000000000002, 127.73000000000005, -10.060000000000041, 2.0000000000000013, -2.020000000000042, -69.97000000000003, -128.6500000000009, 155.0, 35.65999999999967, -219.61000000000007, -35.260000000000346, 7.669999999999964, -87.4900000000001, -10.060000000000041, -217.0900000000005, -114.57999999999969, 182.03000000000003, 2.0000000000000013, -400.0, -310.87, 179.20999999999998, 8.86999999999996, 200.0, -92.85999999999942, -4.030000000000042, 2.0000000000000013, 124.63999999999999, 25.670000000000258, 22.43000000000022, -10.060000000000041], "policy_predator_policy_reward": [10.0, 1.0, 32.0, 20.0, 4.0, 45.0, 1.0, 1.0, 7.0, 15.0, 5.0, 0.0, 2.0, 4.0, 11.0, 4.0, 21.0, 109.0, 85.0, 0.0, 9.0, 9.0, 0.0, 33.0, 42.0, 2.0, 51.0, 56.0, 4.0, 2.0, 9.0, 22.0, 23.0, 56.0, 13.0, 1.0, 40.0, 29.0, 25.0, 7.0, 9.0, 8.0, 35.0, 14.0, 107.0, 0.0, 3.0, 37.0, 0.0, 3.0, 66.0, 76.0, 5.0, 0.0, 14.0, 17.0, 17.0, 19.0, 30.0, 19.0, 200.0, 3.0, 137.0, 45.0, 200.0, 200.0, 6.0, 142.0, 4.0, 4.0, 4.0, 5.0, 55.0, 14.0, 4.0, 6.0, 0.0, 51.0, 60.0, 68.0, 2.0, 0.0, 8.0, 11.0, 4.0, 2.0, 0.0, 200.0, 2.0, 5.0, 31.0, 18.0, 66.0, 35.0, 197.0, 2.0, 5.0, 34.0, 0.0, 7.0, 129.0, 0.0, 16.0, 0.0, 199.0, 200.0, 21.0, 0.0, 22.0, 60.0, 49.0, 36.0, 4.0, 10.0, 200.0, 1.0, 200.0, 2.0, 10.0, 8.0, 13.0, 99.0, 26.0, 1.0, 7.0, 85.0, 8.0, 49.0, 77.0, 30.0, 8.0, 38.0, 0.0, 160.0, 20.0, 20.0, 1.0, 46.0, 2.0, 192.0, 48.0, 6.0, 200.0, 8.0, 120.0, 124.0, 1.0, 0.0, 200.0, 8.0, 23.0, 6.0, 18.0, 11.0, 6.0, 187.0, 200.0, 4.0, 200.0, 17.0, 10.0, 14.0, 8.0, 5.0, 2.0, 35.0, 41.0, 36.0, 22.0, 1.0, 48.0, 45.0, 3.0, 6.0, 2.0, 89.0, 65.0, 15.0, 65.0, 102.0, 24.0, 6.0, 25.0, 60.0, 68.0, 111.0, 0.0, 5.0, 200.0, 54.0, 0.0, 2.0, 51.0, 50.0, 3.0, 3.0, 3.0, 4.0, 12.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6809812894153875, "mean_inference_ms": 1.800584976635522, "mean_action_processing_ms": 0.2913455629190825, "mean_env_wait_ms": 0.22805376312892572, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00746464729309082, "StateBufferConnector_ms": 0.00407254695892334, "ViewRequirementAgentConnector_ms": 0.15107953548431396}, "num_episodes": 18, "episode_return_max": 398.01, "episode_return_min": -553.0, "episode_return_mean": 67.59729999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.63087397326916, "num_env_steps_trained_throughput_per_sec": 329.63087397326916, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 11138.284, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11138.235, "sample_time_ms": 1270.521, "learn_time_ms": 9851.386, "learn_throughput": 406.034, "synch_weights_time_ms": 13.487}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "310e1_00000", "date": "2024-08-15_01-10-57", "timestamp": 1723664457, "time_this_iter_s": 12.175323963165283, "time_total_s": 812.0689606666565, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19ba670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 812.0689606666565, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 56.900000000000006, "ram_util_percent": 83.71764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.47086877252059, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.734834908682203, "policy_loss": -0.002642381007699345, "vf_loss": 4.737172534730699, "vf_explained_var": 0.07640946930047696, "kl": 0.008127064157416968, "entropy": 0.4998711275518256, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.2409299846994815, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.312313921363265, "policy_loss": -0.008674477051608462, "vf_loss": 5.319503364865742, "vf_explained_var": -0.23108044928974575, "kl": 0.03128953965486077, "entropy": 0.9398578069512806, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 379.15, "episode_reward_min": -553.0, "episode_reward_mean": 29.170099999999945, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -34.13995000000002, "predator_policy": 48.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-180.3300000000006, 127.93999999999944, 379.15, -17.649999999999977, 358.32000000000005, -19.269999999999683, 180.9999999999998, 118.85000000000026, -201.03000000000037, -32.18999999999964, 153.47, -95.98000000000002, 178.19999999999948, 0.939999999999981, 199.84000000000003, 84.11000000000129, 185.56, -16.739999999999977, 9.899999999999919, 52.13000000000013, 173.22999999999988, -198.00000000000034, 190.9699999999996, 28.010000000000034, 216.0, -196.99000000000035, 104.20000000000009, -11.110000000000083, 117.25, 192.40999999999977, 0.9999999999999805, 123.37000000000027, 248.06, 19.520000000000003, 46.409999999999535, -17.81, -553.0, 108.64000000000016, 137.56999999999996, 143.05000000000013, -77.04000000000043, 271.0, 154.23000000000002, -5.619999999999981, -126.90999999999968, 134.36000000000018, 123.84000000000026, -182.9700000000002, -50.540000000000624, -16.0, -114.87999999999947, 2.989999999999981, -532.0, 332.28, 67.77000000000007, -188.9200000000003, -149.56999999999988, -197.08000000000033, 283.72, -3.100000000000083, 167.6599999999999, -27.780000000000083, -48.54000000000069, 197.41000000000003, 0.9399999999999819, 19.010000000000197, 106.35000000000018, -16.949999999999875, 2.4099999999999917, -12.54999999999977, -152.6700000000012, 189.02999999999975, -456.87, 190.0799999999997, 208.14000000000004, 3.9699999999999593, 157.31000000000012, 30.370000000000292, -2.999999999999991, 174.03999999999985, 86.48000000000015, 32.700000000000294, -194.00000000000034, -75.99000000000001, -8.27000000000007, -210.5600000000013, -7.1900000000000635, 2.939999999999982, 8.459999999999937, 33.0, 193.0299999999994, -132.6000000000011, -65.00000000000003, 69.69000000000044, -135.97999999999985, 165.05, 89.6700000000001, 98.09, 45.33999999999998, 129.2300000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-121.0, -166.33000000000058, 78.1099999999999, 9.829999999999961, 191.0, 185.15, -28.990000000000002, -130.65999999999957, 185.0, 168.32, -48.250000000000206, -2.020000000000042, 181.19, -36.19000000000036, 106.04, -36.19000000000017, -4.030000000000042, -400.0, -106.30000000000064, -107.89, -400.0, 153.47, -241.84000000000015, -2.1400000000000396, 168.19999999999982, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, 95.83999999999997, 35.0, 15.679999999999964, 58.42999999999974, 76.4, 58.16, -4.030000000000042, -140.71000000000004, 2.0000000000000013, 5.8999999999999595, 47.21000000000007, -14.080000000000041, -6.040000000000042, 173.26999999999998, 2.0000000000000013, -400.0, -2.1100000000000403, 186.07999999999993, -22.989999999999995, 2.0000000000000013, 119.0, -4.0, -2.020000000000042, -393.97, 131.54, -66.33999999999915, -6.040000000000042, -12.070000000000041, -209.76999999999992, 198.01999999999998, 76.79000000000012, 99.62000000000009, 2.0000000000000013, -400.0, -4.030000000000042, 106.4, -28.0, 194.06, -67.47999999999992, 2.0000000000000013, 30.410000000000178, 2.0000000000000013, 181.19, -400.0, -355.0, -400.0, 98.69, -8.050000000000042, 67.52, -41.94999999999999, -50.26000000000019, 166.31000000000003, -156.96999999999946, -12.070000000000041, 161.0, 53.0, 200.0, -152.77000000000112, 2.0000000000000013, -53.619999999999784, -288.90999999999997, 2.0000000000000013, 70.5799999999999, 23.78000000000028, 167.3, -90.45999999999935, -8.050000000000042, -368.92, -10.060000000000041, -94.47999999999922, -400.0, 176.0, -360.88, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -400.0, -340.0, 131.0, 172.28, 16.85000000000011, 21.91999999999984, -10.060000000000041, -371.86, 46.42999999999977, -400.0, -400.0, -14.080000000000041, 122.09000000000002, 137.63, -14.080000000000041, -2.020000000000042, -68.34999999999916, 199.01, -104.77000000000002, -0.00999999999999836, -32.29000000000034, -39.25000000000035, -23.32000000000002, 127.73000000000005, -10.060000000000041, 2.0000000000000013, -2.020000000000042, -69.97000000000003, -128.6500000000009, 155.0, 35.65999999999967, -219.61000000000007, -35.260000000000346, 7.669999999999964, -87.4900000000001, -10.060000000000041, -217.0900000000005, -114.57999999999969, 182.03000000000003, 2.0000000000000013, -400.0, -310.87, 179.20999999999998, 8.86999999999996, 200.0, -92.85999999999942, -4.030000000000042, 2.0000000000000013, 124.63999999999999, 25.670000000000258, 22.43000000000022, -10.060000000000041, -211.0, 2.0000000000000013, 162.05, -0.00999999999999836, 54.50000000000004, -2.020000000000042, -0.00999999999999836, 30.710000000000264, -400.0, 2.0000000000000013, -400.0, 124.00999999999999, -12.070000000000041, -17.19999999999972, -124.95999999999978, -217.60000000000036, -12.070000000000041, -22.119999999999784, 2.0000000000000013, -10.060000000000041, -90.31000000000014, 24.770000000000245, -133.0, -40.0, 5.809999999999961, 178.21999999999989, -176.80000000000013, -152.8000000000011, -400.0, 2.0000000000000013, -268.0, 26.690000000000225, -308.98, 2.0000000000000013, 2.0000000000000013, 123.05, 82.75999999999999, -16.089999999999833, 98.09, -400.0, 140.48, -206.14000000000078, 80.44999999999999, 14.779999999999962], "policy_predator_policy_reward": [107.0, 0.0, 3.0, 37.0, 0.0, 3.0, 66.0, 76.0, 5.0, 0.0, 14.0, 17.0, 17.0, 19.0, 30.0, 19.0, 200.0, 3.0, 137.0, 45.0, 200.0, 200.0, 6.0, 142.0, 4.0, 4.0, 4.0, 5.0, 55.0, 14.0, 4.0, 6.0, 0.0, 51.0, 60.0, 68.0, 2.0, 0.0, 8.0, 11.0, 4.0, 2.0, 0.0, 200.0, 2.0, 5.0, 31.0, 18.0, 66.0, 35.0, 197.0, 2.0, 5.0, 34.0, 0.0, 7.0, 129.0, 0.0, 16.0, 0.0, 199.0, 200.0, 21.0, 0.0, 22.0, 60.0, 49.0, 36.0, 4.0, 10.0, 200.0, 1.0, 200.0, 2.0, 10.0, 8.0, 13.0, 99.0, 26.0, 1.0, 7.0, 85.0, 8.0, 49.0, 77.0, 30.0, 8.0, 38.0, 0.0, 160.0, 20.0, 20.0, 1.0, 46.0, 2.0, 192.0, 48.0, 6.0, 200.0, 8.0, 120.0, 124.0, 1.0, 0.0, 200.0, 8.0, 23.0, 6.0, 18.0, 11.0, 6.0, 187.0, 200.0, 4.0, 200.0, 17.0, 10.0, 14.0, 8.0, 5.0, 2.0, 35.0, 41.0, 36.0, 22.0, 1.0, 48.0, 45.0, 3.0, 6.0, 2.0, 89.0, 65.0, 15.0, 65.0, 102.0, 24.0, 6.0, 25.0, 60.0, 68.0, 111.0, 0.0, 5.0, 200.0, 54.0, 0.0, 2.0, 51.0, 50.0, 3.0, 3.0, 3.0, 4.0, 12.0, 6.0, 119.0, 87.0, 1.0, 11.0, 11.0, 23.0, 1.0, 1.0, 4.0, 200.0, 200.0, 0.0, 10.0, 11.0, 6.0, 126.0, 17.0, 10.0, 6.0, 5.0, 1.0, 73.0, 116.0, 90.0, 5.0, 4.0, 119.0, 78.0, 200.0, 133.0, 156.0, 155.0, 169.0, 2.0, 24.0, 16.0, 10.0, 13.0, 200.0, 200.0, 107.0, 4.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6804264642540381, "mean_inference_ms": 1.80050191849254, "mean_action_processing_ms": 0.29090495406251976, "mean_env_wait_ms": 0.22793981599329713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0077016353607177734, "StateBufferConnector_ms": 0.0043114423751831055, "ViewRequirementAgentConnector_ms": 0.13860690593719482}, "num_episodes": 22, "episode_return_max": 379.15, "episode_return_min": -553.0, "episode_return_mean": 29.170099999999945, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.2663363789373, "num_env_steps_trained_throughput_per_sec": 311.2663363789373, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 11278.575, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11278.525, "sample_time_ms": 1327.576, "learn_time_ms": 9934.428, "learn_throughput": 402.64, "synch_weights_time_ms": 13.626}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "310e1_00000", "date": "2024-08-15_01-11-10", "timestamp": 1723664470, "time_this_iter_s": 12.886357069015503, "time_total_s": 824.955317735672, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a1d0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 824.955317735672, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 58.78888888888889, "ram_util_percent": 83.58333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.061603458217843, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9697165757259996, "policy_loss": -0.0006790831692457672, "vf_loss": 1.9702008925417744, "vf_explained_var": 0.18087821892960362, "kl": 0.005193754779792954, "entropy": 0.4895371130534581, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.441082891080745, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.346066768901058, "policy_loss": -0.010115197228721132, "vf_loss": 3.355196340815731, "vf_explained_var": -0.4871744985933657, "kl": 0.013844887713352872, "entropy": 1.2931664515424657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 332.28, "episode_reward_min": -553.0, "episode_reward_mean": 13.731599999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -40.1392, "predator_policy": 47.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.010000000000034, 216.0, -196.99000000000035, 104.20000000000009, -11.110000000000083, 117.25, 192.40999999999977, 0.9999999999999805, 123.37000000000027, 248.06, 19.520000000000003, 46.409999999999535, -17.81, -553.0, 108.64000000000016, 137.56999999999996, 143.05000000000013, -77.04000000000043, 271.0, 154.23000000000002, -5.619999999999981, -126.90999999999968, 134.36000000000018, 123.84000000000026, -182.9700000000002, -50.540000000000624, -16.0, -114.87999999999947, 2.989999999999981, -532.0, 332.28, 67.77000000000007, -188.9200000000003, -149.56999999999988, -197.08000000000033, 283.72, -3.100000000000083, 167.6599999999999, -27.780000000000083, -48.54000000000069, 197.41000000000003, 0.9399999999999819, 19.010000000000197, 106.35000000000018, -16.949999999999875, 2.4099999999999917, -12.54999999999977, -152.6700000000012, 189.02999999999975, -456.87, 190.0799999999997, 208.14000000000004, 3.9699999999999593, 157.31000000000012, 30.370000000000292, -2.999999999999991, 174.03999999999985, 86.48000000000015, 32.700000000000294, -194.00000000000034, -75.99000000000001, -8.27000000000007, -210.5600000000013, -7.1900000000000635, 2.939999999999982, 8.459999999999937, 33.0, 193.0299999999994, -132.6000000000011, -65.00000000000003, 69.69000000000044, -135.97999999999985, 165.05, 89.6700000000001, 98.09, 45.33999999999998, 129.2300000000002, 92.60000000000106, 26.210000000000424, 39.7600000000003, 40.40999999999941, 51.28999999999964, 0.35000000000004644, 112.91000000000096, -26.189999999999593, -25.299999999999425, -1.050000000000063, -4.719999999999997, -263.77, 5.709999999999632, 13.599999999999923, -124.78000000000016, -18.31999999999945, 3.6999999999999655, -93.71000000000001, -5.810000000000045, 25.26000000000044, 169.67000000000007, 68.48000000000005, 2.2700000000000102], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-22.989999999999995, 2.0000000000000013, 119.0, -4.0, -2.020000000000042, -393.97, 131.54, -66.33999999999915, -6.040000000000042, -12.070000000000041, -209.76999999999992, 198.01999999999998, 76.79000000000012, 99.62000000000009, 2.0000000000000013, -400.0, -4.030000000000042, 106.4, -28.0, 194.06, -67.47999999999992, 2.0000000000000013, 30.410000000000178, 2.0000000000000013, 181.19, -400.0, -355.0, -400.0, 98.69, -8.050000000000042, 67.52, -41.94999999999999, -50.26000000000019, 166.31000000000003, -156.96999999999946, -12.070000000000041, 161.0, 53.0, 200.0, -152.77000000000112, 2.0000000000000013, -53.619999999999784, -288.90999999999997, 2.0000000000000013, 70.5799999999999, 23.78000000000028, 167.3, -90.45999999999935, -8.050000000000042, -368.92, -10.060000000000041, -94.47999999999922, -400.0, 176.0, -360.88, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -400.0, -340.0, 131.0, 172.28, 16.85000000000011, 21.91999999999984, -10.060000000000041, -371.86, 46.42999999999977, -400.0, -400.0, -14.080000000000041, 122.09000000000002, 137.63, -14.080000000000041, -2.020000000000042, -68.34999999999916, 199.01, -104.77000000000002, -0.00999999999999836, -32.29000000000034, -39.25000000000035, -23.32000000000002, 127.73000000000005, -10.060000000000041, 2.0000000000000013, -2.020000000000042, -69.97000000000003, -128.6500000000009, 155.0, 35.65999999999967, -219.61000000000007, -35.260000000000346, 7.669999999999964, -87.4900000000001, -10.060000000000041, -217.0900000000005, -114.57999999999969, 182.03000000000003, 2.0000000000000013, -400.0, -310.87, 179.20999999999998, 8.86999999999996, 200.0, -92.85999999999942, -4.030000000000042, 2.0000000000000013, 124.63999999999999, 25.670000000000258, 22.43000000000022, -10.060000000000041, -211.0, 2.0000000000000013, 162.05, -0.00999999999999836, 54.50000000000004, -2.020000000000042, -0.00999999999999836, 30.710000000000264, -400.0, 2.0000000000000013, -400.0, 124.00999999999999, -12.070000000000041, -17.19999999999972, -124.95999999999978, -217.60000000000036, -12.070000000000041, -22.119999999999784, 2.0000000000000013, -10.060000000000041, -90.31000000000014, 24.770000000000245, -133.0, -40.0, 5.809999999999961, 178.21999999999989, -176.80000000000013, -152.8000000000011, -400.0, 2.0000000000000013, -268.0, 26.690000000000225, -308.98, 2.0000000000000013, 2.0000000000000013, 123.05, 82.75999999999999, -16.089999999999833, 98.09, -400.0, 140.48, -206.14000000000078, 80.44999999999999, 14.779999999999962, 40.54999999999979, 27.05000000000016, 8.719999999999963, -10.51000000000003, -40.78000000000022, -18.460000000000008, 49.5199999999997, -20.109999999999708, 60.40999999999984, -22.119999999999706, -59.590000000000266, -10.060000000000041, 84.1700000000006, -116.25999999999962, -46.960000000000186, -38.23000000000034, -42.220000000000354, -14.080000000000041, -6.040000000000042, -0.00999999999999836, -3.4900000000000304, -44.23000000000015, -140.76999999999998, -325.0, -15.06999999999955, -42.220000000000006, -12.070000000000041, 10.669999999999964, -14.080000000000041, -282.69999999999993, -40.210000000000335, -5.11000000000004, -58.30000000000033, 2.0000000000000013, -349.0, 39.29000000000005, -22.65999999999998, -28.14999999999971, 2.299999999999996, -6.040000000000042, 47.45000000000017, 49.22, 2.0000000000000013, 20.480000000000164, -23.499999999999766, -8.230000000000038], "policy_predator_policy_reward": [31.0, 18.0, 66.0, 35.0, 197.0, 2.0, 5.0, 34.0, 0.0, 7.0, 129.0, 0.0, 16.0, 0.0, 199.0, 200.0, 21.0, 0.0, 22.0, 60.0, 49.0, 36.0, 4.0, 10.0, 200.0, 1.0, 200.0, 2.0, 10.0, 8.0, 13.0, 99.0, 26.0, 1.0, 7.0, 85.0, 8.0, 49.0, 77.0, 30.0, 8.0, 38.0, 0.0, 160.0, 20.0, 20.0, 1.0, 46.0, 2.0, 192.0, 48.0, 6.0, 200.0, 8.0, 120.0, 124.0, 1.0, 0.0, 200.0, 8.0, 23.0, 6.0, 18.0, 11.0, 6.0, 187.0, 200.0, 4.0, 200.0, 17.0, 10.0, 14.0, 8.0, 5.0, 2.0, 35.0, 41.0, 36.0, 22.0, 1.0, 48.0, 45.0, 3.0, 6.0, 2.0, 89.0, 65.0, 15.0, 65.0, 102.0, 24.0, 6.0, 25.0, 60.0, 68.0, 111.0, 0.0, 5.0, 200.0, 54.0, 0.0, 2.0, 51.0, 50.0, 3.0, 3.0, 3.0, 4.0, 12.0, 6.0, 119.0, 87.0, 1.0, 11.0, 11.0, 23.0, 1.0, 1.0, 4.0, 200.0, 200.0, 0.0, 10.0, 11.0, 6.0, 126.0, 17.0, 10.0, 6.0, 5.0, 1.0, 73.0, 116.0, 90.0, 5.0, 4.0, 119.0, 78.0, 200.0, 133.0, 156.0, 155.0, 169.0, 2.0, 24.0, 16.0, 10.0, 13.0, 200.0, 200.0, 107.0, 4.0, 17.0, 17.0, 0.0, 25.0, 0.0, 28.0, 91.0, 8.0, 11.0, 0.0, 12.0, 1.0, 39.0, 31.0, 76.0, 69.0, 11.0, 48.0, 9.0, 22.0, 4.0, 1.0, 11.0, 32.0, 16.0, 186.0, 27.0, 36.0, 8.0, 7.0, 33.0, 139.0, 21.0, 6.0, 30.0, 30.0, 16.0, 200.0, 7.0, 38.0, 6.0, 23.0, 9.0, 64.0, 44.0, 2.0, 25.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6805122968351145, "mean_inference_ms": 1.8012480350573423, "mean_action_processing_ms": 0.29092619044366463, "mean_env_wait_ms": 0.2279017698966794, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007966041564941406, "StateBufferConnector_ms": 0.004352211952209473, "ViewRequirementAgentConnector_ms": 0.14044415950775146}, "num_episodes": 23, "episode_return_max": 332.28, "episode_return_min": -553.0, "episode_return_mean": 13.731599999999982, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.169987117207, "num_env_steps_trained_throughput_per_sec": 322.169987117207, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 11423.0, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11422.948, "sample_time_ms": 1362.824, "learn_time_ms": 10042.826, "learn_throughput": 398.294, "synch_weights_time_ms": 14.031}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "310e1_00000", "date": "2024-08-15_01-11-23", "timestamp": 1723664483, "time_this_iter_s": 12.464008808135986, "time_total_s": 837.419326543808, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b194eb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 837.419326543808, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 61.161111111111104, "ram_util_percent": 83.65555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5489249565929333, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0371984209963885, "policy_loss": -0.002736923838078621, "vf_loss": 2.0395906085375124, "vf_explained_var": 0.14514142240166034, "kl": 0.00919274774407455, "entropy": 0.5303313670334993, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.24732043188085, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.835986537277383, "policy_loss": -0.01136708817415176, "vf_loss": 3.846394759006601, "vf_explained_var": -0.37616194795679164, "kl": 0.013468847832272863, "entropy": 1.2709652330509569, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 332.28, "episode_reward_min": -532.0, "episode_reward_mean": 21.475900000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -30.512050000000002, "predator_policy": 41.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [271.0, 154.23000000000002, -5.619999999999981, -126.90999999999968, 134.36000000000018, 123.84000000000026, -182.9700000000002, -50.540000000000624, -16.0, -114.87999999999947, 2.989999999999981, -532.0, 332.28, 67.77000000000007, -188.9200000000003, -149.56999999999988, -197.08000000000033, 283.72, -3.100000000000083, 167.6599999999999, -27.780000000000083, -48.54000000000069, 197.41000000000003, 0.9399999999999819, 19.010000000000197, 106.35000000000018, -16.949999999999875, 2.4099999999999917, -12.54999999999977, -152.6700000000012, 189.02999999999975, -456.87, 190.0799999999997, 208.14000000000004, 3.9699999999999593, 157.31000000000012, 30.370000000000292, -2.999999999999991, 174.03999999999985, 86.48000000000015, 32.700000000000294, -194.00000000000034, -75.99000000000001, -8.27000000000007, -210.5600000000013, -7.1900000000000635, 2.939999999999982, 8.459999999999937, 33.0, 193.0299999999994, -132.6000000000011, -65.00000000000003, 69.69000000000044, -135.97999999999985, 165.05, 89.6700000000001, 98.09, 45.33999999999998, 129.2300000000002, 92.60000000000106, 26.210000000000424, 39.7600000000003, 40.40999999999941, 51.28999999999964, 0.35000000000004644, 112.91000000000096, -26.189999999999593, -25.299999999999425, -1.050000000000063, -4.719999999999997, -263.77, 5.709999999999632, 13.599999999999923, -124.78000000000016, -18.31999999999945, 3.6999999999999655, -93.71000000000001, -5.810000000000045, 25.26000000000044, 169.67000000000007, 68.48000000000005, 2.2700000000000102, 166.86999999999847, 93.51000000000086, 92.88000000000139, 127.410000000001, 75.78000000000068, 127.38000000000119, -13.180000000000092, 53.63999999999988, 55.19999999999937, 10.409999999999949, 57.37999999999953, 254.25999999999934, 77.30000000000102, 61.21999999999948, 9.419999999999957, 31.16000000000034, 60.209999999999454, 63.11999999999951], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [161.0, 53.0, 200.0, -152.77000000000112, 2.0000000000000013, -53.619999999999784, -288.90999999999997, 2.0000000000000013, 70.5799999999999, 23.78000000000028, 167.3, -90.45999999999935, -8.050000000000042, -368.92, -10.060000000000041, -94.47999999999922, -400.0, 176.0, -360.88, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -400.0, -340.0, 131.0, 172.28, 16.85000000000011, 21.91999999999984, -10.060000000000041, -371.86, 46.42999999999977, -400.0, -400.0, -14.080000000000041, 122.09000000000002, 137.63, -14.080000000000041, -2.020000000000042, -68.34999999999916, 199.01, -104.77000000000002, -0.00999999999999836, -32.29000000000034, -39.25000000000035, -23.32000000000002, 127.73000000000005, -10.060000000000041, 2.0000000000000013, -2.020000000000042, -69.97000000000003, -128.6500000000009, 155.0, 35.65999999999967, -219.61000000000007, -35.260000000000346, 7.669999999999964, -87.4900000000001, -10.060000000000041, -217.0900000000005, -114.57999999999969, 182.03000000000003, 2.0000000000000013, -400.0, -310.87, 179.20999999999998, 8.86999999999996, 200.0, -92.85999999999942, -4.030000000000042, 2.0000000000000013, 124.63999999999999, 25.670000000000258, 22.43000000000022, -10.060000000000041, -211.0, 2.0000000000000013, 162.05, -0.00999999999999836, 54.50000000000004, -2.020000000000042, -0.00999999999999836, 30.710000000000264, -400.0, 2.0000000000000013, -400.0, 124.00999999999999, -12.070000000000041, -17.19999999999972, -124.95999999999978, -217.60000000000036, -12.070000000000041, -22.119999999999784, 2.0000000000000013, -10.060000000000041, -90.31000000000014, 24.770000000000245, -133.0, -40.0, 5.809999999999961, 178.21999999999989, -176.80000000000013, -152.8000000000011, -400.0, 2.0000000000000013, -268.0, 26.690000000000225, -308.98, 2.0000000000000013, 2.0000000000000013, 123.05, 82.75999999999999, -16.089999999999833, 98.09, -400.0, 140.48, -206.14000000000078, 80.44999999999999, 14.779999999999962, 40.54999999999979, 27.05000000000016, 8.719999999999963, -10.51000000000003, -40.78000000000022, -18.460000000000008, 49.5199999999997, -20.109999999999708, 60.40999999999984, -22.119999999999706, -59.590000000000266, -10.060000000000041, 84.1700000000006, -116.25999999999962, -46.960000000000186, -38.23000000000034, -42.220000000000354, -14.080000000000041, -6.040000000000042, -0.00999999999999836, -3.4900000000000304, -44.23000000000015, -140.76999999999998, -325.0, -15.06999999999955, -42.220000000000006, -12.070000000000041, 10.669999999999964, -14.080000000000041, -282.69999999999993, -40.210000000000335, -5.11000000000004, -58.30000000000033, 2.0000000000000013, -349.0, 39.29000000000005, -22.65999999999998, -28.14999999999971, 2.299999999999996, -6.040000000000042, 47.45000000000017, 49.22, 2.0000000000000013, 20.480000000000164, -23.499999999999766, -8.230000000000038, 44.83999999999983, 98.03000000000051, 15.679999999999964, 48.82999999999985, 38.629999999999676, 40.24999999999976, 25.580000000000247, 84.83000000000034, 2.0000000000000013, 44.77999999999986, 49.96999999999981, 57.409999999999734, -43.81000000000021, -39.370000000000324, -146.73999999999938, 108.38000000000007, 18.560000000000244, 22.640000000000253, 3.5299999999999674, -22.119999999999706, 51.079999999999785, -51.70000000000026, 113.87000000000036, 116.39000000000009, 60.25999999999978, -70.95999999999947, 69.32000000000065, -18.099999999999703, 4.969999999999958, -21.549999999999844, -35.56000000000023, 14.719999999999963, 4.909999999999959, 23.300000000000203, -12.070000000000041, 61.18999999999977], "policy_predator_policy_reward": [8.0, 49.0, 77.0, 30.0, 8.0, 38.0, 0.0, 160.0, 20.0, 20.0, 1.0, 46.0, 2.0, 192.0, 48.0, 6.0, 200.0, 8.0, 120.0, 124.0, 1.0, 0.0, 200.0, 8.0, 23.0, 6.0, 18.0, 11.0, 6.0, 187.0, 200.0, 4.0, 200.0, 17.0, 10.0, 14.0, 8.0, 5.0, 2.0, 35.0, 41.0, 36.0, 22.0, 1.0, 48.0, 45.0, 3.0, 6.0, 2.0, 89.0, 65.0, 15.0, 65.0, 102.0, 24.0, 6.0, 25.0, 60.0, 68.0, 111.0, 0.0, 5.0, 200.0, 54.0, 0.0, 2.0, 51.0, 50.0, 3.0, 3.0, 3.0, 4.0, 12.0, 6.0, 119.0, 87.0, 1.0, 11.0, 11.0, 23.0, 1.0, 1.0, 4.0, 200.0, 200.0, 0.0, 10.0, 11.0, 6.0, 126.0, 17.0, 10.0, 6.0, 5.0, 1.0, 73.0, 116.0, 90.0, 5.0, 4.0, 119.0, 78.0, 200.0, 133.0, 156.0, 155.0, 169.0, 2.0, 24.0, 16.0, 10.0, 13.0, 200.0, 200.0, 107.0, 4.0, 17.0, 17.0, 0.0, 25.0, 0.0, 28.0, 91.0, 8.0, 11.0, 0.0, 12.0, 1.0, 39.0, 31.0, 76.0, 69.0, 11.0, 48.0, 9.0, 22.0, 4.0, 1.0, 11.0, 32.0, 16.0, 186.0, 27.0, 36.0, 8.0, 7.0, 33.0, 139.0, 21.0, 6.0, 30.0, 30.0, 16.0, 200.0, 7.0, 38.0, 6.0, 23.0, 9.0, 64.0, 44.0, 2.0, 25.0, 9.0, 0.0, 24.0, 3.0, 26.0, 2.0, 12.0, 11.0, 6.0, 3.0, 26.0, 17.0, 3.0, 29.0, 41.0, 74.0, 18.0, 9.0, 5.0, 17.0, 12.0, 15.0, 43.0, 15.0, 9.0, 32.0, 56.0, 10.0, 0.0, 0.0, 26.0, 17.0, 35.0, 16.0, 16.0, 12.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6801893252131623, "mean_inference_ms": 1.8050613959042878, "mean_action_processing_ms": 0.29022488551691084, "mean_env_wait_ms": 0.22791707811213244, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006395220756530762, "StateBufferConnector_ms": 0.0034373998641967773, "ViewRequirementAgentConnector_ms": 0.12216424942016602}, "num_episodes": 18, "episode_return_max": 332.28, "episode_return_min": -532.0, "episode_return_mean": 21.475900000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.14303494080315, "num_env_steps_trained_throughput_per_sec": 318.14303494080315, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 11587.235, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11587.183, "sample_time_ms": 1397.708, "learn_time_ms": 10171.693, "learn_throughput": 393.248, "synch_weights_time_ms": 14.594}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "310e1_00000", "date": "2024-08-15_01-11-35", "timestamp": 1723664495, "time_this_iter_s": 12.611272096633911, "time_total_s": 850.0305986404419, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1967dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 850.0305986404419, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 60.683333333333344, "ram_util_percent": 83.49444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.341031773065133, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6999866807902302, "policy_loss": -0.002688923447698394, "vf_loss": 1.7025058561216586, "vf_explained_var": 0.09727314445707533, "kl": 0.004526713822726806, "entropy": 0.5684470788669334, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.527618819285953, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.815790837403958, "policy_loss": -0.005182985223524233, "vf_loss": 4.820256558171025, "vf_explained_var": -0.43485491338861054, "kl": 0.010075038291040488, "entropy": 1.2009227608246777, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 254.25999999999934, "episode_reward_min": -456.87, "episode_reward_mean": 38.64149999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -17.469249999999995, "predator_policy": 36.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.100000000000083, 167.6599999999999, -27.780000000000083, -48.54000000000069, 197.41000000000003, 0.9399999999999819, 19.010000000000197, 106.35000000000018, -16.949999999999875, 2.4099999999999917, -12.54999999999977, -152.6700000000012, 189.02999999999975, -456.87, 190.0799999999997, 208.14000000000004, 3.9699999999999593, 157.31000000000012, 30.370000000000292, -2.999999999999991, 174.03999999999985, 86.48000000000015, 32.700000000000294, -194.00000000000034, -75.99000000000001, -8.27000000000007, -210.5600000000013, -7.1900000000000635, 2.939999999999982, 8.459999999999937, 33.0, 193.0299999999994, -132.6000000000011, -65.00000000000003, 69.69000000000044, -135.97999999999985, 165.05, 89.6700000000001, 98.09, 45.33999999999998, 129.2300000000002, 92.60000000000106, 26.210000000000424, 39.7600000000003, 40.40999999999941, 51.28999999999964, 0.35000000000004644, 112.91000000000096, -26.189999999999593, -25.299999999999425, -1.050000000000063, -4.719999999999997, -263.77, 5.709999999999632, 13.599999999999923, -124.78000000000016, -18.31999999999945, 3.6999999999999655, -93.71000000000001, -5.810000000000045, 25.26000000000044, 169.67000000000007, 68.48000000000005, 2.2700000000000102, 166.86999999999847, 93.51000000000086, 92.88000000000139, 127.410000000001, 75.78000000000068, 127.38000000000119, -13.180000000000092, 53.63999999999988, 55.19999999999937, 10.409999999999949, 57.37999999999953, 254.25999999999934, 77.30000000000102, 61.21999999999948, 9.419999999999957, 31.16000000000034, 60.209999999999454, 63.11999999999951, 129.5099999999991, 175.11999999999995, -46.510000000000595, 39.62999999999974, 98.62000000000013, 182.97999999999962, -25.249999999999755, -6.980000000000064, -101.97999999999986, 127.970000000001, -28.789999999999647, 225.5699999999996, 201.18999999999988, 218.08999999999926, 55.09999999999952, -32.90000000000044, 115.65000000000114, 195.23999999999936], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.080000000000041, -2.020000000000042, -68.34999999999916, 199.01, -104.77000000000002, -0.00999999999999836, -32.29000000000034, -39.25000000000035, -23.32000000000002, 127.73000000000005, -10.060000000000041, 2.0000000000000013, -2.020000000000042, -69.97000000000003, -128.6500000000009, 155.0, 35.65999999999967, -219.61000000000007, -35.260000000000346, 7.669999999999964, -87.4900000000001, -10.060000000000041, -217.0900000000005, -114.57999999999969, 182.03000000000003, 2.0000000000000013, -400.0, -310.87, 179.20999999999998, 8.86999999999996, 200.0, -92.85999999999942, -4.030000000000042, 2.0000000000000013, 124.63999999999999, 25.670000000000258, 22.43000000000022, -10.060000000000041, -211.0, 2.0000000000000013, 162.05, -0.00999999999999836, 54.50000000000004, -2.020000000000042, -0.00999999999999836, 30.710000000000264, -400.0, 2.0000000000000013, -400.0, 124.00999999999999, -12.070000000000041, -17.19999999999972, -124.95999999999978, -217.60000000000036, -12.070000000000041, -22.119999999999784, 2.0000000000000013, -10.060000000000041, -90.31000000000014, 24.770000000000245, -133.0, -40.0, 5.809999999999961, 178.21999999999989, -176.80000000000013, -152.8000000000011, -400.0, 2.0000000000000013, -268.0, 26.690000000000225, -308.98, 2.0000000000000013, 2.0000000000000013, 123.05, 82.75999999999999, -16.089999999999833, 98.09, -400.0, 140.48, -206.14000000000078, 80.44999999999999, 14.779999999999962, 40.54999999999979, 27.05000000000016, 8.719999999999963, -10.51000000000003, -40.78000000000022, -18.460000000000008, 49.5199999999997, -20.109999999999708, 60.40999999999984, -22.119999999999706, -59.590000000000266, -10.060000000000041, 84.1700000000006, -116.25999999999962, -46.960000000000186, -38.23000000000034, -42.220000000000354, -14.080000000000041, -6.040000000000042, -0.00999999999999836, -3.4900000000000304, -44.23000000000015, -140.76999999999998, -325.0, -15.06999999999955, -42.220000000000006, -12.070000000000041, 10.669999999999964, -14.080000000000041, -282.69999999999993, -40.210000000000335, -5.11000000000004, -58.30000000000033, 2.0000000000000013, -349.0, 39.29000000000005, -22.65999999999998, -28.14999999999971, 2.299999999999996, -6.040000000000042, 47.45000000000017, 49.22, 2.0000000000000013, 20.480000000000164, -23.499999999999766, -8.230000000000038, 44.83999999999983, 98.03000000000051, 15.679999999999964, 48.82999999999985, 38.629999999999676, 40.24999999999976, 25.580000000000247, 84.83000000000034, 2.0000000000000013, 44.77999999999986, 49.96999999999981, 57.409999999999734, -43.81000000000021, -39.370000000000324, -146.73999999999938, 108.38000000000007, 18.560000000000244, 22.640000000000253, 3.5299999999999674, -22.119999999999706, 51.079999999999785, -51.70000000000026, 113.87000000000036, 116.39000000000009, 60.25999999999978, -70.95999999999947, 69.32000000000065, -18.099999999999703, 4.969999999999958, -21.549999999999844, -35.56000000000023, 14.719999999999963, 4.909999999999959, 23.300000000000203, -12.070000000000041, 61.18999999999977, 74.09000000000053, 44.41999999999972, 152.12000000000006, 2.0000000000000013, -10.060000000000015, -88.4499999999992, -4.330000000000034, -6.040000000000042, -97.99, 34.609999999999694, 187.0999999999999, -22.119999999999713, -99.8199999999994, -3.430000000000005, -0.00999999999999836, -60.9700000000002, -4.030000000000042, -248.95000000000005, 19.820000000000118, 68.15000000000057, -81.51999999999977, -52.270000000000344, 101.09, 71.48000000000022, -53.860000000000014, 135.05, 180.07999999999998, -55.99000000000012, 33.13999999999978, -6.040000000000042, -2.020000000000042, -93.87999999999943, 41.08999999999983, 45.55999999999969, 133.1599999999999, 21.08000000000017], "policy_predator_policy_reward": [8.0, 5.0, 2.0, 35.0, 41.0, 36.0, 22.0, 1.0, 48.0, 45.0, 3.0, 6.0, 2.0, 89.0, 65.0, 15.0, 65.0, 102.0, 24.0, 6.0, 25.0, 60.0, 68.0, 111.0, 0.0, 5.0, 200.0, 54.0, 0.0, 2.0, 51.0, 50.0, 3.0, 3.0, 3.0, 4.0, 12.0, 6.0, 119.0, 87.0, 1.0, 11.0, 11.0, 23.0, 1.0, 1.0, 4.0, 200.0, 200.0, 0.0, 10.0, 11.0, 6.0, 126.0, 17.0, 10.0, 6.0, 5.0, 1.0, 73.0, 116.0, 90.0, 5.0, 4.0, 119.0, 78.0, 200.0, 133.0, 156.0, 155.0, 169.0, 2.0, 24.0, 16.0, 10.0, 13.0, 200.0, 200.0, 107.0, 4.0, 17.0, 17.0, 0.0, 25.0, 0.0, 28.0, 91.0, 8.0, 11.0, 0.0, 12.0, 1.0, 39.0, 31.0, 76.0, 69.0, 11.0, 48.0, 9.0, 22.0, 4.0, 1.0, 11.0, 32.0, 16.0, 186.0, 27.0, 36.0, 8.0, 7.0, 33.0, 139.0, 21.0, 6.0, 30.0, 30.0, 16.0, 200.0, 7.0, 38.0, 6.0, 23.0, 9.0, 64.0, 44.0, 2.0, 25.0, 9.0, 0.0, 24.0, 3.0, 26.0, 2.0, 12.0, 11.0, 6.0, 3.0, 26.0, 17.0, 3.0, 29.0, 41.0, 74.0, 18.0, 9.0, 5.0, 17.0, 12.0, 15.0, 43.0, 15.0, 9.0, 32.0, 56.0, 10.0, 0.0, 0.0, 26.0, 17.0, 35.0, 16.0, 16.0, 12.0, 2.0, 5.0, 6.0, 11.0, 10.0, 51.0, 1.0, 4.0, 46.0, 99.0, 63.0, 6.0, 12.0, 17.0, 61.0, 19.0, 35.0, 81.0, 70.0, 6.0, 34.0, 33.0, 72.0, 26.0, 27.0, 78.0, 42.0, 47.0, 47.0, 14.0, 14.0, 24.0, 39.0, 12.0, 17.0, 0.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6801131881538484, "mean_inference_ms": 1.8087952897495125, "mean_action_processing_ms": 0.28994779306609675, "mean_env_wait_ms": 0.22792082350338133, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006024956703186035, "StateBufferConnector_ms": 0.0034018754959106445, "ViewRequirementAgentConnector_ms": 0.1194157600402832}, "num_episodes": 18, "episode_return_max": 254.25999999999934, "episode_return_min": -456.87, "episode_return_mean": 38.64149999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.532539548919, "num_env_steps_trained_throughput_per_sec": 315.532539548919, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 11782.719, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11782.667, "sample_time_ms": 1424.445, "learn_time_ms": 10339.565, "learn_throughput": 386.863, "synch_weights_time_ms": 14.838}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "310e1_00000", "date": "2024-08-15_01-11-48", "timestamp": 1723664508, "time_this_iter_s": 12.716178178787231, "time_total_s": 862.7467768192291, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a1d700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 862.7467768192291, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 59.516666666666666, "ram_util_percent": 83.58333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.073289110483947, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6783838736001777, "policy_loss": -0.003393678252077686, "vf_loss": 1.6816122521799077, "vf_explained_var": 0.025042231183834175, "kl": 0.008815809807521788, "entropy": 0.6477652520414383, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.553480884227803, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.791556003610924, "policy_loss": -0.005335624262729965, "vf_loss": 5.7959059980180525, "vf_explained_var": 0.2766347256287065, "kl": 0.013844779711298879, "entropy": 1.1234798638908952, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -263.77, "episode_reward_mean": 62.988699999999966, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.03, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -2.4056499999999823, "predator_policy": 33.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.700000000000294, -194.00000000000034, -75.99000000000001, -8.27000000000007, -210.5600000000013, -7.1900000000000635, 2.939999999999982, 8.459999999999937, 33.0, 193.0299999999994, -132.6000000000011, -65.00000000000003, 69.69000000000044, -135.97999999999985, 165.05, 89.6700000000001, 98.09, 45.33999999999998, 129.2300000000002, 92.60000000000106, 26.210000000000424, 39.7600000000003, 40.40999999999941, 51.28999999999964, 0.35000000000004644, 112.91000000000096, -26.189999999999593, -25.299999999999425, -1.050000000000063, -4.719999999999997, -263.77, 5.709999999999632, 13.599999999999923, -124.78000000000016, -18.31999999999945, 3.6999999999999655, -93.71000000000001, -5.810000000000045, 25.26000000000044, 169.67000000000007, 68.48000000000005, 2.2700000000000102, 166.86999999999847, 93.51000000000086, 92.88000000000139, 127.410000000001, 75.78000000000068, 127.38000000000119, -13.180000000000092, 53.63999999999988, 55.19999999999937, 10.409999999999949, 57.37999999999953, 254.25999999999934, 77.30000000000102, 61.21999999999948, 9.419999999999957, 31.16000000000034, 60.209999999999454, 63.11999999999951, 129.5099999999991, 175.11999999999995, -46.510000000000595, 39.62999999999974, 98.62000000000013, 182.97999999999962, -25.249999999999755, -6.980000000000064, -101.97999999999986, 127.970000000001, -28.789999999999647, 225.5699999999996, 201.18999999999988, 218.08999999999926, 55.09999999999952, -32.90000000000044, 115.65000000000114, 195.23999999999936, -1.050000000000063, -44.48000000000064, 107.22000000000043, 71.57000000000001, 232.10999999999922, 187.13999999999976, 21.750000000000213, 29.590000000000522, 154.98000000000005, 157.24999999999943, 241.55999999999972, 247.40999999999968, 129.9000000000002, -10.140000000000082, 47.779999999999504, 276.08, 103.69000000000088, 319.2999999999998, 246.12999999999903, 262.7199999999994, 386.04999999999995, 79.90000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.00999999999999836, 30.710000000000264, -400.0, 2.0000000000000013, -400.0, 124.00999999999999, -12.070000000000041, -17.19999999999972, -124.95999999999978, -217.60000000000036, -12.070000000000041, -22.119999999999784, 2.0000000000000013, -10.060000000000041, -90.31000000000014, 24.770000000000245, -133.0, -40.0, 5.809999999999961, 178.21999999999989, -176.80000000000013, -152.8000000000011, -400.0, 2.0000000000000013, -268.0, 26.690000000000225, -308.98, 2.0000000000000013, 2.0000000000000013, 123.05, 82.75999999999999, -16.089999999999833, 98.09, -400.0, 140.48, -206.14000000000078, 80.44999999999999, 14.779999999999962, 40.54999999999979, 27.05000000000016, 8.719999999999963, -10.51000000000003, -40.78000000000022, -18.460000000000008, 49.5199999999997, -20.109999999999708, 60.40999999999984, -22.119999999999706, -59.590000000000266, -10.060000000000041, 84.1700000000006, -116.25999999999962, -46.960000000000186, -38.23000000000034, -42.220000000000354, -14.080000000000041, -6.040000000000042, -0.00999999999999836, -3.4900000000000304, -44.23000000000015, -140.76999999999998, -325.0, -15.06999999999955, -42.220000000000006, -12.070000000000041, 10.669999999999964, -14.080000000000041, -282.69999999999993, -40.210000000000335, -5.11000000000004, -58.30000000000033, 2.0000000000000013, -349.0, 39.29000000000005, -22.65999999999998, -28.14999999999971, 2.299999999999996, -6.040000000000042, 47.45000000000017, 49.22, 2.0000000000000013, 20.480000000000164, -23.499999999999766, -8.230000000000038, 44.83999999999983, 98.03000000000051, 15.679999999999964, 48.82999999999985, 38.629999999999676, 40.24999999999976, 25.580000000000247, 84.83000000000034, 2.0000000000000013, 44.77999999999986, 49.96999999999981, 57.409999999999734, -43.81000000000021, -39.370000000000324, -146.73999999999938, 108.38000000000007, 18.560000000000244, 22.640000000000253, 3.5299999999999674, -22.119999999999706, 51.079999999999785, -51.70000000000026, 113.87000000000036, 116.39000000000009, 60.25999999999978, -70.95999999999947, 69.32000000000065, -18.099999999999703, 4.969999999999958, -21.549999999999844, -35.56000000000023, 14.719999999999963, 4.909999999999959, 23.300000000000203, -12.070000000000041, 61.18999999999977, 74.09000000000053, 44.41999999999972, 152.12000000000006, 2.0000000000000013, -10.060000000000015, -88.4499999999992, -4.330000000000034, -6.040000000000042, -97.99, 34.609999999999694, 187.0999999999999, -22.119999999999713, -99.8199999999994, -3.430000000000005, -0.00999999999999836, -60.9700000000002, -4.030000000000042, -248.95000000000005, 19.820000000000118, 68.15000000000057, -81.51999999999977, -52.270000000000344, 101.09, 71.48000000000022, -53.860000000000014, 135.05, 180.07999999999998, -55.99000000000012, 33.13999999999978, -6.040000000000042, -2.020000000000042, -93.87999999999943, 41.08999999999983, 45.55999999999969, 133.1599999999999, 21.08000000000017, -0.00999999999999836, -6.040000000000042, -80.4099999999992, -12.070000000000041, 2.0000000000000013, 46.21999999999995, 2.5699999999999843, -73.0, 99.02000000000044, 74.09, 185.15000000000003, -0.00999999999999836, -19.179999999999875, -12.070000000000041, 29.630000000000255, -6.040000000000042, 131.03000000000003, -8.050000000000042, -22.119999999999706, 160.36999999999972, 60.52999999999993, 110.03, 67.03999999999999, 124.37000000000018, 87.11000000000003, 1.7900000000000011, -16.0899999999997, -8.050000000000042, 23.540000000000237, -12.760000000000026, 94.07000000000004, 133.01, 87.71000000000035, -2.020000000000042, 161.29999999999984, 131.0, 92.09000000000053, 121.04, 39.67999999999987, 166.04, 183.01999999999998, 197.03, -231.1600000000007, 194.05999999999997], "policy_predator_policy_reward": [1.0, 1.0, 4.0, 200.0, 200.0, 0.0, 10.0, 11.0, 6.0, 126.0, 17.0, 10.0, 6.0, 5.0, 1.0, 73.0, 116.0, 90.0, 5.0, 4.0, 119.0, 78.0, 200.0, 133.0, 156.0, 155.0, 169.0, 2.0, 24.0, 16.0, 10.0, 13.0, 200.0, 200.0, 107.0, 4.0, 17.0, 17.0, 0.0, 25.0, 0.0, 28.0, 91.0, 8.0, 11.0, 0.0, 12.0, 1.0, 39.0, 31.0, 76.0, 69.0, 11.0, 48.0, 9.0, 22.0, 4.0, 1.0, 11.0, 32.0, 16.0, 186.0, 27.0, 36.0, 8.0, 7.0, 33.0, 139.0, 21.0, 6.0, 30.0, 30.0, 16.0, 200.0, 7.0, 38.0, 6.0, 23.0, 9.0, 64.0, 44.0, 2.0, 25.0, 9.0, 0.0, 24.0, 3.0, 26.0, 2.0, 12.0, 11.0, 6.0, 3.0, 26.0, 17.0, 3.0, 29.0, 41.0, 74.0, 18.0, 9.0, 5.0, 17.0, 12.0, 15.0, 43.0, 15.0, 9.0, 32.0, 56.0, 10.0, 0.0, 0.0, 26.0, 17.0, 35.0, 16.0, 16.0, 12.0, 2.0, 5.0, 6.0, 11.0, 10.0, 51.0, 1.0, 4.0, 46.0, 99.0, 63.0, 6.0, 12.0, 17.0, 61.0, 19.0, 35.0, 81.0, 70.0, 6.0, 34.0, 33.0, 72.0, 26.0, 27.0, 78.0, 42.0, 47.0, 47.0, 14.0, 14.0, 24.0, 39.0, 12.0, 17.0, 0.0, 41.0, 1.0, 4.0, 7.0, 41.0, 19.0, 40.0, 69.0, 73.0, 39.0, 20.0, 1.0, 1.0, 7.0, 46.0, 4.0, 2.0, 15.0, 17.0, 6.0, 13.0, 41.0, 30.0, 25.0, 31.0, 10.0, 31.0, 5.0, 9.0, 7.0, 30.0, 16.0, 33.0, 14.0, 4.0, 6.0, 21.0, 8.0, 25.0, 27.0, 30.0, 5.0, 1.0, 3.0, 114.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6798229329347043, "mean_inference_ms": 1.814231257393411, "mean_action_processing_ms": 0.2891766952767815, "mean_env_wait_ms": 0.22806495149825765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005542755126953125, "StateBufferConnector_ms": 0.0033731460571289062, "ViewRequirementAgentConnector_ms": 0.12585484981536865}, "num_episodes": 22, "episode_return_max": 386.04999999999995, "episode_return_min": -263.77, "episode_return_mean": 62.988699999999966, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.7760046857392, "num_env_steps_trained_throughput_per_sec": 325.7760046857392, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 11914.523, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11914.471, "sample_time_ms": 1444.935, "learn_time_ms": 10450.531, "learn_throughput": 382.756, "synch_weights_time_ms": 14.955}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "310e1_00000", "date": "2024-08-15_01-12-01", "timestamp": 1723664521, "time_this_iter_s": 12.332284212112427, "time_total_s": 875.0790610313416, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b194ef70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 875.0790610313416, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 60.08888888888888, "ram_util_percent": 83.64444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6959678760281316, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2035134205742488, "policy_loss": -0.006219777145556041, "vf_loss": 1.2095721239450747, "vf_explained_var": 0.05288625025244617, "kl": 0.00859050896854047, "entropy": 0.6120816706191926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.859773527503644, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.551928258068347, "policy_loss": -0.0024094182639456696, "vf_loss": 6.5531040141191435, "vf_explained_var": 0.5554654269937485, "kl": 0.01732865327770772, "entropy": 1.0619138948501103, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -263.77, "episode_reward_mean": 99.2437, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -349.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.03, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 23.521850000000025, "predator_policy": 26.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [129.2300000000002, 92.60000000000106, 26.210000000000424, 39.7600000000003, 40.40999999999941, 51.28999999999964, 0.35000000000004644, 112.91000000000096, -26.189999999999593, -25.299999999999425, -1.050000000000063, -4.719999999999997, -263.77, 5.709999999999632, 13.599999999999923, -124.78000000000016, -18.31999999999945, 3.6999999999999655, -93.71000000000001, -5.810000000000045, 25.26000000000044, 169.67000000000007, 68.48000000000005, 2.2700000000000102, 166.86999999999847, 93.51000000000086, 92.88000000000139, 127.410000000001, 75.78000000000068, 127.38000000000119, -13.180000000000092, 53.63999999999988, 55.19999999999937, 10.409999999999949, 57.37999999999953, 254.25999999999934, 77.30000000000102, 61.21999999999948, 9.419999999999957, 31.16000000000034, 60.209999999999454, 63.11999999999951, 129.5099999999991, 175.11999999999995, -46.510000000000595, 39.62999999999974, 98.62000000000013, 182.97999999999962, -25.249999999999755, -6.980000000000064, -101.97999999999986, 127.970000000001, -28.789999999999647, 225.5699999999996, 201.18999999999988, 218.08999999999926, 55.09999999999952, -32.90000000000044, 115.65000000000114, 195.23999999999936, -1.050000000000063, -44.48000000000064, 107.22000000000043, 71.57000000000001, 232.10999999999922, 187.13999999999976, 21.750000000000213, 29.590000000000522, 154.98000000000005, 157.24999999999943, 241.55999999999972, 247.40999999999968, 129.9000000000002, -10.140000000000082, 47.779999999999504, 276.08, 103.69000000000088, 319.2999999999998, 246.12999999999903, 262.7199999999994, 386.04999999999995, 79.90000000000003, 183.99999999999977, 184.0599999999998, 130.03000000000026, 203.03000000000003, 275.2499999999999, 164.56999999999996, 294.31999999999977, 351.15, 235.14, 134.17999999999998, 233.35999999999905, 184.99999999999977, 156.1299999999981, 334.06, -116.51999999999921, 115.9100000000009, 351.03, 119.18000000000065], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [80.44999999999999, 14.779999999999962, 40.54999999999979, 27.05000000000016, 8.719999999999963, -10.51000000000003, -40.78000000000022, -18.460000000000008, 49.5199999999997, -20.109999999999708, 60.40999999999984, -22.119999999999706, -59.590000000000266, -10.060000000000041, 84.1700000000006, -116.25999999999962, -46.960000000000186, -38.23000000000034, -42.220000000000354, -14.080000000000041, -6.040000000000042, -0.00999999999999836, -3.4900000000000304, -44.23000000000015, -140.76999999999998, -325.0, -15.06999999999955, -42.220000000000006, -12.070000000000041, 10.669999999999964, -14.080000000000041, -282.69999999999993, -40.210000000000335, -5.11000000000004, -58.30000000000033, 2.0000000000000013, -349.0, 39.29000000000005, -22.65999999999998, -28.14999999999971, 2.299999999999996, -6.040000000000042, 47.45000000000017, 49.22, 2.0000000000000013, 20.480000000000164, -23.499999999999766, -8.230000000000038, 44.83999999999983, 98.03000000000051, 15.679999999999964, 48.82999999999985, 38.629999999999676, 40.24999999999976, 25.580000000000247, 84.83000000000034, 2.0000000000000013, 44.77999999999986, 49.96999999999981, 57.409999999999734, -43.81000000000021, -39.370000000000324, -146.73999999999938, 108.38000000000007, 18.560000000000244, 22.640000000000253, 3.5299999999999674, -22.119999999999706, 51.079999999999785, -51.70000000000026, 113.87000000000036, 116.39000000000009, 60.25999999999978, -70.95999999999947, 69.32000000000065, -18.099999999999703, 4.969999999999958, -21.549999999999844, -35.56000000000023, 14.719999999999963, 4.909999999999959, 23.300000000000203, -12.070000000000041, 61.18999999999977, 74.09000000000053, 44.41999999999972, 152.12000000000006, 2.0000000000000013, -10.060000000000015, -88.4499999999992, -4.330000000000034, -6.040000000000042, -97.99, 34.609999999999694, 187.0999999999999, -22.119999999999713, -99.8199999999994, -3.430000000000005, -0.00999999999999836, -60.9700000000002, -4.030000000000042, -248.95000000000005, 19.820000000000118, 68.15000000000057, -81.51999999999977, -52.270000000000344, 101.09, 71.48000000000022, -53.860000000000014, 135.05, 180.07999999999998, -55.99000000000012, 33.13999999999978, -6.040000000000042, -2.020000000000042, -93.87999999999943, 41.08999999999983, 45.55999999999969, 133.1599999999999, 21.08000000000017, -0.00999999999999836, -6.040000000000042, -80.4099999999992, -12.070000000000041, 2.0000000000000013, 46.21999999999995, 2.5699999999999843, -73.0, 99.02000000000044, 74.09, 185.15000000000003, -0.00999999999999836, -19.179999999999875, -12.070000000000041, 29.630000000000255, -6.040000000000042, 131.03000000000003, -8.050000000000042, -22.119999999999706, 160.36999999999972, 60.52999999999993, 110.03, 67.03999999999999, 124.37000000000018, 87.11000000000003, 1.7900000000000011, -16.0899999999997, -8.050000000000042, 23.540000000000237, -12.760000000000026, 94.07000000000004, 133.01, 87.71000000000035, -2.020000000000042, 161.29999999999984, 131.0, 92.09000000000053, 121.04, 39.67999999999987, 166.04, 183.01999999999998, 197.03, -231.1600000000007, 194.05999999999997, -2.020000000000042, 177.01999999999998, 2.0000000000000013, 164.06, 2.0000000000000013, 56.029999999999994, 106.00999999999999, 21.020000000000003, 108.07999999999998, 117.17000000000006, 190.10000000000002, -104.52999999999925, 87.02, 158.29999999999978, 188.12, 110.03, 126.08, 50.06000000000003, -2.020000000000042, 111.20000000000007, 86.0300000000005, 113.33000000000001, 170.03, -4.030000000000042, 83.03000000000053, 55.09999999999979, 73.01, 195.05, 2.0000000000000013, -282.52000000000044, 31.250000000000195, 29.6600000000001, 186.01999999999998, 139.01, -56.29000000000019, 135.4699999999996], "policy_predator_policy_reward": [17.0, 17.0, 0.0, 25.0, 0.0, 28.0, 91.0, 8.0, 11.0, 0.0, 12.0, 1.0, 39.0, 31.0, 76.0, 69.0, 11.0, 48.0, 9.0, 22.0, 4.0, 1.0, 11.0, 32.0, 16.0, 186.0, 27.0, 36.0, 8.0, 7.0, 33.0, 139.0, 21.0, 6.0, 30.0, 30.0, 16.0, 200.0, 7.0, 38.0, 6.0, 23.0, 9.0, 64.0, 44.0, 2.0, 25.0, 9.0, 0.0, 24.0, 3.0, 26.0, 2.0, 12.0, 11.0, 6.0, 3.0, 26.0, 17.0, 3.0, 29.0, 41.0, 74.0, 18.0, 9.0, 5.0, 17.0, 12.0, 15.0, 43.0, 15.0, 9.0, 32.0, 56.0, 10.0, 0.0, 0.0, 26.0, 17.0, 35.0, 16.0, 16.0, 12.0, 2.0, 5.0, 6.0, 11.0, 10.0, 51.0, 1.0, 4.0, 46.0, 99.0, 63.0, 6.0, 12.0, 17.0, 61.0, 19.0, 35.0, 81.0, 70.0, 6.0, 34.0, 33.0, 72.0, 26.0, 27.0, 78.0, 42.0, 47.0, 47.0, 14.0, 14.0, 24.0, 39.0, 12.0, 17.0, 0.0, 41.0, 1.0, 4.0, 7.0, 41.0, 19.0, 40.0, 69.0, 73.0, 39.0, 20.0, 1.0, 1.0, 7.0, 46.0, 4.0, 2.0, 15.0, 17.0, 6.0, 13.0, 41.0, 30.0, 25.0, 31.0, 10.0, 31.0, 5.0, 9.0, 7.0, 30.0, 16.0, 33.0, 14.0, 4.0, 6.0, 21.0, 8.0, 25.0, 27.0, 30.0, 5.0, 1.0, 3.0, 114.0, 7.0, 2.0, 8.0, 10.0, 47.0, 25.0, 17.0, 59.0, 22.0, 28.0, 26.0, 53.0, 37.0, 12.0, 24.0, 29.0, 48.0, 11.0, 23.0, 2.0, 18.0, 16.0, 7.0, 12.0, 12.0, 6.0, 26.0, 40.0, 19.0, 145.0, 36.0, 19.0, 20.0, 6.0, 5.0, 35.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6800169811887565, "mean_inference_ms": 1.818817125677593, "mean_action_processing_ms": 0.2893713065479617, "mean_env_wait_ms": 0.2279153346588386, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004938840866088867, "StateBufferConnector_ms": 0.003472566604614258, "ViewRequirementAgentConnector_ms": 0.13688814640045166}, "num_episodes": 18, "episode_return_max": 386.04999999999995, "episode_return_min": -263.77, "episode_return_mean": 99.2437, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.68816832075953, "num_env_steps_trained_throughput_per_sec": 321.68816832075953, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 12061.669, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12061.614, "sample_time_ms": 1489.75, "learn_time_ms": 10552.93, "learn_throughput": 379.042, "synch_weights_time_ms": 15.225}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "310e1_00000", "date": "2024-08-15_01-12-13", "timestamp": 1723664533, "time_this_iter_s": 12.488978862762451, "time_total_s": 887.568039894104, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19f4310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 887.568039894104, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 59.85294117647059, "ram_util_percent": 83.2764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6720250047388532, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4510782426627225, "policy_loss": -0.004696965562031856, "vf_loss": 1.4556169612697822, "vf_explained_var": 0.015120783337840327, "kl": 0.00843982502832748, "entropy": 0.5014277849878583, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.254151445469528, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.370955124103203, "policy_loss": -0.0053734360772761565, "vf_loss": 7.375266961950474, "vf_explained_var": 0.49015779583542435, "kl": 0.014912071957445565, "entropy": 0.9886392157859903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -116.51999999999921, "episode_reward_mean": 150.62079999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -282.52000000000044, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.01999999999998, "predator_policy": 145.0}, "policy_reward_mean": {"prey_policy": 51.61040000000003, "predator_policy": 23.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.2700000000000102, 166.86999999999847, 93.51000000000086, 92.88000000000139, 127.410000000001, 75.78000000000068, 127.38000000000119, -13.180000000000092, 53.63999999999988, 55.19999999999937, 10.409999999999949, 57.37999999999953, 254.25999999999934, 77.30000000000102, 61.21999999999948, 9.419999999999957, 31.16000000000034, 60.209999999999454, 63.11999999999951, 129.5099999999991, 175.11999999999995, -46.510000000000595, 39.62999999999974, 98.62000000000013, 182.97999999999962, -25.249999999999755, -6.980000000000064, -101.97999999999986, 127.970000000001, -28.789999999999647, 225.5699999999996, 201.18999999999988, 218.08999999999926, 55.09999999999952, -32.90000000000044, 115.65000000000114, 195.23999999999936, -1.050000000000063, -44.48000000000064, 107.22000000000043, 71.57000000000001, 232.10999999999922, 187.13999999999976, 21.750000000000213, 29.590000000000522, 154.98000000000005, 157.24999999999943, 241.55999999999972, 247.40999999999968, 129.9000000000002, -10.140000000000082, 47.779999999999504, 276.08, 103.69000000000088, 319.2999999999998, 246.12999999999903, 262.7199999999994, 386.04999999999995, 79.90000000000003, 183.99999999999977, 184.0599999999998, 130.03000000000026, 203.03000000000003, 275.2499999999999, 164.56999999999996, 294.31999999999977, 351.15, 235.14, 134.17999999999998, 233.35999999999905, 184.99999999999977, 156.1299999999981, 334.06, -116.51999999999921, 115.9100000000009, 351.03, 119.18000000000065, 305.7499999999995, 292.11999999999995, 322.05, 168.04999999999995, 155.08000000000007, 344.21999999999986, 235.24, 130.02000000000032, 254.80999999999935, 287.5999999999995, 91.08000000000013, 363.26999999999987, 125.04, 184.88999999999976, 305.5499999999996, 351.03, 266.6399999999995, 181.00999999999976, 175.00999999999982, 270.06999999999994, 115.94000000000028, 67.70000000000009, 361.07], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-23.499999999999766, -8.230000000000038, 44.83999999999983, 98.03000000000051, 15.679999999999964, 48.82999999999985, 38.629999999999676, 40.24999999999976, 25.580000000000247, 84.83000000000034, 2.0000000000000013, 44.77999999999986, 49.96999999999981, 57.409999999999734, -43.81000000000021, -39.370000000000324, -146.73999999999938, 108.38000000000007, 18.560000000000244, 22.640000000000253, 3.5299999999999674, -22.119999999999706, 51.079999999999785, -51.70000000000026, 113.87000000000036, 116.39000000000009, 60.25999999999978, -70.95999999999947, 69.32000000000065, -18.099999999999703, 4.969999999999958, -21.549999999999844, -35.56000000000023, 14.719999999999963, 4.909999999999959, 23.300000000000203, -12.070000000000041, 61.18999999999977, 74.09000000000053, 44.41999999999972, 152.12000000000006, 2.0000000000000013, -10.060000000000015, -88.4499999999992, -4.330000000000034, -6.040000000000042, -97.99, 34.609999999999694, 187.0999999999999, -22.119999999999713, -99.8199999999994, -3.430000000000005, -0.00999999999999836, -60.9700000000002, -4.030000000000042, -248.95000000000005, 19.820000000000118, 68.15000000000057, -81.51999999999977, -52.270000000000344, 101.09, 71.48000000000022, -53.860000000000014, 135.05, 180.07999999999998, -55.99000000000012, 33.13999999999978, -6.040000000000042, -2.020000000000042, -93.87999999999943, 41.08999999999983, 45.55999999999969, 133.1599999999999, 21.08000000000017, -0.00999999999999836, -6.040000000000042, -80.4099999999992, -12.070000000000041, 2.0000000000000013, 46.21999999999995, 2.5699999999999843, -73.0, 99.02000000000044, 74.09, 185.15000000000003, -0.00999999999999836, -19.179999999999875, -12.070000000000041, 29.630000000000255, -6.040000000000042, 131.03000000000003, -8.050000000000042, -22.119999999999706, 160.36999999999972, 60.52999999999993, 110.03, 67.03999999999999, 124.37000000000018, 87.11000000000003, 1.7900000000000011, -16.0899999999997, -8.050000000000042, 23.540000000000237, -12.760000000000026, 94.07000000000004, 133.01, 87.71000000000035, -2.020000000000042, 161.29999999999984, 131.0, 92.09000000000053, 121.04, 39.67999999999987, 166.04, 183.01999999999998, 197.03, -231.1600000000007, 194.05999999999997, -2.020000000000042, 177.01999999999998, 2.0000000000000013, 164.06, 2.0000000000000013, 56.029999999999994, 106.00999999999999, 21.020000000000003, 108.07999999999998, 117.17000000000006, 190.10000000000002, -104.52999999999925, 87.02, 158.29999999999978, 188.12, 110.03, 126.08, 50.06000000000003, -2.020000000000042, 111.20000000000007, 86.0300000000005, 113.33000000000001, 170.03, -4.030000000000042, 83.03000000000053, 55.09999999999979, 73.01, 195.05, 2.0000000000000013, -282.52000000000044, 31.250000000000195, 29.6600000000001, 186.01999999999998, 139.01, -56.29000000000019, 135.4699999999996, 165.14, 127.6100000000003, 107.06, 149.06, 74.03000000000002, 180.01999999999998, -2.020000000000042, 145.07, 135.11, -4.030000000000042, 160.21999999999986, 167.0, 140.09000000000003, -30.85000000000001, 2.0000000000000013, 78.02, 158.06, 68.75000000000037, 72.59000000000026, 187.01, -190.9600000000002, 181.04000000000002, 172.18999999999986, 186.07999999999998, -34.96000000000001, 41.0, 193.01, -22.119999999999852, 186.14000000000001, 81.41000000000015, 159.02, 172.01, 91.03999999999999, 140.5999999999995, 2.0000000000000013, 163.01, -6.040000000000042, 168.04999999999998, 49.010000000000005, 110.06000000000002, 80.0, -10.060000000000041, 48.01999999999999, -62.32000000000033, 198.01999999999998, 147.05], "policy_predator_policy_reward": [25.0, 9.0, 0.0, 24.0, 3.0, 26.0, 2.0, 12.0, 11.0, 6.0, 3.0, 26.0, 17.0, 3.0, 29.0, 41.0, 74.0, 18.0, 9.0, 5.0, 17.0, 12.0, 15.0, 43.0, 15.0, 9.0, 32.0, 56.0, 10.0, 0.0, 0.0, 26.0, 17.0, 35.0, 16.0, 16.0, 12.0, 2.0, 5.0, 6.0, 11.0, 10.0, 51.0, 1.0, 4.0, 46.0, 99.0, 63.0, 6.0, 12.0, 17.0, 61.0, 19.0, 35.0, 81.0, 70.0, 6.0, 34.0, 33.0, 72.0, 26.0, 27.0, 78.0, 42.0, 47.0, 47.0, 14.0, 14.0, 24.0, 39.0, 12.0, 17.0, 0.0, 41.0, 1.0, 4.0, 7.0, 41.0, 19.0, 40.0, 69.0, 73.0, 39.0, 20.0, 1.0, 1.0, 7.0, 46.0, 4.0, 2.0, 15.0, 17.0, 6.0, 13.0, 41.0, 30.0, 25.0, 31.0, 10.0, 31.0, 5.0, 9.0, 7.0, 30.0, 16.0, 33.0, 14.0, 4.0, 6.0, 21.0, 8.0, 25.0, 27.0, 30.0, 5.0, 1.0, 3.0, 114.0, 7.0, 2.0, 8.0, 10.0, 47.0, 25.0, 17.0, 59.0, 22.0, 28.0, 26.0, 53.0, 37.0, 12.0, 24.0, 29.0, 48.0, 11.0, 23.0, 2.0, 18.0, 16.0, 7.0, 12.0, 12.0, 6.0, 26.0, 40.0, 19.0, 145.0, 36.0, 19.0, 20.0, 6.0, 5.0, 35.0, 4.0, 9.0, 7.0, 29.0, 42.0, 26.0, 11.0, 14.0, 16.0, 8.0, 11.0, 6.0, 77.0, 49.0, 40.0, 10.0, 9.0, 19.0, 20.0, 8.0, 5.0, 96.0, 2.0, 3.0, 21.0, 98.0, 14.0, 0.0, 12.0, 26.0, 13.0, 7.0, 0.0, 35.0, 4.0, 12.0, 9.0, 4.0, 63.0, 48.0, 33.0, 13.0, 32.0, 50.0, 0.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6798720427545016, "mean_inference_ms": 1.8242416938443653, "mean_action_processing_ms": 0.2889679676573989, "mean_env_wait_ms": 0.22783354685368087, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004511713981628418, "StateBufferConnector_ms": 0.003977775573730469, "ViewRequirementAgentConnector_ms": 0.12327909469604492}, "num_episodes": 23, "episode_return_max": 386.04999999999995, "episode_return_min": -116.51999999999921, "episode_return_mean": 150.62079999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 327.0125622508747, "num_env_steps_trained_throughput_per_sec": 327.0125622508747, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 12171.481, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12171.425, "sample_time_ms": 1519.632, "learn_time_ms": 10631.939, "learn_throughput": 376.225, "synch_weights_time_ms": 15.726}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "310e1_00000", "date": "2024-08-15_01-12-25", "timestamp": 1723664545, "time_this_iter_s": 12.263895750045776, "time_total_s": 899.8319356441498, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1995a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 899.8319356441498, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 58.28888888888889, "ram_util_percent": 83.22777777777779}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.255703677276455, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3513792101352935, "policy_loss": -0.0023985392767591055, "vf_loss": 1.3535899907192857, "vf_explained_var": 0.023836836739191933, "kl": 0.010013870974174737, "entropy": 0.5381472041209538, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.278687581940303, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.762779248454583, "policy_loss": -0.007566756025700776, "vf_loss": 6.769298313534449, "vf_explained_var": 0.5373081322069522, "kl": 0.0147165458567472, "entropy": 1.007972349376275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -116.51999999999921, "episode_reward_mean": 173.25399999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.01999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 61.96700000000001, "predator_policy": 24.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [63.11999999999951, 129.5099999999991, 175.11999999999995, -46.510000000000595, 39.62999999999974, 98.62000000000013, 182.97999999999962, -25.249999999999755, -6.980000000000064, -101.97999999999986, 127.970000000001, -28.789999999999647, 225.5699999999996, 201.18999999999988, 218.08999999999926, 55.09999999999952, -32.90000000000044, 115.65000000000114, 195.23999999999936, -1.050000000000063, -44.48000000000064, 107.22000000000043, 71.57000000000001, 232.10999999999922, 187.13999999999976, 21.750000000000213, 29.590000000000522, 154.98000000000005, 157.24999999999943, 241.55999999999972, 247.40999999999968, 129.9000000000002, -10.140000000000082, 47.779999999999504, 276.08, 103.69000000000088, 319.2999999999998, 246.12999999999903, 262.7199999999994, 386.04999999999995, 79.90000000000003, 183.99999999999977, 184.0599999999998, 130.03000000000026, 203.03000000000003, 275.2499999999999, 164.56999999999996, 294.31999999999977, 351.15, 235.14, 134.17999999999998, 233.35999999999905, 184.99999999999977, 156.1299999999981, 334.06, -116.51999999999921, 115.9100000000009, 351.03, 119.18000000000065, 305.7499999999995, 292.11999999999995, 322.05, 168.04999999999995, 155.08000000000007, 344.21999999999986, 235.24, 130.02000000000032, 254.80999999999935, 287.5999999999995, 91.08000000000013, 363.26999999999987, 125.04, 184.88999999999976, 305.5499999999996, 351.03, 266.6399999999995, 181.00999999999976, 175.00999999999982, 270.06999999999994, 115.94000000000028, 67.70000000000009, 361.07, 331.04999999999995, 229.15000000000006, 144.51000000000016, 336.15, 358.08, 177.99999999999983, 187.0699999999997, 189.99999999999972, 109.3000000000002, 366.21999999999997, 258.25, 142.01000000000016, -1.050000000000063, -17.94, 176.0999999999998, -48.86999999999963, 320.3299999999999, 348.08], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-12.070000000000041, 61.18999999999977, 74.09000000000053, 44.41999999999972, 152.12000000000006, 2.0000000000000013, -10.060000000000015, -88.4499999999992, -4.330000000000034, -6.040000000000042, -97.99, 34.609999999999694, 187.0999999999999, -22.119999999999713, -99.8199999999994, -3.430000000000005, -0.00999999999999836, -60.9700000000002, -4.030000000000042, -248.95000000000005, 19.820000000000118, 68.15000000000057, -81.51999999999977, -52.270000000000344, 101.09, 71.48000000000022, -53.860000000000014, 135.05, 180.07999999999998, -55.99000000000012, 33.13999999999978, -6.040000000000042, -2.020000000000042, -93.87999999999943, 41.08999999999983, 45.55999999999969, 133.1599999999999, 21.08000000000017, -0.00999999999999836, -6.040000000000042, -80.4099999999992, -12.070000000000041, 2.0000000000000013, 46.21999999999995, 2.5699999999999843, -73.0, 99.02000000000044, 74.09, 185.15000000000003, -0.00999999999999836, -19.179999999999875, -12.070000000000041, 29.630000000000255, -6.040000000000042, 131.03000000000003, -8.050000000000042, -22.119999999999706, 160.36999999999972, 60.52999999999993, 110.03, 67.03999999999999, 124.37000000000018, 87.11000000000003, 1.7900000000000011, -16.0899999999997, -8.050000000000042, 23.540000000000237, -12.760000000000026, 94.07000000000004, 133.01, 87.71000000000035, -2.020000000000042, 161.29999999999984, 131.0, 92.09000000000053, 121.04, 39.67999999999987, 166.04, 183.01999999999998, 197.03, -231.1600000000007, 194.05999999999997, -2.020000000000042, 177.01999999999998, 2.0000000000000013, 164.06, 2.0000000000000013, 56.029999999999994, 106.00999999999999, 21.020000000000003, 108.07999999999998, 117.17000000000006, 190.10000000000002, -104.52999999999925, 87.02, 158.29999999999978, 188.12, 110.03, 126.08, 50.06000000000003, -2.020000000000042, 111.20000000000007, 86.0300000000005, 113.33000000000001, 170.03, -4.030000000000042, 83.03000000000053, 55.09999999999979, 73.01, 195.05, 2.0000000000000013, -282.52000000000044, 31.250000000000195, 29.6600000000001, 186.01999999999998, 139.01, -56.29000000000019, 135.4699999999996, 165.14, 127.6100000000003, 107.06, 149.06, 74.03000000000002, 180.01999999999998, -2.020000000000042, 145.07, 135.11, -4.030000000000042, 160.21999999999986, 167.0, 140.09000000000003, -30.85000000000001, 2.0000000000000013, 78.02, 158.06, 68.75000000000037, 72.59000000000026, 187.01, -190.9600000000002, 181.04000000000002, 172.18999999999986, 186.07999999999998, -34.96000000000001, 41.0, 193.01, -22.119999999999852, 186.14000000000001, 81.41000000000015, 159.02, 172.01, 91.03999999999999, 140.5999999999995, 2.0000000000000013, 163.01, -6.040000000000042, 168.04999999999998, 49.010000000000005, 110.06000000000002, 80.0, -10.060000000000041, 48.01999999999999, -62.32000000000033, 198.01999999999998, 147.05, 177.01999999999998, 125.03000000000002, 86.09000000000003, 83.06, -98.49999999999939, 190.01, 176.0, 128.15, 167.03, 174.05, 2.0000000000000013, 164.0, 172.07, 2.0000000000000013, 2.0000000000000013, 179.0, 177.05, -148.75000000000065, 165.04999999999998, 183.17, 114.11000000000003, 78.13999999999999, 105.05000000000001, -6.040000000000042, -4.030000000000042, -2.020000000000042, 176.06, -400.0, 166.09999999999997, 2.0000000000000013, -162.79000000000002, -14.080000000000041, 85.31, 183.02, 132.07999999999998, 194.0], "policy_predator_policy_reward": [12.0, 2.0, 5.0, 6.0, 11.0, 10.0, 51.0, 1.0, 4.0, 46.0, 99.0, 63.0, 6.0, 12.0, 17.0, 61.0, 19.0, 35.0, 81.0, 70.0, 6.0, 34.0, 33.0, 72.0, 26.0, 27.0, 78.0, 42.0, 47.0, 47.0, 14.0, 14.0, 24.0, 39.0, 12.0, 17.0, 0.0, 41.0, 1.0, 4.0, 7.0, 41.0, 19.0, 40.0, 69.0, 73.0, 39.0, 20.0, 1.0, 1.0, 7.0, 46.0, 4.0, 2.0, 15.0, 17.0, 6.0, 13.0, 41.0, 30.0, 25.0, 31.0, 10.0, 31.0, 5.0, 9.0, 7.0, 30.0, 16.0, 33.0, 14.0, 4.0, 6.0, 21.0, 8.0, 25.0, 27.0, 30.0, 5.0, 1.0, 3.0, 114.0, 7.0, 2.0, 8.0, 10.0, 47.0, 25.0, 17.0, 59.0, 22.0, 28.0, 26.0, 53.0, 37.0, 12.0, 24.0, 29.0, 48.0, 11.0, 23.0, 2.0, 18.0, 16.0, 7.0, 12.0, 12.0, 6.0, 26.0, 40.0, 19.0, 145.0, 36.0, 19.0, 20.0, 6.0, 5.0, 35.0, 4.0, 9.0, 7.0, 29.0, 42.0, 26.0, 11.0, 14.0, 16.0, 8.0, 11.0, 6.0, 77.0, 49.0, 40.0, 10.0, 9.0, 19.0, 20.0, 8.0, 5.0, 96.0, 2.0, 3.0, 21.0, 98.0, 14.0, 0.0, 12.0, 26.0, 13.0, 7.0, 0.0, 35.0, 4.0, 12.0, 9.0, 4.0, 63.0, 48.0, 33.0, 13.0, 32.0, 50.0, 0.0, 16.0, 24.0, 5.0, 23.0, 37.0, 3.0, 50.0, 24.0, 8.0, 5.0, 12.0, 12.0, 0.0, 7.0, 6.0, 2.0, 7.0, 6.0, 75.0, 8.0, 10.0, 49.0, 17.0, 33.0, 10.0, 2.0, 3.0, 6.0, 200.0, 8.0, 0.0, 96.0, 32.0, 26.0, 26.0, 20.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6796514966351991, "mean_inference_ms": 1.828029938080132, "mean_action_processing_ms": 0.28864509891073387, "mean_env_wait_ms": 0.22773509753172896, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004447817802429199, "StateBufferConnector_ms": 0.004003643989562988, "ViewRequirementAgentConnector_ms": 0.12166690826416016}, "num_episodes": 18, "episode_return_max": 386.04999999999995, "episode_return_min": -116.51999999999921, "episode_return_mean": 173.25399999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.7722897909371, "num_env_steps_trained_throughput_per_sec": 323.7722897909371, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 12291.781, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12291.725, "sample_time_ms": 1540.298, "learn_time_ms": 10731.052, "learn_throughput": 372.75, "synch_weights_time_ms": 16.158}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "310e1_00000", "date": "2024-08-15_01-12-38", "timestamp": 1723664558, "time_this_iter_s": 12.389783143997192, "time_total_s": 912.221718788147, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1995820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 912.221718788147, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 60.05882352941177, "ram_util_percent": 83.04117647058824}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0439395372199003, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8707814213302401, "policy_loss": -0.00294458328440746, "vf_loss": 0.8735593462116504, "vf_explained_var": 0.035798004096147244, "kl": 0.008888416037602794, "entropy": 0.635345275502987, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.675061343334339, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.679610532679885, "policy_loss": -0.00644744341581981, "vf_loss": 6.685401194940799, "vf_explained_var": 0.4637832113043972, "kl": 0.009225858057805745, "entropy": 0.9711410033009039, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -198.00000000000034, "episode_reward_mean": 210.91239999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 82.94120000000001, "predator_policy": 22.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [71.57000000000001, 232.10999999999922, 187.13999999999976, 21.750000000000213, 29.590000000000522, 154.98000000000005, 157.24999999999943, 241.55999999999972, 247.40999999999968, 129.9000000000002, -10.140000000000082, 47.779999999999504, 276.08, 103.69000000000088, 319.2999999999998, 246.12999999999903, 262.7199999999994, 386.04999999999995, 79.90000000000003, 183.99999999999977, 184.0599999999998, 130.03000000000026, 203.03000000000003, 275.2499999999999, 164.56999999999996, 294.31999999999977, 351.15, 235.14, 134.17999999999998, 233.35999999999905, 184.99999999999977, 156.1299999999981, 334.06, -116.51999999999921, 115.9100000000009, 351.03, 119.18000000000065, 305.7499999999995, 292.11999999999995, 322.05, 168.04999999999995, 155.08000000000007, 344.21999999999986, 235.24, 130.02000000000032, 254.80999999999935, 287.5999999999995, 91.08000000000013, 363.26999999999987, 125.04, 184.88999999999976, 305.5499999999996, 351.03, 266.6399999999995, 181.00999999999976, 175.00999999999982, 270.06999999999994, 115.94000000000028, 67.70000000000009, 361.07, 331.04999999999995, 229.15000000000006, 144.51000000000016, 336.15, 358.08, 177.99999999999983, 187.0699999999997, 189.99999999999972, 109.3000000000002, 366.21999999999997, 258.25, 142.01000000000016, -1.050000000000063, -17.94, 176.0999999999998, -48.86999999999963, 320.3299999999999, 348.08, 368.16999999999996, 369.28000000000003, 268.4, 341.21, 134.02000000000027, -198.00000000000034, 272.97999999999934, -3.060000000000084, 154.95000000000005, 300.11, 319.25, 104.16000000000017, 297.17999999999995, 304.09999999999997, 362.08, 365.24999999999994, 208.23000000000002, 255.30999999999997, 330.19, 320.01, 169.0499999999999, 370.03999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.5699999999999843, -73.0, 99.02000000000044, 74.09, 185.15000000000003, -0.00999999999999836, -19.179999999999875, -12.070000000000041, 29.630000000000255, -6.040000000000042, 131.03000000000003, -8.050000000000042, -22.119999999999706, 160.36999999999972, 60.52999999999993, 110.03, 67.03999999999999, 124.37000000000018, 87.11000000000003, 1.7900000000000011, -16.0899999999997, -8.050000000000042, 23.540000000000237, -12.760000000000026, 94.07000000000004, 133.01, 87.71000000000035, -2.020000000000042, 161.29999999999984, 131.0, 92.09000000000053, 121.04, 39.67999999999987, 166.04, 183.01999999999998, 197.03, -231.1600000000007, 194.05999999999997, -2.020000000000042, 177.01999999999998, 2.0000000000000013, 164.06, 2.0000000000000013, 56.029999999999994, 106.00999999999999, 21.020000000000003, 108.07999999999998, 117.17000000000006, 190.10000000000002, -104.52999999999925, 87.02, 158.29999999999978, 188.12, 110.03, 126.08, 50.06000000000003, -2.020000000000042, 111.20000000000007, 86.0300000000005, 113.33000000000001, 170.03, -4.030000000000042, 83.03000000000053, 55.09999999999979, 73.01, 195.05, 2.0000000000000013, -282.52000000000044, 31.250000000000195, 29.6600000000001, 186.01999999999998, 139.01, -56.29000000000019, 135.4699999999996, 165.14, 127.6100000000003, 107.06, 149.06, 74.03000000000002, 180.01999999999998, -2.020000000000042, 145.07, 135.11, -4.030000000000042, 160.21999999999986, 167.0, 140.09000000000003, -30.85000000000001, 2.0000000000000013, 78.02, 158.06, 68.75000000000037, 72.59000000000026, 187.01, -190.9600000000002, 181.04000000000002, 172.18999999999986, 186.07999999999998, -34.96000000000001, 41.0, 193.01, -22.119999999999852, 186.14000000000001, 81.41000000000015, 159.02, 172.01, 91.03999999999999, 140.5999999999995, 2.0000000000000013, 163.01, -6.040000000000042, 168.04999999999998, 49.010000000000005, 110.06000000000002, 80.0, -10.060000000000041, 48.01999999999999, -62.32000000000033, 198.01999999999998, 147.05, 177.01999999999998, 125.03000000000002, 86.09000000000003, 83.06, -98.49999999999939, 190.01, 176.0, 128.15, 167.03, 174.05, 2.0000000000000013, 164.0, 172.07, 2.0000000000000013, 2.0000000000000013, 179.0, 177.05, -148.75000000000065, 165.04999999999998, 183.17, 114.11000000000003, 78.13999999999999, 105.05000000000001, -6.040000000000042, -4.030000000000042, -2.020000000000042, 176.06, -400.0, 166.09999999999997, 2.0000000000000013, -162.79000000000002, -14.080000000000041, 85.31, 183.02, 132.07999999999998, 194.0, 154.16000000000003, 199.01, 185.06, 178.21999999999997, 128.21000000000004, 103.19000000000001, 183.04999999999998, 139.16000000000003, -24.129999999999708, 125.14999999999999, -400.0, 2.0000000000000013, 119.7800000000004, 138.2, -6.040000000000042, -2.020000000000042, 178.22, -52.27000000000031, 127.01, 136.10000000000002, 143.15000000000003, 151.10000000000002, -4.030000000000042, 67.19, 189.01999999999998, 55.160000000000046, 149.03, 67.07, 166.07, 181.01, 176.23999999999995, 184.01, 57.230000000000004, 59.0, 140.09, 58.22000000000009, 129.07999999999998, 174.11, 146.0, 151.01, 2.0000000000000013, 132.04999999999998, 191.02999999999997, 169.01], "policy_predator_policy_reward": [69.0, 73.0, 39.0, 20.0, 1.0, 1.0, 7.0, 46.0, 4.0, 2.0, 15.0, 17.0, 6.0, 13.0, 41.0, 30.0, 25.0, 31.0, 10.0, 31.0, 5.0, 9.0, 7.0, 30.0, 16.0, 33.0, 14.0, 4.0, 6.0, 21.0, 8.0, 25.0, 27.0, 30.0, 5.0, 1.0, 3.0, 114.0, 7.0, 2.0, 8.0, 10.0, 47.0, 25.0, 17.0, 59.0, 22.0, 28.0, 26.0, 53.0, 37.0, 12.0, 24.0, 29.0, 48.0, 11.0, 23.0, 2.0, 18.0, 16.0, 7.0, 12.0, 12.0, 6.0, 26.0, 40.0, 19.0, 145.0, 36.0, 19.0, 20.0, 6.0, 5.0, 35.0, 4.0, 9.0, 7.0, 29.0, 42.0, 26.0, 11.0, 14.0, 16.0, 8.0, 11.0, 6.0, 77.0, 49.0, 40.0, 10.0, 9.0, 19.0, 20.0, 8.0, 5.0, 96.0, 2.0, 3.0, 21.0, 98.0, 14.0, 0.0, 12.0, 26.0, 13.0, 7.0, 0.0, 35.0, 4.0, 12.0, 9.0, 4.0, 63.0, 48.0, 33.0, 13.0, 32.0, 50.0, 0.0, 16.0, 24.0, 5.0, 23.0, 37.0, 3.0, 50.0, 24.0, 8.0, 5.0, 12.0, 12.0, 0.0, 7.0, 6.0, 2.0, 7.0, 6.0, 75.0, 8.0, 10.0, 49.0, 17.0, 33.0, 10.0, 2.0, 3.0, 6.0, 200.0, 8.0, 0.0, 96.0, 32.0, 26.0, 26.0, 20.0, 2.0, 10.0, 5.0, 3.0, 3.0, 25.0, 12.0, 15.0, 4.0, 13.0, 20.0, 0.0, 200.0, 14.0, 1.0, 1.0, 4.0, 2.0, 27.0, 17.0, 20.0, 19.0, 6.0, 3.0, 38.0, 33.0, 20.0, 44.0, 44.0, 6.0, 9.0, 0.0, 5.0, 87.0, 5.0, 17.0, 40.0, 6.0, 21.0, 0.0, 23.0, 14.0, 21.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.679333860507645, "mean_inference_ms": 1.8323931548567287, "mean_action_processing_ms": 0.28785590195129274, "mean_env_wait_ms": 0.22780264376669065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00403141975402832, "StateBufferConnector_ms": 0.004000067710876465, "ViewRequirementAgentConnector_ms": 0.11984789371490479}, "num_episodes": 22, "episode_return_max": 386.04999999999995, "episode_return_min": -198.00000000000034, "episode_return_mean": 210.91239999999988, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.30795111010383, "num_env_steps_trained_throughput_per_sec": 322.30795111010383, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 12436.092, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12436.034, "sample_time_ms": 1566.479, "learn_time_ms": 10849.161, "learn_throughput": 368.692, "synch_weights_time_ms": 16.151}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "310e1_00000", "date": "2024-08-15_01-12-50", "timestamp": 1723664570, "time_this_iter_s": 12.446568012237549, "time_total_s": 924.6682868003845, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19f40d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 924.6682868003845, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 58.588888888888896, "ram_util_percent": 83.30555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0230252044856865, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9257407471458748, "policy_loss": -0.002114935337797438, "vf_loss": 0.9277088613421829, "vf_explained_var": 0.05179289197795606, "kl": 0.00783040160749958, "entropy": 0.5975021782533202, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.0055068815196, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.353212492554276, "policy_loss": 0.0001614472264591506, "vf_loss": 6.352388679918158, "vf_explained_var": 0.5126697713735873, "kl": 0.009304096959880596, "entropy": 1.0062892385260769, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 370.03999999999996, "episode_reward_min": -198.00000000000034, "episode_reward_mean": 217.7136999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 86.82185000000001, "predator_policy": 22.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.90000000000003, 183.99999999999977, 184.0599999999998, 130.03000000000026, 203.03000000000003, 275.2499999999999, 164.56999999999996, 294.31999999999977, 351.15, 235.14, 134.17999999999998, 233.35999999999905, 184.99999999999977, 156.1299999999981, 334.06, -116.51999999999921, 115.9100000000009, 351.03, 119.18000000000065, 305.7499999999995, 292.11999999999995, 322.05, 168.04999999999995, 155.08000000000007, 344.21999999999986, 235.24, 130.02000000000032, 254.80999999999935, 287.5999999999995, 91.08000000000013, 363.26999999999987, 125.04, 184.88999999999976, 305.5499999999996, 351.03, 266.6399999999995, 181.00999999999976, 175.00999999999982, 270.06999999999994, 115.94000000000028, 67.70000000000009, 361.07, 331.04999999999995, 229.15000000000006, 144.51000000000016, 336.15, 358.08, 177.99999999999983, 187.0699999999997, 189.99999999999972, 109.3000000000002, 366.21999999999997, 258.25, 142.01000000000016, -1.050000000000063, -17.94, 176.0999999999998, -48.86999999999963, 320.3299999999999, 348.08, 368.16999999999996, 369.28000000000003, 268.4, 341.21, 134.02000000000027, -198.00000000000034, 272.97999999999934, -3.060000000000084, 154.95000000000005, 300.11, 319.25, 104.16000000000017, 297.17999999999995, 304.09999999999997, 362.08, 365.24999999999994, 208.23000000000002, 255.30999999999997, 330.19, 320.01, 169.0499999999999, 370.03999999999996, 121.92000000000027, 198.9399999999996, 183.08999999999997, 180.1399999999998, 141.13000000000017, -181.9600000000002, 138.02000000000018, 328.3299999999999, 162.96999999999997, 352.14, 358.2099999999999, 99.07000000000015, 179.07999999999979, 315.3, 176.05999999999983, 304.15999999999997, 369.16999999999996, 359.22999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-231.1600000000007, 194.05999999999997, -2.020000000000042, 177.01999999999998, 2.0000000000000013, 164.06, 2.0000000000000013, 56.029999999999994, 106.00999999999999, 21.020000000000003, 108.07999999999998, 117.17000000000006, 190.10000000000002, -104.52999999999925, 87.02, 158.29999999999978, 188.12, 110.03, 126.08, 50.06000000000003, -2.020000000000042, 111.20000000000007, 86.0300000000005, 113.33000000000001, 170.03, -4.030000000000042, 83.03000000000053, 55.09999999999979, 73.01, 195.05, 2.0000000000000013, -282.52000000000044, 31.250000000000195, 29.6600000000001, 186.01999999999998, 139.01, -56.29000000000019, 135.4699999999996, 165.14, 127.6100000000003, 107.06, 149.06, 74.03000000000002, 180.01999999999998, -2.020000000000042, 145.07, 135.11, -4.030000000000042, 160.21999999999986, 167.0, 140.09000000000003, -30.85000000000001, 2.0000000000000013, 78.02, 158.06, 68.75000000000037, 72.59000000000026, 187.01, -190.9600000000002, 181.04000000000002, 172.18999999999986, 186.07999999999998, -34.96000000000001, 41.0, 193.01, -22.119999999999852, 186.14000000000001, 81.41000000000015, 159.02, 172.01, 91.03999999999999, 140.5999999999995, 2.0000000000000013, 163.01, -6.040000000000042, 168.04999999999998, 49.010000000000005, 110.06000000000002, 80.0, -10.060000000000041, 48.01999999999999, -62.32000000000033, 198.01999999999998, 147.05, 177.01999999999998, 125.03000000000002, 86.09000000000003, 83.06, -98.49999999999939, 190.01, 176.0, 128.15, 167.03, 174.05, 2.0000000000000013, 164.0, 172.07, 2.0000000000000013, 2.0000000000000013, 179.0, 177.05, -148.75000000000065, 165.04999999999998, 183.17, 114.11000000000003, 78.13999999999999, 105.05000000000001, -6.040000000000042, -4.030000000000042, -2.020000000000042, 176.06, -400.0, 166.09999999999997, 2.0000000000000013, -162.79000000000002, -14.080000000000041, 85.31, 183.02, 132.07999999999998, 194.0, 154.16000000000003, 199.01, 185.06, 178.21999999999997, 128.21000000000004, 103.19000000000001, 183.04999999999998, 139.16000000000003, -24.129999999999708, 125.14999999999999, -400.0, 2.0000000000000013, 119.7800000000004, 138.2, -6.040000000000042, -2.020000000000042, 178.22, -52.27000000000031, 127.01, 136.10000000000002, 143.15000000000003, 151.10000000000002, -4.030000000000042, 67.19, 189.01999999999998, 55.160000000000046, 149.03, 67.07, 166.07, 181.01, 176.23999999999995, 184.01, 57.230000000000004, 59.0, 140.09, 58.22000000000009, 129.07999999999998, 174.11, 146.0, 151.01, 2.0000000000000013, 132.04999999999998, 191.02999999999997, 169.01, 100.04, -22.11999999999971, 199.01, -12.070000000000041, 44.06000000000002, 56.029999999999994, -2.020000000000042, 178.15999999999997, 117.14000000000001, -0.00999999999999836, -2.020000000000042, -369.94, 115.13000000000001, -20.109999999999705, 119.21000000000004, 188.12, 146.0, -4.030000000000042, 157.1, 178.03999999999996, 182.17999999999998, 149.03, 2.0000000000000013, 46.06999999999999, 2.0000000000000013, 162.07999999999998, 143.06, 155.24, 2.0000000000000013, 161.06, 145.01, 131.14999999999998, 173.09000000000003, 189.07999999999998, 188.08999999999997, 162.14], "policy_predator_policy_reward": [3.0, 114.0, 7.0, 2.0, 8.0, 10.0, 47.0, 25.0, 17.0, 59.0, 22.0, 28.0, 26.0, 53.0, 37.0, 12.0, 24.0, 29.0, 48.0, 11.0, 23.0, 2.0, 18.0, 16.0, 7.0, 12.0, 12.0, 6.0, 26.0, 40.0, 19.0, 145.0, 36.0, 19.0, 20.0, 6.0, 5.0, 35.0, 4.0, 9.0, 7.0, 29.0, 42.0, 26.0, 11.0, 14.0, 16.0, 8.0, 11.0, 6.0, 77.0, 49.0, 40.0, 10.0, 9.0, 19.0, 20.0, 8.0, 5.0, 96.0, 2.0, 3.0, 21.0, 98.0, 14.0, 0.0, 12.0, 26.0, 13.0, 7.0, 0.0, 35.0, 4.0, 12.0, 9.0, 4.0, 63.0, 48.0, 33.0, 13.0, 32.0, 50.0, 0.0, 16.0, 24.0, 5.0, 23.0, 37.0, 3.0, 50.0, 24.0, 8.0, 5.0, 12.0, 12.0, 0.0, 7.0, 6.0, 2.0, 7.0, 6.0, 75.0, 8.0, 10.0, 49.0, 17.0, 33.0, 10.0, 2.0, 3.0, 6.0, 200.0, 8.0, 0.0, 96.0, 32.0, 26.0, 26.0, 20.0, 2.0, 10.0, 5.0, 3.0, 3.0, 25.0, 12.0, 15.0, 4.0, 13.0, 20.0, 0.0, 200.0, 14.0, 1.0, 1.0, 4.0, 2.0, 27.0, 17.0, 20.0, 19.0, 6.0, 3.0, 38.0, 33.0, 20.0, 44.0, 44.0, 6.0, 9.0, 0.0, 5.0, 87.0, 5.0, 17.0, 40.0, 6.0, 21.0, 0.0, 23.0, 14.0, 21.0, 0.0, 10.0, 12.0, 32.0, 5.0, 7.0, 32.0, 51.0, 2.0, 2.0, 23.0, 1.0, 180.0, 10.0, 23.0, 20.0, 1.0, 20.0, 3.0, 18.0, 11.0, 6.0, 11.0, 16.0, 2.0, 49.0, 5.0, 10.0, 17.0, 0.0, 5.0, 8.0, 10.0, 18.0, 7.0, 0.0, 8.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6795037038236663, "mean_inference_ms": 1.8364817487639689, "mean_action_processing_ms": 0.2880453027622681, "mean_env_wait_ms": 0.22766766667189778, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003948569297790527, "StateBufferConnector_ms": 0.003941178321838379, "ViewRequirementAgentConnector_ms": 0.11669981479644775}, "num_episodes": 18, "episode_return_max": 370.03999999999996, "episode_return_min": -198.00000000000034, "episode_return_mean": 217.7136999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 330.7076218186162, "num_env_steps_trained_throughput_per_sec": 330.7076218186162, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 12432.141, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12432.086, "sample_time_ms": 1593.2, "learn_time_ms": 10818.78, "learn_throughput": 369.727, "synch_weights_time_ms": 16.009}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "310e1_00000", "date": "2024-08-15_01-13-02", "timestamp": 1723664582, "time_this_iter_s": 12.133625268936157, "time_total_s": 936.8019120693207, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19f4040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 936.8019120693207, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 60.247058823529414, "ram_util_percent": 83.15294117647058}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.146999154614393, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0986648787581732, "policy_loss": -0.001177670524292995, "vf_loss": 1.0997256606817245, "vf_explained_var": 0.07669468629297126, "kl": 0.006233868500845446, "entropy": 0.6633070624694622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.1637012103878, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.613996325598823, "policy_loss": -0.0023453069020496317, "vf_loss": 5.615744597066647, "vf_explained_var": 0.37380202898272763, "kl": 0.008386136112088941, "entropy": 1.0504564781668324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 384.0999999999999, "episode_reward_min": -372.0, "episode_reward_mean": 213.1728, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 85.9664, "predator_policy": 20.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [155.08000000000007, 344.21999999999986, 235.24, 130.02000000000032, 254.80999999999935, 287.5999999999995, 91.08000000000013, 363.26999999999987, 125.04, 184.88999999999976, 305.5499999999996, 351.03, 266.6399999999995, 181.00999999999976, 175.00999999999982, 270.06999999999994, 115.94000000000028, 67.70000000000009, 361.07, 331.04999999999995, 229.15000000000006, 144.51000000000016, 336.15, 358.08, 177.99999999999983, 187.0699999999997, 189.99999999999972, 109.3000000000002, 366.21999999999997, 258.25, 142.01000000000016, -1.050000000000063, -17.94, 176.0999999999998, -48.86999999999963, 320.3299999999999, 348.08, 368.16999999999996, 369.28000000000003, 268.4, 341.21, 134.02000000000027, -198.00000000000034, 272.97999999999934, -3.060000000000084, 154.95000000000005, 300.11, 319.25, 104.16000000000017, 297.17999999999995, 304.09999999999997, 362.08, 365.24999999999994, 208.23000000000002, 255.30999999999997, 330.19, 320.01, 169.0499999999999, 370.03999999999996, 121.92000000000027, 198.9399999999996, 183.08999999999997, 180.1399999999998, 141.13000000000017, -181.9600000000002, 138.02000000000018, 328.3299999999999, 162.96999999999997, 352.14, 358.2099999999999, 99.07000000000015, 179.07999999999979, 315.3, 176.05999999999983, 304.15999999999997, 369.16999999999996, 359.22999999999996, 366.15999999999997, 143.02000000000015, 41.98000000000004, -372.0, 237.27999999999997, 160.18, -0.050000000000041, 161.03999999999996, 308.27000000000004, 1.9800000000000026, 300.58000000000004, 189.8299999999997, 357.35999999999984, 301.22999999999996, 353.10999999999996, 349.08, 384.0999999999999, 335.21000000000004, 152.16000000000014, 177.8999999999998, 365.21999999999997, -55.85000000000004, -10.130000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [135.11, -4.030000000000042, 160.21999999999986, 167.0, 140.09000000000003, -30.85000000000001, 2.0000000000000013, 78.02, 158.06, 68.75000000000037, 72.59000000000026, 187.01, -190.9600000000002, 181.04000000000002, 172.18999999999986, 186.07999999999998, -34.96000000000001, 41.0, 193.01, -22.119999999999852, 186.14000000000001, 81.41000000000015, 159.02, 172.01, 91.03999999999999, 140.5999999999995, 2.0000000000000013, 163.01, -6.040000000000042, 168.04999999999998, 49.010000000000005, 110.06000000000002, 80.0, -10.060000000000041, 48.01999999999999, -62.32000000000033, 198.01999999999998, 147.05, 177.01999999999998, 125.03000000000002, 86.09000000000003, 83.06, -98.49999999999939, 190.01, 176.0, 128.15, 167.03, 174.05, 2.0000000000000013, 164.0, 172.07, 2.0000000000000013, 2.0000000000000013, 179.0, 177.05, -148.75000000000065, 165.04999999999998, 183.17, 114.11000000000003, 78.13999999999999, 105.05000000000001, -6.040000000000042, -4.030000000000042, -2.020000000000042, 176.06, -400.0, 166.09999999999997, 2.0000000000000013, -162.79000000000002, -14.080000000000041, 85.31, 183.02, 132.07999999999998, 194.0, 154.16000000000003, 199.01, 185.06, 178.21999999999997, 128.21000000000004, 103.19000000000001, 183.04999999999998, 139.16000000000003, -24.129999999999708, 125.14999999999999, -400.0, 2.0000000000000013, 119.7800000000004, 138.2, -6.040000000000042, -2.020000000000042, 178.22, -52.27000000000031, 127.01, 136.10000000000002, 143.15000000000003, 151.10000000000002, -4.030000000000042, 67.19, 189.01999999999998, 55.160000000000046, 149.03, 67.07, 166.07, 181.01, 176.23999999999995, 184.01, 57.230000000000004, 59.0, 140.09, 58.22000000000009, 129.07999999999998, 174.11, 146.0, 151.01, 2.0000000000000013, 132.04999999999998, 191.02999999999997, 169.01, 100.04, -22.11999999999971, 199.01, -12.070000000000041, 44.06000000000002, 56.029999999999994, -2.020000000000042, 178.15999999999997, 117.14000000000001, -0.00999999999999836, -2.020000000000042, -369.94, 115.13000000000001, -20.109999999999705, 119.21000000000004, 188.12, 146.0, -4.030000000000042, 157.1, 178.03999999999996, 182.17999999999998, 149.03, 2.0000000000000013, 46.06999999999999, 2.0000000000000013, 162.07999999999998, 143.06, 155.24, 2.0000000000000013, 161.06, 145.01, 131.14999999999998, 173.09000000000003, 189.07999999999998, 188.08999999999997, 162.14, 163.15999999999997, 194.0, -6.040000000000042, 116.06, -8.050000000000042, -30.969999999999985, -283.0, -292.0, 85.18999999999997, 116.09, -8.050000000000042, 156.23000000000002, -6.040000000000042, -0.00999999999999836, 136.04000000000002, 2.0000000000000013, 95.03, 146.24000000000004, -2.020000000000042, 2.0000000000000013, 173.12, 106.4600000000001, 7.789999999999962, 175.04, 183.1699999999999, 166.19000000000003, 164.02999999999997, 57.200000000000095, 188.08999999999997, 141.01999999999998, 196.04, 124.03999999999999, 185.05999999999995, 196.03999999999996, 136.19, 177.01999999999998, 2.0000000000000013, 118.16000000000001, -46.24000000000033, 186.14, 195.04999999999995, 159.17000000000002, -136.0, -48.85000000000004, -6.040000000000042, -16.0899999999997], "policy_predator_policy_reward": [16.0, 8.0, 11.0, 6.0, 77.0, 49.0, 40.0, 10.0, 9.0, 19.0, 20.0, 8.0, 5.0, 96.0, 2.0, 3.0, 21.0, 98.0, 14.0, 0.0, 12.0, 26.0, 13.0, 7.0, 0.0, 35.0, 4.0, 12.0, 9.0, 4.0, 63.0, 48.0, 33.0, 13.0, 32.0, 50.0, 0.0, 16.0, 24.0, 5.0, 23.0, 37.0, 3.0, 50.0, 24.0, 8.0, 5.0, 12.0, 12.0, 0.0, 7.0, 6.0, 2.0, 7.0, 6.0, 75.0, 8.0, 10.0, 49.0, 17.0, 33.0, 10.0, 2.0, 3.0, 6.0, 200.0, 8.0, 0.0, 96.0, 32.0, 26.0, 26.0, 20.0, 2.0, 10.0, 5.0, 3.0, 3.0, 25.0, 12.0, 15.0, 4.0, 13.0, 20.0, 0.0, 200.0, 14.0, 1.0, 1.0, 4.0, 2.0, 27.0, 17.0, 20.0, 19.0, 6.0, 3.0, 38.0, 33.0, 20.0, 44.0, 44.0, 6.0, 9.0, 0.0, 5.0, 87.0, 5.0, 17.0, 40.0, 6.0, 21.0, 0.0, 23.0, 14.0, 21.0, 0.0, 10.0, 12.0, 32.0, 5.0, 7.0, 32.0, 51.0, 2.0, 2.0, 23.0, 1.0, 180.0, 10.0, 23.0, 20.0, 1.0, 20.0, 3.0, 18.0, 11.0, 6.0, 11.0, 16.0, 2.0, 49.0, 5.0, 10.0, 17.0, 0.0, 5.0, 8.0, 10.0, 18.0, 7.0, 0.0, 8.0, 1.0, 7.0, 2.0, 17.0, 16.0, 78.0, 3.0, 192.0, 11.0, 4.0, 32.0, 7.0, 5.0, 4.0, 2.0, 3.0, 20.0, 32.0, 35.0, 0.0, 2.0, 16.0, 5.0, 0.0, 7.0, 5.0, 3.0, 41.0, 39.0, 7.0, 17.0, 24.0, 5.0, 3.0, 0.0, 22.0, 0.0, 12.0, 20.0, 14.0, 24.0, 3.0, 8.0, 125.0, 4.0, 3.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6795574629761633, "mean_inference_ms": 1.8398855842708661, "mean_action_processing_ms": 0.2881180691175127, "mean_env_wait_ms": 0.22763530016503325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003922581672668457, "StateBufferConnector_ms": 0.003790140151977539, "ViewRequirementAgentConnector_ms": 0.11262726783752441}, "num_episodes": 23, "episode_return_max": 384.0999999999999, "episode_return_min": -372.0, "episode_return_mean": 213.1728, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.69840055763535, "num_env_steps_trained_throughput_per_sec": 333.69840055763535, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 12345.755, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12345.701, "sample_time_ms": 1570.514, "learn_time_ms": 10755.481, "learn_throughput": 371.903, "synch_weights_time_ms": 15.718}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "310e1_00000", "date": "2024-08-15_01-13-15", "timestamp": 1723664595, "time_this_iter_s": 12.027889966964722, "time_total_s": 948.8298020362854, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19c50d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 948.8298020362854, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 59.62352941176471, "ram_util_percent": 83.52352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7553846846812617, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4449830983050918, "policy_loss": -0.002050771892179178, "vf_loss": 2.44689181368187, "vf_explained_var": 0.09723004269852209, "kl": 0.007576573324777153, "entropy": 0.47397751655212783, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.604550132928071, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.584218937757785, "policy_loss": -0.0009367101976066512, "vf_loss": 5.584312543919477, "vf_explained_var": 0.40802213641070817, "kl": 0.011842745885484783, "entropy": 1.0649209333790672, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 384.0999999999999, "episode_reward_min": -372.0, "episode_reward_mean": 209.02999999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 81.665, "predator_policy": 22.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [361.07, 331.04999999999995, 229.15000000000006, 144.51000000000016, 336.15, 358.08, 177.99999999999983, 187.0699999999997, 189.99999999999972, 109.3000000000002, 366.21999999999997, 258.25, 142.01000000000016, -1.050000000000063, -17.94, 176.0999999999998, -48.86999999999963, 320.3299999999999, 348.08, 368.16999999999996, 369.28000000000003, 268.4, 341.21, 134.02000000000027, -198.00000000000034, 272.97999999999934, -3.060000000000084, 154.95000000000005, 300.11, 319.25, 104.16000000000017, 297.17999999999995, 304.09999999999997, 362.08, 365.24999999999994, 208.23000000000002, 255.30999999999997, 330.19, 320.01, 169.0499999999999, 370.03999999999996, 121.92000000000027, 198.9399999999996, 183.08999999999997, 180.1399999999998, 141.13000000000017, -181.9600000000002, 138.02000000000018, 328.3299999999999, 162.96999999999997, 352.14, 358.2099999999999, 99.07000000000015, 179.07999999999979, 315.3, 176.05999999999983, 304.15999999999997, 369.16999999999996, 359.22999999999996, 366.15999999999997, 143.02000000000015, 41.98000000000004, -372.0, 237.27999999999997, 160.18, -0.050000000000041, 161.03999999999996, 308.27000000000004, 1.9800000000000026, 300.58000000000004, 189.8299999999997, 357.35999999999984, 301.22999999999996, 353.10999999999996, 349.08, 384.0999999999999, 335.21000000000004, 152.16000000000014, 177.8999999999998, 365.21999999999997, -55.85000000000004, -10.130000000000082, 169.9899999999999, 322.12999999999994, 352.1099999999999, 310.0, 2.989999999999981, -122.10999999999908, 352.29999999999995, 319.68, 190.09999999999968, 324.1399999999999, -179.00000000000017, 337.31999999999994, -4.920000000000044, 339.37999999999994, 129.32000000000016, 178.08999999999986, 213.09000000000003, 255.30999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [198.01999999999998, 147.05, 177.01999999999998, 125.03000000000002, 86.09000000000003, 83.06, -98.49999999999939, 190.01, 176.0, 128.15, 167.03, 174.05, 2.0000000000000013, 164.0, 172.07, 2.0000000000000013, 2.0000000000000013, 179.0, 177.05, -148.75000000000065, 165.04999999999998, 183.17, 114.11000000000003, 78.13999999999999, 105.05000000000001, -6.040000000000042, -4.030000000000042, -2.020000000000042, 176.06, -400.0, 166.09999999999997, 2.0000000000000013, -162.79000000000002, -14.080000000000041, 85.31, 183.02, 132.07999999999998, 194.0, 154.16000000000003, 199.01, 185.06, 178.21999999999997, 128.21000000000004, 103.19000000000001, 183.04999999999998, 139.16000000000003, -24.129999999999708, 125.14999999999999, -400.0, 2.0000000000000013, 119.7800000000004, 138.2, -6.040000000000042, -2.020000000000042, 178.22, -52.27000000000031, 127.01, 136.10000000000002, 143.15000000000003, 151.10000000000002, -4.030000000000042, 67.19, 189.01999999999998, 55.160000000000046, 149.03, 67.07, 166.07, 181.01, 176.23999999999995, 184.01, 57.230000000000004, 59.0, 140.09, 58.22000000000009, 129.07999999999998, 174.11, 146.0, 151.01, 2.0000000000000013, 132.04999999999998, 191.02999999999997, 169.01, 100.04, -22.11999999999971, 199.01, -12.070000000000041, 44.06000000000002, 56.029999999999994, -2.020000000000042, 178.15999999999997, 117.14000000000001, -0.00999999999999836, -2.020000000000042, -369.94, 115.13000000000001, -20.109999999999705, 119.21000000000004, 188.12, 146.0, -4.030000000000042, 157.1, 178.03999999999996, 182.17999999999998, 149.03, 2.0000000000000013, 46.06999999999999, 2.0000000000000013, 162.07999999999998, 143.06, 155.24, 2.0000000000000013, 161.06, 145.01, 131.14999999999998, 173.09000000000003, 189.07999999999998, 188.08999999999997, 162.14, 163.15999999999997, 194.0, -6.040000000000042, 116.06, -8.050000000000042, -30.969999999999985, -283.0, -292.0, 85.18999999999997, 116.09, -8.050000000000042, 156.23000000000002, -6.040000000000042, -0.00999999999999836, 136.04000000000002, 2.0000000000000013, 95.03, 146.24000000000004, -2.020000000000042, 2.0000000000000013, 173.12, 106.4600000000001, 7.789999999999962, 175.04, 183.1699999999999, 166.19000000000003, 164.02999999999997, 57.200000000000095, 188.08999999999997, 141.01999999999998, 196.04, 124.03999999999999, 185.05999999999995, 196.03999999999996, 136.19, 177.01999999999998, 2.0000000000000013, 118.16000000000001, -46.24000000000033, 186.14, 195.04999999999995, 159.17000000000002, -136.0, -48.85000000000004, -6.040000000000042, -16.0899999999997, 157.04000000000002, -8.050000000000042, 173.06, 76.07, 177.05, 155.06, 173.0, 29.0, -0.00999999999999836, 2.0000000000000013, -80.40999999999987, -138.7000000000004, 178.04000000000002, 165.26, 138.41, 173.27, -0.00999999999999836, 189.10999999999999, 192.07999999999993, 83.05999999999999, 2.0000000000000013, -400.0, 186.14000000000004, 101.17999999999998, -377.89, -4.030000000000042, 113.23999999999995, 186.13999999999996, 55.160000000000046, -19.840000000000046, 164.08999999999997, 2.0000000000000013, 68.0, 59.089999999999996, 134.24000000000004, 67.07000000000001], "policy_predator_policy_reward": [0.0, 16.0, 24.0, 5.0, 23.0, 37.0, 3.0, 50.0, 24.0, 8.0, 5.0, 12.0, 12.0, 0.0, 7.0, 6.0, 2.0, 7.0, 6.0, 75.0, 8.0, 10.0, 49.0, 17.0, 33.0, 10.0, 2.0, 3.0, 6.0, 200.0, 8.0, 0.0, 96.0, 32.0, 26.0, 26.0, 20.0, 2.0, 10.0, 5.0, 3.0, 3.0, 25.0, 12.0, 15.0, 4.0, 13.0, 20.0, 0.0, 200.0, 14.0, 1.0, 1.0, 4.0, 2.0, 27.0, 17.0, 20.0, 19.0, 6.0, 3.0, 38.0, 33.0, 20.0, 44.0, 44.0, 6.0, 9.0, 0.0, 5.0, 87.0, 5.0, 17.0, 40.0, 6.0, 21.0, 0.0, 23.0, 14.0, 21.0, 0.0, 10.0, 12.0, 32.0, 5.0, 7.0, 32.0, 51.0, 2.0, 2.0, 23.0, 1.0, 180.0, 10.0, 23.0, 20.0, 1.0, 20.0, 3.0, 18.0, 11.0, 6.0, 11.0, 16.0, 2.0, 49.0, 5.0, 10.0, 17.0, 0.0, 5.0, 8.0, 10.0, 18.0, 7.0, 0.0, 8.0, 1.0, 7.0, 2.0, 17.0, 16.0, 78.0, 3.0, 192.0, 11.0, 4.0, 32.0, 7.0, 5.0, 4.0, 2.0, 3.0, 20.0, 32.0, 35.0, 0.0, 2.0, 16.0, 5.0, 0.0, 7.0, 5.0, 3.0, 41.0, 39.0, 7.0, 17.0, 24.0, 5.0, 3.0, 0.0, 22.0, 0.0, 12.0, 20.0, 14.0, 24.0, 3.0, 8.0, 125.0, 4.0, 3.0, 9.0, 15.0, 6.0, 39.0, 34.0, 8.0, 12.0, 60.0, 48.0, 1.0, 0.0, 3.0, 94.0, 6.0, 3.0, 2.0, 6.0, 1.0, 0.0, 12.0, 37.0, 19.0, 200.0, 27.0, 23.0, 188.0, 189.0, 19.0, 21.0, 26.0, 68.0, 3.0, 9.0, 33.0, 53.0, 24.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.679002475173896, "mean_inference_ms": 1.8440083306461643, "mean_action_processing_ms": 0.2874990285960542, "mean_env_wait_ms": 0.22764852182584788, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004204392433166504, "StateBufferConnector_ms": 0.003322005271911621, "ViewRequirementAgentConnector_ms": 0.11346793174743652}, "num_episodes": 18, "episode_return_max": 384.0999999999999, "episode_return_min": -372.0, "episode_return_mean": 209.02999999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 327.35000306526933, "num_env_steps_trained_throughput_per_sec": 327.35000306526933, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 12326.108, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12326.056, "sample_time_ms": 1560.706, "learn_time_ms": 10746.399, "learn_throughput": 372.218, "synch_weights_time_ms": 15.248}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "310e1_00000", "date": "2024-08-15_01-13-27", "timestamp": 1723664607, "time_this_iter_s": 12.262917041778564, "time_total_s": 961.092719078064, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19c59d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 961.092719078064, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 58.411764705882355, "ram_util_percent": 82.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.753044303147881, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7895984285092228, "policy_loss": -0.0019816441840871616, "vf_loss": 1.7914728059024407, "vf_explained_var": 0.08352915950553128, "kl": 0.0057208708302166796, "entropy": 0.577738574241835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.158779021041103, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.762169369566378, "policy_loss": -0.002179414639249444, "vf_loss": 4.763255352696413, "vf_explained_var": 0.4036677590753666, "kl": 0.01535894363429679, "entropy": 1.1257299575856123, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 384.0999999999999, "episode_reward_min": -460.97, "episode_reward_mean": 196.91099999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 74.20549999999999, "predator_policy": 24.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [348.08, 368.16999999999996, 369.28000000000003, 268.4, 341.21, 134.02000000000027, -198.00000000000034, 272.97999999999934, -3.060000000000084, 154.95000000000005, 300.11, 319.25, 104.16000000000017, 297.17999999999995, 304.09999999999997, 362.08, 365.24999999999994, 208.23000000000002, 255.30999999999997, 330.19, 320.01, 169.0499999999999, 370.03999999999996, 121.92000000000027, 198.9399999999996, 183.08999999999997, 180.1399999999998, 141.13000000000017, -181.9600000000002, 138.02000000000018, 328.3299999999999, 162.96999999999997, 352.14, 358.2099999999999, 99.07000000000015, 179.07999999999979, 315.3, 176.05999999999983, 304.15999999999997, 369.16999999999996, 359.22999999999996, 366.15999999999997, 143.02000000000015, 41.98000000000004, -372.0, 237.27999999999997, 160.18, -0.050000000000041, 161.03999999999996, 308.27000000000004, 1.9800000000000026, 300.58000000000004, 189.8299999999997, 357.35999999999984, 301.22999999999996, 353.10999999999996, 349.08, 384.0999999999999, 335.21000000000004, 152.16000000000014, 177.8999999999998, 365.21999999999997, -55.85000000000004, -10.130000000000082, 169.9899999999999, 322.12999999999994, 352.1099999999999, 310.0, 2.989999999999981, -122.10999999999908, 352.29999999999995, 319.68, 190.09999999999968, 324.1399999999999, -179.00000000000017, 337.31999999999994, -4.920000000000044, 339.37999999999994, 129.32000000000016, 178.08999999999986, 213.09000000000003, 255.30999999999997, 173.14999999999964, 362.12, 14.020000000000042, 96.06000000000012, 262.2800000000001, 338.2299999999999, 354.0899999999999, 48.13999999999999, 209.91999999999962, 306.09, -460.97, -170.91, -0.04000000000003833, -7.110000000000083, 273.05999999999995, 367.0799999999999, 141.31000000000017, 101.01000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [132.07999999999998, 194.0, 154.16000000000003, 199.01, 185.06, 178.21999999999997, 128.21000000000004, 103.19000000000001, 183.04999999999998, 139.16000000000003, -24.129999999999708, 125.14999999999999, -400.0, 2.0000000000000013, 119.7800000000004, 138.2, -6.040000000000042, -2.020000000000042, 178.22, -52.27000000000031, 127.01, 136.10000000000002, 143.15000000000003, 151.10000000000002, -4.030000000000042, 67.19, 189.01999999999998, 55.160000000000046, 149.03, 67.07, 166.07, 181.01, 176.23999999999995, 184.01, 57.230000000000004, 59.0, 140.09, 58.22000000000009, 129.07999999999998, 174.11, 146.0, 151.01, 2.0000000000000013, 132.04999999999998, 191.02999999999997, 169.01, 100.04, -22.11999999999971, 199.01, -12.070000000000041, 44.06000000000002, 56.029999999999994, -2.020000000000042, 178.15999999999997, 117.14000000000001, -0.00999999999999836, -2.020000000000042, -369.94, 115.13000000000001, -20.109999999999705, 119.21000000000004, 188.12, 146.0, -4.030000000000042, 157.1, 178.03999999999996, 182.17999999999998, 149.03, 2.0000000000000013, 46.06999999999999, 2.0000000000000013, 162.07999999999998, 143.06, 155.24, 2.0000000000000013, 161.06, 145.01, 131.14999999999998, 173.09000000000003, 189.07999999999998, 188.08999999999997, 162.14, 163.15999999999997, 194.0, -6.040000000000042, 116.06, -8.050000000000042, -30.969999999999985, -283.0, -292.0, 85.18999999999997, 116.09, -8.050000000000042, 156.23000000000002, -6.040000000000042, -0.00999999999999836, 136.04000000000002, 2.0000000000000013, 95.03, 146.24000000000004, -2.020000000000042, 2.0000000000000013, 173.12, 106.4600000000001, 7.789999999999962, 175.04, 183.1699999999999, 166.19000000000003, 164.02999999999997, 57.200000000000095, 188.08999999999997, 141.01999999999998, 196.04, 124.03999999999999, 185.05999999999995, 196.03999999999996, 136.19, 177.01999999999998, 2.0000000000000013, 118.16000000000001, -46.24000000000033, 186.14, 195.04999999999995, 159.17000000000002, -136.0, -48.85000000000004, -6.040000000000042, -16.0899999999997, 157.04000000000002, -8.050000000000042, 173.06, 76.07, 177.05, 155.06, 173.0, 29.0, -0.00999999999999836, 2.0000000000000013, -80.40999999999987, -138.7000000000004, 178.04000000000002, 165.26, 138.41, 173.27, -0.00999999999999836, 189.10999999999999, 192.07999999999993, 83.05999999999999, 2.0000000000000013, -400.0, 186.14000000000004, 101.17999999999998, -377.89, -4.030000000000042, 113.23999999999995, 186.13999999999996, 55.160000000000046, -19.840000000000046, 164.08999999999997, 2.0000000000000013, 68.0, 59.089999999999996, 134.24000000000004, 67.07000000000001, 174.1999999999999, -8.050000000000042, 181.07, 159.05, 2.0000000000000013, -95.98, 14.060000000000025, 2.0000000000000013, 116.11999999999999, 91.16000000000001, 188.12, 111.11, 194.05999999999995, 140.03000000000003, -70.0, -17.86, 16.85000000000011, 193.07000000000002, 198.01999999999998, 61.07, -400.0, -276.97, -151.0, -222.91, -6.040000000000041, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -28.960000000000022, 198.01999999999998, 181.03999999999996, 175.04000000000002, 126.32000000000004, -0.00999999999999836, 61.069999999999986, -10.060000000000041], "policy_predator_policy_reward": [20.0, 2.0, 10.0, 5.0, 3.0, 3.0, 25.0, 12.0, 15.0, 4.0, 13.0, 20.0, 0.0, 200.0, 14.0, 1.0, 1.0, 4.0, 2.0, 27.0, 17.0, 20.0, 19.0, 6.0, 3.0, 38.0, 33.0, 20.0, 44.0, 44.0, 6.0, 9.0, 0.0, 5.0, 87.0, 5.0, 17.0, 40.0, 6.0, 21.0, 0.0, 23.0, 14.0, 21.0, 0.0, 10.0, 12.0, 32.0, 5.0, 7.0, 32.0, 51.0, 2.0, 2.0, 23.0, 1.0, 180.0, 10.0, 23.0, 20.0, 1.0, 20.0, 3.0, 18.0, 11.0, 6.0, 11.0, 16.0, 2.0, 49.0, 5.0, 10.0, 17.0, 0.0, 5.0, 8.0, 10.0, 18.0, 7.0, 0.0, 8.0, 1.0, 7.0, 2.0, 17.0, 16.0, 78.0, 3.0, 192.0, 11.0, 4.0, 32.0, 7.0, 5.0, 4.0, 2.0, 3.0, 20.0, 32.0, 35.0, 0.0, 2.0, 16.0, 5.0, 0.0, 7.0, 5.0, 3.0, 41.0, 39.0, 7.0, 17.0, 24.0, 5.0, 3.0, 0.0, 22.0, 0.0, 12.0, 20.0, 14.0, 24.0, 3.0, 8.0, 125.0, 4.0, 3.0, 9.0, 15.0, 6.0, 39.0, 34.0, 8.0, 12.0, 60.0, 48.0, 1.0, 0.0, 3.0, 94.0, 6.0, 3.0, 2.0, 6.0, 1.0, 0.0, 12.0, 37.0, 19.0, 200.0, 27.0, 23.0, 188.0, 189.0, 19.0, 21.0, 26.0, 68.0, 3.0, 9.0, 33.0, 53.0, 24.0, 30.0, 5.0, 2.0, 12.0, 10.0, 98.0, 10.0, 60.0, 20.0, 17.0, 38.0, 16.0, 23.0, 1.0, 19.0, 125.0, 11.0, 0.0, 0.0, 44.0, 3.0, 200.0, 16.0, 10.0, 193.0, 4.0, 0.0, 4.0, 7.0, 29.0, 75.0, 5.0, 6.0, 14.0, 1.0, 44.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6789177305616769, "mean_inference_ms": 1.8472476793167432, "mean_action_processing_ms": 0.2873515218072076, "mean_env_wait_ms": 0.22767358572307705, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004470705986022949, "StateBufferConnector_ms": 0.003756999969482422, "ViewRequirementAgentConnector_ms": 0.11764264106750488}, "num_episodes": 18, "episode_return_max": 384.0999999999999, "episode_return_min": -460.97, "episode_return_mean": 196.91099999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.5905111530147, "num_env_steps_trained_throughput_per_sec": 323.5905111530147, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 12304.942, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12304.889, "sample_time_ms": 1563.307, "learn_time_ms": 10722.881, "learn_throughput": 373.034, "synch_weights_time_ms": 15.054}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "310e1_00000", "date": "2024-08-15_01-13-39", "timestamp": 1723664619, "time_this_iter_s": 12.41668701171875, "time_total_s": 973.5094060897827, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a97d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 973.5094060897827, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 57.8111111111111, "ram_util_percent": 82.76666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5815118048083845, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9563611205135073, "policy_loss": -0.00416930485430553, "vf_loss": 0.9603796625736529, "vf_explained_var": 0.057388091875762534, "kl": 0.008040727962254827, "entropy": 0.7243993821282866, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.206785532248714, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.123373398074397, "policy_loss": -0.007608448350358577, "vf_loss": 4.129855888356607, "vf_explained_var": 0.723671481123677, "kl": 0.015815967066582406, "entropy": 1.1241402677127292, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 384.0999999999999, "episode_reward_min": -460.97, "episode_reward_mean": 180.41519999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 66.4826, "predator_policy": 23.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [370.03999999999996, 121.92000000000027, 198.9399999999996, 183.08999999999997, 180.1399999999998, 141.13000000000017, -181.9600000000002, 138.02000000000018, 328.3299999999999, 162.96999999999997, 352.14, 358.2099999999999, 99.07000000000015, 179.07999999999979, 315.3, 176.05999999999983, 304.15999999999997, 369.16999999999996, 359.22999999999996, 366.15999999999997, 143.02000000000015, 41.98000000000004, -372.0, 237.27999999999997, 160.18, -0.050000000000041, 161.03999999999996, 308.27000000000004, 1.9800000000000026, 300.58000000000004, 189.8299999999997, 357.35999999999984, 301.22999999999996, 353.10999999999996, 349.08, 384.0999999999999, 335.21000000000004, 152.16000000000014, 177.8999999999998, 365.21999999999997, -55.85000000000004, -10.130000000000082, 169.9899999999999, 322.12999999999994, 352.1099999999999, 310.0, 2.989999999999981, -122.10999999999908, 352.29999999999995, 319.68, 190.09999999999968, 324.1399999999999, -179.00000000000017, 337.31999999999994, -4.920000000000044, 339.37999999999994, 129.32000000000016, 178.08999999999986, 213.09000000000003, 255.30999999999997, 173.14999999999964, 362.12, 14.020000000000042, 96.06000000000012, 262.2800000000001, 338.2299999999999, 354.0899999999999, 48.13999999999999, 209.91999999999962, 306.09, -460.97, -170.91, -0.04000000000003833, -7.110000000000083, 273.05999999999995, 367.0799999999999, 141.31000000000017, 101.01000000000019, 113.76000000000032, 152.78999999999996, 313.66999999999945, 129.25000000000034, 173.00999999999982, 187.64999999999986, 101.13000000000022, 192.97999999999968, 125.68000000000029, 310.19999999999993, 139.46999999999935, 68.7200000000007, 188.69999999999948, 142.70999999999998, 351.17999999999995, 186.54999999999978, 153.09000000000012, 281.82999999999925, 30.660000000000267, 184.9799999999998, 143.29000000000005, 70.07000000000103], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [191.02999999999997, 169.01, 100.04, -22.11999999999971, 199.01, -12.070000000000041, 44.06000000000002, 56.029999999999994, -2.020000000000042, 178.15999999999997, 117.14000000000001, -0.00999999999999836, -2.020000000000042, -369.94, 115.13000000000001, -20.109999999999705, 119.21000000000004, 188.12, 146.0, -4.030000000000042, 157.1, 178.03999999999996, 182.17999999999998, 149.03, 2.0000000000000013, 46.06999999999999, 2.0000000000000013, 162.07999999999998, 143.06, 155.24, 2.0000000000000013, 161.06, 145.01, 131.14999999999998, 173.09000000000003, 189.07999999999998, 188.08999999999997, 162.14, 163.15999999999997, 194.0, -6.040000000000042, 116.06, -8.050000000000042, -30.969999999999985, -283.0, -292.0, 85.18999999999997, 116.09, -8.050000000000042, 156.23000000000002, -6.040000000000042, -0.00999999999999836, 136.04000000000002, 2.0000000000000013, 95.03, 146.24000000000004, -2.020000000000042, 2.0000000000000013, 173.12, 106.4600000000001, 7.789999999999962, 175.04, 183.1699999999999, 166.19000000000003, 164.02999999999997, 57.200000000000095, 188.08999999999997, 141.01999999999998, 196.04, 124.03999999999999, 185.05999999999995, 196.03999999999996, 136.19, 177.01999999999998, 2.0000000000000013, 118.16000000000001, -46.24000000000033, 186.14, 195.04999999999995, 159.17000000000002, -136.0, -48.85000000000004, -6.040000000000042, -16.0899999999997, 157.04000000000002, -8.050000000000042, 173.06, 76.07, 177.05, 155.06, 173.0, 29.0, -0.00999999999999836, 2.0000000000000013, -80.40999999999987, -138.7000000000004, 178.04000000000002, 165.26, 138.41, 173.27, -0.00999999999999836, 189.10999999999999, 192.07999999999993, 83.05999999999999, 2.0000000000000013, -400.0, 186.14000000000004, 101.17999999999998, -377.89, -4.030000000000042, 113.23999999999995, 186.13999999999996, 55.160000000000046, -19.840000000000046, 164.08999999999997, 2.0000000000000013, 68.0, 59.089999999999996, 134.24000000000004, 67.07000000000001, 174.1999999999999, -8.050000000000042, 181.07, 159.05, 2.0000000000000013, -95.98, 14.060000000000025, 2.0000000000000013, 116.11999999999999, 91.16000000000001, 188.12, 111.11, 194.05999999999995, 140.03000000000003, -70.0, -17.86, 16.85000000000011, 193.07000000000002, 198.01999999999998, 61.07, -400.0, -276.97, -151.0, -222.91, -6.040000000000041, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -28.960000000000022, 198.01999999999998, 181.03999999999996, 175.04000000000002, 126.32000000000004, -0.00999999999999836, 61.069999999999986, -10.060000000000041, -98.49999999999925, 150.2599999999999, -88.44999999999945, 176.23999999999998, 148.51999999999953, 155.14999999999992, -24.129999999999708, 129.38000000000002, -16.0899999999997, 166.09999999999997, 147.17, 20.480000000000228, 57.140000000000015, -0.00999999999999836, 194.06, -14.080000000000041, 134.0, -62.32000000000033, 144.05, 131.14999999999992, 124.49000000000025, -2.020000000000042, 8.719999999999985, 2.0000000000000013, 7.579999999999989, 95.11999999999998, -76.38999999999919, 175.0999999999999, 130.13, 186.05, 37.45999999999971, 116.08999999999999, 2.0000000000000013, 131.09000000000003, 88.76000000000037, 175.07000000000005, -34.18000000000032, 11.83999999999998, 184.01, -4.030000000000042, 99.29000000000003, 2.0000000000000013, 67.13000000000052, -10.060000000000041], "policy_predator_policy_reward": [0.0, 10.0, 12.0, 32.0, 5.0, 7.0, 32.0, 51.0, 2.0, 2.0, 23.0, 1.0, 180.0, 10.0, 23.0, 20.0, 1.0, 20.0, 3.0, 18.0, 11.0, 6.0, 11.0, 16.0, 2.0, 49.0, 5.0, 10.0, 17.0, 0.0, 5.0, 8.0, 10.0, 18.0, 7.0, 0.0, 8.0, 1.0, 7.0, 2.0, 17.0, 16.0, 78.0, 3.0, 192.0, 11.0, 4.0, 32.0, 7.0, 5.0, 4.0, 2.0, 3.0, 20.0, 32.0, 35.0, 0.0, 2.0, 16.0, 5.0, 0.0, 7.0, 5.0, 3.0, 41.0, 39.0, 7.0, 17.0, 24.0, 5.0, 3.0, 0.0, 22.0, 0.0, 12.0, 20.0, 14.0, 24.0, 3.0, 8.0, 125.0, 4.0, 3.0, 9.0, 15.0, 6.0, 39.0, 34.0, 8.0, 12.0, 60.0, 48.0, 1.0, 0.0, 3.0, 94.0, 6.0, 3.0, 2.0, 6.0, 1.0, 0.0, 12.0, 37.0, 19.0, 200.0, 27.0, 23.0, 188.0, 189.0, 19.0, 21.0, 26.0, 68.0, 3.0, 9.0, 33.0, 53.0, 24.0, 30.0, 5.0, 2.0, 12.0, 10.0, 98.0, 10.0, 60.0, 20.0, 17.0, 38.0, 16.0, 23.0, 1.0, 19.0, 125.0, 11.0, 0.0, 0.0, 44.0, 3.0, 200.0, 16.0, 10.0, 193.0, 4.0, 0.0, 4.0, 7.0, 29.0, 75.0, 5.0, 6.0, 14.0, 1.0, 44.0, 6.0, 50.0, 12.0, 30.0, 35.0, 3.0, 7.0, 11.0, 13.0, 14.0, 9.0, 9.0, 11.0, 1.0, 43.0, 5.0, 8.0, 32.0, 22.0, 18.0, 17.0, 9.0, 8.0, 40.0, 18.0, 56.0, 30.0, 39.0, 5.0, 16.0, 19.0, 20.0, 13.0, 20.0, 0.0, 6.0, 12.0, 18.0, 35.0, 5.0, 0.0, 18.0, 24.0, 7.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6786959383757021, "mean_inference_ms": 1.8511652501293832, "mean_action_processing_ms": 0.28715052585526957, "mean_env_wait_ms": 0.22766994822456715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004589200019836426, "StateBufferConnector_ms": 0.0038957595825195312, "ViewRequirementAgentConnector_ms": 0.11976587772369385}, "num_episodes": 22, "episode_return_max": 384.0999999999999, "episode_return_min": -460.97, "episode_return_mean": 180.41519999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.3919353980068, "num_env_steps_trained_throughput_per_sec": 321.3919353980068, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 12281.83, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12281.778, "sample_time_ms": 1573.044, "learn_time_ms": 10691.112, "learn_throughput": 374.143, "synch_weights_time_ms": 14.848}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "310e1_00000", "date": "2024-08-15_01-13-52", "timestamp": 1723664632, "time_this_iter_s": 12.508291244506836, "time_total_s": 986.0176973342896, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a97f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 986.0176973342896, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 59.817647058823525, "ram_util_percent": 82.70588235294116}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2845013606169866, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6074849702220745, "policy_loss": -0.003605624005720808, "vf_loss": 0.611001970478033, "vf_explained_var": 0.08337164943811123, "kl": 0.004726611060708594, "entropy": 0.691189306343674, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8388625420590556, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.631580549068552, "policy_loss": -0.008855774284897264, "vf_loss": 3.639287421312282, "vf_explained_var": 0.8904967410539193, "kl": 0.016138271123521116, "entropy": 1.087992259055849, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 384.0999999999999, "episode_reward_min": -460.97, "episode_reward_mean": 181.6159, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.01999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 67.49795, "predator_policy": 23.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [359.22999999999996, 366.15999999999997, 143.02000000000015, 41.98000000000004, -372.0, 237.27999999999997, 160.18, -0.050000000000041, 161.03999999999996, 308.27000000000004, 1.9800000000000026, 300.58000000000004, 189.8299999999997, 357.35999999999984, 301.22999999999996, 353.10999999999996, 349.08, 384.0999999999999, 335.21000000000004, 152.16000000000014, 177.8999999999998, 365.21999999999997, -55.85000000000004, -10.130000000000082, 169.9899999999999, 322.12999999999994, 352.1099999999999, 310.0, 2.989999999999981, -122.10999999999908, 352.29999999999995, 319.68, 190.09999999999968, 324.1399999999999, -179.00000000000017, 337.31999999999994, -4.920000000000044, 339.37999999999994, 129.32000000000016, 178.08999999999986, 213.09000000000003, 255.30999999999997, 173.14999999999964, 362.12, 14.020000000000042, 96.06000000000012, 262.2800000000001, 338.2299999999999, 354.0899999999999, 48.13999999999999, 209.91999999999962, 306.09, -460.97, -170.91, -0.04000000000003833, -7.110000000000083, 273.05999999999995, 367.0799999999999, 141.31000000000017, 101.01000000000019, 113.76000000000032, 152.78999999999996, 313.66999999999945, 129.25000000000034, 173.00999999999982, 187.64999999999986, 101.13000000000022, 192.97999999999968, 125.68000000000029, 310.19999999999993, 139.46999999999935, 68.7200000000007, 188.69999999999948, 142.70999999999998, 351.17999999999995, 186.54999999999978, 153.09000000000012, 281.82999999999925, 30.660000000000267, 184.9799999999998, 143.29000000000005, 70.07000000000103, 338.41999999999985, 307.6799999999998, 353.28999999999985, 125.39000000000027, 272.4399999999998, 232.41999999999982, 186.07999999999976, 279.23999999999995, 313.07, 171.23999999999953, -14.129999999999729, 142.99000000000012, 273.02999999999906, -3.060000000000084, 127.1300000000005, 156.15999999999997, 305.27000000000004, 349.21999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [188.08999999999997, 162.14, 163.15999999999997, 194.0, -6.040000000000042, 116.06, -8.050000000000042, -30.969999999999985, -283.0, -292.0, 85.18999999999997, 116.09, -8.050000000000042, 156.23000000000002, -6.040000000000042, -0.00999999999999836, 136.04000000000002, 2.0000000000000013, 95.03, 146.24000000000004, -2.020000000000042, 2.0000000000000013, 173.12, 106.4600000000001, 7.789999999999962, 175.04, 183.1699999999999, 166.19000000000003, 164.02999999999997, 57.200000000000095, 188.08999999999997, 141.01999999999998, 196.04, 124.03999999999999, 185.05999999999995, 196.03999999999996, 136.19, 177.01999999999998, 2.0000000000000013, 118.16000000000001, -46.24000000000033, 186.14, 195.04999999999995, 159.17000000000002, -136.0, -48.85000000000004, -6.040000000000042, -16.0899999999997, 157.04000000000002, -8.050000000000042, 173.06, 76.07, 177.05, 155.06, 173.0, 29.0, -0.00999999999999836, 2.0000000000000013, -80.40999999999987, -138.7000000000004, 178.04000000000002, 165.26, 138.41, 173.27, -0.00999999999999836, 189.10999999999999, 192.07999999999993, 83.05999999999999, 2.0000000000000013, -400.0, 186.14000000000004, 101.17999999999998, -377.89, -4.030000000000042, 113.23999999999995, 186.13999999999996, 55.160000000000046, -19.840000000000046, 164.08999999999997, 2.0000000000000013, 68.0, 59.089999999999996, 134.24000000000004, 67.07000000000001, 174.1999999999999, -8.050000000000042, 181.07, 159.05, 2.0000000000000013, -95.98, 14.060000000000025, 2.0000000000000013, 116.11999999999999, 91.16000000000001, 188.12, 111.11, 194.05999999999995, 140.03000000000003, -70.0, -17.86, 16.85000000000011, 193.07000000000002, 198.01999999999998, 61.07, -400.0, -276.97, -151.0, -222.91, -6.040000000000041, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -28.960000000000022, 198.01999999999998, 181.03999999999996, 175.04000000000002, 126.32000000000004, -0.00999999999999836, 61.069999999999986, -10.060000000000041, -98.49999999999925, 150.2599999999999, -88.44999999999945, 176.23999999999998, 148.51999999999953, 155.14999999999992, -24.129999999999708, 129.38000000000002, -16.0899999999997, 166.09999999999997, 147.17, 20.480000000000228, 57.140000000000015, -0.00999999999999836, 194.06, -14.080000000000041, 134.0, -62.32000000000033, 144.05, 131.14999999999992, 124.49000000000025, -2.020000000000042, 8.719999999999985, 2.0000000000000013, 7.579999999999989, 95.11999999999998, -76.38999999999919, 175.0999999999999, 130.13, 186.05, 37.45999999999971, 116.08999999999999, 2.0000000000000013, 131.09000000000003, 88.76000000000037, 175.07000000000005, -34.18000000000032, 11.83999999999998, 184.01, -4.030000000000042, 99.29000000000003, 2.0000000000000013, 67.13000000000052, -10.060000000000041, 115.31000000000003, 189.11, 176.23999999999995, 105.44, 180.19999999999993, 164.09, 47.39000000000017, 2.0000000000000013, 101.24000000000001, 123.20000000000007, 27.290000000000035, 142.13, 174.08, 2.0000000000000013, 131.12, 104.12, 160.04, 113.03, 2.0000000000000013, 155.23999999999984, -12.070000000000041, -10.060000000000041, -12.070000000000041, 125.06000000000002, 138.01999999999998, 100.01000000000052, -4.030000000000042, -4.030000000000042, -16.08999999999971, 112.22000000000001, -16.0899999999997, 157.24999999999994, 147.2, 112.07000000000002, 169.16000000000005, 170.05999999999997], "policy_predator_policy_reward": [8.0, 1.0, 7.0, 2.0, 17.0, 16.0, 78.0, 3.0, 192.0, 11.0, 4.0, 32.0, 7.0, 5.0, 4.0, 2.0, 3.0, 20.0, 32.0, 35.0, 0.0, 2.0, 16.0, 5.0, 0.0, 7.0, 5.0, 3.0, 41.0, 39.0, 7.0, 17.0, 24.0, 5.0, 3.0, 0.0, 22.0, 0.0, 12.0, 20.0, 14.0, 24.0, 3.0, 8.0, 125.0, 4.0, 3.0, 9.0, 15.0, 6.0, 39.0, 34.0, 8.0, 12.0, 60.0, 48.0, 1.0, 0.0, 3.0, 94.0, 6.0, 3.0, 2.0, 6.0, 1.0, 0.0, 12.0, 37.0, 19.0, 200.0, 27.0, 23.0, 188.0, 189.0, 19.0, 21.0, 26.0, 68.0, 3.0, 9.0, 33.0, 53.0, 24.0, 30.0, 5.0, 2.0, 12.0, 10.0, 98.0, 10.0, 60.0, 20.0, 17.0, 38.0, 16.0, 23.0, 1.0, 19.0, 125.0, 11.0, 0.0, 0.0, 44.0, 3.0, 200.0, 16.0, 10.0, 193.0, 4.0, 0.0, 4.0, 7.0, 29.0, 75.0, 5.0, 6.0, 14.0, 1.0, 44.0, 6.0, 50.0, 12.0, 30.0, 35.0, 3.0, 7.0, 11.0, 13.0, 14.0, 9.0, 9.0, 11.0, 1.0, 43.0, 5.0, 8.0, 32.0, 22.0, 18.0, 17.0, 9.0, 8.0, 40.0, 18.0, 56.0, 30.0, 39.0, 5.0, 16.0, 19.0, 20.0, 13.0, 20.0, 0.0, 6.0, 12.0, 18.0, 35.0, 5.0, 0.0, 18.0, 24.0, 7.0, 6.0, 18.0, 16.0, 17.0, 9.0, 0.0, 9.0, 38.0, 38.0, 21.0, 27.0, 51.0, 12.0, 4.0, 6.0, 28.0, 16.0, 12.0, 28.0, 7.0, 7.0, 1.0, 7.0, 24.0, 6.0, 20.0, 15.0, 3.0, 2.0, 22.0, 9.0, 9.0, 6.0, 24.0, 22.0, 2.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6785384430001301, "mean_inference_ms": 1.8544443206513193, "mean_action_processing_ms": 0.28696498580241925, "mean_env_wait_ms": 0.22766455999673846, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004637598991394043, "StateBufferConnector_ms": 0.003979086875915527, "ViewRequirementAgentConnector_ms": 0.12429630756378174}, "num_episodes": 18, "episode_return_max": 384.0999999999999, "episode_return_min": -460.97, "episode_return_mean": 181.6159, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.65386379854755, "num_env_steps_trained_throughput_per_sec": 317.65386379854755, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 12313.225, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12313.172, "sample_time_ms": 1582.971, "learn_time_ms": 10711.68, "learn_throughput": 373.424, "synch_weights_time_ms": 15.879}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "310e1_00000", "date": "2024-08-15_01-14-04", "timestamp": 1723664644, "time_this_iter_s": 12.660022020339966, "time_total_s": 998.6777193546295, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a40dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 998.6777193546295, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 58.633333333333326, "ram_util_percent": 82.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1062249075956445, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9594725237321602, "policy_loss": -0.0017906091095899386, "vf_loss": 0.9611172444058986, "vf_explained_var": 0.17233828375579188, "kl": 0.01556160971771119, "entropy": 0.7470249610603171, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.830466470548085, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1056145283910963, "policy_loss": -0.00358369924404003, "vf_loss": 3.1086706971365308, "vf_explained_var": 0.2954133147600467, "kl": 0.007410130251337636, "entropy": 1.0366001863958973, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 384.03999999999996, "episode_reward_min": -530.9300000000001, "episode_reward_mean": 185.69029999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 70.07015000000003, "predator_policy": 22.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.130000000000082, 169.9899999999999, 322.12999999999994, 352.1099999999999, 310.0, 2.989999999999981, -122.10999999999908, 352.29999999999995, 319.68, 190.09999999999968, 324.1399999999999, -179.00000000000017, 337.31999999999994, -4.920000000000044, 339.37999999999994, 129.32000000000016, 178.08999999999986, 213.09000000000003, 255.30999999999997, 173.14999999999964, 362.12, 14.020000000000042, 96.06000000000012, 262.2800000000001, 338.2299999999999, 354.0899999999999, 48.13999999999999, 209.91999999999962, 306.09, -460.97, -170.91, -0.04000000000003833, -7.110000000000083, 273.05999999999995, 367.0799999999999, 141.31000000000017, 101.01000000000019, 113.76000000000032, 152.78999999999996, 313.66999999999945, 129.25000000000034, 173.00999999999982, 187.64999999999986, 101.13000000000022, 192.97999999999968, 125.68000000000029, 310.19999999999993, 139.46999999999935, 68.7200000000007, 188.69999999999948, 142.70999999999998, 351.17999999999995, 186.54999999999978, 153.09000000000012, 281.82999999999925, 30.660000000000267, 184.9799999999998, 143.29000000000005, 70.07000000000103, 338.41999999999985, 307.6799999999998, 353.28999999999985, 125.39000000000027, 272.4399999999998, 232.41999999999982, 186.07999999999976, 279.23999999999995, 313.07, 171.23999999999953, -14.129999999999729, 142.99000000000012, 273.02999999999906, -3.060000000000084, 127.1300000000005, 156.15999999999997, 305.27000000000004, 349.21999999999986, 285.15, -167.7000000000001, 149.04000000000013, 174.25999999999985, 346.42999999999995, 342.31999999999994, 313.50999999999993, 369.17999999999995, 222.76999999999958, 26.670000000000545, 371.03999999999996, 357.2899999999999, 347.4099999999999, 181.9999999999998, 331.38, 384.03999999999996, 176.07999999999984, 339.40999999999974, 340.44999999999993, 323.16999999999985, 145.29000000000013, 196.1999999999999, -530.9300000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-6.040000000000042, -16.0899999999997, 157.04000000000002, -8.050000000000042, 173.06, 76.07, 177.05, 155.06, 173.0, 29.0, -0.00999999999999836, 2.0000000000000013, -80.40999999999987, -138.7000000000004, 178.04000000000002, 165.26, 138.41, 173.27, -0.00999999999999836, 189.10999999999999, 192.07999999999993, 83.05999999999999, 2.0000000000000013, -400.0, 186.14000000000004, 101.17999999999998, -377.89, -4.030000000000042, 113.23999999999995, 186.13999999999996, 55.160000000000046, -19.840000000000046, 164.08999999999997, 2.0000000000000013, 68.0, 59.089999999999996, 134.24000000000004, 67.07000000000001, 174.1999999999999, -8.050000000000042, 181.07, 159.05, 2.0000000000000013, -95.98, 14.060000000000025, 2.0000000000000013, 116.11999999999999, 91.16000000000001, 188.12, 111.11, 194.05999999999995, 140.03000000000003, -70.0, -17.86, 16.85000000000011, 193.07000000000002, 198.01999999999998, 61.07, -400.0, -276.97, -151.0, -222.91, -6.040000000000041, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -28.960000000000022, 198.01999999999998, 181.03999999999996, 175.04000000000002, 126.32000000000004, -0.00999999999999836, 61.069999999999986, -10.060000000000041, -98.49999999999925, 150.2599999999999, -88.44999999999945, 176.23999999999998, 148.51999999999953, 155.14999999999992, -24.129999999999708, 129.38000000000002, -16.0899999999997, 166.09999999999997, 147.17, 20.480000000000228, 57.140000000000015, -0.00999999999999836, 194.06, -14.080000000000041, 134.0, -62.32000000000033, 144.05, 131.14999999999992, 124.49000000000025, -2.020000000000042, 8.719999999999985, 2.0000000000000013, 7.579999999999989, 95.11999999999998, -76.38999999999919, 175.0999999999999, 130.13, 186.05, 37.45999999999971, 116.08999999999999, 2.0000000000000013, 131.09000000000003, 88.76000000000037, 175.07000000000005, -34.18000000000032, 11.83999999999998, 184.01, -4.030000000000042, 99.29000000000003, 2.0000000000000013, 67.13000000000052, -10.060000000000041, 115.31000000000003, 189.11, 176.23999999999995, 105.44, 180.19999999999993, 164.09, 47.39000000000017, 2.0000000000000013, 101.24000000000001, 123.20000000000007, 27.290000000000035, 142.13, 174.08, 2.0000000000000013, 131.12, 104.12, 160.04, 113.03, 2.0000000000000013, 155.23999999999984, -12.070000000000041, -10.060000000000041, -12.070000000000041, 125.06000000000002, 138.01999999999998, 100.01000000000052, -4.030000000000042, -4.030000000000042, -16.08999999999971, 112.22000000000001, -16.0899999999997, 157.24999999999994, 147.2, 112.07000000000002, 169.16000000000005, 170.05999999999997, 146.06, 98.08999999999999, -331.65999999999997, -6.040000000000042, -14.080000000000041, 134.12000000000003, -2.020000000000042, 172.28, 164.18, 175.25, 153.07999999999998, 176.23999999999998, 108.35000000000005, 184.15999999999997, 198.01999999999998, 154.16000000000003, 104.11999999999998, 72.65000000000026, 27.710000000000267, -6.040000000000042, 174.01999999999998, 183.01999999999998, 168.11000000000004, 182.18, 168.11000000000007, 170.3, 182.06, -10.060000000000041, 174.26, 137.12, 178.04000000000002, 200.0, 159.07999999999998, 2.0000000000000013, 179.21000000000004, 150.19999999999996, 176.23999999999998, 152.21000000000004, 137.14999999999986, 159.01999999999998, -2.020000000000042, 121.31000000000004, 72.05, 68.14999999999999, -343.93, -400.0], "policy_predator_policy_reward": [3.0, 9.0, 15.0, 6.0, 39.0, 34.0, 8.0, 12.0, 60.0, 48.0, 1.0, 0.0, 3.0, 94.0, 6.0, 3.0, 2.0, 6.0, 1.0, 0.0, 12.0, 37.0, 19.0, 200.0, 27.0, 23.0, 188.0, 189.0, 19.0, 21.0, 26.0, 68.0, 3.0, 9.0, 33.0, 53.0, 24.0, 30.0, 5.0, 2.0, 12.0, 10.0, 98.0, 10.0, 60.0, 20.0, 17.0, 38.0, 16.0, 23.0, 1.0, 19.0, 125.0, 11.0, 0.0, 0.0, 44.0, 3.0, 200.0, 16.0, 10.0, 193.0, 4.0, 0.0, 4.0, 7.0, 29.0, 75.0, 5.0, 6.0, 14.0, 1.0, 44.0, 6.0, 50.0, 12.0, 30.0, 35.0, 3.0, 7.0, 11.0, 13.0, 14.0, 9.0, 9.0, 11.0, 1.0, 43.0, 5.0, 8.0, 32.0, 22.0, 18.0, 17.0, 9.0, 8.0, 40.0, 18.0, 56.0, 30.0, 39.0, 5.0, 16.0, 19.0, 20.0, 13.0, 20.0, 0.0, 6.0, 12.0, 18.0, 35.0, 5.0, 0.0, 18.0, 24.0, 7.0, 6.0, 18.0, 16.0, 17.0, 9.0, 0.0, 9.0, 38.0, 38.0, 21.0, 27.0, 51.0, 12.0, 4.0, 6.0, 28.0, 16.0, 12.0, 28.0, 7.0, 7.0, 1.0, 7.0, 24.0, 6.0, 20.0, 15.0, 3.0, 2.0, 22.0, 9.0, 9.0, 6.0, 24.0, 22.0, 2.0, 8.0, 1.0, 40.0, 170.0, 0.0, 16.0, 13.0, 2.0, 2.0, 1.0, 6.0, 0.0, 13.0, 19.0, 2.0, 10.0, 7.0, 15.0, 31.0, 1.0, 4.0, 6.0, 8.0, 0.0, 7.0, 2.0, 7.0, 4.0, 6.0, 17.0, 3.0, 0.0, 6.0, 11.0, 4.0, 8.0, 2.0, 3.0, 9.0, 16.0, 11.0, 17.0, 9.0, 47.0, 9.0, 13.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.678409507836201, "mean_inference_ms": 1.8582496444772836, "mean_action_processing_ms": 0.28672744171865655, "mean_env_wait_ms": 0.22763539800016916, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046378374099731445, "StateBufferConnector_ms": 0.003962039947509766, "ViewRequirementAgentConnector_ms": 0.11538982391357422}, "num_episodes": 23, "episode_return_max": 384.03999999999996, "episode_return_min": -530.9300000000001, "episode_return_mean": 185.69029999999995, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 331.5056267302209, "num_env_steps_trained_throughput_per_sec": 331.5056267302209, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 12276.401, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12276.352, "sample_time_ms": 1568.852, "learn_time_ms": 10689.179, "learn_throughput": 374.21, "synch_weights_time_ms": 15.81}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "310e1_00000", "date": "2024-08-15_01-14-17", "timestamp": 1723664657, "time_this_iter_s": 12.119592189788818, "time_total_s": 1010.7973115444183, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19f4d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1010.7973115444183, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 58.8764705882353, "ram_util_percent": 82.86470588235295}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.22229483848211, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5017511036345568, "policy_loss": -0.002963998990636023, "vf_loss": 1.5045401230060234, "vf_explained_var": 0.15178607339581485, "kl": 0.018664706786329727, "entropy": 0.6540973072960263, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1601547302392423, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3486013573944255, "policy_loss": -0.004933398826264594, "vf_loss": 3.3529650416954486, "vf_explained_var": 0.4635594806027791, "kl": 0.008002583618894997, "entropy": 1.0481979460943314, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 384.03999999999996, "episode_reward_min": -530.9300000000001, "episode_reward_mean": 197.25439999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 77.9822, "predator_policy": 20.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [255.30999999999997, 173.14999999999964, 362.12, 14.020000000000042, 96.06000000000012, 262.2800000000001, 338.2299999999999, 354.0899999999999, 48.13999999999999, 209.91999999999962, 306.09, -460.97, -170.91, -0.04000000000003833, -7.110000000000083, 273.05999999999995, 367.0799999999999, 141.31000000000017, 101.01000000000019, 113.76000000000032, 152.78999999999996, 313.66999999999945, 129.25000000000034, 173.00999999999982, 187.64999999999986, 101.13000000000022, 192.97999999999968, 125.68000000000029, 310.19999999999993, 139.46999999999935, 68.7200000000007, 188.69999999999948, 142.70999999999998, 351.17999999999995, 186.54999999999978, 153.09000000000012, 281.82999999999925, 30.660000000000267, 184.9799999999998, 143.29000000000005, 70.07000000000103, 338.41999999999985, 307.6799999999998, 353.28999999999985, 125.39000000000027, 272.4399999999998, 232.41999999999982, 186.07999999999976, 279.23999999999995, 313.07, 171.23999999999953, -14.129999999999729, 142.99000000000012, 273.02999999999906, -3.060000000000084, 127.1300000000005, 156.15999999999997, 305.27000000000004, 349.21999999999986, 285.15, -167.7000000000001, 149.04000000000013, 174.25999999999985, 346.42999999999995, 342.31999999999994, 313.50999999999993, 369.17999999999995, 222.76999999999958, 26.670000000000545, 371.03999999999996, 357.2899999999999, 347.4099999999999, 181.9999999999998, 331.38, 384.03999999999996, 176.07999999999984, 339.40999999999974, 340.44999999999993, 323.16999999999985, 145.29000000000013, 196.1999999999999, -530.9300000000001, 305.3099999999998, 183.97999999999973, 355.12, 354.3499999999997, 361.27, 344.39999999999975, 263.33, 269.26999999999987, 328.1799999999999, 276.2099999999999, 193.96999999999966, 177.08999999999975, 183.05999999999977, 124.89000000000031, 156.21000000000004, 337.20999999999987, -15.139999999999551, 182.17999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [134.24000000000004, 67.07000000000001, 174.1999999999999, -8.050000000000042, 181.07, 159.05, 2.0000000000000013, -95.98, 14.060000000000025, 2.0000000000000013, 116.11999999999999, 91.16000000000001, 188.12, 111.11, 194.05999999999995, 140.03000000000003, -70.0, -17.86, 16.85000000000011, 193.07000000000002, 198.01999999999998, 61.07, -400.0, -276.97, -151.0, -222.91, -6.040000000000041, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -28.960000000000022, 198.01999999999998, 181.03999999999996, 175.04000000000002, 126.32000000000004, -0.00999999999999836, 61.069999999999986, -10.060000000000041, -98.49999999999925, 150.2599999999999, -88.44999999999945, 176.23999999999998, 148.51999999999953, 155.14999999999992, -24.129999999999708, 129.38000000000002, -16.0899999999997, 166.09999999999997, 147.17, 20.480000000000228, 57.140000000000015, -0.00999999999999836, 194.06, -14.080000000000041, 134.0, -62.32000000000033, 144.05, 131.14999999999992, 124.49000000000025, -2.020000000000042, 8.719999999999985, 2.0000000000000013, 7.579999999999989, 95.11999999999998, -76.38999999999919, 175.0999999999999, 130.13, 186.05, 37.45999999999971, 116.08999999999999, 2.0000000000000013, 131.09000000000003, 88.76000000000037, 175.07000000000005, -34.18000000000032, 11.83999999999998, 184.01, -4.030000000000042, 99.29000000000003, 2.0000000000000013, 67.13000000000052, -10.060000000000041, 115.31000000000003, 189.11, 176.23999999999995, 105.44, 180.19999999999993, 164.09, 47.39000000000017, 2.0000000000000013, 101.24000000000001, 123.20000000000007, 27.290000000000035, 142.13, 174.08, 2.0000000000000013, 131.12, 104.12, 160.04, 113.03, 2.0000000000000013, 155.23999999999984, -12.070000000000041, -10.060000000000041, -12.070000000000041, 125.06000000000002, 138.01999999999998, 100.01000000000052, -4.030000000000042, -4.030000000000042, -16.08999999999971, 112.22000000000001, -16.0899999999997, 157.24999999999994, 147.2, 112.07000000000002, 169.16000000000005, 170.05999999999997, 146.06, 98.08999999999999, -331.65999999999997, -6.040000000000042, -14.080000000000041, 134.12000000000003, -2.020000000000042, 172.28, 164.18, 175.25, 153.07999999999998, 176.23999999999998, 108.35000000000005, 184.15999999999997, 198.01999999999998, 154.16000000000003, 104.11999999999998, 72.65000000000026, 27.710000000000267, -6.040000000000042, 174.01999999999998, 183.01999999999998, 168.11000000000004, 182.18, 168.11000000000007, 170.3, 182.06, -10.060000000000041, 174.26, 137.12, 178.04000000000002, 200.0, 159.07999999999998, 2.0000000000000013, 179.21000000000004, 150.19999999999996, 176.23999999999998, 152.21000000000004, 137.14999999999986, 159.01999999999998, -2.020000000000042, 121.31000000000004, 72.05, 68.14999999999999, -343.93, -400.0, 149.12, 127.19, 178.01, -4.030000000000042, 131.09, 194.02999999999997, 162.32000000000016, 185.02999999999997, 163.10000000000002, 183.17, 184.16000000000003, 152.24, 95.30000000000004, 134.03, 52.07000000000001, 123.20000000000007, 134.12, 167.05999999999997, 94.07000000000004, 132.14000000000001, -10.060000000000041, 197.02999999999997, 149.08999999999995, 2.0000000000000013, 175.13, -12.070000000000041, 123.11, -42.220000000000354, 125.20999999999995, 2.0000000000000013, 166.07, 159.14000000000004, -10.060000000000041, -14.080000000000041, -400.0, 182.17999999999995], "policy_predator_policy_reward": [24.0, 30.0, 5.0, 2.0, 12.0, 10.0, 98.0, 10.0, 60.0, 20.0, 17.0, 38.0, 16.0, 23.0, 1.0, 19.0, 125.0, 11.0, 0.0, 0.0, 44.0, 3.0, 200.0, 16.0, 10.0, 193.0, 4.0, 0.0, 4.0, 7.0, 29.0, 75.0, 5.0, 6.0, 14.0, 1.0, 44.0, 6.0, 50.0, 12.0, 30.0, 35.0, 3.0, 7.0, 11.0, 13.0, 14.0, 9.0, 9.0, 11.0, 1.0, 43.0, 5.0, 8.0, 32.0, 22.0, 18.0, 17.0, 9.0, 8.0, 40.0, 18.0, 56.0, 30.0, 39.0, 5.0, 16.0, 19.0, 20.0, 13.0, 20.0, 0.0, 6.0, 12.0, 18.0, 35.0, 5.0, 0.0, 18.0, 24.0, 7.0, 6.0, 18.0, 16.0, 17.0, 9.0, 0.0, 9.0, 38.0, 38.0, 21.0, 27.0, 51.0, 12.0, 4.0, 6.0, 28.0, 16.0, 12.0, 28.0, 7.0, 7.0, 1.0, 7.0, 24.0, 6.0, 20.0, 15.0, 3.0, 2.0, 22.0, 9.0, 9.0, 6.0, 24.0, 22.0, 2.0, 8.0, 1.0, 40.0, 170.0, 0.0, 16.0, 13.0, 2.0, 2.0, 1.0, 6.0, 0.0, 13.0, 19.0, 2.0, 10.0, 7.0, 15.0, 31.0, 1.0, 4.0, 6.0, 8.0, 0.0, 7.0, 2.0, 7.0, 4.0, 6.0, 17.0, 3.0, 0.0, 6.0, 11.0, 4.0, 8.0, 2.0, 3.0, 9.0, 16.0, 11.0, 17.0, 9.0, 47.0, 9.0, 13.0, 200.0, 20.0, 9.0, 6.0, 4.0, 20.0, 10.0, 3.0, 4.0, 6.0, 9.0, 8.0, 0.0, 4.0, 30.0, 47.0, 47.0, 18.0, 9.0, 39.0, 11.0, 1.0, 6.0, 12.0, 14.0, 9.0, 11.0, 29.0, 15.0, 16.0, 13.0, 3.0, 9.0, 8.0, 1.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6782094383587471, "mean_inference_ms": 1.8611123404375354, "mean_action_processing_ms": 0.2865352287120583, "mean_env_wait_ms": 0.22755969892975694, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004364728927612305, "StateBufferConnector_ms": 0.003908991813659668, "ViewRequirementAgentConnector_ms": 0.11329197883605957}, "num_episodes": 18, "episode_return_max": 384.03999999999996, "episode_return_min": -530.9300000000001, "episode_return_mean": 197.25439999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.3969364967519, "num_env_steps_trained_throughput_per_sec": 329.3969364967519, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 12267.546, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12267.498, "sample_time_ms": 1557.814, "learn_time_ms": 10691.052, "learn_throughput": 374.145, "synch_weights_time_ms": 16.18}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "310e1_00000", "date": "2024-08-15_01-14-29", "timestamp": 1723664669, "time_this_iter_s": 12.179534673690796, "time_total_s": 1022.9768462181091, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1995ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1022.9768462181091, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 58.67222222222222, "ram_util_percent": 83.05}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6326302046340608, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1428306224169555, "policy_loss": -0.0032298700179333095, "vf_loss": 1.1458341346058265, "vf_explained_var": 0.30528016030473054, "kl": 0.024144935513029115, "entropy": 0.809652210007269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0972731713580077, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3571667335020803, "policy_loss": -0.002189741928066329, "vf_loss": 3.3588965086709885, "vf_explained_var": 0.469051975957931, "kl": 0.006460964977112783, "entropy": 1.0293643088883193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 384.03999999999996, "episode_reward_min": -542.8199999999999, "episode_reward_mean": 199.9920999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 81.18605000000002, "predator_policy": 18.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [129.25000000000034, 173.00999999999982, 187.64999999999986, 101.13000000000022, 192.97999999999968, 125.68000000000029, 310.19999999999993, 139.46999999999935, 68.7200000000007, 188.69999999999948, 142.70999999999998, 351.17999999999995, 186.54999999999978, 153.09000000000012, 281.82999999999925, 30.660000000000267, 184.9799999999998, 143.29000000000005, 70.07000000000103, 338.41999999999985, 307.6799999999998, 353.28999999999985, 125.39000000000027, 272.4399999999998, 232.41999999999982, 186.07999999999976, 279.23999999999995, 313.07, 171.23999999999953, -14.129999999999729, 142.99000000000012, 273.02999999999906, -3.060000000000084, 127.1300000000005, 156.15999999999997, 305.27000000000004, 349.21999999999986, 285.15, -167.7000000000001, 149.04000000000013, 174.25999999999985, 346.42999999999995, 342.31999999999994, 313.50999999999993, 369.17999999999995, 222.76999999999958, 26.670000000000545, 371.03999999999996, 357.2899999999999, 347.4099999999999, 181.9999999999998, 331.38, 384.03999999999996, 176.07999999999984, 339.40999999999974, 340.44999999999993, 323.16999999999985, 145.29000000000013, 196.1999999999999, -530.9300000000001, 305.3099999999998, 183.97999999999973, 355.12, 354.3499999999997, 361.27, 344.39999999999975, 263.33, 269.26999999999987, 328.1799999999999, 276.2099999999999, 193.96999999999966, 177.08999999999975, 183.05999999999977, 124.89000000000031, 156.21000000000004, 337.20999999999987, -15.139999999999551, 182.17999999999995, -219.81000000000017, 1.960000000000003, -65.87999999999995, -542.8199999999999, 182.8599999999998, 176.04999999999993, 1.9300000000000028, 302.24999999999994, 341.24999999999983, 330.08000000000004, 313.7799999999994, 345.49999999999994, 334.3599999999999, 342.1699999999999, 311.1399999999999, 150.12000000000012, 181.9999999999998, 134.48999999999944, 189.0199999999997, 188.03999999999974, 355.35, 162.99], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.129999999999708, 129.38000000000002, -16.0899999999997, 166.09999999999997, 147.17, 20.480000000000228, 57.140000000000015, -0.00999999999999836, 194.06, -14.080000000000041, 134.0, -62.32000000000033, 144.05, 131.14999999999992, 124.49000000000025, -2.020000000000042, 8.719999999999985, 2.0000000000000013, 7.579999999999989, 95.11999999999998, -76.38999999999919, 175.0999999999999, 130.13, 186.05, 37.45999999999971, 116.08999999999999, 2.0000000000000013, 131.09000000000003, 88.76000000000037, 175.07000000000005, -34.18000000000032, 11.83999999999998, 184.01, -4.030000000000042, 99.29000000000003, 2.0000000000000013, 67.13000000000052, -10.060000000000041, 115.31000000000003, 189.11, 176.23999999999995, 105.44, 180.19999999999993, 164.09, 47.39000000000017, 2.0000000000000013, 101.24000000000001, 123.20000000000007, 27.290000000000035, 142.13, 174.08, 2.0000000000000013, 131.12, 104.12, 160.04, 113.03, 2.0000000000000013, 155.23999999999984, -12.070000000000041, -10.060000000000041, -12.070000000000041, 125.06000000000002, 138.01999999999998, 100.01000000000052, -4.030000000000042, -4.030000000000042, -16.08999999999971, 112.22000000000001, -16.0899999999997, 157.24999999999994, 147.2, 112.07000000000002, 169.16000000000005, 170.05999999999997, 146.06, 98.08999999999999, -331.65999999999997, -6.040000000000042, -14.080000000000041, 134.12000000000003, -2.020000000000042, 172.28, 164.18, 175.25, 153.07999999999998, 176.23999999999998, 108.35000000000005, 184.15999999999997, 198.01999999999998, 154.16000000000003, 104.11999999999998, 72.65000000000026, 27.710000000000267, -6.040000000000042, 174.01999999999998, 183.01999999999998, 168.11000000000004, 182.18, 168.11000000000007, 170.3, 182.06, -10.060000000000041, 174.26, 137.12, 178.04000000000002, 200.0, 159.07999999999998, 2.0000000000000013, 179.21000000000004, 150.19999999999996, 176.23999999999998, 152.21000000000004, 137.14999999999986, 159.01999999999998, -2.020000000000042, 121.31000000000004, 72.05, 68.14999999999999, -343.93, -400.0, 149.12, 127.19, 178.01, -4.030000000000042, 131.09, 194.02999999999997, 162.32000000000016, 185.02999999999997, 163.10000000000002, 183.17, 184.16000000000003, 152.24, 95.30000000000004, 134.03, 52.07000000000001, 123.20000000000007, 134.12, 167.05999999999997, 94.07000000000004, 132.14000000000001, -10.060000000000041, 197.02999999999997, 149.08999999999995, 2.0000000000000013, 175.13, -12.070000000000041, 123.11, -42.220000000000354, 125.20999999999995, 2.0000000000000013, 166.07, 159.14000000000004, -10.060000000000041, -14.080000000000041, -400.0, 182.17999999999995, -241.96000000000004, -132.85000000000014, -0.00999999999999836, -4.030000000000042, -71.94999999999999, -157.93000000000006, -400.0, -342.82, 181.19, -64.32999999999915, 177.11, -7.060000000000041, -12.070000000000041, 2.0000000000000013, 128.21, 121.03999999999999, 168.11000000000007, 156.14, 154.01, 151.07, 195.05, 106.73000000000033, 169.31, 169.19, 155.15, 161.20999999999998, 147.05, 170.11999999999992, 176.12000000000003, 90.02, 116.12000000000002, 2.0000000000000013, 2.0000000000000013, 143.0, -0.00999999999999836, 123.50000000000023, 180.01999999999998, 2.0000000000000013, -0.00999999999999836, 183.04999999999998, 155.15000000000003, 180.20000000000002, 144.05, -10.060000000000041], "policy_predator_policy_reward": [11.0, 13.0, 14.0, 9.0, 9.0, 11.0, 1.0, 43.0, 5.0, 8.0, 32.0, 22.0, 18.0, 17.0, 9.0, 8.0, 40.0, 18.0, 56.0, 30.0, 39.0, 5.0, 16.0, 19.0, 20.0, 13.0, 20.0, 0.0, 6.0, 12.0, 18.0, 35.0, 5.0, 0.0, 18.0, 24.0, 7.0, 6.0, 18.0, 16.0, 17.0, 9.0, 0.0, 9.0, 38.0, 38.0, 21.0, 27.0, 51.0, 12.0, 4.0, 6.0, 28.0, 16.0, 12.0, 28.0, 7.0, 7.0, 1.0, 7.0, 24.0, 6.0, 20.0, 15.0, 3.0, 2.0, 22.0, 9.0, 9.0, 6.0, 24.0, 22.0, 2.0, 8.0, 1.0, 40.0, 170.0, 0.0, 16.0, 13.0, 2.0, 2.0, 1.0, 6.0, 0.0, 13.0, 19.0, 2.0, 10.0, 7.0, 15.0, 31.0, 1.0, 4.0, 6.0, 8.0, 0.0, 7.0, 2.0, 7.0, 4.0, 6.0, 17.0, 3.0, 0.0, 6.0, 11.0, 4.0, 8.0, 2.0, 3.0, 9.0, 16.0, 11.0, 17.0, 9.0, 47.0, 9.0, 13.0, 200.0, 20.0, 9.0, 6.0, 4.0, 20.0, 10.0, 3.0, 4.0, 6.0, 9.0, 8.0, 0.0, 4.0, 30.0, 47.0, 47.0, 18.0, 9.0, 39.0, 11.0, 1.0, 6.0, 12.0, 14.0, 9.0, 11.0, 29.0, 15.0, 16.0, 13.0, 3.0, 9.0, 8.0, 1.0, 200.0, 200.0, 2.0, 153.0, 3.0, 3.0, 29.0, 135.0, 0.0, 200.0, 33.0, 33.0, 0.0, 6.0, 5.0, 7.0, 24.0, 29.0, 10.0, 7.0, 10.0, 15.0, 5.0, 7.0, 3.0, 4.0, 8.0, 10.0, 19.0, 6.0, 32.0, 13.0, 8.0, 24.0, 19.0, 18.0, 9.0, 2.0, 1.0, 6.0, 0.0, 5.0, 10.0, 10.0, 15.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6775321407281454, "mean_inference_ms": 1.863742679732223, "mean_action_processing_ms": 0.28578259584648813, "mean_env_wait_ms": 0.22750799408275374, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004090070724487305, "StateBufferConnector_ms": 0.0034259557723999023, "ViewRequirementAgentConnector_ms": 0.11549460887908936}, "num_episodes": 22, "episode_return_max": 384.03999999999996, "episode_return_min": -542.8199999999999, "episode_return_mean": 199.9920999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.41350497963595, "num_env_steps_trained_throughput_per_sec": 339.41350497963595, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 12210.614, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12210.563, "sample_time_ms": 1552.705, "learn_time_ms": 10638.31, "learn_throughput": 376.0, "synch_weights_time_ms": 16.963}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "310e1_00000", "date": "2024-08-15_01-14-41", "timestamp": 1723664681, "time_this_iter_s": 11.846384763717651, "time_total_s": 1034.8232309818268, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19c5af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1034.8232309818268, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 55.681250000000006, "ram_util_percent": 83.11250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.126514363288879, "cur_kl_coeff": 0.014062500000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9116343235843396, "policy_loss": -0.0026083645435473904, "vf_loss": 1.914044819717054, "vf_explained_var": 0.21976351747437128, "kl": 0.014070392636783433, "entropy": 0.7288763997731386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.94811149510757, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8572405369824203, "policy_loss": -0.0027305133591489818, "vf_loss": 3.8595879137200653, "vf_explained_var": 0.3176836335785175, "kl": 0.005381808094595934, "entropy": 0.9616722899454612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 384.03999999999996, "episode_reward_min": -557.97, "episode_reward_mean": 189.19219999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 72.70609999999999, "predator_policy": 21.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [70.07000000000103, 338.41999999999985, 307.6799999999998, 353.28999999999985, 125.39000000000027, 272.4399999999998, 232.41999999999982, 186.07999999999976, 279.23999999999995, 313.07, 171.23999999999953, -14.129999999999729, 142.99000000000012, 273.02999999999906, -3.060000000000084, 127.1300000000005, 156.15999999999997, 305.27000000000004, 349.21999999999986, 285.15, -167.7000000000001, 149.04000000000013, 174.25999999999985, 346.42999999999995, 342.31999999999994, 313.50999999999993, 369.17999999999995, 222.76999999999958, 26.670000000000545, 371.03999999999996, 357.2899999999999, 347.4099999999999, 181.9999999999998, 331.38, 384.03999999999996, 176.07999999999984, 339.40999999999974, 340.44999999999993, 323.16999999999985, 145.29000000000013, 196.1999999999999, -530.9300000000001, 305.3099999999998, 183.97999999999973, 355.12, 354.3499999999997, 361.27, 344.39999999999975, 263.33, 269.26999999999987, 328.1799999999999, 276.2099999999999, 193.96999999999966, 177.08999999999975, 183.05999999999977, 124.89000000000031, 156.21000000000004, 337.20999999999987, -15.139999999999551, 182.17999999999995, -219.81000000000017, 1.960000000000003, -65.87999999999995, -542.8199999999999, 182.8599999999998, 176.04999999999993, 1.9300000000000028, 302.24999999999994, 341.24999999999983, 330.08000000000004, 313.7799999999994, 345.49999999999994, 334.3599999999999, 342.1699999999999, 311.1399999999999, 150.12000000000012, 181.9999999999998, 134.48999999999944, 189.0199999999997, 188.03999999999974, 355.35, 162.99, 44.89000000000003, 186.22, -557.97, 183.00999999999976, 350.13999999999993, 339.24999999999983, 364.12, 155.98000000000008, 279.04999999999995, 356.2599999999999, -201.03000000000037, 360.21999999999997, -21.47000000000003, 90.04000000000009, 101.17000000000007, 158.95000000000002, -537.0, 359.2599999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [67.13000000000052, -10.060000000000041, 115.31000000000003, 189.11, 176.23999999999995, 105.44, 180.19999999999993, 164.09, 47.39000000000017, 2.0000000000000013, 101.24000000000001, 123.20000000000007, 27.290000000000035, 142.13, 174.08, 2.0000000000000013, 131.12, 104.12, 160.04, 113.03, 2.0000000000000013, 155.23999999999984, -12.070000000000041, -10.060000000000041, -12.070000000000041, 125.06000000000002, 138.01999999999998, 100.01000000000052, -4.030000000000042, -4.030000000000042, -16.08999999999971, 112.22000000000001, -16.0899999999997, 157.24999999999994, 147.2, 112.07000000000002, 169.16000000000005, 170.05999999999997, 146.06, 98.08999999999999, -331.65999999999997, -6.040000000000042, -14.080000000000041, 134.12000000000003, -2.020000000000042, 172.28, 164.18, 175.25, 153.07999999999998, 176.23999999999998, 108.35000000000005, 184.15999999999997, 198.01999999999998, 154.16000000000003, 104.11999999999998, 72.65000000000026, 27.710000000000267, -6.040000000000042, 174.01999999999998, 183.01999999999998, 168.11000000000004, 182.18, 168.11000000000007, 170.3, 182.06, -10.060000000000041, 174.26, 137.12, 178.04000000000002, 200.0, 159.07999999999998, 2.0000000000000013, 179.21000000000004, 150.19999999999996, 176.23999999999998, 152.21000000000004, 137.14999999999986, 159.01999999999998, -2.020000000000042, 121.31000000000004, 72.05, 68.14999999999999, -343.93, -400.0, 149.12, 127.19, 178.01, -4.030000000000042, 131.09, 194.02999999999997, 162.32000000000016, 185.02999999999997, 163.10000000000002, 183.17, 184.16000000000003, 152.24, 95.30000000000004, 134.03, 52.07000000000001, 123.20000000000007, 134.12, 167.05999999999997, 94.07000000000004, 132.14000000000001, -10.060000000000041, 197.02999999999997, 149.08999999999995, 2.0000000000000013, 175.13, -12.070000000000041, 123.11, -42.220000000000354, 125.20999999999995, 2.0000000000000013, 166.07, 159.14000000000004, -10.060000000000041, -14.080000000000041, -400.0, 182.17999999999995, -241.96000000000004, -132.85000000000014, -0.00999999999999836, -4.030000000000042, -71.94999999999999, -157.93000000000006, -400.0, -342.82, 181.19, -64.32999999999915, 177.11, -7.060000000000041, -12.070000000000041, 2.0000000000000013, 128.21, 121.03999999999999, 168.11000000000007, 156.14, 154.01, 151.07, 195.05, 106.73000000000033, 169.31, 169.19, 155.15, 161.20999999999998, 147.05, 170.11999999999992, 176.12000000000003, 90.02, 116.12000000000002, 2.0000000000000013, 2.0000000000000013, 143.0, -0.00999999999999836, 123.50000000000023, 180.01999999999998, 2.0000000000000013, -0.00999999999999836, 183.04999999999998, 155.15000000000003, 180.20000000000002, 144.05, -10.060000000000041, -221.1100000000008, 143.0, -25.899999999999984, 125.12, -400.0, -384.97, 172.01, 2.0000000000000013, 175.09999999999997, 157.04000000000002, 190.07, 125.18000000000008, 182.06, 164.06, -14.080000000000041, 146.06, 127.04000000000002, 124.00999999999999, 189.07999999999998, 158.18, -400.0, -4.030000000000042, 173.14999999999998, 178.07000000000002, -32.17000000000001, -58.30000000000034, -0.00999999999999836, 36.05000000000001, -3.9099999999999646, 3.080000000000032, 143.0, -8.050000000000042, -364.0, -373.0, 183.14, 164.11999999999998], "policy_predator_policy_reward": [7.0, 6.0, 18.0, 16.0, 17.0, 9.0, 0.0, 9.0, 38.0, 38.0, 21.0, 27.0, 51.0, 12.0, 4.0, 6.0, 28.0, 16.0, 12.0, 28.0, 7.0, 7.0, 1.0, 7.0, 24.0, 6.0, 20.0, 15.0, 3.0, 2.0, 22.0, 9.0, 9.0, 6.0, 24.0, 22.0, 2.0, 8.0, 1.0, 40.0, 170.0, 0.0, 16.0, 13.0, 2.0, 2.0, 1.0, 6.0, 0.0, 13.0, 19.0, 2.0, 10.0, 7.0, 15.0, 31.0, 1.0, 4.0, 6.0, 8.0, 0.0, 7.0, 2.0, 7.0, 4.0, 6.0, 17.0, 3.0, 0.0, 6.0, 11.0, 4.0, 8.0, 2.0, 3.0, 9.0, 16.0, 11.0, 17.0, 9.0, 47.0, 9.0, 13.0, 200.0, 20.0, 9.0, 6.0, 4.0, 20.0, 10.0, 3.0, 4.0, 6.0, 9.0, 8.0, 0.0, 4.0, 30.0, 47.0, 47.0, 18.0, 9.0, 39.0, 11.0, 1.0, 6.0, 12.0, 14.0, 9.0, 11.0, 29.0, 15.0, 16.0, 13.0, 3.0, 9.0, 8.0, 1.0, 200.0, 200.0, 2.0, 153.0, 3.0, 3.0, 29.0, 135.0, 0.0, 200.0, 33.0, 33.0, 0.0, 6.0, 5.0, 7.0, 24.0, 29.0, 10.0, 7.0, 10.0, 15.0, 5.0, 7.0, 3.0, 4.0, 8.0, 10.0, 19.0, 6.0, 32.0, 13.0, 8.0, 24.0, 19.0, 18.0, 9.0, 2.0, 1.0, 6.0, 0.0, 5.0, 10.0, 10.0, 15.0, 14.0, 119.0, 4.0, 8.0, 79.0, 27.0, 200.0, 9.0, 0.0, 0.0, 18.0, 19.0, 5.0, 8.0, 10.0, 4.0, 20.0, 3.0, 25.0, 0.0, 9.0, 200.0, 3.0, 5.0, 4.0, 43.0, 26.0, 45.0, 9.0, 80.0, 22.0, 5.0, 19.0, 195.0, 5.0, 9.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6774297213256869, "mean_inference_ms": 1.8662761803848609, "mean_action_processing_ms": 0.2859098503146454, "mean_env_wait_ms": 0.22728455164451017, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003973245620727539, "StateBufferConnector_ms": 0.0032989978790283203, "ViewRequirementAgentConnector_ms": 0.11330759525299072}, "num_episodes": 18, "episode_return_max": 384.03999999999996, "episode_return_min": -557.97, "episode_return_mean": 189.19219999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.1163685350938, "num_env_steps_trained_throughput_per_sec": 325.1163685350938, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 12199.894, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12199.843, "sample_time_ms": 1543.377, "learn_time_ms": 10635.571, "learn_throughput": 376.096, "synch_weights_time_ms": 18.14}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "310e1_00000", "date": "2024-08-15_01-14-53", "timestamp": 1723664693, "time_this_iter_s": 12.371209144592285, "time_total_s": 1047.194440126419, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a01b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1047.194440126419, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 58.95555555555555, "ram_util_percent": 83.41666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9671047077450172, "cur_kl_coeff": 0.014062500000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5174515409444376, "policy_loss": -0.0024448444990431348, "vf_loss": 1.519547569814813, "vf_explained_var": 0.18799935569838871, "kl": 0.024804937409256513, "entropy": 0.6838514536146134, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8701023316257213, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.71352168466679, "policy_loss": -0.004816918092824164, "vf_loss": 3.7176266648781993, "vf_explained_var": 0.2725727054177138, "kl": 0.010000340854789855, "entropy": 1.0084281755502893, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 384.03999999999996, "episode_reward_min": -557.97, "episode_reward_mean": 163.78169999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 56.30585000000001, "predator_policy": 25.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [346.42999999999995, 342.31999999999994, 313.50999999999993, 369.17999999999995, 222.76999999999958, 26.670000000000545, 371.03999999999996, 357.2899999999999, 347.4099999999999, 181.9999999999998, 331.38, 384.03999999999996, 176.07999999999984, 339.40999999999974, 340.44999999999993, 323.16999999999985, 145.29000000000013, 196.1999999999999, -530.9300000000001, 305.3099999999998, 183.97999999999973, 355.12, 354.3499999999997, 361.27, 344.39999999999975, 263.33, 269.26999999999987, 328.1799999999999, 276.2099999999999, 193.96999999999966, 177.08999999999975, 183.05999999999977, 124.89000000000031, 156.21000000000004, 337.20999999999987, -15.139999999999551, 182.17999999999995, -219.81000000000017, 1.960000000000003, -65.87999999999995, -542.8199999999999, 182.8599999999998, 176.04999999999993, 1.9300000000000028, 302.24999999999994, 341.24999999999983, 330.08000000000004, 313.7799999999994, 345.49999999999994, 334.3599999999999, 342.1699999999999, 311.1399999999999, 150.12000000000012, 181.9999999999998, 134.48999999999944, 189.0199999999997, 188.03999999999974, 355.35, 162.99, 44.89000000000003, 186.22, -557.97, 183.00999999999976, 350.13999999999993, 339.24999999999983, 364.12, 155.98000000000008, 279.04999999999995, 356.2599999999999, -201.03000000000037, 360.21999999999997, -21.47000000000003, 90.04000000000009, 101.17000000000007, 158.95000000000002, -537.0, 359.2599999999999, 184.10999999999973, 372.22, -197.01000000000033, 117.59000000000083, 159.03000000000003, -473.37000000000035, 29.010000000000026, 185.06999999999977, 367.05999999999995, -248.59000000000037, -21.269999999999435, 134.60000000000022, 339.06999999999994, 185.04999999999984, -40.44000000000054, 194.00999999999965, 320.19, -166.95999999999998, 133.21000000000032, 368.17999999999995, 305.6299999999996, -528.99, 168.24999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [164.18, 175.25, 153.07999999999998, 176.23999999999998, 108.35000000000005, 184.15999999999997, 198.01999999999998, 154.16000000000003, 104.11999999999998, 72.65000000000026, 27.710000000000267, -6.040000000000042, 174.01999999999998, 183.01999999999998, 168.11000000000004, 182.18, 168.11000000000007, 170.3, 182.06, -10.060000000000041, 174.26, 137.12, 178.04000000000002, 200.0, 159.07999999999998, 2.0000000000000013, 179.21000000000004, 150.19999999999996, 176.23999999999998, 152.21000000000004, 137.14999999999986, 159.01999999999998, -2.020000000000042, 121.31000000000004, 72.05, 68.14999999999999, -343.93, -400.0, 149.12, 127.19, 178.01, -4.030000000000042, 131.09, 194.02999999999997, 162.32000000000016, 185.02999999999997, 163.10000000000002, 183.17, 184.16000000000003, 152.24, 95.30000000000004, 134.03, 52.07000000000001, 123.20000000000007, 134.12, 167.05999999999997, 94.07000000000004, 132.14000000000001, -10.060000000000041, 197.02999999999997, 149.08999999999995, 2.0000000000000013, 175.13, -12.070000000000041, 123.11, -42.220000000000354, 125.20999999999995, 2.0000000000000013, 166.07, 159.14000000000004, -10.060000000000041, -14.080000000000041, -400.0, 182.17999999999995, -241.96000000000004, -132.85000000000014, -0.00999999999999836, -4.030000000000042, -71.94999999999999, -157.93000000000006, -400.0, -342.82, 181.19, -64.32999999999915, 177.11, -7.060000000000041, -12.070000000000041, 2.0000000000000013, 128.21, 121.03999999999999, 168.11000000000007, 156.14, 154.01, 151.07, 195.05, 106.73000000000033, 169.31, 169.19, 155.15, 161.20999999999998, 147.05, 170.11999999999992, 176.12000000000003, 90.02, 116.12000000000002, 2.0000000000000013, 2.0000000000000013, 143.0, -0.00999999999999836, 123.50000000000023, 180.01999999999998, 2.0000000000000013, -0.00999999999999836, 183.04999999999998, 155.15000000000003, 180.20000000000002, 144.05, -10.060000000000041, -221.1100000000008, 143.0, -25.899999999999984, 125.12, -400.0, -384.97, 172.01, 2.0000000000000013, 175.09999999999997, 157.04000000000002, 190.07, 125.18000000000008, 182.06, 164.06, -14.080000000000041, 146.06, 127.04000000000002, 124.00999999999999, 189.07999999999998, 158.18, -400.0, -4.030000000000042, 173.14999999999998, 178.07000000000002, -32.17000000000001, -58.30000000000034, -0.00999999999999836, 36.05000000000001, -3.9099999999999646, 3.080000000000032, 143.0, -8.050000000000042, -364.0, -373.0, 183.14, 164.11999999999998, 2.0000000000000013, 168.10999999999999, 191.09, 169.13, -400.0, -0.00999999999999836, 98.6000000000003, -0.00999999999999836, 141.05, -2.020000000000042, -287.43999999999977, -385.93000000000006, -6.040000000000042, -56.95, -2.020000000000042, 182.08999999999997, 156.01999999999998, 196.04, -400.0, -59.590000000000025, -46.24000000000035, -4.030000000000042, 165.02, -82.41999999999919, 139.04, 173.03, -2.020000000000042, 181.07000000000002, -72.36999999999922, -12.070000000000041, 181.01, 2.0000000000000013, 132.05, 162.14, -208.95999999999998, -241.0, 133.34000000000003, -24.129999999999708, 177.14000000000004, 184.03999999999996, 177.20000000000002, 100.43000000000019, -334.99, -400.0, 166.27999999999997, -4.030000000000042], "policy_predator_policy_reward": [1.0, 6.0, 0.0, 13.0, 19.0, 2.0, 10.0, 7.0, 15.0, 31.0, 1.0, 4.0, 6.0, 8.0, 0.0, 7.0, 2.0, 7.0, 4.0, 6.0, 17.0, 3.0, 0.0, 6.0, 11.0, 4.0, 8.0, 2.0, 3.0, 9.0, 16.0, 11.0, 17.0, 9.0, 47.0, 9.0, 13.0, 200.0, 20.0, 9.0, 6.0, 4.0, 20.0, 10.0, 3.0, 4.0, 6.0, 9.0, 8.0, 0.0, 4.0, 30.0, 47.0, 47.0, 18.0, 9.0, 39.0, 11.0, 1.0, 6.0, 12.0, 14.0, 9.0, 11.0, 29.0, 15.0, 16.0, 13.0, 3.0, 9.0, 8.0, 1.0, 200.0, 200.0, 2.0, 153.0, 3.0, 3.0, 29.0, 135.0, 0.0, 200.0, 33.0, 33.0, 0.0, 6.0, 5.0, 7.0, 24.0, 29.0, 10.0, 7.0, 10.0, 15.0, 5.0, 7.0, 3.0, 4.0, 8.0, 10.0, 19.0, 6.0, 32.0, 13.0, 8.0, 24.0, 19.0, 18.0, 9.0, 2.0, 1.0, 6.0, 0.0, 5.0, 10.0, 10.0, 15.0, 14.0, 119.0, 4.0, 8.0, 79.0, 27.0, 200.0, 9.0, 0.0, 0.0, 18.0, 19.0, 5.0, 8.0, 10.0, 4.0, 20.0, 3.0, 25.0, 0.0, 9.0, 200.0, 3.0, 5.0, 4.0, 43.0, 26.0, 45.0, 9.0, 80.0, 22.0, 5.0, 19.0, 195.0, 5.0, 9.0, 3.0, 7.0, 7.0, 6.0, 6.0, 200.0, 3.0, 6.0, 13.0, 2.0, 18.0, 0.0, 200.0, 5.0, 87.0, 5.0, 0.0, 1.0, 14.0, 200.0, 11.0, 5.0, 24.0, 44.0, 8.0, 8.0, 19.0, 4.0, 2.0, 37.0, 7.0, 6.0, 5.0, 4.0, 22.0, 194.0, 89.0, 11.0, 13.0, 4.0, 3.0, 11.0, 17.0, 6.0, 200.0, 5.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6773619902383714, "mean_inference_ms": 1.8676182692791066, "mean_action_processing_ms": 0.2859790361575826, "mean_env_wait_ms": 0.2271319595802858, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005042672157287598, "StateBufferConnector_ms": 0.003343939781188965, "ViewRequirementAgentConnector_ms": 0.10831284523010254}, "num_episodes": 23, "episode_return_max": 384.03999999999996, "episode_return_min": -557.97, "episode_return_mean": 163.78169999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.5689218565071, "num_env_steps_trained_throughput_per_sec": 317.5689218565071, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 12249.936, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12249.883, "sample_time_ms": 1545.126, "learn_time_ms": 10680.964, "learn_throughput": 374.498, "synch_weights_time_ms": 20.077}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "310e1_00000", "date": "2024-08-15_01-15-06", "timestamp": 1723664706, "time_this_iter_s": 12.692319869995117, "time_total_s": 1059.8867599964142, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1995040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1059.8867599964142, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 59.55555555555556, "ram_util_percent": 83.44999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4511518365491636, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.21330441987073, "policy_loss": -0.003157239218572618, "vf_loss": 1.2161398860670272, "vf_explained_var": 0.09313050215206449, "kl": 0.01525431670713407, "entropy": 0.7611876309864105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.044688884385679, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.650288139827668, "policy_loss": -0.005814196371655695, "vf_loss": 3.6556033852239134, "vf_explained_var": 0.464954766615358, "kl": 0.0070086335102764515, "entropy": 1.0198680524157469, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 372.22, "episode_reward_min": -557.97, "episode_reward_mean": 135.6689999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.01999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 40.029500000000006, "predator_policy": 27.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-530.9300000000001, 305.3099999999998, 183.97999999999973, 355.12, 354.3499999999997, 361.27, 344.39999999999975, 263.33, 269.26999999999987, 328.1799999999999, 276.2099999999999, 193.96999999999966, 177.08999999999975, 183.05999999999977, 124.89000000000031, 156.21000000000004, 337.20999999999987, -15.139999999999551, 182.17999999999995, -219.81000000000017, 1.960000000000003, -65.87999999999995, -542.8199999999999, 182.8599999999998, 176.04999999999993, 1.9300000000000028, 302.24999999999994, 341.24999999999983, 330.08000000000004, 313.7799999999994, 345.49999999999994, 334.3599999999999, 342.1699999999999, 311.1399999999999, 150.12000000000012, 181.9999999999998, 134.48999999999944, 189.0199999999997, 188.03999999999974, 355.35, 162.99, 44.89000000000003, 186.22, -557.97, 183.00999999999976, 350.13999999999993, 339.24999999999983, 364.12, 155.98000000000008, 279.04999999999995, 356.2599999999999, -201.03000000000037, 360.21999999999997, -21.47000000000003, 90.04000000000009, 101.17000000000007, 158.95000000000002, -537.0, 359.2599999999999, 184.10999999999973, 372.22, -197.01000000000033, 117.59000000000083, 159.03000000000003, -473.37000000000035, 29.010000000000026, 185.06999999999977, 367.05999999999995, -248.59000000000037, -21.269999999999435, 134.60000000000022, 339.06999999999994, 185.04999999999984, -40.44000000000054, 194.00999999999965, 320.19, -166.95999999999998, 133.21000000000032, 368.17999999999995, 305.6299999999996, -528.99, 168.24999999999986, 142.98000000000022, 205.4300000000001, 195.94999999999965, -4.080000000000084, 86.05000000000086, 231.38999999999908, 340.11999999999995, -184.55000000000217, 168.05999999999992, 195.00999999999965, 185.99999999999977, -208.83000000000004, 185.99999999999977, 69.99000000000103, 269.7399999999996, 222.3799999999993, 213.57999999999953, -11.850000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-343.93, -400.0, 149.12, 127.19, 178.01, -4.030000000000042, 131.09, 194.02999999999997, 162.32000000000016, 185.02999999999997, 163.10000000000002, 183.17, 184.16000000000003, 152.24, 95.30000000000004, 134.03, 52.07000000000001, 123.20000000000007, 134.12, 167.05999999999997, 94.07000000000004, 132.14000000000001, -10.060000000000041, 197.02999999999997, 149.08999999999995, 2.0000000000000013, 175.13, -12.070000000000041, 123.11, -42.220000000000354, 125.20999999999995, 2.0000000000000013, 166.07, 159.14000000000004, -10.060000000000041, -14.080000000000041, -400.0, 182.17999999999995, -241.96000000000004, -132.85000000000014, -0.00999999999999836, -4.030000000000042, -71.94999999999999, -157.93000000000006, -400.0, -342.82, 181.19, -64.32999999999915, 177.11, -7.060000000000041, -12.070000000000041, 2.0000000000000013, 128.21, 121.03999999999999, 168.11000000000007, 156.14, 154.01, 151.07, 195.05, 106.73000000000033, 169.31, 169.19, 155.15, 161.20999999999998, 147.05, 170.11999999999992, 176.12000000000003, 90.02, 116.12000000000002, 2.0000000000000013, 2.0000000000000013, 143.0, -0.00999999999999836, 123.50000000000023, 180.01999999999998, 2.0000000000000013, -0.00999999999999836, 183.04999999999998, 155.15000000000003, 180.20000000000002, 144.05, -10.060000000000041, -221.1100000000008, 143.0, -25.899999999999984, 125.12, -400.0, -384.97, 172.01, 2.0000000000000013, 175.09999999999997, 157.04000000000002, 190.07, 125.18000000000008, 182.06, 164.06, -14.080000000000041, 146.06, 127.04000000000002, 124.00999999999999, 189.07999999999998, 158.18, -400.0, -4.030000000000042, 173.14999999999998, 178.07000000000002, -32.17000000000001, -58.30000000000034, -0.00999999999999836, 36.05000000000001, -3.9099999999999646, 3.080000000000032, 143.0, -8.050000000000042, -364.0, -373.0, 183.14, 164.11999999999998, 2.0000000000000013, 168.10999999999999, 191.09, 169.13, -400.0, -0.00999999999999836, 98.6000000000003, -0.00999999999999836, 141.05, -2.020000000000042, -287.43999999999977, -385.93000000000006, -6.040000000000042, -56.95, -2.020000000000042, 182.08999999999997, 156.01999999999998, 196.04, -400.0, -59.590000000000025, -46.24000000000035, -4.030000000000042, 165.02, -82.41999999999919, 139.04, 173.03, -2.020000000000042, 181.07000000000002, -72.36999999999922, -12.070000000000041, 181.01, 2.0000000000000013, 132.05, 162.14, -208.95999999999998, -241.0, 133.34000000000003, -24.129999999999708, 177.14000000000004, 184.03999999999996, 177.20000000000002, 100.43000000000019, -334.99, -400.0, 166.27999999999997, -4.030000000000042, 118.04, -10.060000000000041, 113.3, 34.12999999999998, -12.070000000000041, 198.01999999999998, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 78.05000000000041, 167.14999999999998, 50.23999999999979, 168.04999999999998, 151.07, -153.910000000001, -117.63999999999933, 152.06, 2.0000000000000013, 190.01, 2.0000000000000013, 176.0, 2.0000000000000013, -223.0, -158.83000000000004, 170.0, 2.0000000000000013, -8.050000000000042, 61.03999999999979, 149.29999999999995, 69.44000000000021, 171.01999999999998, 23.36000000000021, 50.41999999999972, 148.16, -400.0, 185.15000000000003], "policy_predator_policy_reward": [13.0, 200.0, 20.0, 9.0, 6.0, 4.0, 20.0, 10.0, 3.0, 4.0, 6.0, 9.0, 8.0, 0.0, 4.0, 30.0, 47.0, 47.0, 18.0, 9.0, 39.0, 11.0, 1.0, 6.0, 12.0, 14.0, 9.0, 11.0, 29.0, 15.0, 16.0, 13.0, 3.0, 9.0, 8.0, 1.0, 200.0, 200.0, 2.0, 153.0, 3.0, 3.0, 29.0, 135.0, 0.0, 200.0, 33.0, 33.0, 0.0, 6.0, 5.0, 7.0, 24.0, 29.0, 10.0, 7.0, 10.0, 15.0, 5.0, 7.0, 3.0, 4.0, 8.0, 10.0, 19.0, 6.0, 32.0, 13.0, 8.0, 24.0, 19.0, 18.0, 9.0, 2.0, 1.0, 6.0, 0.0, 5.0, 10.0, 10.0, 15.0, 14.0, 119.0, 4.0, 8.0, 79.0, 27.0, 200.0, 9.0, 0.0, 0.0, 18.0, 19.0, 5.0, 8.0, 10.0, 4.0, 20.0, 3.0, 25.0, 0.0, 9.0, 200.0, 3.0, 5.0, 4.0, 43.0, 26.0, 45.0, 9.0, 80.0, 22.0, 5.0, 19.0, 195.0, 5.0, 9.0, 3.0, 7.0, 7.0, 6.0, 6.0, 200.0, 3.0, 6.0, 13.0, 2.0, 18.0, 0.0, 200.0, 5.0, 87.0, 5.0, 0.0, 1.0, 14.0, 200.0, 11.0, 5.0, 24.0, 44.0, 8.0, 8.0, 19.0, 4.0, 2.0, 37.0, 7.0, 6.0, 5.0, 4.0, 22.0, 194.0, 89.0, 11.0, 13.0, 4.0, 3.0, 11.0, 17.0, 6.0, 200.0, 5.0, 1.0, 16.0, 19.0, 51.0, 7.0, 3.0, 7.0, 6.0, 2.0, 3.0, 3.0, 9.0, 5.0, 7.0, 14.0, 83.0, 4.0, 14.0, 0.0, 0.0, 3.0, 8.0, 0.0, 168.0, 5.0, 4.0, 10.0, 12.0, 5.0, 22.0, 29.0, 15.0, 13.0, 3.0, 12.0, 200.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6767919201761853, "mean_inference_ms": 1.8706070865392315, "mean_action_processing_ms": 0.28537159736871404, "mean_env_wait_ms": 0.2270456808258482, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054198503494262695, "StateBufferConnector_ms": 0.003405451774597168, "ViewRequirementAgentConnector_ms": 0.10857594013214111}, "num_episodes": 18, "episode_return_max": 372.22, "episode_return_min": -557.97, "episode_return_mean": 135.6689999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.06973232100614, "num_env_steps_trained_throughput_per_sec": 321.06973232100614, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 12297.084, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12297.03, "sample_time_ms": 1546.502, "learn_time_ms": 10726.194, "learn_throughput": 372.919, "synch_weights_time_ms": 20.594}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "310e1_00000", "date": "2024-08-15_01-15-18", "timestamp": 1723664718, "time_this_iter_s": 12.51513123512268, "time_total_s": 1072.4018912315369, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1995790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1072.4018912315369, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 59.35555555555555, "ram_util_percent": 83.61666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3420684584707179, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8679913398450014, "policy_loss": -0.0031127785056553506, "vf_loss": 1.8708208391906092, "vf_explained_var": 0.20458931263792451, "kl": 0.01342916141763062, "entropy": 0.7699669701397104, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.517613098703364, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2494994639719605, "policy_loss": -0.0039762447809889205, "vf_loss": 3.253008203594773, "vf_explained_var": 0.38670757504367326, "kl": 0.00656677612468664, "entropy": 1.0025999786677184, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 372.22, "episode_reward_min": -557.97, "episode_reward_mean": 123.94539999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.01999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 32.6327, "predator_policy": 29.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [182.17999999999995, -219.81000000000017, 1.960000000000003, -65.87999999999995, -542.8199999999999, 182.8599999999998, 176.04999999999993, 1.9300000000000028, 302.24999999999994, 341.24999999999983, 330.08000000000004, 313.7799999999994, 345.49999999999994, 334.3599999999999, 342.1699999999999, 311.1399999999999, 150.12000000000012, 181.9999999999998, 134.48999999999944, 189.0199999999997, 188.03999999999974, 355.35, 162.99, 44.89000000000003, 186.22, -557.97, 183.00999999999976, 350.13999999999993, 339.24999999999983, 364.12, 155.98000000000008, 279.04999999999995, 356.2599999999999, -201.03000000000037, 360.21999999999997, -21.47000000000003, 90.04000000000009, 101.17000000000007, 158.95000000000002, -537.0, 359.2599999999999, 184.10999999999973, 372.22, -197.01000000000033, 117.59000000000083, 159.03000000000003, -473.37000000000035, 29.010000000000026, 185.06999999999977, 367.05999999999995, -248.59000000000037, -21.269999999999435, 134.60000000000022, 339.06999999999994, 185.04999999999984, -40.44000000000054, 194.00999999999965, 320.19, -166.95999999999998, 133.21000000000032, 368.17999999999995, 305.6299999999996, -528.99, 168.24999999999986, 142.98000000000022, 205.4300000000001, 195.94999999999965, -4.080000000000084, 86.05000000000086, 231.38999999999908, 340.11999999999995, -184.55000000000217, 168.05999999999992, 195.00999999999965, 185.99999999999977, -208.83000000000004, 185.99999999999977, 69.99000000000103, 269.7399999999996, 222.3799999999993, 213.57999999999953, -11.850000000000003, -510.53, 362.1099999999999, 182.99999999999977, 367.12, 354.1199999999999, 175.01999999999987, 0.9299999999999827, -156.01999999999998, -347.38000000000136, 351.15, -192.0600000000003, 199.00999999999962, 344.44999999999993, 369.13, 322.02, 157.15, 309.7599999999993, 206.43999999999954], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 182.17999999999995, -241.96000000000004, -132.85000000000014, -0.00999999999999836, -4.030000000000042, -71.94999999999999, -157.93000000000006, -400.0, -342.82, 181.19, -64.32999999999915, 177.11, -7.060000000000041, -12.070000000000041, 2.0000000000000013, 128.21, 121.03999999999999, 168.11000000000007, 156.14, 154.01, 151.07, 195.05, 106.73000000000033, 169.31, 169.19, 155.15, 161.20999999999998, 147.05, 170.11999999999992, 176.12000000000003, 90.02, 116.12000000000002, 2.0000000000000013, 2.0000000000000013, 143.0, -0.00999999999999836, 123.50000000000023, 180.01999999999998, 2.0000000000000013, -0.00999999999999836, 183.04999999999998, 155.15000000000003, 180.20000000000002, 144.05, -10.060000000000041, -221.1100000000008, 143.0, -25.899999999999984, 125.12, -400.0, -384.97, 172.01, 2.0000000000000013, 175.09999999999997, 157.04000000000002, 190.07, 125.18000000000008, 182.06, 164.06, -14.080000000000041, 146.06, 127.04000000000002, 124.00999999999999, 189.07999999999998, 158.18, -400.0, -4.030000000000042, 173.14999999999998, 178.07000000000002, -32.17000000000001, -58.30000000000034, -0.00999999999999836, 36.05000000000001, -3.9099999999999646, 3.080000000000032, 143.0, -8.050000000000042, -364.0, -373.0, 183.14, 164.11999999999998, 2.0000000000000013, 168.10999999999999, 191.09, 169.13, -400.0, -0.00999999999999836, 98.6000000000003, -0.00999999999999836, 141.05, -2.020000000000042, -287.43999999999977, -385.93000000000006, -6.040000000000042, -56.95, -2.020000000000042, 182.08999999999997, 156.01999999999998, 196.04, -400.0, -59.590000000000025, -46.24000000000035, -4.030000000000042, 165.02, -82.41999999999919, 139.04, 173.03, -2.020000000000042, 181.07000000000002, -72.36999999999922, -12.070000000000041, 181.01, 2.0000000000000013, 132.05, 162.14, -208.95999999999998, -241.0, 133.34000000000003, -24.129999999999708, 177.14000000000004, 184.03999999999996, 177.20000000000002, 100.43000000000019, -334.99, -400.0, 166.27999999999997, -4.030000000000042, 118.04, -10.060000000000041, 113.3, 34.12999999999998, -12.070000000000041, 198.01999999999998, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 78.05000000000041, 167.14999999999998, 50.23999999999979, 168.04999999999998, 151.07, -153.910000000001, -117.63999999999933, 152.06, 2.0000000000000013, 190.01, 2.0000000000000013, 176.0, 2.0000000000000013, -223.0, -158.83000000000004, 170.0, 2.0000000000000013, -8.050000000000042, 61.03999999999979, 149.29999999999995, 69.44000000000021, 171.01999999999998, 23.36000000000021, 50.41999999999972, 148.16, -400.0, 185.15000000000003, -377.89, -327.64, 155.08999999999997, 192.01999999999998, 174.01999999999998, -2.020000000000042, 165.01999999999998, 172.10000000000002, 161.03, 176.08999999999992, 2.0000000000000013, 141.01999999999998, 2.0000000000000013, -12.070000000000041, -334.0, -2.020000000000042, -253.27000000000066, -221.1100000000007, 153.14000000000001, 184.01, -10.060000000000041, -400.0, 197.02999999999997, -2.020000000000042, 160.13, 168.32, 169.13, 191.0, 151.01, 148.01, -6.040000000000042, 148.19000000000005, 122.75000000000037, 178.01, 153.11, 8.329999999999977], "policy_predator_policy_reward": [200.0, 200.0, 2.0, 153.0, 3.0, 3.0, 29.0, 135.0, 0.0, 200.0, 33.0, 33.0, 0.0, 6.0, 5.0, 7.0, 24.0, 29.0, 10.0, 7.0, 10.0, 15.0, 5.0, 7.0, 3.0, 4.0, 8.0, 10.0, 19.0, 6.0, 32.0, 13.0, 8.0, 24.0, 19.0, 18.0, 9.0, 2.0, 1.0, 6.0, 0.0, 5.0, 10.0, 10.0, 15.0, 14.0, 119.0, 4.0, 8.0, 79.0, 27.0, 200.0, 9.0, 0.0, 0.0, 18.0, 19.0, 5.0, 8.0, 10.0, 4.0, 20.0, 3.0, 25.0, 0.0, 9.0, 200.0, 3.0, 5.0, 4.0, 43.0, 26.0, 45.0, 9.0, 80.0, 22.0, 5.0, 19.0, 195.0, 5.0, 9.0, 3.0, 7.0, 7.0, 6.0, 6.0, 200.0, 3.0, 6.0, 13.0, 2.0, 18.0, 0.0, 200.0, 5.0, 87.0, 5.0, 0.0, 1.0, 14.0, 200.0, 11.0, 5.0, 24.0, 44.0, 8.0, 8.0, 19.0, 4.0, 2.0, 37.0, 7.0, 6.0, 5.0, 4.0, 22.0, 194.0, 89.0, 11.0, 13.0, 4.0, 3.0, 11.0, 17.0, 6.0, 200.0, 5.0, 1.0, 16.0, 19.0, 51.0, 7.0, 3.0, 7.0, 6.0, 2.0, 3.0, 3.0, 9.0, 5.0, 7.0, 14.0, 83.0, 4.0, 14.0, 0.0, 0.0, 3.0, 8.0, 0.0, 168.0, 5.0, 4.0, 10.0, 12.0, 5.0, 22.0, 29.0, 15.0, 13.0, 3.0, 12.0, 200.0, 3.0, 187.0, 8.0, 11.0, 4.0, 8.0, 3.0, 14.0, 16.0, 17.0, 0.0, 13.0, 19.0, 7.0, 4.0, 177.0, 3.0, 0.0, 127.0, 11.0, 3.0, 193.0, 25.0, 2.0, 2.0, 7.0, 9.0, 6.0, 3.0, 5.0, 18.0, 10.0, 5.0, 7.0, 2.0, 21.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6766834909713892, "mean_inference_ms": 1.8727240247222192, "mean_action_processing_ms": 0.28513329648889835, "mean_env_wait_ms": 0.22696168060744148, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00580286979675293, "StateBufferConnector_ms": 0.0033941268920898438, "ViewRequirementAgentConnector_ms": 0.1109621524810791}, "num_episodes": 18, "episode_return_max": 372.22, "episode_return_min": -557.97, "episode_return_mean": 123.94539999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.1648941077957, "num_env_steps_trained_throughput_per_sec": 323.1648941077957, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 12312.908, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12312.854, "sample_time_ms": 1545.762, "learn_time_ms": 10740.112, "learn_throughput": 372.436, "synch_weights_time_ms": 22.747}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "310e1_00000", "date": "2024-08-15_01-15-31", "timestamp": 1723664731, "time_this_iter_s": 12.466474056243896, "time_total_s": 1084.8683652877808, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a1d5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1084.8683652877808, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 55.64705882352941, "ram_util_percent": 83.05294117647058}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.327163579650026, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2279278353093162, "policy_loss": -0.002870652672869188, "vf_loss": 1.2305417125029539, "vf_explained_var": 0.17383659705913887, "kl": 0.01217303910400529, "entropy": 0.8373765347495912, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3141729276016276, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.872360087513293, "policy_loss": -0.004215668458195906, "vf_loss": 2.8761062741279604, "vf_explained_var": 0.43484157301761484, "kl": 0.006594676040569266, "entropy": 1.0128268482508482, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 385.02, "episode_reward_min": -557.97, "episode_reward_mean": 118.75449999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 29.077249999999985, "predator_policy": 30.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [162.99, 44.89000000000003, 186.22, -557.97, 183.00999999999976, 350.13999999999993, 339.24999999999983, 364.12, 155.98000000000008, 279.04999999999995, 356.2599999999999, -201.03000000000037, 360.21999999999997, -21.47000000000003, 90.04000000000009, 101.17000000000007, 158.95000000000002, -537.0, 359.2599999999999, 184.10999999999973, 372.22, -197.01000000000033, 117.59000000000083, 159.03000000000003, -473.37000000000035, 29.010000000000026, 185.06999999999977, 367.05999999999995, -248.59000000000037, -21.269999999999435, 134.60000000000022, 339.06999999999994, 185.04999999999984, -40.44000000000054, 194.00999999999965, 320.19, -166.95999999999998, 133.21000000000032, 368.17999999999995, 305.6299999999996, -528.99, 168.24999999999986, 142.98000000000022, 205.4300000000001, 195.94999999999965, -4.080000000000084, 86.05000000000086, 231.38999999999908, 340.11999999999995, -184.55000000000217, 168.05999999999992, 195.00999999999965, 185.99999999999977, -208.83000000000004, 185.99999999999977, 69.99000000000103, 269.7399999999996, 222.3799999999993, 213.57999999999953, -11.850000000000003, -510.53, 362.1099999999999, 182.99999999999977, 367.12, 354.1199999999999, 175.01999999999987, 0.9299999999999827, -156.01999999999998, -347.38000000000136, 351.15, -192.0600000000003, 199.00999999999962, 344.44999999999993, 369.13, 322.02, 157.15, 309.7599999999993, 206.43999999999954, 332.08000000000004, 353.11999999999995, 318.1, -394.90999999999997, 363.23999999999995, 255.98000000000013, 385.02, -215.74000000000188, -521.99, -307.5500000000002, 350.14, 323.5499999999999, 39.039999999999964, 355.13, 300.04, -5.100000000000083, 330.5799999999997, 179.06999999999965, 177.06999999999968, 189.01999999999975, -168.0200000000001, 379.05999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [144.05, -10.060000000000041, -221.1100000000008, 143.0, -25.899999999999984, 125.12, -400.0, -384.97, 172.01, 2.0000000000000013, 175.09999999999997, 157.04000000000002, 190.07, 125.18000000000008, 182.06, 164.06, -14.080000000000041, 146.06, 127.04000000000002, 124.00999999999999, 189.07999999999998, 158.18, -400.0, -4.030000000000042, 173.14999999999998, 178.07000000000002, -32.17000000000001, -58.30000000000034, -0.00999999999999836, 36.05000000000001, -3.9099999999999646, 3.080000000000032, 143.0, -8.050000000000042, -364.0, -373.0, 183.14, 164.11999999999998, 2.0000000000000013, 168.10999999999999, 191.09, 169.13, -400.0, -0.00999999999999836, 98.6000000000003, -0.00999999999999836, 141.05, -2.020000000000042, -287.43999999999977, -385.93000000000006, -6.040000000000042, -56.95, -2.020000000000042, 182.08999999999997, 156.01999999999998, 196.04, -400.0, -59.590000000000025, -46.24000000000035, -4.030000000000042, 165.02, -82.41999999999919, 139.04, 173.03, -2.020000000000042, 181.07000000000002, -72.36999999999922, -12.070000000000041, 181.01, 2.0000000000000013, 132.05, 162.14, -208.95999999999998, -241.0, 133.34000000000003, -24.129999999999708, 177.14000000000004, 184.03999999999996, 177.20000000000002, 100.43000000000019, -334.99, -400.0, 166.27999999999997, -4.030000000000042, 118.04, -10.060000000000041, 113.3, 34.12999999999998, -12.070000000000041, 198.01999999999998, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 78.05000000000041, 167.14999999999998, 50.23999999999979, 168.04999999999998, 151.07, -153.910000000001, -117.63999999999933, 152.06, 2.0000000000000013, 190.01, 2.0000000000000013, 176.0, 2.0000000000000013, -223.0, -158.83000000000004, 170.0, 2.0000000000000013, -8.050000000000042, 61.03999999999979, 149.29999999999995, 69.44000000000021, 171.01999999999998, 23.36000000000021, 50.41999999999972, 148.16, -400.0, 185.15000000000003, -377.89, -327.64, 155.08999999999997, 192.01999999999998, 174.01999999999998, -2.020000000000042, 165.01999999999998, 172.10000000000002, 161.03, 176.08999999999992, 2.0000000000000013, 141.01999999999998, 2.0000000000000013, -12.070000000000041, -334.0, -2.020000000000042, -253.27000000000066, -221.1100000000007, 153.14000000000001, 184.01, -10.060000000000041, -400.0, 197.02999999999997, -2.020000000000042, 160.13, 168.32, 169.13, 191.0, 151.01, 148.01, -6.040000000000042, 148.19000000000005, 122.75000000000037, 178.01, 153.11, 8.329999999999977, 127.04, 175.04000000000002, 170.09, 176.03000000000003, 121.04, 167.06, -395.98, -382.93, 178.21999999999997, 162.02, 109.1, 109.87999999999995, 199.01, 175.01, -98.49999999999923, -247.24000000000063, -394.0, -331.99, -400.0, -108.54999999999983, 181.04, 145.10000000000002, 130.45999999999998, 182.09000000000003, -194.98000000000093, 129.02, 138.02, 189.11, 136.04, 143.0, -6.040000000000042, -10.060000000000041, 119.45000000000019, 187.12999999999997, 185.14999999999992, -14.080000000000041, 172.1, -4.030000000000042, 186.05, -4.030000000000042, -367.0, -2.020000000000042, 195.04999999999995, 175.01], "policy_predator_policy_reward": [15.0, 14.0, 119.0, 4.0, 8.0, 79.0, 27.0, 200.0, 9.0, 0.0, 0.0, 18.0, 19.0, 5.0, 8.0, 10.0, 4.0, 20.0, 3.0, 25.0, 0.0, 9.0, 200.0, 3.0, 5.0, 4.0, 43.0, 26.0, 45.0, 9.0, 80.0, 22.0, 5.0, 19.0, 195.0, 5.0, 9.0, 3.0, 7.0, 7.0, 6.0, 6.0, 200.0, 3.0, 6.0, 13.0, 2.0, 18.0, 0.0, 200.0, 5.0, 87.0, 5.0, 0.0, 1.0, 14.0, 200.0, 11.0, 5.0, 24.0, 44.0, 8.0, 8.0, 19.0, 4.0, 2.0, 37.0, 7.0, 6.0, 5.0, 4.0, 22.0, 194.0, 89.0, 11.0, 13.0, 4.0, 3.0, 11.0, 17.0, 6.0, 200.0, 5.0, 1.0, 16.0, 19.0, 51.0, 7.0, 3.0, 7.0, 6.0, 2.0, 3.0, 3.0, 9.0, 5.0, 7.0, 14.0, 83.0, 4.0, 14.0, 0.0, 0.0, 3.0, 8.0, 0.0, 168.0, 5.0, 4.0, 10.0, 12.0, 5.0, 22.0, 29.0, 15.0, 13.0, 3.0, 12.0, 200.0, 3.0, 187.0, 8.0, 11.0, 4.0, 8.0, 3.0, 14.0, 16.0, 17.0, 0.0, 13.0, 19.0, 7.0, 4.0, 177.0, 3.0, 0.0, 127.0, 11.0, 3.0, 193.0, 25.0, 2.0, 2.0, 7.0, 9.0, 6.0, 3.0, 5.0, 18.0, 10.0, 5.0, 7.0, 2.0, 21.0, 24.0, 23.0, 7.0, 7.0, 0.0, 5.0, 25.0, 186.0, 198.0, 11.0, 12.0, 18.0, 19.0, 3.0, 8.0, 130.0, 0.0, 4.0, 200.0, 1.0, 200.0, 9.0, 15.0, 8.0, 3.0, 5.0, 100.0, 8.0, 20.0, 20.0, 1.0, 5.0, 6.0, 12.0, 12.0, 0.0, 8.0, 0.0, 9.0, 1.0, 6.0, 191.0, 10.0, 1.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6768148360167688, "mean_inference_ms": 1.8755686238485736, "mean_action_processing_ms": 0.2849115232872358, "mean_env_wait_ms": 0.2269120160266629, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006575465202331543, "StateBufferConnector_ms": 0.003414154052734375, "ViewRequirementAgentConnector_ms": 0.11912524700164795}, "num_episodes": 22, "episode_return_max": 385.02, "episode_return_min": -557.97, "episode_return_mean": 118.75449999999988, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.5285917180027, "num_env_steps_trained_throughput_per_sec": 338.5285917180027, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 12258.363, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12258.271, "sample_time_ms": 1545.369, "learn_time_ms": 10683.753, "learn_throughput": 374.4, "synch_weights_time_ms": 24.365}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "310e1_00000", "date": "2024-08-15_01-15-43", "timestamp": 1723664743, "time_this_iter_s": 11.926260948181152, "time_total_s": 1096.794626235962, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12d94c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1096.794626235962, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 57.194117647058825, "ram_util_percent": 82.47647058823529}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9048240989288956, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7615842304690175, "policy_loss": -0.00155246633587888, "vf_loss": 0.7629859843345547, "vf_explained_var": 0.3671148361037017, "kl": 0.007144857839118322, "entropy": 0.8300133919905103, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.354230742353611, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.259716030088051, "policy_loss": -0.0062628790180607845, "vf_loss": 2.2653239084930017, "vf_explained_var": 0.7789827622749187, "kl": 0.00920047786634096, "entropy": 0.9154975295382202, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 385.02, "episode_reward_min": -528.99, "episode_reward_mean": 141.47599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 43.04299999999999, "predator_policy": 27.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [359.2599999999999, 184.10999999999973, 372.22, -197.01000000000033, 117.59000000000083, 159.03000000000003, -473.37000000000035, 29.010000000000026, 185.06999999999977, 367.05999999999995, -248.59000000000037, -21.269999999999435, 134.60000000000022, 339.06999999999994, 185.04999999999984, -40.44000000000054, 194.00999999999965, 320.19, -166.95999999999998, 133.21000000000032, 368.17999999999995, 305.6299999999996, -528.99, 168.24999999999986, 142.98000000000022, 205.4300000000001, 195.94999999999965, -4.080000000000084, 86.05000000000086, 231.38999999999908, 340.11999999999995, -184.55000000000217, 168.05999999999992, 195.00999999999965, 185.99999999999977, -208.83000000000004, 185.99999999999977, 69.99000000000103, 269.7399999999996, 222.3799999999993, 213.57999999999953, -11.850000000000003, -510.53, 362.1099999999999, 182.99999999999977, 367.12, 354.1199999999999, 175.01999999999987, 0.9299999999999827, -156.01999999999998, -347.38000000000136, 351.15, -192.0600000000003, 199.00999999999962, 344.44999999999993, 369.13, 322.02, 157.15, 309.7599999999993, 206.43999999999954, 332.08000000000004, 353.11999999999995, 318.1, -394.90999999999997, 363.23999999999995, 255.98000000000013, 385.02, -215.74000000000188, -521.99, -307.5500000000002, 350.14, 323.5499999999999, 39.039999999999964, 355.13, 300.04, -5.100000000000083, 330.5799999999997, 179.06999999999965, 177.06999999999968, 189.01999999999975, -168.0200000000001, 379.05999999999995, 333.42999999999984, 332.16, 331.06999999999994, 339.1899999999999, 192.0199999999997, 331.3499999999997, -42.99999999999999, 351.3499999999999, 166.07999999999998, 185.99999999999977, 164.9699999999999, 165.85999999999996, 159.01000000000002, 358.1199999999999, -187.99, 376.09999999999997, 345.24999999999994, 185.99999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [183.14, 164.11999999999998, 2.0000000000000013, 168.10999999999999, 191.09, 169.13, -400.0, -0.00999999999999836, 98.6000000000003, -0.00999999999999836, 141.05, -2.020000000000042, -287.43999999999977, -385.93000000000006, -6.040000000000042, -56.95, -2.020000000000042, 182.08999999999997, 156.01999999999998, 196.04, -400.0, -59.590000000000025, -46.24000000000035, -4.030000000000042, 165.02, -82.41999999999919, 139.04, 173.03, -2.020000000000042, 181.07000000000002, -72.36999999999922, -12.070000000000041, 181.01, 2.0000000000000013, 132.05, 162.14, -208.95999999999998, -241.0, 133.34000000000003, -24.129999999999708, 177.14000000000004, 184.03999999999996, 177.20000000000002, 100.43000000000019, -334.99, -400.0, 166.27999999999997, -4.030000000000042, 118.04, -10.060000000000041, 113.3, 34.12999999999998, -12.070000000000041, 198.01999999999998, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 78.05000000000041, 167.14999999999998, 50.23999999999979, 168.04999999999998, 151.07, -153.910000000001, -117.63999999999933, 152.06, 2.0000000000000013, 190.01, 2.0000000000000013, 176.0, 2.0000000000000013, -223.0, -158.83000000000004, 170.0, 2.0000000000000013, -8.050000000000042, 61.03999999999979, 149.29999999999995, 69.44000000000021, 171.01999999999998, 23.36000000000021, 50.41999999999972, 148.16, -400.0, 185.15000000000003, -377.89, -327.64, 155.08999999999997, 192.01999999999998, 174.01999999999998, -2.020000000000042, 165.01999999999998, 172.10000000000002, 161.03, 176.08999999999992, 2.0000000000000013, 141.01999999999998, 2.0000000000000013, -12.070000000000041, -334.0, -2.020000000000042, -253.27000000000066, -221.1100000000007, 153.14000000000001, 184.01, -10.060000000000041, -400.0, 197.02999999999997, -2.020000000000042, 160.13, 168.32, 169.13, 191.0, 151.01, 148.01, -6.040000000000042, 148.19000000000005, 122.75000000000037, 178.01, 153.11, 8.329999999999977, 127.04, 175.04000000000002, 170.09, 176.03000000000003, 121.04, 167.06, -395.98, -382.93, 178.21999999999997, 162.02, 109.1, 109.87999999999995, 199.01, 175.01, -98.49999999999923, -247.24000000000063, -394.0, -331.99, -400.0, -108.54999999999983, 181.04, 145.10000000000002, 130.45999999999998, 182.09000000000003, -194.98000000000093, 129.02, 138.02, 189.11, 136.04, 143.0, -6.040000000000042, -10.060000000000041, 119.45000000000019, 187.12999999999997, 185.14999999999992, -14.080000000000041, 172.1, -4.030000000000042, 186.05, -4.030000000000042, -367.0, -2.020000000000042, 195.04999999999995, 175.01, 127.18999999999997, 176.24000000000012, 130.04, 158.12, 153.01999999999998, 159.05, 133.18999999999988, 179.0, 2.0000000000000013, 180.01999999999998, 132.3199999999999, 182.02999999999997, 2.0000000000000013, -220.0, 167.02999999999997, 168.32, 2.0000000000000013, 141.07999999999998, 174.01999999999998, -2.020000000000042, 151.01, -6.040000000000042, -26.13999999999971, 167.0, 2.0000000000000013, 109.01, 172.07, 171.05, 4.010000000000005, -400.0, 159.05, 195.05, 182.05999999999997, 148.19000000000003, -4.030000000000042, 182.03], "policy_predator_policy_reward": [9.0, 3.0, 7.0, 7.0, 6.0, 6.0, 200.0, 3.0, 6.0, 13.0, 2.0, 18.0, 0.0, 200.0, 5.0, 87.0, 5.0, 0.0, 1.0, 14.0, 200.0, 11.0, 5.0, 24.0, 44.0, 8.0, 8.0, 19.0, 4.0, 2.0, 37.0, 7.0, 6.0, 5.0, 4.0, 22.0, 194.0, 89.0, 11.0, 13.0, 4.0, 3.0, 11.0, 17.0, 6.0, 200.0, 5.0, 1.0, 16.0, 19.0, 51.0, 7.0, 3.0, 7.0, 6.0, 2.0, 3.0, 3.0, 9.0, 5.0, 7.0, 14.0, 83.0, 4.0, 14.0, 0.0, 0.0, 3.0, 8.0, 0.0, 168.0, 5.0, 4.0, 10.0, 12.0, 5.0, 22.0, 29.0, 15.0, 13.0, 3.0, 12.0, 200.0, 3.0, 187.0, 8.0, 11.0, 4.0, 8.0, 3.0, 14.0, 16.0, 17.0, 0.0, 13.0, 19.0, 7.0, 4.0, 177.0, 3.0, 0.0, 127.0, 11.0, 3.0, 193.0, 25.0, 2.0, 2.0, 7.0, 9.0, 6.0, 3.0, 5.0, 18.0, 10.0, 5.0, 7.0, 2.0, 21.0, 24.0, 23.0, 7.0, 7.0, 0.0, 5.0, 25.0, 186.0, 198.0, 11.0, 12.0, 18.0, 19.0, 3.0, 8.0, 130.0, 0.0, 4.0, 200.0, 1.0, 200.0, 9.0, 15.0, 8.0, 3.0, 5.0, 100.0, 8.0, 20.0, 20.0, 1.0, 5.0, 6.0, 12.0, 12.0, 0.0, 8.0, 0.0, 9.0, 1.0, 6.0, 191.0, 10.0, 1.0, 8.0, 18.0, 12.0, 21.0, 23.0, 16.0, 3.0, 14.0, 13.0, 6.0, 4.0, 12.0, 5.0, 139.0, 36.0, 10.0, 6.0, 6.0, 17.0, 10.0, 4.0, 15.0, 5.0, 11.0, 14.0, 18.0, 30.0, 8.0, 7.0, 200.0, 8.0, 10.0, 12.0, 11.0, 4.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6774051921068552, "mean_inference_ms": 1.8796577300160175, "mean_action_processing_ms": 0.2849798035666636, "mean_env_wait_ms": 0.22711324303622604, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006942629814147949, "StateBufferConnector_ms": 0.0034064054489135742, "ViewRequirementAgentConnector_ms": 0.13239717483520508}, "num_episodes": 18, "episode_return_max": 385.02, "episode_return_min": -528.99, "episode_return_mean": 141.47599999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.897146106874, "num_env_steps_trained_throughput_per_sec": 319.897146106874, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 12264.179, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12264.085, "sample_time_ms": 1600.149, "learn_time_ms": 10633.188, "learn_throughput": 376.181, "synch_weights_time_ms": 25.769}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "310e1_00000", "date": "2024-08-15_01-15-56", "timestamp": 1723664756, "time_this_iter_s": 12.650204181671143, "time_total_s": 1109.444830417633, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1995940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1109.444830417633, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 56.977777777777774, "ram_util_percent": 82.65555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4358952781983785, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2025485264876532, "policy_loss": -0.0017830259151875028, "vf_loss": 1.2041449430127624, "vf_explained_var": 0.26846855210248755, "kl": 0.008846805888703204, "entropy": 0.6393006485448313, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6853991404096917, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.204974670511074, "policy_loss": -0.007165627526957049, "vf_loss": 2.2114978974458404, "vf_explained_var": 0.4901496150190868, "kl": 0.009023596091977195, "entropy": 0.9228173880980759, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -521.99, "episode_reward_mean": 184.39689999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 68.57344999999998, "predator_policy": 23.625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [168.24999999999986, 142.98000000000022, 205.4300000000001, 195.94999999999965, -4.080000000000084, 86.05000000000086, 231.38999999999908, 340.11999999999995, -184.55000000000217, 168.05999999999992, 195.00999999999965, 185.99999999999977, -208.83000000000004, 185.99999999999977, 69.99000000000103, 269.7399999999996, 222.3799999999993, 213.57999999999953, -11.850000000000003, -510.53, 362.1099999999999, 182.99999999999977, 367.12, 354.1199999999999, 175.01999999999987, 0.9299999999999827, -156.01999999999998, -347.38000000000136, 351.15, -192.0600000000003, 199.00999999999962, 344.44999999999993, 369.13, 322.02, 157.15, 309.7599999999993, 206.43999999999954, 332.08000000000004, 353.11999999999995, 318.1, -394.90999999999997, 363.23999999999995, 255.98000000000013, 385.02, -215.74000000000188, -521.99, -307.5500000000002, 350.14, 323.5499999999999, 39.039999999999964, 355.13, 300.04, -5.100000000000083, 330.5799999999997, 179.06999999999965, 177.06999999999968, 189.01999999999975, -168.0200000000001, 379.05999999999995, 333.42999999999984, 332.16, 331.06999999999994, 339.1899999999999, 192.0199999999997, 331.3499999999997, -42.99999999999999, 351.3499999999999, 166.07999999999998, 185.99999999999977, 164.9699999999999, 165.85999999999996, 159.01000000000002, 358.1199999999999, -187.99, 376.09999999999997, 345.24999999999994, 185.99999999999972, 377.22999999999996, 364.22, 375.04, 364.06, 125.9600000000003, 351.09000000000003, 374.05999999999995, 187.97999999999973, 380.09999999999997, 191.9899999999997, 157.06000000000003, 324.06, 380.01, 386.04999999999995, 375.15000000000003, -125.88, 149.84000000000015, 343.25, 289.09, 352.17999999999995, 160.17999999999998, 364.01, 122.02], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [166.27999999999997, -4.030000000000042, 118.04, -10.060000000000041, 113.3, 34.12999999999998, -12.070000000000041, 198.01999999999998, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 78.05000000000041, 167.14999999999998, 50.23999999999979, 168.04999999999998, 151.07, -153.910000000001, -117.63999999999933, 152.06, 2.0000000000000013, 190.01, 2.0000000000000013, 176.0, 2.0000000000000013, -223.0, -158.83000000000004, 170.0, 2.0000000000000013, -8.050000000000042, 61.03999999999979, 149.29999999999995, 69.44000000000021, 171.01999999999998, 23.36000000000021, 50.41999999999972, 148.16, -400.0, 185.15000000000003, -377.89, -327.64, 155.08999999999997, 192.01999999999998, 174.01999999999998, -2.020000000000042, 165.01999999999998, 172.10000000000002, 161.03, 176.08999999999992, 2.0000000000000013, 141.01999999999998, 2.0000000000000013, -12.070000000000041, -334.0, -2.020000000000042, -253.27000000000066, -221.1100000000007, 153.14000000000001, 184.01, -10.060000000000041, -400.0, 197.02999999999997, -2.020000000000042, 160.13, 168.32, 169.13, 191.0, 151.01, 148.01, -6.040000000000042, 148.19000000000005, 122.75000000000037, 178.01, 153.11, 8.329999999999977, 127.04, 175.04000000000002, 170.09, 176.03000000000003, 121.04, 167.06, -395.98, -382.93, 178.21999999999997, 162.02, 109.1, 109.87999999999995, 199.01, 175.01, -98.49999999999923, -247.24000000000063, -394.0, -331.99, -400.0, -108.54999999999983, 181.04, 145.10000000000002, 130.45999999999998, 182.09000000000003, -194.98000000000093, 129.02, 138.02, 189.11, 136.04, 143.0, -6.040000000000042, -10.060000000000041, 119.45000000000019, 187.12999999999997, 185.14999999999992, -14.080000000000041, 172.1, -4.030000000000042, 186.05, -4.030000000000042, -367.0, -2.020000000000042, 195.04999999999995, 175.01, 127.18999999999997, 176.24000000000012, 130.04, 158.12, 153.01999999999998, 159.05, 133.18999999999988, 179.0, 2.0000000000000013, 180.01999999999998, 132.3199999999999, 182.02999999999997, 2.0000000000000013, -220.0, 167.02999999999997, 168.32, 2.0000000000000013, 141.07999999999998, 174.01999999999998, -2.020000000000042, 151.01, -6.040000000000042, -26.13999999999971, 167.0, 2.0000000000000013, 109.01, 172.07, 171.05, 4.010000000000005, -400.0, 159.05, 195.05, 182.05999999999997, 148.19000000000003, -4.030000000000042, 182.03, 197.02999999999997, 180.2, 153.14000000000001, 192.07999999999998, 164.0, 196.04000000000002, 160.04000000000002, 189.01999999999998, -16.089999999999705, 102.05, 144.05, 169.04, 175.03999999999996, 186.01999999999998, -6.040000000000042, 186.01999999999998, 196.03999999999996, 167.06, 182.0, -0.00999999999999836, -4.030000000000042, 125.09, 176.03000000000003, 104.03, 182.0, 190.01, 189.02, 194.02999999999997, 175.13, 195.01999999999998, -30.880000000000003, -277.0, -32.170000000000364, 148.01, 151.01, 176.24, 99.08000000000004, 139.01, 160.16000000000003, 177.01999999999998, 156.23, -8.050000000000042, 140.0, 199.01, 109.01, -112.99000000000001], "policy_predator_policy_reward": [5.0, 1.0, 16.0, 19.0, 51.0, 7.0, 3.0, 7.0, 6.0, 2.0, 3.0, 3.0, 9.0, 5.0, 7.0, 14.0, 83.0, 4.0, 14.0, 0.0, 0.0, 3.0, 8.0, 0.0, 168.0, 5.0, 4.0, 10.0, 12.0, 5.0, 22.0, 29.0, 15.0, 13.0, 3.0, 12.0, 200.0, 3.0, 187.0, 8.0, 11.0, 4.0, 8.0, 3.0, 14.0, 16.0, 17.0, 0.0, 13.0, 19.0, 7.0, 4.0, 177.0, 3.0, 0.0, 127.0, 11.0, 3.0, 193.0, 25.0, 2.0, 2.0, 7.0, 9.0, 6.0, 3.0, 5.0, 18.0, 10.0, 5.0, 7.0, 2.0, 21.0, 24.0, 23.0, 7.0, 7.0, 0.0, 5.0, 25.0, 186.0, 198.0, 11.0, 12.0, 18.0, 19.0, 3.0, 8.0, 130.0, 0.0, 4.0, 200.0, 1.0, 200.0, 9.0, 15.0, 8.0, 3.0, 5.0, 100.0, 8.0, 20.0, 20.0, 1.0, 5.0, 6.0, 12.0, 12.0, 0.0, 8.0, 0.0, 9.0, 1.0, 6.0, 191.0, 10.0, 1.0, 8.0, 18.0, 12.0, 21.0, 23.0, 16.0, 3.0, 14.0, 13.0, 6.0, 4.0, 12.0, 5.0, 139.0, 36.0, 10.0, 6.0, 6.0, 17.0, 10.0, 4.0, 15.0, 5.0, 11.0, 14.0, 18.0, 30.0, 8.0, 7.0, 200.0, 8.0, 10.0, 12.0, 11.0, 4.0, 5.0, 3.0, 0.0, 0.0, 11.0, 8.0, 8.0, 7.0, 12.0, 3.0, 31.0, 9.0, 20.0, 18.0, 6.0, 7.0, 4.0, 4.0, 8.0, 9.0, 6.0, 4.0, 22.0, 14.0, 13.0, 31.0, 6.0, 2.0, 3.0, 0.0, 3.0, 2.0, 175.0, 7.0, 17.0, 17.0, 16.0, 0.0, 20.0, 31.0, 7.0, 8.0, 5.0, 7.0, 5.0, 20.0, 108.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6787699636081043, "mean_inference_ms": 1.8867396680542, "mean_action_processing_ms": 0.28530864971421027, "mean_env_wait_ms": 0.22765299856515514, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005897879600524902, "StateBufferConnector_ms": 0.00692296028137207, "ViewRequirementAgentConnector_ms": 0.15533673763275146}, "num_episodes": 23, "episode_return_max": 386.04999999999995, "episode_return_min": -521.99, "episode_return_mean": 184.39689999999985, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.2640019473099, "num_env_steps_trained_throughput_per_sec": 292.2640019473099, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 12373.572, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12373.478, "sample_time_ms": 1655.073, "learn_time_ms": 10687.412, "learn_throughput": 374.272, "synch_weights_time_ms": 25.857}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "310e1_00000", "date": "2024-08-15_01-16-10", "timestamp": 1723664770, "time_this_iter_s": 13.784977912902832, "time_total_s": 1123.229808330536, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19e0d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1123.229808330536, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 62.46842105263157, "ram_util_percent": 83.14210526315792}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.498409187131458, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.096670448559302, "policy_loss": -0.002170136608996443, "vf_loss": 1.098728244314118, "vf_explained_var": 0.18398057802644358, "kl": 0.00532565605865244, "entropy": 0.5818234602925638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2431977733102424, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7276151971526879, "policy_loss": -0.004591011624073698, "vf_loss": 1.7315054096242108, "vf_explained_var": 0.8321636741123503, "kl": 0.009843893640564606, "entropy": 0.977258173309306, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -521.99, "episode_reward_mean": 198.9094999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 75.77974999999998, "predator_policy": 23.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.850000000000003, -510.53, 362.1099999999999, 182.99999999999977, 367.12, 354.1199999999999, 175.01999999999987, 0.9299999999999827, -156.01999999999998, -347.38000000000136, 351.15, -192.0600000000003, 199.00999999999962, 344.44999999999993, 369.13, 322.02, 157.15, 309.7599999999993, 206.43999999999954, 332.08000000000004, 353.11999999999995, 318.1, -394.90999999999997, 363.23999999999995, 255.98000000000013, 385.02, -215.74000000000188, -521.99, -307.5500000000002, 350.14, 323.5499999999999, 39.039999999999964, 355.13, 300.04, -5.100000000000083, 330.5799999999997, 179.06999999999965, 177.06999999999968, 189.01999999999975, -168.0200000000001, 379.05999999999995, 333.42999999999984, 332.16, 331.06999999999994, 339.1899999999999, 192.0199999999997, 331.3499999999997, -42.99999999999999, 351.3499999999999, 166.07999999999998, 185.99999999999977, 164.9699999999999, 165.85999999999996, 159.01000000000002, 358.1199999999999, -187.99, 376.09999999999997, 345.24999999999994, 185.99999999999972, 377.22999999999996, 364.22, 375.04, 364.06, 125.9600000000003, 351.09000000000003, 374.05999999999995, 187.97999999999973, 380.09999999999997, 191.9899999999997, 157.06000000000003, 324.06, 380.01, 386.04999999999995, 375.15000000000003, -125.88, 149.84000000000015, 343.25, 289.09, 352.17999999999995, 160.17999999999998, 364.01, 122.02, -205.0700000000004, 143.09000000000017, 177.93999999999983, -1.0600000000000622, 339.33, 172.02999999999986, 187.07999999999976, 359.09000000000003, 146.98000000000013, 163.97999999999996, 370.15, 352.03, 361.07, 311.03999999999996, 376.07, 370.09999999999997, -6.140000000000082, 317.02], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 185.15000000000003, -377.89, -327.64, 155.08999999999997, 192.01999999999998, 174.01999999999998, -2.020000000000042, 165.01999999999998, 172.10000000000002, 161.03, 176.08999999999992, 2.0000000000000013, 141.01999999999998, 2.0000000000000013, -12.070000000000041, -334.0, -2.020000000000042, -253.27000000000066, -221.1100000000007, 153.14000000000001, 184.01, -10.060000000000041, -400.0, 197.02999999999997, -2.020000000000042, 160.13, 168.32, 169.13, 191.0, 151.01, 148.01, -6.040000000000042, 148.19000000000005, 122.75000000000037, 178.01, 153.11, 8.329999999999977, 127.04, 175.04000000000002, 170.09, 176.03000000000003, 121.04, 167.06, -395.98, -382.93, 178.21999999999997, 162.02, 109.1, 109.87999999999995, 199.01, 175.01, -98.49999999999923, -247.24000000000063, -394.0, -331.99, -400.0, -108.54999999999983, 181.04, 145.10000000000002, 130.45999999999998, 182.09000000000003, -194.98000000000093, 129.02, 138.02, 189.11, 136.04, 143.0, -6.040000000000042, -10.060000000000041, 119.45000000000019, 187.12999999999997, 185.14999999999992, -14.080000000000041, 172.1, -4.030000000000042, 186.05, -4.030000000000042, -367.0, -2.020000000000042, 195.04999999999995, 175.01, 127.18999999999997, 176.24000000000012, 130.04, 158.12, 153.01999999999998, 159.05, 133.18999999999988, 179.0, 2.0000000000000013, 180.01999999999998, 132.3199999999999, 182.02999999999997, 2.0000000000000013, -220.0, 167.02999999999997, 168.32, 2.0000000000000013, 141.07999999999998, 174.01999999999998, -2.020000000000042, 151.01, -6.040000000000042, -26.13999999999971, 167.0, 2.0000000000000013, 109.01, 172.07, 171.05, 4.010000000000005, -400.0, 159.05, 195.05, 182.05999999999997, 148.19000000000003, -4.030000000000042, 182.03, 197.02999999999997, 180.2, 153.14000000000001, 192.07999999999998, 164.0, 196.04000000000002, 160.04000000000002, 189.01999999999998, -16.089999999999705, 102.05, 144.05, 169.04, 175.03999999999996, 186.01999999999998, -6.040000000000042, 186.01999999999998, 196.03999999999996, 167.06, 182.0, -0.00999999999999836, -4.030000000000042, 125.09, 176.03000000000003, 104.03, 182.0, 190.01, 189.02, 194.02999999999997, 175.13, 195.01999999999998, -30.880000000000003, -277.0, -32.170000000000364, 148.01, 151.01, 176.24, 99.08000000000004, 139.01, 160.16000000000003, 177.01999999999998, 156.23, -8.050000000000042, 140.0, 199.01, 109.01, -112.99000000000001, -28.14999999999971, -383.9200000000001, -8.050000000000042, 126.14, 175.01, -12.070000000000041, 2.0000000000000013, -10.060000000000041, 190.07, 135.26000000000005, -8.050000000000042, 156.07999999999998, 188.12, -6.040000000000042, 176.0, 167.09, 118.00999999999999, -4.030000000000042, 150.02, -6.040000000000042, 153.14000000000001, 199.01, 198.02, 106.00999999999999, 146.06, 199.01, 139.01, 131.03, 184.01, 182.06, 193.07, 143.03, -16.0899999999997, -8.050000000000042, 133.01, 157.01], "policy_predator_policy_reward": [200.0, 3.0, 187.0, 8.0, 11.0, 4.0, 8.0, 3.0, 14.0, 16.0, 17.0, 0.0, 13.0, 19.0, 7.0, 4.0, 177.0, 3.0, 0.0, 127.0, 11.0, 3.0, 193.0, 25.0, 2.0, 2.0, 7.0, 9.0, 6.0, 3.0, 5.0, 18.0, 10.0, 5.0, 7.0, 2.0, 21.0, 24.0, 23.0, 7.0, 7.0, 0.0, 5.0, 25.0, 186.0, 198.0, 11.0, 12.0, 18.0, 19.0, 3.0, 8.0, 130.0, 0.0, 4.0, 200.0, 1.0, 200.0, 9.0, 15.0, 8.0, 3.0, 5.0, 100.0, 8.0, 20.0, 20.0, 1.0, 5.0, 6.0, 12.0, 12.0, 0.0, 8.0, 0.0, 9.0, 1.0, 6.0, 191.0, 10.0, 1.0, 8.0, 18.0, 12.0, 21.0, 23.0, 16.0, 3.0, 14.0, 13.0, 6.0, 4.0, 12.0, 5.0, 139.0, 36.0, 10.0, 6.0, 6.0, 17.0, 10.0, 4.0, 15.0, 5.0, 11.0, 14.0, 18.0, 30.0, 8.0, 7.0, 200.0, 8.0, 10.0, 12.0, 11.0, 4.0, 5.0, 3.0, 0.0, 0.0, 11.0, 8.0, 8.0, 7.0, 12.0, 3.0, 31.0, 9.0, 20.0, 18.0, 6.0, 7.0, 4.0, 4.0, 8.0, 9.0, 6.0, 4.0, 22.0, 14.0, 13.0, 31.0, 6.0, 2.0, 3.0, 0.0, 3.0, 2.0, 175.0, 7.0, 17.0, 17.0, 16.0, 0.0, 20.0, 31.0, 7.0, 8.0, 5.0, 7.0, 5.0, 20.0, 108.0, 18.0, 15.0, 192.0, 19.0, 6.0, 8.0, 7.0, 6.0, 1.0, 13.0, 1.0, 16.0, 8.0, 1.0, 4.0, 8.0, 8.0, 20.0, 13.0, 4.0, 16.0, 11.0, 7.0, 31.0, 17.0, 4.0, 12.0, 17.0, 24.0, 1.0, 9.0, 18.0, 16.0, 9.0, 9.0, 15.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6802376507365344, "mean_inference_ms": 1.8931582430349343, "mean_action_processing_ms": 0.2856944686261854, "mean_env_wait_ms": 0.22823064901754844, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00556635856628418, "StateBufferConnector_ms": 0.006955265998840332, "ViewRequirementAgentConnector_ms": 0.17184627056121826}, "num_episodes": 18, "episode_return_max": 386.04999999999995, "episode_return_min": -521.99, "episode_return_mean": 198.9094999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.60262810510886, "num_env_steps_trained_throughput_per_sec": 320.60262810510886, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 12414.606, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12414.512, "sample_time_ms": 1700.403, "learn_time_ms": 10681.295, "learn_throughput": 374.486, "synch_weights_time_ms": 27.748}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "310e1_00000", "date": "2024-08-15_01-16-22", "timestamp": 1723664782, "time_this_iter_s": 12.582528114318848, "time_total_s": 1135.8123364448547, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12d94c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1135.8123364448547, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 58.21666666666667, "ram_util_percent": 83.55555555555554}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3976679209048157, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.572435913830207, "policy_loss": -0.0015664841548574191, "vf_loss": 1.5738943012618514, "vf_explained_var": 0.08819031472559329, "kl": 0.005124653240416414, "entropy": 0.5018457577184394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6850189722404276, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2213135899690095, "policy_loss": -0.0045122861253619985, "vf_loss": 2.225421246902022, "vf_explained_var": 0.5095267737668658, "kl": 0.0056837117510273715, "entropy": 0.9608451606419982, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -521.99, "episode_reward_mean": 207.76509999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.01, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": 79.97755, "predator_policy": 23.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-394.90999999999997, 363.23999999999995, 255.98000000000013, 385.02, -215.74000000000188, -521.99, -307.5500000000002, 350.14, 323.5499999999999, 39.039999999999964, 355.13, 300.04, -5.100000000000083, 330.5799999999997, 179.06999999999965, 177.06999999999968, 189.01999999999975, -168.0200000000001, 379.05999999999995, 333.42999999999984, 332.16, 331.06999999999994, 339.1899999999999, 192.0199999999997, 331.3499999999997, -42.99999999999999, 351.3499999999999, 166.07999999999998, 185.99999999999977, 164.9699999999999, 165.85999999999996, 159.01000000000002, 358.1199999999999, -187.99, 376.09999999999997, 345.24999999999994, 185.99999999999972, 377.22999999999996, 364.22, 375.04, 364.06, 125.9600000000003, 351.09000000000003, 374.05999999999995, 187.97999999999973, 380.09999999999997, 191.9899999999997, 157.06000000000003, 324.06, 380.01, 386.04999999999995, 375.15000000000003, -125.88, 149.84000000000015, 343.25, 289.09, 352.17999999999995, 160.17999999999998, 364.01, 122.02, -205.0700000000004, 143.09000000000017, 177.93999999999983, -1.0600000000000622, 339.33, 172.02999999999986, 187.07999999999976, 359.09000000000003, 146.98000000000013, 163.97999999999996, 370.15, 352.03, 361.07, 311.03999999999996, 376.07, 370.09999999999997, -6.140000000000082, 317.02, 364.08, 337.12, 161.94, -75.30999999999969, 122.55999999999995, 326.12, 364.16999999999996, 308.03999999999996, 173.06999999999988, 1.940000000000003, 343.02, -217.11000000000058, 370.03999999999996, 362.18, 307.12, 346.02, -393.0, 301.01, 160.31, 352.15999999999997, 173.93999999999988, 183.00999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-395.98, -382.93, 178.21999999999997, 162.02, 109.1, 109.87999999999995, 199.01, 175.01, -98.49999999999923, -247.24000000000063, -394.0, -331.99, -400.0, -108.54999999999983, 181.04, 145.10000000000002, 130.45999999999998, 182.09000000000003, -194.98000000000093, 129.02, 138.02, 189.11, 136.04, 143.0, -6.040000000000042, -10.060000000000041, 119.45000000000019, 187.12999999999997, 185.14999999999992, -14.080000000000041, 172.1, -4.030000000000042, 186.05, -4.030000000000042, -367.0, -2.020000000000042, 195.04999999999995, 175.01, 127.18999999999997, 176.24000000000012, 130.04, 158.12, 153.01999999999998, 159.05, 133.18999999999988, 179.0, 2.0000000000000013, 180.01999999999998, 132.3199999999999, 182.02999999999997, 2.0000000000000013, -220.0, 167.02999999999997, 168.32, 2.0000000000000013, 141.07999999999998, 174.01999999999998, -2.020000000000042, 151.01, -6.040000000000042, -26.13999999999971, 167.0, 2.0000000000000013, 109.01, 172.07, 171.05, 4.010000000000005, -400.0, 159.05, 195.05, 182.05999999999997, 148.19000000000003, -4.030000000000042, 182.03, 197.02999999999997, 180.2, 153.14000000000001, 192.07999999999998, 164.0, 196.04000000000002, 160.04000000000002, 189.01999999999998, -16.089999999999705, 102.05, 144.05, 169.04, 175.03999999999996, 186.01999999999998, -6.040000000000042, 186.01999999999998, 196.03999999999996, 167.06, 182.0, -0.00999999999999836, -4.030000000000042, 125.09, 176.03000000000003, 104.03, 182.0, 190.01, 189.02, 194.02999999999997, 175.13, 195.01999999999998, -30.880000000000003, -277.0, -32.170000000000364, 148.01, 151.01, 176.24, 99.08000000000004, 139.01, 160.16000000000003, 177.01999999999998, 156.23, -8.050000000000042, 140.0, 199.01, 109.01, -112.99000000000001, -28.14999999999971, -383.9200000000001, -8.050000000000042, 126.14, 175.01, -12.070000000000041, 2.0000000000000013, -10.060000000000041, 190.07, 135.26000000000005, -8.050000000000042, 156.07999999999998, 188.12, -6.040000000000042, 176.0, 167.09, 118.00999999999999, -4.030000000000042, 150.02, -6.040000000000042, 153.14000000000001, 199.01, 198.02, 106.00999999999999, 146.06, 199.01, 139.01, 131.03, 184.01, 182.06, 193.07, 143.03, -16.0899999999997, -8.050000000000042, 133.01, 157.01, 162.05, 188.03, 158.0, 155.12, -10.060000000000041, 149.0, -263.3200000000005, 31.009999999999998, 59.17999999999998, 51.37999999999997, 153.02, 148.10000000000002, 172.16000000000003, 175.01, 154.01, 116.03, -6.040000000000042, 162.11, 2.0000000000000013, -10.060000000000041, 144.01999999999998, 173.0, -400.0, -20.109999999999705, 166.04000000000002, 191.0, 198.01999999999998, 154.16000000000003, 146.06, 137.06, 84.02000000000001, 182.0, -400.0, -456.0, 113.0, 136.01, -16.0899999999997, 160.4, 174.14000000000001, 150.01999999999998, 169.01, -12.070000000000041, 163.01, 2.0000000000000013], "policy_predator_policy_reward": [186.0, 198.0, 11.0, 12.0, 18.0, 19.0, 3.0, 8.0, 130.0, 0.0, 4.0, 200.0, 1.0, 200.0, 9.0, 15.0, 8.0, 3.0, 5.0, 100.0, 8.0, 20.0, 20.0, 1.0, 5.0, 6.0, 12.0, 12.0, 0.0, 8.0, 0.0, 9.0, 1.0, 6.0, 191.0, 10.0, 1.0, 8.0, 18.0, 12.0, 21.0, 23.0, 16.0, 3.0, 14.0, 13.0, 6.0, 4.0, 12.0, 5.0, 139.0, 36.0, 10.0, 6.0, 6.0, 17.0, 10.0, 4.0, 15.0, 5.0, 11.0, 14.0, 18.0, 30.0, 8.0, 7.0, 200.0, 8.0, 10.0, 12.0, 11.0, 4.0, 5.0, 3.0, 0.0, 0.0, 11.0, 8.0, 8.0, 7.0, 12.0, 3.0, 31.0, 9.0, 20.0, 18.0, 6.0, 7.0, 4.0, 4.0, 8.0, 9.0, 6.0, 4.0, 22.0, 14.0, 13.0, 31.0, 6.0, 2.0, 3.0, 0.0, 3.0, 2.0, 175.0, 7.0, 17.0, 17.0, 16.0, 0.0, 20.0, 31.0, 7.0, 8.0, 5.0, 7.0, 5.0, 20.0, 108.0, 18.0, 15.0, 192.0, 19.0, 6.0, 8.0, 7.0, 6.0, 1.0, 13.0, 1.0, 16.0, 8.0, 1.0, 4.0, 8.0, 8.0, 20.0, 13.0, 4.0, 16.0, 11.0, 7.0, 31.0, 17.0, 4.0, 12.0, 17.0, 24.0, 1.0, 9.0, 18.0, 16.0, 9.0, 9.0, 15.0, 12.0, 11.0, 3.0, 14.0, 10.0, 17.0, 6.0, 139.0, 18.0, 8.0, 4.0, 14.0, 11.0, 5.0, 12.0, 28.0, 10.0, 4.0, 13.0, 4.0, 6.0, 14.0, 12.0, 3.0, 200.0, 3.0, 10.0, 0.0, 10.0, 21.0, 3.0, 42.0, 38.0, 263.0, 200.0, 28.0, 24.0, 7.0, 9.0, 15.0, 13.0, 11.0, 6.0, 12.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.682588196768919, "mean_inference_ms": 1.902539439298439, "mean_action_processing_ms": 0.2862446176331334, "mean_env_wait_ms": 0.22932701753409215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005054950714111328, "StateBufferConnector_ms": 0.006942033767700195, "ViewRequirementAgentConnector_ms": 0.18663060665130615}, "num_episodes": 22, "episode_return_max": 386.04999999999995, "episode_return_min": -521.99, "episode_return_mean": 207.76509999999988, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.9970719517009, "num_env_steps_trained_throughput_per_sec": 325.9970719517009, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 12427.272, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12427.173, "sample_time_ms": 1777.819, "learn_time_ms": 10617.193, "learn_throughput": 376.747, "synch_weights_time_ms": 27.242}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "310e1_00000", "date": "2024-08-15_01-16-35", "timestamp": 1723664795, "time_this_iter_s": 12.314487934112549, "time_total_s": 1148.1268243789673, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a971f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1148.1268243789673, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 56.8, "ram_util_percent": 83.10555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5198651204033504, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6177383862790606, "policy_loss": -0.001941277295666397, "vf_loss": 1.6195209368511483, "vf_explained_var": 0.15341233112824657, "kl": 0.007524834384860017, "entropy": 0.5241109711783273, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9715965195623024, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.98114872767181, "policy_loss": -0.004687843673552076, "vf_loss": 2.985165957294444, "vf_explained_var": 0.20858617226282755, "kl": 0.009419900829155399, "entropy": 0.854424459309805, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -575.0, "episode_reward_mean": 214.23409999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": 83.76205, "predator_policy": 23.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [379.05999999999995, 333.42999999999984, 332.16, 331.06999999999994, 339.1899999999999, 192.0199999999997, 331.3499999999997, -42.99999999999999, 351.3499999999999, 166.07999999999998, 185.99999999999977, 164.9699999999999, 165.85999999999996, 159.01000000000002, 358.1199999999999, -187.99, 376.09999999999997, 345.24999999999994, 185.99999999999972, 377.22999999999996, 364.22, 375.04, 364.06, 125.9600000000003, 351.09000000000003, 374.05999999999995, 187.97999999999973, 380.09999999999997, 191.9899999999997, 157.06000000000003, 324.06, 380.01, 386.04999999999995, 375.15000000000003, -125.88, 149.84000000000015, 343.25, 289.09, 352.17999999999995, 160.17999999999998, 364.01, 122.02, -205.0700000000004, 143.09000000000017, 177.93999999999983, -1.0600000000000622, 339.33, 172.02999999999986, 187.07999999999976, 359.09000000000003, 146.98000000000013, 163.97999999999996, 370.15, 352.03, 361.07, 311.03999999999996, 376.07, 370.09999999999997, -6.140000000000082, 317.02, 364.08, 337.12, 161.94, -75.30999999999969, 122.55999999999995, 326.12, 364.16999999999996, 308.03999999999996, 173.06999999999988, 1.940000000000003, 343.02, -217.11000000000058, 370.03999999999996, 362.18, 307.12, 346.02, -393.0, 301.01, 160.31, 352.15999999999997, 173.93999999999988, 183.00999999999976, 189.02999999999972, 367.13, -532.8800000000001, 362.15999999999997, 295.15999999999997, 352.1, 380.02, 376.06, 162.98999999999995, -38.63000000000004, 322.03999999999996, -575.0, 365.01, -214.16000000000054, -1.0800000000000622, 172.0199999999999, -44.519999999999996, 344.02], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [195.04999999999995, 175.01, 127.18999999999997, 176.24000000000012, 130.04, 158.12, 153.01999999999998, 159.05, 133.18999999999988, 179.0, 2.0000000000000013, 180.01999999999998, 132.3199999999999, 182.02999999999997, 2.0000000000000013, -220.0, 167.02999999999997, 168.32, 2.0000000000000013, 141.07999999999998, 174.01999999999998, -2.020000000000042, 151.01, -6.040000000000042, -26.13999999999971, 167.0, 2.0000000000000013, 109.01, 172.07, 171.05, 4.010000000000005, -400.0, 159.05, 195.05, 182.05999999999997, 148.19000000000003, -4.030000000000042, 182.03, 197.02999999999997, 180.2, 153.14000000000001, 192.07999999999998, 164.0, 196.04000000000002, 160.04000000000002, 189.01999999999998, -16.089999999999705, 102.05, 144.05, 169.04, 175.03999999999996, 186.01999999999998, -6.040000000000042, 186.01999999999998, 196.03999999999996, 167.06, 182.0, -0.00999999999999836, -4.030000000000042, 125.09, 176.03000000000003, 104.03, 182.0, 190.01, 189.02, 194.02999999999997, 175.13, 195.01999999999998, -30.880000000000003, -277.0, -32.170000000000364, 148.01, 151.01, 176.24, 99.08000000000004, 139.01, 160.16000000000003, 177.01999999999998, 156.23, -8.050000000000042, 140.0, 199.01, 109.01, -112.99000000000001, -28.14999999999971, -383.9200000000001, -8.050000000000042, 126.14, 175.01, -12.070000000000041, 2.0000000000000013, -10.060000000000041, 190.07, 135.26000000000005, -8.050000000000042, 156.07999999999998, 188.12, -6.040000000000042, 176.0, 167.09, 118.00999999999999, -4.030000000000042, 150.02, -6.040000000000042, 153.14000000000001, 199.01, 198.02, 106.00999999999999, 146.06, 199.01, 139.01, 131.03, 184.01, 182.06, 193.07, 143.03, -16.0899999999997, -8.050000000000042, 133.01, 157.01, 162.05, 188.03, 158.0, 155.12, -10.060000000000041, 149.0, -263.3200000000005, 31.009999999999998, 59.17999999999998, 51.37999999999997, 153.02, 148.10000000000002, 172.16000000000003, 175.01, 154.01, 116.03, -6.040000000000042, 162.11, 2.0000000000000013, -10.060000000000041, 144.01999999999998, 173.0, -400.0, -20.109999999999705, 166.04000000000002, 191.0, 198.01999999999998, 154.16000000000003, 146.06, 137.06, 84.02000000000001, 182.0, -400.0, -456.0, 113.0, 136.01, -16.0899999999997, 160.4, 174.14000000000001, 150.01999999999998, 169.01, -12.070000000000041, 163.01, 2.0000000000000013, 2.0000000000000013, 182.03, 196.01, 161.12, -400.0, -336.8800000000001, 172.16, 173.0, 73.13, 158.03, 200.0, 133.09999999999997, 181.01, 190.01, 199.01, 168.05, 145.01, -2.020000000000042, 101.0, -325.6300000000003, 81.02, 168.02, -400.0, -391.0, 199.01, 140.0, -389.95, -40.210000000000356, 2.0000000000000013, -14.080000000000041, -2.020000000000042, 160.04000000000002, 152.48000000000002, -400.0, 145.01, 172.01], "policy_predator_policy_reward": [1.0, 8.0, 18.0, 12.0, 21.0, 23.0, 16.0, 3.0, 14.0, 13.0, 6.0, 4.0, 12.0, 5.0, 139.0, 36.0, 10.0, 6.0, 6.0, 17.0, 10.0, 4.0, 15.0, 5.0, 11.0, 14.0, 18.0, 30.0, 8.0, 7.0, 200.0, 8.0, 10.0, 12.0, 11.0, 4.0, 5.0, 3.0, 0.0, 0.0, 11.0, 8.0, 8.0, 7.0, 12.0, 3.0, 31.0, 9.0, 20.0, 18.0, 6.0, 7.0, 4.0, 4.0, 8.0, 9.0, 6.0, 4.0, 22.0, 14.0, 13.0, 31.0, 6.0, 2.0, 3.0, 0.0, 3.0, 2.0, 175.0, 7.0, 17.0, 17.0, 16.0, 0.0, 20.0, 31.0, 7.0, 8.0, 5.0, 7.0, 5.0, 20.0, 108.0, 18.0, 15.0, 192.0, 19.0, 6.0, 8.0, 7.0, 6.0, 1.0, 13.0, 1.0, 16.0, 8.0, 1.0, 4.0, 8.0, 8.0, 20.0, 13.0, 4.0, 16.0, 11.0, 7.0, 31.0, 17.0, 4.0, 12.0, 17.0, 24.0, 1.0, 9.0, 18.0, 16.0, 9.0, 9.0, 15.0, 12.0, 11.0, 3.0, 14.0, 10.0, 17.0, 6.0, 139.0, 18.0, 8.0, 4.0, 14.0, 11.0, 5.0, 12.0, 28.0, 10.0, 4.0, 13.0, 4.0, 6.0, 14.0, 12.0, 3.0, 200.0, 3.0, 10.0, 0.0, 10.0, 21.0, 3.0, 42.0, 38.0, 263.0, 200.0, 28.0, 24.0, 7.0, 9.0, 15.0, 13.0, 11.0, 6.0, 12.0, 6.0, 0.0, 5.0, 2.0, 8.0, 200.0, 4.0, 9.0, 8.0, 44.0, 20.0, 19.0, 0.0, 6.0, 3.0, 1.0, 8.0, 18.0, 2.0, 169.0, 17.0, 32.0, 41.0, 200.0, 16.0, 18.0, 8.0, 21.0, 195.0, 8.0, 3.0, 14.0, 0.0, 200.0, 3.0, 18.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6852921576468595, "mean_inference_ms": 1.9120612428412336, "mean_action_processing_ms": 0.2875515807775313, "mean_env_wait_ms": 0.23017379459915865, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00540924072265625, "StateBufferConnector_ms": 0.007055401802062988, "ViewRequirementAgentConnector_ms": 0.17547309398651123}, "num_episodes": 18, "episode_return_max": 386.04999999999995, "episode_return_min": -575.0, "episode_return_mean": 214.23409999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.48473645775056, "num_env_steps_trained_throughput_per_sec": 347.48473645775056, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 12399.897, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12399.802, "sample_time_ms": 1844.767, "learn_time_ms": 10524.394, "learn_throughput": 380.069, "synch_weights_time_ms": 26.003}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "310e1_00000", "date": "2024-08-15_01-16-46", "timestamp": 1723664806, "time_this_iter_s": 11.516268968582153, "time_total_s": 1159.6430933475494, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1995160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1159.6430933475494, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 46.84375, "ram_util_percent": 77.74374999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8240789216504525, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7382791336724367, "policy_loss": -0.004126883615005426, "vf_loss": 0.7422877353295763, "vf_explained_var": 0.11013396817540365, "kl": 0.0056075457608311275, "entropy": 0.4536403478453399, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8984649193665337, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.204159202209856, "policy_loss": -0.008874058502691764, "vf_loss": 2.212178219058526, "vf_explained_var": 0.8850557186616161, "kl": 0.012010500677659406, "entropy": 0.7948556824651345, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 386.04999999999995, "episode_reward_min": -575.0, "episode_reward_mean": 226.31629999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": 90.86814999999999, "predator_policy": 22.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [125.9600000000003, 351.09000000000003, 374.05999999999995, 187.97999999999973, 380.09999999999997, 191.9899999999997, 157.06000000000003, 324.06, 380.01, 386.04999999999995, 375.15000000000003, -125.88, 149.84000000000015, 343.25, 289.09, 352.17999999999995, 160.17999999999998, 364.01, 122.02, -205.0700000000004, 143.09000000000017, 177.93999999999983, -1.0600000000000622, 339.33, 172.02999999999986, 187.07999999999976, 359.09000000000003, 146.98000000000013, 163.97999999999996, 370.15, 352.03, 361.07, 311.03999999999996, 376.07, 370.09999999999997, -6.140000000000082, 317.02, 364.08, 337.12, 161.94, -75.30999999999969, 122.55999999999995, 326.12, 364.16999999999996, 308.03999999999996, 173.06999999999988, 1.940000000000003, 343.02, -217.11000000000058, 370.03999999999996, 362.18, 307.12, 346.02, -393.0, 301.01, 160.31, 352.15999999999997, 173.93999999999988, 183.00999999999976, 189.02999999999972, 367.13, -532.8800000000001, 362.15999999999997, 295.15999999999997, 352.1, 380.02, 376.06, 162.98999999999995, -38.63000000000004, 322.03999999999996, -575.0, 365.01, -214.16000000000054, -1.0800000000000622, 172.0199999999999, -44.519999999999996, 344.02, 267.95, 313.37999999999994, 331.28999999999996, 300.23, 343.2299999999999, 369.1499999999999, 356.11, 339.29999999999995, 371.12999999999994, 358.2, 343.15999999999997, 338.0, 165.08999999999986, 182.00999999999982, 336.53999999999996, 194.03999999999968, 341.09999999999997, 319.1, 345.31, 357.12, 320.17999999999995, 364.25, 198.92999999999967], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.089999999999705, 102.05, 144.05, 169.04, 175.03999999999996, 186.01999999999998, -6.040000000000042, 186.01999999999998, 196.03999999999996, 167.06, 182.0, -0.00999999999999836, -4.030000000000042, 125.09, 176.03000000000003, 104.03, 182.0, 190.01, 189.02, 194.02999999999997, 175.13, 195.01999999999998, -30.880000000000003, -277.0, -32.170000000000364, 148.01, 151.01, 176.24, 99.08000000000004, 139.01, 160.16000000000003, 177.01999999999998, 156.23, -8.050000000000042, 140.0, 199.01, 109.01, -112.99000000000001, -28.14999999999971, -383.9200000000001, -8.050000000000042, 126.14, 175.01, -12.070000000000041, 2.0000000000000013, -10.060000000000041, 190.07, 135.26000000000005, -8.050000000000042, 156.07999999999998, 188.12, -6.040000000000042, 176.0, 167.09, 118.00999999999999, -4.030000000000042, 150.02, -6.040000000000042, 153.14000000000001, 199.01, 198.02, 106.00999999999999, 146.06, 199.01, 139.01, 131.03, 184.01, 182.06, 193.07, 143.03, -16.0899999999997, -8.050000000000042, 133.01, 157.01, 162.05, 188.03, 158.0, 155.12, -10.060000000000041, 149.0, -263.3200000000005, 31.009999999999998, 59.17999999999998, 51.37999999999997, 153.02, 148.10000000000002, 172.16000000000003, 175.01, 154.01, 116.03, -6.040000000000042, 162.11, 2.0000000000000013, -10.060000000000041, 144.01999999999998, 173.0, -400.0, -20.109999999999705, 166.04000000000002, 191.0, 198.01999999999998, 154.16000000000003, 146.06, 137.06, 84.02000000000001, 182.0, -400.0, -456.0, 113.0, 136.01, -16.0899999999997, 160.4, 174.14000000000001, 150.01999999999998, 169.01, -12.070000000000041, 163.01, 2.0000000000000013, 2.0000000000000013, 182.03, 196.01, 161.12, -400.0, -336.8800000000001, 172.16, 173.0, 73.13, 158.03, 200.0, 133.09999999999997, 181.01, 190.01, 199.01, 168.05, 145.01, -2.020000000000042, 101.0, -325.6300000000003, 81.02, 168.02, -400.0, -391.0, 199.01, 140.0, -389.95, -40.210000000000356, 2.0000000000000013, -14.080000000000041, -2.020000000000042, 160.04000000000002, 152.48000000000002, -400.0, 145.01, 172.01, 83.92999999999998, 165.01999999999998, 121.34000000000007, 169.04000000000002, 173.18, 123.10999999999999, 61.03999999999999, 172.19, 156.13999999999996, 170.09, 200.0, 149.14999999999998, 165.05, 179.06, 145.07000000000002, 174.23, 190.09999999999997, 164.03, 143.09000000000003, 186.11, 103.03999999999999, 188.12, 125.0, 182.0, 134.09000000000003, 2.0000000000000013, -4.030000000000042, 175.04000000000002, 132.47, 193.07, 187.04000000000002, 2.0000000000000013, 188.05999999999995, 124.04, 157.04000000000002, 122.06, 151.07, 176.24, 125.03, 191.09, 147.14, 142.04, 181.01, 176.24, 198.02, -16.0899999999997], "policy_predator_policy_reward": [31.0, 9.0, 20.0, 18.0, 6.0, 7.0, 4.0, 4.0, 8.0, 9.0, 6.0, 4.0, 22.0, 14.0, 13.0, 31.0, 6.0, 2.0, 3.0, 0.0, 3.0, 2.0, 175.0, 7.0, 17.0, 17.0, 16.0, 0.0, 20.0, 31.0, 7.0, 8.0, 5.0, 7.0, 5.0, 20.0, 108.0, 18.0, 15.0, 192.0, 19.0, 6.0, 8.0, 7.0, 6.0, 1.0, 13.0, 1.0, 16.0, 8.0, 1.0, 4.0, 8.0, 8.0, 20.0, 13.0, 4.0, 16.0, 11.0, 7.0, 31.0, 17.0, 4.0, 12.0, 17.0, 24.0, 1.0, 9.0, 18.0, 16.0, 9.0, 9.0, 15.0, 12.0, 11.0, 3.0, 14.0, 10.0, 17.0, 6.0, 139.0, 18.0, 8.0, 4.0, 14.0, 11.0, 5.0, 12.0, 28.0, 10.0, 4.0, 13.0, 4.0, 6.0, 14.0, 12.0, 3.0, 200.0, 3.0, 10.0, 0.0, 10.0, 21.0, 3.0, 42.0, 38.0, 263.0, 200.0, 28.0, 24.0, 7.0, 9.0, 15.0, 13.0, 11.0, 6.0, 12.0, 6.0, 0.0, 5.0, 2.0, 8.0, 200.0, 4.0, 9.0, 8.0, 44.0, 20.0, 19.0, 0.0, 6.0, 3.0, 1.0, 8.0, 18.0, 2.0, 169.0, 17.0, 32.0, 41.0, 200.0, 16.0, 18.0, 8.0, 21.0, 195.0, 8.0, 3.0, 14.0, 0.0, 200.0, 3.0, 18.0, 9.0, 8.0, 11.0, 12.0, 11.0, 22.0, 13.0, 23.0, 44.0, 6.0, 11.0, 8.0, 12.0, 0.0, 12.0, 3.0, 17.0, 7.0, 10.0, 16.0, 13.0, 31.0, 21.0, 26.0, 5.0, 17.0, 12.0, 7.0, 4.0, 7.0, 4.0, 3.0, 2.0, 3.0, 26.0, 16.0, 24.0, 12.0, 6.0, 23.0, 18.0, 23.0, 8.0, 1.0, 6.0, 9.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.687729789665849, "mean_inference_ms": 1.9194656306379665, "mean_action_processing_ms": 0.28871826837769715, "mean_env_wait_ms": 0.23094660640898912, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004946351051330566, "StateBufferConnector_ms": 0.0070154666900634766, "ViewRequirementAgentConnector_ms": 0.15879809856414795}, "num_episodes": 23, "episode_return_max": 386.04999999999995, "episode_return_min": -575.0, "episode_return_mean": 226.31629999999993, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.0523952196333, "num_env_steps_trained_throughput_per_sec": 378.0523952196333, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 12227.623, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12227.53, "sample_time_ms": 1820.05, "learn_time_ms": 10378.312, "learn_throughput": 385.419, "synch_weights_time_ms": 24.862}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "310e1_00000", "date": "2024-08-15_01-16-57", "timestamp": 1723664817, "time_this_iter_s": 10.586523056030273, "time_total_s": 1170.2296164035797, "pid": 86731, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1995c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1170.2296164035797, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 48.38, "ram_util_percent": 77.53999999999999}}
