{"num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.40409842270776, "num_env_steps_trained_throughput_per_sec": 157.40409842270776, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "training_iteration": 100, "timestamp": 1724317099, "time_this_iter_s": 25.481299877166748, "time_total_s": 2590.150098800659, "time_since_restore": 2590.150098800659, "iterations_since_restore": 100, "info/num_env_steps_sampled": 400000, "info/num_env_steps_trained": 400000, "info/num_agent_steps_sampled": 1600000, "info/num_agent_steps_trained": 1600000, "env_runners/episode_reward_max": 930.1104736383732, "env_runners/episode_reward_min": -165.20547486986484, "env_runners/episode_reward_mean": 236.62618024052688, "env_runners/episode_len_mean": 400.0, "env_runners/episodes_timesteps_total": 40000, "env_runners/num_faulty_episodes": 0, "env_runners/num_episodes": 9, "env_runners/episode_return_max": 930.1104736383732, "env_runners/episode_return_min": -165.20547486986484, "env_runners/episode_return_mean": 236.62618024052688, "env_runners/episodes_this_iter": 9, "timers/training_iteration_time_ms": 25733.113, "timers/restore_workers_time_ms": 0.025, "timers/training_step_time_ms": 25732.852, "timers/sample_time_ms": 2387.639, "timers/learn_time_ms": 23320.776, "timers/learn_throughput": 171.521, "timers/synch_weights_time_ms": 21.961, "counters/num_env_steps_sampled": 400000, "counters/num_env_steps_trained": 400000, "counters/num_agent_steps_sampled": 1600000, "counters/num_agent_steps_trained": 1600000, "perf/cpu_util_percent": 32.222222222222214, "perf/ram_util_percent": 83.16944444444444, "info/learner/predator_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/predator_policy/num_grad_updates_lifetime": 94028.0, "info/learner/predator_policy/diff_num_grad_updates_vs_sampler_policy": 472.0, "info/learner/prey_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/prey_policy/num_grad_updates_lifetime": 94028.0, "info/learner/prey_policy/diff_num_grad_updates_vs_sampler_policy": 472.0, "info/learner/predator_policy/learner_stats/allreduce_latency": 0.0, "info/learner/predator_policy/learner_stats/grad_gnorm": 27.810931699742717, "info/learner/predator_policy/learner_stats/cur_kl_coeff": 0.1, "info/learner/predator_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/predator_policy/learner_stats/total_loss": 7.04558997532678, "info/learner/predator_policy/learner_stats/policy_loss": -0.008626659687056585, "info/learner/predator_policy/learner_stats/vf_loss": 7.053512392094526, "info/learner/predator_policy/learner_stats/vf_explained_var": 0.12987904946009318, "info/learner/predator_policy/learner_stats/kl": 0.007042333601589595, "info/learner/predator_policy/learner_stats/entropy": 0.2722452781503163, "info/learner/predator_policy/learner_stats/entropy_coeff": 0.0, "info/learner/prey_policy/learner_stats/allreduce_latency": 0.0, "info/learner/prey_policy/learner_stats/grad_gnorm": 34.33387846189832, "info/learner/prey_policy/learner_stats/cur_kl_coeff": 0.2, "info/learner/prey_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/prey_policy/learner_stats/total_loss": 7.100638500597111, "info/learner/prey_policy/learner_stats/policy_loss": -0.007998831850038003, "info/learner/prey_policy/learner_stats/vf_loss": 7.10735845515337, "info/learner/prey_policy/learner_stats/vf_explained_var": 0.4835566000332908, "info/learner/prey_policy/learner_stats/kl": 0.006394367639428724, "info/learner/prey_policy/learner_stats/entropy": 0.5266360229916043, "info/learner/prey_policy/learner_stats/entropy_coeff": 0.0, "_timestamp": 1724317099.1352031, "_runtime": 2588.4563932418823, "_step": 99, "env_runners/policy_reward_min/prey_policy": -989.4450671957516, "env_runners/policy_reward_min/predator_policy": 11.582035499078014, "env_runners/policy_reward_max/prey_policy": 397.3, "env_runners/policy_reward_max/predator_policy": 892.6661183972611, "env_runners/policy_reward_mean/prey_policy": -363.8699444635861, "env_runners/policy_reward_mean/predator_policy": 482.18303458384975, "env_runners/sampler_perf/mean_raw_obs_processing_ms": 4.954371480846042, "env_runners/sampler_perf/mean_inference_ms": 4.414580221387782, "env_runners/sampler_perf/mean_action_processing_ms": 1.6340141197903784, "env_runners/sampler_perf/mean_env_wait_ms": 12.69869803929163, "env_runners/sampler_perf/mean_env_render_ms": 0.0, "env_runners/connector_metrics/ObsPreprocessorConnector_ms": 0.004554271697998047, "env_runners/connector_metrics/StateBufferConnector_ms": 0.005121588706970215, "env_runners/connector_metrics/ViewRequirementAgentConnector_ms": 0.14476561546325684}