{"num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 4000000, "num_agent_steps_trained": 4000000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 65.0716489671565, "num_env_steps_trained_throughput_per_sec": 65.0716489671565, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 4000000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 4000000, "training_iteration": 100, "timestamp": 1724418936, "time_this_iter_s": 61.53222179412842, "time_total_s": 6657.240989208221, "time_since_restore": 6657.240989208221, "iterations_since_restore": 100, "info/num_env_steps_sampled": 400000, "info/num_env_steps_trained": 400000, "info/num_agent_steps_sampled": 4000000, "info/num_agent_steps_trained": 4000000, "env_runners/episode_reward_max": 928.1732582393693, "env_runners/episode_reward_min": 414.22395313391416, "env_runners/episode_reward_mean": 658.2888366474513, "env_runners/episode_len_mean": 400.0, "env_runners/episodes_timesteps_total": 40000, "env_runners/num_faulty_episodes": 0, "env_runners/num_episodes": 11, "env_runners/episode_return_max": 928.1732582393693, "env_runners/episode_return_min": 414.22395313391416, "env_runners/episode_return_mean": 658.2888366474513, "env_runners/episodes_this_iter": 11, "timers/training_iteration_time_ms": 61765.148, "timers/restore_workers_time_ms": 0.014, "timers/training_step_time_ms": 61765.095, "timers/sample_time_ms": 3371.965, "timers/learn_time_ms": 58371.198, "timers/learn_throughput": 68.527, "timers/synch_weights_time_ms": 14.26, "counters/num_env_steps_sampled": 400000, "counters/num_env_steps_trained": 400000, "counters/num_agent_steps_sampled": 4000000, "counters/num_agent_steps_trained": 4000000, "perf/cpu_util_percent": 29.4816091954023, "perf/ram_util_percent": 82.95862068965518, "info/learner/predator_policy/num_agent_steps_trained": 127.38853503184713, "info/learner/predator_policy/num_grad_updates_lifetime": 234323.0, "info/learner/predator_policy/diff_num_grad_updates_vs_sampler_policy": 1177.0, "info/learner/prey_policy/num_agent_steps_trained": 127.38853503184713, "info/learner/prey_policy/num_grad_updates_lifetime": 234323.0, "info/learner/prey_policy/diff_num_grad_updates_vs_sampler_policy": 1177.0, "info/learner/predator_policy/learner_stats/allreduce_latency": 0.0, "info/learner/predator_policy/learner_stats/grad_gnorm": 6.6074967605546275, "info/learner/predator_policy/learner_stats/cur_kl_coeff": 0.15000000000000002, "info/learner/predator_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/predator_policy/learner_stats/total_loss": Infinity, "info/learner/predator_policy/learner_stats/policy_loss": -0.005082764016215209, "info/learner/predator_policy/learner_stats/vf_loss": 6.440557753811976, "info/learner/predator_policy/learner_stats/vf_explained_var": 0.15299329517247065, "info/learner/predator_policy/learner_stats/kl": Infinity, "info/learner/predator_policy/learner_stats/entropy": 0.5916877762780322, "info/learner/predator_policy/learner_stats/entropy_coeff": 0.0, "info/learner/prey_policy/learner_stats/allreduce_latency": 0.0, "info/learner/prey_policy/learner_stats/grad_gnorm": 11.047466083443595, "info/learner/prey_policy/learner_stats/cur_kl_coeff": 0.2, "info/learner/prey_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/prey_policy/learner_stats/total_loss": 7.891693566761705, "info/learner/prey_policy/learner_stats/policy_loss": -0.01053516999778838, "info/learner/prey_policy/learner_stats/vf_loss": 7.900287429137341, "info/learner/prey_policy/learner_stats/vf_explained_var": -0.0811768582165874, "info/learner/prey_policy/learner_stats/kl": 0.009706459445839317, "info/learner/prey_policy/learner_stats/entropy": 0.7683194393058744, "info/learner/prey_policy/learner_stats/entropy_coeff": 0.0, "_timestamp": 1724418936.84161, "_runtime": 6643.553997993469, "_step": 99, "env_runners/policy_reward_min/prey_policy": -295.07807142237266, "env_runners/policy_reward_min/predator_policy": 73.88097816460521, "env_runners/policy_reward_max/prey_policy": 202.108567222058, "env_runners/policy_reward_max/predator_policy": 354.0179288806733, "env_runners/policy_reward_mean/prey_policy": -55.034685795446116, "env_runners/policy_reward_mean/predator_policy": 186.6924531249344, "env_runners/sampler_perf/mean_raw_obs_processing_ms": 11.525476682901928, "env_runners/sampler_perf/mean_inference_ms": 7.790650762264106, "env_runners/sampler_perf/mean_action_processing_ms": 4.197253487368397, "env_runners/sampler_perf/mean_env_wait_ms": 12.704494294084821, "env_runners/sampler_perf/mean_env_render_ms": 0.0, "env_runners/connector_metrics/ObsPreprocessorConnector_ms": 0.021119117736816406, "env_runners/connector_metrics/StateBufferConnector_ms": 0.011327981948852539, "env_runners/connector_metrics/ViewRequirementAgentConnector_ms": 0.299741268157959}