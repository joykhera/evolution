{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1420088072617849, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4647984355688095, "policy_loss": -0.02587617055833107, "vf_loss": 5.487083757917087, "vf_explained_var": -0.003895837875703971, "kl": 0.017954249050279425, "entropy": 1.5916425139953694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5494537261995018, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7962479097411987, "policy_loss": -0.007865124120185455, "vf_loss": 0.8024261051326568, "vf_explained_var": 3.791316181209916e-05, "kl": 0.008434595746419886, "entropy": 1.6012232940670446, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 1410.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 130.39449651842182, "episode_reward_min": -125.81902043454991, "episode_reward_mean": -5.716734720813262, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -125.81902043454991}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 3.4640522875816995, "agent_policy": -16.108891583558357}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.283725820125303, -9.413195422230679, 0.0, -14.215152418040967, -3.695494284033594, -0.4571636446124361, -3.1671459374940802, -21.14964018047038, -2.2687606447573305, 0.0, 100.0, 0.0, 130.39449651842182, -20.862609820943185, -6.487060124461822, 13.64230287088052, 0.0, 60.0, -3.0035584760454563, 20.0, 0.0, 0.0, 0.0, -15.722364232063518, 6.551914728132109, -22.787175913127708, 0.0, -24.640643955584444, -45.430285724987044, -13.818127168566164, -0.17990986839077183, 0.0, -10.293111403342312, -27.014384114733385, -27.384276720475462, 0.0, -5.2041403393465995, -16.838959849896494, -2.7139651525447324, 0.0, -65.8802787919937, -19.952158780705535, 23.9195997343404, 0.0, -16.107479727706888, -30.552564061961146, 60.0, -8.836173637755017, -15.865245059176477, 0.0, 37.22693803653689, 0.0, 0.0, -4.226775183214697, 40.0, 0.0, -9.967227184075238, -11.46944528860115, -1.6321713267629268, 0.0, -38.92183923103943, 0.0, -1.5529865346545535, -36.04818093585241, -38.31963657020035, -15.565300095735644, 39.49781073444791, -15.075955138589668, 0.0, 0.0, -2.2690655054784425, -29.732888557371513, -13.389360973022821, 0.0, 0.0, 0.0, 0.0, -43.77732715197794, -14.865790306123692, 16.206900035342187, -2.753124750302504, 0.0, -1.129973221390036, 40.0, -15.241955110871473, -15.076240558556703, -125.81902043454991, -14.09038167905986, -8.577980243854167, 0.0, 0.0, -1.034411111261374, -33.15998876491169, 0.0, -34.66132608462749, 80.0, 42.31579222566811, -9.025549708503, -6.504712365950197, 0.0, 16.20659542004664, -10.126316837590208, 0.0, 0.0, -25.766364955464876, 0.0, -79.9982500173797, -4.350919597484852, -14.089722930058365, -35.82735072870616, -5.015663200204563, 41.03700522335306, -36.3848817185125, 0.0, -1.4525764730446016, -57.429873075939966, 0.0, 40.0, -44.214991406473644, -19.813964696714653, -72.18824182279901, 0.0, 0.0, -17.399646665220697, -0.36771320580398004, 0.0, 59.30278260296593, -21.29445482005916, -59.95970788093132, -13.65674043656936, 0.0, -19.449602398299, -9.123729055296861, -62.35488746372604, 0.0, 0.0, 0.0, 20.0, -2.5720140755447245, 0.0, -4.1628797333502785, 33.57558419386549, -26.651258314189228, -4.212748546982396, -17.133878101806452, -0.5562835375670139, 0.0, 0.0, -29.20428978408486, -15.355693453294448, -16.69494931922897, -26.27436554667952, -54.90826115756176], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-18.71627417987469, -9.413195422230679, 0.0, -14.215152418040967, -3.695494284033594, -0.4571636446124361, -3.1671459374940802, -21.14964018047038, -2.2687606447573305, 0.0, -50.0, 0.0, -79.60550348157818, -20.862609820943185, -36.48706012446183, -16.35769712911948, 0.0, -30.0, -3.0035584760454563, -10.0, 0.0, 0.0, 0.0, -15.722364232063518, -23.448085271867892, -22.787175913127708, 0.0, -24.640643955584444, -45.430285724987044, -13.818127168566164, -0.17990986839077183, 0.0, -10.293111403342312, -27.014384114733385, -27.384276720475462, 0.0, -5.2041403393465995, -16.838959849896494, -2.7139651525447324, 0.0, -65.8802787919937, -19.952158780705535, -36.0804002656596, 0.0, -16.107479727706888, -30.552564061961146, -30.0, -8.836173637755017, -15.865245059176477, 0.0, -22.773061963463103, 0.0, 0.0, -4.226775183214697, -20.0, 0.0, -9.967227184075238, -11.46944528860115, -1.6321713267629268, 0.0, -38.92183923103943, 0.0, -1.5529865346545535, -36.04818093585241, -38.31963657020035, -15.565300095735644, -20.50218926555209, -15.075955138589668, 0.0, 0.0, -2.2690655054784425, -29.732888557371513, -13.389360973022821, 0.0, 0.0, 0.0, 0.0, -43.77732715197794, -14.865790306123692, -13.79309996465781, -2.753124750302504, 0.0, -1.129973221390036, -20.0, -15.241955110871473, -15.076240558556703, -125.81902043454991, -14.09038167905986, -8.577980243854167, 0.0, 0.0, -1.034411111261374, -33.15998876491169, 0.0, -34.66132608462749, -40.0, -47.68420777433189, -9.025549708503, -6.504712365950197, 0.0, -13.793404579953362, -10.126316837590208, 0.0, 0.0, -25.766364955464876, 0.0, -79.9982500173797, -4.350919597484852, -14.089722930058365, -35.82735072870616, -5.015663200204563, -48.96299477664692, -36.3848817185125, 0.0, -1.4525764730446016, -57.429873075939966, 0.0, -20.0, -44.214991406473644, -19.813964696714653, -72.18824182279901, 0.0, 0.0, -17.399646665220697, -0.36771320580398004, 0.0, -30.69721739703407, -21.29445482005916, -59.95970788093132, -13.65674043656936, 0.0, -19.449602398299, -9.123729055296861, -62.35488746372604, 0.0, 0.0, 0.0, -10.0, -2.5720140755447245, 0.0, -4.1628797333502785, -26.4244158061345, -26.651258314189228, -4.212748546982396, -17.133878101806452, -0.5562835375670139, 0.0, 0.0, -29.20428978408486, -15.355693453294448, -16.69494931922897, -26.27436554667952, -54.90826115756176]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6705532363723998, "mean_inference_ms": 1.208620533958366, "mean_action_processing_ms": 0.24619945217889921, "mean_env_wait_ms": 0.520245446665113, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005295151978536369, "StateBufferConnector_ms": 0.0034094635957206774, "ViewRequirementAgentConnector_ms": 0.09552014419455933}, "num_episodes": 153, "episode_return_max": 130.39449651842182, "episode_return_min": -125.81902043454991, "episode_return_mean": -5.716734720813262}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.10955637627734, "num_env_steps_trained_throughput_per_sec": 300.10955637627734, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 13328.576, "restore_workers_time_ms": 0.095, "training_step_time_ms": 13328.226, "sample_time_ms": 1239.324, "learn_time_ms": 12072.495, "learn_throughput": 331.332, "synch_weights_time_ms": 15.349}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-36-16", "timestamp": 1723138576, "time_this_iter_s": 13.378559112548828, "time_total_s": 13.378559112548828, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc92e430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 13.378559112548828, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 33.65, "ram_util_percent": 82.47999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9909244839412471, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.842201486974955, "policy_loss": -0.02223193890725573, "vf_loss": 3.8615737578521174, "vf_explained_var": -0.002210368278125922, "kl": 0.014298451836148173, "entropy": 1.5554229993373156, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5562949725076662, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7255763685238277, "policy_loss": -0.008283377212558127, "vf_loss": 1.7323436689292286, "vf_explained_var": 8.362278025201027e-06, "kl": 0.007579961967482316, "entropy": 1.587835168838501, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 4230.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -166.41208813908372, "episode_reward_mean": 6.6278510971606694, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -166.41208813908372}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.037037037037037, "agent_policy": -14.48326001395044}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 20.0, -4.018271333483188, 80.0, 0.0, 39.54832663904761, -21.620529752293937, -9.717808168311818, 0.0, 0.0, 20.0, -0.6128037102310746, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, -12.412080354828568, 20.0, -56.46391409073654, 40.0, 0.0, 120.0, -2.859389344742901, -28.44263745921834, -22.95966680874339, -0.5445360893903173, -9.14239021328159, -15.382718057476614, -2.9966652168506416, 39.669348817849865, -2.558159469972077, -5.764831622813094, 0.0, 0.0, -13.634612215089023, 0.0, 12.45784021415439, 0.0, 9.764307063073613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -15.09881809844498, 20.0, 20.0, 0.0, 58.767946273969656, 14.723314586253558, 0.0, -8.798708658693151, 0.0, 60.0, -166.41208813908372, 20.0, 0.0, 0.0, 60.0, -3.5345046397385573, 100.0, -15.244217336540554, -24.290701037594104, -3.383262899131071, 34.939548372649284, 0.0, 0.0, -17.513487154989217, 20.0, 38.25743702463452, 0.0, 0.0, 11.726736998320861, 0.0, 60.0, 0.0, 0.0, -0.13973649721551462, 16.97460052941872, -0.9618422171943153, -0.35819170366929165, -28.148956586602612, 0.0, 40.0, -2.31370344953726, 0.0, 0.0, -45.72221139858417, -10.382898617293984, 97.73492767562449, 0.0, 0.0, 80.0, -7.266957557026384, 0.0, 0.0, 40.0, 0.0, -3.976360687918083, -0.07316064519507837, -37.894844710941044, 60.0, -26.961502906562064, 0.0, 0.0, -41.92267365448886, 40.0, 10.994217689250188, 40.0, 14.26358073482821, -11.924484111875119, 0.0, 0.0, 60.0, 60.0, -70.39996264707602, 60.0, 0.0, 40.0, 60.0, -7.2258736239812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -23.86117133332926, 0.0, 0.0, -2.069900894477988, 0.0, -19.73609322071256, 0.0, 0.0, 0.0, -0.8273942019848801, 60.0, 60.0, 18.227657961930973, 0.0, -19.093604030711553, 36.47043704465073, 0.0, 0.0, -1.1037841681404825, -4.498465603045819, -10.424215377082335, 56.369115799491425, -48.29566681922632, -9.40629683458354, 60.0, 40.780654428905244, -37.4127899780411, -0.1305997528961056, -2.0045619611726595, 0.0, -0.013413051780796215, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -10.0, -34.018271333483185, -40.0, 0.0, -20.45167336095239, -21.620529752293937, -9.717808168311818, 0.0, 0.0, -10.0, -0.6128037102310746, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -12.412080354828568, -10.0, -56.46391409073654, -20.0, 0.0, -60.0, -2.859389344742901, -28.44263745921834, -22.95966680874339, -0.5445360893903173, -9.14239021328159, -15.382718057476614, -2.9966652168506416, -20.330651182150135, -2.558159469972077, -5.764831622813094, 0.0, 0.0, -43.634612215089035, 0.0, -77.54215978584561, 0.0, -20.235692936926384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -15.09881809844498, -10.0, -10.0, 0.0, -31.232053726030344, -15.276685413746444, 0.0, -8.798708658693151, 0.0, -30.0, -166.41208813908372, -10.0, 0.0, 0.0, -30.0, -3.5345046397385573, -50.0, -15.244217336540554, -24.290701037594104, -3.383262899131071, -25.060451627350716, 0.0, 0.0, -17.513487154989217, -10.0, -21.74256297536548, 0.0, 0.0, -48.27326300167914, 0.0, -30.0, 0.0, 0.0, -0.13973649721551462, -13.025399470581284, -0.9618422171943153, -0.35819170366929165, -28.148956586602612, 0.0, -20.0, -2.31370344953726, 0.0, 0.0, -45.72221139858417, -10.382898617293984, -82.26507232437551, 0.0, 0.0, -40.0, -7.266957557026384, 0.0, 0.0, -20.0, 0.0, -3.976360687918083, -0.07316064519507837, -37.894844710941044, -30.0, -26.961502906562064, 0.0, 0.0, -41.92267365448886, -20.0, -19.00578231074981, -20.0, -75.73641926517178, -11.924484111875119, 0.0, 0.0, -30.0, -30.0, -70.39996264707602, -30.0, 0.0, -20.0, -30.0, -7.2258736239812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -23.86117133332926, 0.0, 0.0, -2.069900894477988, 0.0, -19.73609322071256, 0.0, 0.0, 0.0, -0.8273942019848801, -30.0, -30.0, -11.772342038069025, 0.0, -19.093604030711553, -23.529562955349267, 0.0, 0.0, -1.1037841681404825, -4.498465603045819, -10.424215377082335, -63.63088420050856, -48.29566681922632, -9.40629683458354, -30.0, -49.219345571094756, -37.4127899780411, -0.1305997528961056, -2.0045619611726595, 0.0, -0.013413051780796215, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6871827077657118, "mean_inference_ms": 1.2035461912921634, "mean_action_processing_ms": 0.24110012436189143, "mean_env_wait_ms": 0.513307220266332, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005409894166169343, "StateBufferConnector_ms": 0.004055470596125097, "ViewRequirementAgentConnector_ms": 0.10794563057981892}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -166.41208813908372, "episode_return_mean": 6.6278510971606694}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.6267098788617, "num_env_steps_trained_throughput_per_sec": 199.6267098788617, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 16682.991, "restore_workers_time_ms": 0.054, "training_step_time_ms": 16682.793, "sample_time_ms": 1245.296, "learn_time_ms": 15409.964, "learn_throughput": 259.572, "synch_weights_time_ms": 25.237}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-36-36", "timestamp": 1723138596, "time_this_iter_s": 20.082593202590942, "time_total_s": 33.46115231513977, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc970430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 33.46115231513977, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 65.13571428571427, "ram_util_percent": 83.05}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0830666463201244, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2579071544731657, "policy_loss": -0.017039622968877666, "vf_loss": 2.272610191317896, "vf_explained_var": 0.00500115267932415, "kl": 0.011682926188100311, "entropy": 1.5240309083213408, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5744276960479452, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0602469316082643, "policy_loss": -0.008693932873446244, "vf_loss": 1.0673300540933373, "vf_explained_var": 7.335027904375225e-06, "kl": 0.008053879116553123, "entropy": 1.5706702029451411, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 7050.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -59.0835816329902, "episode_reward_mean": 6.081155808449348, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -59.0835816329902}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.753086419753086, "agent_policy": -8.17810345080991}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 54.24135573752551, -1.6086689506439378, -59.0835816329902, -1.6397696229331504, 0.0, 0.0, 0.0, 79.61728757157535, -4.161475648978886, -14.013933731268157, 0.0, 20.0, 40.0, 0.0, -0.5421723351959307, 0.0, 58.08193074377771, 0.0, -3.819805681684646, 0.0, -0.09987782860425232, 0.0, 0.0, -15.854969740315559, -46.98332898600874, -3.911725558281739, 0.0, 0.0, -3.0032334670817162, -0.22870722227952722, 0.0, 0.0, -2.059761392680649, 0.0, -2.2927717711136344, 20.0, 0.0, -2.296257163844828, 31.15571469909404, 0.0, 0.0, 0.0, 0.0, -31.128682107921644, 0.0, 0.0, 60.0, -9.749421460134563, 0.0, 0.0, 0.0, 39.906343438840565, 0.0, 0.0, 0.0, 0.0, 80.0, 0.0, 20.0, 0.0, -0.006060317894766021, 0.0, 0.0, 0.0, 0.0, -0.4656048530224488, 40.0, 0.0, 39.998279320426924, -24.933546748384252, 0.0, -2.2228603097720034, 0.0, -0.23220411114154182, -0.43375541492538083, -1.636651763323519, 0.0, -1.2337639552092627, -2.726834767944645, 0.0, 20.0, 40.0, 20.0, -2.5944359794521334, 0.0, 60.0, 20.0, 0.0, 0.0, 0.0, 0.0, -8.16378521191499, 0.0, -3.051743738930406, -3.246507591045546, 0.0, 0.0, 20.0, 0.0, 13.582225861652788, -0.31646581051500755, 0.0, 6.670498414090992, 0.0, 0.0, -26.53969225348486, 60.0, 0.0, -8.068535325389762, 0.0, 0.0, 80.0, -0.49816653461158267, 0.0, 78.90447131558335, 19.211826312747412, 0.0, 0.0, 0.0, 60.0, 11.220871268444949, -17.591290653698355, -37.552922573344034, -31.565245071399094, -0.8760266664803207, 0.0, -20.05531247900316, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 0.0, 60.0, 20.0, -16.04829673707716, 80.0, -43.48519051666389, -7.441611960125363, -0.521975023859419, 0.0, 0.0, -1.6873972221113298, -10.868329685282482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.914158611329674, 58.85742372394549, -27.80353917169448, 0.0, 58.95906792208194, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -35.75864426247449, -1.6086689506439378, -59.0835816329902, -1.6397696229331504, 0.0, 0.0, 0.0, -40.382712428424654, -4.161475648978886, -14.013933731268157, 0.0, -10.0, -20.0, 0.0, -0.5421723351959307, 0.0, -31.91806925622229, 0.0, -3.819805681684646, 0.0, -0.09987782860425232, 0.0, 0.0, -15.854969740315559, -46.98332898600874, -3.911725558281739, 0.0, 0.0, -3.0032334670817162, -0.22870722227952722, 0.0, 0.0, -2.059761392680649, 0.0, -2.2927717711136344, -10.0, 0.0, -2.296257163844828, -28.84428530090596, 0.0, 0.0, 0.0, 0.0, -31.128682107921644, 0.0, 0.0, -30.0, -9.749421460134563, 0.0, 0.0, 0.0, -20.09365656115943, 0.0, 0.0, 0.0, 0.0, -40.0, 0.0, -10.0, 0.0, -0.006060317894766021, 0.0, 0.0, 0.0, 0.0, -0.4656048530224488, -20.0, 0.0, -20.001720679573076, -24.933546748384252, 0.0, -2.2228603097720034, 0.0, -0.23220411114154182, -0.43375541492538083, -1.636651763323519, 0.0, -1.2337639552092627, -2.726834767944645, 0.0, -10.0, -20.0, -10.0, -2.5944359794521334, 0.0, -30.0, -10.0, 0.0, 0.0, 0.0, 0.0, -8.16378521191499, 0.0, -3.051743738930406, -3.246507591045546, 0.0, 0.0, -10.0, 0.0, -16.417774138347212, -0.31646581051500755, 0.0, -23.329501585909, 0.0, 0.0, -26.53969225348486, -30.0, 0.0, -8.068535325389762, 0.0, 0.0, -40.0, -0.49816653461158267, 0.0, -41.09552868441665, -10.788173687252582, 0.0, 0.0, 0.0, -30.0, -18.779128731555048, -17.591290653698355, -37.552922573344034, -31.565245071399094, -0.8760266664803207, 0.0, -20.05531247900316, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, 0.0, -30.0, -10.0, -16.04829673707716, -40.0, -43.48519051666389, -7.441611960125363, -0.521975023859419, 0.0, 0.0, -1.6873972221113298, -10.868329685282482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.914158611329674, -31.142576276054506, -27.80353917169448, 0.0, -31.040932077918058, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7112941268032199, "mean_inference_ms": 1.2414664524033754, "mean_action_processing_ms": 0.24484337421287575, "mean_env_wait_ms": 0.5215554281172406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005693053021843051, "StateBufferConnector_ms": 0.004080195485809703, "ViewRequirementAgentConnector_ms": 0.11206556249547887}, "num_episodes": 162, "episode_return_max": 80.0, "episode_return_min": -59.0835816329902, "episode_return_mean": 6.081155808449348}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.2416296774567, "num_env_steps_trained_throughput_per_sec": 287.2416296774567, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 15763.853, "restore_workers_time_ms": 0.048, "training_step_time_ms": 15763.693, "sample_time_ms": 1305.145, "learn_time_ms": 14434.645, "learn_throughput": 277.111, "synch_weights_time_ms": 21.32}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-36-50", "timestamp": 1723138610, "time_this_iter_s": 13.98140287399292, "time_total_s": 47.44255518913269, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f9280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 47.44255518913269, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 41.57894736842106, "ram_util_percent": 82.09473684210526}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8458814970838527, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.169948985738059, "policy_loss": -0.015465432648003723, "vf_loss": 2.183352593332529, "vf_explained_var": 0.0031805602212746937, "kl": 0.010309144671125654, "entropy": 1.5087778072804212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5700391285649851, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.280629791837212, "policy_loss": -0.008810230822290842, "vf_loss": 1.2875574638023444, "vf_explained_var": 7.471125176612367e-06, "kl": 0.009412460983839004, "entropy": 1.5571156248978688, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 9870.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -48.165670928601784, "episode_reward_mean": 10.05418388965198, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0977339015798}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.049382716049383, "agent_policy": -8.093964258496168}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.1083206741304505, 0.0, 0.0, 0.0, 0.0, 0.0, -14.504493759280741, -0.03466033563268467, -5.721976604059776, 0.0, -0.002342236954989696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, -7.062384325964487, -10.977893964018758, 0.0, -12.116419677203554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 28.269918211366047, -10.03207297633063, -0.024102084671028257, -1.3323251861798413, 20.0, -2.9126611205074466, 60.0, -9.368517870193257, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 40.0, 0.0, 0.0, 80.0, 0.0, 0.0, 0.0, 90.62347673625851, -0.12952307407349095, 0.0, -45.42546782462649, 0.0, 0.0, -16.831415669874243, 0.0, 0.0, -1.0977489200410695, 0.0, -0.3919031063127598, 0.0, 0.0, -0.33030067437447186, 0.0, -0.33552266449259904, 40.0, 0.0, 0.0, 60.0, 0.0, -12.054848405185284, 28.80417478008077, 20.0, -26.373611267953002, 40.0, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 0.0, -0.3568314270849082, 40.0, -0.2638893119942376, -1.482197431769211, 0.0, 40.0, 0.0, 0.0, -0.2786149858137643, -4.738800293263005, -14.933926335292599, 60.0, -2.004966072619979, 40.0, 0.0, -11.158732448479112, 0.0, 0.0, 0.0, 39.03658614698317, 0.0, 0.0, 0.0, 0.0, 74.4872649278573, 0.0, -7.965344432785115, 0.0, 0.0, 0.0, 0.0, 15.642141689308334, 60.0, 119.9022660984202, 60.0, -4.813345268172448, 0.0, -1.1955428874438634, 0.0, 0.0, 20.0, -48.165670928601784, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 40.0, 60.0, -4.204774550824411, 40.0, 120.0, 0.0, 0.0, 0.0, 40.0, -2.965405248783994, 40.0, 0.0, 0.0, -3.63956284963851, 0.0, 40.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 60.0, -0.6519215720255345], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-2.1083206741304505, 0.0, 0.0, 0.0, 0.0, 0.0, -14.504493759280741, -0.03466033563268467, -5.721976604059776, 0.0, -0.002342236954989696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -7.062384325964487, -10.977893964018758, 0.0, -12.116419677203554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -50.0, 0.0, -31.730081788633953, -10.03207297633063, -0.024102084671028257, -1.3323251861798413, -10.0, -2.9126611205074466, -30.0, -9.368517870193257, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, -20.0, 0.0, 0.0, -40.0, 0.0, 0.0, 0.0, -59.376523263741504, -0.12952307407349095, 0.0, -45.42546782462649, 0.0, 0.0, -16.831415669874243, 0.0, 0.0, -1.0977489200410695, 0.0, -0.3919031063127598, 0.0, 0.0, -0.33030067437447186, 0.0, -0.33552266449259904, -20.0, 0.0, 0.0, -30.0, 0.0, -12.054848405185284, -31.19582521991922, -10.0, -26.373611267953002, -20.0, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, 0.0, -0.3568314270849082, -20.0, -0.2638893119942376, -1.482197431769211, 0.0, -20.0, 0.0, 0.0, -0.2786149858137643, -4.738800293263005, -14.933926335292599, -30.0, -2.004966072619979, -20.0, 0.0, -11.158732448479112, 0.0, 0.0, 0.0, -20.96341385301683, 0.0, 0.0, 0.0, 0.0, -45.5127350721427, 0.0, -7.965344432785115, 0.0, 0.0, 0.0, 0.0, -14.357858310691666, -30.0, -60.0977339015798, -30.0, -4.813345268172448, 0.0, -1.1955428874438634, 0.0, 0.0, -10.0, -48.165670928601784, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -20.0, -30.0, -4.204774550824411, -20.0, -60.0, 0.0, 0.0, 0.0, -20.0, -2.965405248783994, -20.0, 0.0, 0.0, -3.63956284963851, 0.0, -20.0, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, -30.0, -0.6519215720255345]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6929190203221431, "mean_inference_ms": 1.210145199092687, "mean_action_processing_ms": 0.23935674032033546, "mean_env_wait_ms": 0.5130720062099589, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004606629595344449, "StateBufferConnector_ms": 0.0034256481829984687, "ViewRequirementAgentConnector_ms": 0.09425503236276132}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -48.165670928601784, "episode_return_mean": 10.05418388965198}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.6265313563686, "num_env_steps_trained_throughput_per_sec": 276.6265313563686, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 15437.874, "restore_workers_time_ms": 0.039, "training_step_time_ms": 15437.742, "sample_time_ms": 1270.188, "learn_time_ms": 14143.155, "learn_throughput": 282.822, "synch_weights_time_ms": 21.035}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-37-04", "timestamp": 1723138624, "time_this_iter_s": 14.527925968170166, "time_total_s": 61.970481157302856, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f94c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 61.970481157302856, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 41.357142857142854, "ram_util_percent": 82.14285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9604670624559124, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3935548045362034, "policy_loss": -0.0171276044328503, "vf_loss": 2.4085253066072863, "vf_explained_var": -0.0025106636186440785, "kl": 0.01078551603659322, "entropy": 1.4728453910599153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6105962741142469, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4487645423158686, "policy_loss": -0.010474830973936337, "vf_loss": 1.4572622153775912, "vf_explained_var": 1.0018631921592334e-05, "kl": 0.009885321152323347, "entropy": 1.5347999483135575, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 12690.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -41.244044949973635, "episode_reward_mean": 13.43525653143241, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -76.88583803253054}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.770700636942675, "agent_policy": -9.876845379395615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.4400415769491666, 39.34978863762764, -12.258427464378924, -15.509237224843169, 0.0, 0.0, 100.0, 60.0, 0.0, 0.0, -3.034096864171718, 0.0, 0.0, 0.0, 57.97431916032437, 0.0, 19.799743302940872, 0.0, -2.30684094680492, 0.0, 0.0, -1.5194939043920375, 80.0, 40.0, -41.244044949973635, 0.0, 20.0, -5.819379336166076, -2.0260179912193523, 80.0, 0.0, 0.0, 80.0, 40.0, -2.2075494381920766, 0.0, 40.0, 40.0, 0.0, 0.0, 0.0, -22.299554365871344, 0.0, 0.0, -12.392574047069042, 0.0, 0.0, 0.0, -2.0971513225434415, 73.11416196746946, 20.0, 0.0, 100.0, 39.01045901780209, 0.0, 0.0, 0.0, 0.0, -0.5417804376520596, -0.9141644473327604, -1.164092329608456, -9.419240124832427, 0.0, -1.0912257308115236, 0.0, 0.0, -8.217336607923574, 60.0, 19.560782146629013, -0.4698758179660856, 0.0, 0.0, 40.0, 0.0, 40.0, -9.510474284029154, 20.0, 11.76845327209501, 49.59098125022492, 60.0, 100.0, -0.09513768609263673, 0.0, -5.4966948232310475, 0.0, 0.0, -5.753310970800403, 0.0, 20.0, 0.0, 57.00563508467174, -0.613526656925667, 0.0, 40.0, 0.0, -2.3062737411962067, 40.0, 55.02305043520859, 0.0, 20.0, -0.9199938382971462, -0.6132003151186072, 0.0, 79.50260997645736, 90.42306205437781, 60.0, 60.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, 80.0, -0.33208979355587753, 0.0, 0.0, -9.149535191818655, -9.419182493626398, 0.0, 0.0, -1.2066544569972926, 17.79304480770476, 0.0, 0.0, -1.2249200784418546, 38.99272398723481, 60.0, 0.0, 0.0, 0.0, -6.336623839086697, 0.0, 0.0, 60.0, 0.0, -8.366238572676497, -1.379033977871027, 0.0, 0.0, 0.0, 0.0, 40.0, 20.0, 0.0, 0.0, -15.934183162324565, 0.0, -1.0859406497293655, -3.0886759122061447, 0.0, 0.0, 0.0, 40.0, 80.0, -9.769724293152949, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-2.4400415769491666, -20.65021136237236, -12.258427464378924, -15.509237224843169, 0.0, 0.0, -50.0, -30.0, 0.0, 0.0, -3.034096864171718, 0.0, 0.0, 0.0, -32.02568083967564, 0.0, -10.200256697059128, 0.0, -2.30684094680492, 0.0, 0.0, -1.5194939043920375, -40.0, -20.0, -41.244044949973635, 0.0, -10.0, -5.819379336166076, -2.0260179912193523, -40.0, 0.0, 0.0, -40.0, -20.0, -2.2075494381920766, 0.0, -20.0, -20.0, 0.0, 0.0, 0.0, -22.299554365871344, 0.0, 0.0, -12.392574047069042, 0.0, 0.0, 0.0, -2.0971513225434415, -76.88583803253054, -10.0, 0.0, -50.0, -50.98954098219791, 0.0, 0.0, 0.0, 0.0, -0.5417804376520596, -0.9141644473327604, -1.164092329608456, -9.419240124832427, 0.0, -1.0912257308115236, 0.0, 0.0, -8.217336607923574, -30.0, -10.43921785337099, -0.4698758179660856, 0.0, 0.0, -20.0, 0.0, -20.0, -9.510474284029154, -10.0, -18.23154672790499, -40.40901874977508, -30.0, -50.0, -0.09513768609263673, 0.0, -5.4966948232310475, 0.0, 0.0, -5.753310970800403, 0.0, -10.0, 0.0, -32.994364915328276, -0.613526656925667, 0.0, -20.0, 0.0, -2.3062737411962067, -20.0, -34.976949564791404, 0.0, -10.0, -0.9199938382971462, -0.6132003151186072, 0.0, -40.497390023542636, -59.57693794562218, -30.0, -30.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, -40.0, -0.33208979355587753, 0.0, 0.0, -9.149535191818655, -9.419182493626398, 0.0, 0.0, -1.2066544569972926, -12.206955192295238, 0.0, 0.0, -1.2249200784418546, -21.007276012765185, -30.0, 0.0, 0.0, 0.0, -6.336623839086697, 0.0, 0.0, -30.0, 0.0, -8.366238572676497, -1.379033977871027, 0.0, 0.0, 0.0, 0.0, -20.0, -10.0, 0.0, 0.0, -15.934183162324565, 0.0, -1.0859406497293655, -3.0886759122061447, 0.0, 0.0, 0.0, -20.0, -40.0, -9.769724293152949, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6971448810835762, "mean_inference_ms": 1.2146127839739662, "mean_action_processing_ms": 0.24186303996502917, "mean_env_wait_ms": 0.5169461177973435, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004932986702888635, "StateBufferConnector_ms": 0.003816747361687338, "ViewRequirementAgentConnector_ms": 0.10355445230083102}, "num_episodes": 157, "episode_return_max": 100.0, "episode_return_min": -41.244044949973635, "episode_return_mean": 13.43525653143241}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 284.19451474212326, "num_env_steps_trained_throughput_per_sec": 284.19451474212326, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 15165.275, "restore_workers_time_ms": 0.034, "training_step_time_ms": 15165.16, "sample_time_ms": 1308.691, "learn_time_ms": 13834.326, "learn_throughput": 289.136, "synch_weights_time_ms": 19.366}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-37-18", "timestamp": 1723138638, "time_this_iter_s": 14.099800825119019, "time_total_s": 76.07028198242188, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc970a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 76.07028198242188, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 42.265, "ram_util_percent": 82.16}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9127000636731585, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6317541881153983, "policy_loss": -0.013163926269529232, "vf_loss": 2.6430847174177567, "vf_explained_var": 0.00327494852244854, "kl": 0.009167017264375032, "entropy": 1.463400974497199, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6068827936412595, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5789476180752964, "policy_loss": -0.010291771958367437, "vf_loss": 1.5874151013844402, "vf_explained_var": 1.6771330901071534e-05, "kl": 0.009120890414417292, "entropy": 1.5191419197312483, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 15510.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -49.04734073919296, "episode_reward_mean": 11.096845166043657, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.962025316455696, "agent_policy": -9.789230783323429}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.6040619656676947, 0.0, 59.742079845032, 0.0, -2.11025682105726, 0.0, 0.0, 0.0, -49.04734073919296, -8.120115815843628, 20.0, 0.0, 0.0, 0.0, 120.0, 0.0, 0.0, 0.0, 0.0, -0.5503056764355962, 48.74771702776408, 0.0, -0.319159463336961, 0.0, 52.20488090473557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.68753062807803, 0.0, -28.17918698161165, 0.0, 0.0, -16.838532533982637, 0.0, -0.23665757043183633, -1.567244194160925, 0.0, 98.98847368083423, 74.73438631869311, 40.0, -6.712975618433402, 0.0, -0.5261701516969675, 13.926583246671331, 20.0, -9.15144248197026, 35.3124742904562, 7.784677187797062, 19.329671915298626, 0.0, -26.93317121234334, -11.202909656803609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.11647188491339278, 0.0, 0.0, -7.048698622037762, 0.0, 0.0, 0.0, 0.0, -2.94687973947765, -2.323971542903836, 60.0, 37.942869499178116, 0.0, -2.1097928764646348, 0.0, 80.0, 0.0, -29.39602797035225, 60.0, 20.0, 80.0, 0.0, -0.5286638419448009, 40.0, 0.0, 0.0, 40.0, 1.0759276491535068, 0.0, 19.875981411958385, 60.0, 0.0, -7.250128107585135, 0.0, 0.0, 0.0, 60.0, 0.0, -1.6526318328346246, 0.0, -33.93070890716112, -0.3875276234312419, -0.3106811546687138, -7.600380899198869, 0.0, 20.0, -5.146036884696152, 0.0, 80.0, 60.0, 60.0, 0.0, 58.808842516598204, -15.226511317404459, -3.886128072510412, 0.0, 60.0, 9.689293651619527, 0.0, 0.0, -1.3786038040981918, 54.24787019828793, 0.0, 40.0, -0.2984375880086376, 0.0, -3.8509210427917306, -0.07884639438423435, 100.0, 80.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 39.76070856323515, 19.534526452882012, 40.0, 0.0, 60.0, 0.0, 0.0, -2.865454681152775, 0.0, 40.0, 0.0, 0.0, -10.530906416057856, 10.906065750244519, -35.011776309136884, -0.3260951289650482, -2.6972109784703604], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-1.6040619656676947, 0.0, -30.257920154967998, 0.0, -2.11025682105726, 0.0, 0.0, 0.0, -49.04734073919296, -8.120115815843628, -10.0, 0.0, 0.0, 0.0, -60.0, 0.0, 0.0, 0.0, 0.0, -0.5503056764355962, -41.25228297223592, 0.0, -0.319159463336961, 0.0, -37.79511909526444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -39.31246937192197, 0.0, -28.17918698161165, 0.0, 0.0, -16.838532533982637, 0.0, -0.23665757043183633, -1.567244194160925, 0.0, -51.011526319165775, -45.265613681306874, -20.0, -6.712975618433402, 0.0, -0.5261701516969675, -16.073416753328676, -10.0, -9.15144248197026, -24.6875257095438, -22.21532281220294, -10.670328084701367, 0.0, -26.93317121234334, -11.202909656803609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.11647188491339278, 0.0, 0.0, -7.048698622037762, 0.0, 0.0, 0.0, 0.0, -2.94687973947765, -2.323971542903836, -30.0, -22.05713050082188, 0.0, -2.1097928764646348, 0.0, -40.0, 0.0, -29.39602797035225, -30.0, -10.0, -40.0, 0.0, -0.5286638419448009, -20.0, 0.0, 0.0, -20.0, -28.924072350846494, 0.0, -10.124018588041615, -30.0, 0.0, -7.250128107585135, 0.0, 0.0, 0.0, -30.0, 0.0, -1.6526318328346246, 0.0, -33.93070890716112, -0.3875276234312419, -0.3106811546687138, -7.600380899198869, 0.0, -10.0, -5.146036884696152, 0.0, -40.0, -30.0, -30.0, 0.0, -31.191157483401796, -15.226511317404459, -3.886128072510412, 0.0, -30.0, -20.310706348380478, 0.0, 0.0, -1.3786038040981918, -35.75212980171208, 0.0, -20.0, -0.2984375880086376, 0.0, -3.8509210427917306, -0.07884639438423435, -50.0, -40.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -20.23929143676485, -10.465473547117986, -20.0, 0.0, -30.0, 0.0, 0.0, -2.865454681152775, 0.0, -20.0, 0.0, 0.0, -10.530906416057856, -19.093934249755478, -35.011776309136884, -0.3260951289650482, -2.6972109784703604]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6844358259052595, "mean_inference_ms": 1.1911771961227895, "mean_action_processing_ms": 0.23805897666909387, "mean_env_wait_ms": 0.5098667680590845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004941677745384506, "StateBufferConnector_ms": 0.003125169609166399, "ViewRequirementAgentConnector_ms": 0.08761279190642925}, "num_episodes": 158, "episode_return_max": 120.0, "episode_return_min": -49.04734073919296, "episode_return_mean": 11.096845166043657}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 208.8626019724881, "num_env_steps_trained_throughput_per_sec": 208.8626019724881, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 15829.622, "restore_workers_time_ms": 0.03, "training_step_time_ms": 15829.52, "sample_time_ms": 1277.398, "learn_time_ms": 14530.93, "learn_throughput": 275.275, "synch_weights_time_ms": 18.792}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-37-38", "timestamp": 1723138658, "time_this_iter_s": 19.201385021209717, "time_total_s": 95.27166700363159, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc90d940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 95.27166700363159, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 63.5962962962963, "ram_util_percent": 81.84814814814814}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9228976141661406, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4421571190779408, "policy_loss": -0.014393187692136659, "vf_loss": 2.4545349859942993, "vf_explained_var": -0.000679711066186428, "kl": 0.0100765726543719, "entropy": 1.436413806055983, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6290627514111234, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5495412348644109, "policy_loss": -0.009908511197022725, "vf_loss": 1.557457921331656, "vf_explained_var": -2.0370014170382884e-05, "kl": 0.009958585306672341, "entropy": 1.5048778669631226, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 18330.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -32.01092923550872, "episode_reward_mean": 10.906749402373649, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.728395061728395, "agent_policy": -9.278435782811536}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.1877263021019335, 0.0, 0.0, 0.0, 0.0, 38.53883404189003, 0.0, 0.0, 0.0, -3.1037927700645693, -11.515339781868523, 0.0, 60.0, 40.0, 0.0, 0.0, 60.0, 0.0, 60.0, 0.0, -2.9392014709528738, 0.0, -10.745874255888092, 0.0, 20.0, -21.452270614250022, 56.71525062977621, 60.0, 0.0, 60.0, -2.7334774578530086, 100.0, 0.0, 20.0, 39.728868599976664, -12.027360770204286, -21.43497409184163, 0.0, 0.0, 0.0, 0.0, 39.37562180199096, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, -4.55073048569121, 40.0, 60.0, -2.7923181703246884, 0.0, -26.544866998604455, 0.0, 79.95214190490171, 60.0, 0.0, 80.0, -1.7802678067602118, -5.232784644579816, 0.0, 0.0, 58.59369674559727, 0.0, 20.0, 80.0, 0.0, -2.9909186294206975, -0.3190451803871619, 0.0, 0.0, 0.0, 40.0, -11.433478165713165, 40.0, 0.0, 0.0, 0.0, -11.672214404491095, 0.0, 0.0, 0.0, 0.0, 40.0, -0.3158704677061863, 0.0, 80.0, -2.544141619381496, -0.2662546524717835, 58.08265213017154, 31.411748251747802, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -18.728279697673333, -32.01092923550872, 38.87904363624328, 0.0, 0.0, -0.16941582111192566, 0.0, 120.0, -3.0672789528258715, 0.0, 0.0, 0.0, -1.9864918769087458, 20.0, 0.0, 60.0, 0.0, 20.0, 0.0, 34.067552731189735, -31.893596719013324, 0.0, 0.0, -23.834668652040076, -0.09511323630746249, 0.0, -25.493986830387414, 0.0, -4.089096359275398, -2.576706439243546, 0.0, 0.0, -12.50512715328297, -5.71532223965078, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, 19.536575011184045, -1.053426767417458, 0.0, 0.0, 0.0, 40.0, 0.0, -0.09344053139386355, 0.0, 0.0, 60.0, 0.0, 0.0, -7.09279304754031], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-1.1877263021019335, 0.0, 0.0, 0.0, 0.0, -51.46116595810997, 0.0, 0.0, 0.0, -3.1037927700645693, -11.515339781868523, 0.0, -30.0, -20.0, 0.0, 0.0, -30.0, 0.0, -30.0, 0.0, -2.9392014709528738, 0.0, -10.745874255888092, 0.0, -10.0, -21.452270614250022, -33.28474937022379, -30.0, 0.0, -30.0, -2.7334774578530086, -50.0, 0.0, -10.0, -20.271131400023336, -42.0273607702043, -21.43497409184163, 0.0, 0.0, 0.0, 0.0, -20.62437819800904, 0.0, 0.0, 0.0, 0.0, 0.0, -60.0, -4.55073048569121, -20.0, -30.0, -2.7923181703246884, 0.0, -26.544866998604455, 0.0, -40.0478580950983, -30.0, 0.0, -40.0, -1.7802678067602118, -5.232784644579816, 0.0, 0.0, -31.406303254402737, 0.0, -10.0, -40.0, 0.0, -2.9909186294206975, -0.3190451803871619, 0.0, 0.0, 0.0, -20.0, -11.433478165713165, -20.0, 0.0, 0.0, 0.0, -11.672214404491095, 0.0, 0.0, 0.0, 0.0, -20.0, -0.3158704677061863, 0.0, -40.0, -2.544141619381496, -0.2662546524717835, -31.91734786982847, -58.5882517482522, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -18.728279697673333, -32.01092923550872, -21.12095636375672, 0.0, 0.0, -0.16941582111192566, 0.0, -60.0, -3.0672789528258715, 0.0, 0.0, 0.0, -1.9864918769087458, -10.0, 0.0, -30.0, 0.0, -10.0, 0.0, -25.932447268810257, -31.893596719013324, 0.0, 0.0, -23.834668652040076, -0.09511323630746249, 0.0, -25.493986830387414, 0.0, -4.089096359275398, -2.576706439243546, 0.0, 0.0, -12.50512715328297, -5.71532223965078, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, -10.463424988815955, -1.053426767417458, 0.0, 0.0, 0.0, -20.0, 0.0, -0.09344053139386355, 0.0, 0.0, -30.0, 0.0, 0.0, -7.09279304754031]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6922518105569347, "mean_inference_ms": 1.2017858379594513, "mean_action_processing_ms": 0.24093170405592332, "mean_env_wait_ms": 0.5146040117305042, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0056410277331316915, "StateBufferConnector_ms": 0.0034010704652762706, "ViewRequirementAgentConnector_ms": 0.10645235026324237}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -32.01092923550872, "episode_return_mean": 10.906749402373649}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 177.06768210760282, "num_env_steps_trained_throughput_per_sec": 177.06768210760282, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 16795.425, "restore_workers_time_ms": 0.028, "training_step_time_ms": 16795.33, "sample_time_ms": 1316.563, "learn_time_ms": 15456.929, "learn_throughput": 258.784, "synch_weights_time_ms": 19.244}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-38-00", "timestamp": 1723138680, "time_this_iter_s": 22.63684582710266, "time_total_s": 117.90851283073425, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d12f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 117.90851283073425, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 66.56875, "ram_util_percent": 82.00625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9776697625095646, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.099739184292654, "policy_loss": -0.012180645511640857, "vf_loss": 2.1100391533225773, "vf_explained_var": 0.011685715119043986, "kl": 0.00940339165094158, "entropy": 1.4159528159846861, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6431729081568989, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2267743981687735, "policy_loss": -0.009934111972461647, "vf_loss": 1.2349291338565502, "vf_explained_var": 2.594444345920644e-05, "kl": 0.00889645489021631, "entropy": 1.4961478186414596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 21150.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 137.8088002023685, "episode_reward_min": -35.4677577242063, "episode_reward_mean": 8.71277970978445, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.1911997976315}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.493827160493828, "agent_policy": -7.768701771697032}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 40.0, -35.4677577242063, 137.8088002023685, 0.0, -1.8992112336411215, 20.0, 0.0, 0.0, 0.0, 0.0, 39.831282217470736, 0.0, 0.0, 59.396258596607964, -0.22865390753891046, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.348384409595287, -5.3581546139705845, 0.0, 20.0, 20.0, 0.0, 35.245675958293596, 0.0, -1.594207108259701, 0.0, 20.0, 0.0, 38.24650116203355, 20.0, 0.0, 0.0, 0.0, 0.0, 56.18370060835758, 0.0, 0.0, -1.0705615349691278, 0.0, 0.0, 80.0, 59.386254736673095, 0.0, 0.0, 111.6537243651559, 20.0, 0.0, -11.16181290717035, 0.0, -5.501387855471337, -3.2637659381399624, 0.0, 0.0, -0.06857793942143808, -29.263528296894147, -17.122409217042474, 0.0, -19.568542296500297, 0.0, 0.0, 0.0, 0.0, 0.0, -7.477874410986185, -18.32502249570464, 0.0, 50.8726077901436, -0.06103979243952895, 0.0, 20.0, -6.25241753072451, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, -0.36385223559055935, 56.87495010525482, 0.0, 0.0, -3.4710856761837983, 0.0, 0.0, -6.711059351132072, 0.0, 80.0, 0.0, 0.0, 19.093299087908953, 0.0, 0.0, 0.0, -0.9352502957974373, 60.0, 0.0, 0.0, -1.283611364868148, 0.0, 0.0, 0.0, 40.0, -1.9124131119540966, 0.0, 0.0, 0.0, -5.171003373403042, -7.127408117972099, 20.0, 0.0, 60.0, 20.0, 0.0, -0.4200375270846224, -1.0363053993256655, 0.0, -6.238778506527531, -1.373575943052281, -7.322045931561828, 0.0, 0.0, -22.626929422373056, -0.7479306151485865, 0.0, 0.0, 0.0, 60.0, 18.94933939770005, 20.0, -13.883056344149427, -17.93470891464862, -0.15978405422046205, 0.0, -27.923132270138794, 0.0, 100.0, 60.0, -0.4559969099733885, -6.651296958494078, 60.0, 0.0, -6.513503573055062, -1.8028416306954798, -1.2415495656169506, 0.0, 18.92645262275434, -0.23204063397306407, -0.4260269260257987], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -20.0, -35.4677577242063, -72.1911997976315, 0.0, -1.8992112336411215, -10.0, 0.0, 0.0, 0.0, 0.0, -20.168717782529264, 0.0, 0.0, -30.603741403392043, -0.22865390753891046, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.348384409595287, -5.3581546139705845, 0.0, -10.0, -10.0, 0.0, -24.7543240417064, 0.0, -1.594207108259701, 0.0, -10.0, 0.0, -21.753498837966447, -10.0, 0.0, 0.0, 0.0, 0.0, -63.81629939164241, 0.0, 0.0, -1.0705615349691278, 0.0, 0.0, -40.0, -30.613745263326898, 0.0, 0.0, -68.34627563484413, -10.0, 0.0, -11.16181290717035, 0.0, -5.501387855471337, -3.2637659381399624, 0.0, 0.0, -0.06857793942143808, -29.263528296894147, -17.122409217042474, 0.0, -19.568542296500297, 0.0, 0.0, 0.0, 0.0, 0.0, -7.477874410986185, -18.32502249570464, 0.0, -39.1273922098564, -0.06103979243952895, 0.0, -10.0, -6.25241753072451, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -0.36385223559055935, -33.12504989474518, 0.0, 0.0, -3.4710856761837983, 0.0, 0.0, -6.711059351132072, 0.0, -40.0, 0.0, 0.0, -10.906700912091047, 0.0, 0.0, 0.0, -0.9352502957974373, -30.0, 0.0, 0.0, -1.283611364868148, 0.0, 0.0, 0.0, -20.0, -1.9124131119540966, 0.0, 0.0, 0.0, -5.171003373403042, -7.127408117972099, -10.0, 0.0, -30.0, -10.0, 0.0, -0.4200375270846224, -1.0363053993256655, 0.0, -6.238778506527531, -1.373575943052281, -7.322045931561828, 0.0, 0.0, -22.626929422373056, -0.7479306151485865, 0.0, 0.0, 0.0, -30.0, -11.05066060229995, -10.0, -13.883056344149427, -17.93470891464862, -0.15978405422046205, 0.0, -27.923132270138794, 0.0, -50.0, -30.0, -0.4559969099733885, -6.651296958494078, -30.0, 0.0, -6.513503573055062, -1.8028416306954798, -1.2415495656169506, 0.0, -11.07354737724566, -0.23204063397306407, -0.4260269260257987]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6956439073211699, "mean_inference_ms": 1.212206726213117, "mean_action_processing_ms": 0.24167196910263533, "mean_env_wait_ms": 0.5180543278100483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005727417675065406, "StateBufferConnector_ms": 0.0035616350762638044, "ViewRequirementAgentConnector_ms": 0.09841631959985804}, "num_episodes": 162, "episode_return_max": 137.8088002023685, "episode_return_min": -35.4677577242063, "episode_return_mean": 8.71277970978445}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.006087709376, "num_env_steps_trained_throughput_per_sec": 157.006087709376, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 17880.588, "restore_workers_time_ms": 0.026, "training_step_time_ms": 17880.5, "sample_time_ms": 1323.038, "learn_time_ms": 16535.042, "learn_throughput": 241.91, "synch_weights_time_ms": 19.896}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-38-26", "timestamp": 1723138706, "time_this_iter_s": 25.492136001586914, "time_total_s": 143.40064883232117, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9ef0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 143.40064883232117, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 71.1111111111111, "ram_util_percent": 82.35833333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9437391860721012, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.631659396365285, "policy_loss": -0.01589026720757829, "vf_loss": 2.645436475177606, "vf_explained_var": 0.014250820005933444, "kl": 0.010565970153335276, "entropy": 1.3957519900053739, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6620043455603275, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.822894627215169, "policy_loss": -0.011573870348205777, "vf_loss": 1.832539160623618, "vf_explained_var": 1.560081826879623e-05, "kl": 0.009646186054590404, "entropy": 1.4880459037232907, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 23970.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -42.889828221131964, "episode_reward_mean": 14.15070857745332, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.3318400865413}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.089171974522293, "agent_policy": -10.116807346113559}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 20.0, 40.0, 40.0, 77.6681599134587, 0.0, -3.883233274470393, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -6.644430182285857, -1.8817199043597965, 60.0, 0.0, 0.0, -0.7569944513589821, 56.3619777625141, 0.0, 60.0, -0.06447022322214169, 80.0, 59.298145212335825, 0.0, 19.6412476017733, 0.0, -7.811147466993492, 0.0, 20.0, 60.0, 19.62966253482427, 0.0, -5.1289748706880465, 0.0, -0.07367824069619, 0.0, -12.997082847057563, -10.556720735187607, 40.0, -3.7300077168631267, 0.0, 0.0, 80.0, 0.0, 0.0, 0.0, 39.86345134565787, 0.0, 0.0, 100.0, 0.0, 20.0, 60.0, 60.0, -2.4703580916062453, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 0.0, 0.0, 20.0, 0.0, 0.0, -2.048895367942769, 19.246225056551104, 0.0, -3.0984729200771666, -4.482811238574378, 0.0, 20.0, 28.495028607077856, 40.0, 0.0, 0.0, 40.0, -15.19580060889245, -0.4918194838884504, -0.19630738383580426, 0.0, -42.889828221131964, -16.272623982457684, -1.2791816473334339, 80.0, 40.0, 0.0, 60.0, 50.554391570102744, -5.251363251675217, -21.028694479602226, -1.6267939378309004, 40.0, -7.995482267310271, 0.0, 59.8228642638978, 0.0, 40.0, -0.0777249730670515, 0.0, 0.0, -2.2399918051083274, 40.0, 60.0, 0.0, 0.0, 60.0, -20.22739627010383, 0.0, 0.0, 0.0, 60.0, -1.258718699794792, 0.0, 0.0, 60.0, 20.0, 0.0, -0.7091209503120943, -12.226118767115851, -11.198186285923766, 120.0, 0.0, 0.0, -1.3194211803501876, 60.0, 0.0, -0.3319503657130052, -0.8093361617649464, 0.0, 0.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, -14.848419895595406, 18.60663510890293, 60.0, 0.0, -0.6616189921047066, 0.0, 36.358010247131986, 0.0, 0.0, 0.0, 0.0, -0.11965542176114008, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -10.0, -20.0, -20.0, -72.3318400865413, 0.0, -3.883233274470393, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -6.644430182285857, -1.8817199043597965, -30.0, 0.0, 0.0, -0.7569944513589821, -33.638022237485906, 0.0, -30.0, -0.06447022322214169, -40.0, -30.701854787664175, 0.0, -10.358752398226699, 0.0, -7.811147466993492, 0.0, -10.0, -30.0, -10.37033746517573, 0.0, -5.1289748706880465, 0.0, -0.07367824069619, 0.0, -12.997082847057563, -10.556720735187607, -20.0, -3.7300077168631267, 0.0, 0.0, -40.0, 0.0, 0.0, 0.0, -20.13654865434213, 0.0, 0.0, -50.0, 0.0, -10.0, -30.0, -30.0, -2.4703580916062453, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -20.0, 0.0, 0.0, -10.0, 0.0, 0.0, -2.048895367942769, -10.753774943448896, 0.0, -3.0984729200771666, -4.482811238574378, 0.0, -10.0, -31.504971392922137, -20.0, 0.0, 0.0, -20.0, -15.19580060889245, -0.4918194838884504, -0.19630738383580426, 0.0, -42.889828221131964, -16.272623982457684, -1.2791816473334339, -40.0, -20.0, 0.0, -30.0, -39.445608429897256, -5.251363251675217, -21.028694479602226, -1.6267939378309004, -20.0, -7.995482267310271, 0.0, -30.177135736102198, 0.0, -20.0, -0.0777249730670515, 0.0, 0.0, -2.2399918051083274, -20.0, -30.0, 0.0, 0.0, -30.0, -20.22739627010383, 0.0, 0.0, 0.0, -30.0, -1.258718699794792, 0.0, 0.0, -30.0, -10.0, 0.0, -0.7091209503120943, -12.226118767115851, -11.198186285923766, -60.0, 0.0, 0.0, -1.3194211803501876, -30.0, 0.0, -0.3319503657130052, -0.8093361617649464, 0.0, 0.0, -30.0, -30.0, 0.0, 0.0, 0.0, 0.0, -14.848419895595406, -11.393364891097074, -30.0, 0.0, -0.6616189921047066, 0.0, -53.64198975286801, 0.0, 0.0, 0.0, 0.0, -0.11965542176114008, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.70092389617499, "mean_inference_ms": 1.2211610694929298, "mean_action_processing_ms": 0.24332540778840298, "mean_env_wait_ms": 0.5223572047266716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006182634147109499, "StateBufferConnector_ms": 0.003455778595748221, "ViewRequirementAgentConnector_ms": 0.10978841477898275}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -42.889828221131964, "episode_return_mean": 14.15070857745332}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 160.69264929047594, "num_env_steps_trained_throughput_per_sec": 160.69264929047594, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 18659.662, "restore_workers_time_ms": 0.025, "training_step_time_ms": 18659.577, "sample_time_ms": 1363.403, "learn_time_ms": 17273.659, "learn_throughput": 231.566, "synch_weights_time_ms": 20.126}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-38-51", "timestamp": 1723138731, "time_this_iter_s": 24.90482997894287, "time_total_s": 168.30547881126404, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d284c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 168.30547881126404, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 70.42857142857143, "ram_util_percent": 82.43714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0007615217318138, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1968644694114725, "policy_loss": -0.013975548686479064, "vf_loss": 2.20899774475644, "vf_explained_var": 0.006648966483771801, "kl": 0.009211407484044809, "entropy": 1.3640500561644633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.674925463049547, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6052611766554785, "policy_loss": -0.011737406795187226, "vf_loss": 1.61518358932742, "vf_explained_var": -2.7959017043418075e-06, "kl": 0.009074533665605922, "entropy": 1.4682090262994698, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 26790.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -28.855772067877993, "episode_reward_mean": 10.358768342398598, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.925925925925926, "agent_policy": -7.419009435379181}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -3.271275158765297, 0.0, 10.910776205789448, 0.0, 0.0, -1.2542629221298685, 38.88756265481615, 0.0, 0.0, 0.0, 16.5087726175793, 60.0, 0.0, -4.443925248915831, 0.0, 0.0, 40.0, 40.0, 0.0, 0.0, 60.0, 58.947678492597504, 0.0, 0.0, 0.0, 40.0, 0.0, 17.329018511835077, 0.0, 59.76645308911952, 0.0, 0.0, 0.0, 0.0, -3.0685413353631006, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 40.0, -13.374719736495347, 100.0, 60.0, 0.0, 60.0, 0.0, 0.0, 31.530873252890153, 20.0, 0.0, -23.964216008282655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.1816019496676367, 0.0, 60.0, 0.0, 20.0, -6.865821795015687, 40.0, 0.0, 0.0, 20.0, 40.0, 60.0, 11.049035050589287, -1.6895709467844389, 0.0, -1.4227187088758975, -1.9748070324701117, 0.0, -0.027182249047220663, 20.0, -1.1975057012393342, -0.13029516661538287, 40.0, 0.0, 0.0, 0.0, -2.3950868732368122, -0.9242526447332211, 0.0, 0.0, -28.855772067877993, 20.0, -4.094034263559137, 19.30431191074528, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, 40.0, 0.0, -2.1853686616609975, 0.0, 0.0, 60.0, 0.0, -4.063126330761694, 0.0, -1.522152239540513, 0.0, -0.33376743259588837, 0.0, 60.0, -3.543630568009191, 40.0, -2.4968073654225975, -1.1539699959525263, 0.0, 0.0, 60.0, -0.8704538584437571, 40.0, 20.0, -15.335403512718987, 39.98199991604015, 0.0, 20.0, -14.465514942510222, -0.8592658973629896, 35.94121161672242, 0.0, 0.0, 20.0, 40.0, -1.5892762482645595, 59.482383502769665, 0.0, -2.143807646730511, -0.12207943102033436, 0.0, 0.0, 40.0, 0.0, 48.09619806217429, -2.824441884711553, 0.0, -7.327154422916026, -3.475709792348976, 0.0, -5.168283375049158, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -3.271275158765297, 0.0, -19.08922379421055, 0.0, 0.0, -1.2542629221298685, -21.11243734518385, 0.0, 0.0, 0.0, -13.4912273824207, -30.0, 0.0, -4.443925248915831, 0.0, 0.0, -20.0, -20.0, 0.0, 0.0, -30.0, -31.05232150740249, 0.0, 0.0, 0.0, -20.0, 0.0, -42.67098148816493, 0.0, -30.23354691088047, 0.0, 0.0, 0.0, 0.0, -3.0685413353631006, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -20.0, -13.374719736495347, -50.0, -30.0, 0.0, -30.0, 0.0, 0.0, -28.469126747109847, -10.0, 0.0, -23.964216008282655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.1816019496676367, 0.0, -30.0, 0.0, -10.0, -6.865821795015687, -20.0, 0.0, 0.0, -10.0, -20.0, -30.0, -18.950964949410718, -1.6895709467844389, 0.0, -1.4227187088758975, -1.9748070324701117, 0.0, -0.027182249047220663, -10.0, -1.1975057012393342, -0.13029516661538287, -20.0, 0.0, 0.0, 0.0, -2.3950868732368122, -0.9242526447332211, 0.0, 0.0, -28.855772067877993, -10.0, -4.094034263559137, -10.695688089254721, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -10.0, -30.0, 0.0, -20.0, 0.0, -2.1853686616609975, 0.0, 0.0, -30.0, 0.0, -4.063126330761694, 0.0, -1.522152239540513, 0.0, -0.33376743259588837, 0.0, -30.0, -3.543630568009191, -20.0, -2.4968073654225975, -1.1539699959525263, 0.0, 0.0, -30.0, -0.8704538584437571, -20.0, -10.0, -15.335403512718987, -20.018000083959848, 0.0, -10.0, -14.465514942510222, -0.8592658973629896, -24.05878838327758, 0.0, 0.0, -10.0, -20.0, -1.5892762482645595, -30.517616497230335, 0.0, -2.143807646730511, -0.12207943102033436, 0.0, 0.0, -20.0, 0.0, -41.90380193782572, -2.824441884711553, 0.0, -7.327154422916026, -3.475709792348976, 0.0, -5.168283375049158, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7029387713279535, "mean_inference_ms": 1.2278429936698634, "mean_action_processing_ms": 0.24415171000732183, "mean_env_wait_ms": 0.5252374559185486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004969261310718677, "StateBufferConnector_ms": 0.003595778971542547, "ViewRequirementAgentConnector_ms": 0.10984238283133801}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -28.855772067877993, "episode_return_mean": 10.358768342398598}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 181.53718825336097, "num_env_steps_trained_throughput_per_sec": 181.53718825336097, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 18997.102, "restore_workers_time_ms": 0.024, "training_step_time_ms": 18997.022, "sample_time_ms": 1363.528, "learn_time_ms": 17611.508, "learn_throughput": 227.124, "synch_weights_time_ms": 19.801}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-39-13", "timestamp": 1723138753, "time_this_iter_s": 22.047385215759277, "time_total_s": 190.35286402702332, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d12280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 190.35286402702332, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 64.85483870967742, "ram_util_percent": 81.90967741935482}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8941252778905133, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2945708136074243, "policy_loss": -0.015600214315297005, "vf_loss": 2.308280627553662, "vf_explained_var": 0.0010432864228884378, "kl": 0.00945200369695021, "entropy": 1.3429379546393951, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6910316333914479, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7812363675300111, "policy_loss": -0.013082052469798463, "vf_loss": 1.7922853900397078, "vf_explained_var": 7.562117373689692e-06, "kl": 0.010164718770133708, "entropy": 1.4402359338516886, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 29610.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 119.93918507298605, "episode_reward_min": -34.301578057034796, "episode_reward_mean": 14.297832590765642, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.060814927013936}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.784810126582278, "agent_policy": -9.056597788981191}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 53.375434670510025, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -0.3350535678716271, -4.370809984328009, 0.0, 40.0, 20.0, 0.0, 32.11795553332022, 39.429168837746325, 0.0, 40.0, -0.8212720631258663, 18.069263337701926, 0.0, 60.0, 60.0, 0.0, 0.0, 20.0, 0.0, 0.0, -0.07654109980176904, 60.0, -1.3405636724628445, -34.301578057034796, 80.0, 35.04775316073619, 0.0, -22.76716902819483, 20.0, 60.0, -1.1130254203916434, 0.0, 59.759701433027885, 0.0, 0.0, -8.623285293523121, 0.0, 0.0, 0.0, 0.0, 0.0, -4.695668070677127, 0.0, 0.0, 0.0, 48.97052617904584, -1.6820057917178732, 100.0, -2.5385273284376684, 20.0, 0.0, 60.0, 0.0, 40.0, 80.0, 80.0, 0.0, -0.22225108730954513, 0.0, 40.0, 40.0, 0.0, 40.0, 60.0, 20.0, -1.1588283139758915, -0.30901448092907957, 0.0, 0.0, 0.0, 0.0, 0.0, -6.5250065439776455, 60.0, 0.0, 0.0, 40.0, -29.097475722438414, 119.93918507298605, 40.0, 0.0, 0.0, -0.16712287459467956, 0.0, 100.0, -0.12487570172851625, 0.0, 40.0, 0.0, 0.0, 20.0, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -10.038719487329601, -2.8569961347054003, 0.0, -1.2055650365473691, 0.0, 40.0, 0.0, 0.0, -13.677106653661435, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, 80.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, 20.0, 20.0, 0.0, 60.0, -5.78322047901438, 0.0, -1.3679951110174626, -2.31427143374503, 20.0, -1.25407247594578, 0.0, -5.586258231570846, -1.138192054069903, 0.0, 100.0, 0.0, 20.0, -2.1589676839746224, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -36.624565329489975, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -0.3350535678716271, -4.370809984328009, 0.0, -20.0, -10.0, 0.0, -27.882044466679766, -20.570831162253675, 0.0, -20.0, -0.8212720631258663, -11.930736662298076, 0.0, -30.0, -30.0, 0.0, 0.0, -10.0, 0.0, 0.0, -0.07654109980176904, -30.0, -1.3405636724628445, -34.301578057034796, -40.0, -24.952246839263807, 0.0, -22.76716902819483, -10.0, -30.0, -1.1130254203916434, 0.0, -30.24029856697211, 0.0, 0.0, -8.623285293523121, 0.0, 0.0, 0.0, 0.0, 0.0, -4.695668070677127, 0.0, 0.0, 0.0, -41.02947382095416, -1.6820057917178732, -50.0, -2.5385273284376684, -10.0, 0.0, -30.0, 0.0, -20.0, -40.0, -40.0, 0.0, -0.22225108730954513, 0.0, -20.0, -20.0, 0.0, -20.0, -30.0, -10.0, -1.1588283139758915, -0.30901448092907957, 0.0, 0.0, 0.0, 0.0, 0.0, -6.5250065439776455, -30.0, 0.0, 0.0, -20.0, -29.097475722438414, -60.060814927013936, -20.0, 0.0, 0.0, -0.16712287459467956, 0.0, -50.0, -0.12487570172851625, 0.0, -20.0, 0.0, 0.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -10.038719487329601, -2.8569961347054003, 0.0, -1.2055650365473691, 0.0, -20.0, 0.0, 0.0, -13.677106653661435, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, -40.0, -20.0, -20.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, -10.0, -10.0, 0.0, -30.0, -5.78322047901438, 0.0, -1.3679951110174626, -2.31427143374503, -10.0, -1.25407247594578, 0.0, -5.586258231570846, -1.138192054069903, 0.0, -50.0, 0.0, -10.0, -2.1589676839746224, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7071089767121888, "mean_inference_ms": 1.2322886038990697, "mean_action_processing_ms": 0.2454879477943376, "mean_env_wait_ms": 0.5284896807772603, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005715406393703026, "StateBufferConnector_ms": 0.004242718974246254, "ViewRequirementAgentConnector_ms": 0.10856261736230005}, "num_episodes": 158, "episode_return_max": 119.93918507298605, "episode_return_min": -34.301578057034796, "episode_return_mean": 14.297832590765642}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 178.55052871805722, "num_env_steps_trained_throughput_per_sec": 178.55052871805722, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 19904.51, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19904.45, "sample_time_ms": 1376.855, "learn_time_ms": 18504.353, "learn_throughput": 216.165, "synch_weights_time_ms": 20.868}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-39-35", "timestamp": 1723138775, "time_this_iter_s": 22.42258906364441, "time_total_s": 212.77545309066772, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc92e430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 212.77545309066772, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 65.7625, "ram_util_percent": 82.69062500000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8822715977827708, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.238555512391031, "policy_loss": -0.014560935259699667, "vf_loss": 2.251026751101017, "vf_explained_var": 0.0011520129318038622, "kl": 0.010448461338720237, "entropy": 1.3362455622603495, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7039921592736075, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7013989324476702, "policy_loss": -0.010288637288984784, "vf_loss": 1.7101525625227192, "vf_explained_var": 1.240469885210619e-05, "kl": 0.007674562724068444, "entropy": 1.4226714039102513, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 32430.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -29.260186815262156, "episode_reward_mean": 13.472359211990284, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.530864197530864, "agent_policy": -9.120233380602308}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 20.0, -3.097470068039491, -19.57197517027551, 0.0, 0.0, 0.0, 0.0, -0.2918937352870865, 80.0, 0.0, 58.57809735260162, 0.0, 20.0, 0.0, 23.24387780617335, 0.0, 0.0, 40.0, 0.0, -0.6624082118443042, -3.5271569576994173, 3.186196470962279, 58.954469277834306, 60.0, 0.0, -6.379447569890473, 0.0, 39.07721686794741, -9.118268777779406, 80.0, -1.1664768847979012, 80.0, 15.026858047646122, -1.2338933659847673, 60.0, 17.57576942998866, 0.0, 16.069218186285052, 40.0, 60.0, 0.0, 20.0, 0.0, 59.228901083859654, 0.0, 80.0, -29.260186815262156, -4.653425516669506, 8.082116877455064, -2.0895187422954766, 40.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.38045021483351316, 60.0, 0.0, 0.0, -7.480617502400358, 39.3669412540263, 0.0, 60.0, 0.0, 40.0, 0.0, 60.0, 0.0, -0.8126114516649108, 0.0, 0.0, 60.0, 0.0, 0.0, -15.64211355970274, -2.697186900084495, 60.0, 40.0, 0.0, -0.7977477241018982, 0.0, 0.0, 0.0, -0.014833932240496672, 100.0, 0.0, 0.0, 40.0, 0.0, -2.039244684089941, 0.0, -0.7739209814825332, 0.0, -0.3253475062435107, 0.0, -4.169515715306274, 0.0, 60.0, 0.0, -27.622415043755097, 0.0, 44.24004210555214, 0.0, 40.0, 56.655816506392384, 0.0, 0.0, -10.164324114797568, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, -10.18796352998412, 60.0, 0.0, 0.0, -0.3648294993547585, 40.0, 0.0, 0.0, 40.0, 0.0, 40.0, 0.0, 20.0, 0.0, -6.791994229684298, 80.0, 0.0, 0.0, 60.0, 40.0, -0.36300056931494074, 0.0, 0.0, -1.1197186960196548, -1.439455304879983, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, -1.5853575681310617, -0.9385583804006237, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -10.0, -3.097470068039491, -19.57197517027551, 0.0, 0.0, 0.0, 0.0, -0.2918937352870865, -40.0, 0.0, -31.421902647398383, 0.0, -10.0, 0.0, -36.756122193826656, 0.0, 0.0, -20.0, 0.0, -0.6624082118443042, -3.5271569576994173, -26.81380352903772, -31.045530722165687, -30.0, 0.0, -6.379447569890473, 0.0, -20.922783132052583, -9.118268777779406, -40.0, -1.1664768847979012, -40.0, -14.973141952353878, -1.2338933659847673, -30.0, -12.424230570011337, 0.0, -13.930781813714948, -20.0, -30.0, 0.0, -10.0, 0.0, -30.771098916140353, 0.0, -40.0, -29.260186815262156, -4.653425516669506, -21.917883122544936, -2.0895187422954766, -20.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.38045021483351316, -30.0, 0.0, 0.0, -7.480617502400358, -20.6330587459737, 0.0, -30.0, 0.0, -20.0, 0.0, -30.0, 0.0, -0.8126114516649108, 0.0, 0.0, -30.0, 0.0, 0.0, -15.64211355970274, -2.697186900084495, -30.0, -20.0, 0.0, -0.7977477241018982, 0.0, 0.0, 0.0, -0.014833932240496672, -50.0, 0.0, 0.0, -20.0, 0.0, -2.039244684089941, 0.0, -0.7739209814825332, 0.0, -0.3253475062435107, 0.0, -4.169515715306274, 0.0, -30.0, 0.0, -27.622415043755097, 0.0, -45.75995789444785, 0.0, -20.0, -33.344183493607616, 0.0, 0.0, -10.164324114797568, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, -10.18796352998412, -30.0, 0.0, 0.0, -0.3648294993547585, -20.0, 0.0, 0.0, -20.0, 0.0, -20.0, 0.0, -10.0, 0.0, -6.791994229684298, -40.0, 0.0, 0.0, -30.0, -20.0, -0.36300056931494074, 0.0, 0.0, -1.1197186960196548, -1.439455304879983, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -1.5853575681310617, -0.9385583804006237, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.711330922212195, "mean_inference_ms": 1.2334536154503513, "mean_action_processing_ms": 0.24570514318410025, "mean_env_wait_ms": 0.5284474902561026, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005840519328176239, "StateBufferConnector_ms": 0.0038046895721812308, "ViewRequirementAgentConnector_ms": 0.10452491265756113}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -29.260186815262156, "episode_return_mean": 13.472359211990284}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 188.60801778920455, "num_env_steps_trained_throughput_per_sec": 188.60801778920455, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 20021.572, "restore_workers_time_ms": 0.015, "training_step_time_ms": 20021.511, "sample_time_ms": 1386.591, "learn_time_ms": 18613.905, "learn_throughput": 214.893, "synch_weights_time_ms": 18.957}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-39-56", "timestamp": 1723138796, "time_this_iter_s": 21.24900197982788, "time_total_s": 234.0244550704956, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d20310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 234.0244550704956, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 64.24666666666667, "ram_util_percent": 82.06666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0249862790728608, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2284151171023647, "policy_loss": -0.013430878053380486, "vf_loss": 2.239729455113411, "vf_explained_var": 0.0037203246727585794, "kl": 0.010582717557802601, "entropy": 1.334456030279398, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7196885009395315, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6686687600739458, "policy_loss": -0.013105497507672387, "vf_loss": 1.6798537252642585, "vf_explained_var": 5.140308792709459e-06, "kl": 0.009602277766515998, "entropy": 1.4004310191945826, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 35250.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 177.37172418732587, "episode_reward_min": -21.987805981294393, "episode_reward_mean": 13.873665628194361, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -92.62827581267413}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.515923566878981, "agent_policy": -8.67410507244258}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 40.0, -15.277310265869055, 58.49155038458417, 0.0, 20.0, 0.0, 80.0, 0.0, 0.0, -0.19005842410389717, 0.0, -0.007856060855433444, -0.36692403614411173, 20.0, -0.38546397683720923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, -3.7973086272318244, 76.86441972825222, 0.0, 0.0, 40.0, -2.3220379430437452, -1.7237713997157622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0267944591608347, -2.1177365564488992, 0.0, 60.0, 0.0, 40.0, 0.0, 0.0, 0.0, -1.6894216142189489, 0.0, 0.0, 40.0, -21.987805981294393, 0.0, 0.0, 0.0, 0.0, -2.0997118013175498, 60.0, -3.279484853993968, 0.0, 40.0, 56.67227412417426, -1.591766053427458, 0.0, -3.897776824231541, 177.37172418732587, 20.0, 0.0, 0.0, -1.1867665599705046, -7.988439768157011, -0.980345280498407, 0.0, 80.0, -1.1142624880879748, 0.0, 20.0, 60.0, -1.3288727996591054, 0.0, 0.0, -7.833498934436507, -0.07712625730378231, 60.0, 20.0, 57.25783591468527, 0.0, 0.0, 79.32578881689628, -10.429082700386443, 0.0, -0.4666090945988943, 0.0, 0.0, 15.657118919845194, -12.380821559315061, 0.0, -0.0652913337957739, -4.107719202127399, 0.0, -6.327310648099986, 0.0, 0.0, 60.0, 0.0, 20.0, 0.0, 0.0, 20.0, 0.0, 140.0, -1.356056891461257, 0.0, 0.0, 29.91416523785999, 0.0, -1.8049769937130644, 80.0, -0.8328512325000104, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 20.0, 0.0, 0.0, -0.510422289286141, -0.03845840965204128, -1.399212922590326, 0.0, 0.0, 98.67822461119121, 100.0, -0.17783086309574148, -3.9700931529706462, 40.0, 0.0, 0.0, 40.0, 0.0, 40.0, 0.0, 0.0, 80.0, 60.0, 0.0, -0.45864454150081224, -2.143237181289946, 60.0, 60.0, 0.0, 0.0, -3.328438315908492], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -20.0, -15.277310265869055, -31.50844961541582, 0.0, -10.0, 0.0, -40.0, 0.0, 0.0, -0.19005842410389717, 0.0, -0.007856060855433444, -0.36692403614411173, -10.0, -0.38546397683720923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, -3.7973086272318244, -73.13558027174776, 0.0, 0.0, -20.0, -2.3220379430437452, -1.7237713997157622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0267944591608347, -2.1177365564488992, 0.0, -30.0, 0.0, -20.0, 0.0, 0.0, 0.0, -1.6894216142189489, 0.0, 0.0, -20.0, -21.987805981294393, 0.0, 0.0, 0.0, 0.0, -2.0997118013175498, -30.0, -3.279484853993968, 0.0, -20.0, -33.32772587582574, -1.591766053427458, 0.0, -3.897776824231541, -92.62827581267413, -10.0, 0.0, 0.0, -1.1867665599705046, -7.988439768157011, -0.980345280498407, 0.0, -40.0, -1.1142624880879748, 0.0, -10.0, -30.0, -1.3288727996591054, 0.0, 0.0, -7.833498934436507, -0.07712625730378231, -30.0, -10.0, -32.74216408531473, 0.0, 0.0, -40.67421118310372, -10.429082700386443, 0.0, -0.4666090945988943, 0.0, 0.0, -14.342881080154807, -12.380821559315061, 0.0, -0.0652913337957739, -4.107719202127399, 0.0, -6.327310648099986, 0.0, 0.0, -30.0, 0.0, -10.0, 0.0, 0.0, -10.0, 0.0, -70.0, -1.356056891461257, 0.0, 0.0, -30.08583476214001, 0.0, -1.8049769937130644, -40.0, -0.8328512325000104, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -10.0, 0.0, 0.0, -0.510422289286141, -0.03845840965204128, -1.399212922590326, 0.0, 0.0, -51.32177538880878, -50.0, -0.17783086309574148, -3.9700931529706462, -20.0, 0.0, 0.0, -20.0, 0.0, -20.0, 0.0, 0.0, -40.0, -30.0, 0.0, -0.45864454150081224, -2.143237181289946, -30.0, -30.0, 0.0, 0.0, -3.328438315908492]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7132243630903842, "mean_inference_ms": 1.2329401210786544, "mean_action_processing_ms": 0.24524286322618338, "mean_env_wait_ms": 0.5291696791844224, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004563741623216374, "StateBufferConnector_ms": 0.0034703570566359597, "ViewRequirementAgentConnector_ms": 0.10368968271146155}, "num_episodes": 157, "episode_return_max": 177.37172418732587, "episode_return_min": -21.987805981294393, "episode_return_mean": 13.873665628194361}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.10516569278408, "num_env_steps_trained_throughput_per_sec": 210.10516569278408, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 20532.823, "restore_workers_time_ms": 0.013, "training_step_time_ms": 20532.766, "sample_time_ms": 1372.061, "learn_time_ms": 19133.552, "learn_throughput": 209.057, "synch_weights_time_ms": 24.532}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-40-16", "timestamp": 1723138816, "time_this_iter_s": 19.18814206123352, "time_total_s": 253.21259713172913, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f10d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 253.21259713172913, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 60.63333333333333, "ram_util_percent": 81.83703703703705}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8551745348920424, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1505656579509376, "policy_loss": -0.018491641870787133, "vf_loss": 3.167009626577298, "vf_explained_var": -0.005469455818335215, "kl": 0.010238337415365291, "entropy": 1.310649244983991, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.732442876453518, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.825363782280726, "policy_loss": -0.011768659960283694, "vf_loss": 2.83563275696538, "vf_explained_var": -7.038928092794216e-06, "kl": 0.007498177090986903, "entropy": 1.4045288424965339, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 38070.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -30.51013167671178, "episode_reward_mean": 20.747970338224427, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.049382716049383, "agent_policy": -12.40017780992372}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 20.0, 20.0, -9.516958784105107, 0.0, 0.0, 0.0, -30.51013167671178, 0.0, 60.0, 20.0, 20.0, 59.481390811792664, 100.0, 0.0, -0.23225615013443068, 60.0, 60.0, -10.390759944718777, 75.41587996944139, 0.0, 0.0, 58.04219725131307, 0.0, 0.0, 0.0, 80.0, 0.0, 20.0, 0.0, -1.9423452763223226, 40.0, 17.415660248048894, 60.0, 0.0, 0.0, -0.064326979831002, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 60.0, 0.0, 100.0, 0.0, -0.5276320473056129, 40.0, 40.0, 0.0, 0.0, 140.0, 0.0, 0.0, -0.7978227700731733, 20.0, 60.0, 20.0, 0.0, 0.0, 59.47410574702597, 60.0, 40.0, -0.7990044433091437, 60.0, 0.0, 20.0, 40.0, 20.0, 0.0, -0.7749937176041999, -7.739417907131992, 40.0, 40.0, 0.0, 0.0, -1.7704878760356602, 0.0, 0.0, -21.238170531590267, 19.239640736906825, 98.41247916926815, 0.0, -5.174882469183328, -0.673587204304239, 80.0, -0.18184523380237794, 0.0, 40.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 80.0, 60.0, 53.74874407083883, 40.0, -2.7182215857083163, 0.0, -8.685664570004118, 19.81791027157602, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 19.65101206239849, 0.0, 0.0, 0.0, -1.6211646561304793, 80.0, 59.93111692996666, 100.0, 60.0, 60.0, 100.0, 0.0, 20.0, 20.0, -3.2857143759574976, 60.0, 39.63914505977609, 13.084049341113342, 0.0, 0.0, 0.0, 60.0, 0.0, 20.0, 0.0, 0.0, 20.0, 0.0, -2.440888188826821, 0.0, -0.6279296166678727, 0.0, 0.0, -26.782889835601946, 40.0, 0.0, 0.0, 40.0, -5.513224551790518, 40.0, 0.0, 20.0, -2.7882472335529025, 0.0, 0.0, 80.0, 40.0, -5.38356925070509, 0.0, 80.0, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [0.0, -10.0, -10.0, -9.516958784105107, 0.0, 0.0, 0.0, -30.51013167671178, 0.0, -30.0, -10.0, -10.0, -30.51860918820733, -50.0, 0.0, -30.232256150134432, -30.0, -30.0, -10.390759944718777, -44.584120030558594, 0.0, 0.0, -31.95780274868693, 0.0, 0.0, 0.0, -40.0, 0.0, -10.0, 0.0, -1.9423452763223226, -20.0, -12.584339751951104, -30.0, 0.0, 0.0, -0.064326979831002, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -30.0, 0.0, -50.0, 0.0, -0.5276320473056129, -20.0, -20.0, 0.0, 0.0, -70.0, 0.0, 0.0, -0.7978227700731733, -10.0, -30.0, -10.0, 0.0, 0.0, -30.52589425297402, -30.0, -20.0, -0.7990044433091437, -30.0, 0.0, -10.0, -20.0, -10.0, 0.0, -0.7749937176041999, -7.739417907131992, -20.0, -20.0, 0.0, 0.0, -1.7704878760356602, 0.0, 0.0, -21.238170531590267, -10.760359263093175, -51.58752083073185, 0.0, -5.174882469183328, -0.673587204304239, -40.0, -0.18184523380237794, 0.0, -20.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -40.0, -30.0, -36.25125592916117, -20.0, -2.7182215857083163, 0.0, -8.685664570004118, -10.182089728423978, -40.0, -40.0, 0.0, 0.0, 0.0, 0.0, -10.34898793760151, 0.0, 0.0, 0.0, -1.6211646561304793, -40.0, -30.06888307003333, -50.0, -30.0, -30.0, -50.0, 0.0, -10.0, -10.0, -3.2857143759574976, -30.0, -20.36085494022391, -46.91595065888666, 0.0, 0.0, 0.0, -30.0, 0.0, -10.0, 0.0, 0.0, -10.0, 0.0, -2.440888188826821, 0.0, -0.6279296166678727, 0.0, 0.0, -26.782889835601946, -20.0, 0.0, 0.0, -20.0, -5.513224551790518, -20.0, 0.0, -10.0, -2.7882472335529025, 0.0, 0.0, -40.0, -20.0, -5.38356925070509, 0.0, -40.0, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7166040072869225, "mean_inference_ms": 1.2312993670047037, "mean_action_processing_ms": 0.24498870715723878, "mean_env_wait_ms": 0.5288831814733903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006920467188328873, "StateBufferConnector_ms": 0.003671131016295633, "ViewRequirementAgentConnector_ms": 0.1168756573288529}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -30.51013167671178, "episode_return_mean": 20.747970338224427}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 236.77393882552607, "num_env_steps_trained_throughput_per_sec": 236.77393882552607, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 20776.206, "restore_workers_time_ms": 0.015, "training_step_time_ms": 20776.148, "sample_time_ms": 1399.713, "learn_time_ms": 19350.393, "learn_throughput": 206.714, "synch_weights_time_ms": 23.872}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-40-33", "timestamp": 1723138833, "time_this_iter_s": 16.939244031906128, "time_total_s": 270.15184116363525, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f1e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 270.15184116363525, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 42.724999999999994, "ram_util_percent": 82.58749999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9128888531898459, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1495233247677485, "policy_loss": -0.020299241836861864, "vf_loss": 3.167670847227176, "vf_explained_var": 0.003953457437455654, "kl": 0.010758604988486064, "entropy": 1.3140573490411043, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7325470797030639, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3875512471435765, "policy_loss": -0.011789275757582027, "vf_loss": 2.3976340870907964, "vf_explained_var": 3.2387515331836457e-06, "kl": 0.00853198860266052, "entropy": 1.3918371533248441, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 40890.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -60.052514575795605, "episode_reward_mean": 16.694253364003938, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.506172839506172, "agent_policy": -11.824265154514581}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.8017921588875008, 0.0, 59.59628021457392, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 80.0, 0.0, -18.061349818969326, 40.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, -27.907478585039126, 33.58522968508939, 0.0, 40.0, 40.0, 0.0, 20.0, 20.0, -0.1540762195234835, -2.750876723214313, 100.0, 0.0, 58.81625760455722, 0.0, 0.0, -3.4637702536344284, -4.733070799503668, -0.7742186257744987, 140.0, 0.0, 40.0, -0.684541666428794, 0.0, 40.0, 0.0, -21.833123947017594, 40.0, 0.0, -60.052514575795605, -1.5291528943547417, 11.700016118570662, 0.0, 0.0, 80.0, 0.0, 0.0, 80.0, 60.0, 20.0, 0.0, 100.0, -16.78183544993989, 20.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 80.0, 20.0, 60.0, 20.0, 0.0, -30.115764833997257, -5.852489547586707, 58.36308587801392, -3.1980353256676697, 20.0, -4.986099738864653, 40.0, 0.0, 0.0, 0.0, 19.374236873168172, 0.0, 38.571928981419134, 80.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, -12.26035927266304, 0.0, 60.0, 0.0, -0.328690846368519, 0.0, 59.216636020223206, -0.4859907815438491, -1.5397306538198396, 0.0, 40.0, 0.0, 20.0, 19.889889521456357, -0.5667493798993184, 0.0, -0.3605085018298104, -0.12328662946207603, 60.0, 0.0, 0.0, 0.0, 60.0, 40.0, -0.46260740488570873, 80.0, 20.0, -0.05351858667457021, 40.0, 0.0, 0.0, -4.568202464241235, -0.033818962683341836, -0.4356309441537931, 100.0, 39.99662445340156, 20.0, 20.0, -11.278813149818847, 0.0, -11.11353849480111, -6.030052833980064, 0.0, 60.0, 40.0, -0.8643684295995724, 20.0, 0.0, 0.0, -4.563036549043318, 12.070880038732886, 40.0, 0.0, 60.0, 17.789167742706965, -46.27334683464623, 20.0, -5.787356375240919, 0.0, 60.0, 0.0, -7.118379288854086, 60.0, 60.0, 54.66961257015254, -0.24262318501970692, 0.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-1.8017921588875008, 0.0, -30.403719785426077, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -40.0, 0.0, -18.061349818969326, -20.0, -50.0, 0.0, 0.0, 0.0, 0.0, 0.0, -27.907478585039126, -26.414770314910612, 0.0, -20.0, -20.0, 0.0, -10.0, -10.0, -0.1540762195234835, -2.750876723214313, -50.0, 0.0, -31.18374239544277, 0.0, 0.0, -3.4637702536344284, -4.733070799503668, -0.7742186257744987, -70.0, 0.0, -20.0, -0.684541666428794, 0.0, -20.0, 0.0, -21.833123947017594, -20.0, 0.0, -60.052514575795605, -1.5291528943547417, -18.299983881429334, 0.0, 0.0, -40.0, 0.0, 0.0, -40.0, -30.0, -10.0, 0.0, -50.0, -16.78183544993989, -10.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -40.0, -10.0, -30.0, -10.0, 0.0, -30.115764833997257, -5.852489547586707, -31.636914121986074, -3.1980353256676697, -10.0, -4.986099738864653, -20.0, 0.0, 0.0, 0.0, -10.625763126831826, 0.0, -21.42807101858087, -40.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -12.26035927266304, 0.0, -30.0, 0.0, -0.328690846368519, 0.0, -30.783363979776794, -0.4859907815438491, -1.5397306538198396, 0.0, -20.0, 0.0, -10.0, -10.110110478543643, -0.5667493798993184, 0.0, -0.3605085018298104, -0.12328662946207603, -30.0, 0.0, 0.0, 0.0, -30.0, -20.0, -0.46260740488570873, -40.0, -10.0, -0.05351858667457021, -20.0, 0.0, 0.0, -4.568202464241235, -0.033818962683341836, -0.4356309441537931, -50.0, -20.00337554659844, -10.0, -10.0, -11.278813149818847, 0.0, -11.11353849480111, -6.030052833980064, 0.0, -30.0, -20.0, -0.8643684295995724, -10.0, 0.0, 0.0, -34.56303654904332, -17.92911996126711, -20.0, 0.0, -30.0, -12.210832257293035, -46.27334683464623, -10.0, -5.787356375240919, 0.0, -30.0, 0.0, -7.118379288854086, -30.0, -30.0, -35.330387429847455, -0.24262318501970692, 0.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7110358228897149, "mean_inference_ms": 1.2216001075893221, "mean_action_processing_ms": 0.24325765287097295, "mean_env_wait_ms": 0.5253019128425132, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004966097113526898, "StateBufferConnector_ms": 0.0031535272245053893, "ViewRequirementAgentConnector_ms": 0.09442810659055356}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -60.052514575795605, "episode_return_mean": 16.694253364003938}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.5601194589719, "num_env_steps_trained_throughput_per_sec": 268.5601194589719, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 20858.144, "restore_workers_time_ms": 0.015, "training_step_time_ms": 20858.081, "sample_time_ms": 1369.607, "learn_time_ms": 19461.027, "learn_throughput": 205.539, "synch_weights_time_ms": 24.67}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-40-48", "timestamp": 1723138848, "time_this_iter_s": 14.915319919586182, "time_total_s": 285.06716108322144, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d20f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 285.06716108322144, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 30.557142857142853, "ram_util_percent": 82.31904761904762}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8880703256775936, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0726017554601035, "policy_loss": -0.016276708544076732, "vf_loss": 3.08687072613587, "vf_explained_var": 0.0012817800045013428, "kl": 0.010038759711510182, "entropy": 1.3187062986195088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7200811422145958, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4156566264358816, "policy_loss": -0.010909218028524613, "vf_loss": 2.4250240100190994, "vf_explained_var": -6.504240610920791e-06, "kl": 0.00770901114438795, "entropy": 1.36774860278089, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 43710.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -31.698788765034458, "episode_reward_mean": 18.777432761121247, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.379746835443038, "agent_policy": -12.361807745207866}, "custom_metrics": {}, "hist_stats": {"episode_reward": [57.63371994298987, 60.0, 160.0, 40.0, 0.0, 20.0, 60.0, 59.86349163535229, -0.6369663176598306, 0.0, 0.0, 0.0, -2.4325441636825254, 0.0, 36.746318852662284, 20.0, 0.0, 36.945968377995314, 40.0, -2.7818547025809703, -1.3622869180025132, 20.0, 100.0, 60.0, 60.0, 40.0, 60.0, 40.0, 19.659187837479937, 60.0, -2.8878428083349412, 60.0, 0.0, -0.0819922370590076, -3.0243470986321324, 0.0, 60.0, 0.0, 0.0, 0.0, 60.0, -10.706530628791588, 0.0, -1.9378437972982188, 0.0, -0.40246570375144675, -14.210860768699483, 80.0, 80.0, -31.381745622425953, -4.182331094124341, 0.0, 38.570274390264316, 0.0, 0.0, 0.0, 60.0, 52.68198867510861, 0.0, 0.0, 0.0, 0.0, 0.0, -23.09116309040711, 0.0, 60.0, 0.0, -0.2145371456575884, 0.0, 20.0, 60.0, -0.2407799637390906, 38.3385513165219, -1.2253914124449827, 0.0, 0.0, 0.0, -25.758749935518107, -20.767268815860028, 0.0, 0.0, 0.0, -2.6543814163601462, 39.10621748065736, 0.0, 60.0, 0.0, 0.0, 0.0, 40.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 0.0, 0.0, 0.0, 10.15009163759656, -0.8692367268735202, 40.0, 80.0, 29.82688831136666, -0.7174522099838077, -1.3664011409283394, 39.87888331404036, 20.0, 20.0, -6.295872672010649, 0.0, -5.4049337420921315, 0.0, 35.61053458524191, 0.0, 0.0, 40.0, 40.0, 0.0, 20.0, 120.0, -7.58474693311691, 60.0, 40.0, -5.228112834092887, 0.0, 120.0, -31.698788765034458, 40.0, 0.0, 0.0, 0.0, 100.0, -14.807316532204009, -8.911242192328132, 0.0, -3.3033957884631313, 0.0, 0.0, -0.5663851214736226, 0.0, 75.93476317157734, -0.3275573954150812, 20.0, 60.0, 40.0, 20.0, 120.0, 0.0, 0.0, 0.0, -4.676966581388388, 20.0, 0.0, 0.0, 0.0, -2.3722109952624226], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-32.36628005701013, -30.0, -80.0, -20.0, 0.0, -10.0, -30.0, -30.13650836464771, -0.6369663176598306, 0.0, 0.0, 0.0, -2.4325441636825254, 0.0, -23.25368114733772, -10.0, 0.0, -23.054031622004686, -20.0, -2.7818547025809703, -1.3622869180025132, -10.0, -50.0, -30.0, -30.0, -20.0, -30.0, -20.0, -10.340812162520063, -30.0, -2.8878428083349412, -30.0, 0.0, -0.0819922370590076, -3.0243470986321324, 0.0, -30.0, 0.0, 0.0, 0.0, -30.0, -10.706530628791588, 0.0, -1.9378437972982188, 0.0, -0.40246570375144675, -14.210860768699483, -40.0, -40.0, -31.381745622425953, -4.182331094124341, 0.0, -21.42972560973568, 0.0, 0.0, 0.0, -30.0, -37.31801132489139, 0.0, 0.0, 0.0, 0.0, 0.0, -23.09116309040711, 0.0, -30.0, 0.0, -0.2145371456575884, 0.0, -10.0, -30.0, -0.2407799637390906, -21.661448683478095, -1.2253914124449827, 0.0, 0.0, 0.0, -25.758749935518107, -20.767268815860028, 0.0, 0.0, 0.0, -2.6543814163601462, -20.89378251934264, 0.0, -30.0, 0.0, 0.0, 0.0, -20.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -60.0, 0.0, 0.0, 0.0, -19.84990836240344, -0.8692367268735202, -20.0, -40.0, -30.17311168863334, -0.7174522099838077, -1.3664011409283394, -20.12111668595964, -10.0, -10.0, -36.29587267201066, 0.0, -5.4049337420921315, 0.0, -24.3894654147581, 0.0, 0.0, -20.0, -20.0, 0.0, -10.0, -60.0, -7.58474693311691, -30.0, -20.0, -5.228112834092887, 0.0, -60.0, -31.698788765034458, -20.0, 0.0, 0.0, 0.0, -50.0, -14.807316532204009, -8.911242192328132, 0.0, -3.3033957884631313, 0.0, 0.0, -0.5663851214736226, 0.0, -44.06523682842266, -0.3275573954150812, -10.0, -30.0, -20.0, -10.0, -60.0, 0.0, 0.0, 0.0, -4.676966581388388, -10.0, 0.0, 0.0, 0.0, -2.3722109952624226]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7102118296550898, "mean_inference_ms": 1.2210989080112118, "mean_action_processing_ms": 0.24316690264472782, "mean_env_wait_ms": 0.5247594211136346, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006230118908459628, "StateBufferConnector_ms": 0.003349781036376953, "ViewRequirementAgentConnector_ms": 0.09904051128822038}, "num_episodes": 158, "episode_return_max": 160.0, "episode_return_min": -31.698788765034458, "episode_return_mean": 18.777432761121247}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 250.21692545299015, "num_env_steps_trained_throughput_per_sec": 250.21692545299015, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 20541.625, "restore_workers_time_ms": 0.015, "training_step_time_ms": 20541.558, "sample_time_ms": 1389.945, "learn_time_ms": 19121.759, "learn_throughput": 209.186, "synch_weights_time_ms": 26.957}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-41-04", "timestamp": 1723138864, "time_this_iter_s": 15.999189853668213, "time_total_s": 301.06635093688965, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f9160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 301.06635093688965, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 36.74782608695652, "ram_util_percent": 81.72173913043478}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9076143302333851, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5476763604519266, "policy_loss": -0.014017760240191517, "vf_loss": 2.560041944993039, "vf_explained_var": 0.0016793406878908475, "kl": 0.008260862297385107, "entropy": 1.3043116482595603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7205990853144767, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0590703467950755, "policy_loss": -0.012520017227197582, "vf_loss": 2.0698692375463796, "vf_explained_var": 3.8844473818515207e-07, "kl": 0.008605453246987286, "entropy": 1.3491314581945433, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 46530.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -17.524924168791607, "episode_reward_mean": 16.355771814199382, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.726114649681529, "agent_policy": -9.822572134845206}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.22640530695269, 0.0, 0.0, -0.2614900878711801, 0.0, 98.16638845807533, -0.11182620095933404, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, -13.740333895462115, 40.0, -0.18246885700735516, 0.0, 0.0, 0.0, -1.3957505850601826, -12.605058547918524, 60.0, -12.705711844305116, -8.539552677520664, 95.32879688396179, 0.0, -5.480358958631242, -1.3811399400113544, 40.0, 0.0, 60.0, 0.0, 20.0, -0.17326021363824107, 0.0, 20.0, 0.0, -4.439579684838435, -1.0479072450806026, 51.08613841116518, -3.90322164751312, 40.0, 77.52639386812956, 0.0, -7.387703741365395, 40.0, 20.0, 0.0, 40.0, 0.0, 0.0, 0.0, 19.75509125768154, -6.493850624439071, 0.0, 0.0, 60.0, 0.0, -0.5042599117790103, 80.0, 40.0, -9.805947865947637, 38.88149711073184, 0.0, 0.0, -17.524924168791607, 0.0, 0.0, 0.0, 18.03597783826477, -1.2430471331768633, -1.0599843996639946, 60.0, 60.0, 20.0, -6.786637361402298, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, -0.32514589988222764, 0.0, 20.0, 0.0, 0.0, -0.049804232979938634, 0.0, 60.0, 52.52386987220088, 0.0, 60.0, -0.17887307320823775, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 120.0, 80.0, 0.0, 0.0, 119.7030436813591, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 20.0, 0.0, 100.0, 0.0, 37.74989473374768, 40.0, -12.123929219109634, 40.0, 0.0, 80.0, 19.62535365096658, 140.0, 0.0, 59.86650536658357, 0.0, -2.858910497217936, 20.0, 60.0, -0.2709238476257636, 0.0, 0.0, 0.0, 60.0, 0.0, -2.208023227700365, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 0.0, -0.3767454065050546, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-5.22640530695269, 0.0, 0.0, -0.2614900878711801, 0.0, -51.833611541924675, -0.11182620095933404, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, -13.740333895462115, -20.0, -0.18246885700735516, 0.0, 0.0, 0.0, -1.3957505850601826, -12.605058547918524, -30.0, -12.705711844305116, -8.539552677520664, -54.67120311603822, 0.0, -5.480358958631242, -1.3811399400113544, -20.0, 0.0, -30.0, 0.0, -10.0, -0.17326021363824107, 0.0, -10.0, 0.0, -4.439579684838435, -1.0479072450806026, -38.91386158883482, -3.90322164751312, -20.0, -42.47360613187045, 0.0, -7.387703741365395, -20.0, -10.0, 0.0, -20.0, 0.0, 0.0, 0.0, -10.244908742318465, -6.493850624439071, 0.0, 0.0, -30.0, 0.0, -0.5042599117790103, -40.0, -20.0, -9.805947865947637, -21.118502889268157, 0.0, 0.0, -17.524924168791607, 0.0, 0.0, 0.0, -11.964022161735228, -1.2430471331768633, -1.0599843996639946, -30.0, -30.0, -10.0, -6.786637361402298, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, -0.32514589988222764, 0.0, -10.0, 0.0, 0.0, -0.049804232979938634, 0.0, -30.0, -37.47613012779912, 0.0, -30.0, -0.17887307320823775, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -60.0, -40.0, 0.0, 0.0, -60.29695631864089, 0.0, 0.0, 0.0, 0.0, 0.0, -40.0, -10.0, 0.0, -50.0, 0.0, -22.250105266252323, -20.0, -12.123929219109634, -20.0, 0.0, -40.0, -10.37464634903342, -70.0, 0.0, -30.13349463341644, 0.0, -2.858910497217936, -10.0, -30.0, -0.2709238476257636, 0.0, 0.0, 0.0, -30.0, 0.0, -2.208023227700365, 0.0, 0.0, 0.0, 0.0, 0.0, -50.0, 0.0, 0.0, 0.0, 0.0, -0.3767454065050546, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.711122692242954, "mean_inference_ms": 1.2212861023409922, "mean_action_processing_ms": 0.2432858808497382, "mean_env_wait_ms": 0.5244357214807671, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006120447899885239, "StateBufferConnector_ms": 0.004471639159378732, "ViewRequirementAgentConnector_ms": 0.10632284127982558}, "num_episodes": 157, "episode_return_max": 140.0, "episode_return_min": -17.524924168791607, "episode_return_mean": 16.355771814199382}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 219.12330569365974, "num_env_steps_trained_throughput_per_sec": 219.12330569365974, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 20108.059, "restore_workers_time_ms": 0.015, "training_step_time_ms": 20107.99, "sample_time_ms": 1397.769, "learn_time_ms": 18678.991, "learn_throughput": 214.144, "synch_weights_time_ms": 28.423}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-41-22", "timestamp": 1723138882, "time_this_iter_s": 18.28742218017578, "time_total_s": 319.35377311706543, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d16160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 319.35377311706543, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 55.9076923076923, "ram_util_percent": 82.00769230769232}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0819052785634995, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6795086223321656, "policy_loss": -0.012418383701879065, "vf_loss": 2.6902061852316064, "vf_explained_var": -0.00460053663700819, "kl": 0.00860411830134506, "entropy": 1.282376318797469, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7180488467005127, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7597409337547654, "policy_loss": -0.011957491374515156, "vf_loss": 1.770085327929639, "vf_explained_var": -3.909494014496499e-06, "kl": 0.008065390756220642, "entropy": 1.318613218711623, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 49350.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 159.3124134115211, "episode_reward_min": -29.234585820066116, "episode_reward_mean": 16.35772097879712, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.68758658847891}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.135802469135802, "agent_policy": -11.049686428610293}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 0.0, -0.3672995748202579, 0.0, 0.0, 20.0, -6.3391351597665295, 0.0, 0.0, 0.0, 75.1509111342213, 0.0, -1.7656250122482176, 0.0, -2.449555334892371, 20.0, 40.0, 20.0, 60.0, -0.9168895506702712, -2.2009321336347494, 60.0, -29.234585820066116, -14.711868408675501, -8.11911126540669, 0.0, 0.0, 0.0, -5.4965361274659505, 0.0, 0.0, -0.6745926472630237, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 0.0, 0.0, 0.0, -0.9505615903987785, -7.078948307130778, 19.919007688884662, -0.28957959948329504, 58.91042845432261, 60.0, 0.0, 0.0, 57.22711806622942, -0.8394136818178755, 0.0, 0.0, 0.0, 0.0, -2.9084073935024435, 40.0, -8.373534182800089, 40.0, 0.0, 10.893546653522945, 0.0, 0.0, 100.0, 39.298968742065604, 29.392353985469114, 0.0, 0.0, 0.0, 100.0, -4.917057900645814, 120.0, 0.0, 0.0, -12.752203039827188, 39.392902526614606, -0.9086637701989475, 0.0, -10.408896018424365, 0.0, 19.457743911031596, 0.0, 0.0, 80.0, 60.0, 20.0, 140.0, -0.4798694141546256, 0.0, 60.0, 0.0, 20.0, -13.399307580515092, 20.0, -4.466428124162174, 0.0, 0.0, -2.444015671512785, 60.0, 0.0, 40.0, 0.0, 0.0, 80.0, -19.525551439725454, 0.0, 80.0, 80.0, 0.0, 0.0, 0.0, 40.0, 56.34477954768791, 80.0, 0.0, 60.0, 0.0, 0.0, 20.0, 0.0, -0.018997395616600077, 0.0, 60.0, 0.0, 60.0, -8.206898813258814, 0.0, -1.95813244267526, 140.0, 40.0, 0.0, 60.0, 0.0, 0.0, 0.0, 40.0, 0.0, -2.405627481068879, 77.31276478711082, 0.0, 20.0, 0.0, 0.0, -7.596744653160637, 0.0, 159.3124134115211, 20.0, -2.639713067947495, -2.287460681771921, 0.0, -6.097389796722858, 0.0, -11.391170439438485, 60.0, 0.0, 0.0, 0.0, 0.0, -13.409572207208019, -13.804857374344587, -0.827007241125981, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, 0.0, -0.3672995748202579, 0.0, 0.0, -10.0, -6.3391351597665295, 0.0, 0.0, 0.0, -44.84908886577871, 0.0, -1.7656250122482176, 0.0, -2.449555334892371, -10.0, -20.0, -10.0, -30.0, -0.9168895506702712, -2.2009321336347494, -30.0, -29.234585820066116, -44.7118684086755, -8.11911126540669, 0.0, 0.0, 0.0, -5.4965361274659505, 0.0, 0.0, -0.6745926472630237, 0.0, 0.0, 0.0, 0.0, -20.0, -20.0, 0.0, 0.0, 0.0, -0.9505615903987785, -7.078948307130778, -10.080992311115338, -0.28957959948329504, -31.089571545677387, -30.0, 0.0, 0.0, -32.772881933770584, -0.8394136818178755, 0.0, 0.0, 0.0, 0.0, -2.9084073935024435, -20.0, -8.373534182800089, -20.0, 0.0, -19.106453346477057, 0.0, 0.0, -50.0, -50.7010312579344, -30.607646014530882, 0.0, 0.0, 0.0, -50.0, -4.917057900645814, -60.0, 0.0, 0.0, -12.752203039827188, -20.607097473385394, -0.9086637701989475, 0.0, -10.408896018424365, 0.0, -10.542256088968404, 0.0, 0.0, -40.0, -30.0, -10.0, -70.0, -0.4798694141546256, 0.0, -30.0, 0.0, -10.0, -13.399307580515092, -10.0, -4.466428124162174, 0.0, 0.0, -2.444015671512785, -30.0, 0.0, -20.0, 0.0, 0.0, -40.0, -19.525551439725454, 0.0, -40.0, -40.0, 0.0, 0.0, 0.0, -20.0, -33.65522045231209, -40.0, 0.0, -30.0, 0.0, 0.0, -10.0, 0.0, -0.018997395616600077, 0.0, -30.0, 0.0, -30.0, -8.206898813258814, 0.0, -1.95813244267526, -70.0, -20.0, 0.0, -30.0, 0.0, 0.0, 0.0, -20.0, 0.0, -2.405627481068879, -42.687235212889185, 0.0, -10.0, 0.0, 0.0, -7.596744653160637, 0.0, -80.68758658847891, -10.0, -2.639713067947495, -2.287460681771921, 0.0, -6.097389796722858, 0.0, -11.391170439438485, -30.0, 0.0, 0.0, 0.0, 0.0, -13.409572207208019, -13.804857374344587, -0.827007241125981, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.710734219500232, "mean_inference_ms": 1.2204451410130295, "mean_action_processing_ms": 0.2431381290946559, "mean_env_wait_ms": 0.5239670577433846, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00513453542450328, "StateBufferConnector_ms": 0.0033945213129490982, "ViewRequirementAgentConnector_ms": 0.10710108427353847}, "num_episodes": 162, "episode_return_max": 159.3124134115211, "episode_return_min": -29.234585820066116, "episode_return_mean": 16.35772097879712}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 171.41823616839596, "num_env_steps_trained_throughput_per_sec": 171.41823616839596, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 19893.861, "restore_workers_time_ms": 0.016, "training_step_time_ms": 19893.792, "sample_time_ms": 1394.754, "learn_time_ms": 18466.205, "learn_throughput": 216.612, "synch_weights_time_ms": 30.191}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-41-45", "timestamp": 1723138905, "time_this_iter_s": 23.354609966278076, "time_total_s": 342.7083830833435, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bced4670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 342.7083830833435, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 70.23939393939393, "ram_util_percent": 82.42424242424242}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0156005581219991, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3034119879206023, "policy_loss": -0.013344551875585845, "vf_loss": 2.3149795338511465, "vf_explained_var": 0.009292508102953434, "kl": 0.008884971451850514, "entropy": 1.2840125678728025, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7332640555310757, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6289613319415572, "policy_loss": -0.012438685606326248, "vf_loss": 1.6397015366782532, "vf_explained_var": 5.61194639679388e-06, "kl": 0.008492310039944223, "entropy": 1.3073698354951033, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 52170.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 178.5648446389634, "episode_reward_min": -47.97273228808603, "episode_reward_mean": 13.10386598039985, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -91.4351553610366}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.407407407407407, "agent_policy": -9.118356241822374}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 100.0, -2.200408571378129, 0.0, 0.0, 100.0, -8.475489335191307, 0.0, 40.0, -1.5246459170447024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -19.593720663055517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, -10.105748216513538, 20.0, 0.0, 0.0, 56.9612316789934, 0.0, 0.0, 0.0, 0.0, 20.0, 19.397435688079625, 0.0, 60.0, 0.0, 40.0, -1.050573569635026, 19.28489365718293, 0.0, -6.485950417355809, -5.0928018735796305, -1.658073840538556, 60.0, 178.5648446389634, 59.48639822157591, 0.0, 0.0, -2.5758646592816614, 88.79220827034885, 0.0, 39.880040864362286, 60.0, 80.0, -2.8832245231657234, 0.0, 0.0, 0.0, 0.0, -31.24938035539002, -0.44135571827390363, 40.0, 0.0, -2.202635227742247, -1.4446103478077665, 0.0, -1.955967377747514, 58.82212529456331, 40.0, 0.0, 120.0, -7.282555300930782, -1.5156315645567742, -1.0900770852919839, -3.8564563628016946, 0.0, 0.0, -0.02171407329712216, 0.0, 40.0, 0.0, -2.0805300070584334, 60.0, -12.162548445441951, -6.135291388117325, 0.0, 40.0, 60.0, 100.0, -1.7562298603885385, -0.22895742135378372, 0.0, 19.204245218011838, -0.8547489461526936, -0.07797471675338952, 60.0, 40.0, 60.0, 0.0, 0.0, 20.0, 100.0, 0.0, 0.0, -2.044450818270721, 60.0, 0.0, -21.115247533747286, 0.0, -47.97273228808603, -0.7273624596316486, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 20.0, 0.0, 0.0, 71.56307721265388, 0.0, 0.0, 0.0, -3.4692205305065507, -3.722840845288588, 20.0, 0.0, -4.429664154978384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, -7.979162242017681, -1.6663652615874602, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -30.0, -50.0, -2.200408571378129, 0.0, 0.0, -50.0, -8.475489335191307, 0.0, -20.0, -1.5246459170447024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -19.593720663055517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -10.105748216513538, -10.0, 0.0, 0.0, -33.0387683210066, 0.0, 0.0, 0.0, 0.0, -10.0, -10.602564311920377, 0.0, -30.0, 0.0, -20.0, -1.050573569635026, -10.71510634281707, 0.0, -6.485950417355809, -5.0928018735796305, -31.658073840538552, -30.0, -91.4351553610366, -30.513601778424082, 0.0, 0.0, -2.5758646592816614, -61.207791729651156, 0.0, -20.119959135637714, -30.0, -40.0, -2.8832245231657234, 0.0, 0.0, 0.0, 0.0, -31.24938035539002, -0.44135571827390363, -20.0, 0.0, -2.202635227742247, -1.4446103478077665, 0.0, -1.955967377747514, -31.177874705436686, -20.0, 0.0, -60.0, -7.282555300930782, -1.5156315645567742, -1.0900770852919839, -3.8564563628016946, 0.0, 0.0, -0.02171407329712216, 0.0, -20.0, 0.0, -2.0805300070584334, -30.0, -12.162548445441951, -6.135291388117325, 0.0, -20.0, -30.0, -50.0, -1.7562298603885385, -0.22895742135378372, 0.0, -10.795754781988162, -0.8547489461526936, -0.07797471675338952, -30.0, -20.0, -30.0, 0.0, 0.0, -10.0, -50.0, 0.0, 0.0, -2.044450818270721, -30.0, 0.0, -21.115247533747286, 0.0, -47.97273228808603, -0.7273624596316486, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -10.0, 0.0, 0.0, -48.436922787346084, 0.0, 0.0, 0.0, -3.4692205305065507, -3.722840845288588, -10.0, 0.0, -4.429664154978384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, -7.979162242017681, -1.6663652615874602, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7124369325919669, "mean_inference_ms": 1.224514380907753, "mean_action_processing_ms": 0.24370069334220507, "mean_env_wait_ms": 0.5257880450471467, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00577583725069776, "StateBufferConnector_ms": 0.0047248086811583715, "ViewRequirementAgentConnector_ms": 0.11340423866554543}, "num_episodes": 162, "episode_return_max": 178.5648446389634, "episode_return_min": -47.97273228808603, "episode_return_mean": 13.10386598039985}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 252.1148325675214, "num_env_steps_trained_throughput_per_sec": 252.1148325675214, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 18991.215, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18991.148, "sample_time_ms": 1364.758, "learn_time_ms": 17594.621, "learn_throughput": 227.342, "synch_weights_time_ms": 29.124}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-42-01", "timestamp": 1723138921, "time_this_iter_s": 15.917624950408936, "time_total_s": 358.62600803375244, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bceef4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 358.62600803375244, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 39.445454545454545, "ram_util_percent": 81.96363636363637}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9537220723616581, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.006191919123133, "policy_loss": -0.017175042723829394, "vf_loss": 3.02122767282029, "vf_explained_var": -0.0030529767895738284, "kl": 0.010696406348759997, "entropy": 1.2753171611577272, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7400497062937588, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5200946549997263, "policy_loss": -0.013885374689402045, "vf_loss": 2.5324043292103084, "vf_explained_var": 2.6393866708092657e-06, "kl": 0.00787841707944979, "entropy": 1.2713983664698634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 54990.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 139.94155216286313, "episode_reward_min": -26.534831357291782, "episode_reward_mean": 21.500672169292034, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.05844783713687}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.358024691358025, "agent_policy": -12.573401904782042}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.34592552383829633, 40.0, 58.76764938205666, 60.0, 0.0, 20.0, 0.0, 0.0, 39.28469893324947, 0.0, 0.0, 0.0, 60.0, -5.303182912167427, 0.0, 60.0, 0.0, 0.0, 0.0, 100.0, 120.0, -1.0896006997680108, -10.00788702359898, 33.38161712975284, -1.5553086983265574, 0.0, -0.31967040159921356, -5.796263149626657, 0.0, 0.0, 0.0, 60.0, -0.676747417992789, 0.0, 0.0, 0.0, 117.41073377250028, 40.0, 20.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, -5.989654865872887, 0.0, 0.0, 0.0, -2.0445964381171553, -7.480236668427395, -24.3970524366421, 40.0, 60.0, 0.0, 0.0, 58.49127445400612, 40.0, 19.46555037199847, 0.0, 40.0, 0.0, 0.0, 60.0, 0.0, 60.0, 0.0, 59.453831648670686, 0.0, 0.0, 60.0, 40.0, 60.0, 0.0, 60.0, 0.0, 40.0, 20.0, 60.0, 0.0, 79.84007679984654, 0.0, 0.0, 0.0, -21.25192945786766, 0.0, 0.0, 40.0, 0.0, -5.302964259082696, 80.0, 0.0, 120.0, 0.0, -4.620813583775602, 0.0, 0.0, 60.0, 80.0, -0.30105351090154, 0.0, 0.0, 0.0, 0.0, -26.534831357291782, 40.0, 0.0, 0.0, 0.0, 0.0, 120.0, 20.0, 60.0, 0.0, 15.4653666142293, 0.0, -1.425224935940348, 0.0, 120.0, 40.0, 39.60660392725147, 20.0, -0.5985001477196028, 0.0, 100.0, 0.0, 60.0, 0.0, 57.56314634492702, 0.0, 0.0, -22.55776876471996, 0.0, 0.0, 80.0, 0.0, 0.0, 139.94155216286313, 20.0, 20.0, 0.0, 60.0, 0.0, 0.0, -1.3259243326677927, -3.3588884895858584, 0.0, 0.0, 20.0, -3.065899617315206, 39.951590193715205, 40.0, 40.0, 60.0, 40.0, 0.0, 80.0, 40.0, 0.0, 20.0, 59.937759530587876, 39.897364852499656], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-0.34592552383829633, -20.0, -31.23235061794334, -30.0, 0.0, -10.0, 0.0, 0.0, -20.715301066750527, 0.0, 0.0, 0.0, -30.0, -5.303182912167427, 0.0, -30.0, 0.0, 0.0, 0.0, -50.0, -60.0, -1.0896006997680108, -10.00788702359898, -26.61838287024716, -1.5553086983265574, 0.0, -0.31967040159921356, -5.796263149626657, 0.0, 0.0, 0.0, -30.0, -0.676747417992789, 0.0, 0.0, 0.0, -62.58926622749972, -20.0, -10.0, 0.0, -40.0, 0.0, 0.0, 0.0, 0.0, -5.989654865872887, 0.0, 0.0, 0.0, -2.0445964381171553, -7.480236668427395, -24.3970524366421, -20.0, -30.0, 0.0, 0.0, -31.508725545993883, -20.0, -10.534449628001529, 0.0, -20.0, 0.0, 0.0, -30.0, 0.0, -30.0, 0.0, -30.546168351329317, 0.0, 0.0, -30.0, -20.0, -30.0, 0.0, -30.0, 0.0, -20.0, -10.0, -30.0, 0.0, -40.15992320015345, 0.0, 0.0, 0.0, -21.25192945786766, 0.0, 0.0, -20.0, 0.0, -5.302964259082696, -40.0, 0.0, -60.0, 0.0, -4.620813583775602, 0.0, 0.0, -30.0, -40.0, -0.30105351090154, 0.0, 0.0, 0.0, 0.0, -26.534831357291782, -20.0, 0.0, 0.0, 0.0, 0.0, -60.0, -10.0, -30.0, 0.0, -14.5346333857707, 0.0, -1.425224935940348, 0.0, -60.0, -20.0, -20.393396072748533, -10.0, -0.5985001477196028, 0.0, -50.0, 0.0, -30.0, 0.0, -32.43685365507298, 0.0, 0.0, -22.55776876471996, 0.0, 0.0, -40.0, 0.0, 0.0, -70.05844783713687, -10.0, -10.0, 0.0, -30.0, 0.0, 0.0, -1.3259243326677927, -3.3588884895858584, 0.0, 0.0, -10.0, -3.065899617315206, -50.048409806284795, -20.0, -20.0, -30.0, -20.0, 0.0, -40.0, -20.0, 0.0, -10.0, -30.062240469412128, -20.102635147500344]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.711389507520502, "mean_inference_ms": 1.2229723088292688, "mean_action_processing_ms": 0.24317050321581157, "mean_env_wait_ms": 0.5249690359053613, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005958551242027754, "StateBufferConnector_ms": 0.0033893702942648053, "ViewRequirementAgentConnector_ms": 0.09781468061753261}, "num_episodes": 162, "episode_return_max": 139.94155216286313, "episode_return_min": -26.534831357291782, "episode_return_mean": 21.500672169292034}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.1770279449071, "num_env_steps_trained_throughput_per_sec": 269.1770279449071, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 18273.821, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18273.753, "sample_time_ms": 1351.902, "learn_time_ms": 16889.166, "learn_throughput": 236.838, "synch_weights_time_ms": 29.714}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-42-16", "timestamp": 1723138936, "time_this_iter_s": 14.89821195602417, "time_total_s": 373.5242199897766, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d160d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 373.5242199897766, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 34.55, "ram_util_percent": 82.47727272727272}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1063337370132407, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9020070639749367, "policy_loss": -0.01504439937149679, "vf_loss": 2.915010658279061, "vf_explained_var": 0.0029612569759289425, "kl": 0.010204073236864276, "entropy": 1.2971357937902213, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7540370855136966, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.151715275708665, "policy_loss": -0.012297958342675516, "vf_loss": 2.1625203163065807, "vf_explained_var": -1.013173279187358e-06, "kl": 0.007464549996848023, "entropy": 1.273012947402102, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 57810.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 157.81246005972935, "episode_reward_min": -33.944067303818045, "episode_reward_mean": 17.988364972327265, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -82.18753994027065}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.869281045751634, "agent_policy": -11.619478164927635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.711646190043416, 0.0, -33.944067303818045, 0.0, 40.0, 0.0, -19.770906003206974, 0.0, 19.640608442675607, 20.0, 120.0, 99.2166333222032, 0.0, 0.0, -0.4779444244281117, -6.708030823672117, 0.0, 40.0, 0.0, -20.175350831320756, 57.74064906382509, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, -15.179069754698899, 20.0, -1.3541131881595125, -0.5611748416365292, 0.0, 40.0, 0.0, -0.6413650263413451, -1.8815108630973798, -4.716623483401298, 60.0, 0.0, 60.0, 39.08740859660775, -5.213137140297701, -0.4054496296400667, 0.0, -1.2646343589521047, 0.0, 0.0, -19.012556780508486, 0.0, 0.0, 0.0, -7.622682696987351, 40.0, 20.0, 0.0, 40.0, 0.0, 100.0, 0.0, 38.37338203777302, 60.0, 0.0, 157.81246005972935, 0.0, -0.13710957046541572, 0.0, -19.717705688250128, 20.0, 0.0, 0.0, 0.0, 38.66527165291321, 0.0, -0.7775103955070484, 58.22437636786177, 0.0, 46.51539031968245, 0.0, 0.0, 13.117339991956221, 0.0, -3.0218862157028017, 0.0, 60.0, 100.0, 60.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 37.63476567811446, 0.0, 60.0, -19.390841905460174, 0.0, 0.0, -1.4907630588271692, -0.0632992758202977, 60.0, 119.94213135897307, 0.0, 0.0, 0.0, 40.0, 60.0, 0.0, 40.0, 0.0, 59.13511882058124, 40.0, 20.0, -0.06236010097730782, 80.0, -4.541205805379331, 20.0, 0.0, 60.0, 0.0, 0.0, 80.0, 20.0, -26.933315890978932, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 0.0, 79.83460252048184, 0.0, -0.29081873376783474, 0.0, 20.0, 80.0, 20.0, 40.0, 0.0, 60.0, 60.0, 0.0, -4.869304633383369, 0.0, 0.0, -0.48631446986498683, 60.0, 34.70240161728854, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-6.711646190043416, 0.0, -33.944067303818045, 0.0, -20.0, 0.0, -19.770906003206974, 0.0, -10.359391557324392, -10.0, -60.0, -50.7833666777968, 0.0, 0.0, -0.4779444244281117, -6.708030823672117, 0.0, -20.0, 0.0, -20.175350831320756, -32.25935093617492, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -15.179069754698899, -10.0, -1.3541131881595125, -0.5611748416365292, 0.0, -20.0, 0.0, -0.6413650263413451, -1.8815108630973798, -4.716623483401298, -30.0, 0.0, -30.0, -20.91259140339225, -5.213137140297701, -0.4054496296400667, 0.0, -1.2646343589521047, 0.0, 0.0, -19.012556780508486, 0.0, 0.0, 0.0, -7.622682696987351, -20.0, -10.0, 0.0, -20.0, 0.0, -50.0, 0.0, -21.626617962226977, -30.0, 0.0, -82.18753994027065, 0.0, -0.13710957046541572, 0.0, -19.717705688250128, -10.0, 0.0, 0.0, 0.0, -21.334728347086788, 0.0, -0.7775103955070484, -31.77562363213823, 0.0, -43.48460968031755, 0.0, 0.0, -16.88266000804378, 0.0, -3.0218862157028017, 0.0, -30.0, -50.0, -30.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -22.365234321885538, 0.0, -30.0, -19.390841905460174, 0.0, 0.0, -1.4907630588271692, -0.0632992758202977, -30.0, -60.05786864102693, 0.0, 0.0, 0.0, -20.0, -30.0, 0.0, -20.0, 0.0, -30.864881179418763, -20.0, -10.0, -0.06236010097730782, -40.0, -4.541205805379331, -10.0, 0.0, -30.0, 0.0, 0.0, -40.0, -10.0, -26.933315890978932, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -20.0, 0.0, -40.165397479518155, 0.0, -0.29081873376783474, 0.0, -10.0, -40.0, -10.0, -20.0, 0.0, -30.0, -30.0, 0.0, -4.869304633383369, 0.0, 0.0, -0.48631446986498683, -30.0, -25.29759838271146, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7086415992662704, "mean_inference_ms": 1.2202815724941949, "mean_action_processing_ms": 0.24286027195302978, "mean_env_wait_ms": 0.5240128212341103, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045678973977082695, "StateBufferConnector_ms": 0.003283319909588184, "ViewRequirementAgentConnector_ms": 0.09870116227592518}, "num_episodes": 153, "episode_return_max": 157.81246005972935, "episode_return_min": -33.944067303818045, "episode_return_mean": 17.988364972327265}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 256.22321398859026, "num_env_steps_trained_throughput_per_sec": 256.22321398859026, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 17594.695, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17594.637, "sample_time_ms": 1336.604, "learn_time_ms": 16227.059, "learn_throughput": 246.502, "synch_weights_time_ms": 28.266}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-42-32", "timestamp": 1723138952, "time_this_iter_s": 15.667924165725708, "time_total_s": 389.1921441555023, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d20f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 389.1921441555023, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 51.14090909090908, "ram_util_percent": 82.10909090909091}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0552163818851112, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.326942257831494, "policy_loss": -0.013915268415197109, "vf_loss": 3.3391115938623748, "vf_explained_var": 0.002166355090836684, "kl": 0.00872964291653929, "entropy": 1.2865207271029553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7548654211434067, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0940478322776497, "policy_loss": -0.012665990167891885, "vf_loss": 2.105007018053785, "vf_explained_var": -2.314435674789104e-06, "kl": 0.00853400373376079, "entropy": 1.242736147312408, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 60630.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -56.41516187447318, "episode_reward_mean": 15.926123793842548, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.691358024691358, "agent_policy": -13.147950280231527}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.937292061835253, 40.0, 0.0, -0.046229584988189965, 0.0, 78.273976319884, 0.0, 59.63251634865026, 0.0, 0.0, 99.52126622533135, 40.0, 40.0, 0.0, 28.678982184301432, 80.0, 80.0, 100.0, -56.41516187447318, 60.0, -7.837190611976846, 0.0, 0.0, 0.0, 60.0, 60.0, 38.08312640751809, 120.0, 60.0, -31.25360109772449, 45.05377766416787, 60.0, 160.0, 0.0, 0.0, 40.0, 0.0, 40.0, 60.0, -15.872454621116757, -0.5010017887837548, -12.406040130284241, -0.20217181214365554, 0.0, 40.0, 0.0, 0.0, -30.411447965838533, 0.0, 0.0, 0.0, 0.0, 0.0, -12.23849681258568, 60.0, 0.0, 0.0, 40.0, -5.646394190542416, 80.0, 40.0, 40.0, 0.0, 40.0, 0.0, 100.0, -15.224058203201546, -3.8661956510565085, 20.0, -10.2880066470652, 0.0, 0.0, 38.93651562302642, -20.053125328415113, -0.06622414009667899, 0.0, 0.0, -22.111577661753902, 0.0, -17.975095580120446, 0.0, 0.0, 60.0, 0.0, 0.0, -0.36235200996559525, 80.0, 0.0, -37.264874116055346, 19.90061042632846, -2.581464584566982, -4.890989296360262, -11.621627359819, 100.0, -4.030548793399705, 0.0, 27.99261578255593, -23.040102187556165, 0.0, -11.806982558419463, 0.0, -0.5826493914950925, 0.0, 0.0, 0.0, -43.58150698211276, -14.087418382060326, 0.0, 0.0, 140.0, 20.0, 0.0, -0.9821581124313616, 0.0, 0.0, 0.0, -1.1394542949515085, 0.0, 0.0, 0.0, -11.945655304853574, -4.187348754440854, -5.894168840230771, 40.0, 0.0, 0.0, 56.9738609344013, 60.0, -17.883625510664736, 60.0, -2.90383549058305, 0.0, 80.0, 0.0, -2.0189482616858596, 0.0, 40.0, 20.0, 0.0, -11.560952683267073, -0.2484816600668871, -1.1243193836073007, 0.0, -0.9627527265943159, 0.0, 0.0, 19.70259746596215, 0.0, 40.0, 60.0, 0.0, 0.0, 0.0, 80.0, 0.0, 99.00854362675321, 0.0, 0.0, 7.327648042802712, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-1.937292061835253, -20.0, 0.0, -0.046229584988189965, 0.0, -41.72602368011599, 0.0, -30.367483651349737, 0.0, 0.0, -50.47873377466866, -20.0, -20.0, 0.0, -31.321017815698568, -40.0, -40.0, -50.0, -56.41516187447318, -30.0, -7.837190611976846, 0.0, 0.0, 0.0, -30.0, -30.0, -21.916873592481913, -60.0, -30.0, -31.25360109772449, -44.94622233583213, -30.0, -80.0, 0.0, 0.0, -20.0, 0.0, -20.0, -30.0, -15.872454621116757, -0.5010017887837548, -12.406040130284241, -0.20217181214365554, 0.0, -20.0, 0.0, 0.0, -30.411447965838533, 0.0, 0.0, 0.0, 0.0, 0.0, -12.23849681258568, -30.0, 0.0, 0.0, -20.0, -5.646394190542416, -40.0, -20.0, -20.0, 0.0, -20.0, 0.0, -50.0, -15.224058203201546, -3.8661956510565085, -10.0, -10.2880066470652, 0.0, 0.0, -21.063484376973577, -20.053125328415113, -0.06622414009667899, 0.0, 0.0, -22.111577661753902, 0.0, -17.975095580120446, 0.0, 0.0, -30.0, 0.0, 0.0, -0.36235200996559525, -40.0, 0.0, -37.264874116055346, -10.09938957367154, -2.581464584566982, -4.890989296360262, -11.621627359819, -50.0, -4.030548793399705, 0.0, -32.00738421744407, -23.040102187556165, 0.0, -11.806982558419463, 0.0, -0.5826493914950925, 0.0, 0.0, 0.0, -43.58150698211276, -14.087418382060326, 0.0, 0.0, -70.0, -10.0, 0.0, -0.9821581124313616, 0.0, 0.0, 0.0, -1.1394542949515085, 0.0, 0.0, 0.0, -11.945655304853574, -4.187348754440854, -5.894168840230771, -20.0, 0.0, 0.0, -33.02613906559869, -30.0, -17.883625510664736, -30.0, -32.90383549058305, 0.0, -40.0, 0.0, -2.0189482616858596, 0.0, -20.0, -10.0, 0.0, -11.560952683267073, -0.2484816600668871, -1.1243193836073007, 0.0, -0.9627527265943159, 0.0, 0.0, -10.297402534037852, 0.0, -20.0, -30.0, 0.0, 0.0, 0.0, -40.0, 0.0, -50.9914563732468, 0.0, 0.0, -22.672351957197293, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.707941225770959, "mean_inference_ms": 1.2190349220854937, "mean_action_processing_ms": 0.24302984437620084, "mean_env_wait_ms": 0.5239969360689423, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0049796369340684675, "StateBufferConnector_ms": 0.003473552656762394, "ViewRequirementAgentConnector_ms": 0.09812587573204512}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -56.41516187447318, "episode_return_mean": 15.926123793842548}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 259.1882896416333, "num_env_steps_trained_throughput_per_sec": 259.1882896416333, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 17017.174, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17017.116, "sample_time_ms": 1329.212, "learn_time_ms": 15654.887, "learn_throughput": 255.511, "synch_weights_time_ms": 29.685}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-42-47", "timestamp": 1723138967, "time_this_iter_s": 15.46518087387085, "time_total_s": 404.65732502937317, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d20dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 404.65732502937317, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 36.559090909090905, "ram_util_percent": 82.47727272727273}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0168576125676434, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4188675140341123, "policy_loss": -0.019455836623092183, "vf_loss": 3.436159649739663, "vf_explained_var": -0.006056813709437847, "kl": 0.010818522408095669, "entropy": 1.2625175156941018, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7565453785742429, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.65831087548682, "policy_loss": -0.013322871106392737, "vf_loss": 2.6699634307242452, "vf_explained_var": -2.824541524792394e-06, "kl": 0.008351563339485727, "entropy": 1.23740766132977, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 63450.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -32.69625980361579, "episode_reward_mean": 22.61209358264317, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.407407407407407, "agent_policy": -14.610128639579052}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, 100.0, 0.0, 120.0, 0.0, 40.0, 0.0, 120.0, 20.0, 40.0, -0.39575826026477245, 39.76564207500762, 20.0, 20.0, 20.0, -0.018376560707543677, 0.0, -0.512416276725125, 20.0, 60.0, 0.0, 40.0, 0.0, -4.687677721346629, -15.25658425312788, 8.658928068671408, 0.0, 56.522444335468435, -21.75367239022717, 38.19331962590444, 40.0, -1.71454339962536, 0.0, 33.09319060920031, -1.0475305841788918, 0.0, 0.0, 40.0, 0.0, 120.0, 20.0, 0.0, 0.0, 0.0, 60.0, -8.777646114935049, 60.0, 40.0, 0.0, 80.0, 0.0, 0.0, 38.10460780272114, 0.0, 0.0, 60.0, 0.0, -0.4501297430359408, 0.0, 0.0, -2.9759512760534954, 0.0, 38.96675033754846, 80.0, -0.02712987995595495, -26.17227600880353, 99.28683955307429, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 60.0, 80.0, -32.69625980361579, -0.9559734602099457, 0.0, -6.765723881486632, 40.0, 20.0, 0.0, 0.0, -0.32091142695770736, 51.57805821496341, 0.0, -29.155846695070387, 0.0, 59.904048238207885, 0.0, 100.0, 0.0, 40.0, 19.6088273505975, 59.23885137893731, 40.0, 60.0, -0.5110888017224446, 0.0, 14.165623411355906, 0.0, 60.0, -6.5726680457708895, -9.41596943582168, 0.0, 40.0, 33.83820303296318, 20.0, 0.0, 0.0, 40.0, 0.0, 0.0, 60.0, 60.0, -0.2585896927033471, 60.0, 99.87333979559256, 0.0, -20.749593130135516, 60.0, 0.0, -0.8445839206704631, 0.0, 0.0, -13.019418663788498, 118.58497166924974, 0.0, 18.74019315230074, 60.0, 0.0, 77.16188345336788, 20.0, -6.426503699281618, 68.25560443779304, 0.0, 0.0, -15.25477844350747, 160.0, 0.0, 37.020763987523715, 60.0, 100.0, -2.2600481655244105, 0.0, 40.0, 0.0, 0.0, 0.0, 60.0, -2.6497093116516783, 0.0, 0.0, 39.9422484695605, 0.0, 0.0, 0.0, 38.508332801803235, 25.793847633286216], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-40.0, -50.0, 0.0, -60.0, 0.0, -20.0, 0.0, -60.0, -10.0, -20.0, -0.39575826026477245, -20.23435792499238, -10.0, -10.0, -10.0, -0.018376560707543677, 0.0, -0.512416276725125, -10.0, -30.0, 0.0, -20.0, 0.0, -4.687677721346629, -15.25658425312788, -21.341071931328592, 0.0, -33.477555664531565, -21.75367239022717, -21.806680374095553, -20.0, -1.71454339962536, 0.0, -56.9068093907997, -1.0475305841788918, 0.0, 0.0, -20.0, 0.0, -60.0, -10.0, 0.0, 0.0, 0.0, -30.0, -8.777646114935049, -30.0, -20.0, 0.0, -40.0, 0.0, 0.0, -21.89539219727886, 0.0, 0.0, -30.0, 0.0, -0.4501297430359408, 0.0, 0.0, -2.9759512760534954, 0.0, -21.03324966245154, -40.0, -0.02712987995595495, -26.17227600880353, -50.713160446925706, 0.0, 0.0, -50.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -30.0, -40.0, -32.69625980361579, -0.9559734602099457, 0.0, -6.765723881486632, -20.0, -10.0, 0.0, 0.0, -0.32091142695770736, -38.42194178503659, 0.0, -29.155846695070387, 0.0, -30.09595176179211, 0.0, -50.0, 0.0, -20.0, -10.391172649402499, -30.76114862106268, -20.0, -30.0, -0.5110888017224446, 0.0, -15.834376588644094, 0.0, -30.0, -6.5726680457708895, -9.41596943582168, 0.0, -20.0, -26.161796967036825, -10.0, 0.0, 0.0, -20.0, 0.0, 0.0, -30.0, -30.0, -0.2585896927033471, -30.0, -50.12666020440744, 0.0, -20.749593130135516, -30.0, 0.0, -0.8445839206704631, 0.0, 0.0, -13.019418663788498, -61.415028330750246, 0.0, -11.259806847699258, -30.0, 0.0, -42.83811654663212, -10.0, -36.42650369928162, -51.74439556220696, 0.0, 0.0, -15.25477844350747, -80.0, 0.0, -22.97923601247629, -30.0, -50.0, -2.2600481655244105, 0.0, -20.0, 0.0, 0.0, 0.0, -30.0, -2.6497093116516783, 0.0, 0.0, -20.0577515304395, 0.0, 0.0, 0.0, -21.49166719819676, -34.20615236671378]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7056991075528746, "mean_inference_ms": 1.215105205660466, "mean_action_processing_ms": 0.2420839954608543, "mean_env_wait_ms": 0.5225004128911597, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004694417670921043, "StateBufferConnector_ms": 0.0037474396788043742, "ViewRequirementAgentConnector_ms": 0.0959845236790033}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -32.69625980361579, "episode_return_mean": 22.61209358264317}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 265.6386465703915, "num_env_steps_trained_throughput_per_sec": 265.6386465703915, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 16619.17, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16619.113, "sample_time_ms": 1320.904, "learn_time_ms": 15268.918, "learn_throughput": 261.97, "synch_weights_time_ms": 26.801}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-43-03", "timestamp": 1723138983, "time_this_iter_s": 15.089418172836304, "time_total_s": 419.7467432022095, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bceef940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 419.7467432022095, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 37.38095238095238, "ram_util_percent": 81.5714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1411844824130337, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5059099762390056, "policy_loss": -0.01713567767049729, "vf_loss": 3.5208290100097654, "vf_explained_var": -0.01199857530494531, "kl": 0.01108326586726278, "entropy": 1.2285640039791663, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7584895335930459, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8658056142059625, "policy_loss": -0.012624956267565515, "vf_loss": 2.876985446231585, "vf_explained_var": 3.6143242044651765e-08, "kl": 0.0072256169232417684, "entropy": 1.2303056348722876, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 66270.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -46.922534461610574, "episode_reward_mean": 22.314107658780504, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.037037037037036, "agent_policy": -13.797003452330603}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 20.0, -6.041382195695004, 0.0, 60.0, 28.44416037991621, 100.0, 80.0, -10.378461022336769, 0.0, 39.765576036989586, 60.0, 0.0, 60.0, 20.0, 36.7650813573674, 79.62924969738532, 0.0, 100.0, 0.0, -0.9046913764800291, 20.0, 0.0, 100.0, 0.0, 0.0, -46.922534461610574, 0.0, 0.0, 0.0, 40.0, 80.0, 40.0, 35.68592293297318, -0.29824662435170013, 0.0, 0.0, 40.0, -20.721769133200684, 100.0, 0.0, 40.0, 2.3920771743188958, 19.36162731226195, 60.0, 100.0, -0.5361484510734682, 0.0, 57.695801120002244, 20.0, 0.0, 100.0, 0.0, -4.488132671635759, 0.0, 0.0, 120.0, 79.0175107672955, 0.0, -20.500557736406613, 60.0, -5.1171026916155355, 0.0, 0.0, 40.0, -13.511464432704903, 38.54981644241802, -1.612729596774739, 20.0, 60.0, 77.45435445783625, 15.645119454975116, 0.0, 60.0, 0.0, 0.0, 0.0, 60.0, 60.0, 80.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, -15.428306515850016, -1.0180056638187795, 20.0, 0.0, -1.3100966756477461, 60.0, 40.0, 0.0, 0.0, 0.0, -5.585552494472001, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 100.0, -2.0954975292167006, -2.344637981049413, -4.311962544632625, 0.0, -2.939929682201706, 0.0, 0.0, -0.23791839806828863, -1.522368125397204, -1.5064102974807148, 39.750553117562944, 15.738467882687221, 0.0, -2.4852237668608783, 0.0, 0.0, 0.0, 27.126909826570056, 0.0, 40.0, 0.0, 60.0, 200.0, -0.09280783585080443, 0.0, -0.7681565448199412, 60.0, 38.15747996997189, 0.0, 60.0, 40.0, 40.0, -0.13470206798473217, 0.0, 0.0, 120.0, 40.0, 0.0, 0.0, 0.0, 80.0, -1.8248859939238926, 20.0, -1.5191340144678966, 0.0, 60.0, 38.56179079589542, -0.513130757585587, -2.5894738759911418, 60.0, 0.0, 38.9730328534464, 0.0, 0.0, -6.410284346341025, 60.0, -8.157385351884528, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -10.0, -6.041382195695004, 0.0, -30.0, -31.555839620083788, -50.0, -40.0, -10.378461022336769, 0.0, -20.234423963010414, -30.0, 0.0, -30.0, -10.0, -23.234918642632596, -40.37075030261468, 0.0, -50.0, 0.0, -0.9046913764800291, -10.0, 0.0, -50.0, 0.0, 0.0, -46.922534461610574, 0.0, 0.0, 0.0, -20.0, -40.0, -20.0, -24.314077067026822, -0.29824662435170013, 0.0, 0.0, -20.0, -20.721769133200684, -50.0, 0.0, -20.0, -27.607922825681104, -10.63837268773805, -30.0, -50.0, -0.5361484510734682, 0.0, -32.304198879997756, -10.0, 0.0, -50.0, 0.0, -4.488132671635759, 0.0, 0.0, -60.0, -40.98248923270449, 0.0, -20.500557736406613, -30.0, -5.1171026916155355, 0.0, 0.0, -20.0, -13.511464432704903, -21.45018355758198, -1.612729596774739, -10.0, -30.0, -42.545645542163754, -14.354880545024884, 0.0, -30.0, 0.0, 0.0, 0.0, -30.0, -30.0, -40.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, -15.428306515850016, -1.0180056638187795, -10.0, 0.0, -1.3100966756477461, -30.0, -20.0, 0.0, 0.0, 0.0, -5.585552494472001, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -50.0, -2.0954975292167006, -2.344637981049413, -4.311962544632625, 0.0, -2.939929682201706, 0.0, 0.0, -0.23791839806828863, -31.522368125397204, -1.5064102974807148, -20.24944688243706, -14.261532117312779, 0.0, -2.4852237668608783, 0.0, 0.0, 0.0, -32.873090173429944, 0.0, -20.0, 0.0, -30.0, -100.0, -0.09280783585080443, 0.0, -0.7681565448199412, -30.0, -21.842520030028112, 0.0, -30.0, -20.0, -20.0, -0.13470206798473217, 0.0, 0.0, -60.0, -20.0, 0.0, 0.0, 0.0, -40.0, -1.8248859939238926, -10.0, -1.5191340144678966, 0.0, -30.0, -21.43820920410458, -0.513130757585587, -2.5894738759911418, -30.0, 0.0, -21.026967146553602, 0.0, 0.0, -6.410284346341025, -30.0, -8.157385351884528, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7039070376647798, "mean_inference_ms": 1.2095998639527805, "mean_action_processing_ms": 0.24119129870840883, "mean_env_wait_ms": 0.52055459110972, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005448306048357928, "StateBufferConnector_ms": 0.003416965037216375, "ViewRequirementAgentConnector_ms": 0.09281650001620069}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -46.922534461610574, "episode_return_mean": 22.314107658780504}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 270.69566082071924, "num_env_steps_trained_throughput_per_sec": 270.69566082071924, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 16407.469, "restore_workers_time_ms": 0.014, "training_step_time_ms": 16407.413, "sample_time_ms": 1290.964, "learn_time_ms": 15084.74, "learn_throughput": 265.169, "synch_weights_time_ms": 29.1}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-43-17", "timestamp": 1723138997, "time_this_iter_s": 14.802645921707153, "time_total_s": 434.5493891239166, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bceefb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 434.5493891239166, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 34.24761904761905, "ram_util_percent": 81.93333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1321428688863913, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9543348367015523, "policy_loss": -0.014228566614716935, "vf_loss": 2.9668755397200584, "vf_explained_var": -0.006247191814084848, "kl": 0.008439319040358818, "entropy": 1.2057246596862872, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7685544499480133, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.476881718889196, "policy_loss": -0.014318778803687648, "vf_loss": 2.489675679781758, "vf_explained_var": -1.2965067058590288e-07, "kl": 0.007624060943875452, "entropy": 1.2322485359847968, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 69090.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -17.44835786114968, "episode_reward_mean": 17.587005375979615, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.25925925925926, "agent_policy": -10.190772401798162}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 80.0, -5.802447698400725, 0.0, 16.373832782244342, 40.0, 20.0, 11.451056991787691, 0.0, -0.09906622659795583, 0.0, 60.0, 0.0, 20.0, 76.63094563348616, 0.0, 20.0, 0.0, 120.0, 0.0, 0.0, 59.63652730655585, 0.0, 100.0, -0.28057247304275057, 20.0, 39.018258573610254, 20.0, 0.0, -0.05638818532197054, 0.0, -0.7911746526898433, 40.0, 0.0, 40.0, 0.0, 0.0, -2.8753760656766905, 0.0, 0.0, 60.0, 0.0, 40.0, 59.89525217135599, -0.18979502295169315, -6.0518341139129195, 0.0, 60.0, -3.3802503035549885, 40.0, 39.54090169938935, 0.0, -2.4497660225062905, 0.0, 80.0, -0.8517023592457273, -3.319719983172682, 60.0, 0.0, 80.0, 0.0, 40.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 0.0, 60.0, 40.0, 0.0, 58.526534257863716, 39.98058480396991, 0.0, 0.0, 0.0, 0.0, -2.257536996513434, 80.0, 100.0, 0.0, -2.2836389831519313, 0.0, 80.0, 0.0, -13.394512931087219, 0.0, 0.0, 59.959927899387594, 60.0, 0.0, 0.0, 0.0, 40.0, -14.995995224437978, 0.0, 0.0, -17.44835786114968, -10.610865909539298, -8.005525602919064, 40.0, 60.0, 0.0, -0.3683812144502496, 0.0, 0.0, 37.62141746608899, -0.858542839261186, 0.0, 0.0, 40.0, -9.354900684881013, 60.0, -6.59578195756997, 0.0, 0.0, 0.0, 40.0, 0.0, 60.0, -0.2734057180076277, 60.0, 0.0, -0.1217582886835833, 40.0, -0.0872156689016379, -2.1103204876775505, 0.0, 0.0, 0.0, 0.0, 0.0, -2.334954125462507, 0.0, 0.0, -1.7590873511165084, 0.0, -5.480813045274803, -1.6997949898822984, 40.0, 40.0, 40.0, 100.0, 0.0, 60.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 0.0, -2.235776859642197, 0.0, 40.0, 58.88489116964185, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, 0.0, -40.0, -5.802447698400725, 0.0, -13.626167217755656, -20.0, -10.0, -18.54894300821231, 0.0, -0.09906622659795583, 0.0, -30.0, 0.0, -10.0, -43.369054366513836, 0.0, -10.0, 0.0, -60.0, 0.0, 0.0, -30.363472693444145, 0.0, -50.0, -0.28057247304275057, -10.0, -20.981741426389746, -10.0, 0.0, -0.05638818532197054, 0.0, -0.7911746526898433, -20.0, 0.0, -20.0, 0.0, 0.0, -2.8753760656766905, 0.0, 0.0, -30.0, 0.0, -20.0, -30.104747828644008, -0.18979502295169315, -6.0518341139129195, 0.0, -30.0, -3.3802503035549885, -20.0, -20.459098300610652, 0.0, -2.4497660225062905, 0.0, -40.0, -0.8517023592457273, -3.319719983172682, -30.0, 0.0, -40.0, 0.0, -20.0, -30.0, 0.0, 0.0, 0.0, -20.0, -20.0, 0.0, -30.0, -20.0, 0.0, -31.473465742136288, -20.019415196030092, 0.0, 0.0, 0.0, 0.0, -2.257536996513434, -40.0, -50.0, 0.0, -2.2836389831519313, 0.0, -40.0, 0.0, -13.394512931087219, 0.0, 0.0, -30.040072100612406, -30.0, 0.0, 0.0, 0.0, -20.0, -14.995995224437978, 0.0, 0.0, -17.44835786114968, -10.610865909539298, -8.005525602919064, -20.0, -30.0, 0.0, -0.3683812144502496, 0.0, 0.0, -22.378582533911008, -0.858542839261186, 0.0, 0.0, -20.0, -9.354900684881013, -30.0, -6.59578195756997, 0.0, 0.0, 0.0, -20.0, 0.0, -30.0, -0.2734057180076277, -30.0, 0.0, -0.1217582886835833, -20.0, -0.0872156689016379, -2.1103204876775505, 0.0, 0.0, 0.0, 0.0, 0.0, -2.334954125462507, 0.0, 0.0, -1.7590873511165084, 0.0, -5.480813045274803, -1.6997949898822984, -20.0, -20.0, -20.0, -50.0, 0.0, -30.0, -10.0, 0.0, 0.0, 0.0, -10.0, -10.0, 0.0, -2.235776859642197, 0.0, -20.0, -31.11510883035815, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7026879118425814, "mean_inference_ms": 1.2096695871808936, "mean_action_processing_ms": 0.24109214436316226, "mean_env_wait_ms": 0.5202892619135719, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004581463189772618, "StateBufferConnector_ms": 0.0034012912232198834, "ViewRequirementAgentConnector_ms": 0.09499766208507397}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -17.44835786114968, "episode_return_mean": 17.587005375979615}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 214.74277942620424, "num_env_steps_trained_throughput_per_sec": 214.74277942620424, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 16780.738, "restore_workers_time_ms": 0.014, "training_step_time_ms": 16780.683, "sample_time_ms": 1298.497, "learn_time_ms": 15445.218, "learn_throughput": 258.98, "synch_weights_time_ms": 33.976}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-43-36", "timestamp": 1723139016, "time_this_iter_s": 18.676969051361084, "time_total_s": 453.2263581752777, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d1e160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 453.2263581752777, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 50.74444444444444, "ram_util_percent": 82.39629629629631}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.054551833992203, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3810184499869744, "policy_loss": -0.012738556278539667, "vf_loss": 3.3922625745336217, "vf_explained_var": -0.0064719279607137045, "kl": 0.007472137244546436, "entropy": 1.187451285868883, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7687787981426463, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8990995814191534, "policy_loss": -0.01503045122768294, "vf_loss": 2.912492612321326, "vf_explained_var": 5.960253113550497e-07, "kl": 0.008187089855244606, "entropy": 1.211509296234618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 71910.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -33.196127791750115, "episode_reward_mean": 21.34079139537028, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.30718954248366, "agent_policy": -12.580777232080697}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.841974076819284, 98.5699122330891, -0.1006750543057311, 0.0, 0.0, 0.0, 60.0, 58.933287633750865, 0.0, 0.0, 120.0, 40.0, 39.7550557200904, 60.0, 0.0, 22.518027284627117, 59.961941046341494, 0.0, -0.7572740006579359, 54.87317857741482, 80.0, 29.9833249608251, 0.0, 0.0, 20.0, 40.0, 0.0, 20.0, 60.0, 0.0, -33.196127791750115, 40.0, 0.0, -24.53881760278961, 19.91677270999517, 0.0, 0.0, 0.0, 0.0, 0.0, 76.51352946198799, 40.0, 0.0, 0.0, 0.0, 20.0, -1.2823528381438565, 40.0, 0.0, -1.504376835887794, 60.0, 60.0, -2.2429191685721106, 20.0, -0.9875854822866903, -2.1515820177646345, 20.0, -4.7517314151089804, 0.0, 80.0, 80.0, 0.0, 0.0, 60.0, -2.1023418045915774, 0.0, 0.0, 0.0, 0.0, -2.0005784630313417, 57.15755393763513, 40.0, 39.019585865815884, 0.0, 17.147999485637747, 40.0, 0.0, 100.0, 40.0, -28.667837449240274, -0.40278030917824226, 0.0, 40.0, 0.0, 0.0, 0.0, -4.595651845656969, 0.0, -5.539314067581558, 20.0, 80.0, 0.0, 40.0, 39.99472879839254, 0.0, -3.4788103227853426, 59.97346005540376, 20.0, -1.4151682378181152, 40.0, 0.0, 60.0, 100.0, 0.0, -13.601502715325282, -0.3628759736428133, 0.0, 40.0, -1.534292488630099, 0.0, 60.0, 20.0, 40.0, 0.0, 0.0, 60.0, 40.0, 0.0, 59.50628964366284, 40.0, 40.0, 60.0, 20.0, 40.0, 0.0, -2.0563658839449497, 80.0, 0.0, 0.0, 40.0, 36.41301636151912, 140.0, -0.06635944069890987, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 60.0, -0.11773024351545258, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5164970915535, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-10.158025923180716, -51.430087766910894, -0.1006750543057311, 0.0, 0.0, 0.0, -30.0, -31.066712366249142, 0.0, 0.0, -60.0, -20.0, -20.244944279909603, -30.0, 0.0, -37.4819727153729, -30.038058953658506, 0.0, -0.7572740006579359, -35.12682142258518, -40.0, -30.016675039174903, 0.0, 0.0, -10.0, -20.0, 0.0, -10.0, -30.0, 0.0, -33.196127791750115, -20.0, 0.0, -24.53881760278961, -10.083227290004832, 0.0, 0.0, 0.0, 0.0, 0.0, -43.486470538012014, -20.0, 0.0, 0.0, 0.0, -10.0, -1.2823528381438565, -20.0, 0.0, -1.504376835887794, -30.0, -30.0, -2.2429191685721106, -10.0, -0.9875854822866903, -2.1515820177646345, -10.0, -4.7517314151089804, 0.0, -40.0, -40.0, 0.0, 0.0, -30.0, -2.1023418045915774, 0.0, 0.0, 0.0, 0.0, -2.0005784630313417, -32.842446062364864, -20.0, -20.980414134184116, 0.0, -12.85200051436225, -20.0, 0.0, -50.0, -20.0, -28.667837449240274, -0.40278030917824226, 0.0, -20.0, 0.0, 0.0, 0.0, -4.595651845656969, 0.0, -5.539314067581558, -10.0, -40.0, 0.0, -20.0, -20.00527120160746, 0.0, -3.4788103227853426, -30.026539944596244, -10.0, -1.4151682378181152, -20.0, 0.0, -30.0, -50.0, 0.0, -13.601502715325282, -0.3628759736428133, 0.0, -20.0, -1.534292488630099, 0.0, -30.0, -10.0, -20.0, 0.0, 0.0, -30.0, -20.0, 0.0, -30.49371035633716, -20.0, -20.0, -30.0, -10.0, -20.0, 0.0, -2.0563658839449497, -40.0, 0.0, 0.0, -20.0, -23.586983638480877, -70.0, -0.06635944069890987, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -30.0, -0.11773024351545258, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -17.483502908446507, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7050652480750201, "mean_inference_ms": 1.215803825309562, "mean_action_processing_ms": 0.24220692099975616, "mean_env_wait_ms": 0.5219932898419332, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004902696297838797, "StateBufferConnector_ms": 0.007038100872164458, "ViewRequirementAgentConnector_ms": 0.1125542946111143}, "num_episodes": 153, "episode_return_max": 140.0, "episode_return_min": -33.196127791750115, "episode_return_mean": 21.34079139537028}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.86722014299949, "num_env_steps_trained_throughput_per_sec": 157.86722014299949, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 17715.898, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17715.844, "sample_time_ms": 1318.401, "learn_time_ms": 16358.604, "learn_throughput": 244.52, "synch_weights_time_ms": 35.97}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-44-02", "timestamp": 1723139042, "time_this_iter_s": 25.38400101661682, "time_total_s": 478.61035919189453, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bceef790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 478.61035919189453, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 72.65555555555554, "ram_util_percent": 82.49722222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0851743714883924, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0473180172344048, "policy_loss": -0.0176927123015048, "vf_loss": 3.0629104052980742, "vf_explained_var": -0.0032037134592731793, "kl": 0.010501660222135929, "entropy": 1.1874183803796767, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7739909031923781, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3430833834282896, "policy_loss": -0.01631446221987023, "vf_loss": 2.357546542637737, "vf_explained_var": -3.5773355064662636e-07, "kl": 0.009256514516833677, "entropy": 1.1792833397997187, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 74730.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -27.216663535567008, "episode_reward_mean": 23.919002627378195, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.777777777777779, "agent_policy": -14.41433070595514}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 60.0, -0.6348551885987486, -0.21120341690677114, 0.0, 59.628831040196246, 0.0, 220.0, 0.0, 0.0, 0.0, 80.0, -17.609168392132556, 80.0, 20.0, 0.0, 60.0, 19.863126670696307, 79.64115336048935, 0.0, 0.0, 40.0, 0.0, 0.0, 100.0, 40.0, 0.0, 20.0, 60.0, 180.0, 0.0, 60.0, 60.0, 0.0, 0.0, -9.056184553392068, 0.0, 60.0, 0.0, 0.0, 40.0, -1.8057510735393778, 0.0, -1.7831855064199642, 0.0, 0.0, 0.0, 0.0, 100.0, 60.0, -1.4617857784057275, 120.0, -1.847863413081976, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2934951873987113, 0.0, 20.0, 39.67394701283342, -1.8677062767867403, 0.0, 60.0, 0.0, -0.040440589510921665, -23.004101125804844, 0.0, -7.6357203447854936, 0.0, 40.0, 60.0, -15.005976061352154, 20.0, 0.0, 0.0, 60.0, 60.0, 80.0, -1.1657377698885873, 16.793775037713242, 60.0, 0.0, 0.0, 60.0, 40.0, 37.42826471484373, 17.945180310535157, -0.12619660211493633, 0.0, 0.0, -13.255570144411415, -23.454339959898242, 0.0, 0.0, -23.068304727083085, 0.0, 77.64722376950894, 60.0, 0.0, 200.0, 80.0, 0.0, 0.0, 60.0, 0.0, 0.0, -1.7128496073861843, -0.5482371190007074, 0.0, 80.0, 60.0, 0.0, 0.0, -3.2696754328017037, 0.0, 0.0, 0.0, -0.5165499138557261, 0.0, -3.860652897667867, 0.0, 0.0, -12.154155815668608, 0.0, 0.0, 0.0, 0.0, -0.6653142170416293, -27.216663535567008, 0.0, 0.0, 74.13961304491198, 100.0, 40.0, 55.19925415071637, 120.0, -9.771771383006097, -8.466914680067912, 0.0, 60.0, 0.0, 0.0, 20.0, 0.0, 40.0, 180.0, 60.0, 160.0, -0.05137146421008487, 60.0, -3.1826437732012507, -10.331915830805453, -3.468768844278035, -0.33923397915990305, 59.34066500581014, 78.96453372114895, -0.2604205394438386, 27.757582940537887, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -30.0, -0.6348551885987486, -0.21120341690677114, 0.0, -30.371168959803747, 0.0, -110.0, 0.0, 0.0, 0.0, -40.0, -17.609168392132556, -40.0, -10.0, 0.0, -30.0, -10.136873329303693, -40.358846639510645, 0.0, 0.0, -20.0, 0.0, 0.0, -50.0, -20.0, 0.0, -10.0, -30.0, -90.0, 0.0, -30.0, -30.0, 0.0, 0.0, -9.056184553392068, 0.0, -30.0, 0.0, 0.0, -20.0, -1.8057510735393778, 0.0, -1.7831855064199642, 0.0, 0.0, 0.0, 0.0, -50.0, -30.0, -1.4617857784057275, -60.0, -1.847863413081976, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2934951873987113, 0.0, -10.0, -20.326052987166584, -1.8677062767867403, 0.0, -30.0, 0.0, -0.040440589510921665, -23.004101125804844, 0.0, -7.6357203447854936, 0.0, -20.0, -30.0, -15.005976061352154, -10.0, 0.0, 0.0, -30.0, -30.0, -40.0, -1.1657377698885873, -13.206224962286758, -30.0, 0.0, 0.0, -30.0, -20.0, -22.571735285156272, -12.054819689464843, -0.12619660211493633, 0.0, 0.0, -13.255570144411415, -23.454339959898242, 0.0, 0.0, -23.068304727083085, 0.0, -42.35277623049105, -30.0, 0.0, -100.0, -40.0, 0.0, 0.0, -30.0, 0.0, 0.0, -1.7128496073861843, -0.5482371190007074, 0.0, -40.0, -30.0, 0.0, 0.0, -3.2696754328017037, 0.0, 0.0, 0.0, -0.5165499138557261, 0.0, -3.860652897667867, 0.0, 0.0, -12.154155815668608, 0.0, 0.0, 0.0, 0.0, -0.6653142170416293, -27.216663535567008, 0.0, 0.0, -45.86038695508801, -50.0, -20.0, -34.800745849283636, -60.0, -9.771771383006097, -8.466914680067912, 0.0, -30.0, 0.0, 0.0, -10.0, 0.0, -20.0, -90.0, -30.0, -80.0, -0.05137146421008487, -30.0, -3.1826437732012507, -10.331915830805453, -3.468768844278035, -0.33923397915990305, -30.659334994189855, -41.03546627885105, -0.2604205394438386, -32.24241705946211, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7069759792020098, "mean_inference_ms": 1.219553586502178, "mean_action_processing_ms": 0.2428899098782671, "mean_env_wait_ms": 0.522744247239389, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0074333614773220485, "StateBufferConnector_ms": 0.003993290442007559, "ViewRequirementAgentConnector_ms": 0.12190415535444095}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -27.216663535567008, "episode_return_mean": 23.919002627378195}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 181.77084539787433, "num_env_steps_trained_throughput_per_sec": 181.77084539787433, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 18091.015, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18090.962, "sample_time_ms": 1295.472, "learn_time_ms": 16758.578, "learn_throughput": 238.684, "synch_weights_time_ms": 34.201}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-44-24", "timestamp": 1723139064, "time_this_iter_s": 22.01991868019104, "time_total_s": 500.63027787208557, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d20280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 500.63027787208557, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 63.767741935483876, "ram_util_percent": 81.63870967741937}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2095912099505464, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3103900590290625, "policy_loss": -0.018283082257645824, "vf_loss": 3.326749384775758, "vf_explained_var": -0.009940721467137337, "kl": 0.009618795436272858, "entropy": 1.1763990060736735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7759809136496368, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4000537215395177, "policy_loss": -0.016580144297298545, "vf_loss": 2.4150044328777502, "vf_explained_var": 1.613869734689699e-06, "kl": 0.008147141441253537, "entropy": 1.1716945788961777, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 77550.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -53.86575490271628, "episode_reward_mean": 19.12493990905331, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.617283950617283, "agent_policy": -12.72691194279854}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.4527089192403, 0.0, -0.7865540179033603, -1.0024418990823691, 0.0, 0.0, -11.710370439013689, 0.0, -2.3429578834988343, 0.0, 0.0, 19.536075580986278, 100.0, 40.0, 60.0, 0.0, 0.0, 39.563489649380905, 200.0, -11.67110911617035, 40.0, 38.97039353874673, -11.44438230458941, 57.33613285986384, 80.0, 10.13430955448191, -0.23299280980434323, 80.0, 0.0, 78.5977020850281, -0.6207737055811879, 20.0, -1.8217688151223466, 0.0, 20.0, 0.0, 120.0, -1.8813342298535363, 17.681520909453447, 0.0, 0.0, 0.0, 120.0, 60.0, -3.430224604034662, 40.0, 60.0, 40.0, 100.0, 60.0, 40.0, 0.0, 100.0, 0.0, 0.0, 39.10401209359778, 20.0, 40.0, 0.0, 60.0, 60.0, 0.0, -14.771666329907516, 0.0, 20.0, 0.0, 60.0, -6.183310279259375, 0.0, 40.0, 0.0, -2.41839774731004, 0.0, -0.262525650684311, 0.0, 0.0, -0.32747191634147854, 0.0, 54.3673668128674, 0.0, 0.0, -9.538855333673801, 60.0, 40.0, 0.0, 40.0, -1.3590166704264361, -8.979366656771525, -53.86575490271628, 60.0, 60.0, -5.273806559252703, -13.57943020450651, 0.0, 0.0, 0.0, 19.92964253444299, -0.3453889769288365, 120.0, 20.0, 0.0, 0.0, 60.0, -4.735953367646758, 0.0, 0.0, 0.0, -20.236727412721265, 0.0, -7.1175588320506105, 0.0, -4.2706106265119175, 60.0, 60.0, -15.60497061035611, 77.87291538940364, 40.0, 0.0, 0.0, 0.0, 0.0, -11.293350741538896, -20.477892822150697, 0.0, -0.011961837168887879, 0.0, 20.0, 20.0, 41.87884935199169, -13.657330905900022, -0.2912297588836721, 80.0, 0.0, 40.0, 38.30583120596061, 60.0, 0.0, 0.0, -6.324893467556719, 80.0, 0.0, -6.853993785391986, 0.0, -15.67448255869319, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.910172560194457, 40.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-10.547291080759697, 0.0, -0.7865540179033603, -1.0024418990823691, 0.0, 0.0, -11.710370439013689, 0.0, -2.3429578834988343, 0.0, 0.0, -10.463924419013722, -50.0, -20.0, -30.0, 0.0, 0.0, -20.436510350619095, -100.0, -11.67110911617035, -20.0, -21.029606461253273, -11.44438230458941, -32.66386714013616, -40.0, -19.86569044551809, -0.23299280980434323, -40.0, 0.0, -41.4022979149719, -0.6207737055811879, -10.0, -1.8217688151223466, 0.0, -10.0, 0.0, -60.0, -1.8813342298535363, -12.318479090546555, 0.0, 0.0, 0.0, -60.0, -30.0, -3.430224604034662, -20.0, -30.0, -20.0, -50.0, -30.0, -20.0, 0.0, -50.0, 0.0, 0.0, -20.89598790640222, -10.0, -20.0, 0.0, -30.0, -30.0, 0.0, -14.771666329907516, 0.0, -10.0, 0.0, -30.0, -6.183310279259375, 0.0, -20.0, 0.0, -2.41839774731004, 0.0, -0.262525650684311, 0.0, 0.0, -0.32747191634147854, 0.0, -35.6326331871326, 0.0, 0.0, -9.538855333673801, -30.0, -20.0, 0.0, -20.0, -1.3590166704264361, -8.979366656771525, -53.86575490271628, -30.0, -30.0, -5.273806559252703, -13.57943020450651, 0.0, 0.0, 0.0, -10.070357465557008, -0.3453889769288365, -60.0, -10.0, 0.0, 0.0, -30.0, -4.735953367646758, 0.0, 0.0, 0.0, -20.236727412721265, 0.0, -7.1175588320506105, 0.0, -4.2706106265119175, -30.0, -30.0, -15.60497061035611, -42.127084610596356, -20.0, 0.0, 0.0, 0.0, 0.0, -11.293350741538896, -20.477892822150697, 0.0, -0.011961837168887879, 0.0, -10.0, -10.0, -48.12115064800832, -13.657330905900022, -0.2912297588836721, -40.0, 0.0, -20.0, -21.694168794039392, -30.0, 0.0, 0.0, -6.324893467556719, -40.0, 0.0, -6.853993785391986, 0.0, -15.67448255869319, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -14.089827439805543, -20.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7076712230544218, "mean_inference_ms": 1.221440554003877, "mean_action_processing_ms": 0.2434153964500893, "mean_env_wait_ms": 0.5234167013993318, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006991330488228503, "StateBufferConnector_ms": 0.004013747344782323, "ViewRequirementAgentConnector_ms": 0.10389553176032172}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -53.86575490271628, "episode_return_mean": 19.12493990905331}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 191.45638289012498, "num_env_steps_trained_throughput_per_sec": 191.45638289012498, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 17846.789, "restore_workers_time_ms": 0.015, "training_step_time_ms": 17846.736, "sample_time_ms": 1294.92, "learn_time_ms": 16516.66, "learn_throughput": 242.18, "synch_weights_time_ms": 32.442}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-44-44", "timestamp": 1723139084, "time_this_iter_s": 20.90907096862793, "time_total_s": 521.5393488407135, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bced45e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 521.5393488407135, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 61.52068965517242, "ram_util_percent": 81.55517241379312}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1745990470051766, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3350419629365207, "policy_loss": -0.01879585207789205, "vf_loss": 3.351662203545372, "vf_explained_var": -0.011620397989948591, "kl": 0.010878055902471572, "entropy": 1.1667783549676338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7555513635806158, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.507789268688107, "policy_loss": -0.016645488848972486, "vf_loss": 2.522652556160663, "vf_explained_var": 1.3383779119937977e-06, "kl": 0.008910983226373265, "entropy": 1.1750842052571318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 80370.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -30.52102392626212, "episode_reward_mean": 21.95259869204772, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.91358024691358, "agent_policy": -13.788142048693025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [99.18597741646958, 0.0, 20.0, 0.0, -4.229086774865569, 0.0, 0.0, 0.0, -0.5621204623410125, 20.0, 0.0, 40.0, 60.0, -0.3053353259449676, -9.220296966675308, 12.57451543890656, 0.0, -23.736460720718718, -0.0870748276759159, 120.0, 40.0, 0.0, 0.0, 0.0, -1.343928905135251, -4.469569509704193, 0.0, 0.0, 60.0, 0.0, -19.39411151376175, 60.0, -2.0773889549959756, -8.843738178827708, -2.9712328532610375, 0.0, 0.0, -5.922223236820619, 0.0, 0.0, 0.0, 60.0, 40.0, 60.0, 0.0, 60.0, 60.0, -30.52102392626212, 40.0, -11.617202750873101, 60.0, -0.17111420259148136, 0.0, -13.635373504633604, 0.0, -5.05433073333043, 40.0, 0.0, 0.0, 0.0, 40.0, 0.0, 60.0, -19.744871397598324, -0.5523281177231099, -1.9527580791819221, 120.0, 0.0, 60.0, 0.0, 0.0, 140.0, 0.0, 0.0, 0.0, 79.87427523710426, 0.0, 0.0, 40.0, 99.71373695128814, 0.0, 40.0, 60.0, 60.0, 0.0, 0.0, 80.0, 0.0, 80.0, -2.9013063086635436, 60.0, 0.0, 60.0, 0.0, 80.0, 20.0, 20.0, 60.0, 38.217601148752536, 0.0, 0.0, -0.3736779974172877, 0.0, 20.0, -0.3998709238806408, 0.0, 75.23370847030222, 57.310361273372166, 0.0, 19.825534272332035, -0.5724046679929495, -23.103009648262937, 0.0, 40.0, 0.0, 120.0, 0.0, 0.0, 0.0, 0.0, 60.0, 80.0, -1.6417361221693794, 80.0, 120.0, 18.541485425348128, -7.498127323074667, 40.0, 0.0, -6.8271666658831185, 0.0, 180.0, 0.0, 0.0, 69.62999725941742, 0.0, -0.5205433841794993, 120.0, 60.0, 80.0, 0.0, 0.0, 0.0, 0.0, 18.444396805632923, 0.0, -8.703524604719913, 40.0, 0.0, -0.7752360303946138, 100.0, -24.48514275460453, 60.0, 0.0, 120.0, -3.3638750201739747, 0.0, -0.12426675555590072, 0.0, 0.0, -24.52914243730051, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-50.81402258353042, 0.0, -10.0, 0.0, -4.229086774865569, 0.0, 0.0, 0.0, -0.5621204623410125, -10.0, 0.0, -20.0, -30.0, -0.3053353259449676, -9.220296966675308, -17.425484561093437, 0.0, -23.736460720718718, -0.0870748276759159, -60.0, -20.0, 0.0, 0.0, 0.0, -1.343928905135251, -4.469569509704193, 0.0, 0.0, -30.0, 0.0, -19.39411151376175, -30.0, -2.0773889549959756, -8.843738178827708, -2.9712328532610375, 0.0, 0.0, -5.922223236820619, 0.0, 0.0, 0.0, -30.0, -20.0, -30.0, 0.0, -30.0, -30.0, -30.52102392626212, -20.0, -11.617202750873101, -30.0, -0.17111420259148136, 0.0, -13.635373504633604, 0.0, -5.05433073333043, -20.0, 0.0, 0.0, 0.0, -20.0, 0.0, -30.0, -19.744871397598324, -0.5523281177231099, -1.9527580791819221, -60.0, 0.0, -30.0, 0.0, 0.0, -70.0, 0.0, 0.0, 0.0, -40.125724762895736, 0.0, 0.0, -20.0, -50.28626304871186, 0.0, -20.0, -30.0, -30.0, 0.0, 0.0, -40.0, 0.0, -40.0, -2.9013063086635436, -30.0, 0.0, -30.0, 0.0, -40.0, -10.0, -10.0, -30.0, -21.782398851247464, 0.0, 0.0, -0.3736779974172877, 0.0, -10.0, -0.3998709238806408, 0.0, -44.766291529697774, -32.689638726627834, 0.0, -10.174465727667965, -0.5724046679929495, -23.103009648262937, 0.0, -20.0, 0.0, -60.0, 0.0, 0.0, 0.0, 0.0, -30.0, -40.0, -1.6417361221693794, -40.0, -60.0, -11.458514574651872, -7.498127323074667, -20.0, 0.0, -6.8271666658831185, 0.0, -90.0, 0.0, 0.0, -50.370002740582585, 0.0, -0.5205433841794993, -60.0, -30.0, -40.0, 0.0, 0.0, 0.0, 0.0, -11.555603194367077, 0.0, -8.703524604719913, -20.0, 0.0, -0.7752360303946138, -50.0, -24.48514275460453, -30.0, 0.0, -60.0, -3.3638750201739747, 0.0, -0.12426675555590072, 0.0, 0.0, -24.52914243730051, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.709188028766995, "mean_inference_ms": 1.2253884529456702, "mean_action_processing_ms": 0.24372454858211723, "mean_env_wait_ms": 0.5248541243174412, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005457062780121227, "StateBufferConnector_ms": 0.0035935713921064214, "ViewRequirementAgentConnector_ms": 0.10151009500762563}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -30.52102392626212, "episode_return_mean": 21.95259869204772}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 190.51863952251423, "num_env_steps_trained_throughput_per_sec": 190.51863952251423, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 18359.743, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18359.69, "sample_time_ms": 1294.326, "learn_time_ms": 17029.756, "learn_throughput": 234.883, "synch_weights_time_ms": 32.986}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-45-06", "timestamp": 1723139106, "time_this_iter_s": 21.00711488723755, "time_total_s": 542.546463727951, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d30700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 542.546463727951, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 61.906666666666666, "ram_util_percent": 81.86333333333337}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1457719293112556, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.464243021979928, "policy_loss": -0.019317496729005748, "vf_loss": 3.481451669211189, "vf_explained_var": -0.016436901999016602, "kl": 0.01054426937711265, "entropy": 1.1388899934788546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7625093693323169, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8564362911467858, "policy_loss": -0.0178534458192389, "vf_loss": 2.872321956292957, "vf_explained_var": 2.6251407379799702e-08, "kl": 0.009838879809896563, "entropy": 1.159197929903125, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 83190.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -29.64283718743365, "episode_reward_mean": 20.99996209514452, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.337579617834395, "agent_policy": -13.012776758358664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 120.0, -0.0004113740472511118, 37.05027964713753, 173.1407353505092, 40.0, -0.3811778916362052, 0.0, 0.0, -0.30027147924180375, 20.0, -29.64283718743365, -0.736862104260162, 0.0, 0.0, 60.0, -13.03880851417968, 40.0, 16.051363133731996, 80.0, 0.0, -1.5166768814422948, 0.0, 13.066050050414328, 40.0, 60.0, 60.0, 19.5894684136316, 0.0, -0.8758767664675848, -3.089261901992579, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 60.0, 120.0, 0.0, 80.0, 0.0, 60.0, -9.638128716345022, 200.0, 0.0, 0.0, 60.0, -19.12690987548799, -0.4146232896403679, 0.0, -7.437421156795261, 20.0, 0.0, 20.0, 0.0, 0.0, 60.0, 0.0, 0.0, 20.0, 60.0, 20.0, 20.0, -1.522500668866359, 40.0, 60.0, 40.0, -1.1398389979423706, 0.0, 18.08058439607437, 0.0, 100.0, 0.0, 6.296150899746014, 157.0194315648244, 0.0, 60.0, 0.0, 0.0, 20.0, 20.0, -1.540265497150316, 115.33094010111476, 0.0, 0.0, 0.0, -1.7725262275297604, 0.0, 40.0, 0.0, 60.0, 0.0, 0.0, 40.0, 0.0, 59.812979176400574, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0993847888170416, -15.864042292856531, 40.0, -4.176388302958005, 0.0, 0.0, 0.0, -0.39259894105015625, 58.386776653533346, -12.219587653469812, -0.6158241077833693, 0.0, 0.0, 40.0, 60.0, 0.0, 40.0, 80.0, 0.0, -0.5428003945027249, 0.0, 0.0, -18.04493696926814, 40.0, 60.0, 0.0, 0.0, -4.816039148316957, 38.0387289592895, 60.0, 60.0, -0.3484285528970321, 0.0, 0.0, 0.0, 40.0, -0.46837502477831694, 0.0, 140.0, -4.248802222658825, -5.735919600428147, 0.0, -28.939733111328117, -3.2449359593934295, -1.93724380775258, 60.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -60.0, -0.0004113740472511118, -22.949720352862467, -96.85926464949083, -20.0, -0.3811778916362052, 0.0, 0.0, -0.30027147924180375, -10.0, -29.64283718743365, -0.736862104260162, 0.0, 0.0, -30.0, -13.03880851417968, -20.0, -13.948636866268007, -40.0, 0.0, -1.5166768814422948, 0.0, -16.933949949585674, -20.0, -30.0, -30.0, -10.410531586368402, 0.0, -0.8758767664675848, -3.089261901992579, -10.0, -10.0, -10.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, -30.0, -60.0, 0.0, -40.0, 0.0, -30.0, -9.638128716345022, -100.0, 0.0, 0.0, -30.0, -19.12690987548799, -0.4146232896403679, 0.0, -7.437421156795261, -10.0, 0.0, -10.0, 0.0, 0.0, -30.0, 0.0, 0.0, -10.0, -30.0, -10.0, -10.0, -1.522500668866359, -20.0, -30.0, -20.0, -1.1398389979423706, 0.0, -11.919415603925628, 0.0, -50.0, 0.0, -23.703849100253983, -82.9805684351756, 0.0, -30.0, 0.0, 0.0, -10.0, -10.0, -1.540265497150316, -64.66905989888524, 0.0, 0.0, 0.0, -1.7725262275297604, 0.0, -20.0, 0.0, -30.0, 0.0, 0.0, -20.0, 0.0, -30.18702082359942, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0993847888170416, -15.864042292856531, -20.0, -4.176388302958005, 0.0, 0.0, 0.0, -0.39259894105015625, -31.613223346466658, -42.219587653469816, -0.6158241077833693, 0.0, 0.0, -20.0, -30.0, 0.0, -20.0, -40.0, 0.0, -0.5428003945027249, 0.0, 0.0, -18.04493696926814, -20.0, -30.0, 0.0, 0.0, -4.816039148316957, -21.961271040710496, -30.0, -30.0, -0.3484285528970321, 0.0, 0.0, 0.0, -20.0, -0.46837502477831694, 0.0, -70.0, -4.248802222658825, -5.735919600428147, 0.0, -28.939733111328117, -3.2449359593934295, -1.93724380775258, -30.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7067405757304178, "mean_inference_ms": 1.2212320717733296, "mean_action_processing_ms": 0.24291698783776308, "mean_env_wait_ms": 0.5235132465294057, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005552950938036487, "StateBufferConnector_ms": 0.0034708126335387017, "ViewRequirementAgentConnector_ms": 0.09109799269657985}, "num_episodes": 157, "episode_return_max": 200.0, "episode_return_min": -29.64283718743365, "episode_return_mean": 20.99996209514452}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 267.7672033145824, "num_env_steps_trained_throughput_per_sec": 267.7672033145824, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 18367.567, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18367.515, "sample_time_ms": 1288.018, "learn_time_ms": 17044.885, "learn_throughput": 234.675, "synch_weights_time_ms": 32.24}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-45-20", "timestamp": 1723139120, "time_this_iter_s": 14.946249008178711, "time_total_s": 557.4927127361298, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf233a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 557.4927127361298, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 38.90952380952382, "ram_util_percent": 81.54761904761905}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2532444230591258, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0828594842304784, "policy_loss": -0.014572694125187505, "vf_loss": 3.095813435067733, "vf_explained_var": -0.007244144131739934, "kl": 0.008093699616159314, "entropy": 1.1581465495129426, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7706859714807348, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.444690272698166, "policy_loss": -0.01685643674273635, "vf_loss": 2.4599770979678377, "vf_explained_var": 5.620591183926197e-07, "kl": 0.007848063141137219, "entropy": 1.1261672397877307, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 86010.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 240.0, "episode_reward_min": -28.795682791654578, "episode_reward_mean": 21.981163237396007, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.0}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.772151898734178, "agent_policy": -13.335292458806524}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 80.0, 0.0, 0.0, -1.9758280154995012, -7.772023373797226, 18.20776178223072, 40.0, 0.0, 0.0, 139.3933827227429, 0.0, -28.795682791654578, 0.0, 0.0, -4.200051184822165, 24.154034989712443, 0.0, -25.285125004312086, 40.0, 60.0, 0.0, 0.0, -1.179869769037999, 0.0, 0.0, -0.7748516073697143, 60.0, 18.018013809193093, -2.5039931133892255, -2.5764107788213866, 0.0, 0.0, -0.3047898896669865, 20.0, 35.26727797314399, -2.3992296094568752, 20.0, 0.0, 0.0, 0.0, 60.0, 20.0, 20.0, 20.0, -11.277253954879843, -13.367602693509802, 20.0, 0.0, 0.0, 0.0, 136.29856650925632, -2.3489912250041165, -2.9101581316980893, 60.0, 99.05179327606788, 40.0, 0.0, 120.0, 0.0, 20.0, -0.590945055347214, 40.0, 80.0, 60.0, -5.5040943770603175, 0.0, 0.0, 41.767315897284504, 0.0, 34.130403438421325, -0.7738324963947507, 0.0, 80.0, -0.3438615041641857, 60.0, 59.26046987862907, 0.0, 40.0, -0.034236233305250385, 0.0, 0.0, 0.0, 0.0, 60.0, 20.0, 79.7545671990737, 0.0, 60.0, 20.0, 40.0, -0.3220308863871102, 60.0, 77.21876556824982, -3.90901125131308, -4.047791472677825, -20.263365586207303, -0.2673727446935181, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 140.0, -0.32951755728526044, 0.0, 0.0, 0.0, 40.0, -0.045668573414193725, -1.6129455548314053, 0.0, 60.0, 60.0, -0.639711344141124, -4.135512321228688, -2.109377738923812, 0.0, 0.0, -10.664662974019084, 80.0, 40.0, -4.282552992886408, 40.0, 0.0, 0.0, 40.0, -1.0824319042457953, 0.0, 60.0, 0.0, 40.0, 40.0, 0.0, 60.0, -10.167311832079248, -0.15910544758889977, 0.0, 60.0, 0.0, 60.0, 0.0, 80.0, 40.0, 0.0, 40.0, 0.0, 34.21502665442746, 0.0, 240.0, 120.0, -2.598542012745912, 0.0, 40.0, 0.0, 0.0, -2.1578451860039705], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 120.0, 120.0, 120.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -40.0, 0.0, 0.0, -1.9758280154995012, -7.772023373797226, -11.792238217769283, -20.0, 0.0, 0.0, -70.6066172772571, 0.0, -28.795682791654578, 0.0, 0.0, -4.200051184822165, -35.84596501028757, 0.0, -25.285125004312086, -20.0, -30.0, 0.0, 0.0, -1.179869769037999, 0.0, 0.0, -0.7748516073697143, -30.0, -11.981986190806909, -2.5039931133892255, -2.5764107788213866, 0.0, 0.0, -0.3047898896669865, -10.0, -24.73272202685601, -2.3992296094568752, -10.0, 0.0, 0.0, 0.0, -30.0, -10.0, -10.0, -10.0, -11.277253954879843, -13.367602693509802, -10.0, 0.0, 0.0, 0.0, -73.7014334907437, -2.3489912250041165, -2.9101581316980893, -30.0, -50.94820672393211, -20.0, 0.0, -60.0, 0.0, -10.0, -0.590945055347214, -20.0, -40.0, -30.0, -5.5040943770603175, 0.0, 0.0, -48.232684102715496, 0.0, -25.869596561578675, -0.7738324963947507, 0.0, -40.0, -0.3438615041641857, -30.0, -30.739530121370926, 0.0, -20.0, -0.034236233305250385, 0.0, 0.0, 0.0, 0.0, -30.0, -10.0, -40.2454328009263, 0.0, -30.0, -10.0, -20.0, -0.3220308863871102, -30.0, -42.781234431750185, -3.90901125131308, -4.047791472677825, -20.263365586207303, -0.2673727446935181, -30.0, -30.0, 0.0, 0.0, 0.0, -20.0, -70.0, -0.32951755728526044, 0.0, 0.0, 0.0, -20.0, -0.045668573414193725, -1.6129455548314053, 0.0, -30.0, -30.0, -0.639711344141124, -4.135512321228688, -2.109377738923812, 0.0, 0.0, -10.664662974019084, -40.0, -20.0, -4.282552992886408, -20.0, 0.0, 0.0, -20.0, -1.0824319042457953, 0.0, -30.0, 0.0, -20.0, -20.0, 0.0, -30.0, -10.167311832079248, -0.15910544758889977, 0.0, -30.0, 0.0, -30.0, 0.0, -40.0, -20.0, 0.0, -20.0, 0.0, -25.78497334557254, 0.0, -120.0, -60.0, -2.598542012745912, 0.0, -20.0, 0.0, 0.0, -2.1578451860039705]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7045022985669677, "mean_inference_ms": 1.2173628818716702, "mean_action_processing_ms": 0.24245476281542236, "mean_env_wait_ms": 0.5223943413025389, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004691715481915051, "StateBufferConnector_ms": 0.0035777876648721814, "ViewRequirementAgentConnector_ms": 0.09399478948568996}, "num_episodes": 158, "episode_return_max": 240.0, "episode_return_min": -28.795682791654578, "episode_return_mean": 21.981163237396007}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.9192955966375, "num_env_steps_trained_throughput_per_sec": 268.9192955966375, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 18293.862, "restore_workers_time_ms": 0.014, "training_step_time_ms": 18293.812, "sample_time_ms": 1280.934, "learn_time_ms": 16977.904, "learn_throughput": 235.6, "synch_weights_time_ms": 32.515}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-45-35", "timestamp": 1723139135, "time_this_iter_s": 14.881534099578857, "time_total_s": 572.3742468357086, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bced4af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 572.3742468357086, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 34.5047619047619, "ram_util_percent": 81.9047619047619}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2206720033039649, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9723911645511785, "policy_loss": -0.01687898510620774, "vf_loss": 3.98724139581124, "vf_explained_var": 0.0018784267206986744, "kl": 0.01014376338660945, "entropy": 1.1583943990369638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7774540297000121, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0827345723378743, "policy_loss": -0.016104992066761015, "vf_loss": 3.0973422721768102, "vf_explained_var": 3.2535258759843545e-07, "kl": 0.007486453538633781, "entropy": 1.0989385729985879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 88830.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -36.48885279043933, "episode_reward_mean": 23.188978513655126, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.839506172839506, "agent_policy": -15.329540004863393}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -2.374262415554549, 100.0, 60.0, -0.3332807631657997, 40.0, 0.0, 18.61620708812874, -16.281122403566336, 0.0, 60.0, 0.0, 20.0, 0.0, -4.361521451364552, 0.0, 80.0, -1.8006215615558074, -22.398304625062924, 134.57153830375142, 40.0, 0.0, -12.766531234536348, -0.8182427870338771, 80.0, 0.0, 100.0, 0.0, 60.0, 40.0, 52.36551703833728, 0.0, 20.0, 0.0, 0.0, 32.32830541225301, -0.8049962297944913, -0.6613153889154655, 0.0, 100.0, 0.0, -31.45166694541664, -36.48885279043933, 0.0, 40.0, 11.18512083839406, 40.0, 0.0, 0.0, 80.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -10.438610631659355, -11.851101965035475, 0.0, 160.0, -0.600703186594036, -0.26186211696084927, 39.98986109785663, -9.774719175483057, 6.278570324148937, 60.0, 0.0, 0.0, 60.0, 40.0, -22.058905393955776, 58.246096062246124, 80.0, -2.1380476817268077, 120.0, 0.0, 0.0, 0.0, 40.0, 0.0, 60.0, 0.0, 40.0, 0.0, 60.0, 39.537780649523626, 40.0, 20.0, 20.0, -3.9155307619072346, 60.0, 60.0, 0.0, 0.0, -0.8546935702294367, 0.0, -0.23508511503709584, 13.392483848465027, 0.0, 0.0, 0.0, 40.0, -0.20929634679110243, -16.42856370958136, -5.639529501015126, -4.046388044333878, 80.0, 18.84166990579071, -3.81553332268834, 20.0, 80.0, -0.8020398831361719, 160.0, 20.0, 11.678878949133235, -11.212303146930498, -29.786482179769003, 60.0, 40.0, 40.0, 100.0, -0.5146484915046745, -0.7271272435485809, -0.4329896983695891, -0.08779623015740312, 40.0, 80.0, 40.0, 60.0, -0.7687946425037206, -0.21156450037484453, 0.0, -2.3294279922859813, 26.772056539591574, -3.443150300196071, 117.78121474821526, 0.0, 59.26694564326533, 60.0, 40.0, 50.675702537640475, -9.279574038854236, -18.901085824365634, 20.0, -5.679964510155582, 100.0, 0.0, -0.8692750776151359, 0.0, 140.0, 40.0, -0.25409870055187356, 0.0, -0.09899953444198029, 120.0, 0.0, 0.0, 40.0, 0.0, -6.704818660445349, 40.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -2.374262415554549, -50.0, -30.0, -0.3332807631657997, -20.0, 0.0, -11.38379291187126, -16.281122403566336, 0.0, -30.0, 0.0, -10.0, 0.0, -4.361521451364552, 0.0, -40.0, -1.8006215615558074, -22.398304625062924, -75.4284616962486, -20.0, 0.0, -12.766531234536348, -0.8182427870338771, -40.0, 0.0, -50.0, 0.0, -30.0, -20.0, -37.63448296166273, 0.0, -10.0, 0.0, 0.0, -27.67169458774699, -0.8049962297944913, -0.6613153889154655, 0.0, -50.0, 0.0, -31.45166694541664, -36.48885279043933, 0.0, -20.0, -18.81487916160594, -20.0, 0.0, 0.0, -40.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -10.438610631659355, -11.851101965035475, 0.0, -80.0, -0.600703186594036, -0.26186211696084927, -20.010138902143368, -9.774719175483057, -23.721429675851063, -30.0, 0.0, 0.0, -30.0, -20.0, -22.058905393955776, -31.753903937753883, -40.0, -2.1380476817268077, -60.0, 0.0, 0.0, 0.0, -20.0, 0.0, -30.0, 0.0, -20.0, 0.0, -30.0, -20.462219350476374, -20.0, -10.0, -10.0, -3.9155307619072346, -30.0, -30.0, 0.0, 0.0, -0.8546935702294367, 0.0, -0.23508511503709584, -16.60751615153497, 0.0, 0.0, 0.0, -20.0, -0.20929634679110243, -16.42856370958136, -5.639529501015126, -4.046388044333878, -40.0, -11.158330094209289, -3.81553332268834, -10.0, -40.0, -0.8020398831361719, -80.0, -10.0, -18.321121050866765, -11.212303146930498, -29.786482179769003, -30.0, -20.0, -20.0, -50.0, -0.5146484915046745, -0.7271272435485809, -0.4329896983695891, -0.08779623015740312, -20.0, -40.0, -20.0, -30.0, -0.7687946425037206, -0.21156450037484453, 0.0, -2.3294279922859813, -33.22794346040841, -3.443150300196071, -62.21878525178474, 0.0, -30.733054356734662, -30.0, -20.0, -39.324297462359525, -9.279574038854236, -18.901085824365634, -10.0, -5.679964510155582, -50.0, 0.0, -0.8692750776151359, 0.0, -70.0, -20.0, -0.25409870055187356, 0.0, -0.09899953444198029, -60.0, 0.0, 0.0, -20.0, 0.0, -6.704818660445349, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7032041808366477, "mean_inference_ms": 1.2161326100766499, "mean_action_processing_ms": 0.2423276087537579, "mean_env_wait_ms": 0.5218706411532678, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005181188936586733, "StateBufferConnector_ms": 0.003938542471991645, "ViewRequirementAgentConnector_ms": 0.10151944042723855}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -36.48885279043933, "episode_return_mean": 23.188978513655126}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 138.55279329017702, "num_env_steps_trained_throughput_per_sec": 138.55279329017702, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 19637.568, "restore_workers_time_ms": 0.014, "training_step_time_ms": 19637.519, "sample_time_ms": 1272.778, "learn_time_ms": 18331.649, "learn_throughput": 218.202, "synch_weights_time_ms": 31.238}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-46-04", "timestamp": 1723139164, "time_this_iter_s": 28.886777877807617, "time_total_s": 601.2610247135162, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f13a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 601.2610247135162, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 72.93170731707316, "ram_util_percent": 82.42682926829268}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2079473414768775, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7358804480483134, "policy_loss": -0.017135649289897022, "vf_loss": 3.7511895172297955, "vf_explained_var": -0.0057718959326545395, "kl": 0.009132858118971798, "entropy": 1.1656180976579587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7613729952814731, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.07623957099644, "policy_loss": -0.015059046262085887, "vf_loss": 3.0898437498309086, "vf_explained_var": -3.0698505699211824e-07, "kl": 0.00727431796021742, "entropy": 1.0726804264259677, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 91650.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -29.60477447162881, "episode_reward_mean": 32.27896509409563, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 16.97530864197531, "agent_policy": -18.646960831830288}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 40.0, 220.0, 0.0, -0.28550266848215267, 0.0, 0.0, 0.0, 0.0, 40.0, -2.2487131301288326, 20.0, -29.299291802933546, 59.262095978858, 40.0, 60.0, 0.0, 0.0, -1.2356787581718731, 27.992556684577707, 100.0, 0.0, -8.84957898151041, 0.0, 0.0, -5.838277565306817, 80.0, -1.3250451356069048, 40.0, 0.0, 60.0, 80.0, 0.0, -25.199965515303308, 60.0, 39.772691845544074, 0.0, 0.0, 80.0, 0.0, 0.0, 60.0, 0.0, 0.0, 60.0, 80.0, -0.788283985090894, 140.0, -0.8298280669133662, 100.0, 40.0, 0.0, 80.0, 60.0, 60.0, -8.338843374535026, 0.0, 200.0, 0.0, 0.0, 200.0, -10.245124754857475, -9.279377862297226, 0.0, 140.0, 80.0, -24.48312331227391, -12.434286891059932, 0.0, -4.4462559964271575, 120.0, 0.0, -29.60477447162881, -6.328939547121529, 0.0, 35.915458077318675, 60.0, 120.0, 60.0, -7.295305461174834, 0.0, 56.24587145846915, 0.0, 160.0, 0.0, -4.598192826936394, -2.427287912029417, 60.0, 0.0, 40.0, 60.0, 0.0, 199.43977183711308, -10.246124995488897, 60.0, 138.6744039467807, 59.80429501580764, 40.0, 80.0, 60.0, 0.0, 0.0, 0.0, -3.4374449625666235, -0.1422269306621926, 0.0, 0.0, 0.0, 59.95152351383034, 0.0, 200.0, 0.0, -1.471889492851588, 0.0, 60.0, 140.0, 0.0, 0.0, 100.0, 0.0, 20.0, 51.44045091272181, 40.0, 0.0, 0.0, 0.0, 180.0, 0.0, 120.0, 60.0, 0.0, 0.0, 60.0, 0.0, 60.0, 16.99339078865954, 18.462257427041376, 60.0, 0.0, 0.0, 0.0, 0.0, -0.7967184437502917, 0.0, 0.0, -2.894406158280227, 20.0, -0.8505525846294171, 0.0, 20.0, 0.0, 40.0, 40.0, -0.0258597629570112, 220.0, 60.0, -19.515520892253374], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 110.0, 110.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -20.0, -110.0, 0.0, -0.28550266848215267, 0.0, 0.0, 0.0, 0.0, -20.0, -2.2487131301288326, -10.0, -29.299291802933546, -30.737904021142, -20.0, -30.0, 0.0, 0.0, -1.2356787581718731, -32.00744331542229, -50.0, 0.0, -8.84957898151041, 0.0, 0.0, -5.838277565306817, -40.0, -1.3250451356069048, -20.0, 0.0, -30.0, -40.0, 0.0, -25.199965515303308, -30.0, -20.227308154455926, 0.0, 0.0, -40.0, 0.0, 0.0, -30.0, 0.0, 0.0, -30.0, -40.0, -0.788283985090894, -70.0, -0.8298280669133662, -50.0, -20.0, 0.0, -40.0, -30.0, -30.0, -8.338843374535026, 0.0, -100.0, 0.0, 0.0, -100.0, -10.245124754857475, -9.279377862297226, 0.0, -70.0, -40.0, -24.48312331227391, -12.434286891059932, 0.0, -4.4462559964271575, -60.0, 0.0, -29.60477447162881, -6.328939547121529, 0.0, -24.084541922681325, -30.0, -60.0, -30.0, -7.295305461174834, 0.0, -33.75412854153085, 0.0, -80.0, 0.0, -4.598192826936394, -2.427287912029417, -30.0, 0.0, -20.0, -30.0, 0.0, -100.5602281628869, -10.246124995488897, -30.0, -71.3255960532193, -30.195704984192368, -20.0, -40.0, -30.0, 0.0, 0.0, 0.0, -3.4374449625666235, -0.1422269306621926, 0.0, 0.0, 0.0, -30.04847648616966, 0.0, -100.0, 0.0, -1.471889492851588, 0.0, -30.0, -70.0, 0.0, 0.0, -50.0, 0.0, -10.0, -38.55954908727819, -20.0, 0.0, 0.0, 0.0, -90.0, 0.0, -60.0, -30.0, 0.0, 0.0, -30.0, 0.0, -30.0, -13.006609211340459, -11.537742572958624, -30.0, 0.0, 0.0, 0.0, 0.0, -0.7967184437502917, 0.0, 0.0, -2.894406158280227, -10.0, -0.8505525846294171, 0.0, -10.0, 0.0, -20.0, -20.0, -0.0258597629570112, -110.0, -30.0, -19.515520892253374]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.704582845228975, "mean_inference_ms": 1.2199828783419546, "mean_action_processing_ms": 0.24284337035796869, "mean_env_wait_ms": 0.5229891552404466, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005159701830075111, "StateBufferConnector_ms": 0.00479596632498282, "ViewRequirementAgentConnector_ms": 0.10980551625475471}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -29.60477447162881, "episode_return_mean": 32.27896509409563}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 232.66898090065632, "num_env_steps_trained_throughput_per_sec": 232.66898090065632, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 19850.944, "restore_workers_time_ms": 0.014, "training_step_time_ms": 19850.894, "sample_time_ms": 1295.527, "learn_time_ms": 18522.913, "learn_throughput": 215.949, "synch_weights_time_ms": 30.06}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-46-22", "timestamp": 1723139182, "time_this_iter_s": 17.24099588394165, "time_total_s": 618.5020205974579, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf07430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 618.5020205974579, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 44.74800000000001, "ram_util_percent": 82.068}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3385227125758925, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.770225873962045, "policy_loss": -0.015187011990443958, "vf_loss": 3.7838319800794125, "vf_explained_var": -0.010040760847429435, "kl": 0.007904541734520269, "entropy": 1.1104605332016946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7793094825871447, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7021334765227976, "policy_loss": -0.013922122534255477, "vf_loss": 2.714760638128781, "vf_explained_var": -1.9204743365024e-06, "kl": 0.0064747985173822815, "entropy": 1.0563344244415878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 94470.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 168.91665893159936, "episode_reward_min": -32.1344946623618, "episode_reward_mean": 23.595766353627848, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -101.08334106840067}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.248407643312103, "agent_policy": -16.149456576308456}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -3.9419594785044865, 0.0, 98.29208932555238, 100.0, 80.0, 36.47008638768125, 60.0, 0.0, -1.6659566488387523, 0.0, 0.0, -0.9536943648598917, 40.0, 0.0, 60.0, 20.0, 0.0, 100.0, -5.6646795918620025, 0.0, -1.8730817570634073, 98.01508004599455, 100.0, 16.626924876677208, 60.0, 0.0, 0.0, 0.0, 58.91270132017931, 0.0, 95.42753901955453, 60.0, 0.0, 60.0, 60.0, 0.0, 0.0, -12.728361493058697, 52.50408988609307, 20.0, 58.57511313551878, 0.0, 0.0, 59.75869927941217, 0.0, 0.0, -0.23195858636921418, -3.3052724172330894, -0.7835105378006035, 0.0, -0.9400738057676195, 117.77051583326244, 0.0, -13.987259687817682, -0.12067438008229847, 0.0, 40.0, 20.0, 0.0, 0.0, 20.0, 34.30423688116569, 60.0, 0.0, 60.0, 80.0, 80.0, 0.0, 0.0, 168.91665893159936, 0.0, -2.466059022101771, 0.0, 0.0, 0.0, -18.67557813407431, 0.0, -15.928915975232531, 0.0, 0.0, -10.13647887692438, 0.0, -16.29333341998104, -13.461375401501952, -15.008862112570624, -1.4581115415634105, -20.253685533358606, 0.0, 0.0, 0.0, 60.0, -15.225242432089416, 59.02659571106159, 20.0, 0.0, -6.62889738579608, 60.0, 0.0, -0.15428440446127234, 99.29073021283736, -17.890309249861378, 40.0, 60.0, 0.0, 60.0, 0.0, 60.0, 0.0, 0.0, 79.83332605786072, 59.15401106270879, 60.0, 0.0, -21.82964355922817, 0.0, 0.0, 0.0, -1.641224096520817, 15.942770199333367, 0.0, 100.0, 80.0, 0.0, 27.384455014920146, 0.0, 20.0, 100.0, 18.172117946471257, -2.9272607597695783, -1.0039189002959836, 0.0, 0.0, 60.0, 54.606297937790174, 60.0, 0.0, -12.646038684711915, 0.0, 79.35969268975191, 100.0, 0.0, 60.0, 0.0, -1.455145361205381, -15.678374303026963, 120.0, 140.0, 16.726274244487666, 0.0, 31.33811568801382, -2.7790876024601827, -32.1344946623618, 40.0, 0.0, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [0.0, 0.0, -3.9419594785044865, 0.0, -51.707910674447625, -50.0, -40.0, -83.52991361231877, -30.0, 0.0, -1.6659566488387523, 0.0, 0.0, -0.9536943648598917, -20.0, 0.0, -30.0, -10.0, 0.0, -50.0, -5.6646795918620025, 0.0, -1.8730817570634073, -51.984919954005456, -50.0, -13.373075123322794, -30.0, 0.0, 0.0, 0.0, -31.08729867982069, 0.0, -54.57246098044548, -30.0, 0.0, -30.0, -30.0, 0.0, 0.0, -12.728361493058697, -37.49591011390693, -10.0, -31.42488686448123, 0.0, 0.0, -30.241300720587834, 0.0, 0.0, -0.23195858636921418, -3.3052724172330894, -0.7835105378006035, 0.0, -0.9400738057676195, -62.22948416673758, 0.0, -43.98725968781769, -0.12067438008229847, 0.0, -20.0, -10.0, 0.0, 0.0, -10.0, -25.695763118834307, -30.0, 0.0, -30.0, -40.0, -40.0, 0.0, 0.0, -101.08334106840067, 0.0, -2.466059022101771, 0.0, 0.0, 0.0, -18.67557813407431, 0.0, -15.928915975232531, 0.0, 0.0, -10.13647887692438, 0.0, -16.29333341998104, -13.461375401501952, -15.008862112570624, -1.4581115415634105, -20.253685533358606, 0.0, 0.0, 0.0, -30.0, -15.225242432089416, -30.973404288938404, -10.0, 0.0, -6.62889738579608, -30.0, 0.0, -0.15428440446127234, -50.70926978716265, -17.890309249861378, -20.0, -30.0, 0.0, -30.0, 0.0, -30.0, 0.0, 0.0, -40.16667394213928, -30.845988937291214, -30.0, 0.0, -21.82964355922817, 0.0, 0.0, 0.0, -1.641224096520817, -14.057229800666633, 0.0, -50.0, -40.0, 0.0, -32.61554498507985, 0.0, -10.0, -50.0, -11.827882053528741, -2.9272607597695783, -1.0039189002959836, 0.0, 0.0, -30.0, -35.39370206220982, -30.0, 0.0, -12.646038684711915, 0.0, -40.6403073102481, -50.0, 0.0, -30.0, 0.0, -1.455145361205381, -15.678374303026963, -60.0, -70.0, -13.273725755512338, 0.0, -58.661884311986185, -2.7790876024601827, -32.1344946623618, -20.0, 0.0, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7032431215628463, "mean_inference_ms": 1.2180587675572532, "mean_action_processing_ms": 0.24249211266110043, "mean_env_wait_ms": 0.5224896715586685, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004368906567810448, "StateBufferConnector_ms": 0.0034573731149078173, "ViewRequirementAgentConnector_ms": 0.09503873290529677}, "num_episodes": 157, "episode_return_max": 168.91665893159936, "episode_return_min": -32.1344946623618, "episode_return_mean": 23.595766353627848}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 262.38028164300334, "num_env_steps_trained_throughput_per_sec": 262.38028164300334, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 19897.775, "restore_workers_time_ms": 0.014, "training_step_time_ms": 19897.725, "sample_time_ms": 1299.545, "learn_time_ms": 18568.065, "learn_throughput": 215.424, "synch_weights_time_ms": 27.934}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-46-37", "timestamp": 1723139197, "time_this_iter_s": 15.251698970794678, "time_total_s": 633.7537195682526, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf079d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 633.7537195682526, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 33.69047619047619, "ram_util_percent": 81.20476190476188}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3168450290958087, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.946129430582126, "policy_loss": -0.018311864559655076, "vf_loss": 3.9624737200637656, "vf_explained_var": 0.00012956447899341582, "kl": 0.009837857941625571, "entropy": 1.1438243226458629, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7534631445898232, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.012982591077791, "policy_loss": -0.015971998690713383, "vf_loss": 3.0274453309410854, "vf_explained_var": -7.349548610389655e-07, "kl": 0.007546290588253755, "entropy": 1.042324159838629, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 97290.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 238.1752604574528, "episode_reward_min": -45.80825979348518, "episode_reward_mean": 23.068447366137324, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -121.8247395425472}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.654320987654321, "agent_policy": -14.894515596825636}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -8.008113370607532, 120.0, 0.0, -1.25958921986691, 0.0, 60.0, 80.0, 40.0, 20.0, 0.0, 16.833773120012662, 60.0, 0.0, 0.0, 60.0, 20.0, -1.9424815227115022, 40.0, 80.0, 40.0, 0.0, 20.0, -9.532563270349817, 0.0, -2.9324796198170473, 0.0, 40.0, 57.71393469829021, 0.0, 20.0, -13.375099783333836, 0.0, 40.0, -21.601429348502492, 0.0, 0.0, 20.0, -12.591506975449038, 60.0, 0.0, 0.0, -12.470956991071088, 0.0, 19.233390885753618, 20.0, 0.0, 120.0, -0.8667875795697444, -8.231037962824324, 0.0, 0.0, 0.0, 0.0, 57.144526800658014, 0.0, -0.7813437937133849, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 60.0, 0.0, -2.6980703578346645, -6.335618121013137, -14.71451405402302, 0.0, 60.0, 60.0, -12.963911915582052, 0.0, 100.0, 0.0, -2.461934342822265, 238.1752604574528, 34.35917972675445, -0.8736478830983507, -0.03340903235046433, -4.275695401337992, -12.031882172143774, -0.6413931767683623, 0.0, 0.0, 59.95083818550545, 0.0, -45.80825979348518, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 100.0, -9.876133302586517, -3.5565422392924306, 100.0, 60.0, 20.0, 119.33583284708459, 60.0, 0.0, 100.0, 0.0, 0.5356353278843349, 0.0, 0.0, 20.0, -11.87728211476179, 60.0, 79.90136729370164, 120.0, 20.0, -5.6750525190726435, 60.0, 66.68930476456045, 20.0, 40.0, 0.0, 0.0, 55.980535427989295, -10.77474584501918, 0.0, 18.791545449437777, -10.841660409921431, 38.8858721983453, 99.46319198919022, 40.0, 0.0, -5.263880634884012, 0.0, 0.0, 20.0, 40.0, 20.0, 59.88675806706433, 100.0, 0.0, 0.0, 60.0, 0.0, 0.0, 40.0, 20.0, 0.0, -6.103983361948101, 0.0, 80.0, 60.0, 40.0, 0.0, 80.0, 0.0, 120.0, -1.0381152452488451, 60.0, 0.0, 60.0, -4.353352564427317, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 120.0, 120.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -8.008113370607532, -60.0, 0.0, -1.25958921986691, 0.0, -30.0, -40.0, -20.0, -10.0, 0.0, -13.166226879987338, -30.0, 0.0, 0.0, -30.0, -10.0, -1.9424815227115022, -20.0, -40.0, -20.0, 0.0, -10.0, -9.532563270349817, 0.0, -2.9324796198170473, 0.0, -20.0, -32.28606530170978, 0.0, -10.0, -13.375099783333836, 0.0, -20.0, -21.601429348502492, 0.0, 0.0, -10.0, -42.591506975449036, -30.0, 0.0, 0.0, -12.470956991071088, 0.0, -10.766609114246382, -10.0, 0.0, -60.0, -0.8667875795697444, -8.231037962824324, 0.0, 0.0, 0.0, 0.0, -32.85547319934199, 0.0, -0.7813437937133849, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -30.0, 0.0, -2.6980703578346645, -6.335618121013137, -14.71451405402302, 0.0, -30.0, -30.0, -12.963911915582052, 0.0, -50.0, 0.0, -2.461934342822265, -121.8247395425472, -25.64082027324555, -0.8736478830983507, -0.03340903235046433, -4.275695401337992, -42.031882172143774, -0.6413931767683623, 0.0, 0.0, -30.049161814494553, 0.0, -45.80825979348518, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -50.0, -9.876133302586517, -3.5565422392924306, -50.0, -30.0, -10.0, -60.66416715291541, -30.0, 0.0, -50.0, 0.0, -29.464364672115668, 0.0, 0.0, -10.0, -11.87728211476179, -30.0, -40.09863270629837, -60.0, -10.0, -5.6750525190726435, -30.0, -53.31069523543955, -10.0, -20.0, 0.0, 0.0, -34.019464572010705, -10.77474584501918, 0.0, -11.208454550562221, -10.841660409921431, -21.114127801654703, -50.536808010809786, -20.0, 0.0, -5.263880634884012, 0.0, 0.0, -10.0, -20.0, -10.0, -30.113241932935672, -50.0, 0.0, 0.0, -30.0, 0.0, 0.0, -20.0, -10.0, 0.0, -6.103983361948101, 0.0, -40.0, -30.0, -20.0, 0.0, -40.0, 0.0, -60.0, -1.0381152452488451, -30.0, 0.0, -30.0, -4.353352564427317, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7009016598669953, "mean_inference_ms": 1.215172193813872, "mean_action_processing_ms": 0.241907980005815, "mean_env_wait_ms": 0.5214774000603145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005484510351110388, "StateBufferConnector_ms": 0.003184286164648739, "ViewRequirementAgentConnector_ms": 0.09257307759037724}, "num_episodes": 162, "episode_return_max": 238.1752604574528, "episode_return_min": -45.80825979348518, "episode_return_mean": 23.068447366137324}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 263.02179826426664, "num_env_steps_trained_throughput_per_sec": 263.02179826426664, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 19555.867, "restore_workers_time_ms": 0.014, "training_step_time_ms": 19555.823, "sample_time_ms": 1291.317, "learn_time_ms": 18240.743, "learn_throughput": 219.289, "synch_weights_time_ms": 22.59}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-46-52", "timestamp": 1723139212, "time_this_iter_s": 15.216130018234253, "time_total_s": 648.9698495864868, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d33160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 648.9698495864868, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 31.977272727272727, "ram_util_percent": 80.3409090909091}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.544386756233871, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.032978261758884, "policy_loss": -0.019971899780405995, "vf_loss": 4.051021953175465, "vf_explained_var": 0.006420144935448965, "kl": 0.009641021165005863, "entropy": 1.1266657536228497, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7768862940846606, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.757079900748341, "policy_loss": -0.017322628177596746, "vf_loss": 2.77282801422667, "vf_explained_var": -9.140647049491287e-07, "kl": 0.00787256762117294, "entropy": 1.028027507810728, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 100110.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -32.966143462499275, "episode_reward_mean": 23.711475807796184, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.417721518987342, "agent_policy": -16.54168874916584}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 80.0, 0.0, 0.0, 38.75560803322588, 39.265743526611686, 0.0, 100.0, -20.670451450776344, 60.0, -7.302400253817215, 11.103865551533104, 40.0, -1.6419361144139188, 0.0, 20.0, -0.2537640642001515, 0.0, -8.945483973998332, 0.0, 80.0, 0.0, 80.0, 0.0, -12.96888946822157, -0.06127683966828501, 0.0, 60.0, 0.0, 48.16327149478349, 49.73396485121582, 39.883875667703194, 0.0, 0.0, 99.97133995021959, 0.0, -18.293299684386742, 140.0, 60.0, 12.908554890966094, 0.0, -13.68864413994853, 40.0, 20.0, -20.53733939485999, 0.0, 40.0, 0.0, 60.0, 40.0, 39.27957118927014, 60.0, 59.504841334885214, 0.0, 40.0, 0.0, -10.211976565042221, 0.0, 32.99522663182035, -1.8743324336472122, 80.0, -1.8003140704052545, 80.0, 0.0, 52.78514985021444, -3.717242415565253, 120.0, 0.0, 32.194134005855915, 0.0, -13.191546982472799, -3.7242209479088144, -4.054993743513667, 0.0, 140.0, 44.54876147771196, 40.0, -3.725401508896367, 60.0, 60.0, 0.0, -4.411020157835494, 38.60319665636692, 17.339009238913015, -3.561661584640178, 99.02949442174662, 0.0, -0.19978991124126488, -3.6453549986771456, -4.8146587007442285, 60.0, 0.0, 0.0, -16.40855213538316, -27.42423504684157, 60.0, 40.0, -6.99631355185214, -0.013530280972184894, 59.480763678440525, -5.76642455791662, 0.0, -10.62427352416503, -6.88328920330935, 40.0, -11.775297487402522, 0.0, 100.0, 38.45554555628331, 40.0, 0.0, 20.0, 0.0, 60.0, 16.123430607421746, 0.0, 80.0, -31.022753276604405, -13.134738688338064, 0.0, -1.5559057267296184, 40.0, 0.0, 0.0, 80.0, 0.0, 140.0, -4.471118794534259, 0.0, 40.0, -22.27421068108786, 60.0, 0.0, 100.0, 80.0, 99.97726116487443, -0.8566148604583601, 60.0, 57.07900200107997, 80.0, 0.0, 0.0, 18.308562691274158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.59302556072686, 0.0, 0.0, -1.335607056126129, 120.0, 40.0, 0.0, -1.8650146622457198, -32.966143462499275], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -40.0, 0.0, 0.0, -21.244391966774117, -20.734256473388317, 0.0, -50.0, -20.670451450776344, -30.0, -7.302400253817215, -18.896134448466896, -20.0, -1.6419361144139188, 0.0, -10.0, -0.2537640642001515, 0.0, -8.945483973998332, 0.0, -40.0, 0.0, -40.0, 0.0, -12.96888946822157, -0.06127683966828501, 0.0, -30.0, 0.0, -41.83672850521651, -40.26603514878418, -20.11612433229681, 0.0, 0.0, -50.02866004978041, 0.0, -18.293299684386742, -70.0, -30.0, -17.091445109033906, 0.0, -13.68864413994853, -20.0, -10.0, -20.53733939485999, 0.0, -20.0, 0.0, -30.0, -20.0, -20.720428810729857, -30.0, -30.495158665114786, 0.0, -20.0, 0.0, -10.211976565042221, 0.0, -27.00477336817965, -1.8743324336472122, -40.0, -1.8003140704052545, -40.0, 0.0, -37.21485014978557, -3.717242415565253, -60.0, 0.0, -27.80586599414408, 0.0, -13.191546982472799, -3.7242209479088144, -4.054993743513667, 0.0, -70.0, -45.45123852228804, -20.0, -3.725401508896367, -30.0, -30.0, 0.0, -4.411020157835494, -21.39680334363308, -12.660990761086987, -3.561661584640178, -50.97050557825339, 0.0, -0.19978991124126488, -3.6453549986771456, -4.8146587007442285, -30.0, 0.0, 0.0, -16.40855213538316, -27.42423504684157, -30.0, -20.0, -6.99631355185214, -0.013530280972184894, -30.519236321559468, -5.76642455791662, 0.0, -10.62427352416503, -6.88328920330935, -20.0, -41.77529748740252, 0.0, -50.0, -21.54445444371669, -20.0, 0.0, -10.0, 0.0, -30.0, -43.87656939257825, 0.0, -40.0, -31.022753276604405, -13.134738688338064, 0.0, -1.5559057267296184, -20.0, 0.0, 0.0, -40.0, 0.0, -70.0, -4.471118794534259, 0.0, -20.0, -22.27421068108786, -30.0, 0.0, -50.0, -40.0, -50.02273883512557, -0.8566148604583601, -30.0, -32.920997998920036, -40.0, 0.0, 0.0, -11.691437308725842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -60.40697443927314, 0.0, 0.0, -1.335607056126129, -60.0, -20.0, 0.0, -1.8650146622457198, -32.966143462499275]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6996842778266582, "mean_inference_ms": 1.2134537258676796, "mean_action_processing_ms": 0.2416334605737868, "mean_env_wait_ms": 0.5209897185520983, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004912931707840931, "StateBufferConnector_ms": 0.0032452842857264266, "ViewRequirementAgentConnector_ms": 0.09444884107082704}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -32.966143462499275, "episode_return_mean": 23.711475807796184}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.7058811387296, "num_env_steps_trained_throughput_per_sec": 253.7058811387296, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 18598.719, "restore_workers_time_ms": 0.013, "training_step_time_ms": 18598.679, "sample_time_ms": 1261.723, "learn_time_ms": 17315.289, "learn_throughput": 231.01, "synch_weights_time_ms": 20.442}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-47-08", "timestamp": 1723139228, "time_this_iter_s": 15.774034261703491, "time_total_s": 664.7438838481903, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf074c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 664.7438838481903, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 35.94090909090909, "ram_util_percent": 80.33181818181819}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.680216671153903, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9276296003411213, "policy_loss": -0.013671744039311307, "vf_loss": 3.9398560856779414, "vf_explained_var": -0.009302434511482716, "kl": 0.00722626861804961, "entropy": 1.131222918132941, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8036031780936194, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9024739823020096, "policy_loss": -0.016487324741299113, "vf_loss": 2.917414671943543, "vf_explained_var": -2.426458588728668e-07, "kl": 0.007733170370838481, "entropy": 1.0403794093334928, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 102930.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -25.474835151165887, "episode_reward_mean": 22.786527999124498, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.469135802469136, "agent_policy": -14.620879408282908}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 0.0, -19.125895292699056, -11.745030451798852, 19.195648946355824, 0.0, -3.9483783635743865, 40.0, 0.0, -4.028655301109355, 35.86382391352827, 0.0, 77.77649745019578, 100.0, -10.237906378598527, 0.0, 80.0, 0.0, 140.0, 0.0, -7.54732281538715, 0.0, 0.0, 60.0, 60.0, -0.6470921472789071, 0.0, 40.0, 160.0, 60.0, 0.0, 0.0, 60.0, 30.517199275408608, 120.0, 60.0, 60.0, 79.85859011619641, 20.0, -0.5271569716008506, -19.417639547670458, 0.0, 60.0, 0.0, 80.0, -6.487988319411546, 0.0, 40.0, 40.0, 0.0, -15.6921952324607, 0.0, 60.0, -25.474835151165887, 40.0, -4.360658998173407, 0.0, 20.0, 80.0, 11.390257658306481, 0.0, 0.0, 80.0, 0.0, 0.0, -16.5338283507529, 0.0, -4.5728943778816875, 20.0, 0.0, 19.360600949043096, 60.0, 0.0, 60.0, 40.0, 80.0, 0.0, -3.0065421982762253, 100.0, 0.0, 60.0, 80.0, -0.7568416243233522, 20.0, 0.0, 0.0, -8.443101113616233, 20.0, 20.0, 100.0, 40.0, 60.0, 0.0, 0.0, 0.0, 0.0, 60.0, 20.0, 0.0, 20.0, 4.688616040318069, 0.0, -4.6542686329383205, -3.906883638961318, 18.80764332361025, 0.0, 18.3495822678457, -1.9525990278600702, 20.0, 35.47862103080091, 37.509869418751244, -0.11184137619565382, 20.0, -0.3900922493211456, 0.0, 0.0, 0.0, 0.0, -0.9982460798818815, 53.696079483414174, 17.906830658377885, 100.0, 0.0, 60.0, 100.0, 0.0, 20.0, 0.0, -3.274752723752436, 40.0, -1.4987725948787234, 100.0, 30.786276545409734, 0.0, 0.0, 19.041082132742027, -10.440220703825185, 1.067393049739101, 76.7424530663212, 80.0, -8.142827339330497, 0.0, 0.0, 60.0, 0.0, 0.0, 60.0, -3.8770792603258855, 20.0, 40.0, 20.98911719702671, 20.0, 0.0, 0.0, -13.030717519297468, 0.0, -0.24676244615534415, 80.0, -2.5296204367192123, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -30.0, 0.0, -19.125895292699056, -11.745030451798852, -10.804351053644174, 0.0, -3.9483783635743865, -20.0, 0.0, -4.028655301109355, -24.13617608647173, 0.0, -42.22350254980422, -50.0, -10.237906378598527, 0.0, -40.0, 0.0, -70.0, 0.0, -7.54732281538715, 0.0, 0.0, -30.0, -30.0, -0.6470921472789071, 0.0, -20.0, -80.0, -30.0, 0.0, 0.0, -30.0, -29.482800724591392, -60.0, -30.0, -30.0, -40.14140988380358, -10.0, -0.5271569716008506, -19.417639547670458, 0.0, -30.0, 0.0, -40.0, -6.487988319411546, 0.0, -20.0, -20.0, 0.0, -15.6921952324607, 0.0, -30.0, -25.474835151165887, -20.0, -4.360658998173407, 0.0, -10.0, -40.0, -18.60974234169352, 0.0, 0.0, -40.0, 0.0, 0.0, -16.5338283507529, 0.0, -4.5728943778816875, -10.0, 0.0, -10.639399050956902, -30.0, 0.0, -30.0, -20.0, -40.0, 0.0, -3.0065421982762253, -50.0, 0.0, -30.0, -40.0, -0.7568416243233522, -10.0, 0.0, 0.0, -8.443101113616233, -10.0, -10.0, -50.0, -20.0, -30.0, 0.0, 0.0, 0.0, 0.0, -30.0, -10.0, 0.0, -10.0, -25.311383959681933, 0.0, -4.6542686329383205, -3.906883638961318, -11.192356676389752, 0.0, -41.650417732154295, -1.9525990278600702, -10.0, -24.52137896919908, -22.490130581248756, -0.11184137619565382, -10.0, -0.3900922493211456, 0.0, 0.0, 0.0, 0.0, -0.9982460798818815, -36.303920516585826, -12.093169341622113, -50.0, 0.0, -30.0, -50.0, 0.0, -10.0, 0.0, -3.274752723752436, -20.0, -1.4987725948787234, -50.0, -29.21372345459028, 0.0, 0.0, -10.958917867257975, -10.440220703825185, -28.932606950260904, -43.257546933678796, -40.0, -8.142827339330497, 0.0, 0.0, -30.0, 0.0, 0.0, -30.0, -3.8770792603258855, -10.0, -20.0, -39.0108828029733, -10.0, 0.0, 0.0, -13.030717519297468, 0.0, -0.24676244615534415, -40.0, -2.5296204367192123, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6983450412960063, "mean_inference_ms": 1.2119390792821647, "mean_action_processing_ms": 0.24131159141452865, "mean_env_wait_ms": 0.5203439792531132, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004416998521781262, "StateBufferConnector_ms": 0.003468328052096897, "ViewRequirementAgentConnector_ms": 0.09806207668634108}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -25.474835151165887, "episode_return_mean": 22.786527999124498}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 263.54322096376467, "num_env_steps_trained_throughput_per_sec": 263.54322096376467, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 17915.924, "restore_workers_time_ms": 0.013, "training_step_time_ms": 17915.883, "sample_time_ms": 1238.665, "learn_time_ms": 16653.019, "learn_throughput": 240.197, "synch_weights_time_ms": 22.85}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-47-23", "timestamp": 1723139243, "time_this_iter_s": 15.197733163833618, "time_total_s": 679.9416170120239, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f1310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 679.9416170120239, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 37.70454545454545, "ram_util_percent": 82.40454545454544}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5430094049622616, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6677249560753507, "policy_loss": -0.01883202919222337, "vf_loss": 3.6845737437407178, "vf_explained_var": 0.004045057483017445, "kl": 0.00991632513009912, "entropy": 1.1314482082923254, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.795452314213658, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6227256482374584, "policy_loss": -0.01626279872828923, "vf_loss": 2.6375498670212765, "vf_explained_var": -1.3057433121593286e-06, "kl": 0.007192898089213582, "entropy": 1.0396020507981591, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 105750.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -47.92012753488942, "episode_reward_mean": 26.399466069269508, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.585987261146498, "agent_policy": -17.358495714169983}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -1.48985919502161, 140.0, 0.0, 40.0, 60.0, 0.0, 0.0, 60.0, -8.963604645538732, -9.502497759861114, 40.0, 0.0, 40.0, 63.57768000497106, -0.16191701005062997, 18.568543197672298, 37.937759891725435, 60.0, 40.0, -0.47087466505097764, 55.49283750630556, 0.0, 0.0, 40.0, 40.0, -0.6767257008133232, 0.0, 0.0, 76.71888198374657, -4.7105909486699575, 0.0, 60.0, 19.57065083271179, -14.716526226554521, 0.0, 0.0, 0.0, 100.0, -29.93452926246112, 20.0, 80.0, 0.0, 0.0, 0.0, 14.058632179181451, -4.079466230088183, 0.0, 40.0, 0.0, 60.0, 79.37756216183718, 0.0, 60.0, 60.0, 0.0, 0.0, 0.0, 13.781491276743356, 100.0, 0.0, -14.27048638368472, -5.078380141244771, 0.0, 20.0, 60.0, 40.0, 100.0, 0.0, 43.116849607270105, 0.0, 0.0, -14.163532204790636, -20.602328711267287, 0.0, 0.0, 160.0, 60.0, 56.72670361504814, 37.318177181039076, -3.304010873269924, 17.98810290450977, -2.679939949998694, 40.0, 0.0, 0.0, 80.0, -18.888977049425893, 0.0, 138.7055954995571, 0.0, 40.0, 100.0, 60.0, -21.10136976025547, 0.0, 0.0, 0.0, 78.4878806936928, -0.9722946359332596, 0.0, -5.595776266509299, 0.0, 60.0, 0.0, 0.0, 80.0, 0.0, 100.0, 120.0, 120.0, 0.0, 100.0, -4.657653491985395, -1.1979200270762391, 0.0, 20.0, 0.0, -13.426406370986317, 0.0, 60.0, 0.0, 0.0, 83.89087709301985, 0.0, 0.0, 118.33679535515793, -2.380714758487217, -0.9050256971421733, 0.0, -19.6993160037513, 120.0, 60.0, 0.0, 0.0, -1.3918660172835395, 80.0, 0.0, -0.08018163720499127, 20.0, -21.627486402744214, 0.0, 59.93468558723174, 37.848040000196555, 120.0, 59.91674888078202, 0.0, 140.0, -10.764793035895076, -1.223143979151221, 0.0, 140.0, -47.92012753488942, 0.0, 0.0, 40.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -1.48985919502161, -70.0, 0.0, -20.0, -30.0, 0.0, 0.0, -30.0, -8.963604645538732, -9.502497759861114, -20.0, 0.0, -20.0, -56.42231999502894, -30.161917010050633, -11.431456802327704, -22.062240108274562, -30.0, -20.0, -0.47087466505097764, -34.50716249369444, 0.0, 0.0, -20.0, -20.0, -0.6767257008133232, 0.0, 0.0, -43.28111801625344, -4.7105909486699575, 0.0, -30.0, -10.429349167288207, -14.716526226554521, 0.0, 0.0, 0.0, -50.0, -29.93452926246112, -10.0, -40.0, 0.0, 0.0, 0.0, -15.94136782081855, -4.079466230088183, 0.0, -20.0, 0.0, -30.0, -40.62243783816283, 0.0, -30.0, -30.0, 0.0, 0.0, 0.0, -46.21850872325665, -50.0, 0.0, -14.27048638368472, -5.078380141244771, 0.0, -10.0, -30.0, -20.0, -50.0, 0.0, -46.88315039272989, 0.0, 0.0, -14.163532204790636, -20.602328711267287, 0.0, 0.0, -80.0, -30.0, -33.273296384951855, -22.681822818960917, -3.304010873269924, -12.01189709549023, -2.679939949998694, -20.0, 0.0, 0.0, -40.0, -18.888977049425893, 0.0, -71.29440450044291, 0.0, -20.0, -50.0, -30.0, -21.10136976025547, 0.0, 0.0, 0.0, -41.51211930630719, -0.9722946359332596, 0.0, -5.595776266509299, 0.0, -30.0, 0.0, 0.0, -40.0, 0.0, -50.0, -60.0, -60.0, 0.0, -50.0, -4.657653491985395, -1.1979200270762391, 0.0, -10.0, 0.0, -13.426406370986317, 0.0, -30.0, 0.0, 0.0, -66.10912290698015, 0.0, 0.0, -61.66320464484207, -2.380714758487217, -0.9050256971421733, 0.0, -19.6993160037513, -60.0, -30.0, 0.0, 0.0, -1.3918660172835395, -40.0, 0.0, -0.08018163720499127, -10.0, -21.627486402744214, 0.0, -30.06531441276826, -22.151959999803445, -60.0, -30.08325111921797, 0.0, -70.0, -10.764793035895076, -1.223143979151221, 0.0, -70.0, -47.92012753488942, 0.0, 0.0, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6971743704232967, "mean_inference_ms": 1.21023732002055, "mean_action_processing_ms": 0.24094877896151212, "mean_env_wait_ms": 0.5196186970644237, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005213242427558656, "StateBufferConnector_ms": 0.0033865309065314615, "ViewRequirementAgentConnector_ms": 0.09336175432630406}, "num_episodes": 157, "episode_return_max": 160.0, "episode_return_min": -47.92012753488942, "episode_return_mean": 26.399466069269508}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 277.9351596902228, "num_env_steps_trained_throughput_per_sec": 277.9351596902228, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 17265.86, "restore_workers_time_ms": 0.013, "training_step_time_ms": 17265.819, "sample_time_ms": 1222.202, "learn_time_ms": 16020.697, "learn_throughput": 249.677, "synch_weights_time_ms": 21.589}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-47-37", "timestamp": 1723139257, "time_this_iter_s": 14.398355960845947, "time_total_s": 694.3399729728699, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d203a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 694.3399729728699, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 34.925, "ram_util_percent": 82.64500000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4889410199597477, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9574672140181066, "policy_loss": -0.020229226793647588, "vf_loss": 3.9755868658423426, "vf_explained_var": -0.011967085488140582, "kl": 0.010547810845642403, "entropy": 1.168842805425326, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7781237427647232, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.675272478152674, "policy_loss": -0.018836739463715134, "vf_loss": 2.6924589981846774, "vf_explained_var": 1.2538745893654249e-06, "kl": 0.008251088995972626, "entropy": 1.0252505701061683, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 108570.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -34.38890660875758, "episode_reward_mean": 23.412701674968712, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.209876543209877, "agent_policy": -16.216927954660918}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.435940203080264, -10.869096948615883, 37.56881013765582, 40.0, 0.0, 60.0, -7.778100132624873, 0.0, -0.5260983393014362, -34.38890660875758, 40.0, 60.0, 40.0, -0.4903632641970479, -19.4914184629338, 0.0, 0.0, 0.0, 0.0, 40.0, 60.0, -4.288353076322811, 0.0, -21.552885873110576, 0.0, -0.3751618196734152, 0.0, -6.700134814399142, -0.4194875224457817, -0.2587016611093418, -3.687477582889697, 0.0, 30.692165419520443, 0.0, 0.0, 60.0, 40.0, -0.4249247041799553, 60.0, 79.08373337231208, 107.5155310558962, 100.0, 60.0, 20.0, 0.0, 0.0, 39.173002409418544, 0.0, 80.0, 60.0, 20.0, 0.0, 0.0, 60.0, -3.2657974785403105, 0.0, 0.0, 5.644756457830789, 40.0, 60.0, 0.0, 59.575316902067726, -5.769469436276452, 37.45044195062373, 20.0, -1.050970897555279, 80.0, -3.226476355671841, 80.0, 100.0, 0.0, 40.0, 20.0, -5.165552035231028, 0.0, 100.0, 0.0, 0.0, -13.061577800936549, 0.0, 138.57265964390632, 40.0, 0.0, 0.0, 40.0, 0.0, 160.0, 100.0, 40.0, -1.189344053342316, 60.0, 54.17164925470529, 0.0, 0.0, -0.709330675508909, -4.033131800810287, -14.126495803703074, 0.0, 38.60035390092175, -27.381347340844968, 40.0, -0.3231882534338848, 20.0, 160.0, 60.0, -0.01102901847542026, 52.095936456645056, 20.0, -1.4935767724164222, 57.71013405310186, 0.0, -24.07729806375758, 0.0, -0.4289328208336296, 80.0, -3.176552823460358, -2.707952167255808, 0.0, 0.0, 0.0, 0.0, 59.939507154635464, 120.0, 0.0, -1.574700390169147, -9.090758297983662, -5.966847075476788, 60.0, 40.0, 120.0, -17.273884129427344, 100.0, 0.0, 40.0, 75.01638381130172, 0.0, -29.17113687134713, -26.663659013267512, 59.98040693064344, 0.0, 0.0, -7.785398840887791, -10.48606009399334, 0.0, 39.860870839551666, 76.68507783043397, 120.0, 0.0, 20.0, -27.6739204745454, -22.048714946136826, -3.260614548984697, 20.0, 0.0, -0.23940467959999712, 0.0, 40.0, 40.0, 0.0, 78.84220175545882, 17.74806065595601, -8.821035080300357], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.564059796919732, -10.869096948615883, -22.431189862344183, -20.0, 0.0, -30.0, -7.778100132624873, 0.0, -0.5260983393014362, -34.38890660875758, -20.0, -30.0, -20.0, -0.4903632641970479, -19.4914184629338, 0.0, 0.0, 0.0, 0.0, -20.0, -30.0, -4.288353076322811, 0.0, -21.552885873110576, 0.0, -0.3751618196734152, 0.0, -6.700134814399142, -0.4194875224457817, -0.2587016611093418, -3.687477582889697, 0.0, -29.307834580479565, 0.0, 0.0, -30.0, -20.0, -0.4249247041799553, -30.0, -40.91626662768792, -72.48446894410381, -50.0, -30.0, -10.0, 0.0, 0.0, -20.82699759058146, 0.0, -40.0, -30.0, -10.0, 0.0, 0.0, -30.0, -3.2657974785403105, 0.0, 0.0, -24.35524354216921, -20.0, -30.0, 0.0, -30.42468309793228, -5.769469436276452, -22.549558049376273, -10.0, -1.050970897555279, -40.0, -3.226476355671841, -40.0, -50.0, 0.0, -20.0, -10.0, -5.165552035231028, 0.0, -50.0, 0.0, 0.0, -13.061577800936549, 0.0, -71.42734035609368, -20.0, 0.0, 0.0, -20.0, 0.0, -80.0, -50.0, -20.0, -1.189344053342316, -30.0, -35.82835074529471, 0.0, 0.0, -0.709330675508909, -4.033131800810287, -14.126495803703074, 0.0, -21.399646099078247, -27.381347340844968, -20.0, -0.3231882534338848, -10.0, -80.0, -30.0, -0.01102901847542026, -67.90406354335491, -10.0, -1.4935767724164222, -32.28986594689814, 0.0, -24.07729806375758, 0.0, -0.4289328208336296, -40.0, -3.176552823460358, -2.707952167255808, 0.0, 0.0, 0.0, 0.0, -30.060492845364532, -60.0, 0.0, -1.574700390169147, -9.090758297983662, -5.966847075476788, -30.0, -20.0, -60.0, -17.273884129427344, -50.0, 0.0, -20.0, -44.983616188698264, 0.0, -29.17113687134713, -26.663659013267512, -30.019593069356556, 0.0, 0.0, -7.785398840887791, -10.48606009399334, 0.0, -20.139129160448334, -43.31492216956603, -60.0, 0.0, -10.0, -27.6739204745454, -22.048714946136826, -3.260614548984697, -10.0, 0.0, -0.23940467959999712, 0.0, -20.0, -20.0, 0.0, -41.1577982445412, -12.25193934404399, -8.821035080300357]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6955727147783248, "mean_inference_ms": 1.2078113599409128, "mean_action_processing_ms": 0.24050047952806344, "mean_env_wait_ms": 0.5185281524819184, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004489407127286181, "StateBufferConnector_ms": 0.003243302121574496, "ViewRequirementAgentConnector_ms": 0.09384824905866458}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -34.38890660875758, "episode_return_mean": 23.412701674968712}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 286.01065029464155, "num_env_steps_trained_throughput_per_sec": 286.01065029464155, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 16564.877, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16564.835, "sample_time_ms": 1198.988, "learn_time_ms": 15340.973, "learn_throughput": 260.74, "synch_weights_time_ms": 23.089}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-47-52", "timestamp": 1723139272, "time_this_iter_s": 14.027852058410645, "time_total_s": 708.3678250312805, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d21310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 708.3678250312805, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 33.245, "ram_util_percent": 82.45}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6727999138956269, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5856307576100033, "policy_loss": -0.01693612598319305, "vf_loss": 3.6008429723481337, "vf_explained_var": 0.03343348962565263, "kl": 0.00861949641016316, "entropy": 1.136729558929801, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7780763783987532, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9836601625097559, "policy_loss": -0.015987521620031368, "vf_loss": 1.9982177156083127, "vf_explained_var": -1.5207004885301522e-06, "kl": 0.007149837849580898, "entropy": 0.9835887064747777, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 111390.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -31.792207864928677, "episode_reward_mean": 16.1620546659405, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -106.04105719585783}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.061728395061728, "agent_policy": -14.023130519244685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -8.122772818706018, 36.20115965567319, -30.7502618772873, -7.435980135339504, 0.0, 120.0, -0.5907156938676894, 0.0, -19.151990406647773, -5.876328210962065, 0.0, 20.0, -26.31300512861557, 0.0, 40.0, 60.0, 0.0, -17.258022143060668, 80.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4483775570878912, 60.0, 100.0, 0.0, 0.0, -15.945962224483482, 40.0, 74.78676599604344, -0.6956446897884705, 60.0, -3.0560837426597174, 0.0, 0.0, 20.0, 0.0, -17.680139555307992, 0.0, 0.0, 0.0, -5.058942916532418, 0.0, 45.04838570980856, 0.0, 60.0, -2.2021596507109717, 0.0, -4.664115203139406, 0.0, -0.0058400540220182595, 60.0, 0.0, 0.0, 0.0, 0.0, -0.14185344386266285, -31.618564080714716, -7.573539434574878, -11.5435434401813, -1.7436310692799961, 0.0, -0.5031771260713036, -0.048634149363583346, 40.0, 0.0, 55.327167736687926, 0.0, 27.87480679626919, 60.0, 60.0, 0.0, 0.0, -4.230045510220517, -0.4734561222458067, 0.0, 60.0, 50.54848791324993, -17.59575279792334, 60.0, 20.0, -27.263943939174784, -4.728713872432957, 140.0, -21.691115330720926, 0.0, -12.17916061977632, -0.5421279706796267, 0.0, -20.170071919909294, 0.0, 0.0, -1.5656666849861034, 38.394004842350654, -1.4718549570954398, 140.0, 60.0, -10.198055725418333, 20.0, -0.04072270459794969, -20.293603664854473, 71.965206654411, 0.0, 0.0, 60.0, 77.74039475077116, 0.0, 80.0, 20.0, -15.73047181082827, -8.914092561956856, 0.0, -31.792207864928677, 0.0, 60.0, 59.54385415052546, 80.0, 20.0, 0.0, 100.0, 31.93397212405872, 0.0, 0.0, 103.95894280414215, -1.8704001589580144, 0.0, 14.980606616608632, -7.057247211755945, 0.0, 55.98402328695188, 0.0, 40.0, 0.0, 0.0, -4.571408631423748, -0.09473653094113632, -8.112399660024238, 0.0, 57.44653362600684, 0.0, 0.0, 0.0, 40.0, 20.0, 120.0, 69.09345290554592, 0.0, 0.0, 34.89399806197164, -22.54174462487406, -2.665941222731745, 0.0, -23.244680897989085, 60.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -8.122772818706018, -23.798840344326813, -30.7502618772873, -7.435980135339504, 0.0, -60.0, -0.5907156938676894, 0.0, -19.151990406647773, -5.876328210962065, 0.0, -10.0, -26.31300512861557, 0.0, -20.0, -30.0, 0.0, -17.258022143060668, -40.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4483775570878912, -30.0, -50.0, 0.0, 0.0, -15.945962224483482, -20.0, -45.21323400395656, -0.6956446897884705, -30.0, -3.0560837426597174, 0.0, 0.0, -10.0, 0.0, -17.680139555307992, 0.0, 0.0, 0.0, -5.058942916532418, 0.0, -44.95161429019144, 0.0, -30.0, -32.202159650710975, 0.0, -4.664115203139406, 0.0, -0.0058400540220182595, -30.0, 0.0, 0.0, 0.0, 0.0, -0.14185344386266285, -31.618564080714716, -7.573539434574878, -11.5435434401813, -1.7436310692799961, 0.0, -0.5031771260713036, -0.048634149363583346, -20.0, 0.0, -34.67283226331207, 0.0, -32.12519320373082, -30.0, -30.0, 0.0, 0.0, -4.230045510220517, -0.4734561222458067, 0.0, -30.0, -39.45151208675007, -17.59575279792334, -30.0, -10.0, -27.263943939174784, -4.728713872432957, -70.0, -21.691115330720926, 0.0, -12.17916061977632, -0.5421279706796267, 0.0, -20.170071919909294, 0.0, 0.0, -1.5656666849861034, -21.605995157649346, -1.4718549570954398, -70.0, -30.0, -10.198055725418333, -10.0, -0.04072270459794969, -20.293603664854473, -48.034793345588994, 0.0, 0.0, -30.0, -42.25960524922885, 0.0, -40.0, -10.0, -15.73047181082827, -8.914092561956856, 0.0, -31.792207864928677, 0.0, -30.0, -30.456145849474535, -40.0, -10.0, 0.0, -50.0, -28.06602787594128, 0.0, 0.0, -106.04105719585783, -1.8704001589580144, 0.0, -15.019393383391368, -7.057247211755945, 0.0, -34.015976713048126, 0.0, -20.0, 0.0, 0.0, -4.571408631423748, -0.09473653094113632, -8.112399660024238, 0.0, -32.55346637399316, 0.0, 0.0, 0.0, -20.0, -10.0, -60.0, -50.906547094454076, 0.0, 0.0, -25.10600193802836, -22.54174462487406, -2.665941222731745, 0.0, -23.244680897989085, -30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6944458471273509, "mean_inference_ms": 1.20523237596674, "mean_action_processing_ms": 0.24005017974717166, "mean_env_wait_ms": 0.5175819722435099, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006342743649894809, "StateBufferConnector_ms": 0.003889387036547249, "ViewRequirementAgentConnector_ms": 0.09477057574707785}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -31.792207864928677, "episode_return_mean": 16.1620546659405}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 267.93218504435754, "num_env_steps_trained_throughput_per_sec": 267.93218504435754, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 16563.957, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16563.916, "sample_time_ms": 1198.394, "learn_time_ms": 15340.809, "learn_throughput": 260.742, "synch_weights_time_ms": 22.964}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-48-06", "timestamp": 1723139286, "time_this_iter_s": 14.935898303985596, "time_total_s": 723.3037233352661, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d21550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 723.3037233352661, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 34.74090909090909, "ram_util_percent": 81.69545454545454}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6538570631295442, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.789946105952064, "policy_loss": -0.01794162106089061, "vf_loss": 3.806305802240968, "vf_explained_var": -0.003990696122248967, "kl": 0.00790960640309835, "entropy": 1.1757183828701576, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7794585982535748, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.70232472347875, "policy_loss": -0.01672768407249047, "vf_loss": 2.7176326095212437, "vf_explained_var": 2.9166116782114016e-07, "kl": 0.0070989852649316195, "entropy": 0.9800509974254784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 114210.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -32.94870595401574, "episode_reward_mean": 23.23401859669747, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -75.82801018617666}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.974683544303797, "agent_policy": -15.690032036213923}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 35.32766633182604, 40.0, 20.0, 20.0, 19.00786290495818, 0.0, 0.0, -4.555875241123279, 0.0, 0.0, -6.382192831799574, 0.0, 0.0, 120.0, 0.0, 80.0, 120.0, 0.0, -0.29509329259586825, -0.31352203448587135, 0.0, -5.142864788477029, 0.0, 59.98822798642786, 0.0, 23.412103227475423, 60.0, 0.0, 40.0, 0.0, 76.90691244790816, 120.0, 60.0, -0.8911178982419732, 0.0, 0.0, -0.12325924424851142, 0.0, -32.94870595401574, 0.0, 0.0, 56.85032355205627, 0.0, -13.02611690779625, 0.0, -5.293704313663858, 20.0, 0.0, -27.665323864639884, 0.0, 60.0, -1.2916055505737645, 0.0, 0.0, 0.0, -23.282698698359305, -1.3963164775173476, 0.0, 12.30211792620306, -0.611049531425848, 72.3557921800786, 40.0, -0.7329315144939508, 0.0, 0.0, 40.0, -3.0579997740305007, 0.0, -5.983472090837487, 139.32042811411435, 20.0, 40.0, 13.385168288803042, -28.061766058535248, 0.0, 20.0, 0.0, 60.0, -5.992011776408434, -0.14604225804807025, 119.57039425163181, 0.0, 60.0, 80.0, 0.0, 13.905541439605386, 20.0, 60.0, 0.0, 0.0, 0.0, 58.87953248925207, 0.0, -5.611891894773876, -1.7555098648035827, 0.0, -22.414796901743912, 100.0, 20.0, 0.0, 140.0, 59.03051133518119, 19.84148702924097, 140.0, -9.866575396175909, 41.29257308080561, 40.0, 20.0, 60.0, -2.2034239065608086, 0.0, 120.0, 21.917719971067513, 60.0, -13.428312487421277, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 100.0, -6.712628380756197, -1.5508210759568428, 0.0, 20.0, 40.0, -2.1228830788829125, 0.0, 56.398750116371914, 0.0, -3.27159954296756, 0.0, 45.390700499717994, 100.0, 20.0, 0.0, 134.17198981382333, -14.58339790440826, 40.0, 98.93126605494147, -0.7165207702638088, 80.0, 0.0, 140.0, 20.0, 0.0, 60.0, -1.8258645317761835, 0.0, 20.0, 0.0, -13.954234925481265, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -24.67233366817396, -20.0, -10.0, -10.0, -10.99213709504182, 0.0, 0.0, -34.55587524112327, 0.0, 0.0, -6.382192831799574, 0.0, 0.0, -60.0, 0.0, -40.0, -60.0, 0.0, -0.29509329259586825, -0.31352203448587135, 0.0, -5.142864788477029, 0.0, -30.01177201357214, 0.0, -36.587896772524566, -30.0, 0.0, -20.0, 0.0, -43.093087552091845, -60.0, -30.0, -0.8911178982419732, 0.0, 0.0, -0.12325924424851142, 0.0, -32.94870595401574, 0.0, 0.0, -33.14967644794374, 0.0, -13.02611690779625, 0.0, -5.293704313663858, -10.0, 0.0, -27.665323864639884, 0.0, -30.0, -1.2916055505737645, 0.0, 0.0, 0.0, -23.282698698359305, -1.3963164775173476, 0.0, -17.69788207379694, -0.611049531425848, -47.64420781992143, -20.0, -0.7329315144939508, 0.0, 0.0, -20.0, -3.0579997740305007, 0.0, -5.983472090837487, -70.67957188588564, -10.0, -20.0, -16.614831711196956, -28.061766058535248, 0.0, -10.0, 0.0, -30.0, -5.992011776408434, -0.14604225804807025, -60.42960574836817, 0.0, -30.0, -40.0, 0.0, -16.094458560394614, -10.0, -30.0, 0.0, 0.0, 0.0, -31.12046751074793, 0.0, -5.611891894773876, -1.7555098648035827, 0.0, -22.414796901743912, -50.0, -10.0, 0.0, -70.0, -30.96948866481882, -10.158512970759032, -70.0, -9.866575396175909, -48.70742691919439, -20.0, -10.0, -30.0, -2.2034239065608086, 0.0, -60.0, -38.08228002893249, -30.0, -13.428312487421277, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, -50.0, -6.712628380756197, -31.55082107595685, 0.0, -10.0, -20.0, -2.1228830788829125, 0.0, -33.601249883628086, 0.0, -3.27159954296756, 0.0, -44.609299500282006, -50.0, -10.0, 0.0, -75.82801018617666, -14.58339790440826, -20.0, -51.068733945058526, -0.7165207702638088, -40.0, 0.0, -70.0, -10.0, 0.0, -30.0, -1.8258645317761835, 0.0, -10.0, 0.0, -13.954234925481265, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.69254974407537, "mean_inference_ms": 1.2016487199621788, "mean_action_processing_ms": 0.23947950574935897, "mean_env_wait_ms": 0.5164428315896045, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004469367522227613, "StateBufferConnector_ms": 0.0030266333229934115, "ViewRequirementAgentConnector_ms": 0.08741488939599146}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -32.94870595401574, "episode_return_mean": 23.23401859669747}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 279.9768218155291, "num_env_steps_trained_throughput_per_sec": 279.9768218155291, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 16505.212, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16505.17, "sample_time_ms": 1193.94, "learn_time_ms": 15286.729, "learn_throughput": 261.665, "synch_weights_time_ms": 22.845}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-48-21", "timestamp": 1723139301, "time_this_iter_s": 14.298676013946533, "time_total_s": 737.6023993492126, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d203a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 737.6023993492126, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 31.270000000000003, "ram_util_percent": 82.62}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.591498301178217, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9731875979652007, "policy_loss": -0.019914345328773682, "vf_loss": 3.9910759374499323, "vf_explained_var": 0.03462830111384392, "kl": 0.010130064595557542, "entropy": 1.1571521444867054, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7865415988556037, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.41022861612604, "policy_loss": -0.01640828444165981, "vf_loss": 2.425208702746858, "vf_explained_var": -1.1522507836632694e-06, "kl": 0.007140985533584416, "entropy": 0.9621187113278301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 117030.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 154.94603447173125, "episode_reward_min": -44.85494293434715, "episode_reward_mean": 19.298963541261877, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -85.05396552826873}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.59235668789809, "agent_policy": -15.478106522432391}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.9455511011373086, 80.0, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, -1.274624319990467, 38.851547734649486, -35.78131658388626, 0.0, 59.555535486643606, 40.0, 40.0, 0.0, 60.0, -12.814229173299026, 100.0, 80.0, 0.0, -0.6627943871484621, -6.778461248655905, 40.0, 80.0, 40.0, 0.0, 0.0, 0.0, -5.075698868340051, 0.0, 0.0, -0.8761874937005609, 0.0, -18.06880594055257, 140.0, -13.618220823836953, 0.0, 119.3161768336326, 40.0, 0.0, 38.9203524276342, 0.0, 40.0, -0.765245907578399, 18.242382441670184, 40.0, 56.98642217191869, 120.0, 0.0, 40.0, 40.0, -0.5575577805165366, -27.09536351364808, -2.9027599622467877, -1.7756692095916404, -2.7681370013318993, 0.0, 60.0, 39.599325533354445, 40.0, -0.008590329685064235, 16.452647058012595, 20.0, -13.20138975418558, -23.351139982354262, 0.0, 0.0, 0.0, -15.651761189675302, 100.0, -14.570912055348408, 0.0, 40.0, 0.0, 20.0, 37.7180694579701, -0.38985692452175535, 100.0, -10.294247890824138, 0.0, -18.291699055052497, -2.4553051857669876, -0.08511637241693237, -10.524808708451136, 60.0, 20.0, 56.62712858521104, 40.0, 74.055372329039, 140.0, 60.0, -3.011028507353192, 0.0, 40.0, 0.0, 20.0, 60.0, 60.0, 0.0, 0.0, 60.0, 17.717691319202974, 0.0, 0.0, 0.0, -13.995782849785968, -44.85494293434715, 0.0, -7.519850000493273, -28.073047474063742, -0.5313212165939452, -0.13176442776232755, 47.27298649791675, 60.0, 24.73473282460271, -0.6176176601622552, 0.0, 0.0, -6.634299421987783, -27.409956614780302, -20.53311664651755, -19.17947927909888, -33.73499473370943, 0.0, 0.0, 20.0, -11.525410249020863, -12.180528919563534, 154.94603447173125, 58.304915227338505, -0.9980665798015764, 0.0, -4.018539149043775, 40.0, 0.0, -21.11644482074625, 80.0, 100.0, 20.0, 0.0, -0.25327407243513567, 40.0, -0.08158309797588914, 100.0, -2.535892759842123, 19.269395612960714, -1.893520466587575, 40.0, 22.823783591137556, 40.0, -5.93233688515531, 0.0, -2.625403048946464, 0.0, 58.51642895300533, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.9455511011373086, -40.0, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, -1.274624319990467, -21.148452265350514, -35.78131658388626, 0.0, -30.444464513356394, -20.0, -20.0, 0.0, -30.0, -12.814229173299026, -50.0, -40.0, 0.0, -0.6627943871484621, -6.778461248655905, -20.0, -40.0, -20.0, 0.0, 0.0, 0.0, -5.075698868340051, 0.0, 0.0, -0.8761874937005609, 0.0, -18.06880594055257, -70.0, -13.618220823836953, 0.0, -60.6838231663674, -20.0, 0.0, -21.0796475723658, 0.0, -20.0, -0.765245907578399, -11.757617558329816, -20.0, -33.01357782808132, -60.0, 0.0, -20.0, -20.0, -0.5575577805165366, -27.09536351364808, -2.9027599622467877, -1.7756692095916404, -2.7681370013318993, 0.0, -30.0, -20.400674466645558, -20.0, -0.008590329685064235, -43.5473529419874, -10.0, -13.20138975418558, -23.351139982354262, 0.0, 0.0, 0.0, -15.651761189675302, -50.0, -14.570912055348408, 0.0, -20.0, 0.0, -10.0, -22.2819305420299, -0.38985692452175535, -50.0, -10.294247890824138, 0.0, -18.291699055052497, -2.4553051857669876, -0.08511637241693237, -10.524808708451136, -30.0, -10.0, -33.37287141478897, -20.0, -45.944627670961, -70.0, -30.0, -3.011028507353192, 0.0, -20.0, 0.0, -10.0, -30.0, -30.0, 0.0, 0.0, -30.0, -12.282308680797026, 0.0, 0.0, 0.0, -13.995782849785968, -44.85494293434715, 0.0, -7.519850000493273, -28.073047474063742, -0.5313212165939452, -0.13176442776232755, -42.72701350208325, -30.0, -35.26526717539729, -0.6176176601622552, 0.0, 0.0, -6.634299421987783, -27.409956614780302, -20.53311664651755, -19.17947927909888, -33.73499473370943, 0.0, 0.0, -10.0, -11.525410249020863, -12.180528919563534, -85.05396552826873, -31.695084772661502, -0.9980665798015764, 0.0, -4.018539149043775, -20.0, 0.0, -21.11644482074625, -40.0, -50.0, -10.0, 0.0, -0.25327407243513567, -20.0, -0.08158309797588914, -50.0, -2.535892759842123, -10.730604387039287, -1.893520466587575, -20.0, -37.17621640886243, -20.0, -5.93233688515531, 0.0, -2.625403048946464, 0.0, -31.48357104699468, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.691709515132936, "mean_inference_ms": 1.2012557177583227, "mean_action_processing_ms": 0.25594982859565696, "mean_env_wait_ms": 0.5163023627191681, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005359406683854996, "StateBufferConnector_ms": 0.0033818232785364625, "ViewRequirementAgentConnector_ms": 0.09832549247012776}, "num_episodes": 157, "episode_return_max": 154.94603447173125, "episode_return_min": -44.85494293434715, "episode_return_mean": 19.298963541261877}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 275.911750622142, "num_env_steps_trained_throughput_per_sec": 275.911750622142, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 15067.965, "restore_workers_time_ms": 0.013, "training_step_time_ms": 15067.924, "sample_time_ms": 1226.889, "learn_time_ms": 13816.845, "learn_throughput": 289.502, "synch_weights_time_ms": 22.52}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-48-35", "timestamp": 1723139315, "time_this_iter_s": 14.5388662815094, "time_total_s": 752.141265630722, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f93a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 752.141265630722, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 33.24761904761905, "ram_util_percent": 82.1190476190476}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7722246288632353, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.262516619389256, "policy_loss": -0.016980636768615418, "vf_loss": 4.277882152050734, "vf_explained_var": -0.009438275421659151, "kl": 0.008075532706570243, "entropy": 1.1667678579688072, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7598465022360179, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8736152761371425, "policy_loss": -0.01771780787855684, "vf_loss": 2.8898308214989115, "vf_explained_var": 2.1242080850804106e-07, "kl": 0.007511277346020811, "entropy": 0.9558942447528771, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 119850.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -32.21139503835675, "episode_reward_mean": 20.627714548601404, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.91358024691358, "agent_policy": -15.113026192139337}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 0.0, 120.0, 0.0, 0.0, -2.9006253186421826, -32.21139503835675, 100.0, 60.0, 0.0, -4.981783059935509, 32.319694474903905, 7.4237937196454205, 60.0, 31.473092451247147, 0.0, -1.2597704955513644, -0.0035309708156061603, 0.0, 40.0, 30.843527327812104, -23.025425192813927, 60.0, -1.4216752722856196, 6.7984053314399056, 0.0, -11.131036362763252, 0.0, 0.0, 0.0, 0.0, 18.441863376129575, 0.0, -0.5859280443937409, -1.1191561746897405, -0.006736155011398681, -8.179638657092456, -23.049704942262697, -11.53207384477785, 40.0, -17.269790949242164, 0.0, 109.9345613378077, 120.0, -1.6000615521479267, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 40.0, 34.043623023740906, -2.870954926362529, -6.3341775600738774, 40.0, -9.281974862358352, 16.9371565060154, 40.0, 80.0, 60.0, 0.0, 0.0, 40.0, -5.346597952838482, -27.61280120842534, -5.058694202996726, 40.0, 17.410881184917425, 100.0, 39.4786836497496, -1.73107261499849, 38.00870590365057, 97.38980525674916, 60.0, 33.807985915993996, 19.61999644383235, 0.0, 60.0, 60.0, 49.47343159011515, -12.951902297621134, 0.0, 0.0, 0.0, -13.699889094190828, 20.0, 160.0, 80.0, 0.0, 0.0, 40.0, 60.0, 60.0, 0.0, -0.20784753753833152, 0.0, -2.0621092006651165, 0.0, 0.0, 0.0, 0.0, 0.0, 59.90051383128662, 140.0, -7.225041926435109, -20.075346169692924, -0.0409246261166063, -9.237468379780761, -1.993480257349119, 0.0, 60.0, 20.0, -13.805746733537768, 60.0, 0.0, -2.0783384023027454, 0.0, -6.568774983932583, 70.49335867824388, 60.0, 0.0, 100.0, 80.0, 20.0, 20.0, 0.0, 40.0, -32.06483640899969, 0.0, -1.5756120652701777, 0.0, -10.626373801193955, 80.0, 39.184142610905994, 39.73978670663238, 0.0, 136.7067650230468, 0.0, 0.0, -4.65753469162733, 0.0, -18.019759582046905, 0.0, 40.0, -20.82761306392576, 32.08980706199753, -0.59910098962912, 40.0, 0.0, -1.402584672454007, 0.0, 99.96220816690696, 0.0, -0.829065604936704, 0.0, -4.054372169957172, -15.589082933885, 20.0, 100.0, 38.915378252581505], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -30.0, 0.0, -60.0, 0.0, 0.0, -2.9006253186421826, -32.21139503835675, -50.0, -30.0, 0.0, -4.981783059935509, -27.68030552509609, -22.576206280354576, -30.0, -28.52690754875286, 0.0, -1.2597704955513644, -0.0035309708156061603, 0.0, -20.0, -29.156472672187896, -23.025425192813927, -30.0, -1.4216752722856196, -23.201594668560094, 0.0, -11.131036362763252, 0.0, 0.0, 0.0, 0.0, -11.558136623870425, 0.0, -0.5859280443937409, -1.1191561746897405, -0.006736155011398681, -8.179638657092456, -23.049704942262697, -11.53207384477785, -20.0, -17.269790949242164, 0.0, -70.0654386621923, -60.0, -1.6000615521479267, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -20.0, -25.9563769762591, -2.870954926362529, -6.3341775600738774, -20.0, -9.281974862358352, -13.062843493984602, -20.0, -40.0, -30.0, 0.0, 0.0, -20.0, -5.346597952838482, -27.61280120842534, -5.058694202996726, -20.0, -12.589118815082575, -50.0, -20.521316350250395, -1.73107261499849, -21.991294096349428, -52.61019474325085, -30.0, -26.192014084006, -10.380003556167653, 0.0, -30.0, -30.0, -40.52656840988485, -12.951902297621134, 0.0, 0.0, 0.0, -13.699889094190828, -10.0, -80.0, -40.0, 0.0, 0.0, -20.0, -30.0, -30.0, 0.0, -0.20784753753833152, 0.0, -2.0621092006651165, 0.0, 0.0, 0.0, 0.0, 0.0, -30.099486168713387, -70.0, -7.225041926435109, -20.075346169692924, -0.0409246261166063, -9.237468379780761, -1.993480257349119, 0.0, -30.0, -10.0, -13.805746733537768, -30.0, 0.0, -2.0783384023027454, 0.0, -6.568774983932583, -49.50664132175614, -30.0, 0.0, -50.0, -40.0, -10.0, -10.0, 0.0, -20.0, -32.06483640899969, 0.0, -1.5756120652701777, 0.0, -10.626373801193955, -40.0, -20.81585738909401, -20.26021329336762, 0.0, -73.29323497695319, 0.0, 0.0, -4.65753469162733, 0.0, -18.019759582046905, 0.0, -20.0, -20.82761306392576, -27.910192938002464, -0.59910098962912, -20.0, 0.0, -1.402584672454007, 0.0, -50.03779183309303, 0.0, -0.829065604936704, 0.0, -4.054372169957172, -15.589082933885, -10.0, -50.0, -21.084621747418495]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6900635021910557, "mean_inference_ms": 1.198715341457115, "mean_action_processing_ms": 0.25512376789262337, "mean_env_wait_ms": 0.5153517641613213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0049044320612777895, "StateBufferConnector_ms": 0.0034524334801567923, "ViewRequirementAgentConnector_ms": 0.0939628960173807}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -32.21139503835675, "episode_return_mean": 20.627714548601404}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 277.97701480952065, "num_env_steps_trained_throughput_per_sec": 277.97701480952065, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 14787.752, "restore_workers_time_ms": 0.013, "training_step_time_ms": 14787.712, "sample_time_ms": 1200.663, "learn_time_ms": 13564.757, "learn_throughput": 294.882, "synch_weights_time_ms": 21.173}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-48-50", "timestamp": 1723139330, "time_this_iter_s": 14.395820140838623, "time_total_s": 766.5370857715607, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d30670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 766.5370857715607, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 32.205, "ram_util_percent": 82.12499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7753195190802216, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4922505484273034, "policy_loss": -0.017585275277572993, "vf_loss": 3.5081857621669768, "vf_explained_var": 0.02697764163215955, "kl": 0.008250345751955261, "entropy": 1.1049464799463748, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7758431855457049, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5111010139292858, "policy_loss": -0.017887101135735155, "vf_loss": 2.5276300237111164, "vf_explained_var": -1.9019165783063739e-06, "kl": 0.006790418900303972, "entropy": 0.9094072889140312, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 122670.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 179.27785738984096, "episode_reward_min": -25.706961059352132, "episode_reward_mean": 21.47652975800408, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.72214261015904}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.790123456790123, "agent_policy": -13.893840612366292}, "custom_metrics": {}, "hist_stats": {"episode_reward": [179.27785738984096, 0.0, -6.896172574488993, 0.0, 0.0, 0.0, 0.0, 99.76170551363845, 60.0, 0.0, 0.0, 0.0, 160.0, 0.0, 40.0, 0.0, 50.124262207439614, 60.0, 0.0, 38.535564037560874, 0.0, -11.361399508938458, -0.2201860621888252, 40.0, 20.0, 0.0, -19.404289506325995, 55.20829098189317, -10.07875779280219, 79.30865796173693, -20.612759721355737, 34.47843700359549, 60.0, 0.0, 0.0, 0.0, -8.366549338447447, 0.0, 20.0, -21.342845569584682, 40.0, 40.0, 0.0, 40.0, 40.0, 0.0, 40.0, 0.0, 60.0, 0.0, -6.0910404637913516, 20.0, 0.0, 0.0, 0.0, -5.706996123308348, -6.1895875346491795, 80.0, 120.0, 60.0, 40.0, 0.0, -11.043148376553125, -5.250097026930241, 59.16592216570098, 0.0, -2.4424755978031563, 79.90854715218352, 0.0, -5.074997816974332, -4.51527518490067, 40.0, 99.94300715068512, 60.0, 59.288895789403625, 0.0, 20.0, -1.0136652032227944, 0.0, 60.0, -1.3737023960848493, 0.0, 72.43982113991218, -12.755994059584047, 0.0, 20.0, 0.0, 59.94411541349858, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, 40.0, 17.76293769348963, 20.0, 0.0, 0.0, -0.005667332673978676, 80.0, -3.234905363985153, 18.81420934802978, 60.0, 17.894209466832706, 40.0, -1.45954864800652, 0.0, -4.27148989744845, 60.0, 60.0, 0.0, 100.0, 0.0, 40.0, -6.3624223177758505, -2.1276727472275567, 0.0, -9.893265143428, 0.0, 0.0, -0.5820559104779099, -10.117222324375383, 40.0, 40.0, 40.0, 0.0, 40.0, -4.13453265842749, 40.0, 0.0, 0.0, 100.0, -0.13907650519495163, 140.0, 0.0, 0.0, 78.52665467446643, 0.0, -0.16316606762067365, 0.0, 71.76667565745203, 0.0, 0.0, -11.616954740693776, 98.3094365892026, -0.06994402756246854, 0.0, 0.0, 0.0, 0.0, 0.0, 11.528321960416518, 40.0, 40.0, -3.1648838981336924, 100.0, -25.706961059352132, 0.0, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-90.72214261015904, 0.0, -6.896172574488993, 0.0, 0.0, 0.0, 0.0, -50.23829448636156, -30.0, 0.0, 0.0, 0.0, -80.0, 0.0, -20.0, 0.0, -39.875737792560386, -30.0, 0.0, -21.464435962439122, 0.0, -11.361399508938458, -0.2201860621888252, -20.0, -10.0, 0.0, -19.404289506325995, -34.791709018106815, -10.07875779280219, -40.691342038263066, -50.61275972135574, -25.52156299640452, -30.0, 0.0, 0.0, 0.0, -8.366549338447447, 0.0, -10.0, -21.342845569584682, -20.0, -20.0, 0.0, -20.0, -20.0, 0.0, -20.0, 0.0, -30.0, 0.0, -6.0910404637913516, -10.0, 0.0, 0.0, 0.0, -5.706996123308348, -6.1895875346491795, -40.0, -60.0, -30.0, -20.0, 0.0, -11.043148376553125, -5.250097026930241, -30.83407783429902, 0.0, -2.4424755978031563, -40.091452847816484, 0.0, -5.074997816974332, -4.51527518490067, -20.0, -50.05699284931488, -30.0, -30.711104210596375, 0.0, -10.0, -1.0136652032227944, 0.0, -30.0, -1.3737023960848493, 0.0, -47.56017886008781, -12.755994059584047, 0.0, -10.0, 0.0, -30.05588458650142, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -20.0, -12.237062306510367, -10.0, 0.0, 0.0, -0.005667332673978676, -40.0, -3.234905363985153, -11.185790651970217, -30.0, -12.105790533167294, -20.0, -1.45954864800652, 0.0, -4.27148989744845, -30.0, -30.0, 0.0, -50.0, 0.0, -20.0, -6.3624223177758505, -2.1276727472275567, 0.0, -9.893265143428, 0.0, 0.0, -0.5820559104779099, -10.117222324375383, -20.0, -20.0, -20.0, 0.0, -20.0, -4.13453265842749, -20.0, 0.0, 0.0, -50.0, -0.13907650519495163, -70.0, 0.0, 0.0, -41.47334532553359, 0.0, -0.16316606762067365, 0.0, -48.23332434254798, 0.0, 0.0, -11.616954740693776, -51.690563410797395, -0.06994402756246854, 0.0, 0.0, 0.0, 0.0, 0.0, -48.471678039583466, -20.0, -20.0, -3.1648838981336924, -50.0, -25.706961059352132, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6884129980799173, "mean_inference_ms": 1.1954928995269516, "mean_action_processing_ms": 0.2542285828338948, "mean_env_wait_ms": 0.5142221558035399, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004620978861679266, "StateBufferConnector_ms": 0.003408649821340302, "ViewRequirementAgentConnector_ms": 0.090744024441566}, "num_episodes": 162, "episode_return_max": 179.27785738984096, "episode_return_min": -25.706961059352132, "episode_return_mean": 21.47652975800408}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 271.52749819399395, "num_env_steps_trained_throughput_per_sec": 271.52749819399395, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 14736.394, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14736.348, "sample_time_ms": 1203.265, "learn_time_ms": 13510.089, "learn_throughput": 296.075, "synch_weights_time_ms": 21.312}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-49-05", "timestamp": 1723139345, "time_this_iter_s": 14.767499923706055, "time_total_s": 781.3045856952667, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf23700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 781.3045856952667, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 33.88571428571428, "ram_util_percent": 82.38571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8011530548334123, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.334248317033053, "policy_loss": -0.016373128692794125, "vf_loss": 4.348907863845428, "vf_explained_var": -0.0017775862788160643, "kl": 0.008567962233418243, "entropy": 1.138018670802315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7785224137788124, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.824204360466477, "policy_loss": -0.017042296651688053, "vf_loss": 2.839954565602837, "vf_explained_var": -5.254508755731245e-07, "kl": 0.006460446223838269, "entropy": 0.9222777381222299, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 125490.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -38.08136891048052, "episode_reward_mean": 24.8825479815317, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.197530864197532, "agent_policy": -17.71004461106089}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 79.61311597698638, 47.70029839266267, -15.998500336720726, 40.0, -0.3305846677932367, 180.0, -4.43335763668451, 20.0, 60.0, 0.0, 40.368735615018124, -0.6178275773076813, 100.0, 0.0, 7.046499152478228, 0.0, 32.91338042608604, 75.72743659307243, 60.0, 60.0, 0.0, -6.253737695593015, 60.0, 20.0, 60.0, 21.50099283612385, 60.0, 18.94505133521813, -8.658685780318478, 20.0, 0.0, -10.161434454241217, 60.0, 92.73024141150387, 0.0, 55.40824067028494, -6.889591832939287, -9.917542162128845, 35.79374069519306, 60.0, 0.0, 0.0, 40.0, 120.0, 0.0, 79.71652524702178, 0.0, 0.0, 40.0, 0.0, 10.497365481897093, 19.823968722919048, 20.0, 20.0, 0.0, 23.050926391568538, 0.0, -24.55594576158342, -2.041946209135391, 180.0, -38.08136891048052, -13.383112278486255, 0.0, -11.684510993386453, -4.676450740586693, 0.0, 0.0, -33.533170248138376, 0.0, 0.0, -20.896346327297962, 38.611055445952786, 38.312279554123904, 20.0, -5.985305797580294, -13.016511136385747, -0.008798161560393813, 0.0, 20.0, 60.0, 116.3721128513892, -0.16893481169535707, -18.292929773988114, 0.0, 0.0, -11.739986873703337, -0.10709349176407978, 40.0, 0.0, 0.0, 60.0, 60.0, 21.729257065458075, 60.0, 0.0, -3.3936279810136982, 0.0, 140.0, -2.2965748778192117, 0.0, 60.0, 74.65130414009738, 60.0, 0.0, 0.0, 0.0, 76.94546576124858, -0.4554667791327571, 0.0, 40.0, 92.84703327852961, 0.0, 0.0, 160.0, 20.0, 56.17123912541032, 40.0, 58.97002226120552, -0.9730842345372759, 0.0, 79.07592530264841, -1.2644675741196676, 80.0, 0.0, 0.0, 60.0, -0.014903919418111089, -24.096614465140025, 0.0, 38.98322313173409, -8.361281044527026, -0.30257029409740954, -4.251162555867011, 0.0, 10.815242668251585, 52.140176478321614, 0.0, 40.0, 0.0, 80.0, 60.0, 98.55310696640458, 100.0, 0.0, 20.0, 140.0, 0.0, -19.168568641537153, 60.0, 80.0, 0.0, 0.0, -15.344619478641475, -13.161259347811786, -5.3870968043745515, 0.0, 40.0, 0.0, -3.664386865513511, 0.0, -0.47183144762393714], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -40.38688402301362, -42.29970160733733, -15.998500336720726, -20.0, -0.3305846677932367, -90.0, -4.43335763668451, -10.0, -30.0, 0.0, -49.631264384981876, -0.6178275773076813, -50.0, 0.0, -22.95350084752178, 0.0, -27.08661957391395, -44.272563406927574, -30.0, -30.0, 0.0, -6.253737695593015, -30.0, -10.0, -30.0, -38.49900716387614, -30.0, -11.05494866478187, -8.658685780318478, -10.0, 0.0, -10.161434454241217, -30.0, -57.269758588496124, 0.0, -34.59175932971506, -6.889591832939287, -9.917542162128845, -24.20625930480695, -30.0, 0.0, 0.0, -20.0, -60.0, 0.0, -40.28347475297822, 0.0, 0.0, -20.0, 0.0, -19.502634518102912, -10.176031277080954, -10.0, -10.0, 0.0, -36.94907360843147, 0.0, -24.55594576158342, -2.041946209135391, -90.0, -38.08136891048052, -13.383112278486255, 0.0, -41.68451099338645, -4.676450740586693, 0.0, 0.0, -33.533170248138376, 0.0, 0.0, -20.896346327297962, -21.388944554047214, -21.6877204458761, -10.0, -5.985305797580294, -13.016511136385747, -0.008798161560393813, 0.0, -10.0, -30.0, -63.62788714861079, -0.16893481169535707, -18.292929773988114, 0.0, 0.0, -11.739986873703337, -0.10709349176407978, -20.0, 0.0, 0.0, -30.0, -30.0, -38.27074293454192, -30.0, 0.0, -3.3936279810136982, 0.0, -70.0, -2.2965748778192117, 0.0, -30.0, -45.34869585990262, -30.0, 0.0, 0.0, 0.0, -43.054534238751415, -0.4554667791327571, 0.0, -20.0, -57.15296672147039, 0.0, 0.0, -80.0, -10.0, -33.82876087458969, -20.0, -31.02997773879448, -0.9730842345372759, 0.0, -40.924074697351585, -1.2644675741196676, -40.0, 0.0, 0.0, -30.0, -0.014903919418111089, -24.096614465140025, 0.0, -21.016776868265907, -8.361281044527026, -0.30257029409740954, -4.251162555867011, 0.0, -19.184757331748408, -37.859823521678386, 0.0, -20.0, 0.0, -40.0, -30.0, -51.44689303359542, -50.0, 0.0, -10.0, -70.0, 0.0, -19.168568641537153, -30.0, -40.0, 0.0, 0.0, -15.344619478641475, -13.161259347811786, -5.3870968043745515, 0.0, -20.0, 0.0, -3.664386865513511, 0.0, -0.47183144762393714]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6900725636850117, "mean_inference_ms": 1.1986109745612388, "mean_action_processing_ms": 0.25453101539513484, "mean_env_wait_ms": 0.5153128830863494, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005576345655653212, "StateBufferConnector_ms": 0.005232846295392072, "ViewRequirementAgentConnector_ms": 0.11071437670860762}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -38.08136891048052, "episode_return_mean": 24.8825479815317}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 241.298241174638, "num_env_steps_trained_throughput_per_sec": 241.298241174638, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 14873.308, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14873.261, "sample_time_ms": 1237.786, "learn_time_ms": 13611.87, "learn_throughput": 293.861, "synch_weights_time_ms": 21.889}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-49-21", "timestamp": 1723139361, "time_this_iter_s": 16.61833906173706, "time_total_s": 797.9229247570038, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d12160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 797.9229247570038, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 40.47826086956521, "ram_util_percent": 82.8391304347826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8520086569711567, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.063853327681621, "policy_loss": -0.017239164006847812, "vf_loss": 4.07912514085571, "vf_explained_var": -0.013663478940725327, "kl": 0.009836804099425934, "entropy": 1.1596547916531563, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.788766294411311, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5897868443465404, "policy_loss": -0.016504896000516436, "vf_loss": 2.6050162529269008, "vf_explained_var": 2.100958046338237e-07, "kl": 0.006377454715612683, "entropy": 0.9154606551566022, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 128310.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -35.03635830689074, "episode_reward_mean": 19.584363549797327, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.70660769064605}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.372549019607844, "agent_policy": -14.533283509026202}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.72891251794596, 0.0, 0.0, 40.0, -12.475761916283325, 0.0, -4.131999449503424, 0.0, 20.0, 40.0, -10.66250714919093, 140.0, 0.0, 60.0, 75.78308721306732, 0.0, -3.3648026005252447, 180.0, 0.0, 20.0, 15.878330930745593, 0.0, 0.0, 59.45040274819658, 40.0, -0.8292064718250547, 100.0, 80.0, 0.0, 20.0, -29.285360039288733, 19.998264221691105, 0.0, 0.0, 60.0, 0.0, 40.0, 0.0, 0.0, 57.79594380951245, -4.791899493375326, 40.0, 0.0, 0.0, -14.765892748382248, -35.03635830689074, 0.0, 122.76883133937255, 60.0, -2.161732096456154, 0.0, -11.828272513262338, 18.026885314073922, 20.0, -0.023725277634021547, 60.0, 179.29339230935398, -9.079097915677671, 20.0, 0.0, 39.24888270677133, -24.63838741772469, -4.966892320058928, 20.0, 0.0, 59.03124013271233, 37.689880816938086, -18.318173622862457, 0.0, 0.0, 0.0, 59.676860080322214, 40.0, 0.0, 20.334093297058217, -0.7813673207918059, 40.0, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, -0.016602390952626944, -14.843151660204157, 0.0, 80.0, -0.1335490521606597, 0.0, 0.0, -2.011916646491929, 40.0, 0.0, -0.17024149597256844, 118.26989378042416, 0.0, 20.0, 0.0, 100.0, 20.0, 20.0, 140.0, 0.0, -13.284194823687614, 0.0, -21.20348055037977, -4.841104313242971, 20.0, 58.76982029107431, -9.50931409074205, -4.093793617782997, -2.1160192913026545, 60.0, 60.0, 48.2524316961682, 60.0, 0.0, 0.0, 43.12597922087581, 0.0, -5.226700661330137, 40.0, 0.0, 0.0, 40.0, 38.596973987223265, -0.5237724070490524, 140.0, 120.0, 0.0, 0.0, -10.029111481021245, 0.0, 0.0, -11.586630323806714, 40.0, 0.0, -1.5700237759273517, 0.0, -1.345474940691972, -16.915114902309703, -9.68666623988172, 0.0, 20.0, -0.5320180284576503, -26.97071811465952, -15.103622790855834, 0.0, 40.0, 0.0, 0.0, 20.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-16.72891251794596, 0.0, 0.0, -20.0, -12.475761916283325, 0.0, -4.131999449503424, 0.0, -10.0, -20.0, -10.66250714919093, -70.0, 0.0, -30.0, -44.21691278693269, 0.0, -3.3648026005252447, -90.0, 0.0, -10.0, -14.12166906925441, 0.0, 0.0, -30.549597251803416, -20.0, -0.8292064718250547, -50.0, -40.0, 0.0, -10.0, -29.285360039288733, -10.001735778308895, 0.0, 0.0, -30.0, 0.0, -20.0, 0.0, 0.0, -32.20405619048755, -4.791899493375326, -20.0, 0.0, 0.0, -14.765892748382248, -35.03635830689074, 0.0, -87.23116866062747, -30.0, -2.161732096456154, 0.0, -11.828272513262338, -11.97311468592608, -10.0, -30.023725277634025, -30.0, -90.70660769064605, -9.079097915677671, -10.0, 0.0, -20.751117293228667, -24.63838741772469, -4.966892320058928, -10.0, 0.0, -30.96875986728768, -22.310119183061918, -18.318173622862457, 0.0, 0.0, 0.0, -30.32313991967779, -20.0, 0.0, -39.66590670294178, -0.7813673207918059, -20.0, 0.0, 0.0, 0.0, -10.0, -30.0, 0.0, -0.016602390952626944, -14.843151660204157, 0.0, -40.0, -0.1335490521606597, 0.0, 0.0, -2.011916646491929, -20.0, 0.0, -0.17024149597256844, -61.73010621957585, 0.0, -10.0, 0.0, -50.0, -10.0, -10.0, -70.0, 0.0, -13.284194823687614, 0.0, -21.20348055037977, -4.841104313242971, -10.0, -31.23017970892569, -9.50931409074205, -4.093793617782997, -2.1160192913026545, -30.0, -30.0, -41.7475683038318, -30.0, 0.0, 0.0, -46.87402077912419, 0.0, -5.226700661330137, -20.0, 0.0, 0.0, -20.0, -21.403026012776728, -0.5237724070490524, -70.0, -60.0, 0.0, 0.0, -10.029111481021245, 0.0, 0.0, -11.586630323806714, -20.0, 0.0, -1.5700237759273517, 0.0, -1.345474940691972, -16.915114902309703, -9.68666623988172, 0.0, -10.0, -0.5320180284576503, -26.97071811465952, -15.103622790855834, 0.0, -20.0, 0.0, 0.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6885567051521784, "mean_inference_ms": 1.1964862685809812, "mean_action_processing_ms": 0.2537100896845034, "mean_env_wait_ms": 0.5144342417717451, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00430361118191987, "StateBufferConnector_ms": 0.003247011720744613, "ViewRequirementAgentConnector_ms": 0.09004142549302843}, "num_episodes": 153, "episode_return_max": 180.0, "episode_return_min": -35.03635830689074, "episode_return_mean": 19.584363549797327}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 261.84375113492905, "num_env_steps_trained_throughput_per_sec": 261.84375113492905, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 14824.308, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14824.261, "sample_time_ms": 1226.671, "learn_time_ms": 13576.32, "learn_throughput": 294.631, "synch_weights_time_ms": 19.59}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-49-37", "timestamp": 1723139377, "time_this_iter_s": 15.28226900100708, "time_total_s": 813.2051937580109, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b99e4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 813.2051937580109, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 34.054545454545455, "ram_util_percent": 82.24545454545454}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.794925614260137, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.050356733053922, "policy_loss": -0.019934228018003826, "vf_loss": 4.068476864819726, "vf_explained_var": 0.021105996208886306, "kl": 0.009070442340531674, "entropy": 1.133190148944656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7556646255630973, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3066984475504424, "policy_loss": -0.017393016869842952, "vf_loss": 2.322713504615405, "vf_explained_var": -1.4067752986935014e-06, "kl": 0.006889806044474329, "entropy": 0.9061933312855713, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 131130.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -41.70051746152565, "episode_reward_mean": 17.637428823647475, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.049382716049383, "agent_policy": -15.510719324500673}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -2.03005378221105, 40.0, -2.054954962389237, 0.0, -5.7419817103908315, 92.43583575696395, 60.0, 20.0, 0.0, 0.0, -20.302897796967123, 0.0, 0.0, -4.947278822689343, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.587768283595011, 37.97988718655463, 0.0, 40.0, 40.0, 0.0, 20.0, 60.0, 40.0, 40.0, -4.4627107753256805, 20.0, 0.0, 0.0, -7.840682946025587, 20.0, 0.0, 0.0, 0.0, -19.961373067425395, -20.09563649005172, 0.0, 0.0, -27.57701266582879, 0.0, 0.0, 59.14023101209949, 85.41689288816484, 93.3690969651239, 0.0, -1.4483562655766913, -5.281406185120554, 0.0, -0.3294382934922968, 40.0, -12.024100576891142, 0.0, 100.0, 0.0, -3.9679872402354577, 0.0, -2.3467252242343806, -27.488920578494962, 120.0, 0.0, -0.41011452950754146, 0.0, -17.85430332139396, 35.86465914062701, 57.88214209800531, -0.649944795938342, 0.0, 60.0, 0.0, -2.348018836644596, -3.646753111814999, 80.0, 0.0, 60.0, 140.0, 60.0, 0.0, -13.798873566754022, 40.0, 0.0, 40.0, 59.80341338698952, 0.0, -13.768323753942894, 80.0, 0.0, 19.972732214087884, 52.28471913779706, 0.0, -8.1010532598525, -29.626529398511924, 0.0, -4.649588173966192, 0.0, 60.0, -9.11715234692126, 0.14352738846582724, -26.450531623765187, 80.0, -4.948624483945283, 80.0, 0.0, -1.630705701796592, 9.694074204146595, 0.0, 80.0, -8.921703217229563, -10.60717677173313, 60.0, 0.0, -19.6258805100497, -7.35807478321449, 58.35055846142396, 0.0, 0.0, 160.0, 20.0, 120.0, -8.405654695502825, -24.6483586517674, -1.1034333976818433, -0.009703056565849577, 80.0, 40.0, 0.0, -0.715159618107617, 38.4707086975638, 0.0, -9.144113792494595, 21.232705905345256, 40.0, -24.321483386953844, 38.1782918320976, 0.0, 0.0, -2.271875835088598, 17.89665312928996, 60.0, 116.32254114696337, -41.70051746152565, -0.5806873568120197, 79.43541190583589, 0.0, -0.10279077190603059, 0.0, -24.883564212726625, 0.0, -1.509975544553468, 57.84062727831099, 0.0, -1.5430211175188613, 60.0, 16.589075186355824, 31.90266126181076, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-30.0, -2.03005378221105, -20.0, -2.054954962389237, 0.0, -5.7419817103908315, -57.564164243036046, -30.0, -10.0, 0.0, 0.0, -20.302897796967123, 0.0, 0.0, -4.947278822689343, -10.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.587768283595011, -22.020112813445373, 0.0, -20.0, -20.0, 0.0, -10.0, -30.0, -20.0, -20.0, -4.4627107753256805, -10.0, 0.0, 0.0, -7.840682946025587, -10.0, 0.0, 0.0, 0.0, -19.961373067425395, -20.09563649005172, 0.0, 0.0, -27.57701266582879, 0.0, 0.0, -30.85976898790051, -64.58310711183516, -56.63090303487609, 0.0, -1.4483562655766913, -5.281406185120554, 0.0, -0.3294382934922968, -20.0, -12.024100576891142, 0.0, -50.0, 0.0, -3.9679872402354577, 0.0, -2.3467252242343806, -27.488920578494962, -60.0, 0.0, -0.41011452950754146, 0.0, -17.85430332139396, -24.13534085937299, -32.1178579019947, -0.649944795938342, 0.0, -30.0, 0.0, -2.348018836644596, -3.646753111814999, -40.0, 0.0, -30.0, -70.0, -30.0, 0.0, -13.798873566754022, -20.0, 0.0, -20.0, -30.19658661301048, 0.0, -13.768323753942894, -40.0, 0.0, -10.027267785912116, -37.71528086220294, 0.0, -8.1010532598525, -29.626529398511924, 0.0, -4.649588173966192, 0.0, -30.0, -9.11715234692126, -29.85647261153418, -26.450531623765187, -40.0, -4.948624483945283, -40.0, 0.0, -1.630705701796592, -20.305925795853405, 0.0, -40.0, -8.921703217229563, -10.60717677173313, -30.0, 0.0, -49.6258805100497, -37.35807478321449, -31.649441538576045, 0.0, 0.0, -80.0, -10.0, -60.0, -8.405654695502825, -24.6483586517674, -1.1034333976818433, -0.009703056565849577, -40.0, -20.0, 0.0, -0.715159618107617, -51.5292913024362, 0.0, -9.144113792494595, -68.76729409465474, -20.0, -24.321483386953844, -21.821708167902404, 0.0, 0.0, -2.271875835088598, -12.103346870710043, -30.0, -63.67745885303663, -41.70051746152565, -0.5806873568120197, -40.56458809416411, 0.0, -0.10279077190603059, 0.0, -24.883564212726625, 0.0, -1.509975544553468, -32.15937272168901, 0.0, -1.5430211175188613, -30.0, -13.410924813644176, -58.09733873818924, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6876973958095515, "mean_inference_ms": 1.1950099437440445, "mean_action_processing_ms": 0.2531958706318557, "mean_env_wait_ms": 0.5139072981620726, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004632384688765915, "StateBufferConnector_ms": 0.0034080611334906686, "ViewRequirementAgentConnector_ms": 0.09515866821194872}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -41.70051746152565, "episode_return_mean": 17.637428823647475}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 263.2703363163454, "num_env_steps_trained_throughput_per_sec": 263.2703363163454, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 14825.881, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14825.835, "sample_time_ms": 1228.372, "learn_time_ms": 13579.328, "learn_throughput": 294.565, "synch_weights_time_ms": 16.616}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-49-52", "timestamp": 1723139392, "time_this_iter_s": 15.201509952545166, "time_total_s": 828.406703710556, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf23700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 828.406703710556, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 33.67727272727273, "ram_util_percent": 81.80454545454545}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9725506477678816, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2185485951602457, "policy_loss": -0.02648719436886798, "vf_loss": 3.2427320749809345, "vf_explained_var": 0.08614518071214358, "kl": 0.011518605749538313, "entropy": 1.1581042951593796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7745167680877321, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8200928597374166, "policy_loss": -0.016304875613381783, "vf_loss": 1.8351063829787233, "vf_explained_var": 1.18031992134473e-06, "kl": 0.006456759335446724, "entropy": 0.9009832438636334, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 133950.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -47.697542437523545, "episode_reward_mean": 13.752099168416365, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.39494080870293}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.135802469135802, "agent_policy": -13.655308238991045}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -4.466750158930587, 0.0, 60.0, 0.0, 0.0, 0.0, -4.224623409917831, -1.635490242179286, 0.0, 0.0, 60.0, 0.0, 0.0, 60.0, 55.827475642191054, 0.0, 0.0, -1.4917777988500724, -30.267782550453877, 20.0, 0.0, 60.0, -3.6002296281808457, -22.661148052044073, 0.0, 0.0, 0.0, 20.0, 0.0, 60.0, 0.0, 0.0, -11.703911421213105, 0.0, -47.697542437523545, 10.74085431262411, -28.420726771220593, 72.31167377440525, 56.714422089387185, 100.0, 18.158075718548876, -7.0550867897133624, 20.0, 40.0, 20.0, 60.0, 0.0, 0.0, 0.0, 60.0, -2.6999539423301373, 0.0, 0.0, 40.0, -0.132807301976966, -0.12297971789827389, 20.0, 60.0, 0.0, 0.0, -22.505177079880113, -1.937455244711389, 0.0, 0.0, 60.0, -32.56840657461133, -1.5520782750878515, 0.0, -34.43366943937594, 0.0, -1.596753577914889e-05, -11.199862209222985, -0.17586352350370205, 160.0, -6.519334170419298, -0.9166882823430134, 40.0, -9.984087110732286, -4.161160340372533, -3.099942128336326, -0.9480772980064567, 48.34585454140027, -0.45122883949520576, 36.87264079019339, 59.02351080276486, 23.2870596379063, 0.0, 0.0, -1.918950391920855, 0.0, 57.76613963086138, -0.40487917895429826, 18.161538379861675, 40.0, 159.60505919129707, -0.5118893723696494, -8.471623535747076, 0.0, 60.0, 54.25534181286437, 40.5788880774566, 40.0, -10.344375016868817, 0.0, -3.517644144572919, -3.7581036972835236, 0.0, 140.0, 40.0, 0.0, 0.0, -21.271018750973717, 0.0, 0.0, 19.93250505010576, 0.0, 0.0, -31.11278512196124, 0.0, 0.0, 0.0, 19.981463080974745, 80.0, 80.0, 0.0, 40.0, -19.995571169083526, -0.5148619791277909, 0.0, 120.0, -0.05063738112806915, -10.578074455416433, 0.0, 0.0, -8.83934543694482, -0.43606759278919105, 20.0, 0.0, 0.0, -4.004127098586132, 0.0, -29.069392194437278, -3.322545517743592, 100.0, 0.0, 0.0, 0.0, 0.0, -46.18611506631815, 40.0, -14.387741451792765, 19.566177444400566, 0.0, 0.0, 40.0, 39.375725342599566, -1.787776701272109, 100.0, -0.6421816058900887, 0.0, -24.904776469143204], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -4.466750158930587, 0.0, -30.0, 0.0, 0.0, 0.0, -4.224623409917831, -1.635490242179286, 0.0, 0.0, -30.0, 0.0, 0.0, -30.0, -34.172524357808946, 0.0, 0.0, -1.4917777988500724, -30.267782550453877, -10.0, 0.0, -30.0, -3.6002296281808457, -22.661148052044073, 0.0, 0.0, 0.0, -10.0, 0.0, -30.0, 0.0, 0.0, -11.703911421213105, 0.0, -47.697542437523545, -49.25914568737589, -28.420726771220593, -47.688326225594764, -33.285577910612815, -50.0, -11.841924281451124, -7.0550867897133624, -10.0, -20.0, -10.0, -30.0, 0.0, 0.0, 0.0, -30.0, -2.6999539423301373, 0.0, 0.0, -20.0, -0.132807301976966, -0.12297971789827389, -10.0, -30.0, 0.0, 0.0, -22.505177079880113, -1.937455244711389, 0.0, 0.0, -30.0, -32.56840657461133, -1.5520782750878515, 0.0, -34.43366943937594, 0.0, -1.596753577914889e-05, -11.199862209222985, -0.17586352350370205, -80.0, -6.519334170419298, -0.9166882823430134, -20.0, -69.98408711073229, -4.161160340372533, -3.099942128336326, -0.9480772980064567, -41.65414545859973, -0.45122883949520576, -23.127359209806606, -30.97648919723514, -36.71294036209372, 0.0, 0.0, -1.918950391920855, 0.0, -32.23386036913861, -0.40487917895429826, -11.838461620138325, -20.0, -80.39494080870293, -0.5118893723696494, -8.471623535747076, 0.0, -30.0, -35.74465818713562, -49.4211119225434, -20.0, -10.344375016868817, 0.0, -3.517644144572919, -3.7581036972835236, 0.0, -70.0, -20.0, 0.0, 0.0, -21.271018750973717, 0.0, 0.0, -40.06749494989423, 0.0, 0.0, -31.11278512196124, 0.0, 0.0, 0.0, -10.018536919025255, -40.0, -40.0, 0.0, -20.0, -19.995571169083526, -0.5148619791277909, 0.0, -60.0, -0.05063738112806915, -10.578074455416433, 0.0, 0.0, -8.83934543694482, -0.43606759278919105, -10.0, 0.0, 0.0, -34.00412709858613, 0.0, -29.069392194437278, -3.322545517743592, -50.0, 0.0, 0.0, 0.0, 0.0, -46.18611506631815, -20.0, -14.387741451792765, -10.433822555599434, 0.0, 0.0, -20.0, -20.624274657400434, -1.787776701272109, -50.0, -0.6421816058900887, 0.0, -24.904776469143204]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6878247946911732, "mean_inference_ms": 1.1955045409826268, "mean_action_processing_ms": 0.2529741998000963, "mean_env_wait_ms": 0.5140994904910613, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005779737307701582, "StateBufferConnector_ms": 0.004089025803554205, "ViewRequirementAgentConnector_ms": 0.10645632390622739}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -47.697542437523545, "episode_return_mean": 13.752099168416365}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 263.0457372275747, "num_env_steps_trained_throughput_per_sec": 263.0457372275747, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 14907.344, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14907.299, "sample_time_ms": 1235.732, "learn_time_ms": 13652.757, "learn_throughput": 292.981, "synch_weights_time_ms": 17.177}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-50-07", "timestamp": 1723139407, "time_this_iter_s": 15.221915006637573, "time_total_s": 843.6286187171936, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf4b160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 843.6286187171936, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 33.46666666666667, "ram_util_percent": 82.16190476190476}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9614418534561993, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.230517269670964, "policy_loss": -0.01862042991172833, "vf_loss": 4.247160780926546, "vf_explained_var": 0.0012097999453544617, "kl": 0.009884574676762545, "entropy": 1.123046859477957, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7873921872136441, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5648889731430837, "policy_loss": -0.018975441878024118, "vf_loss": 2.582391400624674, "vf_explained_var": -1.3631286350547845e-06, "kl": 0.007365073465313221, "entropy": 0.8868137311850879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 136770.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 137.5795133768663, "episode_reward_min": -37.939614339905646, "episode_reward_mean": 19.15419809161582, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.42048662313373}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.666666666666666, "agent_policy": -15.84580190838418}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -24.711644022027446, 0.0, 40.0, 0.0, 0.0, 39.89265467173581, 0.0, 0.0, -2.3723004437094968, 0.0, 60.0, 0.0, 0.0, 80.0, 20.0, -7.453660080023164, 58.983033969710604, 0.0, 31.492850528274147, 20.0, 0.0, 0.0, -2.886492069826229, 80.0, 38.112595055511854, 0.0, -0.19163348245062495, 0.0, 33.20976897958, 97.03660855727652, -3.494541256968822, 90.50683621207362, 0.0, 78.05643007125539, -10.352728828664663, 0.0, 40.0, 25.60488215445715, 40.0, 20.0, 0.0, -4.825917175253699, -6.32299577520009, 0.0, 0.0, 80.0, 0.0, 20.0, 0.0, 40.0, 0.0, 60.0, 60.0, -5.443724197128287, 18.675298934861523, 0.0, 0.0, -29.82331730046528, 0.0, 60.0, 0.0, 34.93639496985003, 40.0, -1.7807383690513456, -3.906022256805789, 60.0, 40.0, -0.7892256924841679, 97.62917169331764, 40.0, 0.0, 0.0, 80.0, 51.96062490467089, 0.0, -4.489151689873695, -0.2347674993165194, -28.789922764676447, 60.0, -0.06476157850234476, 60.0, -11.269186002049448, -0.04812219914908211, 0.0, 18.297843724308414, -3.4846043410620586, -0.8641445466926634, 0.0, 59.79827426910752, 18.18906877871758, 60.0, -11.156002088646046, -1.2855404420287098, 20.0, 0.0, -19.738233196644718, 60.0, -1.6336093134484297, 0.0, 99.86635982406776, 59.93216716978627, 0.0, 0.0, 100.0, -3.243768944680979, 19.724152896131017, -21.005444432482566, 0.0, -30.57630265613983, 0.0, -37.939614339905646, -30.37084623761471, 137.5795133768663, 60.0, 80.0, 60.0, 0.0, -7.46174300026232, -4.501354051244494, 0.0, 0.0, 40.0, 39.852105475159746, 40.0, -18.91711630122066, 80.0, -20.796381287951117, 0.0, -21.060122673917263, 0.0, 40.0, 50.092270338161825, -6.286747526685895, 0.0, 20.0, -9.785834606079113, 84.46034252362188, 0.0, 60.0, -17.834162903761626, 0.0, 0.0, 60.0, 60.0, -17.6537881072323, 62.69858520147677, -24.36223822206501, -19.52628848419407, 0.0, 40.0, 0.0, -6.52151501904147, 0.0, 60.0, 60.0, 60.0, 60.0, -3.3648987792250065, -12.880878945875283, 40.0, -2.1057103064888474], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [0.0, -24.711644022027446, 0.0, -20.0, 0.0, 0.0, -20.10734532826419, 0.0, 0.0, -2.3723004437094968, 0.0, -30.0, 0.0, 0.0, -40.0, -10.0, -7.453660080023164, -31.016966030289396, 0.0, -28.507149471725857, -10.0, 0.0, 0.0, -2.886492069826229, -40.0, -21.887404944488154, 0.0, -0.19163348245062495, 0.0, -26.79023102042001, -52.96339144272348, -3.494541256968822, -59.49316378792638, 0.0, -41.94356992874461, -10.352728828664663, 0.0, -20.0, -34.39511784554284, -20.0, -10.0, 0.0, -4.825917175253699, -6.32299577520009, 0.0, 0.0, -40.0, 0.0, -10.0, 0.0, -20.0, 0.0, -30.0, -30.0, -5.443724197128287, -11.324701065138475, 0.0, 0.0, -29.82331730046528, 0.0, -30.0, 0.0, -25.063605030149972, -20.0, -1.7807383690513456, -3.906022256805789, -30.0, -20.0, -0.7892256924841679, -52.370828306682355, -20.0, 0.0, 0.0, -40.0, -38.03937509532911, 0.0, -4.489151689873695, -0.2347674993165194, -28.789922764676447, -30.0, -0.06476157850234476, -30.0, -11.269186002049448, -0.04812219914908211, 0.0, -11.702156275691587, -3.4846043410620586, -0.8641445466926634, 0.0, -30.201725730892477, -11.81093122128242, -30.0, -11.156002088646046, -1.2855404420287098, -10.0, 0.0, -19.738233196644718, -30.0, -1.6336093134484297, 0.0, -50.13364017593224, -30.06783283021373, 0.0, 0.0, -50.0, -3.243768944680979, -10.275847103868985, -21.005444432482566, 0.0, -30.57630265613983, 0.0, -37.939614339905646, -60.37084623761472, -72.42048662313373, -30.0, -40.0, -30.0, 0.0, -7.46174300026232, -4.501354051244494, 0.0, 0.0, -20.0, -20.147894524840254, -20.0, -18.91711630122066, -40.0, -20.796381287951117, 0.0, -21.060122673917263, 0.0, -20.0, -39.907729661838175, -6.286747526685895, 0.0, -10.0, -9.785834606079113, -65.53965747637812, 0.0, -30.0, -17.834162903761626, 0.0, 0.0, -30.0, -30.0, -17.6537881072323, -57.30141479852325, -24.36223822206501, -19.52628848419407, 0.0, -20.0, 0.0, -6.52151501904147, 0.0, -30.0, -30.0, -30.0, -30.0, -3.3648987792250065, -42.88087894587528, -20.0, -32.10571030648885]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6869214790826641, "mean_inference_ms": 1.1937366735432027, "mean_action_processing_ms": 0.2522439971592707, "mean_env_wait_ms": 0.5133273451066074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00471509533163942, "StateBufferConnector_ms": 0.003176486050641095, "ViewRequirementAgentConnector_ms": 0.0920712947845459}, "num_episodes": 162, "episode_return_max": 137.5795133768663, "episode_return_min": -37.939614339905646, "episode_return_mean": 19.15419809161582}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 280.3284932441402, "num_env_steps_trained_throughput_per_sec": 280.3284932441402, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 14935.692, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14935.647, "sample_time_ms": 1235.371, "learn_time_ms": 13683.855, "learn_throughput": 292.315, "synch_weights_time_ms": 15.259}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-50-21", "timestamp": 1723139421, "time_this_iter_s": 14.275882959365845, "time_total_s": 857.9045016765594, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b99e430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 857.9045016765594, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 31.876190476190487, "ram_util_percent": 82.57619047619048}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0482105553150176, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3596370305866, "policy_loss": -0.01656843243399635, "vf_loss": 3.374234953771035, "vf_explained_var": 0.018292728004356225, "kl": 0.00985249309129895, "entropy": 1.1552674237638711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7585371355321391, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1639114053536814, "policy_loss": -0.017543538701216894, "vf_loss": 2.180241577929639, "vf_explained_var": -1.951861888804334e-06, "kl": 0.006066823964377215, "entropy": 0.8823984752098719, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 139590.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -22.79516393335323, "episode_reward_mean": 20.148679894872018, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.358024691358025, "agent_policy": -13.925394179202057}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 51.03760618742276, 34.23241797691451, -8.02743934975066, 0.0, 0.0, 0.0, 54.38665929971718, 0.0, -4.041030714067614, 0.0, 0.0, 55.671565924752024, 0.0, 0.0, -1.1788955847577731, 36.29464224501506, -10.0061343590174, 79.7423871778334, 0.0, 0.0, 40.0, 0.0, -3.5306275387292767, 60.0, 39.9563124333561, 37.57224333603762, 0.0, 40.0, -3.0052013655023773, 0.0, 0.0, 0.0, 39.56581829383214, 40.0, -10.735596668841664, 40.0, 0.0, -4.245712184977801, 40.0, 100.0, 0.0, 17.213167353830098, 60.0, 0.0, 36.0851542873757, -0.997533053226205, -0.12779664901157228, 80.0, 0.0, 0.0, 38.143960885150264, 79.76813505102683, -0.6583707248378423, 18.410845540402168, 0.0, -22.247213779204714, -14.934724495904518, 0.0, 60.0, -2.697164388051111, 160.0, -19.35447627973468, 39.616051756479635, -0.5357596062308967, 40.0, 80.0, 0.0, 0.0, -1.376843971553352, -0.3542744738263315, -2.2956910646640205, -1.3396151209514406, 0.0, 0.0, 33.38071928810999, 60.0, 40.0, 32.3210390933554, 0.0, 0.0, 19.097190538281577, -10.4671018625704, 96.00110002952574, -5.567261909726585, 36.35270984850386, -0.20008329200482455, 0.0, 60.0, 69.08861805999406, 0.0, 0.0, 0.0, 27.643741258943912, 27.035662983328407, 0.0, 0.0, 100.0, 60.0, 0.0, 80.0, 40.0, -7.5855907537031095, 0.0, 120.0, -1.992157484449405, 0.0, 0.0, 26.56472692271342, -0.770412286993235, 20.0, 20.0, 0.0, 0.0, 0.0, -8.66377128192729, 55.35579040399183, 40.0, 80.0, 60.0, 0.0, -18.485340211574268, 0.0, 60.0, 0.0, 0.0, 20.0, 0.0, 0.0, 41.872731349361665, 0.0, 60.0, -5.436816293841081, 20.0, 0.0, 0.0, 60.0, -21.457029224894963, 19.572072057032244, 100.0, -22.30397788914526, 0.0, -22.79516393335323, 0.0, 0.0, 80.0, 60.0, 0.0, 60.0, 40.0, 0.0, 0.0, 80.0, 40.0, -0.28082889323533866, -0.2012899227605558, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, -38.96239381257724, -25.76758202308548, -8.02743934975066, 0.0, 0.0, 0.0, -35.61334070028282, 0.0, -4.041030714067614, 0.0, 0.0, -34.328434075247976, 0.0, 0.0, -1.1788955847577731, -23.70535775498493, -10.0061343590174, -40.25761282216661, 0.0, 0.0, -20.0, 0.0, -3.5306275387292767, -30.0, -20.043687566643893, -52.427756663962384, 0.0, -20.0, -3.0052013655023773, 0.0, 0.0, 0.0, -20.43418170616786, -20.0, -10.735596668841664, -20.0, 0.0, -4.245712184977801, -20.0, -50.0, 0.0, -12.786832646169904, -30.0, 0.0, -23.914845712624302, -0.997533053226205, -0.12779664901157228, -40.0, 0.0, 0.0, -51.856039114849736, -40.23186494897317, -0.6583707248378423, -11.589154459597834, 0.0, -22.247213779204714, -14.934724495904518, 0.0, -30.0, -2.697164388051111, -80.0, -19.35447627973468, -20.38394824352036, -0.5357596062308967, -20.0, -40.0, 0.0, 0.0, -1.376843971553352, -0.3542744738263315, -2.2956910646640205, -1.3396151209514406, 0.0, 0.0, -26.619280711890035, -30.0, -20.0, -27.6789609066446, 0.0, 0.0, -10.902809461718423, -10.4671018625704, -53.99889997047425, -5.567261909726585, -23.64729015149614, -0.20008329200482455, 0.0, -30.0, -50.91138194000594, 0.0, 0.0, 0.0, -32.35625874105609, -32.96433701667159, 0.0, 0.0, -50.0, -30.0, 0.0, -40.0, -20.0, -7.5855907537031095, 0.0, -60.0, -1.992157484449405, 0.0, 0.0, -33.43527307728658, -0.770412286993235, -10.0, -10.0, 0.0, 0.0, 0.0, -8.66377128192729, -34.64420959600817, -20.0, -40.0, -30.0, 0.0, -18.485340211574268, 0.0, -30.0, 0.0, 0.0, -10.0, 0.0, 0.0, -48.127268650638335, 0.0, -30.0, -5.436816293841081, -10.0, 0.0, 0.0, -30.0, -21.457029224894963, -10.427927942967754, -50.0, -22.30397788914526, 0.0, -22.79516393335323, 0.0, 0.0, -40.0, -30.0, 0.0, -30.0, -20.0, 0.0, 0.0, -40.0, -20.0, -0.28082889323533866, -0.2012899227605558, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6852860875177055, "mean_inference_ms": 1.1910865711799314, "mean_action_processing_ms": 0.25151275123616745, "mean_env_wait_ms": 0.512366962121222, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042588622481734666, "StateBufferConnector_ms": 0.0032034921057430316, "ViewRequirementAgentConnector_ms": 0.08877214090323743}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -22.79516393335323, "episode_return_mean": 20.148679894872018}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 273.6532886342146, "num_env_steps_trained_throughput_per_sec": 273.6532886342146, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 14904.481, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14904.435, "sample_time_ms": 1228.378, "learn_time_ms": 13659.607, "learn_throughput": 292.834, "synch_weights_time_ms": 15.334}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-50-36", "timestamp": 1723139436, "time_this_iter_s": 14.624070167541504, "time_total_s": 872.528571844101, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f93a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 872.528571844101, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 32.95, "ram_util_percent": 82.46499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2159667703012627, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.120863325397173, "policy_loss": -0.020842000376675666, "vf_loss": 4.139856559783221, "vf_explained_var": 0.09002472528566917, "kl": 0.00924378798718711, "entropy": 1.1771141755084196, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7691968598475692, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.18382661752667, "policy_loss": -0.017866755894415002, "vf_loss": 2.2003915483224477, "vf_explained_var": 2.4702109343616674e-07, "kl": 0.006509128487039596, "entropy": 0.8518875609052942, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 142410.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 138.51574209551367, "episode_reward_min": -47.3683726186654, "episode_reward_mean": 16.44197002536963, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -71.48425790448633}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.522875816993464, "agent_policy": -15.12665742561076}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.406710033277506, 40.0, 44.83203726938307, -0.9547966423401144, -3.2497013316660928, 20.0, 60.0, 20.0, 0.0, -16.243162881634646, 59.8087822419645, 20.0, 60.0, 0.0, -5.996718952348411, 0.0, 29.302020169538608, -14.155462165904249, 0.0, -0.864872338314715, -14.275347870725913, -24.991858461459472, 0.0, -42.484647606870695, 40.0, 0.0, 0.0, -0.3032809628422406, 0.0, 97.80127637955448, 36.49432004372102, 20.0, 33.88370750599146, 0.0, -17.32073470683761, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, 39.90113925700889, 120.0, -17.999032242626598, -4.7498328918454575, 0.0, 60.0, -5.261030162661566, -7.854428451011053, -0.6282599058995697, 80.0, 0.0, 0.0, 78.08450191927135, -20.194503479132866, 0.0, -14.239392916847967, 0.0, 0.0, 16.541813600470388, 100.0, -2.704175981260323, 0.0, 0.0, 58.49829728169014, -28.246096656660136, 138.51574209551367, 40.0, 0.0, 0.0, 0.0, 0.0, -20.97142679036788, 40.0, 0.0, 74.48775352501815, 75.45317210603122, 40.0, 0.0, -5.315376834128656, 0.0, 80.0, 120.0, -0.30625097374090804, 20.0, 0.0, 0.0, -0.610596797434082, 0.0, 20.0, -5.78155441399533, 59.28317327100379, 0.0, -9.301823965380184, -6.125979554534106, 0.0, -11.207789045636718, -8.0185244662027, -12.096114181490577, -14.455957285557304, -13.506857404961131, 0.0, 40.0, 30.28773133722774, 51.14625931231093, 20.0, -7.481650934364409, 0.0, -2.942966806245982, 0.0, 0.0, 79.94589970817576, -17.477096602987338, 60.0, 60.0, 40.0, -17.65926732327475, -17.6185715739926, 0.0, -4.3027418461219815, 0.0, 0.0, 54.73115705237561, 100.0, 0.0, 52.10421523596621, -47.3683726186654, 60.0, 0.0, 36.58506837498461, 119.09890510389667, -2.479165956072098, 0.0, -3.658369069121602, 40.0, 0.0, 0.0, 40.0, 59.68235926298772, 0.0, -16.727593554768852, 60.0, 53.73636059380566, 0.0, -1.392917949547493, 100.0, -20.018376926694202, 0.0, -1.56394608999888, -15.45740688145516, -24.740671047697308, -23.266731641592703, -9.419553654695521], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.593289966722493, -20.0, -45.16796273061692, -0.9547966423401144, -3.2497013316660928, -10.0, -30.0, -10.0, 0.0, -16.243162881634646, -30.191217758035496, -10.0, -30.0, 0.0, -5.996718952348411, 0.0, -30.697979830461392, -14.155462165904249, 0.0, -0.864872338314715, -14.275347870725913, -24.991858461459472, 0.0, -42.484647606870695, -20.0, 0.0, 0.0, -0.3032809628422406, 0.0, -52.19872362044551, -23.505679956278982, -10.0, -26.11629249400854, 0.0, -17.32073470683761, 0.0, -40.0, 0.0, 0.0, 0.0, 0.0, -20.098860742991107, -60.0, -17.999032242626598, -4.7498328918454575, 0.0, -30.0, -5.261030162661566, -7.854428451011053, -0.6282599058995697, -40.0, 0.0, 0.0, -41.91549808072867, -20.194503479132866, 0.0, -14.239392916847967, 0.0, 0.0, -43.458186399529616, -50.0, -2.704175981260323, 0.0, 0.0, -31.50170271830986, -28.246096656660136, -71.48425790448633, -20.0, 0.0, 0.0, 0.0, 0.0, -20.97142679036788, -20.0, 0.0, -45.51224647498185, -44.546827893968796, -20.0, 0.0, -5.315376834128656, 0.0, -40.0, -60.0, -0.30625097374090804, -10.0, 0.0, 0.0, -0.610596797434082, 0.0, -10.0, -5.78155441399533, -30.71682672899622, 0.0, -9.301823965380184, -6.125979554534106, 0.0, -11.207789045636718, -8.0185244662027, -12.096114181490577, -14.455957285557304, -13.506857404961131, 0.0, -20.0, -29.71226866277226, -38.85374068768907, -10.0, -7.481650934364409, 0.0, -2.942966806245982, 0.0, 0.0, -40.05410029182424, -17.477096602987338, -30.0, -30.0, -20.0, -17.65926732327475, -17.6185715739926, 0.0, -4.3027418461219815, 0.0, 0.0, -35.26884294762439, -50.0, 0.0, -37.895784764033785, -47.3683726186654, -30.0, 0.0, -23.41493162501539, -60.901094896103324, -2.479165956072098, 0.0, -3.658369069121602, -20.0, 0.0, 0.0, -20.0, -30.31764073701229, 0.0, -16.727593554768852, -30.0, -36.26363940619434, 0.0, -1.392917949547493, -50.0, -20.018376926694202, 0.0, -1.56394608999888, -15.45740688145516, -24.740671047697308, -23.266731641592703, -9.419553654695521]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6873121607580496, "mean_inference_ms": 1.1933577124949561, "mean_action_processing_ms": 0.2514720026098325, "mean_env_wait_ms": 0.512975008695731, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005651455299527037, "StateBufferConnector_ms": 0.003667049158632366, "ViewRequirementAgentConnector_ms": 0.11499902002172532}, "num_episodes": 153, "episode_return_max": 138.51574209551367, "episode_return_min": -47.3683726186654, "episode_return_mean": 16.44197002536963}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.60819263015776, "num_env_steps_trained_throughput_per_sec": 229.60819263015776, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 15217.888, "restore_workers_time_ms": 0.012, "training_step_time_ms": 15217.843, "sample_time_ms": 1261.042, "learn_time_ms": 13939.872, "learn_throughput": 286.947, "synch_weights_time_ms": 15.765}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-50-53", "timestamp": 1723139453, "time_this_iter_s": 17.452919960021973, "time_total_s": 889.9814918041229, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf2e280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 889.9814918041229, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 46.52, "ram_util_percent": 82.29199999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1151870618884763, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.716915342211723, "policy_loss": -0.02259514848216592, "vf_loss": 3.737399941931168, "vf_explained_var": 0.06628570711861054, "kl": 0.010552760372448811, "entropy": 1.1908545753608146, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7810310965417124, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.103399321542564, "policy_loss": -0.018026287396147794, "vf_loss": 2.1201333479678377, "vf_explained_var": -2.0756789133058373e-06, "kl": 0.006461309324224061, "entropy": 0.854432054593208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 145230.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 136.2517103182599, "episode_reward_min": -38.940002234267, "episode_reward_mean": 16.674662560539947, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -92.13385425551306}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.37037037037037, "agent_policy": -14.436448550571162}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-26.28137559419618, -1.2084622299236147, -6.459192456503625, 0.0, 0.0, -1.1862402148124052, 79.79225374924708, 20.0, 39.329188628475336, -4.229760538994691, 0.0, -3.8946910792480756, 0.0, 73.95552147875391, 20.0, -11.406671868960224, 60.0, 0.0, -19.815554858904214, 0.0, 0.0, 20.0, 0.0, 40.0, 60.0, 100.0, -15.096176331358173, -16.65644604469535, 40.0, 0.0, 0.0, 0.0, 0.0, -1.0847494038282723, -0.10961029293670155, -0.10739336845421166, 0.0, 60.0, 132.74204316330724, 0.0, -17.47803409566611, -8.042814724440735, 0.0, 0.0, 60.0, 0.0, 60.0, 34.99357195210308, 0.0, -18.30252913565087, -6.431384030880358, 0.0, 78.40150521691642, 0.0, 0.0, -2.086343306856435, -18.944328752251593, -7.842787279891372, 0.0, 0.0, 0.0, -5.858346147850178, -6.8747354186539615, 0.0, 0.0, -0.6614645476589571, 19.614758231863505, 35.66226052614386, 0.0, 37.563129684828425, -19.800152551201286, 120.0, 0.0, 80.0, 0.0, -2.4359942403447996, 29.76192941411381, -2.3574624777639097, 20.0, -0.22350298266417434, -29.58359897785624, 0.0, 80.0, -16.946281115813953, 0.0, 0.0, 33.8568916366857, 0.0, 60.0, 0.0, -5.227171989981385, -4.277328039868619, -10.941344116013072, 100.0, 40.0, 60.0, 0.0, -9.675011754211637, 0.0, 0.0, 0.0, 19.919808696368197, 98.31847428786217, 76.11290336189015, 80.0, 68.14129845760166, 0.0, 40.0, -1.2841707913385192, -9.097174283125584, -17.03955934237152, 0.0, 0.0, -17.433224901368863, 0.0, 0.0, -10.989984644827162, 60.0, 20.33572988651079, 60.0, 40.0, -3.6684969676977066, 0.0, 0.0, 117.86614574448697, 0.0, 100.0, -3.8946953874661574, 40.0, 60.0, 17.81378286139213, 60.0, 0.0, -4.602992091714064, -38.940002234267, -1.5366609484589266, -1.9106063229632342, 20.0, -2.3905354729212247, 0.0, 40.0, 0.0, 60.0, 40.0, -3.686395648170742, -0.3678107998801372, -1.918637284891438, 0.0, 20.0, 0.0, 0.0, 20.0, 136.2517103182599, 0.0, -13.441682451297638, 0.0, 0.0, -6.835900173901667, 51.42789722565824, 40.0, 60.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-26.28137559419618, -1.2084622299236147, -6.459192456503625, 0.0, 0.0, -1.1862402148124052, -40.20774625075292, -10.0, -20.670811371524664, -4.229760538994691, 0.0, -3.8946910792480756, 0.0, -76.04447852124609, -10.0, -11.406671868960224, -30.0, 0.0, -19.815554858904214, 0.0, 0.0, -10.0, 0.0, -20.0, -30.0, -50.0, -45.09617633135818, -16.65644604469535, -20.0, 0.0, 0.0, 0.0, 0.0, -1.0847494038282723, -0.10961029293670155, -0.10739336845421166, 0.0, -30.0, -77.25795683669274, 0.0, -17.47803409566611, -8.042814724440735, 0.0, 0.0, -30.0, 0.0, -30.0, -25.006428047896925, 0.0, -18.30252913565087, -6.431384030880358, 0.0, -41.59849478308358, 0.0, 0.0, -2.086343306856435, -18.944328752251593, -7.842787279891372, 0.0, 0.0, 0.0, -5.858346147850178, -6.8747354186539615, 0.0, 0.0, -30.66146454765896, -40.385241768136495, -24.33773947385614, 0.0, -22.436870315171575, -19.800152551201286, -60.0, 0.0, -40.0, 0.0, -2.4359942403447996, -30.238070585886184, -2.3574624777639097, -10.0, -0.22350298266417434, -29.58359897785624, 0.0, -40.0, -16.946281115813953, 0.0, 0.0, -26.143108363314294, 0.0, -30.0, 0.0, -5.227171989981385, -4.277328039868619, -10.941344116013072, -50.0, -20.0, -30.0, 0.0, -9.675011754211637, 0.0, 0.0, 0.0, -10.0801913036318, -51.68152571213785, -43.88709663810985, -40.0, -51.85870154239831, 0.0, -20.0, -1.2841707913385192, -39.09717428312558, -17.03955934237152, 0.0, 0.0, -17.433224901368863, 0.0, 0.0, -10.989984644827162, -30.0, -39.66427011348921, -30.0, -20.0, -3.6684969676977066, 0.0, 0.0, -92.13385425551306, 0.0, -50.0, -3.8946953874661574, -20.0, -30.0, -12.186217138607871, -30.0, 0.0, -4.602992091714064, -38.940002234267, -1.5366609484589266, -1.9106063229632342, -10.0, -2.3905354729212247, 0.0, -20.0, 0.0, -30.0, -20.0, -3.686395648170742, -0.3678107998801372, -1.918637284891438, 0.0, -10.0, 0.0, 0.0, -10.0, -73.74828968174009, 0.0, -13.441682451297638, 0.0, 0.0, -6.835900173901667, -38.57210277434176, -20.0, -30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6863953993495246, "mean_inference_ms": 1.1913808246563693, "mean_action_processing_ms": 0.25086977443466396, "mean_env_wait_ms": 0.512345855128757, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047604978820424025, "StateBufferConnector_ms": 0.0032870857803909866, "ViewRequirementAgentConnector_ms": 0.09248138945779683}, "num_episodes": 162, "episode_return_max": 136.2517103182599, "episode_return_min": -38.940002234267, "episode_return_mean": 16.674662560539947}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 288.0007278460777, "num_env_steps_trained_throughput_per_sec": 288.0007278460777, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 15157.035, "restore_workers_time_ms": 0.012, "training_step_time_ms": 15156.964, "sample_time_ms": 1222.646, "learn_time_ms": 13916.571, "learn_throughput": 287.427, "synch_weights_time_ms": 16.343}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-51-07", "timestamp": 1723139467, "time_this_iter_s": 13.931629180908203, "time_total_s": 903.9131209850311, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf2e4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 903.9131209850311, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 33.92, "ram_util_percent": 80.55499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0127778093641004, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8563220183054607, "policy_loss": -0.02073493290420932, "vf_loss": 3.875030067563057, "vf_explained_var": 0.011783318283657232, "kl": 0.010134499662525337, "entropy": 1.1741291670749585, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7419465067327445, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.676689511114824, "policy_loss": -0.019757014340869686, "vf_loss": 2.695044695739205, "vf_explained_var": -2.4207940338351203e-06, "kl": 0.007009159738494515, "entropy": 0.8188848645763195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 148050.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -35.294244019557546, "episode_reward_mean": 24.333886126630965, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.703703703703704, "agent_policy": -16.777224984480142}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -1.3971476339039435, -8.100788883704837, -2.957613812815638, -35.294244019557546, -0.9729591676758609, 76.5032193295335, 60.0, 0.0, 60.0, 60.0, 60.0, -5.238254920183141, -0.05578995233313733, 0.0, -13.971287511843238, 0.0, 0.0, 0.0, 60.0, 60.0, 15.333765945579225, -0.3160957910632012, 100.0, -9.730127012598416, 0.0, -1.310424563032578, 40.0, 39.71814140455883, 0.0, -0.8819785101349731, 0.0, 60.0, -14.278646265776379, 19.19719800858978, -2.3371292281404914, 29.60452909054691, 0.0, 0.0, 0.0, 60.0, -10.071416268011168, 60.0, 0.0, 40.0, -7.437576654646746, -25.66880938505181, 0.0, 40.0, -5.135998496546698, 43.60003087743073, -0.149681543494663, 96.38250271198353, 0.0, 0.0, 0.0, 140.0, 0.0, 40.0, 0.0, 60.0, 18.393131699535978, 0.0, -0.9448519659806132, 0.0, 0.0, 80.0, 63.86592548969902, 0.0, 60.0, -3.4072748174366563, 80.0, 100.0, -23.475357716001824, 20.0, 52.840057717281795, 0.0, 0.0, 0.0, 0.0, 32.64640084928278, 80.0, -12.848469312035963, -0.03996978494894998, 60.0, 40.0, 0.0, 60.0, 38.68251195311904, -14.502245353170517, -0.4180773912596458, -7.327461745070704, 100.0, 0.0, 60.0, -10.542547447019679, 40.0, 60.0, 200.0, 40.0, 132.92290655330362, 40.0, 60.0, 60.0, -16.460325494142662, -0.847994653234625, 0.0, 0.0, 0.0, 60.0, 0.0, 200.0, 40.0, -19.471881682049986, 0.0, -1.6321416681347267, 60.0, 20.0, 0.0, 60.0, -0.9986897111054815, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -3.327602497020992, 0.0, -22.134779276013067, 54.709886232261994, 0.0, 40.0, 53.93277028441719, -5.003227064131096, 40.0, 120.0, 0.0, -31.154653558828223, 0.0, -16.999621369779707, 20.0, 80.0, 16.17595751799762, 40.0, 60.0, 40.0, 0.0, -0.9388098029629321, 0.0, 0.0, 100.0, 0.0, 0.0, 140.0, 20.0, 60.0, 40.0, -0.6023550874222905, -4.035076132640077], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 100.0, 100.0, 100.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -1.3971476339039435, -8.100788883704837, -2.957613812815638, -35.294244019557546, -0.9729591676758609, -43.496780670466514, -30.0, 0.0, -30.0, -30.0, -30.0, -5.238254920183141, -0.05578995233313733, 0.0, -13.971287511843238, 0.0, 0.0, 0.0, -30.0, -30.0, -44.66623405442077, -0.3160957910632012, -50.0, -9.730127012598416, 0.0, -1.310424563032578, -20.0, -20.28185859544117, 0.0, -0.8819785101349731, 0.0, -30.0, -14.278646265776379, -10.802801991410218, -2.3371292281404914, -60.39547090945309, 0.0, 0.0, 0.0, -30.0, -10.071416268011168, -30.0, 0.0, -20.0, -7.437576654646746, -25.66880938505181, 0.0, -20.0, -5.135998496546698, -46.39996912256927, -0.149681543494663, -53.617497288016466, 0.0, 0.0, 0.0, -70.0, 0.0, -20.0, 0.0, -30.0, -11.606868300464024, 0.0, -0.9448519659806132, 0.0, 0.0, -40.0, -56.134074510300984, 0.0, -30.0, -3.4072748174366563, -40.0, -50.0, -23.475357716001824, -10.0, -37.159942282718205, 0.0, 0.0, 0.0, 0.0, -27.353599150717223, -40.0, -12.848469312035963, -0.03996978494894998, -30.0, -20.0, 0.0, -30.0, -21.31748804688096, -14.502245353170517, -0.4180773912596458, -7.327461745070704, -50.0, 0.0, -30.0, -10.542547447019679, -20.0, -30.0, -100.0, -20.0, -77.07709344669641, -20.0, -30.0, -30.0, -16.460325494142662, -0.847994653234625, 0.0, 0.0, 0.0, -30.0, 0.0, -100.0, -20.0, -19.471881682049986, 0.0, -1.6321416681347267, -30.0, -10.0, 0.0, -30.0, -0.9986897111054815, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -33.327602497021005, 0.0, -22.134779276013067, -35.29011376773801, 0.0, -20.0, -36.06722971558281, -5.003227064131096, -20.0, -60.0, 0.0, -31.154653558828223, 0.0, -16.999621369779707, -10.0, -40.0, -13.82404248200238, -20.0, -30.0, -20.0, 0.0, -0.9388098029629321, 0.0, 0.0, -50.0, 0.0, 0.0, -70.0, -10.0, -30.0, -20.0, -0.6023550874222905, -4.035076132640077]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6854588024739369, "mean_inference_ms": 1.189879410514831, "mean_action_processing_ms": 0.2503784915864521, "mean_env_wait_ms": 0.5118969539382111, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005326815593389817, "StateBufferConnector_ms": 0.0034202764063705634, "ViewRequirementAgentConnector_ms": 0.09080465929007825}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -35.294244019557546, "episode_return_mean": 24.333886126630965}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 273.2472259786378, "num_env_steps_trained_throughput_per_sec": 273.2472259786378, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 15181.943, "restore_workers_time_ms": 0.012, "training_step_time_ms": 15181.871, "sample_time_ms": 1222.569, "learn_time_ms": 13939.923, "learn_throughput": 286.946, "synch_weights_time_ms": 17.928}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-51-22", "timestamp": 1723139482, "time_this_iter_s": 14.650742053985596, "time_total_s": 918.5638630390167, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf2e820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 918.5638630390167, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 36.009523809523806, "ram_util_percent": 81.82857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1577374383807184, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.209503406782945, "policy_loss": -0.02144676488096593, "vf_loss": 4.228744057565928, "vf_explained_var": 0.034788946310679116, "kl": 0.011030579830183922, "entropy": 1.1608107820153237, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7390479872412715, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4666984439741637, "policy_loss": -0.016998471798185765, "vf_loss": 2.48241725775367, "vf_explained_var": -4.015493054761954e-07, "kl": 0.006398312826716714, "entropy": 0.8362427372458979, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 150870.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -38.55513782528344, "episode_reward_mean": 16.728908644987815, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.679012345679013, "agent_policy": -15.308128392049223}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.11113627356421, -4.578120002236784, 0.0, 20.0, 39.93678386004575, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4266151874573654, 25.233809567564506, 0.0, 45.7425444207751, -0.5092158122042079, 20.0, 0.0, -0.13343524457408273, 7.001293109658896, -8.836544220096169, 39.582351008591985, 37.6576219596301, 0.0, 59.461797284923264, -2.048929416952723, 0.0, 60.0, 18.236937344892013, 0.0, -2.180141052959513, 0.0, 52.618048705295195, 0.0, 0.0, -7.326556513463251, 13.897327200031677, 0.0, 80.0, 57.190298975137935, 60.0, 60.0, 0.0, 60.0, -19.31983782432243, 80.0, 60.0, -6.901401598265215, 0.0, -1.859497217434699, -9.189792073686876, -9.68001091370345, 19.746641099529576, 0.0, 0.0, 0.0, 60.0, -3.4097223742824028, 180.0, 0.0, -27.127627911260788, -36.4348954005111, 0.0, 0.0, -35.743869483070156, 80.0, 0.0, 0.0, 80.0, 119.80034679482426, 80.0, 0.0, 0.0, 40.0, 54.43883419282954, -5.484336662581754, 0.0, -19.73058553951905, -0.6199695836192676, 0.0, -9.371377374071646, -4.349996452428834, 40.0, 60.0, 60.0, -5.783468087870505, 39.071589554083666, 39.80241199913772, 20.0, 60.0, 0.0, 59.59769131517998, 0.0, -22.82809469182907, -19.363074268534767, -22.252933668262894, 0.0, 40.0, -2.156929454399119, 31.1844817339341, 0.0, 60.0, 0.0, 28.742962839017945, -6.368196445160708, -2.6621452878471885, 20.0, -13.542813804629557, -5.39288906337489, 100.0, 13.111148629413133, 0.0, -38.55513782528344, 58.80237925372806, 37.599705880256195, 0.0, 20.0, 0.0, 18.04575753204297, -8.956564312119253, 52.65270969413395, 6.757412271910987, -38.39692654870392, -17.4155872259362, 0.0, 0.0, 0.0, 0.0, 29.87092954010144, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, -4.427021142232528, -2.604300294139062, 0.0, 60.0, -4.072760103668234, -7.392173479514251, 0.0, -2.071529755999758, 0.0, 0.0, 60.0, 46.77292735105687, 0.0, 0.0, 120.0, 0.0, 39.18846533830236, 0.0, -7.351792880237214, 40.0, 0.0, -18.766059132735492, 20.0, 20.0, 0.0, 40.0, -29.91856611355754, -5.2317027968299], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-40.88886372643579, -4.578120002236784, 0.0, -10.0, -20.063216139954253, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4266151874573654, -34.766190432435494, 0.0, -44.25745557922491, -0.5092158122042079, -10.0, 0.0, -0.13343524457408273, -22.998706890341104, -8.836544220096169, -20.417648991408015, -22.3423780403699, 0.0, -30.538202715076736, -32.048929416952724, 0.0, -30.0, -11.763062655107989, 0.0, -2.180141052959513, 0.0, -37.381951294704805, 0.0, 0.0, -7.326556513463251, -16.102672799968317, 0.0, -40.0, -32.80970102486207, -30.0, -30.0, 0.0, -30.0, -19.31983782432243, -40.0, -30.0, -6.901401598265215, 0.0, -1.859497217434699, -9.189792073686876, -9.68001091370345, -10.253358900470424, 0.0, 0.0, 0.0, -30.0, -3.4097223742824028, -90.0, 0.0, -27.127627911260788, -36.4348954005111, 0.0, 0.0, -35.743869483070156, -40.0, 0.0, 0.0, -40.0, -60.19965320517574, -40.0, 0.0, 0.0, -20.0, -35.56116580717046, -5.484336662581754, 0.0, -19.73058553951905, -0.6199695836192676, 0.0, -9.371377374071646, -4.349996452428834, -20.0, -30.0, -30.0, -35.78346808787051, -20.928410445916345, -20.197588000862286, -10.0, -30.0, 0.0, -60.40230868482001, 0.0, -22.82809469182907, -19.363074268534767, -22.252933668262894, 0.0, -20.0, -2.156929454399119, -28.8155182660659, 0.0, -30.0, 0.0, -61.25703716098206, -6.368196445160708, -2.6621452878471885, -10.0, -13.542813804629557, -5.39288906337489, -50.0, -16.888851370586867, 0.0, -38.55513782528344, -31.19762074627194, -22.400294119743812, 0.0, -10.0, 0.0, -11.954242467957028, -8.956564312119253, -67.34729030586603, -23.242587728089013, -38.39692654870392, -17.4155872259362, 0.0, 0.0, 0.0, 0.0, -30.129070459898568, 0.0, 0.0, -20.0, -20.0, -20.0, -30.0, -4.427021142232528, -2.604300294139062, 0.0, -30.0, -4.072760103668234, -7.392173479514251, 0.0, -2.071529755999758, 0.0, 0.0, -30.0, -43.22707264894313, 0.0, 0.0, -60.0, 0.0, -20.811534661697642, 0.0, -7.351792880237214, -20.0, 0.0, -18.766059132735492, -10.0, -10.0, 0.0, -20.0, -29.91856611355754, -5.2317027968299]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6840008784443803, "mean_inference_ms": 1.1873433726003457, "mean_action_processing_ms": 0.24975568933545866, "mean_env_wait_ms": 0.5110212161895821, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004168719421198339, "StateBufferConnector_ms": 0.0031698633123327185, "ViewRequirementAgentConnector_ms": 0.08854115450823749}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -38.55513782528344, "episode_return_mean": 16.728908644987815}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.2122468022653, "num_env_steps_trained_throughput_per_sec": 291.2122468022653, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 15082.365, "restore_workers_time_ms": 0.012, "training_step_time_ms": 15082.299, "sample_time_ms": 1212.113, "learn_time_ms": 13851.494, "learn_throughput": 288.778, "synch_weights_time_ms": 17.802}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-51-36", "timestamp": 1723139496, "time_this_iter_s": 13.744067192077637, "time_total_s": 932.3079302310944, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f1c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 932.3079302310944, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 31.889473684210532, "ram_util_percent": 81.85789473684208}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3284923183421293, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8575102113187314, "policy_loss": -0.021905172308227822, "vf_loss": 3.8772919620076816, "vf_explained_var": 0.022039636597037317, "kl": 0.010617088276288437, "entropy": 1.1487698826938868, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.718229271027636, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0775733632398836, "policy_loss": -0.016038223093372262, "vf_loss": 2.092420212470048, "vf_explained_var": -1.6167654213330425e-06, "kl": 0.005956865170734616, "entropy": 0.7912349232545136, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 153690.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 179.5713481857475, "episode_reward_min": -57.66436142802176, "episode_reward_mean": 13.908148893889217, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.4286518142525}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.980891719745223, "agent_policy": -13.034526265346448}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.0, -7.6980968091586695, -2.8685960667719623, -33.59391570081846, 0.0, 20.0, -11.970814240459559, -0.6049026393124746, 0.0, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, -9.929803688025642, 0.0, 100.0, -1.7866977026336095, 0.0, 100.0, 20.0, 17.99650003428115, 0.0, 120.0, 20.0, -6.561748734319496, 0.0, 60.0, 69.42601988627112, -25.32289140818604, -4.731027014472394, -0.026298080215597652, 60.0, -0.17037326882578196, 20.0, -20.166527765686272, -6.57469945286895, 0.0, -9.557402187220513, 0.0, 35.94979986675071, 0.0, -2.256318984577117, -5.312514253089432, 40.0, -3.4835332808170727, 20.0, -1.1006899036155982, 0.0, 0.0, 20.0, 0.0, -3.1982855489363207, 0.0, -15.67756356621539, 0.0, -0.5544690356065307, -2.349106055527369, 0.0, -1.5993864949325465, 31.72241718037312, 0.0, -4.784635480243095, 0.0, 40.0, 0.0, 0.0, 60.0, -0.10194793105252509, 0.0, 1.2600759938164254, 0.0, -57.66436142802176, 20.0, -6.346662080785217, -3.5968558114889255, 58.855401103209985, -9.183486050966359, 0.0, -4.805720071517777, -16.077162234605403, 34.64498696253576, -7.867299124242878, 107.72667655174767, 0.0, -0.48051539599912596, 40.0, 20.0, 0.0, 0.0, 59.39360478130884, -16.849879081216827, 115.35686295301396, 60.0, 0.0, 0.0, -1.7972635621146782, 60.0, 40.0, 13.714528800281412, -1.4545744555691786, -0.09455755111955733, 0.0, 0.0, 40.0, 0.0, -30.84930995740386, 0.0, 60.0, 20.0, 0.0, 0.0, -0.7948436085842014, 99.87747943151732, -10.358410059969591, 0.0, 0.0, -0.7012643412811503, 0.0, 59.69766382380885, 0.0, 20.0, -38.69303260477975, 0.0, -10.363990987337178, 40.0, -17.371312821834287, -0.886484130729428, 0.0, 0.0, -8.1406719426201, 0.0, -14.948154843151771, 179.5713481857475, 100.0, 40.0, -10.488603241157623, 0.0, 0.0, 73.40297325981612, 0.0, 40.0, -5.171697880523309, -31.51074738344925, 17.516049866763552, 20.0, 0.0, 40.0, -5.063023868846701, 40.0, 35.99594163164094, 17.32514181074282, 0.0, 0.0, 80.0, 7.6880340298844585], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-50.0, -7.6980968091586695, -2.8685960667719623, -33.59391570081846, 0.0, -10.0, -11.970814240459559, -0.6049026393124746, 0.0, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, -9.929803688025642, 0.0, -50.0, -1.7866977026336095, 0.0, -50.0, -10.0, -12.003499965718849, 0.0, -60.0, -10.0, -6.561748734319496, 0.0, -30.0, -50.57398011372888, -25.32289140818604, -4.731027014472394, -0.026298080215597652, -30.0, -0.17037326882578196, -10.0, -20.166527765686272, -6.57469945286895, 0.0, -9.557402187220513, 0.0, -24.05020013324929, 0.0, -2.256318984577117, -5.312514253089432, -20.0, -3.4835332808170727, -10.0, -1.1006899036155982, 0.0, 0.0, -10.0, 0.0, -3.1982855489363207, 0.0, -15.67756356621539, 0.0, -0.5544690356065307, -2.349106055527369, 0.0, -1.5993864949325465, -28.27758281962688, 0.0, -4.784635480243095, 0.0, -20.0, 0.0, 0.0, -30.0, -0.10194793105252509, 0.0, -28.739924006183575, 0.0, -57.66436142802176, -10.0, -6.346662080785217, -3.5968558114889255, -31.144598896790015, -9.183486050966359, 0.0, -4.805720071517777, -16.077162234605403, -25.35501303746424, -7.867299124242878, -72.27332344825234, 0.0, -0.48051539599912596, -20.0, -10.0, 0.0, 0.0, -30.60639521869116, -16.849879081216827, -64.64313704698604, -30.0, 0.0, 0.0, -1.7972635621146782, -30.0, -20.0, -16.28547119971859, -1.4545744555691786, -0.09455755111955733, 0.0, 0.0, -20.0, 0.0, -30.84930995740386, 0.0, -30.0, -10.0, 0.0, 0.0, -0.7948436085842014, -50.122520568482685, -10.358410059969591, 0.0, 0.0, -0.7012643412811503, 0.0, -30.302336176191147, 0.0, -10.0, -38.69303260477975, 0.0, -10.363990987337178, -20.0, -17.371312821834287, -0.886484130729428, 0.0, 0.0, -8.1406719426201, 0.0, -14.948154843151771, -90.4286518142525, -50.0, -20.0, -10.488603241157623, 0.0, 0.0, -76.59702674018388, 0.0, -20.0, -5.171697880523309, -31.51074738344925, -12.483950133236446, -10.0, 0.0, -20.0, -5.063023868846701, -20.0, -54.00405836835906, -12.674858189257181, 0.0, 0.0, -40.0, -22.311965970115534]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6827991085160248, "mean_inference_ms": 1.1855774752575565, "mean_action_processing_ms": 0.24926813942775108, "mean_env_wait_ms": 0.510342723037857, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004496164382643001, "StateBufferConnector_ms": 0.0032015666840182746, "ViewRequirementAgentConnector_ms": 0.09116997384721306}, "num_episodes": 157, "episode_return_max": 179.5713481857475, "episode_return_min": -57.66436142802176, "episode_return_mean": 13.908148893889217}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.39786568034143, "num_env_steps_trained_throughput_per_sec": 131.39786568034143, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 16468.854, "restore_workers_time_ms": 0.012, "training_step_time_ms": 16468.79, "sample_time_ms": 1176.545, "learn_time_ms": 15273.693, "learn_throughput": 261.888, "synch_weights_time_ms": 17.685}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-52-06", "timestamp": 1723139526, "time_this_iter_s": 30.455008029937744, "time_total_s": 962.7629382610321, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b99e670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 962.7629382610321, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 76.9906976744186, "ram_util_percent": 82.94418604651163}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.411470499013861, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.727555823077758, "policy_loss": -0.01956306321226293, "vf_loss": 3.7454287889103095, "vf_explained_var": 0.040210998803377154, "kl": 0.008450560676388904, "entropy": 1.1684997349977493, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7026145538011341, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9296042982568131, "policy_loss": -0.01720619203080258, "vf_loss": 1.9454787233619826, "vf_explained_var": -3.386896552769005e-07, "kl": 0.006658817289359854, "entropy": 0.7844900732133405, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 156510.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 280.0, "episode_reward_min": -36.01558522907624, "episode_reward_mean": 14.988163472951685, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -140.0}, "policy_reward_max": {"adversary_policy": 140.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.683544303797468, "agent_policy": -14.06246943844072}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 0.0, 0.0, 18.10660791384745, 0.0, 0.0, -0.22786350855868887, 0.0, 40.0, 13.655796559801562, -6.10412103245718, 0.0, 20.0, 0.0, 0.0, -25.822084730506525, 0.0, -3.005519904334081, -1.0576141859091692, -9.35876692890281, 19.425032399297905, -14.215017736542597, 0.0, 0.0, -0.3620582016843743, -7.153272091518185, -3.4862148730511135, 58.45870231054967, -21.634381876131265, 0.0, -2.2871824744322433, 0.0, 0.0, 0.0, -3.786087428793101, -11.687900824391699, 0.0, -1.3740243408132846, -1.3124567113745322, -3.269768353704203, -1.3913778038100022, -4.491377225606439, -0.01917535768982237, -1.2152549060026796, -13.591152507395762, 0.0, 79.55190993134089, 0.0, 19.20061032417911, 80.0, 40.0, 0.0, 0.0, -28.79378936480793, 0.0, 280.0, 39.135980041343146, -26.694859534865394, -0.06939618082471788, 0.0, -2.2851529512832043, 19.19563964760281, 0.0, 80.0, 0.0, 0.0, 0.0, -8.040148725380472, 0.0, 40.45544270311928, -29.27347917180782, 40.0, 0.0, -9.16384438801239, -5.425939297491292, 59.528841553068105, -5.166162181137234, -0.14290126922168356, 0.0, 60.0, 0.0, 60.0, -1.3416268394918496, -17.55336854026761, 0.0, 40.0, -14.773284091022974, 0.0, 0.0, -3.1567387975113315, 60.0, 40.0, 14.200510886517772, -2.3218950375714567, -8.473319220562871, 39.77251573598929, 0.0, 40.0, 7.89894991610434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -11.477604206578855, 20.0, 33.29466212686494, -18.720456447465693, 40.0, -2.436228416783498, 40.0, 160.0, 40.0, 0.0, 40.0, -23.640412780716954, 0.0, -16.598008254499835, 27.017483169236627, 0.0, 0.0, 60.0, 15.194390728224793, 0.0, 60.0, -13.797591884282681, 60.0, 40.0, -0.9374256075293372, 140.0, 80.0, -3.169211189120886, 100.0, 100.0, 58.79725821353752, -4.044225230886988, 0.0, 0.0, -0.043817985238909785, -0.0371225601695524, -28.565451603405517, 34.89357456775657, 60.0, 60.0, 0.0, 0.0, 0.0, -36.01558522907624, 0.0, 39.26471974879199, 0.0, 54.768347966892165, 40.0, -10.228026211767366, -0.0152020300568656, 100.0, -14.432199485250628], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 140.0, 140.0, 140.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, 0.0, 0.0, -11.893392086152549, 0.0, 0.0, -0.22786350855868887, 0.0, -20.0, -16.344203440198438, -6.10412103245718, 0.0, -10.0, 0.0, 0.0, -25.822084730506525, 0.0, -3.005519904334081, -1.0576141859091692, -9.35876692890281, -10.574967600702095, -14.215017736542597, 0.0, 0.0, -0.3620582016843743, -7.153272091518185, -3.4862148730511135, -31.541297689450328, -21.634381876131265, 0.0, -2.2871824744322433, 0.0, 0.0, 0.0, -3.786087428793101, -11.687900824391699, 0.0, -1.3740243408132846, -1.3124567113745322, -3.269768353704203, -1.3913778038100022, -4.491377225606439, -0.01917535768982237, -1.2152549060026796, -13.591152507395762, 0.0, -40.448090068659106, 0.0, -40.799389675820905, -40.0, -20.0, 0.0, 0.0, -28.79378936480793, 0.0, -140.0, -20.864019958656854, -26.694859534865394, -0.06939618082471788, 0.0, -2.2851529512832043, -10.804360352397191, 0.0, -40.0, 0.0, 0.0, 0.0, -8.040148725380472, 0.0, -49.54455729688071, -29.27347917180782, -20.0, 0.0, -9.16384438801239, -5.425939297491292, -30.471158446931902, -5.166162181137234, -0.14290126922168356, 0.0, -30.0, 0.0, -30.0, -1.3416268394918496, -17.55336854026761, 0.0, -20.0, -14.773284091022974, 0.0, 0.0, -3.1567387975113315, -30.0, -20.0, -15.799489113482228, -2.3218950375714567, -8.473319220562871, -50.22748426401073, 0.0, -20.0, -22.10105008389566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -11.477604206578855, -10.0, -26.70533787313507, -18.720456447465693, -20.0, -2.436228416783498, -20.0, -80.0, -20.0, 0.0, -20.0, -23.640412780716954, 0.0, -16.598008254499835, -32.98251683076338, 0.0, 0.0, -30.0, -14.805609271775207, 0.0, -30.0, -13.797591884282681, -30.0, -20.0, -60.937425607529335, -70.0, -40.0, -3.169211189120886, -50.0, -50.0, -31.202741786462486, -4.044225230886988, 0.0, 0.0, -0.043817985238909785, -0.0371225601695524, -28.565451603405517, -55.10642543224343, -30.0, -30.0, 0.0, 0.0, 0.0, -36.01558522907624, 0.0, -20.73528025120801, 0.0, -65.23165203310782, -20.0, -10.228026211767366, -0.0152020300568656, -50.0, -14.432199485250628]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6834478846231804, "mean_inference_ms": 1.1867913666169627, "mean_action_processing_ms": 0.24927618836358464, "mean_env_wait_ms": 0.5109398126034752, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006221894976458972, "StateBufferConnector_ms": 0.003372717507277863, "ViewRequirementAgentConnector_ms": 0.10666424715066258}, "num_episodes": 158, "episode_return_max": 280.0, "episode_return_min": -36.01558522907624, "episode_return_mean": 14.988163472951685}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 226.30474362600603, "num_env_steps_trained_throughput_per_sec": 226.30474362600603, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 16708.754, "restore_workers_time_ms": 0.012, "training_step_time_ms": 16708.688, "sample_time_ms": 1195.255, "learn_time_ms": 15494.585, "learn_throughput": 258.155, "synch_weights_time_ms": 17.834}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-52-24", "timestamp": 1723139544, "time_this_iter_s": 17.73311495780945, "time_total_s": 980.4960532188416, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf4e790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 980.4960532188416, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 45.372, "ram_util_percent": 82.26799999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.967773621280988, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.80436916872859, "policy_loss": -0.02080871850994299, "vf_loss": 3.8231996146341163, "vf_explained_var": 0.08298520911484956, "kl": 0.009891352850267043, "entropy": 1.1657113283872604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7174468084218654, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3939848096658154, "policy_loss": -0.01759038290780051, "vf_loss": 2.4103409425586673, "vf_explained_var": -7.254434815535309e-07, "kl": 0.0061712367436072765, "entropy": 0.7743815397328518, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 159330.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -36.748521819603404, "episode_reward_mean": 18.767565642583083, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -86.22621913874485}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.296296296296296, "agent_policy": -15.121323246305806}, "custom_metrics": {}, "hist_stats": {"episode_reward": [93.77378086125518, -0.6149312974408505, 0.0, 79.72954463659833, 0.0, -7.699619316651016, 20.0, 60.0, 0.0, -24.723919481678962, 24.372543955338504, 40.0, -13.370191167190404, 20.0, 20.0, 0.0, 0.0, 119.31498832875141, 60.0, 21.856738448495978, 59.891169858792665, 58.14343714326284, -9.475341709362024, 60.0, -35.93210755643645, 0.0, 0.0, 0.0, 40.0, 20.0, 0.0, 0.0, 0.0, 0.0, 59.57753834295292, 0.0, -5.352403059895109, 40.0, -33.909350083772416, 0.0, 0.0, -36.748521819603404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -8.220513225691654, 40.0, 38.16881177082206, 28.875093735439368, 0.0, -0.3691268813187998, 0.0, -1.3373875897087206, 0.0, 66.81053231245474, -9.123638186891394, 0.0, 27.3643238264253, -26.784952692793436, 10.16664268767931, 60.0, 120.0, -25.867546745587813, -19.990451303491742, 0.0, 20.0, 0.0, -4.070139952269669, 60.0, 0.0, 0.0, 11.0295912276115, 50.48434168686386, 0.0, 20.0, 40.0, -1.6685477833209184, 0.0, -0.006200513020110376, -8.91660507394059, 0.0, 22.062305583945726, 0.0, 60.0, -1.204825736806876, 0.0, -0.9723518539455411, -7.318134634150718, 78.56280949900587, -0.9292584472708754, -4.933896645586153, 40.0, 20.0, 100.0, 40.0, 20.0, 0.0, 0.0, 59.864861969921066, 40.0, 0.0, 0.0, 60.0, 58.935847501560204, 40.0, -7.121584979203844, -0.1505889791397308, 0.0, 40.0, -3.865986974984472, -2.891123584006192, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, -10.225966882510203, 20.0, -21.635904590853894, 0.0, -2.9278873463674695, 160.0, 0.0, 0.0, 18.298507725743683, -22.84103260895675, -7.793765120739147, -16.436005937308604, -9.621180848552893, 60.0, 120.0, 0.0, 0.0, 0.0, 0.0, -1.7411153641956212, 20.0, 60.0, 0.0, 0.0, 0.0, 80.0, 60.0, 0.0, 0.0, 95.09486611812974, 40.0, 0.0, 0.0, 80.0, 79.68705704603207, 60.0, 18.433846117766088, 59.09122947858002, 0.0, 57.54733020967532, 0.0, 140.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0], "policy_agent_policy_reward": [-86.22621913874485, -0.6149312974408505, 0.0, -40.270455363401666, 0.0, -7.699619316651016, -10.0, -30.0, 0.0, -24.723919481678962, -35.627456044661486, -20.0, -13.370191167190404, -10.0, -10.0, 0.0, 0.0, -60.685011671248574, -30.0, -38.14326155150401, -30.108830141207328, -31.85656285673716, -9.475341709362024, -30.0, -35.93210755643645, 0.0, 0.0, 0.0, -20.0, -10.0, 0.0, 0.0, 0.0, 0.0, -30.42246165704708, 0.0, -5.352403059895109, -20.0, -33.909350083772416, 0.0, 0.0, -66.7485218196034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -8.220513225691654, -20.0, -21.831188229177936, -31.12490626456063, 0.0, -0.3691268813187998, 0.0, -1.3373875897087206, 0.0, -53.189467687545246, -9.123638186891394, 0.0, -62.6356761735747, -26.784952692793436, -19.83335731232069, -30.0, -60.0, -25.867546745587813, -19.990451303491742, 0.0, -10.0, 0.0, -4.070139952269669, -30.0, 0.0, 0.0, -18.970408772388495, -39.51565831313614, 0.0, -10.0, -20.0, -1.6685477833209184, 0.0, -0.006200513020110376, -8.91660507394059, 0.0, -37.937694416054285, 0.0, -30.0, -1.204825736806876, 0.0, -0.9723518539455411, -7.318134634150718, -41.43719050099411, -30.929258447270886, -4.933896645586153, -20.0, -10.0, -50.0, -20.0, -10.0, 0.0, 0.0, -30.13513803007893, -20.0, 0.0, 0.0, -30.0, -31.064152498439796, -20.0, -7.121584979203844, -0.1505889791397308, 0.0, -20.0, -3.865986974984472, -2.891123584006192, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -10.225966882510203, -10.0, -21.635904590853894, 0.0, -2.9278873463674695, -80.0, 0.0, 0.0, -11.701492274256317, -22.84103260895675, -7.793765120739147, -16.436005937308604, -9.621180848552893, -30.0, -60.0, 0.0, 0.0, 0.0, 0.0, -1.7411153641956212, -10.0, -30.0, 0.0, 0.0, 0.0, -40.0, -30.0, 0.0, 0.0, -54.90513388187024, -20.0, 0.0, 0.0, -40.0, -40.31294295396793, -30.0, -11.56615388223391, -30.908770521419985, 0.0, -32.45266979032468, 0.0, -70.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6849861044955385, "mean_inference_ms": 1.1889225641621293, "mean_action_processing_ms": 0.24945859403906212, "mean_env_wait_ms": 0.5118687880684734, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005899314527158384, "StateBufferConnector_ms": 0.004180419592209804, "ViewRequirementAgentConnector_ms": 0.11462076210681303}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -36.748521819603404, "episode_return_mean": 18.767565642583083}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 175.97855751382895, "num_env_steps_trained_throughput_per_sec": 175.97855751382895, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 17462.413, "restore_workers_time_ms": 0.012, "training_step_time_ms": 17462.341, "sample_time_ms": 1305.509, "learn_time_ms": 16136.923, "learn_throughput": 247.879, "synch_weights_time_ms": 17.95}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-52-47", "timestamp": 1723139567, "time_this_iter_s": 22.74731183052063, "time_total_s": 1003.2433650493622, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b9d3430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1003.2433650493622, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 66.39687500000001, "ram_util_percent": 82.40312499999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1733371051649253, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.168904179210464, "policy_loss": -0.019029260224488097, "vf_loss": 3.1860987933973473, "vf_explained_var": 0.02995472668359677, "kl": 0.009173292255813347, "entropy": 1.1684149229278167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7714588384573341, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8728536948244623, "policy_loss": -0.018552027244293397, "vf_loss": 1.8900709220280885, "vf_explained_var": 2.495363249000928e-07, "kl": 0.006673992925993292, "entropy": 0.78377208508921, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 162150.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -34.046197934796645, "episode_reward_mean": 16.18309564669923, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.00625942580004}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.753086419753087, "agent_policy": -13.076163612560032}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.484912689333685, 11.992017446355126, -2.29969370968084, 0.0, 95.72905579265137, 9.482823406300879, -17.83871533700749, 0.0, 59.19109432259373, 0.0, 0.0, -0.9197628321534768, 0.0, 0.0, -0.27512673244538766, 60.0, -4.6826164021333, 0.0, 78.67742181787217, 40.0, 62.92882228892748, 0.0, 20.0, -0.11372462315725973, 0.0, 30.55979581664137, 0.0, 0.0, -4.23301027250779, -1.5969143651039697, 79.99829017343507, 59.60953302715044, -3.0281860371915634, -15.245103545324554, 0.0, 0.0, -13.93107943008002, 0.0, 0.0, 52.33039723206907, 0.0, -0.4988258594002759, -24.890148279265027, 0.0, 0.0, -1.4768740143561487, -31.7089630548396, -10.396073975435055, 60.0, -0.025890214966083347, -1.182501464238468, 0.0, -32.95093717450807, 0.0, 0.0, -3.746103302225179, 78.63237154751478, -10.805784540346284, 60.0, 0.0, 0.0, -34.046197934796645, 0.0, 140.0, 38.109008969761135, -0.08445493219325528, -5.201749220028503, 40.0, 0.0, -0.12442714763945317, 0.0, 100.0, 48.22091905048993, 0.0, -11.003645727046845, -2.367255896368672, 0.0, -0.9453376764166799, 0.0, -16.515059754202653, 0.0, 0.0, 0.0, -0.9332847974650349, 80.0, 60.0, 52.24712431454199, 35.9507200508143, 0.0, -10.349633952013452, 80.0, 0.0, 0.0, 60.0, 0.0, 20.0, 100.0, -1.2134858160138384, 0.0, 0.0, 40.0, 100.0, -1.5229881218056762, -7.891341668044989, 48.57999176249553, 20.0, 36.262316499185545, -5.039463482315669, 0.0, -0.5008082073412612, 20.0, 0.0, 0.0, -1.135082082633908, 0.0, 0.0, 107.99374057419999, -15.440997014447568, 0.0, 0.0, 20.0, 20.0, -4.886833676837767, -6.033564039453561, -3.736416861827494, 0.0, 57.69511543782194, -2.132157217065801, 0.0, 40.0, 0.0, 80.0, -1.4494448056734985, 60.0, -18.675213344644284, 0.0, -0.29288967035047575, 80.0, 0.0, 60.0, 0.0, 31.5644620192824, -14.628632861241716, 0.0, -4.90906688023199, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, -2.2797453592560446, -0.9818587956086389, -0.40817961947479886, 0.0, 60.0, 13.886480327224408, 39.40461881676424, 100.0, -9.324461510678434, 120.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0], "policy_agent_policy_reward": [0.0, -1.484912689333685, -18.007982553644876, -2.29969370968084, 0.0, -54.270944207348634, -50.517176593699105, -17.83871533700749, 0.0, -30.808905677406273, 0.0, 0.0, -0.9197628321534768, 0.0, 0.0, -0.27512673244538766, -30.0, -4.6826164021333, 0.0, -41.32257818212783, -20.0, -57.071177711072515, 0.0, -10.0, -0.11372462315725973, 0.0, -29.44020418335863, 0.0, 0.0, -4.23301027250779, -1.5969143651039697, -40.001709826564934, -30.39046697284956, -3.0281860371915634, -15.245103545324554, 0.0, 0.0, -13.93107943008002, 0.0, 0.0, -37.66960276793092, 0.0, -0.4988258594002759, -24.890148279265027, 0.0, 0.0, -1.4768740143561487, -31.7089630548396, -10.396073975435055, -30.0, -0.025890214966083347, -1.182501464238468, 0.0, -32.95093717450807, 0.0, 0.0, -3.746103302225179, -41.36762845248521, -10.805784540346284, -30.0, 0.0, 0.0, -34.046197934796645, 0.0, -70.0, -51.89099103023886, -0.08445493219325528, -5.201749220028503, -20.0, 0.0, -0.12442714763945317, 0.0, -50.0, -41.77908094951007, 0.0, -11.003645727046845, -2.367255896368672, 0.0, -0.9453376764166799, 0.0, -16.515059754202653, 0.0, 0.0, 0.0, -0.9332847974650349, -40.0, -30.0, -37.752875685458015, -24.049279949185703, 0.0, -10.349633952013452, -40.0, 0.0, 0.0, -30.0, 0.0, -10.0, -50.0, -1.2134858160138384, 0.0, 0.0, -20.0, -50.0, -1.5229881218056762, -7.891341668044989, -41.42000823750447, -10.0, -23.73768350081446, -5.039463482315669, 0.0, -0.5008082073412612, -10.0, 0.0, 0.0, -1.135082082633908, 0.0, 0.0, -72.00625942580004, -15.440997014447568, 0.0, 0.0, -10.0, -10.0, -4.886833676837767, -6.033564039453561, -3.736416861827494, 0.0, -32.30488456217807, -2.132157217065801, 0.0, -20.0, 0.0, -40.0, -1.4494448056734985, -30.0, -18.675213344644284, 0.0, -0.29288967035047575, -40.0, 0.0, -30.0, 0.0, -28.4355379807176, -14.628632861241716, 0.0, -4.90906688023199, 0.0, 0.0, 0.0, 0.0, 0.0, -60.0, -2.2797453592560446, -0.9818587956086389, -0.40817961947479886, 0.0, -30.0, -16.113519672775595, -20.59538118323575, -50.0, -9.324461510678434, -60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6854873680790924, "mean_inference_ms": 1.1898494577889498, "mean_action_processing_ms": 0.2493800332756604, "mean_env_wait_ms": 0.5122446692556021, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005475164931497456, "StateBufferConnector_ms": 0.0036779745125476225, "ViewRequirementAgentConnector_ms": 0.1086538956489092}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -34.046197934796645, "episode_return_mean": 16.18309564669923}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.29114248505766, "num_env_steps_trained_throughput_per_sec": 204.29114248505766, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 17899.755, "restore_workers_time_ms": 0.012, "training_step_time_ms": 17899.683, "sample_time_ms": 1314.255, "learn_time_ms": 16565.745, "learn_throughput": 241.462, "synch_weights_time_ms": 17.797}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-53-06", "timestamp": 1723139586, "time_this_iter_s": 19.59582281112671, "time_total_s": 1022.8391878604889, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b99e430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1022.8391878604889, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 59.439285714285724, "ram_util_percent": 82.60714285714288}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.166714869067073, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3782118573784827, "policy_loss": -0.018237848935920436, "vf_loss": 3.3946701433509587, "vf_explained_var": 0.07499483587841192, "kl": 0.008897770549852387, "entropy": 1.1663527441521486, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7308390679300254, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0964284272481364, "policy_loss": -0.019402021903491825, "vf_loss": 2.114509456377503, "vf_explained_var": -2.9745254110782704e-07, "kl": 0.0066049740245267465, "entropy": 0.7475779663797811, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 164970.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -48.68169087492589, "episode_reward_mean": 19.16980381999411, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.210191082802547, "agent_policy": -14.460769428413531}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 79.86262836447978, 0.0, 40.0, -24.895927885821582, 76.80372740848006, 20.0, 80.0, 0.0, 60.0, 60.0, 0.0, -13.811564153232789, 60.0, 20.0, 0.0, 0.0, 60.0, 0.0, 80.0, 0.0, 100.0, 0.0, 12.581988415320406, -16.779061401917943, -4.657908962683015, 0.0, 63.255028780543626, 0.0, 0.0, -0.5179540783116154, 31.518931020311317, 0.0, 0.0, -5.243762726332459, -5.426093399226537, -0.5051459548586457, -0.5106722241970496, -4.895939402686057, 40.0, -1.7862600864786715, 99.0822704381133, 100.0, 0.0, -0.2881074116170812, -1.5674324445428967, 0.0, 13.260447720502908, 57.106595876894104, 0.0, 0.0, -7.985246886295521, -1.9118539089871422, 0.0, 140.0, 0.0, 0.0, 0.0, 0.0, -16.41423270284634, 52.292084410577075, 80.0, 39.95628547547808, 0.0, 0.0, -16.916366918924428, 0.0, -19.319347786797046, 0.0, 0.0, 0.0, -23.692918577706553, 100.0, -4.514595242387361, -10.902868169664313, 92.04406351843261, 0.0, 0.0, 11.050828048655102, 0.0, 0.0, 100.0, 0.0, 120.0, 53.67148069555366, -23.335687574479067, 160.0, -2.0719951585685537, 0.0, 31.47524541466327, 0.0, 60.0, 40.89179919569686, 0.0, 40.0, 31.19937546923434, -12.497033485121602, 0.0, 0.0, -0.351645202182409, 40.0, 60.0, 0.0, -4.3155172059084945, 100.0, 40.0, -48.68169087492589, 0.0, 0.0, 0.0, -4.1063572442944025, 0.0, 52.190870375424396, 0.0, 0.0, -4.857080472267025, 20.0, 54.35430289778991, 0.0, 0.0, -0.4278966901949599, 40.0, 60.0, 120.0, -4.112560682119771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.972725470949506, 0.0, -33.92394346626145, 40.0, -0.49201270611969106, 51.59659588576059, 0.0, 60.0, 40.0, 19.607863620947384, 0.0, 0.0, -0.5474995055687204, -1.8941763650627086, 120.0, 0.0, 117.55377222829522, -2.5659030925391155, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -40.13737163552023, 0.0, -20.0, -24.895927885821582, -73.19627259151994, -10.0, -40.0, 0.0, -30.0, -30.0, 0.0, -13.811564153232789, -30.0, -10.0, 0.0, 0.0, -30.0, 0.0, -40.0, 0.0, -50.0, 0.0, -17.41801158467959, -16.779061401917943, -4.657908962683015, 0.0, -56.744971219456374, 0.0, 0.0, -0.5179540783116154, -28.481068979688693, 0.0, 0.0, -5.243762726332459, -5.426093399226537, -0.5051459548586457, -0.5106722241970496, -4.895939402686057, -20.0, -1.7862600864786715, -50.9177295618867, -50.0, 0.0, -0.2881074116170812, -1.5674324445428967, 0.0, -46.739552279497104, -32.893404123105896, 0.0, 0.0, -7.985246886295521, -1.9118539089871422, 0.0, -70.0, 0.0, 0.0, 0.0, 0.0, -16.41423270284634, -37.707915589422925, -40.0, -20.043714524521913, 0.0, 0.0, -16.916366918924428, 0.0, -19.319347786797046, 0.0, 0.0, 0.0, -23.692918577706553, -50.0, -4.514595242387361, -10.902868169664313, -57.95593648156739, 0.0, 0.0, -18.949171951344887, 0.0, 0.0, -50.0, 0.0, -60.0, -36.32851930444633, -23.335687574479067, -80.0, -2.0719951585685537, 0.0, -28.52475458533673, 0.0, -30.0, -49.10820080430314, 0.0, -20.0, -28.800624530765663, -12.497033485121602, 0.0, 0.0, -0.351645202182409, -20.0, -30.0, 0.0, -4.3155172059084945, -50.0, -20.0, -48.68169087492589, 0.0, 0.0, 0.0, -4.1063572442944025, 0.0, -37.809129624575604, 0.0, 0.0, -4.857080472267025, -10.0, -35.64569710221009, 0.0, 0.0, -0.4278966901949599, -20.0, -30.0, -60.0, -4.112560682119771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.972725470949506, 0.0, -33.92394346626145, -20.0, -0.49201270611969106, -38.40340411423941, 0.0, -30.0, -20.0, -10.392136379052618, 0.0, 0.0, -0.5474995055687204, -1.8941763650627086, -60.0, 0.0, -62.446227771704784, -2.5659030925391155, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6856204114473082, "mean_inference_ms": 1.18978523785125, "mean_action_processing_ms": 0.24927084589341858, "mean_env_wait_ms": 0.5123043131290969, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046615387983382885, "StateBufferConnector_ms": 0.004014847384896248, "ViewRequirementAgentConnector_ms": 0.09285363422077932}, "num_episodes": 157, "episode_return_max": 160.0, "episode_return_min": -48.68169087492589, "episode_return_mean": 19.16980381999411}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.26571048417924, "num_env_steps_trained_throughput_per_sec": 212.26571048417924, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 18357.289, "restore_workers_time_ms": 0.013, "training_step_time_ms": 18357.216, "sample_time_ms": 1328.902, "learn_time_ms": 17006.534, "learn_throughput": 235.204, "synch_weights_time_ms": 19.71}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-53-25", "timestamp": 1723139605, "time_this_iter_s": 18.877445697784424, "time_total_s": 1041.7166335582733, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f1310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1041.7166335582733, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 56.17037037037038, "ram_util_percent": 82.39999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2396590443328024, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1194997393836577, "policy_loss": -0.02239811045631844, "vf_loss": 3.1398059302320083, "vf_explained_var": 0.01827124667664369, "kl": 0.010459574867903616, "entropy": 1.1555541129161915, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.742233804777159, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8104564568463792, "policy_loss": -0.018085329428254065, "vf_loss": 1.8272384752618505, "vf_explained_var": 1.572526938526343e-06, "kl": 0.006516547552605538, "entropy": 0.7468120447921415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 167790.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 134.73569674309013, "episode_reward_min": -26.449386084493135, "episode_reward_mean": 15.351826825807683, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -75.26430325690987}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.074074074074074, "agent_policy": -11.870395396414542}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.1624700642913146, 0.0, 0.0, 0.0, -16.987337693772673, 0.0, 60.0, 59.86275570518857, -25.134785202513676, -0.6292219887401063, 100.0, -2.0210330792011346, -0.03065912009007521, 40.0, -0.2780993154989997, 0.0, 0.0, 0.0, 0.0, -0.5436592968206111, -1.8900777661866175, 57.06231897285212, 60.0, 78.6786544909575, 0.0, 0.0, 60.0, 0.0, 100.0, 100.0, -8.937407339309525, 0.0, 58.20490309879862, -1.2977990728039335, 20.0, 60.0, 0.0, 20.0, 60.0, 60.0, -6.063064210141123, -11.811744558438804, -15.11928145027481, -4.753524477164529, 0.0, 0.0, -10.156928781011716, 0.0, -0.9702573416408211, 0.0, 0.0, 0.0, 20.0, 0.0, -15.34501560894024, 0.0, 0.0, -17.123851179229792, -10.307024412380972, 38.53092709037809, 0.0, -3.080405172608609, 60.0, -0.8254109992028758, 0.0, 0.0, 40.0, 0.0, 0.0, 60.0, 60.0, 60.0, -9.289421570193623, -8.67605776211811, 40.0, 0.0, 0.0, 80.0, -25.344447714135043, 0.0, 0.0, -14.05984748060362, -13.295860240290388, 40.0, 60.0, 0.0, 134.73569674309013, -2.394265534442419, 0.0, 20.0, 0.0, 0.0, 0.0, -4.1178168296214235, 0.0, 60.0, -26.449386084493135, 0.0, 0.0, 0.0, 0.0, -4.8776652095495825, 38.84257249757569, -5.7190517350212, 38.81445346562361, 0.0, 20.0, -0.3924001016635348, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 34.983566631070204, 0.0, 0.0, 0.0, 0.0, 70.08698270203148, 0.0, 21.397982884357724, -1.8423555806151801, 0.0, 80.0, -13.653441174647869, -12.353195822340084, 40.0, 0.0, 0.0, 24.3681475490517, -3.969363533674411, 60.0, 51.78490917066272, 0.0, -3.5667084032542737, 0.0, 0.0, 46.8359103012576, 0.0, 32.715280444685085, 60.0, 0.0, 40.0, 0.0, 0.0, -0.974572280545416, 40.0, 0.0, -0.02502892021019054, -20.939460326709533, 40.0, 40.0, 0.0, -5.097359708564102, 36.984611281831164, -5.970392597803476, 100.0, 39.58342949219168], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, 0.0, -0.1624700642913146, 0.0, 0.0, 0.0, -16.987337693772673, 0.0, -30.0, -30.137244294811428, -25.134785202513676, -0.6292219887401063, -50.0, -2.0210330792011346, -0.03065912009007521, -20.0, -0.2780993154989997, 0.0, 0.0, 0.0, 0.0, -0.5436592968206111, -1.8900777661866175, -32.937681027147875, -30.0, -41.321345509042494, 0.0, 0.0, -30.0, 0.0, -50.0, -50.0, -8.937407339309525, 0.0, -31.79509690120138, -1.2977990728039335, -10.0, -30.0, 0.0, -10.0, -30.0, -30.0, -6.063064210141123, -11.811744558438804, -15.11928145027481, -4.753524477164529, 0.0, 0.0, -10.156928781011716, 0.0, -0.9702573416408211, 0.0, 0.0, 0.0, -10.0, 0.0, -15.34501560894024, 0.0, 0.0, -17.123851179229792, -10.307024412380972, -21.469072909621907, 0.0, -3.080405172608609, -30.0, -0.8254109992028758, 0.0, 0.0, -20.0, 0.0, 0.0, -30.0, -30.0, -30.0, -9.289421570193623, -8.67605776211811, -20.0, 0.0, 0.0, -40.0, -25.344447714135043, 0.0, 0.0, -14.05984748060362, -13.295860240290388, -20.0, -30.0, 0.0, -75.26430325690987, -2.394265534442419, 0.0, -10.0, 0.0, 0.0, 0.0, -4.1178168296214235, 0.0, -30.0, -26.449386084493135, 0.0, 0.0, 0.0, 0.0, -4.8776652095495825, -21.157427502424316, -5.7190517350212, -21.185546534376392, 0.0, -10.0, -0.3924001016635348, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -25.016433368929793, 0.0, 0.0, 0.0, 0.0, -49.913017297968544, 0.0, -38.6020171156423, -31.84235558061518, 0.0, -40.0, -13.653441174647869, -12.353195822340084, -20.0, 0.0, 0.0, -35.63185245094831, -3.969363533674411, -30.0, -38.21509082933727, 0.0, -3.5667084032542737, 0.0, 0.0, -43.1640896987424, 0.0, -27.284719555314915, -30.0, 0.0, -20.0, 0.0, 0.0, -0.974572280545416, -20.0, 0.0, -0.02502892021019054, -20.939460326709533, -20.0, -20.0, 0.0, -5.097359708564102, -23.01538871816883, -5.970392597803476, -50.0, -20.416570507808323]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6863042467762235, "mean_inference_ms": 1.1911307838474587, "mean_action_processing_ms": 0.2493225426619361, "mean_env_wait_ms": 0.5130665345965697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0053939260082480345, "StateBufferConnector_ms": 0.0035450782304928628, "ViewRequirementAgentConnector_ms": 0.10347807848895038}, "num_episodes": 162, "episode_return_max": 134.73569674309013, "episode_return_min": -26.449386084493135, "episode_return_mean": 15.351826825807683}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 166.8026313812805, "num_env_steps_trained_throughput_per_sec": 166.8026313812805, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 19293.629, "restore_workers_time_ms": 0.013, "training_step_time_ms": 19293.556, "sample_time_ms": 1351.037, "learn_time_ms": 17918.769, "learn_throughput": 223.23, "synch_weights_time_ms": 21.625}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-53-49", "timestamp": 1723139629, "time_this_iter_s": 23.997508764266968, "time_total_s": 1065.7141423225403, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf2e0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1065.7141423225403, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 67.90882352941175, "ram_util_percent": 82.43823529411763}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.089645058910052, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8980118612448376, "policy_loss": -0.021436107242576934, "vf_loss": 3.9173905479411286, "vf_explained_var": 0.032537350555260976, "kl": 0.010287068253891326, "entropy": 1.135886420061191, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7315474704225012, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.539409206522272, "policy_loss": -0.019023181822733846, "vf_loss": 2.5571531471631204, "vf_explained_var": -5.529281940866024e-08, "kl": 0.006396229937368211, "entropy": 0.7012427589572068, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 170610.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -28.340420523582978, "episode_reward_mean": 19.863757378113057, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.518987341772151, "agent_policy": -14.693204647203398}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 0.0, 60.0, 40.0, 20.0, 40.0, -4.779532642126556, -10.67719217040992, -1.4126652519853444, -19.73335493366222, 20.0, 0.0, 0.0, 120.0, 20.0, -28.31138608959148, -0.02571364725127645, 75.72399974646456, 0.0, 40.0, 19.779312948613224, 40.0, -21.198180435280953, 0.0, 100.0, 40.0, 0.0, 0.0, -19.569395742208428, -0.10089736681753947, 0.0, 20.0, -26.22768990564543, 0.0, 45.67687440649755, 59.382107166566975, -1.1314265388982037, 0.0, 0.0, 40.0, -1.4353244754294547, 80.0, 0.0, 20.0, 0.0, -3.06008709965072, 20.0, -0.19976027504560068, -9.393325869475618, 60.0, 60.0, 38.29053712207059, 58.67272319724755, -0.6381156442133507, 0.0, -0.17503828630408558, 58.29964282177751, 49.42537943765809, -0.7228859524217535, -1.6317076614325887, 0.0, 20.0, 53.92973793426769, 59.09213933559971, 0.0, 38.975929217722154, -15.980325844403751, 40.0, 10.571899011052942, 80.0, 19.714591404649894, -6.369882945993779, 0.0, 0.0, 0.0, 0.0, -15.16448779983569, -0.48583628949741664, -13.95629061943173, 0.0, -0.1316307997944599, 0.0, -13.32548386545755, -0.21365465194173705, -2.594368445291031, 0.0, 60.0, 93.08927490047887, -13.752008799676833, -10.03983169431932, -0.33141440802261113, 20.62348789206291, -1.1889874019437352, 140.0, -0.5817168149753238, 60.0, 180.0, 0.0, -5.282699858230569, -2.640426115721767, 19.98491846635593, -8.021468142494582, 0.0, 0.0, -9.938176956691617, 0.0, 60.0, 20.0, -1.006704598435918, 0.0, 0.0, 20.0, 40.0, 99.58343663262983, -0.30002141434052443, 60.0, -10.577643084635218, 60.0, 8.612574541749053, -3.7542732895166884, 0.0, -1.208223875222748, 60.0, 0.0, -1.8224238978942608, 0.0, 40.0, 100.0, 120.0, -1.1402990470938101, 0.0, 40.0, 0.0, -1.9061404372434287, 0.0, 0.0, 0.0, 20.0, 0.0, 78.16464149150715, 60.0, 20.0, -5.25580507518948, 40.0, -23.06567225100736, -1.6962888138049637, -28.340420523582978, 0.0, 40.0, -1.5110698583436155, 33.576068569917894, 60.0, 0.0, 100.0, 60.0, 60.0, -10.688252895142023], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -30.0, 0.0, -30.0, -20.0, -10.0, -20.0, -4.779532642126556, -10.67719217040992, -1.4126652519853444, -19.73335493366222, -10.0, 0.0, 0.0, -60.0, -10.0, -28.31138608959148, -0.02571364725127645, -74.27600025353541, 0.0, -20.0, -10.220687051386776, -20.0, -21.198180435280953, 0.0, -50.0, -20.0, 0.0, 0.0, -19.569395742208428, -0.10089736681753947, 0.0, -10.0, -26.22768990564543, 0.0, -44.32312559350245, -30.617892833433025, -1.1314265388982037, 0.0, 0.0, -20.0, -1.4353244754294547, -40.0, 0.0, -10.0, 0.0, -3.06008709965072, -10.0, -0.19976027504560068, -9.393325869475618, -30.0, -30.0, -21.709462877929415, -31.327276802752447, -0.6381156442133507, 0.0, -0.17503828630408558, -31.700357178222486, -40.5746205623419, -0.7228859524217535, -1.6317076614325887, 0.0, -10.0, -36.0702620657323, -30.907860664400282, 0.0, -21.024070782277846, -15.980325844403751, -20.0, -19.428100988947055, -40.0, -10.285408595350106, -6.369882945993779, 0.0, 0.0, 0.0, 0.0, -15.16448779983569, -0.48583628949741664, -13.95629061943173, 0.0, -0.1316307997944599, 0.0, -13.32548386545755, -0.21365465194173705, -2.594368445291031, 0.0, -30.0, -86.91072509952113, -13.752008799676833, -10.03983169431932, -0.33141440802261113, -39.37651210793709, -1.1889874019437352, -70.0, -0.5817168149753238, -30.0, -90.0, 0.0, -5.282699858230569, -2.640426115721767, -10.01508153364407, -8.021468142494582, 0.0, 0.0, -9.938176956691617, 0.0, -30.0, -10.0, -1.006704598435918, 0.0, 0.0, -10.0, -20.0, -50.41656336737017, -0.30002141434052443, -30.0, -10.577643084635218, -30.0, -21.387425458250945, -3.7542732895166884, 0.0, -1.208223875222748, -30.0, 0.0, -1.8224238978942608, 0.0, -20.0, -50.0, -60.0, -1.1402990470938101, 0.0, -20.0, 0.0, -1.9061404372434287, 0.0, 0.0, 0.0, -10.0, 0.0, -41.83535850849284, -30.0, -10.0, -5.25580507518948, -20.0, -23.06567225100736, -1.6962888138049637, -28.340420523582978, 0.0, -20.0, -1.5110698583436155, -26.4239314300821, -30.0, 0.0, -50.0, -30.0, -30.0, -10.688252895142023]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6873121941202596, "mean_inference_ms": 1.1928270811941133, "mean_action_processing_ms": 0.24931265573860237, "mean_env_wait_ms": 0.5133345231965208, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006286403800867781, "StateBufferConnector_ms": 0.0033900707582884197, "ViewRequirementAgentConnector_ms": 0.10880148863490624}, "num_episodes": 158, "episode_return_max": 180.0, "episode_return_min": -28.340420523582978, "episode_return_mean": 19.863757378113057}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 245.0295475365734, "num_env_steps_trained_throughput_per_sec": 245.0295475365734, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 19183.988, "restore_workers_time_ms": 0.013, "training_step_time_ms": 19183.913, "sample_time_ms": 1346.814, "learn_time_ms": 17813.423, "learn_throughput": 224.55, "synch_weights_time_ms": 21.542}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-54-06", "timestamp": 1723139646, "time_this_iter_s": 16.334647178649902, "time_total_s": 1082.0487895011902, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b9d3af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1082.0487895011902, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 39.34347826086957, "ram_util_percent": 81.90434782608698}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.276202172910174, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3821308193107447, "policy_loss": -0.022092816931641817, "vf_loss": 3.402207200601697, "vf_explained_var": 0.031730349237720175, "kl": 0.010082218647733043, "entropy": 1.1497538449863594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6935670276747105, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7946863734975773, "policy_loss": -0.016448035768021875, "vf_loss": 1.809951241092479, "vf_explained_var": 1.4945970359423483e-06, "kl": 0.0059158244885392335, "entropy": 0.7288007164889193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 173430.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -53.36584688373231, "episode_reward_mean": 13.074224892989706, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -107.83227819057959}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.703703703703704, "agent_policy": -13.036886218121404}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.968483362217434, -15.628011754577205, 0.0, -8.861100964901757, 99.81330352926649, 60.0, 60.0, 0.0, -0.40843524618481286, -26.151592749818512, 0.0, 0.0, 0.0, 60.0, -6.320459808367698, -4.92774290260985, -2.9555914338213483, -0.22143788432052336, 34.43347823338249, 20.0, 60.0, 60.0, 0.0, 100.0, 19.77392056338015, 1.9473178283696366, 80.0, -0.38790142764008273, 0.0, 39.62115229817042, -0.17007771202183553, 140.0, 51.1532135935401, 0.0, 0.0, -0.39768193419782105, 0.0, -11.249190163580916, 40.0, 0.0, 59.69216519057801, 0.0, 40.0, 140.0, 0.0, 0.0, -3.530530135308282, 0.0, 0.0, 0.0, 0.0, -1.8559987871959294, -5.520572368455417, 0.0, -3.053936169905085, -9.020378540778223, 33.24852065464221, -0.16409387279854082, 0.0, 0.0, 69.99504151209733, -53.36584688373231, 60.0, -0.24654158650772695, -0.08693780436886844, -16.020203542149925, 0.0, 40.0, -1.5021675853668215, 40.0, 60.0, 0.0, 0.0, 20.0, 40.0, 0.0, -8.867651761518443, -2.9297905905407924, 0.0, -1.2289605931274494, 0.0, 0.0, -0.5213025693390549, 30.263553867331666, 0.0, -16.985702705223005, 18.228179705219056, -1.182841241717737, 0.0, -7.207313336998711, 58.41446562423044, 57.772110872768025, -2.4699379595031488, -0.5434131518162455, -13.718365068600617, 0.0, -16.038154079630534, 140.0, 20.0, 57.33797615758145, 0.0, 7.814334187332119, 0.0, -23.354816163781365, 0.0, -3.8487286536919965, -1.0916916303261526, -1.9466907933450983, 20.0, 100.0, 0.0, 0.0, 20.0, 79.34230018488708, 0.0, 0.0, 0.0, 0.0, 80.0, 20.0, 54.654422406113945, -7.358106497625983, -4.0406018355091335, 132.1677218094204, -23.99211762466903, 0.0, 19.165058945203143, -2.108364638605422, -1.5673333461682548, -3.1287819143024382, 0.0, 0.0, 0.0, 0.0, -4.794944839864712, 0.0, -27.144475611176656, -0.4071332150750828, -0.5916465377246927, -6.099251636034767, 0.0, 40.0, -17.868070265385693, 0.0, -1.917903554951309, 0.0, 39.47475964770623, -0.3104765383860719, 0.0, 0.0, -23.197947162567495, 40.0, 0.0, -26.824593201023948, 0.0, -46.75582664437114, 40.0, 0.0, -1.230714163458464, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-12.968483362217434, -15.628011754577205, 0.0, -8.861100964901757, -50.18669647073352, -30.0, -30.0, 0.0, -0.40843524618481286, -26.151592749818512, 0.0, 0.0, 0.0, -30.0, -6.320459808367698, -4.92774290260985, -2.9555914338213483, -0.22143788432052336, -55.56652176661751, -10.0, -30.0, -30.0, 0.0, -50.0, -10.226079436619852, -28.05268217163036, -40.0, -0.38790142764008273, 0.0, -20.378847701829574, -0.17007771202183553, -70.0, -38.8467864064599, 0.0, 0.0, -0.39768193419782105, 0.0, -11.249190163580916, -20.0, 0.0, -30.30783480942199, 0.0, -20.0, -70.0, 0.0, 0.0, -3.530530135308282, 0.0, 0.0, 0.0, 0.0, -1.8559987871959294, -5.520572368455417, 0.0, -3.053936169905085, -9.020378540778223, -56.75147934535779, -0.16409387279854082, 0.0, 0.0, -50.00495848790266, -53.36584688373231, -30.0, -0.24654158650772695, -0.08693780436886844, -16.020203542149925, 0.0, -20.0, -1.5021675853668215, -20.0, -30.0, 0.0, 0.0, -10.0, -20.0, 0.0, -8.867651761518443, -2.9297905905407924, 0.0, -1.2289605931274494, 0.0, 0.0, -0.5213025693390549, -29.736446132668334, 0.0, -16.985702705223005, -11.771820294780944, -1.182841241717737, 0.0, -7.207313336998711, -61.585534375769576, -62.227889127231975, -2.4699379595031488, -0.5434131518162455, -13.718365068600617, 0.0, -16.038154079630534, -70.0, -10.0, -32.66202384241855, 0.0, -22.18566581266788, 0.0, -23.354816163781365, 0.0, -3.8487286536919965, -1.0916916303261526, -1.9466907933450983, -10.0, -50.0, 0.0, 0.0, -10.0, -40.65769981511293, 0.0, 0.0, 0.0, 0.0, -40.0, -10.0, -35.345577593886055, -7.358106497625983, -4.0406018355091335, -107.83227819057959, -23.99211762466903, 0.0, -10.834941054796856, -2.108364638605422, -31.567333346168255, -3.1287819143024382, 0.0, 0.0, 0.0, 0.0, -4.794944839864712, 0.0, -27.144475611176656, -0.4071332150750828, -0.5916465377246927, -6.099251636034767, 0.0, -20.0, -17.868070265385693, 0.0, -1.917903554951309, 0.0, -20.525240352293768, -0.3104765383860719, 0.0, 0.0, -23.197947162567495, -20.0, 0.0, -26.824593201023948, 0.0, -46.75582664437114, -20.0, 0.0, -1.230714163458464, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.686163943917365, "mean_inference_ms": 1.190731305811544, "mean_action_processing_ms": 0.24879379882570304, "mean_env_wait_ms": 0.5126405501925253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004283219207952052, "StateBufferConnector_ms": 0.0030488143732518326, "ViewRequirementAgentConnector_ms": 0.0876378130029749}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -53.36584688373231, "episode_return_mean": 13.074224892989706}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.9984042446817, "num_env_steps_trained_throughput_per_sec": 287.9984042446817, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 19183.999, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19183.948, "sample_time_ms": 1346.949, "learn_time_ms": 17813.416, "learn_throughput": 224.55, "synch_weights_time_ms": 21.444}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-54-20", "timestamp": 1723139660, "time_this_iter_s": 13.902139902114868, "time_total_s": 1095.950929403305, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b9d3d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1095.950929403305, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 28.831578947368417, "ram_util_percent": 81.2421052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3806603896121183, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3131088505188626, "policy_loss": -0.020305863013588048, "vf_loss": 3.331658957650264, "vf_explained_var": 0.048519182267288366, "kl": 0.008778732415248864, "entropy": 1.1612363319844008, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.740658670103719, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1832954249483474, "policy_loss": -0.01759478248794504, "vf_loss": 2.1997820623800264, "vf_explained_var": 1.380904346493119e-06, "kl": 0.005540707666854435, "entropy": 0.7069559213540233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 176250.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -26.802209431166283, "episode_reward_mean": 18.39427388166234, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.700636942675159, "agent_policy": -13.707636946363142}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.65076864063216, -0.09696689393911995, 120.0, 0.0, -2.5462929898033195, 39.78935531752438, 0.0, 40.0, -0.8269244787559971, 60.0, -0.9281558796609735, 0.0, -10.440023428869829, 20.0, 97.81530792035628, 0.0, 20.0, 0.0, 94.13200659581534, 30.584242441536983, 0.0, -6.019328542080084, -22.602087059067703, 0.0, 60.0, -1.9710914956204728, -26.802209431166283, -1.680820746112901, -1.3972751639262437, -16.143048622689786, 100.0, 20.0, 59.944605689598504, 20.0, 0.0, 0.0, -2.596554382071595, 20.603646397373605, -0.759028859461659, 40.0, 39.64003242649205, 0.0, -4.010411410099222, -1.6063153204593161, 0.0, -2.10179751948565, 0.0, -4.075326532658915, 37.94267554824969, 60.0, 40.0, 0.0, 40.0, -19.431219318111847, 11.302992649569287, 0.0, -0.02414279639168071, 0.0, -4.157420405736185, 0.0, 60.0, -8.396988783101975, 58.4771245938889, 0.0, 0.0, 20.0, 0.0, 0.0, 20.0, -16.94751099517569, 0.0, 0.0, 60.0, 40.0, 34.08443397449324, 0.0, 60.0, -1.9817099171560681, -0.8417024467729128, 40.0, 0.0, -3.2077660356348794, 0.0, -2.586329342354566, 0.0, 14.746112359107226, -1.4922533777788072, 0.0, -4.331364947835258, -4.447485014919092, -4.490810181915861, 0.0, 80.0, -13.241468404461138, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 80.0, 20.0, 0.0, 40.0, -12.535744869710422, 54.885344498906534, 60.0, 100.0, -8.134542098087133, 7.390197115487437, 48.35281048116869, 15.495343664725638, 0.0, 0.0, 62.94968706801199, -3.5420590099726885, -1.551113582378164, 40.0, 0.0, -0.6258047613394568, 0.0, 0.0, 120.0, 39.54586923005623, 160.0, 0.0, 119.87110254457033, 5.168010113780975, 20.0, 0.0, -3.17751781609561, 0.0, 0.0, 0.0, 39.418925087238456, 57.0624708367375, 0.0, -1.5496794856118379, -0.7724902557291702, 0.0, 55.830838950345985, 180.0, 0.0, -4.044828323427257, 20.0, -9.92856653360929, 0.0, 17.31815092059174, -4.6039138091085565, 39.41964434117311, 0.0, -26.103148844754656, -4.9005937972761595, 23.432671205194204, 0.0, 0.0, 160.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0], "policy_agent_policy_reward": [-23.65076864063216, -0.09696689393911995, -60.0, 0.0, -2.5462929898033195, -20.21064468247562, 0.0, -20.0, -0.8269244787559971, -30.0, -0.9281558796609735, 0.0, -10.440023428869829, -10.0, -52.18469207964372, 0.0, -10.0, 0.0, -55.86799340418465, -29.415757558463024, 0.0, -6.019328542080084, -22.602087059067703, 0.0, -30.0, -1.9710914956204728, -26.802209431166283, -1.680820746112901, -1.3972751639262437, -16.143048622689786, -50.0, -10.0, -30.055394310401493, -10.0, 0.0, 0.0, -2.596554382071595, -39.39635360262639, -0.759028859461659, -20.0, -20.35996757350795, 0.0, -4.010411410099222, -1.6063153204593161, 0.0, -2.10179751948565, 0.0, -4.075326532658915, -22.05732445175032, -30.0, -20.0, 0.0, -20.0, -19.431219318111847, -18.697007350430713, 0.0, -0.02414279639168071, 0.0, -4.157420405736185, 0.0, -30.0, -8.396988783101975, -31.522875406111094, 0.0, 0.0, -10.0, 0.0, 0.0, -10.0, -16.94751099517569, 0.0, 0.0, -30.0, -20.0, -25.915566025506763, 0.0, -30.0, -1.9817099171560681, -0.8417024467729128, -20.0, 0.0, -3.2077660356348794, 0.0, -2.586329342354566, 0.0, -45.25388764089277, -1.4922533777788072, 0.0, -4.331364947835258, -4.447485014919092, -4.490810181915861, 0.0, -40.0, -13.241468404461138, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -40.0, -10.0, 0.0, -20.0, -12.535744869710422, -35.11465550109347, -30.0, -50.0, -8.134542098087133, -22.609802884512565, -41.64718951883131, -14.504656335274362, 0.0, 0.0, -57.05031293198801, -3.5420590099726885, -1.551113582378164, -20.0, 0.0, -0.6258047613394568, 0.0, 0.0, -60.0, -20.454130769943767, -80.0, 0.0, -60.128897455429666, -24.831989886219034, -10.0, 0.0, -3.17751781609561, 0.0, 0.0, 0.0, -20.581074912761544, -32.9375291632625, 0.0, -1.5496794856118379, -0.7724902557291702, 0.0, -34.16916104965402, -90.0, 0.0, -4.044828323427257, -10.0, -9.92856653360929, 0.0, -12.68184907940826, -4.6039138091085565, -20.580355658826893, 0.0, -26.103148844754656, -4.9005937972761595, -36.56732879480579, 0.0, 0.0, -80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6845398403567513, "mean_inference_ms": 1.1878459312010907, "mean_action_processing_ms": 0.24814919428789864, "mean_env_wait_ms": 0.511575379183798, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004445215699019706, "StateBufferConnector_ms": 0.0032005796007290007, "ViewRequirementAgentConnector_ms": 0.08586174363543274}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -26.802209431166283, "episode_return_mean": 18.39427388166234}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 299.4182077692537, "num_env_steps_trained_throughput_per_sec": 299.4182077692537, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 19056.047, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19055.996, "sample_time_ms": 1341.008, "learn_time_ms": 17693.073, "learn_throughput": 226.077, "synch_weights_time_ms": 19.778}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-54-33", "timestamp": 1723139673, "time_this_iter_s": 13.365625143051147, "time_total_s": 1109.3165545463562, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b9d3a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1109.3165545463562, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 28.042105263157893, "ram_util_percent": 80.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3152123631288606, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.363897989069422, "policy_loss": -0.02376167021332852, "vf_loss": 3.385645748178164, "vf_explained_var": 0.05142884676655134, "kl": 0.010069581479466754, "entropy": 1.148179752131303, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7235812494412381, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9179002468678967, "policy_loss": -0.01819442034201987, "vf_loss": 1.9348219560815934, "vf_explained_var": -6.857915972986965e-07, "kl": 0.0063635461869715046, "entropy": 0.6931246130601734, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 179070.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -23.484767954921878, "episode_reward_mean": 14.345006818851418, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.99719931778545}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.703703703703704, "agent_policy": -11.766104292259694}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, -1.3669466553190035, -7.50014985592892, -0.3777974688521868, 40.0, 80.0, -2.428691473359907, 0.0, 0.0, 0.0, -6.9699577972842786, 0.0, 20.0, 0.0, -16.5964381764497, 57.73192894700364, 20.0, 32.634215324029086, 0.0, -1.3862206333792704, -7.357810806385492, 0.0, 60.0, 0.0, -4.7244301919876035, 0.0, 0.0, 0.0, 0.0, 16.76801440514416, -12.162859952874259, 6.848571908674391, -1.8920268170949872, 0.0, 0.0, -6.230165530848426, 0.0, 39.00842202837953, 60.0, -4.981482270390432, 20.0, 0.0, -0.03634215325206025, 40.0, -3.1727665655273247, 0.0, -0.2300268995068977, 0.0, 0.0, -3.402209931444549, -1.8008908014454883, 0.0, -14.130182413227068, -2.09825443237981, 15.656767009007389, 20.0, -23.484767954921878, 0.0, 0.0, -4.517435998372381, 60.0, 38.824019382137124, -13.665282259305656, 40.0, 0.0, 48.51571531117752, 80.0, 0.0, -0.0345488344101752, -0.7920882696758291, 18.72383333599988, 0.0, 0.0, 0.0, -20.69824018426316, 120.0, 2.3566364283387142, 0.0, -1.2215961343500703, 0.0, -6.126160188944098, 95.17266432878846, 0.0, 20.0, 0.0, 34.69267082068312, -3.4567740713893436, 0.0, 80.0, 97.52531197559021, 60.0, 0.0, 0.0, 59.77881530874566, -6.284638195450862, -1.5228919654938056, 19.9451625092402, 0.0, -9.328123701296398, 60.0, -2.380987933393488, 20.0, 0.0, 0.0, -0.4146693824413139, 59.99568234084336, -2.3042084916119485, 0.0, -0.6191577194356834, 60.0, 40.0, -7.649420598200768, -19.504386754042983, 118.00280068221451, 0.0, -12.113011421342645, 19.99906503956619, 0.0, -1.1484698088174816, 19.407566960136506, 0.0, 0.0, 0.0, 0.0, 0.0, 63.396885500539355, 29.22644913495452, -11.975618866360142, -1.42074717153728, 0.0, 43.43840074963863, 35.54164181687446, -7.851588718987235, 0.0, -5.340198912867518, 60.0, 40.0, 120.0, -4.5926085798783305, -20.778505347236415, 0.0, 80.0, 60.0, 0.0, -15.806525480774322, 39.19545237448827, 40.0, 27.056037787348608, 0.0, 0.0, 0.0, 20.0, 40.0, 40.0, -0.21313892113428268, 0.0, -2.8358500044365167, 20.0, -8.624334058304148, 20.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -30.0, -1.3669466553190035, -7.50014985592892, -0.3777974688521868, -20.0, -40.0, -2.428691473359907, 0.0, 0.0, 0.0, -6.9699577972842786, 0.0, -10.0, 0.0, -16.5964381764497, -32.26807105299637, -10.0, -27.365784675970904, 0.0, -1.3862206333792704, -7.357810806385492, 0.0, -30.0, 0.0, -4.7244301919876035, 0.0, 0.0, 0.0, 0.0, -43.23198559485586, -12.162859952874259, -23.151428091325602, -1.8920268170949872, 0.0, 0.0, -6.230165530848426, 0.0, -20.991577971620462, -30.0, -4.981482270390432, -10.0, 0.0, -0.03634215325206025, -20.0, -3.1727665655273247, 0.0, -0.2300268995068977, 0.0, 0.0, -3.402209931444549, -1.8008908014454883, 0.0, -14.130182413227068, -2.09825443237981, -14.343232990992611, -10.0, -23.484767954921878, 0.0, 0.0, -4.517435998372381, -30.0, -21.17598061786288, -13.665282259305656, -20.0, 0.0, -41.48428468882249, -40.0, 0.0, -0.0345488344101752, -0.7920882696758291, -11.276166664000119, 0.0, 0.0, 0.0, -20.69824018426316, -60.0, -27.643363571661286, 0.0, -1.2215961343500703, 0.0, -6.126160188944098, -54.82733567121154, 0.0, -10.0, 0.0, -25.30732917931688, -3.4567740713893436, 0.0, -40.0, -52.47468802440979, -30.0, 0.0, 0.0, -30.221184691254344, -6.284638195450862, -1.5228919654938056, -10.0548374907598, 0.0, -9.328123701296398, -30.0, -2.380987933393488, -10.0, 0.0, 0.0, -0.4146693824413139, -30.004317659156634, -2.3042084916119485, 0.0, -0.6191577194356834, -30.0, -20.0, -7.649420598200768, -19.504386754042983, -61.99719931778545, 0.0, -12.113011421342645, -10.000934960433812, 0.0, -1.1484698088174816, -10.592433039863492, 0.0, 0.0, 0.0, 0.0, 0.0, -56.60311449946065, -30.773550865045475, -11.975618866360142, -1.42074717153728, 0.0, -46.56159925036137, -24.45835818312554, -7.851588718987235, 0.0, -5.340198912867518, -30.0, -20.0, -60.0, -4.5926085798783305, -20.778505347236415, 0.0, -40.0, -30.0, 0.0, -15.806525480774322, -50.80454762551173, -20.0, -32.94396221265139, 0.0, 0.0, 0.0, -10.0, -20.0, -20.0, -0.21313892113428268, 0.0, -2.8358500044365167, -10.0, -8.624334058304148, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6831407860701059, "mean_inference_ms": 1.1853199226524116, "mean_action_processing_ms": 0.2476063305212218, "mean_env_wait_ms": 0.5107554165108203, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004550336319723247, "StateBufferConnector_ms": 0.0030962037451473285, "ViewRequirementAgentConnector_ms": 0.0851960829746576}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -23.484767954921878, "episode_return_mean": 14.345006818851418}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 296.1419260044813, "num_env_steps_trained_throughput_per_sec": 296.1419260044813, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 19033.182, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19033.131, "sample_time_ms": 1345.033, "learn_time_ms": 17666.225, "learn_throughput": 226.421, "synch_weights_time_ms": 19.737}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-54-47", "timestamp": 1723139687, "time_this_iter_s": 13.51633095741272, "time_total_s": 1122.832885503769, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bc9f1dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1122.832885503769, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 28.935000000000002, "ram_util_percent": 79.80999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.370147998382648, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7221908760567506, "policy_loss": -0.022056693394309452, "vf_loss": 3.742397884527842, "vf_explained_var": 0.06465378614763419, "kl": 0.009248396611069805, "entropy": 1.1543700544784465, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7638602642619864, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9452986545596562, "policy_loss": -0.018377147016036224, "vf_loss": 1.9624242759342734, "vf_explained_var": 6.80380679191427e-08, "kl": 0.006257635630381407, "entropy": 0.6915203813542711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 181890.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -39.09236971098782, "episode_reward_mean": 14.429130424555055, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -76.75292160292666}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.197530864197532, "agent_policy": -13.163462168037537}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 20.0, 40.69457289464442, 0.0, 0.0, -1.9338785443788686, 0.0, 0.0, 0.0, 0.0, 72.67669694976613, 0.0, 20.0, 40.0, 40.0, 0.0, 60.0, -2.6886684371584533, -6.714712573725113, 20.0, 0.0, 60.0, 80.0, 43.61104237474424, 110.56314008334746, -15.101565102450515, 15.549184321083054, 0.0, 40.0, 0.0, -1.98118504102195, -3.3471870658249703, -27.840377948685813, 17.0926090813172, -9.123681137130736, -11.797571504321986, 0.0, 0.0, 20.0, 0.0, 20.0, -0.6180771807847008, -23.298270124097957, 0.0, 60.0, 0.0, 0.0, 0.0, -16.365906706000075, 59.66729816676995, 0.0, 0.0, -6.117066550517518, 16.570664970217436, 0.0, 0.0, 0.0, 0.0, -6.032993143089362, 20.0, -9.050530724175394, -19.666330449080736, -16.94421158621313, -0.700113302689005, 59.5556364626114, 38.8588462331246, 80.0, 60.0, 140.0, -6.181031627979201, 60.0, 51.19468348989311, 16.384865229236617, -9.502704269996105, 0.0, -0.34602524580536476, 0.0, 0.0, -1.396670827280152, 0.0, 0.0, 70.27495580253252, 0.0, 0.0, 80.0, -6.9957129116345484, 19.796595977955665, 20.0, -9.0914471707564, 0.0, -3.3093686407481817, 59.57575507408562, -19.08587738549222, -20.44476600376102, -35.61921294469548, 45.69834013509958, 0.0, 103.24707839707334, -1.6453728463200634, 0.0, 0.0, -32.590415179977214, 94.7152703775311, 80.0, 0.0, 20.0, 0.0, 0.0, 36.78216725919272, -18.473160697456137, -5.285383636026149, 39.60084127593983, 0.0, 38.85017009133479, 0.0, -21.937788790236983, -0.03902038402426866, -2.225922694443665, 0.0, -1.5386370485332779, 20.0, -7.408979212810948, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 77.11282669758563, 60.0, 0.0, -5.209382884348103, 80.0, 0.0, 40.0, -2.3135921363241296, 0.0, 0.0, 0.0, 0.0, -9.061782224405706, 54.39291652817684, 40.0, 0.0, 20.0, 0.0, 48.708075453353445, 0.0, 0.0, -23.908608671520014, 17.68552723962147, 60.0, -10.836266043363224, 60.0, 0.0, 120.0, -7.8013085126881165, -10.67749696535857, 20.0, 0.0, -39.09236971098782], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -10.0, -49.30542710535558, 0.0, 0.0, -1.9338785443788686, 0.0, 0.0, 0.0, 0.0, -47.32330305023388, 0.0, -10.0, -20.0, -20.0, 0.0, -30.0, -2.6886684371584533, -6.714712573725113, -10.0, 0.0, -30.0, -40.0, -46.38895762525576, -69.43685991665254, -15.101565102450515, -14.450815678916944, 0.0, -20.0, 0.0, -1.98118504102195, -3.3471870658249703, -27.840377948685813, -12.907390918682802, -9.123681137130736, -11.797571504321986, 0.0, 0.0, -10.0, 0.0, -10.0, -0.6180771807847008, -23.298270124097957, 0.0, -30.0, 0.0, 0.0, 0.0, -16.365906706000075, -30.33270183323005, 0.0, 0.0, -6.117066550517518, -13.42933502978256, 0.0, 0.0, 0.0, 0.0, -6.032993143089362, -10.0, -9.050530724175394, -19.666330449080736, -16.94421158621313, -0.700113302689005, -30.444363537388597, -21.141153766875398, -40.0, -30.0, -70.0, -6.181031627979201, -30.0, -38.80531651010689, -13.615134770763383, -9.502704269996105, 0.0, -0.34602524580536476, 0.0, 0.0, -1.396670827280152, 0.0, 0.0, -49.7250441974675, 0.0, 0.0, -40.0, -6.9957129116345484, -10.203404022044335, -10.0, -9.0914471707564, 0.0, -3.3093686407481817, -30.424244925914373, -19.08587738549222, -20.44476600376102, -35.61921294469548, -44.30165986490042, 0.0, -76.75292160292666, -1.6453728463200634, 0.0, 0.0, -32.590415179977214, -55.28472962246891, -40.0, 0.0, -10.0, 0.0, 0.0, -23.217832740807285, -18.473160697456137, -5.285383636026149, -20.399158724060168, 0.0, -21.14982990866521, 0.0, -21.937788790236983, -0.03902038402426866, -2.225922694443665, 0.0, -1.5386370485332779, -10.0, -7.408979212810948, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -42.887173302414396, -30.0, 0.0, -5.209382884348103, -40.0, 0.0, -20.0, -2.3135921363241296, 0.0, 0.0, 0.0, 0.0, -9.061782224405706, -35.60708347182317, -20.0, 0.0, -10.0, 0.0, -41.29192454664657, 0.0, 0.0, -23.908608671520014, -12.314472760378528, -30.0, -10.836266043363224, -30.0, 0.0, -60.0, -7.8013085126881165, -10.67749696535857, -10.0, 0.0, -39.09236971098782]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.68154023746122, "mean_inference_ms": 1.1824679613253157, "mean_action_processing_ms": 0.2469954127577703, "mean_env_wait_ms": 0.5097413428325658, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004054734736313055, "StateBufferConnector_ms": 0.003092524446087119, "ViewRequirementAgentConnector_ms": 0.08672439021828734}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -39.09236971098782, "episode_return_mean": 14.429130424555055}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.4814034459044, "num_env_steps_trained_throughput_per_sec": 300.4814034459044, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 17320.19, "restore_workers_time_ms": 0.015, "training_step_time_ms": 17320.139, "sample_time_ms": 1335.916, "learn_time_ms": 15962.931, "learn_throughput": 250.581, "synch_weights_time_ms": 19.168}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-55-00", "timestamp": 1723139700, "time_this_iter_s": 13.31882381439209, "time_total_s": 1136.151709318161, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf4bc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1136.151709318161, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 29.521052631578947, "ram_util_percent": 79.83684210526316}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0969239149863523, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.236516179020206, "policy_loss": -0.022489209680255348, "vf_loss": 3.256624502936999, "vf_explained_var": 0.05481749679893255, "kl": 0.011904433407908456, "entropy": 1.1390755895525218, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7253780844997852, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.043700105416859, "policy_loss": -0.017446145309376406, "vf_loss": 2.0600620565684973, "vf_explained_var": -7.992729227593604e-07, "kl": 0.005420955775304249, "entropy": 0.6512575826534989, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 184710.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -57.57884158604855, "episode_reward_mean": 16.88972110263667, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.936708860759493, "agent_policy": -12.920405479641813}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.010517435853869, -0.2269806524358886, 0.0, 0.0, 100.0, 0.0, 0.0, -19.277104762359986, -10.60120408300532, 0.0, 80.0, -11.180917918689488, 0.0, -15.738999932451373, 0.0, 38.978759589680664, 40.0, 0.0, 18.320411101524506, 0.0, 52.49052681277722, 80.0, 8.425727441394283, 0.0, 0.0, 0.0, 20.0, -2.234155852791451, 50.66818181086357, 60.0, 0.0, -17.076763954786585, 0.0, 60.0, 34.89712830088077, -17.924478245932534, 0.0, -57.57884158604855, 60.0, 0.0, 20.0, 0.0, 0.0, 18.80585366540499, 0.0, -7.987002272592253, 20.0, 0.0, 19.981332752149424, -2.4024401944070064, 0.0, 0.0, 4.769262340766391, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 27.921722916964566, 0.0, 60.0, 56.97608511746776, 0.0, 79.67394697301059, 0.0, 0.0, 58.80020407096211, 0.0, 60.0, 0.0, 40.0, -2.9456055228116336, 0.0, 92.45516205106706, 0.0, -1.9813093900624956, 0.0, 180.0, 80.0, 0.0, 70.6288274595613, 40.55268912422451, 58.53131948391496, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 59.06189959973358, 40.0, 0.0, 15.508690457372445, 0.0, 40.0, 65.51938689210715, -1.8478304522558409, 60.0, 0.0, 100.0, 15.23549633783901, 80.0, 0.0, 0.0, 0.0, 0.0, -18.12756823155267, 57.357724124055764, 0.0, -0.06649461105665444, 0.0, 0.0, 0.0, -0.35549359331436214, -13.589424729054489, -6.506862730542265, -3.1020072980600037, 38.40091658288646, 19.896143504842584, 0.0, -10.254512002661132, 0.0, 40.0, 0.0, 0.0, 37.25662371910979, -4.373086762246686, -0.34943032793704143, 100.0, -0.04577627021141284, 0.0, 16.482194087374374, -8.16084719917301, 0.0, -0.6567392000536576, -30.76482616771519, -4.141758767601108, 0.0, 0.0, 40.0, 0.0, 60.0, 0.0, 0.0, -7.959255505947034, -1.6988087058105728, -1.0510845514246236, 0.0, -22.771933056793287, 59.25451761703026, 0.0, -0.28473775073313945, 60.0, 0.0, 60.0, 60.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-5.010517435853869, -0.2269806524358886, 0.0, 0.0, -50.0, 0.0, 0.0, -19.277104762359986, -10.60120408300532, 0.0, -40.0, -11.180917918689488, 0.0, -15.738999932451373, 0.0, -21.02124041031934, -20.0, 0.0, -11.679588898475494, 0.0, -37.50947318722278, -40.0, -21.574272558605717, 0.0, 0.0, 0.0, -10.0, -2.234155852791451, -39.33181818913643, -30.0, 0.0, -17.076763954786585, 0.0, -30.0, -25.102871699119227, -17.924478245932534, 0.0, -57.57884158604855, -30.0, 0.0, -10.0, 0.0, 0.0, -11.194146334595015, 0.0, -7.987002272592253, -10.0, 0.0, -10.018667247850576, -2.4024401944070064, 0.0, 0.0, -25.230737659233604, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -32.078277083035424, 0.0, -30.0, -33.023914882532246, 0.0, -40.32605302698941, 0.0, 0.0, -31.199795929037897, 0.0, -30.0, 0.0, -20.0, -2.9456055228116336, 0.0, -57.54483794893292, 0.0, -1.9813093900624956, 0.0, -90.0, -40.0, 0.0, -49.37117254043873, -49.4473108757755, -31.46868051608504, -10.0, -10.0, -10.0, 0.0, 0.0, 0.0, -30.93810040026643, -20.0, 0.0, -14.491309542627556, 0.0, -20.0, -54.480613107892864, -1.8478304522558409, -30.0, 0.0, -50.0, -44.76450366216099, -40.0, 0.0, 0.0, 0.0, 0.0, -18.12756823155267, -32.642275875944236, 0.0, -0.06649461105665444, 0.0, 0.0, 0.0, -0.35549359331436214, -13.589424729054489, -6.506862730542265, -3.1020072980600037, -21.59908341711354, -10.103856495157416, 0.0, -10.254512002661132, 0.0, -20.0, 0.0, 0.0, -22.74337628089021, -4.373086762246686, -0.34943032793704143, -50.0, -0.04577627021141284, 0.0, -13.517805912625628, -8.16084719917301, 0.0, -0.6567392000536576, -30.76482616771519, -4.141758767601108, 0.0, 0.0, -20.0, 0.0, -30.0, 0.0, 0.0, -7.959255505947034, -1.6988087058105728, -1.0510845514246236, 0.0, -22.771933056793287, -30.745482382969744, 0.0, -0.28473775073313945, -30.0, 0.0, -30.0, -30.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.680322661244243, "mean_inference_ms": 1.1804643314244065, "mean_action_processing_ms": 0.24645857104856128, "mean_env_wait_ms": 0.5090742874885864, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004287686529038827, "StateBufferConnector_ms": 0.0033573259281206736, "ViewRequirementAgentConnector_ms": 0.09392892258076728}, "num_episodes": 158, "episode_return_max": 180.0, "episode_return_min": -57.57884158604855, "episode_return_mean": 16.88972110263667}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 289.02817718837485, "num_env_steps_trained_throughput_per_sec": 289.02817718837485, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 16936.61, "restore_workers_time_ms": 0.015, "training_step_time_ms": 16936.56, "sample_time_ms": 1314.315, "learn_time_ms": 15601.45, "learn_throughput": 256.386, "synch_weights_time_ms": 18.864}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-55-14", "timestamp": 1723139714, "time_this_iter_s": 13.84557294845581, "time_total_s": 1149.9972822666168, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d12160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1149.9972822666168, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 29.731578947368426, "ram_util_percent": 80.10526315789473}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.186078443005681, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.319040155162414, "policy_loss": -0.020165961610230928, "vf_loss": 3.337306843822201, "vf_explained_var": 0.03725053146481514, "kl": 0.009496366153892488, "entropy": 1.1663757752627135, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6568606750920732, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.044177956445843, "policy_loss": -0.01692000357651916, "vf_loss": 2.059886598587036, "vf_explained_var": -2.8732820605555326e-07, "kl": 0.006056796228419858, "entropy": 0.642157618225889, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 187530.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 197.36050999978198, "episode_reward_min": -33.72690406552686, "episode_reward_mean": 17.260736714373817, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -102.63949000021805}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.254777070063694, "agent_policy": -13.503594495817266}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.51477113364985, 0.0, 35.708803906883425, 0.0, 0.0, 59.60910933839294, 80.0, 0.0, 40.0, 59.63075692855824, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.302477370272504, 60.0, 40.0, 0.0, 0.0, -33.72690406552686, 0.0, 58.66899504559925, 80.0, -2.921326342984, 78.18826701784695, 0.0, 20.0, 0.0, -4.960172186869355, -16.876557553220636, 0.0, 100.0, 20.0, 54.937550584325805, 17.210982106027018, 39.880121889127516, 100.0, 36.30867304258342, -16.478561345790816, 40.0, 0.0, -0.5649542681897857, 0.0, -0.1665724177028194, 0.0, -4.024767874661932, -13.391572391205754, 80.0, 0.0, 0.0, 72.69038404019946, -13.643756731017795, 9.511680449326803, -10.82931184747137, 0.0, 19.964938886044045, 0.0, -0.27146128972574846, -0.8573726722274899, 20.0, 0.0, -20.191492428036852, 39.52298899160904, 0.0, 85.97934728980957, 0.0, 20.0, 17.296691636588857, 0.0, -1.1974237406363475, 9.203105297539135, 0.0, 54.809469183327515, 0.0, 0.0, 46.80216659703046, 0.0, 0.0, 80.0, -21.633557169647606, 17.464467766139634, 0.0, -7.391466105554568, 0.0, 0.0, 120.0, 0.0, 80.0, 0.0, -8.07479657239142, -9.55487457587068, -10.840298147996071, 3.51486349962351, 0.0, 0.0, 0.0, 0.0, 0.0, 17.091781702272485, 0.0, 0.0, 0.0, 8.286029268518782, 80.0, 40.0, 0.0, 60.0, 0.0, 0.0, -4.732584375499103, 20.0, 40.0, 0.0, 20.0, -0.5455529779873125, -10.109734263336088, 35.35026067349553, 24.471379415570418, 0.0, 0.0, -21.858670623732188, -0.27914687535574356, -1.5747756439561111, 0.0, 31.771887021137083, 40.0, -1.5569411484636408, 19.120051133612062, 0.0, 39.545420896838, -1.7682577290298152, -3.4627389579372263, 10.49132864274608, 197.36050999978198, 180.0, 0.0, 0.0, -8.055602524048851, 0.0, 71.45807618809181, -5.648174427317455, 120.0, -4.087417812376861, 0.0, -0.29657452435405074, 0.0, 0.0, 60.0, -9.553346435212774, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 100.0, 100.0, 100.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-21.48522886635015, 0.0, -54.291196093116575, 0.0, 0.0, -30.390890661607063, -40.0, 0.0, -20.0, -30.369243071441762, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.302477370272504, -30.0, -20.0, 0.0, 0.0, -33.72690406552686, 0.0, -31.331004954400747, -40.0, -2.921326342984, -41.811732982153046, 0.0, -10.0, 0.0, -4.960172186869355, -16.876557553220636, 0.0, -50.0, -10.0, -35.062449415674195, -12.789017893972984, -20.119878110872484, -50.0, -23.69132695741658, -16.478561345790816, -20.0, 0.0, -0.5649542681897857, 0.0, -0.1665724177028194, 0.0, -4.024767874661932, -13.391572391205754, -40.0, 0.0, 0.0, -47.30961595980053, -13.643756731017795, -20.488319550673197, -10.82931184747137, 0.0, -10.035061113955955, 0.0, -0.27146128972574846, -0.8573726722274899, -10.0, 0.0, -20.191492428036852, -20.477011008390964, 0.0, -64.02065271019043, 0.0, -10.0, -12.703308363411148, 0.0, -1.1974237406363475, -50.79689470246085, 0.0, -35.190530816672485, 0.0, 0.0, -43.197833402969536, 0.0, 0.0, -40.0, -21.633557169647606, -12.535532233860364, 0.0, -7.391466105554568, 0.0, 0.0, -60.0, 0.0, -40.0, 0.0, -8.07479657239142, -9.55487457587068, -10.840298147996071, -26.4851365003765, 0.0, 0.0, 0.0, 0.0, 0.0, -12.908218297727522, 0.0, 0.0, 0.0, -21.71397073148122, -40.0, -20.0, 0.0, -30.0, 0.0, 0.0, -4.732584375499103, -10.0, -20.0, 0.0, -10.0, -0.5455529779873125, -10.109734263336088, -24.64973932650448, -35.52862058442958, 0.0, 0.0, -21.858670623732188, -0.27914687535574356, -1.5747756439561111, 0.0, -58.228112978862924, -20.0, -1.5569411484636408, -10.879948866387938, 0.0, -20.454579103161997, -1.7682577290298152, -3.4627389579372263, -19.508671357253917, -102.63949000021805, -90.0, 0.0, 0.0, -8.055602524048851, 0.0, -48.54192381190819, -5.648174427317455, -60.0, -4.087417812376861, 0.0, -0.29657452435405074, 0.0, 0.0, -30.0, -9.553346435212774, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6790533488495858, "mean_inference_ms": 1.1783867036932811, "mean_action_processing_ms": 0.24601220935532472, "mean_env_wait_ms": 0.5081897860811988, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004162833948803555, "StateBufferConnector_ms": 0.0034622326018703973, "ViewRequirementAgentConnector_ms": 0.08604200022995093}, "num_episodes": 157, "episode_return_max": 197.36050999978198, "episode_return_min": -33.72690406552686, "episode_return_mean": 17.260736714373817}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 312.4677749057096, "num_env_steps_trained_throughput_per_sec": 312.4677749057096, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 15943.731, "restore_workers_time_ms": 0.014, "training_step_time_ms": 15943.689, "sample_time_ms": 1195.033, "learn_time_ms": 14729.23, "learn_throughput": 271.569, "synch_weights_time_ms": 18.507}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-55-27", "timestamp": 1723139727, "time_this_iter_s": 12.80606198310852, "time_total_s": 1162.8033442497253, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d01160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1162.8033442497253, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 28.294736842105266, "ram_util_percent": 80.2}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.060271097968022, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4170104576895635, "policy_loss": -0.02575779921050222, "vf_loss": 3.4407614562660456, "vf_explained_var": 0.033721173740923406, "kl": 0.010034004215428183, "entropy": 1.152569239338239, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 64800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6856015120203613, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3223097420753316, "policy_loss": -0.018800062584382785, "vf_loss": 2.339871453858436, "vf_explained_var": 1.8995281652355872e-07, "kl": 0.0061917499960440605, "entropy": 0.6304886885779969, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 190350.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 280.0, "episode_reward_min": -52.0136634431059, "episode_reward_mean": 20.50519736239893, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -140.0}, "policy_reward_max": {"adversary_policy": 140.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.666666666666666, "agent_policy": -14.49480263760107}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.5456293186737704, -15.090877338147616, 0.0, 20.0, 115.65066208245925, -21.57967368025578, 0.0, -0.9970855413504165, -28.252561140143055, 40.0, 55.83818636152591, -52.0136634431059, 0.0, 16.892661870269755, 0.0, -4.817264573077573, 39.29499733885795, 13.747903750616466, 39.9850219034475, 15.244423861178504, 0.0, -10.76322527287248, 0.0, -4.182444851059701, 0.0, 77.62415451944204, 0.0, 0.0, 40.0, 60.0, -6.386956785005695, 0.0, 40.0, 39.104369752507544, 60.0, 0.0, -8.064252553316756, -3.5645289257226134, -4.74433162597735, -0.3331285420628205, 0.0, 40.0, 0.0, -10.07154194099477, 0.0, 53.37551037429052, 60.0, 0.0, 80.0, 40.0, -0.29940657718512176, 39.97651952917717, 0.0, -4.480526139564581, 33.382352491021216, 20.0, 0.0, -2.389419837188731, 0.0, 0.0, -20.73691383328947, -3.1510392807931478, 80.0, 0.0, 59.01678861646981, 120.0, 40.0, 0.0, 60.0, -9.755655650415996, -5.457062259900311, -31.751104731990395, 60.0, 80.0, -0.5739209906070686, 60.0, 0.0, 0.0, -0.834287666353486, -5.418169273759536, 80.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, -1.021337959222951, 20.0, 60.0, 0.0, 0.0, 0.0, 15.582482782678289, 60.0, -9.64512671876846, 59.23212902061941, 280.0, -9.488662653711573, 0.0, -0.2760463770137922, -0.3179779203879973, 0.0, 0.0, 0.0, -0.15831655083561658, 0.0, 37.77063033329625, 0.0, -0.47210885785318624, 0.0, 54.18262122290946, -1.3484158898419918, 80.0, 40.0, 0.0, 14.684397442436977, 0.0, 100.0, 60.0, 0.0, 0.0, 100.0, 0.0, 40.0, -0.28813733253282403, 20.0, 75.87990341730666, 0.0, 0.0, 0.0, 0.0, 11.306178415113909, 34.484460305521125, 60.0, 100.0, 80.0, -30.371733739928032, -3.8223669924236408, 98.93490095529008, 0.0, -5.0973851621530315, -2.756916522558942, -2.5986519673819375, 0.0, 97.65645330020271, -0.3796754118363499, 60.0, 0.0, 40.0, -19.204595859928297, 36.002556182030354, 0.0, 0.0, 51.57943372362498, 0.0, 0.0, 40.0, 19.782326314883917, 39.13207453064208], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 140.0, 140.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -0.5456293186737704, -15.090877338147616, 0.0, -10.0, -64.34933791754077, -21.57967368025578, 0.0, -0.9970855413504165, -28.252561140143055, -20.0, -34.16181363847409, -52.0136634431059, 0.0, -13.107338129730245, 0.0, -4.817264573077573, -20.70500266114206, -46.25209624938354, -20.0149780965525, -14.755576138821498, 0.0, -10.76322527287248, 0.0, -4.182444851059701, 0.0, -42.37584548055797, 0.0, 0.0, -20.0, -30.0, -6.386956785005695, 0.0, -20.0, -20.895630247492456, -30.0, 0.0, -8.064252553316756, -3.5645289257226134, -4.74433162597735, -0.3331285420628205, 0.0, -20.0, 0.0, -10.07154194099477, 0.0, -36.62448962570947, -30.0, 0.0, -40.0, -20.0, -0.29940657718512176, -20.023480470822832, 0.0, -4.480526139564581, -26.61764750897879, -10.0, 0.0, -2.389419837188731, 0.0, 0.0, -20.73691383328947, -3.1510392807931478, -40.0, 0.0, -30.98321138353019, -60.0, -20.0, 0.0, -30.0, -9.755655650415996, -5.457062259900311, -31.751104731990395, -30.0, -40.0, -0.5739209906070686, -30.0, 0.0, 0.0, -0.834287666353486, -5.418169273759536, -40.0, 0.0, 0.0, 0.0, 0.0, -50.0, 0.0, 0.0, -1.021337959222951, -10.0, -30.0, 0.0, 0.0, 0.0, -14.417517217321715, -30.0, -9.64512671876846, -30.767870979380593, -140.0, -9.488662653711573, 0.0, -0.2760463770137922, -0.3179779203879973, 0.0, 0.0, 0.0, -0.15831655083561658, 0.0, -22.22936966670374, 0.0, -0.47210885785318624, 0.0, -35.81737877709055, -1.3484158898419918, -40.0, -20.0, 0.0, -15.315602557563022, 0.0, -50.0, -30.0, 0.0, 0.0, -50.0, 0.0, -20.0, -0.28813733253282403, -10.0, -44.12009658269335, 0.0, 0.0, 0.0, 0.0, -18.69382158488609, -25.515539694478885, -30.0, -50.0, -40.0, -30.371733739928032, -3.8223669924236408, -51.065099044709925, 0.0, -5.0973851621530315, -2.756916522558942, -2.5986519673819375, 0.0, -52.34354669979729, -0.3796754118363499, -30.0, 0.0, -20.0, -19.204595859928297, -23.997443817969653, 0.0, 0.0, -38.42056627637502, 0.0, 0.0, -20.0, -10.217673685116083, -20.86792546935792]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.677818958888887, "mean_inference_ms": 1.1761581077748942, "mean_action_processing_ms": 0.24548768661833212, "mean_env_wait_ms": 0.5073668722959113, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042474564210868175, "StateBufferConnector_ms": 0.0031037831012113593, "ViewRequirementAgentConnector_ms": 0.0880086127622628}, "num_episodes": 162, "episode_return_max": 280.0, "episode_return_min": -52.0136634431059, "episode_return_mean": 20.50519736239893}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.63156766417677, "num_env_steps_trained_throughput_per_sec": 202.63156766417677, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 15959.767, "restore_workers_time_ms": 0.014, "training_step_time_ms": 15959.726, "sample_time_ms": 1172.794, "learn_time_ms": 14767.307, "learn_throughput": 270.869, "synch_weights_time_ms": 18.728}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-55-46", "timestamp": 1723139746, "time_this_iter_s": 19.751669883728027, "time_total_s": 1182.5550141334534, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d01dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1182.5550141334534, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 57.885714285714286, "ram_util_percent": 81.80357142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9668995266159375, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4551016153146823, "policy_loss": -0.024435430820449255, "vf_loss": 3.4775746919214727, "vf_explained_var": 0.052421416404346624, "kl": 0.009811710461817608, "entropy": 1.1711891108502945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 65760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7349126971042748, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.240237796095246, "policy_loss": -0.018937394412437532, "vf_loss": 2.2579602539962065, "vf_explained_var": -5.043356131154595e-07, "kl": 0.006074667044962084, "entropy": 0.6690832930887844, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 193170.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -41.25868253929981, "episode_reward_mean": 18.08234989245795, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0315405640425}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.493827160493828, "agent_policy": -13.399131589023527}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, 0.0, 31.459553481237492, 56.656201914736414, -0.5615873568200425, 0.0, 0.0, 20.0, 0.0, 19.4635094209309, 80.0, 0.0, 40.0, 0.0, 40.0, 0.0, -41.25868253929981, 0.0, 80.0, -3.7774160663244487, 60.0, 0.0, 0.0, 17.313706712866818, 23.087712356713556, -9.059754029864479, 50.204805745537314, 80.0, 0.0, 60.0, 20.0, 0.0, 0.0, 0.0, 0.0, -2.558547763726607, 0.0, 60.0, 20.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 19.173733792991154, 0.0, 60.0, 0.0, 0.0, 80.0, 40.0, -0.45150541323004445, -0.9978401863525321, 45.12097261047052, -16.181146300524738, -5.126996873591386, 60.0, 0.0, 60.0, 60.0, -6.508024932494369, 1.2380943334254884, 0.0, 58.0750558766605, 0.0, 18.313274166628986, -2.2506199611690247, -24.728370481226126, 0.0, 40.0, 0.0, 0.0, -4.86706149056284, -9.514467759369818, 0.0, 0.0, 100.0, -0.9257481118733313, -5.770136897142404, -16.528517918308037, -3.4038775384389175, 140.0, 0.0, 0.0, 79.98444590224173, 0.0, 78.92325995839796, -1.439850294020295, -1.2087691542151735, -0.5917526503391124, 0.0, 0.0, 40.0, -0.852343530976597, -7.97595227211601, 0.0, -7.434992078127929, 0.0, -10.94138939677252, 0.0, 0.0, -8.40652076134128, 109.9684594359575, 0.0, 100.0, 60.0, 51.86380425409773, 0.0, -25.378230296460888, 0.0, -0.2705704502640516, -14.625419356519613, -3.504506893031139, 20.0, 0.0, 0.0, 30.9147512033979, 80.0, 0.0, 60.0, 0.0, 0.0, -7.162530934092906, 140.0, 0.0, 40.0, 0.0, 20.0, 0.0, 100.0, 0.0, -16.23159195784637, 40.0, 0.0, -16.29761382390667, 0.0, 66.56508154719955, 88.47486495560136, 0.0, 0.0, -3.4755308506659164, -2.074808375234456, -7.3586044494302625, 0.0, 80.0, 0.0, 0.0, 40.0, 75.61034052789387, 9.913223813567223, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 20.0, 18.344790222468305, -11.26897194482315, 60.0, -0.3587085643307264], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-40.0, 0.0, -58.54044651876251, -33.343798085263586, -0.5615873568200425, 0.0, 0.0, -10.0, 0.0, -10.536490579069103, -40.0, 0.0, -20.0, 0.0, -20.0, 0.0, -41.25868253929981, 0.0, -40.0, -3.7774160663244487, -30.0, 0.0, 0.0, -12.686293287133182, -36.91228764328645, -9.059754029864479, -39.795194254462686, -40.0, 0.0, -30.0, -10.0, 0.0, 0.0, 0.0, 0.0, -2.558547763726607, 0.0, -30.0, -10.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -10.826266207008846, 0.0, -30.0, 0.0, 0.0, -40.0, -20.0, -0.45150541323004445, -0.9978401863525321, -44.87902738952949, -16.181146300524738, -5.126996873591386, -30.0, 0.0, -30.0, -30.0, -6.508024932494369, -28.761905666574513, 0.0, -31.9249441233395, 0.0, -11.686725833371016, -2.2506199611690247, -24.728370481226126, 0.0, -20.0, 0.0, 0.0, -4.86706149056284, -9.514467759369818, 0.0, 0.0, -50.0, -0.9257481118733313, -5.770136897142404, -16.528517918308037, -3.4038775384389175, -70.0, 0.0, 0.0, -40.015554097758276, 0.0, -41.07674004160204, -1.439850294020295, -1.2087691542151735, -0.5917526503391124, 0.0, 0.0, -20.0, -0.852343530976597, -7.97595227211601, 0.0, -7.434992078127929, 0.0, -10.94138939677252, 0.0, 0.0, -8.40652076134128, -70.0315405640425, 0.0, -50.0, -30.0, -38.13619574590227, 0.0, -25.378230296460888, 0.0, -0.2705704502640516, -14.625419356519613, -3.504506893031139, -10.0, 0.0, 0.0, -29.085248796602105, -40.0, 0.0, -30.0, 0.0, 0.0, -7.162530934092906, -70.0, 0.0, -20.0, 0.0, -10.0, 0.0, -50.0, 0.0, -16.23159195784637, -20.0, 0.0, -16.29761382390667, 0.0, -53.434918452800424, -61.52513504439863, 0.0, 0.0, -3.4755308506659164, -2.074808375234456, -7.3586044494302625, 0.0, -40.0, 0.0, 0.0, -20.0, -44.389659472106125, -20.086776186432775, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -10.0, -11.655209777531695, -11.26897194482315, -30.0, -0.3587085643307264]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6774141254289697, "mean_inference_ms": 1.175548294201918, "mean_action_processing_ms": 0.24526279125277134, "mean_env_wait_ms": 0.5072131705910556, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054068771409399715, "StateBufferConnector_ms": 0.003321303261650933, "ViewRequirementAgentConnector_ms": 0.09592859833328812}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -41.25868253929981, "episode_return_mean": 18.08234989245795}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 248.73333988429934, "num_env_steps_trained_throughput_per_sec": 248.73333988429934, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 15683.485, "restore_workers_time_ms": 0.014, "training_step_time_ms": 15683.437, "sample_time_ms": 1161.823, "learn_time_ms": 14503.096, "learn_throughput": 275.803, "synch_weights_time_ms": 17.698}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-56-02", "timestamp": 1723139762, "time_this_iter_s": 16.15582299232483, "time_total_s": 1198.7108371257782, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf4e8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1198.7108371257782, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 43.77272727272728, "ram_util_percent": 81.43181818181819}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0090954046696425, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.39233789841334, "policy_loss": -0.01983930077209758, "vf_loss": 3.4104880263408024, "vf_explained_var": 0.0703084327901403, "kl": 0.008445895240993232, "entropy": 1.187759487827619, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 66720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7273729157151906, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.974607928572817, "policy_loss": -0.01948042070139728, "vf_loss": 1.9929724437970642, "vf_explained_var": 1.738701306336315e-06, "kl": 0.005579537971860365, "entropy": 0.6500448894627551, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 195990.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -39.54242050788444, "episode_reward_mean": 15.438398751522348, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -86.22152388795631}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.444444444444445, "agent_policy": -12.894934581810986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.921713371514876, -0.4123583490816096, 54.39610501425074, 0.0, -1.938741333503149, 60.0, 20.0, 40.0, -0.7828320157986624, 0.0, -0.4999135800439425, 0.0, 40.0, 0.0, 80.0, 20.0, 20.0, -3.6003062468908653, -0.055479612015921775, 0.0, 100.0, 40.0, 56.31601693386317, 0.0, -2.379846162582764, -17.276255844701616, -20.16760106180341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.396383023377284, 59.546637830286585, 40.0, 60.0, -0.029440445603564624, 40.0, -0.0006772716889147379, 0.0, -0.5532515741262123, -0.10465138870347945, -14.883049840542323, 0.0, 100.0, 79.76671912194465, 60.0, 45.077705821401224, -9.19448484968693, 0.0, 0.0, 20.0, 0.0, 0.0, -3.9981993990265856, 0.0, 0.0, -18.03354068384621, 20.0, 24.501406503367093, 80.0, 0.0, -39.54242050788444, 0.0, 140.0, 0.0, 40.0, -19.36140980771652, 0.0, -1.4627987248459606, 40.0, 100.0, 0.0, 76.11210035758702, 0.0, -9.433728052547043, 0.0, 0.0, 0.0, 40.0, 0.0, -12.81365896591558, 38.027425231782956, 0.0, -2.3267918295503187, 0.0, 40.0, 0.0, 0.0, -2.169059535409563, -20.426604174850862, -1.6769712052807961, 40.0, 60.0, 0.0, 0.0, -1.5798302645098228, 0.0, 0.0, -20.696107916973165, 0.0, 20.0, 0.0, 39.72338952729526, 60.0, 59.943230447952544, -0.02535311484012759, 0.0, -14.410240385849349, 60.0, 0.0, 0.0, 40.0, 18.473074744370678, 13.008138240336196, 0.0, -26.90144588663069, -20.603520126306584, -19.023428494396992, 0.0, 0.0, 40.0, 20.0, 36.44039448469718, 20.0, -4.2346213526370855, 18.904910898912718, -9.423567218126667, 0.0, -2.1660820275102854, 60.0, 20.0, -0.3346891231352678, -3.193254422854025, 48.53709536658069, 38.478212373820156, 59.06400953253251, 100.0, -4.933995775056096, 54.81610335186516, 0.0, 39.459399145010565, 16.618087254613684, 0.0, -5.310866723992783, 0.0, 0.0, 0.0, 60.0, 33.778476112043734, 25.610882739704955, -20.85089618131145, 0.0, 60.0, -16.698447774055822, 0.0, 0.0, -27.326417402803056, 36.354151944601185, -0.15678495673475568, -1.4647839689663678], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.078286628485124, -0.4123583490816096, -35.60389498574926, 0.0, -1.938741333503149, -30.0, -10.0, -20.0, -0.7828320157986624, 0.0, -0.4999135800439425, 0.0, -20.0, 0.0, -40.0, -10.0, -10.0, -3.6003062468908653, -0.055479612015921775, 0.0, -50.0, -20.0, -33.68398306613683, 0.0, -2.379846162582764, -17.276255844701616, -20.16760106180341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.396383023377284, -30.45336216971341, -20.0, -30.0, -0.029440445603564624, -20.0, -0.0006772716889147379, 0.0, -0.5532515741262123, -0.10465138870347945, -14.883049840542323, 0.0, -50.0, -40.23328087805535, -30.0, -44.922294178598776, -9.19448484968693, 0.0, 0.0, -10.0, 0.0, 0.0, -3.9981993990265856, 0.0, 0.0, -18.03354068384621, -10.0, -35.49859349663291, -40.0, 0.0, -39.54242050788444, 0.0, -70.0, 0.0, -20.0, -19.36140980771652, 0.0, -1.4627987248459606, -20.0, -50.0, 0.0, -43.88789964241297, 0.0, -9.433728052547043, 0.0, 0.0, 0.0, -20.0, 0.0, -12.81365896591558, -21.972574768217044, 0.0, -2.3267918295503187, 0.0, -20.0, 0.0, 0.0, -2.169059535409563, -20.426604174850862, -1.6769712052807961, -20.0, -30.0, 0.0, 0.0, -1.5798302645098228, 0.0, 0.0, -20.696107916973165, 0.0, -10.0, 0.0, -20.27661047270474, -30.0, -30.056769552047452, -0.02535311484012759, 0.0, -14.410240385849349, -30.0, 0.0, 0.0, -20.0, -11.52692525562932, -16.991861759663802, 0.0, -26.90144588663069, -20.603520126306584, -19.023428494396992, 0.0, 0.0, -20.0, -10.0, -23.559605515302824, -10.0, -4.2346213526370855, -11.095089101087279, -9.423567218126667, 0.0, -2.1660820275102854, -30.0, -10.0, -0.3346891231352678, -3.193254422854025, -41.46290463341931, -21.521787626179844, -30.935990467467494, -50.0, -4.933995775056096, -35.18389664813485, 0.0, -20.540600854989435, -13.38191274538632, 0.0, -5.310866723992783, 0.0, 0.0, 0.0, -30.0, -86.22152388795631, -34.38911726029504, -20.85089618131145, 0.0, -30.0, -16.698447774055822, 0.0, 0.0, -27.326417402803056, -23.645848055398815, -0.15678495673475568, -1.4647839689663678]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6781457017166711, "mean_inference_ms": 1.1767626862045009, "mean_action_processing_ms": 0.24523696492720132, "mean_env_wait_ms": 0.5075705959620481, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00565559775741012, "StateBufferConnector_ms": 0.003347279113016011, "ViewRequirementAgentConnector_ms": 0.09568171736634808}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -39.54242050788444, "episode_return_mean": 15.438398751522348}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 258.7187377389877, "num_env_steps_trained_throughput_per_sec": 258.7187377389877, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 14831.522, "restore_workers_time_ms": 0.013, "training_step_time_ms": 14831.472, "sample_time_ms": 1161.518, "learn_time_ms": 13652.486, "learn_throughput": 292.987, "synch_weights_time_ms": 15.883}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-56-18", "timestamp": 1723139778, "time_this_iter_s": 15.502424001693726, "time_total_s": 1214.213261127472, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d20670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1214.213261127472, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 39.777272727272724, "ram_util_percent": 82.71818181818182}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.983397318671147, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2410815014193455, "policy_loss": -0.024248387731495312, "vf_loss": 3.2633476708084346, "vf_explained_var": 0.0485040683299303, "kl": 0.009911096063205586, "entropy": 1.1686118771632512, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 67680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6505109733512215, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1065360969262765, "policy_loss": -0.01689553183803982, "vf_loss": 2.1223404252360054, "vf_explained_var": -4.2080456483448653e-07, "kl": 0.005456004824299965, "entropy": 0.6197686322508974, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 198810.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 230.98996976210037, "episode_reward_min": -80.05338100286802, "episode_reward_mean": 18.49767184869055, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -129.01003023789963}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.784313725490197, "agent_policy": -13.855269327780034}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.48427366220862, 40.0, 0.0, 0.0, 139.56041236198595, 71.77140742933707, -2.750847285244966, -0.041983829971039555, -1.7382660864126798, 17.882544360432952, 0.0, 0.0, -0.8833343621495893, 32.68436793391333, 6.037933677768875, -6.887012451431435, -1.7993078604869583, 0.0, 0.0, -3.464737983217201, -3.241721931990466, -19.04359086100603, 0.0, 0.0, 29.025116563527483, 0.0, 0.0, 0.0, 20.0, 100.0, 0.0, 60.0, 0.0, 0.0, 0.0, 40.0, -2.8309783576291636, 0.0, -28.891739552270806, 0.0, -14.16605181574185, 40.0, 0.0, -32.731835628013904, 0.0, 0.0, 60.0, 0.0, 19.47847140692824, 0.0, -0.15047647244045725, 60.0, 0.0, -80.05338100286802, 0.0, 0.0, 20.0, 120.0, -1.8372504458869054, 0.0, 0.0, 0.0, 99.96806133189423, 80.0, -8.820664757197527, 0.0, 51.35211582774305, 20.0, -0.6584088033579771, 40.0, 0.0, 140.0, 0.0, 60.0, 40.0, 0.0, 40.0, 20.0, 0.0, 0.0, 0.0, -15.360859900550125, 60.0, -21.239865592208847, -0.7387359842125663, -4.752387107787094, 0.0, 0.0, 0.0, 230.98996976210037, 40.0, 0.0, 80.0, 0.0, 0.0, -11.067828563233334, 25.167569034534793, 0.0, 0.0, 95.99286894968341, 30.28361322097947, -0.06886760264878444, 0.0, 36.676179224219354, 60.0, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, 0.0, 100.0, 60.0, 0.0, 40.0, 49.971240878911125, 0.0, 0.0, 0.0, 120.0, 0.0, 20.0, -5.482503544248038, -0.8506032493091054, -6.362613901388562, 0.0, 0.0, 0.0, 60.0, -11.197843470681814, 60.0, 0.0, -0.6324860120936293, 0.0, 140.0, 40.0, 0.0, 0.0, 0.0, -3.3432941401651277, 80.0, 15.675209533262098, 0.0, -9.743407450203032, -2.669350799945854, 40.0, -5.996725304256692, 0.0, -5.59805003058877, 0.0, 130.5274515343593, -9.288001703296601], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 120.0, 120.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-18.51572633779138, -20.0, 0.0, 0.0, -70.43958763801406, -48.228592570662926, -2.750847285244966, -0.041983829971039555, -1.7382660864126798, -12.117455639567048, 0.0, 0.0, -0.8833343621495893, -27.31563206608666, -23.962066322231127, -6.887012451431435, -1.7993078604869583, 0.0, 0.0, -3.464737983217201, -3.241721931990466, -19.04359086100603, 0.0, 0.0, -30.974883436472517, 0.0, 0.0, 0.0, -10.0, -50.0, 0.0, -30.0, 0.0, 0.0, 0.0, -20.0, -2.8309783576291636, 0.0, -28.891739552270806, 0.0, -14.16605181574185, -20.0, 0.0, -32.731835628013904, 0.0, 0.0, -30.0, 0.0, -10.52152859307176, 0.0, -0.15047647244045725, -30.0, 0.0, -80.05338100286802, 0.0, 0.0, -10.0, -60.0, -1.8372504458869054, 0.0, 0.0, 0.0, -50.031938668105774, -40.0, -8.820664757197527, 0.0, -68.64788417225695, -10.0, -0.6584088033579771, -20.0, 0.0, -70.0, 0.0, -30.0, -20.0, 0.0, -20.0, -10.0, 0.0, 0.0, 0.0, -15.360859900550125, -30.0, -21.239865592208847, -0.7387359842125663, -4.752387107787094, 0.0, 0.0, 0.0, -129.01003023789963, -20.0, 0.0, -40.0, 0.0, 0.0, -11.067828563233334, -34.83243096546521, 0.0, 0.0, -54.00713105031658, -29.71638677902053, -0.06886760264878444, 0.0, -23.32382077578064, -30.0, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, 0.0, -50.0, -30.0, 0.0, -20.0, -40.028759121088875, 0.0, 0.0, 0.0, -60.0, 0.0, -10.0, -5.482503544248038, -0.8506032493091054, -6.362613901388562, 0.0, 0.0, 0.0, -30.0, -11.197843470681814, -30.0, 0.0, -0.6324860120936293, 0.0, -70.0, -20.0, 0.0, 0.0, 0.0, -3.3432941401651277, -40.0, -14.324790466737904, 0.0, -9.743407450203032, -2.669350799945854, -20.0, -5.996725304256692, 0.0, -5.59805003058877, 0.0, -79.4725484656407, -9.288001703296601]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6780446310554601, "mean_inference_ms": 1.1769705364313467, "mean_action_processing_ms": 0.2451188968514502, "mean_env_wait_ms": 0.5076684655086467, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005930077795888863, "StateBufferConnector_ms": 0.0032821511910631766, "ViewRequirementAgentConnector_ms": 0.10042502210031148}, "num_episodes": 153, "episode_return_max": 230.98996976210037, "episode_return_min": -80.05338100286802, "episode_return_mean": 18.49767184869055}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.92205500116447, "num_env_steps_trained_throughput_per_sec": 229.92205500116447, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 14938.785, "restore_workers_time_ms": 0.013, "training_step_time_ms": 14938.721, "sample_time_ms": 1145.477, "learn_time_ms": 13774.628, "learn_throughput": 290.389, "synch_weights_time_ms": 16.563}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-56-35", "timestamp": 1723139795, "time_this_iter_s": 17.45494794845581, "time_total_s": 1231.6682090759277, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b9d3550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1231.6682090759277, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 45.536, "ram_util_percent": 82.16}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.025325729511678, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7857271248474715, "policy_loss": -0.02549866563398003, "vf_loss": 2.8091455368325113, "vf_explained_var": 0.04709978314737479, "kl": 0.010401294801935891, "entropy": 1.1762784945468108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 68640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6726953158987329, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6624988717813018, "policy_loss": -0.016321035098129263, "vf_loss": 1.677646645882451, "vf_explained_var": -1.0680222342200312e-07, "kl": 0.005866322434283904, "entropy": 0.6065664658521084, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 201630.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -29.469757109720454, "episode_reward_mean": 13.96316175094022, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.02574861671017}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.333333333333334, "agent_policy": -11.03683824905978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-29.469757109720454, -2.1177021438542454, 60.0, -1.0152248893898352, 0.0, 0.0, 40.0, -1.816592023072835, 0.0, 0.0, -23.48769489939561, -0.20996011960354388, 0.0, 20.0, -3.429265499992898, 20.0, 25.599324735104933, 0.0, 20.0, -4.085129342479879, 0.0, 0.0, 60.0, 40.0, 0.0, 0.0, 100.0, -0.21531041955249575, 0.0, 0.0, -14.568322422809352, 58.751445025814576, 80.0, 0.0, 0.0, 0.0, -1.3594083276055657, 118.97425138328983, 0.0, -7.934587258384363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -17.02802657402311, 0.0, 38.75193125061839, 0.0, 39.59686756255342, -0.7259630086410485, -12.760537674467027, 0.0, 0.0, 19.31821270861328, 40.0, -0.0415407947558033, 0.0, -11.410875691227002, 0.0, 13.028381995829212, 60.0, 0.0, 24.659841272909922, 20.0, 1.6287984508994455, 0.14498702912213313, 0.0, -2.1757160806598144, 40.0, 0.0, 0.0, 0.0, 71.05124508300275, 40.0, 0.0, 39.600355204419884, 0.0, 58.51198206521346, 100.0, 40.0, 0.0, 36.632675605787426, 6.678387955508853, 0.0, 0.0, -10.855043765352807, 80.0, 0.0, -0.9523384306575622, 0.0, 119.93357283782689, 79.89030333141092, -0.28949022947475034, -11.871048771052891, 58.048969108465485, -8.747127743101757, 18.473413725159237, 40.0, -11.612923443706883, 17.367017340603805, 0.0, -4.861947815106798, 0.0, 20.0, -4.267504710742087, -0.8534608551044276, 0.0, -5.426889579209609, 0.0, 0.0, 0.0, -17.004090259191663, 77.64576586821373, -2.808334014869895, -21.38110603917227, 98.6121954692774, -0.17189353580545075, 0.0, 42.9414987013165, 0.0, -3.8568953310245204, 0.0, -1.0321110579523307, 0.0, 0.0, 120.0, 0.0, 20.0, 20.0, 80.0, -1.6057072290987173, 0.0, 120.0, 40.0, 0.0, 0.0, -9.217214059415003, 0.0, -1.3364691638016502, 0.0, -14.489648047416747, 0.0, 20.0, -1.9200077927716686, -0.012520650432608083, 0.0, 80.0, -1.8529854544709368, -1.1331992162507498, 20.0, 0.0, 0.0, 20.0, 0.0, -4.0763896072123815, -5.889941728498126, -0.35455039346829476, 0.0, 17.923233145351535], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-29.469757109720454, -2.1177021438542454, -30.0, -1.0152248893898352, 0.0, 0.0, -20.0, -1.816592023072835, 0.0, 0.0, -23.48769489939561, -0.20996011960354388, 0.0, -10.0, -3.429265499992898, -10.0, -34.400675264895085, 0.0, -10.0, -4.085129342479879, 0.0, 0.0, -30.0, -20.0, 0.0, 0.0, -50.0, -0.21531041955249575, 0.0, 0.0, -14.568322422809352, -31.24855497418543, -40.0, 0.0, 0.0, 0.0, -1.3594083276055657, -61.02574861671017, 0.0, -7.934587258384363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -17.02802657402311, 0.0, -21.24806874938161, 0.0, -20.40313243744658, -0.7259630086410485, -12.760537674467027, 0.0, 0.0, -10.681787291386717, -20.0, -0.0415407947558033, 0.0, -11.410875691227002, 0.0, -16.97161800417079, -30.0, 0.0, -35.340158727090085, -10.0, -28.371201549100554, -29.855012970877862, 0.0, -2.1757160806598144, -20.0, 0.0, 0.0, 0.0, -48.948754916997245, -20.0, 0.0, -20.399644795580112, 0.0, -31.488017934786534, -50.0, -20.0, 0.0, -23.367324394212574, -23.321612044491147, 0.0, 0.0, -10.855043765352807, -40.0, 0.0, -0.9523384306575622, 0.0, -60.06642716217313, -40.10969666858908, -0.28949022947475034, -11.871048771052891, -31.951030891534522, -8.747127743101757, -11.526586274840763, -20.0, -11.612923443706883, -12.632982659396195, 0.0, -4.861947815106798, 0.0, -10.0, -4.267504710742087, -0.8534608551044276, 0.0, -5.426889579209609, 0.0, 0.0, 0.0, -17.004090259191663, -42.35423413178627, -2.808334014869895, -21.38110603917227, -51.387804530722605, -0.17189353580545075, 0.0, -47.0585012986835, 0.0, -3.8568953310245204, 0.0, -1.0321110579523307, 0.0, 0.0, -60.0, 0.0, -10.0, -10.0, -40.0, -1.6057072290987173, 0.0, -60.0, -20.0, 0.0, 0.0, -9.217214059415003, 0.0, -1.3364691638016502, 0.0, -14.489648047416747, 0.0, -10.0, -1.9200077927716686, -0.012520650432608083, 0.0, -40.0, -1.8529854544709368, -1.1331992162507498, -10.0, 0.0, 0.0, -10.0, 0.0, -4.0763896072123815, -5.889941728498126, -0.35455039346829476, 0.0, -42.07676685464846]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6791862043905988, "mean_inference_ms": 1.1789454214661013, "mean_action_processing_ms": 0.2453680498278629, "mean_env_wait_ms": 0.5084691805329199, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00497720859668873, "StateBufferConnector_ms": 0.0038483996450165174, "ViewRequirementAgentConnector_ms": 0.11323212105550884}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -29.469757109720454, "episode_return_mean": 13.96316175094022}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 173.43947881616577, "num_env_steps_trained_throughput_per_sec": 173.43947881616577, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 15856.168, "restore_workers_time_ms": 0.013, "training_step_time_ms": 15856.099, "sample_time_ms": 1193.696, "learn_time_ms": 14643.977, "learn_throughput": 273.15, "synch_weights_time_ms": 16.539}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-56-59", "timestamp": 1723139819, "time_this_iter_s": 23.075330018997192, "time_total_s": 1254.743539094925, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d011f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1254.743539094925, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 67.96969696969697, "ram_util_percent": 81.56060606060605}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2594101359446843, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.838308786849181, "policy_loss": -0.026463031642197165, "vf_loss": 2.8625891375044983, "vf_explained_var": 0.03621370817224185, "kl": 0.010913402048511026, "entropy": 1.1994252680490414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 69600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6599924590887752, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8816445174792134, "policy_loss": -0.017010993730022527, "vf_loss": 1.8974770980523834, "vf_explained_var": -7.222307489273396e-08, "kl": 0.005892070824409242, "entropy": 0.5862751899881565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 204450.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -32.54736994165892, "episode_reward_mean": 15.621225806715175, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.012345679012345, "agent_policy": -11.41581123032186}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.561321029762224, 0.0, 79.97507559923574, 0.0, -7.146218566904659, 60.0, 0.0, 0.0, -0.24796567686203197, 40.0, -0.243740050464768, 60.0, 0.0, 0.0, 73.018454463937, -2.3655348578393847, 0.0, -4.5849969029081485, 0.0, -2.9439989487042557, 0.0, -5.046024092974083, 0.0, 0.0, 0.0, 40.0, -0.3652751616169725, 0.0, 63.60952472022318, -4.823567169908391, 0.0, -1.5578227963554159, 0.0, 80.0, -1.2276376270757683, 7.57656169548121, 0.0, 158.34359738652182, 100.0, -1.155919227661123, -0.8728078192439337, 31.678235444988374, 27.30433098468913, 59.59524049956882, 0.0, 38.066306959348395, -6.263101620060224, 60.0, 20.0, 0.0, -23.327482219373415, 19.925634726763803, 40.0, 0.0, 0.0, -0.20138038768140465, 120.0, 0.0, 0.0, 0.0, -26.43014887101188, 0.0, -0.011429927743227264, -2.476012292194091, 0.0, 0.0, 40.0, 40.0, 20.0, -4.847186441779327, 0.0, -4.283275380659833, -11.360849316740744, 36.394563910541635, 55.72423613056695, -3.5950008441250114, 40.0, -0.3363569375841069, 0.0, 60.0, 0.0, 80.0, 0.0, -0.9440602107540541, 0.0, 79.84045312527944, -0.1469350074966025, 60.0, 0.0, 0.0, 20.0, 79.70952058850403, 0.0, 0.0, 0.0, -3.3625776631713835, 62.80758473905633, 0.0, 0.0, 80.0, 60.0, 40.0, 60.0, -3.5658489144942025, 0.0, 0.0, -0.13513593976049898, 40.0, 0.0, -9.722342128582971, -0.6308703704171859, 40.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, -0.9989309895293852, -0.5114543316577103, 0.0, -15.63341756986144, 0.0, -12.821395802086215, 60.0, 27.963595644828008, 0.0, -3.7330783145084414, 13.685873004651269, 20.0, 0.0, 0.0, -0.21938922186500176, 80.0, -0.8317331282352503, 0.0, -8.659246356903502, 80.0, 0.0, -2.0949508587114227, 15.852666936198291, 220.0, -32.54736994165892, 0.0, 0.0, 0.0, 40.0, -5.976421900059635, -12.466917038517714, -0.665092516398621, 0.0, -0.11561894075215906, 0.0, 0.0, 0.0, 0.0, -1.0623979608231837, 8.400259727063482, 10.42458716435569, 0.0, -0.13748349046422526, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 110.0, 110.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-6.561321029762224, 0.0, -40.02492440076426, 0.0, -7.146218566904659, -30.0, 0.0, 0.0, -0.24796567686203197, -20.0, -0.243740050464768, -30.0, 0.0, 0.0, -46.98154553606298, -2.3655348578393847, 0.0, -34.584996902908145, 0.0, -2.9439989487042557, 0.0, -5.046024092974083, 0.0, 0.0, 0.0, -20.0, -0.3652751616169725, 0.0, -56.39047527977682, -4.823567169908391, 0.0, -1.5578227963554159, 0.0, -40.0, -1.2276376270757683, -22.423438304518793, 0.0, -81.65640261347819, -50.0, -1.155919227661123, -0.8728078192439337, -28.321764555011626, -32.69566901531087, -30.404759500431183, 0.0, -21.9336930406516, -6.263101620060224, -30.0, -10.0, 0.0, -23.327482219373415, -10.074365273236197, -20.0, 0.0, 0.0, -0.20138038768140465, -60.0, 0.0, 0.0, 0.0, -26.43014887101188, 0.0, -0.011429927743227264, -2.476012292194091, 0.0, 0.0, -20.0, -20.0, -10.0, -4.847186441779327, 0.0, -4.283275380659833, -11.360849316740744, -23.605436089458365, -34.27576386943306, -3.5950008441250114, -20.0, -0.3363569375841069, 0.0, -30.0, 0.0, -40.0, 0.0, -0.9440602107540541, 0.0, -40.15954687472057, -0.1469350074966025, -30.0, 0.0, 0.0, -10.0, -40.29047941149597, 0.0, 0.0, 0.0, -3.3625776631713835, -57.19241526094366, 0.0, 0.0, -40.0, -30.0, -20.0, -30.0, -3.5658489144942025, 0.0, 0.0, -0.13513593976049898, -20.0, 0.0, -9.722342128582971, -0.6308703704171859, -20.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -0.9989309895293852, -0.5114543316577103, 0.0, -15.63341756986144, 0.0, -12.821395802086215, -30.0, -32.03640435517199, 0.0, -3.7330783145084414, -16.314126995348737, -10.0, 0.0, 0.0, -0.21938922186500176, -40.0, -0.8317331282352503, 0.0, -8.659246356903502, -40.0, 0.0, -2.0949508587114227, -14.147333063801709, -110.0, -32.54736994165892, 0.0, 0.0, 0.0, -20.0, -5.976421900059635, -12.466917038517714, -0.665092516398621, 0.0, -0.11561894075215906, 0.0, 0.0, 0.0, 0.0, -1.0623979608231837, -21.599740272936515, -19.57541283564431, 0.0, -0.13748349046422526, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6794824431458618, "mean_inference_ms": 1.1796672700649236, "mean_action_processing_ms": 0.24538032119877276, "mean_env_wait_ms": 0.5087915849236662, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005450145697888033, "StateBufferConnector_ms": 0.004040311883997034, "ViewRequirementAgentConnector_ms": 0.10108300197271654}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -32.54736994165892, "episode_return_mean": 15.621225806715175}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.26025360561758, "num_env_steps_trained_throughput_per_sec": 199.26025360561758, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 16527.669, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16527.6, "sample_time_ms": 1216.296, "learn_time_ms": 15292.173, "learn_throughput": 261.572, "synch_weights_time_ms": 17.094}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-57-19", "timestamp": 1723139839, "time_this_iter_s": 20.098772048950195, "time_total_s": 1274.8423111438751, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf46a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1274.8423111438751, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 60.825, "ram_util_percent": 81.20714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0168777131165068, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.304221231987079, "policy_loss": -0.025946617687683707, "vf_loss": 3.328212075183789, "vf_explained_var": 0.05505603278676669, "kl": 0.009778852451579272, "entropy": 1.2032167937606573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 70560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7169035794358727, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3016679152106563, "policy_loss": -0.017133550486256574, "vf_loss": 2.3176344560393205, "vf_explained_var": 9.804541337574627e-07, "kl": 0.005835058737449964, "entropy": 0.5879278313500661, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 207270.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -38.79243968790754, "episode_reward_mean": 18.91907142622732, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.864197530864198, "agent_policy": -13.67352116636527}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, -1.4332503980103017, 20.0, -3.6914444759945058, 0.0, 140.0, 0.0, 57.68561673494051, 34.37867740812112, 0.0, 40.0, -1.964753724067384, -12.532296943834535, 60.0, 0.0, 0.0, -0.44219523263618, 0.0, 0.0, 0.0, 0.0, 34.71263315086974, -21.133554381829228, -1.789539290912845, -1.6818131457853003, -0.8375404226461969, -2.3067834979206996, 0.0, 0.0, -2.3605114266492655, 0.0, 60.0, 0.0, -6.842241093870645, -15.92511609487861, 0.0, 31.63631010078508, -0.9630717177102233, 0.0, 114.83355688161754, 40.0, 0.0, 19.961065023369542, 0.0, 20.435425961952305, 100.0, 20.0, -0.7362504066123887, 60.0, 59.302076864040025, -0.5850658710528456, -2.288463321502423, 40.0, 0.0, -0.6188423338155391, 120.0, 80.0, -0.1163449923114479, 40.0, 0.0, 0.0, 0.0, 60.0, -0.5053890316210663, 0.0, 39.969532890585796, 0.0, -3.3888397272482473, 0.0, 107.10212818789972, 0.0, -2.8788369877207756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 31.621240022844756, 40.572831532569296, -38.79243968790754, 0.0, 16.00117125058493, 0.0, -14.884839063035155, 0.0, -10.232911336281921, 20.0, 0.0, -2.539590464119591, 0.0, -4.921285720702818, 0.0, -0.007073822544917396, 0.0, 0.0, 200.0, 0.0, -23.791548915665008, 120.0, 0.0, 0.0, -4.614168089826744, -1.0618824895147516, 40.0, -0.11562108400289817, 0.0, 0.0, -3.900163119687802, 0.0, 48.76924735927624, -5.840545336229428, 39.732335224820616, 0.0, 40.0, 60.0, 60.0, 0.0, 0.0, 0.0, -25.05197145121577, 0.0, 40.0, 20.0, 60.0, 39.63824599523923, 20.39872988747063, 40.0, 0.0, 0.0, 0.0, -22.271761859316918, 68.61609144764579, -0.027215732638125045, 120.0, -4.108711857231643, 0.0, 40.0, -16.348659719094943, 60.0, 77.6130036342678, 100.0, 0.0, -1.0603837905245739, 0.0, 60.0, 20.0, 87.18603774726525, 0.0, 0.0, 20.0, -0.6095686974822945, 60.0, 0.0, -0.07389950168592563, 40.0, 20.0, 0.0, 100.0, 40.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -1.4332503980103017, -10.0, -3.6914444759945058, 0.0, -70.0, 0.0, -32.31438326505949, -25.621322591878876, 0.0, -20.0, -1.964753724067384, -12.532296943834535, -30.0, 0.0, 0.0, -0.44219523263618, 0.0, 0.0, 0.0, 0.0, -25.287366849130247, -21.133554381829228, -1.789539290912845, -1.6818131457853003, -0.8375404226461969, -2.3067834979206996, 0.0, 0.0, -2.3605114266492655, 0.0, -30.0, 0.0, -6.842241093870645, -15.92511609487861, 0.0, -28.36368989921492, -0.9630717177102233, 0.0, -65.16644311838246, -20.0, 0.0, -10.038934976630458, 0.0, -69.56457403804771, -50.0, -10.0, -0.7362504066123887, -30.0, -30.69792313595997, -0.5850658710528456, -2.288463321502423, -20.0, 0.0, -0.6188423338155391, -60.0, -40.0, -0.1163449923114479, -20.0, 0.0, 0.0, 0.0, -30.0, -0.5053890316210663, 0.0, -20.0304671094142, 0.0, -3.3888397272482473, 0.0, -72.89787181210029, 0.0, -2.8788369877207756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -28.378759977155237, -49.427168467430704, -38.79243968790754, 0.0, -43.99882874941507, 0.0, -14.884839063035155, 0.0, -10.232911336281921, -10.0, 0.0, -2.539590464119591, 0.0, -4.921285720702818, 0.0, -0.007073822544917396, 0.0, 0.0, -100.0, 0.0, -23.791548915665008, -60.0, 0.0, 0.0, -4.614168089826744, -1.0618824895147516, -20.0, -0.11562108400289817, 0.0, 0.0, -3.900163119687802, 0.0, -41.23075264072376, -5.840545336229428, -20.26766477517938, 0.0, -20.0, -30.0, -30.0, 0.0, 0.0, 0.0, -25.05197145121577, 0.0, -20.0, -10.0, -30.0, -20.361754004760773, -39.601270112529384, -20.0, 0.0, 0.0, 0.0, -22.271761859316918, -51.383908552354235, -0.027215732638125045, -60.0, -4.108711857231643, 0.0, -20.0, -16.348659719094943, -30.0, -42.3869963657322, -50.0, 0.0, -1.0603837905245739, 0.0, -30.0, -10.0, -62.813962252734726, 0.0, 0.0, -10.0, -0.6095686974822945, -30.0, 0.0, -0.07389950168592563, -20.0, -10.0, 0.0, -50.0, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6808234481118499, "mean_inference_ms": 1.1807303085371792, "mean_action_processing_ms": 0.24541129854810623, "mean_env_wait_ms": 0.5094019723352138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005161541479605215, "StateBufferConnector_ms": 0.003943987834600754, "ViewRequirementAgentConnector_ms": 0.10557822239251784}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -38.79243968790754, "episode_return_mean": 18.91907142622732}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.83620658315, "num_env_steps_trained_throughput_per_sec": 197.83620658315, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 17198.84, "restore_workers_time_ms": 0.014, "training_step_time_ms": 17198.769, "sample_time_ms": 1238.444, "learn_time_ms": 15939.887, "learn_throughput": 250.943, "synch_weights_time_ms": 18.247}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-57-39", "timestamp": 1723139859, "time_this_iter_s": 20.23157024383545, "time_total_s": 1295.0738813877106, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16b9d3ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1295.0738813877106, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 59.199999999999996, "ram_util_percent": 81.63793103448278}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3525554268310467, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3316306716452044, "policy_loss": -0.024008691348232483, "vf_loss": 3.3534913203368584, "vf_explained_var": 0.0659839768583576, "kl": 0.010740179048417627, "entropy": 1.187976828838388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 71520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6746969624085629, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8842141509056092, "policy_loss": -0.01708684610171947, "vf_loss": 1.9000904993385288, "vf_explained_var": -6.882222831671965e-07, "kl": 0.006052469651387634, "entropy": 0.584228282194611, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 210090.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 197.44456355561042, "episode_reward_min": -34.39048604190206, "episode_reward_mean": 16.117432387171494, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -102.55543644438961}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.567901234567902, "agent_policy": -12.586271316532205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.13804612435978636, 60.0, 40.0, 0.0, -0.15493322854883584, 22.957829371709973, 0.0, 0.0, 20.0, -2.717114711410387, 97.88548439233851, -7.577326067541947, 10.820697308907182, 0.0, 0.0, -10.356106055475543, 0.0, -0.9409500294152351, 60.0, -5.057530120773112, 0.0, -19.218472403832813, -1.5168559656808023, -3.4329527380042606, -0.36233122708133947, 0.0, 0.0, 0.0, 0.0, -0.9451635620550647, 40.0, 0.0, -1.0011442644500468, -3.1515318261351255, -0.06210392191573377, 30.917803045535365, 60.0, -34.39048604190206, 0.0, 60.0, 0.0, 0.0, 60.0, 40.0, 36.9133700903175, 114.71844662312422, 0.0, 0.0, 76.25969218568169, 32.03353763975119, 20.0, 0.0, -4.05399282936753, 0.0, 40.0, 36.03804494903475, -2.1321256743110495, 109.57711009934894, 18.147351122418073, -21.821890687209734, 39.91380466447964, 0.0, -0.5953134667856408, -1.307505990236838, -21.33873454956672, 197.44456355561042, 40.0, 20.0, 0.0, 0.0, 0.0, -12.256155921532688, 0.0, -3.8060736656866503, 80.0, 0.0, -0.3940136708913877, 0.0, 59.33558216745932, 0.0, 80.0, 19.313518960852228, 0.0, 0.0, -1.619840643944318, 0.0, 20.0, 80.0, 0.0, -1.6886849585581096, 0.0, 36.0322400862014, 0.0, 31.397925832092124, 0.0, -0.6841714737461824, 24.15349040898318, -0.24404385142829166, 0.0, 0.0, 57.18663869503163, 68.23316394246184, 20.0, 60.0, -13.663789029336252, 100.0, 119.7744411580392, 51.017065417918786, -0.6678975118060515, 0.0, 0.0, -14.234536852422302, 0.0, 0.0, 0.0, -0.5278317376666475, -9.356155445051838, 0.0, 0.0, -5.329584074457705, -3.922216094979637, 0.0, 140.0, 40.0, 0.0, 0.0, 0.0, 0.0, -8.242767316455135, 0.0, -5.4137502367621515, 0.0, -12.086112454778133, 40.0, 39.935347148422885, -5.041828119869811, 60.0, -9.155843735482557, 20.0, -7.518210121157902, 0.0, 0.0, 0.0, -18.69773980562005, 0.0, 52.01172316876782, 20.0, 20.0, 39.23846042902737, -3.500753082836251, 100.0, -9.039459179688194, 0.0, 0.0, 0.0, -8.810294032459009, 0.0, -0.562008694329974, 0.0, -7.7250234506907764, 0.0, 56.22811090596485], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-0.13804612435978636, -30.0, -20.0, 0.0, -0.15493322854883584, -37.04217062829002, 0.0, 0.0, -10.0, -2.717114711410387, -52.11451560766149, -7.577326067541947, -19.179302691092808, 0.0, 0.0, -10.356106055475543, 0.0, -0.9409500294152351, -30.0, -5.057530120773112, 0.0, -19.218472403832813, -1.5168559656808023, -3.4329527380042606, -0.36233122708133947, 0.0, 0.0, 0.0, 0.0, -0.9451635620550647, -20.0, 0.0, -1.0011442644500468, -3.1515318261351255, -0.06210392191573377, -29.08219695446463, -30.0, -34.39048604190206, 0.0, -30.0, 0.0, 0.0, -30.0, -20.0, -23.086629909682504, -65.28155337687578, 0.0, 0.0, -43.74030781431831, -27.966462360248805, -10.0, 0.0, -4.05399282936753, 0.0, -20.0, -53.96195505096525, -2.1321256743110495, -70.42288990065107, -11.852648877581927, -21.821890687209734, -20.086195335520355, 0.0, -0.5953134667856408, -1.307505990236838, -21.33873454956672, -102.55543644438961, -20.0, -10.0, 0.0, 0.0, 0.0, -12.256155921532688, 0.0, -3.8060736656866503, -40.0, 0.0, -0.3940136708913877, 0.0, -30.664417832540682, 0.0, -40.0, -10.68648103914777, 0.0, 0.0, -1.619840643944318, 0.0, -10.0, -40.0, 0.0, -31.68868495855811, 0.0, -23.967759913798602, 0.0, -28.602074167907883, 0.0, -0.6841714737461824, -35.84650959101679, -0.24404385142829166, 0.0, 0.0, -32.813361304968375, -51.76683605753816, -10.0, -30.0, -13.663789029336252, -50.0, -60.2255588419608, -38.9829345820812, -0.6678975118060515, 0.0, 0.0, -14.234536852422302, 0.0, 0.0, 0.0, -0.5278317376666475, -9.356155445051838, 0.0, 0.0, -5.329584074457705, -3.922216094979637, 0.0, -70.0, -20.0, 0.0, 0.0, 0.0, 0.0, -8.242767316455135, 0.0, -5.4137502367621515, 0.0, -12.086112454778133, -20.0, -20.06465285157711, -5.041828119869811, -30.0, -9.155843735482557, -10.0, -7.518210121157902, 0.0, 0.0, 0.0, -18.69773980562005, 0.0, -37.98827683123218, -10.0, -10.0, -20.76153957097263, -3.500753082836251, -50.0, -9.039459179688194, 0.0, 0.0, 0.0, -8.810294032459009, 0.0, -0.562008694329974, 0.0, -7.7250234506907764, 0.0, -33.77188909403517]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6811507226975543, "mean_inference_ms": 1.181001724818392, "mean_action_processing_ms": 0.24539855449930367, "mean_env_wait_ms": 0.5097751801778198, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004515015048745238, "StateBufferConnector_ms": 0.0036146169827308183, "ViewRequirementAgentConnector_ms": 0.09602632051632728}, "num_episodes": 162, "episode_return_max": 197.44456355561042, "episode_return_min": -34.39048604190206, "episode_return_mean": 16.117432387171494}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 171.90464451126408, "num_env_steps_trained_throughput_per_sec": 171.90464451126408, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 18194.515, "restore_workers_time_ms": 0.014, "training_step_time_ms": 18194.442, "sample_time_ms": 1258.424, "learn_time_ms": 16913.415, "learn_throughput": 236.499, "synch_weights_time_ms": 20.351}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-58-02", "timestamp": 1723139882, "time_this_iter_s": 23.32143521308899, "time_total_s": 1318.3953166007996, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d21160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1318.3953166007996, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 70.73939393939395, "ram_util_percent": 82.10303030303032}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1422667844841876, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6471392047901947, "policy_loss": -0.022997599126635276, "vf_loss": 3.668082764496406, "vf_explained_var": 0.041495083707074325, "kl": 0.010270185416723702, "entropy": 1.177777184545994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 72480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7083065539598465, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0002113806017747, "policy_loss": -0.018303620920546274, "vf_loss": 2.0174996306287483, "vf_explained_var": 8.006467886850344e-08, "kl": 0.005076856536847721, "entropy": 0.5600731749272515, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 212910.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -46.310961052496296, "episode_reward_mean": 13.667981638855386, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.88888888888889, "agent_policy": -12.998685027811277}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -7.63137361598988, 0.0, -25.58180876160542, -34.16253244387248, -10.216676105375935, 80.0, 0.0, 38.85674022171078, -17.37465226278778, 0.0, 38.706964453558044, 40.0, -19.482662968420705, 20.0, 60.0, -1.6536892008078685, 0.0, -1.2726873472551148, 51.224147100066055, 20.0, 0.0, 0.0, -6.67836004563843, 0.0, 0.0, -3.608874953662621, 60.0, -0.619551828063224, 39.72938303089365, -5.291860827767475, 0.0, -1.1358397595509184, -13.647085455106474, -12.601736369222287, -39.37236952351117, -0.897066451497438, 50.250624134687094, 0.0, -1.4398314089778796, 0.0, 60.0, -0.14927883757782423, -15.382326326601705, 0.0, 0.0, 140.0, 119.95312050919202, 40.0, 0.0, 40.0, -8.178063256429317, 60.0, 38.7013876899465, 57.07941123085886, -1.9348452955932705, 0.0, -46.310961052496296, -0.2838724695723249, -0.01474428105210257, -10.217996350534438, 0.0, -0.14179048955244133, 0.0, -23.05429501679676, 60.0, -2.2651412372311954, 0.0, 0.0, -20.353046892692884, -23.6725281644642, 40.0, -8.308246247455134, 11.287190535666845, 0.0, 0.0, -13.128389820998283, 60.0, 20.0, 0.0, -2.4338166359618296, -0.9324186823127056, -0.4205164065957845, -33.58782288335044, 120.0, 0.0, -2.0020697890611787, 100.0, 19.00299351879989, 0.0, 60.0, -4.54559133805721, 0.0, 60.0, 0.0, 20.0, 40.0, 60.0, 40.0, 60.0, 0.0, 0.0, -5.0239047360162505, 0.0, 91.26490644270893, -0.5217490924308787, 60.0, 0.0, 20.0, 0.0, 0.0, 0.0, -18.525283495404064, 140.0, 0.0, -14.360189742209432, -16.104856196259327, 60.0, 0.0, -29.4214877445077, 0.0, 79.23380531731806, -32.62680455014406, 88.29071979143386, -0.35252195268035025, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -3.0978370723738435, 0.0, 20.0, -0.9321400538356417, 60.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.22407887011656968, -11.091901722797765, 0.0, 60.0, -0.11102719968982933, 20.0, 40.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -7.63137361598988, 0.0, -25.58180876160542, -34.16253244387248, -10.216676105375935, -40.0, 0.0, -21.14325977828922, -17.37465226278778, 0.0, -21.293035546441963, -20.0, -19.482662968420705, -10.0, -30.0, -1.6536892008078685, 0.0, -1.2726873472551148, -38.775852899933945, -10.0, 0.0, 0.0, -6.67836004563843, 0.0, 0.0, -3.608874953662621, -30.0, -0.619551828063224, -20.27061696910635, -5.291860827767475, 0.0, -1.1358397595509184, -13.647085455106474, -12.601736369222287, -39.37236952351117, -0.897066451497438, -39.749375865312906, 0.0, -1.4398314089778796, 0.0, -30.0, -0.14927883757782423, -15.382326326601705, 0.0, 0.0, -70.0, -60.04687949080799, -20.0, 0.0, -20.0, -8.178063256429317, -30.0, -21.2986123100535, -32.92058876914114, -1.9348452955932705, 0.0, -46.310961052496296, -0.2838724695723249, -0.01474428105210257, -10.217996350534438, 0.0, -0.14179048955244133, 0.0, -23.05429501679676, -30.0, -2.2651412372311954, 0.0, 0.0, -20.353046892692884, -23.6725281644642, -20.0, -8.308246247455134, -48.712809464333155, 0.0, 0.0, -13.128389820998283, -30.0, -10.0, 0.0, -2.4338166359618296, -0.9324186823127056, -0.4205164065957845, -33.58782288335044, -60.0, 0.0, -2.0020697890611787, -50.0, -10.997006481200112, 0.0, -30.0, -4.54559133805721, 0.0, -30.0, 0.0, -10.0, -20.0, -30.0, -20.0, -30.0, 0.0, 0.0, -5.0239047360162505, 0.0, -58.735093557291066, -0.5217490924308787, -30.0, 0.0, -10.0, 0.0, 0.0, 0.0, -18.525283495404064, -70.0, 0.0, -14.360189742209432, -16.104856196259327, -30.0, 0.0, -29.4214877445077, 0.0, -40.766194682681956, -32.62680455014406, -61.70928020856613, -0.35252195268035025, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -3.0978370723738435, 0.0, -10.0, -0.9321400538356417, -30.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.22407887011656968, -11.091901722797765, 0.0, -30.0, -0.11102719968982933, -10.0, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6813586131653092, "mean_inference_ms": 1.1815928729891072, "mean_action_processing_ms": 0.2455764210640603, "mean_env_wait_ms": 0.5100865749509459, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005013412899441189, "StateBufferConnector_ms": 0.0032950850094065945, "ViewRequirementAgentConnector_ms": 0.1015312531415154}, "num_episodes": 153, "episode_return_max": 140.0, "episode_return_min": -46.310961052496296, "episode_return_mean": 13.667981638855386}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 267.1295089824146, "num_env_steps_trained_throughput_per_sec": 267.1295089824146, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 18307.969, "restore_workers_time_ms": 0.014, "training_step_time_ms": 18307.895, "sample_time_ms": 1284.97, "learn_time_ms": 16999.815, "learn_throughput": 235.297, "synch_weights_time_ms": 20.856}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-58-17", "timestamp": 1723139897, "time_this_iter_s": 15.026126146316528, "time_total_s": 1333.421442747116, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf46040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1333.421442747116, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 45.80952380952381, "ram_util_percent": 82.60952380952381}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.287410153200229, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.40794762087365, "policy_loss": -0.02652619593864074, "vf_loss": 3.432399594038725, "vf_explained_var": -0.004222205591698488, "kl": 0.01037114745418973, "entropy": 1.1713698207090297, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 73440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.726858896566621, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.235225347804685, "policy_loss": -0.018039237875871174, "vf_loss": 2.2521609041707737, "vf_explained_var": 9.726336661805497e-07, "kl": 0.005518408162037948, "entropy": 0.5457862300124574, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 215730.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -35.78003337275321, "episode_reward_mean": 18.019742506284903, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -74.9940985422643}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.493827160493828, "agent_policy": -13.461738975196578}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, 100.0, 0.0, 78.65770807583226, 40.0, -0.13952116827671945, 40.0, -11.666170938758645, -1.3375796019676345, 0.0, 0.0, -21.939173394787662, 60.0, -1.246408194531743, 0.0, 80.0, 0.0, 60.0, -0.4649383441650412, 20.0, 60.0, -1.2352450711272533, -7.960794432276919, 20.0, -1.072353044914649, 38.706584403688844, 20.0, -10.270026460641365, 0.0, -5.0431384772525965, 40.0, 40.0, 32.55106908136181, -10.871730328761997, 0.0, -2.8174961037897006, 0.0, 60.0, 0.0, 0.0, -4.1839125389151075, 60.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 40.0, -9.975178484142523, 60.0, 0.0, 0.0, 80.0, 20.0, 0.0, 0.0, 0.0, 60.0, 0.0, -0.8835532915821509, -2.223091398425206, -2.334647459278904, 0.0, 60.0, 40.0, 40.0, 40.0, -2.192604875254407, 20.0, 35.07877858815529, 20.0, -1.0749633403209313, -3.0540820171503, 0.0, 40.0, -6.9439118785391045, -2.8976255959999473, 60.0, 0.0, 40.0, -6.310362440808598, -4.24520225521915, 35.08612424462369, 0.0, 0.0, -1.1180416073690858, 80.0, -4.193251635345865, 0.0, -26.632767738472747, 36.77912649669295, 80.0, 53.45411792727154, -2.5264598667099483, 0.0, 59.632617537692795, -9.202837296943251, -1.2176134536421679, 0.0, -2.7560377897197634, 58.95319405575726, 0.0, -16.223490450800384, 0.0, 0.0, -6.793258497850779, 0.0, 59.7566586906004, 0.0, -10.799791348458136, -1.1687105090619099, 0.0, 140.0, -1.5608586464503427, 0.0, -0.26801974474887413, 0.0, 38.92905224379162, -4.28822884468044, -2.1895382969739687, 0.0, -2.670719900202382, 0.0, 13.836708642886318, 58.87690109211525, -35.78003337275321, 20.0, -10.167147984499682, -0.18008175590995656, -22.493821507166633, 40.0, 20.0, 0.0, 0.0, -16.01922533982324, 60.0, 140.0, -25.29255861744148, 80.0, 0.0, -11.995550025505334, 59.72249560338643, -0.4528569690771478, -1.7387573317967775, 100.0, -30.639006439457802, -3.9210379571149288, 0.0, 116.70587615547097, 120.0, 60.0, 105.0059014577357, 38.89369857548323, 0.0, -6.024395071757233, -12.889884510713916, 0.0, 0.0, 39.32438415699736, 0.0, -7.165017364053794], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-40.0, -50.0, 0.0, -41.342291924167746, -20.0, -0.13952116827671945, -20.0, -11.666170938758645, -1.3375796019676345, 0.0, 0.0, -21.939173394787662, -30.0, -1.246408194531743, 0.0, -40.0, 0.0, -30.0, -0.4649383441650412, -10.0, -30.0, -1.2352450711272533, -7.960794432276919, -10.0, -1.072353044914649, -21.293415596311156, -10.0, -10.270026460641365, 0.0, -5.0431384772525965, -20.0, -20.0, -27.4489309186382, -10.871730328761997, 0.0, -2.8174961037897006, 0.0, -30.0, 0.0, 0.0, -4.1839125389151075, -30.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -20.0, -9.975178484142523, -30.0, 0.0, 0.0, -40.0, -10.0, 0.0, 0.0, 0.0, -30.0, 0.0, -0.8835532915821509, -2.223091398425206, -2.334647459278904, 0.0, -30.0, -20.0, -20.0, -20.0, -2.192604875254407, -10.0, -24.921221411844716, -10.0, -1.0749633403209313, -3.0540820171503, 0.0, -20.0, -6.9439118785391045, -2.8976255959999473, -30.0, 0.0, -20.0, -6.310362440808598, -4.24520225521915, -24.913875755376317, 0.0, 0.0, -1.1180416073690858, -40.0, -4.193251635345865, 0.0, -26.632767738472747, -23.220873503307043, -40.0, -36.54588207272846, -2.5264598667099483, 0.0, -30.367382462307205, -9.202837296943251, -1.2176134536421679, 0.0, -2.7560377897197634, -31.04680594424274, 0.0, -16.223490450800384, 0.0, 0.0, -6.793258497850779, 0.0, -30.243341309399604, 0.0, -10.799791348458136, -1.1687105090619099, 0.0, -70.0, -1.5608586464503427, 0.0, -0.26801974474887413, 0.0, -21.070947756208383, -4.28822884468044, -2.1895382969739687, 0.0, -2.670719900202382, 0.0, -46.16329135711368, -31.123098907884756, -35.78003337275321, -10.0, -10.167147984499682, -0.18008175590995656, -22.493821507166633, -20.0, -10.0, 0.0, 0.0, -16.01922533982324, -30.0, -70.0, -25.29255861744148, -40.0, 0.0, -11.995550025505334, -30.27750439661357, -0.4528569690771478, -1.7387573317967775, -50.0, -30.639006439457802, -3.9210379571149288, 0.0, -63.294123844529025, -60.0, -30.0, -74.9940985422643, -21.106301424516772, 0.0, -6.024395071757233, -12.889884510713916, 0.0, 0.0, -20.67561584300264, 0.0, -7.165017364053794]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6813664112700241, "mean_inference_ms": 1.1811734223761952, "mean_action_processing_ms": 0.24539075234813343, "mean_env_wait_ms": 0.5099514133597607, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006468281333829149, "StateBufferConnector_ms": 0.003782098675951546, "ViewRequirementAgentConnector_ms": 0.10176065527362588}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -35.78003337275321, "episode_return_mean": 18.019742506284903}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 282.51021907823844, "num_env_steps_trained_throughput_per_sec": 282.51021907823844, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 18443.715, "restore_workers_time_ms": 0.014, "training_step_time_ms": 18443.641, "sample_time_ms": 1294.928, "learn_time_ms": 17125.366, "learn_throughput": 233.572, "synch_weights_time_ms": 21.07}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-58-32", "timestamp": 1723139912, "time_this_iter_s": 14.165788173675537, "time_total_s": 1347.5872309207916, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf469d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1347.5872309207916, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 39.095, "ram_util_percent": 82.10000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2205195892602205, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0962473352750144, "policy_loss": -0.02538288984214887, "vf_loss": 3.119675611828764, "vf_explained_var": 0.04964385659744342, "kl": 0.00977306428614905, "entropy": 1.2093318818757932, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 74400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7097528451829092, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9706840624200537, "policy_loss": -0.018304246362027918, "vf_loss": 1.9878656915316344, "vf_explained_var": -1.304136945846233e-06, "kl": 0.005613092780733059, "entropy": 0.5441318644805158, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 218550.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -28.212621674974745, "episode_reward_mean": 14.973057620822567, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.703703703703704, "agent_policy": -11.138053490288545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.2961808417774814, 40.0, 39.1835068061336, 46.67649926992238, 40.0, 0.0, -5.343842443298777, 0.0, -5.501430156451745, 0.0, -1.0504361595101375, -1.635357589527643, -1.8811074363199953, 60.0, 60.0, 0.0, -0.7103475596657671, -12.977500076072708, 60.0, 0.0, 80.0, 40.0, 60.0, 39.34100511008555, 0.0, 0.0, 100.0, -1.1596426768177037, 0.0, -0.8395036154237612, 0.0, 40.0, 0.0, 40.0, 68.60328256585242, 0.0, -0.6793033812648974, 38.866224765528926, 0.0, 20.0, 4.169105421155718, -1.5578237133423056, 0.0, 25.3651878133418, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 78.20494202306381, -13.139754055003435, 36.2010961179494, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, -3.164279092120424, 140.0, 0.0, -0.2088633676728313, 40.0, 0.0, 37.88388854231017, -8.485631691257373, 0.0, 0.0, 0.0, -8.679720545992492, 30.658491283253376, 38.747167070579664, -3.881749760815106, 0.0, 39.316743477396386, 100.0, 100.0, 56.35340206058755, -9.12449026923953, 60.0, 0.0, -5.514287656767509, 0.0, 57.497060151804064, 40.0, 0.0, 20.0, 0.0, 60.0, 0.0, -0.3234815419143111, 60.0, 42.855307253383465, 40.0, 0.0, -9.269893090390957, 0.0, -7.672393563929753, -1.9083754606580983, -8.468197938556163, 0.0, -15.07032881734542, 0.0, -2.4597612456811757, -7.938150353811193, 60.0, 0.0, 17.749574357635836, -2.150994782624508, -1.7493547374174034, -0.055688186598475964, -3.586696737104287, 0.0, 42.33892404012759, -8.829957894252718, 100.0, 0.0, -0.21552050803361866, -20.955709539555762, -0.09168420304241032, -0.12118881794242697, -7.9288880113037195, 60.0, 0.0, 0.0, 0.0, 40.0, -12.830088563515192, -0.10204934497486384, 0.0, 40.0, -15.217608295773429, 0.0, 59.986782307281615, 0.0, 0.0, 60.0, -28.212621674974745, 0.0, -10.72854868108104, 0.0, 0.0, 60.0, -1.147386484253471, 40.0, 0.0, 0.0, -15.112971685286462, -2.537675625783196, -1.685362931658655, 20.0, 0.0, -2.1610250583324415], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.2961808417774814, -20.0, -20.8164931938664, -43.323500730077605, -20.0, 0.0, -5.343842443298777, 0.0, -5.501430156451745, 0.0, -1.0504361595101375, -1.635357589527643, -1.8811074363199953, -30.0, -30.0, 0.0, -0.7103475596657671, -12.977500076072708, -30.0, 0.0, -40.0, -20.0, -30.0, -20.65899488991445, 0.0, 0.0, -50.0, -1.1596426768177037, 0.0, -0.8395036154237612, 0.0, -20.0, 0.0, -20.0, -51.39671743414756, 0.0, -0.6793033812648974, -21.133775234471084, 0.0, -10.0, -25.830894578844283, -1.5578237133423056, 0.0, -34.6348121866582, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -41.795057976936185, -13.139754055003435, -23.798903882050595, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -3.164279092120424, -70.0, 0.0, -0.2088633676728313, -20.0, 0.0, -22.116111457689833, -8.485631691257373, 0.0, 0.0, 0.0, -8.679720545992492, -29.341508716746624, -21.25283292942034, -3.881749760815106, 0.0, -20.683256522603614, -50.0, -50.0, -33.64659793941245, -9.12449026923953, -30.0, 0.0, -5.514287656767509, 0.0, -32.502939848195936, -20.0, 0.0, -10.0, 0.0, -30.0, 0.0, -0.3234815419143111, -30.0, -47.14469274661653, -20.0, 0.0, -9.269893090390957, 0.0, -7.672393563929753, -1.9083754606580983, -8.468197938556163, 0.0, -15.07032881734542, 0.0, -2.4597612456811757, -7.938150353811193, -30.0, 0.0, -12.250425642364162, -2.150994782624508, -1.7493547374174034, -0.055688186598475964, -3.586696737104287, 0.0, -47.66107595987241, -8.829957894252718, -50.0, 0.0, -0.21552050803361866, -20.955709539555762, -0.09168420304241032, -0.12118881794242697, -7.9288880113037195, -30.0, 0.0, 0.0, 0.0, -20.0, -12.830088563515192, -0.10204934497486384, 0.0, -20.0, -15.217608295773429, 0.0, -30.01321769271838, 0.0, 0.0, -30.0, -28.212621674974745, 0.0, -10.72854868108104, 0.0, 0.0, -30.0, -1.147386484253471, -20.0, 0.0, 0.0, -15.112971685286462, -2.537675625783196, -1.685362931658655, -10.0, 0.0, -2.1610250583324415]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6807347837310925, "mean_inference_ms": 1.1799925348656952, "mean_action_processing_ms": 0.24511564510587655, "mean_env_wait_ms": 0.5096268861253934, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004888316731394073, "StateBufferConnector_ms": 0.0033831890718436534, "ViewRequirementAgentConnector_ms": 0.09497256926548334}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -28.212621674974745, "episode_return_mean": 14.973057620822567}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 264.466636915801, "num_env_steps_trained_throughput_per_sec": 264.466636915801, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 17982.167, "restore_workers_time_ms": 0.015, "training_step_time_ms": 17982.083, "sample_time_ms": 1300.255, "learn_time_ms": 16657.423, "learn_throughput": 240.133, "synch_weights_time_ms": 21.63}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-58-47", "timestamp": 1723139927, "time_this_iter_s": 15.174820184707642, "time_total_s": 1362.7620511054993, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d4db80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1362.7620511054993, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 43.17619047619048, "ram_util_percent": 82.01904761904761}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.343276396766305, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4782497310390075, "policy_loss": -0.023548578686798768, "vf_loss": 3.499615106234948, "vf_explained_var": 0.07383899558335542, "kl": 0.010915960383361104, "entropy": 1.2029843479394913, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 75360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7274805025323063, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.360059810657028, "policy_loss": -0.01890272743354307, "vf_loss": 2.377816563210589, "vf_explained_var": 1.2104181533164165e-06, "kl": 0.005729854782696644, "entropy": 0.5373176334703222, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 221370.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -36.22465267694793, "episode_reward_mean": 17.00559009097335, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.061728395061728, "agent_policy": -13.179595094211832}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -31.25251956381365, 0.0, -0.4119192992264742, 20.0, 40.0, 0.0, 40.0, 0.0, -0.47202172873711645, 0.0, 80.0, 0.0, 35.17448139236511, -7.245387823659637, 0.0, 20.0, 98.63222889565851, -2.5047250434057604, -4.024754972911355, 0.0, 0.0, 140.0, 0.0, 0.0, 40.0, -0.208055287247374, 39.99073972685005, 50.593329204873, 59.821827798668636, 42.89345133615702, 0.0, 0.0, 36.78194386873565, 0.0, -5.461754836156534, 0.0, 20.0, -4.655680984702442, 80.0, 0.0, -1.482400136170745, 0.0, 0.0, -10.215004240118969, 0.0, -3.6907099464223547, 0.0, 0.0, 60.0, -25.215184180087178, 0.0, 56.432890333114635, 0.0, -24.950292796704826, 71.51095915041478, -9.312760567741087, 98.64417620954217, -0.9835054541835464, 36.62152826138682, 40.0, 20.0, 59.13997210877915, 0.0, 0.0, -0.5550049469783358, 0.0, 80.0, 68.27333844254908, 0.0, -0.2662852891853229, 24.468559289860643, 40.0, 20.0, 0.0, 0.0, 20.0, -1.4085546212102995, 0.0, -7.374498714002587, 54.70246494614683, 0.0, -4.3417949415531965, 40.0, 0.0, 80.0, -7.125656129658711, 0.0, 40.0, 20.0, 60.0, -0.39034479631494756, -0.6533341879951293, 40.0, 0.0, -17.905506040188495, -0.07377171629790236, -3.016852572134061, 0.0, 40.0, 18.883850012636625, 20.0, 0.0, 39.916139275535215, 91.80640685384178, 40.0, 57.29273299590455, -36.22465267694793, 68.97607275903123, 0.0, 20.0, 40.0, -2.2395483261075255, -4.447631377130242, 100.0, 34.16120142746568, -3.1343383415471204, 0.0, 0.0, 0.0, 26.841409732425724, 0.0, 12.013946140796689, 0.0, 20.0, 0.0, 0.0, -11.448376349112618, -4.342572317647073, 20.0, 20.0, 36.79198898969229, -22.275347506686465, -2.722240198004104, 0.0, 20.0, 0.0, 20.0, 0.0, 23.71899247417522, 0.0, 15.892486851172908, 0.0, -3.0384359111026926, 0.0, 76.62412895606884, 0.0, 0.0, -13.303861834309275, -11.51625458290799, 100.0, 20.0, 80.0, -0.8932434423866586, 20.0, -15.153762015871179, 0.0, -5.973380134947435, 0.0, 0.0, 10.216273135350571, 100.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0], "policy_agent_policy_reward": [0.0, -31.25251956381365, 0.0, -0.4119192992264742, -10.0, -20.0, 0.0, -20.0, 0.0, -0.47202172873711645, 0.0, -40.0, 0.0, -24.825518607634887, -7.245387823659637, 0.0, -10.0, -51.367771104341486, -2.5047250434057604, -4.024754972911355, 0.0, 0.0, -70.0, 0.0, 0.0, -20.0, -0.208055287247374, -20.009260273149952, -39.406670795127, -30.178172201331364, -47.10654866384298, 0.0, 0.0, -23.218056131264333, 0.0, -5.461754836156534, 0.0, -10.0, -4.655680984702442, -40.0, 0.0, -1.482400136170745, 0.0, 0.0, -10.215004240118969, 0.0, -3.6907099464223547, 0.0, 0.0, -30.0, -25.215184180087178, 0.0, -33.567109666885365, 0.0, -24.950292796704826, -48.48904084958523, -9.312760567741087, -51.35582379045784, -0.9835054541835464, -23.37847173861318, -20.0, -10.0, -30.86002789122085, 0.0, 0.0, -0.5550049469783358, 0.0, -40.0, -51.72666155745089, 0.0, -0.2662852891853229, -35.53144071013936, -20.0, -10.0, 0.0, 0.0, -10.0, -1.4085546212102995, 0.0, -7.374498714002587, -35.29753505385317, 0.0, -4.3417949415531965, -20.0, 0.0, -40.0, -7.125656129658711, 0.0, -20.0, -10.0, -30.0, -0.39034479631494756, -0.6533341879951293, -20.0, 0.0, -17.905506040188495, -0.07377171629790236, -3.016852572134061, 0.0, -20.0, -11.116149987363372, -10.0, 0.0, -20.083860724464785, -58.193593146158214, -20.0, -32.707267004095456, -36.22465267694793, -51.02392724096879, 0.0, -10.0, -20.0, -2.2395483261075255, -4.447631377130242, -50.0, -25.838798572534312, -3.1343383415471204, 0.0, 0.0, 0.0, -33.158590267574276, 0.0, -17.98605385920331, 0.0, -10.0, 0.0, 0.0, -11.448376349112618, -4.342572317647073, -10.0, -10.0, -23.208011010307708, -22.275347506686465, -2.722240198004104, 0.0, -10.0, 0.0, -10.0, 0.0, -36.281007525824776, 0.0, -14.107513148827092, 0.0, -3.0384359111026926, 0.0, -43.37587104393114, 0.0, 0.0, -13.303861834309275, -11.51625458290799, -50.0, -10.0, -40.0, -0.8932434423866586, -10.0, -15.153762015871179, 0.0, -5.973380134947435, 0.0, 0.0, -49.783726864649424, -50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6804874477413506, "mean_inference_ms": 1.1802989678991982, "mean_action_processing_ms": 0.24499795010137457, "mean_env_wait_ms": 0.5096501060830497, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004757554442794235, "StateBufferConnector_ms": 0.004700378135398582, "ViewRequirementAgentConnector_ms": 0.09257970032868562}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -36.22465267694793, "episode_return_mean": 17.00559009097335}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.63708901371456, "num_env_steps_trained_throughput_per_sec": 202.63708901371456, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 18347.991, "restore_workers_time_ms": 0.014, "training_step_time_ms": 18347.905, "sample_time_ms": 1308.753, "learn_time_ms": 17013.227, "learn_throughput": 235.111, "synch_weights_time_ms": 22.759}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-59-07", "timestamp": 1723139947, "time_this_iter_s": 19.767372131347656, "time_total_s": 1382.529423236847, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf4eca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1382.529423236847, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 59.03103448275862, "ram_util_percent": 82.89310344827588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2344858136648935, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.060172668720285, "policy_loss": -0.02721638455550419, "vf_loss": 3.085381730645895, "vf_explained_var": 0.0932447078327338, "kl": 0.010036639590043705, "entropy": 1.1467694179465373, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 76320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6879360389730609, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8261295906829496, "policy_loss": -0.017750595626834093, "vf_loss": 1.842789598094656, "vf_explained_var": 1.6714030123771504e-06, "kl": 0.005452932800834831, "entropy": 0.5378802148057213, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 224190.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 129.15388172412528, "episode_reward_min": -33.00428044492547, "episode_reward_mean": 13.496484035990003, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -92.66998708226446}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.471337579617835, "agent_policy": -11.9175287028635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.04770793242196647, 39.904095308575016, 60.0, 0.0, 0.0, 0.0, 117.59363911445456, 19.978096264762158, -1.1590676513978382, 20.0, 40.0, 60.0, 0.0, 0.0, -1.2348970061524311, -33.00428044492547, 0.0, 0.0, -1.902051822457499, 0.0, -5.742528362393128, 100.0, -4.676464353625103, 0.0, -32.74612119920416, 12.853647242752587, 49.914728552286235, -19.41098422798944, 59.70018864912436, 36.42484377000004, 20.978642151252732, 129.15388172412528, -10.795954742346892, -20.48132895531475, -8.574443302522356, 0.0, 0.0, -12.117967278209663, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, 59.776263560777956, -12.740089096907484, 0.0, 0.0, 0.0, 0.0, 40.0, -27.74832467246122, -0.8394511310341812, 0.0, 0.0, -0.10934938828580987, 0.0, 53.35145749274133, -0.2385084481078359, 0.0, 38.76145150873623, -16.986070331514778, 0.0, 0.0, 16.929151998469393, 0.0, 20.0, -0.43550149985263964, -0.891996201093106, 40.0, 38.83900350311267, 39.98308723707255, 80.0, 25.91878402251571, -29.37315314009565, 0.0, 15.81710098470168, 0.0, 20.0, 40.0, 0.0, 20.0, 40.0, 60.0, 50.37870048845668, -5.196181718260362, 0.0, -0.38299841740858764, 19.301144367308595, -0.03370371826806995, 0.0, 0.0, -0.6020133044330067, -3.448879350538405, -1.8024170801523698, 87.33001291773554, 0.0, -2.502324129945873, 0.0, 60.0, -2.6288394642148494, 0.0, 0.0, 58.76755141376835, 0.0, 0.0, 0.0, 0.0, 20.0, -14.119578240561614, 0.0, 0.0, 5.3408109778244, 22.53636886939925, 40.0, 20.0, 0.0, -1.888750374310978, 0.0, 0.0, -0.18845023353868728, -0.7686952835828931, -8.691216412515216, -7.6662112613695275, 58.59184769416845, 0.0, -19.652766626996076, -2.4300544872510024, 20.0, 0.0, 40.0, 11.322159575635098, -0.9680936613392777, 40.0, -0.18535679618545964, 0.0, 54.12610804848508, 40.0, 60.0, -3.4819258543757474, -14.323128366680422, 0.0, 0.0, 18.645833565254854, 0.0, 0.0, 0.0, 0.0, 0.0, 77.3675405259106, 95.47730102022987, 60.0, -3.8976229289651076], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -0.04770793242196647, -20.095904691424987, -30.0, 0.0, 0.0, 0.0, -62.406360885545425, -10.021903735237842, -1.1590676513978382, -10.0, -20.0, -30.0, 0.0, 0.0, -1.2348970061524311, -33.00428044492547, 0.0, 0.0, -1.902051822457499, 0.0, -5.742528362393128, -50.0, -4.676464353625103, 0.0, -32.74612119920416, -17.146352757247417, -40.08527144771377, -19.41098422798944, -30.299811350875647, -23.575156229999962, -39.02135784874727, -80.84611827587473, -10.795954742346892, -20.48132895531475, -8.574443302522356, 0.0, 0.0, -12.117967278209663, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -30.0, 0.0, -30.223736439222048, -12.740089096907484, 0.0, 0.0, 0.0, 0.0, -20.0, -27.74832467246122, -0.8394511310341812, 0.0, 0.0, -0.10934938828580987, 0.0, -36.64854250725867, -0.2385084481078359, 0.0, -21.238548491263767, -16.986070331514778, 0.0, 0.0, -13.070848001530607, 0.0, -10.0, -0.43550149985263964, -0.891996201093106, -20.0, -21.160996496887332, -20.016912762927447, -40.0, -34.08121597748429, -29.37315314009565, 0.0, -14.182899015298318, 0.0, -10.0, -20.0, 0.0, -10.0, -20.0, -30.0, -39.62129951154332, -5.196181718260362, 0.0, -0.38299841740858764, -10.698855632691407, -0.03370371826806995, 0.0, 0.0, -0.6020133044330067, -3.448879350538405, -1.8024170801523698, -92.66998708226446, 0.0, -2.502324129945873, 0.0, -30.0, -2.6288394642148494, 0.0, 0.0, -31.232448586231634, 0.0, 0.0, 0.0, 0.0, -10.0, -14.119578240561614, 0.0, 0.0, -54.659189022175596, -37.46363113060076, -20.0, -10.0, 0.0, -1.888750374310978, 0.0, 0.0, -0.18845023353868728, -0.7686952835828931, -8.691216412515216, -7.6662112613695275, -31.408152305831543, 0.0, -19.652766626996076, -2.4300544872510024, -10.0, 0.0, -20.0, -18.677840424364902, -0.9680936613392777, -20.0, -0.18535679618545964, 0.0, -35.87389195151492, -20.0, -30.0, -3.4819258543757474, -14.323128366680422, 0.0, 0.0, -11.354166434745146, 0.0, 0.0, 0.0, 0.0, 0.0, -42.632459474089394, -54.52269897977012, -30.0, -3.8976229289651076]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6800495989934717, "mean_inference_ms": 1.17986218813117, "mean_action_processing_ms": 0.24481804376317096, "mean_env_wait_ms": 0.5093737064399025, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00480048975367455, "StateBufferConnector_ms": 0.0033832659387284785, "ViewRequirementAgentConnector_ms": 0.09369250315769463}, "num_episodes": 157, "episode_return_max": 129.15388172412528, "episode_return_min": -33.00428044492547, "episode_return_mean": 13.496484035990003}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 259.87705187074215, "num_env_steps_trained_throughput_per_sec": 259.87705187074215, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 18341.1, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18341.016, "sample_time_ms": 1294.488, "learn_time_ms": 17021.548, "learn_throughput": 234.996, "synch_weights_time_ms": 22.591}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-59-22", "timestamp": 1723139962, "time_this_iter_s": 15.401360988616943, "time_total_s": 1397.9307842254639, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf4e8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1397.9307842254639, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 38.13333333333334, "ram_util_percent": 81.9857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.303261331592997, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.140550835306446, "policy_loss": -0.022294020945264493, "vf_loss": 3.161134782185157, "vf_explained_var": 0.06532513884206613, "kl": 0.008550330339185367, "entropy": 1.1609037188192208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 77280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6917828216937417, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0493884767623656, "policy_loss": -0.019053342968352628, "vf_loss": 2.0672927746958765, "vf_explained_var": 1.9007963491669782e-07, "kl": 0.005745227662228591, "entropy": 0.5392484165358206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 227010.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -17.091417651379096, "episode_reward_mean": 16.153416340180904, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.45372228174188}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.240506329113924, "agent_policy": -11.568102647160869}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.9596576634166185, -13.945591041592284, 40.0, 0.0, 0.0, 79.17705458641991, -8.020940562696325, -1.0676896118353407, 100.0, 0.0, -5.579451531373811, -4.862927989594688, 0.0, 0.0, 35.008800898940244, 0.0, -11.903802387636155, -11.788976349367209, 80.0, 31.831850308077065, 48.73060283959701, 0.0, 80.0, 0.0, -10.0525643977745, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, -3.90279510328184, -8.302050816243927, 0.0, 60.0, 0.0, 60.0, 0.0, -0.38155809539528573, 0.0, 60.0, -6.582729639959286, -0.03613783565154294, 100.0, 60.0, 0.0, -5.442154840628894, 0.0, 139.54627771825812, 55.71932891966324, 140.0, 0.0, 31.654167773813654, 16.05705069144403, 0.0, 0.0, -14.312942681559331, -0.13122740838717784, -0.734404077193922, 0.0, -0.2656432198936187, -10.555254832208611, 0.0, 43.98803899703412, 40.0, -3.8628798630249994, 60.0, -12.63569250020657, -4.25044844935262, -15.493842334260899, 0.0, -5.37294358875999, 0.0, 0.0, 40.0, 100.0, -9.328452986372133, 40.0, 40.0, -2.5536600296376366, -1.2980640774802388, -0.374817650086654, -0.45855490162633017, -0.6319183075391699, 80.0, 0.0, -17.091417651379096, 0.0, 40.0, 37.795934870312635, 0.0, 0.0, -0.9304827606784738, 0.0, 0.0, 0.0, 0.0, 0.0, 30.802008524162716, -10.84466228400834, 20.0, 0.0, -5.579820440382052, -1.9052253689865353, 60.0, 57.64242361743237, 0.0, 100.0, 78.47315706067502, 20.0, 20.0, 0.0, 20.0, 0.0, 0.0, 0.0, 59.78905796662738, -9.414538875494786, -5.87043364989636, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 80.0, -2.119388116663118, 0.0, 0.0, -0.9108353395409119, 40.0, 13.188908194496065, -0.32750616055990833, 0.0, 60.0, 0.0, -2.4775240478902916, 60.0, 39.863497369824074, 40.0, 0.0, 60.0, 4.702795245852181, 20.0, -4.424026890121816, 0.0, 0.0, -2.425187571789529, -6.078508464620005, 20.0, 0.0, 0.0, 40.0, 19.921775431456894, -0.1636168694550333, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-6.9596576634166185, -13.945591041592284, -20.0, 0.0, 0.0, -40.822945413580086, -8.020940562696325, -1.0676896118353407, -50.0, 0.0, -5.579451531373811, -4.862927989594688, 0.0, 0.0, -24.991199101059763, 0.0, -11.903802387636155, -11.788976349367209, -40.0, -28.16814969192293, -41.26939716040299, 0.0, -40.0, 0.0, -10.0525643977745, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -3.90279510328184, -8.302050816243927, 0.0, -30.0, 0.0, -30.0, 0.0, -0.38155809539528573, 0.0, -30.0, -6.582729639959286, -0.03613783565154294, -50.0, -30.0, 0.0, -5.442154840628894, 0.0, -70.45372228174188, -34.28067108033675, -70.0, 0.0, -28.345832226186346, -13.942949308555972, 0.0, 0.0, -14.312942681559331, -0.13122740838717784, -0.734404077193922, 0.0, -0.2656432198936187, -10.555254832208611, 0.0, -46.01196100296588, -20.0, -3.8628798630249994, -30.0, -12.63569250020657, -4.25044844935262, -15.493842334260899, 0.0, -5.37294358875999, 0.0, 0.0, -20.0, -50.0, -9.328452986372133, -20.0, -20.0, -2.5536600296376366, -1.2980640774802388, -0.374817650086654, -0.45855490162633017, -0.6319183075391699, -40.0, 0.0, -17.091417651379096, 0.0, -20.0, -22.204065129687372, 0.0, 0.0, -0.9304827606784738, 0.0, 0.0, 0.0, 0.0, 0.0, -59.197991475837284, -10.84466228400834, -10.0, 0.0, -5.579820440382052, -1.9052253689865353, -30.0, -32.35757638256763, 0.0, -50.0, -41.526842939324986, -10.0, -10.0, 0.0, -10.0, 0.0, 0.0, 0.0, -30.210942033372618, -9.414538875494786, -5.87043364989636, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, -40.0, -2.119388116663118, 0.0, 0.0, -0.9108353395409119, -20.0, -16.811091805503935, -0.32750616055990833, 0.0, -30.0, 0.0, -2.4775240478902916, -30.0, -20.13650263017593, -20.0, 0.0, -30.0, -25.29720475414782, -10.0, -4.424026890121816, 0.0, 0.0, -2.425187571789529, -6.078508464620005, -10.0, 0.0, 0.0, -20.0, -10.078224568543105, -0.1636168694550333, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6802133740456164, "mean_inference_ms": 1.1802420232702666, "mean_action_processing_ms": 0.24469392327872827, "mean_env_wait_ms": 0.5096216133985263, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005720461471171319, "StateBufferConnector_ms": 0.003436622740347174, "ViewRequirementAgentConnector_ms": 0.10797207868551906}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -17.091417651379096, "episode_return_mean": 16.153416340180904}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 256.6161238169322, "num_env_steps_trained_throughput_per_sec": 256.6161238169322, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 18160.128, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18160.051, "sample_time_ms": 1298.942, "learn_time_ms": 16835.913, "learn_throughput": 237.587, "synch_weights_time_ms": 22.466}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-59-38", "timestamp": 1723139978, "time_this_iter_s": 15.687708377838135, "time_total_s": 1413.618492603302, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d4d160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1413.618492603302, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 39.8304347826087, "ram_util_percent": 81.79130434782608}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.253924573088686, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2265410953511795, "policy_loss": -0.022336914681848914, "vf_loss": 3.2469917587935924, "vf_explained_var": 0.0686175779129068, "kl": 0.009431237146399004, "entropy": 1.1446812103192012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 78240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6278360090357192, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0356031964856682, "policy_loss": -0.018192968494382667, "vf_loss": 2.052545064687729, "vf_explained_var": -2.3643175760904949e-07, "kl": 0.006255489895475903, "entropy": 0.529856649315949, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 229830.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 173.60108949117364, "episode_reward_min": -29.34132558372735, "episode_reward_mean": 17.547605398142146, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -96.39891050882638}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.37037037037037, "agent_policy": -13.563505712968963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [75.57627078510481, -21.585332449891002, 0.0, -1.546462280137605, -6.975662901488861, -0.032689642806364994, -2.455684644094526, 0.0, -1.2056664932089178, 60.0, 60.0, 20.0, 0.0, 0.0, 10.93933542153608, 53.19613748175162, 0.0, -0.7143818590711615, 40.0, 0.0, 0.0, 0.0, 52.69900959770217, 119.77932433491515, 20.0, 80.0, -1.7117268311621803, 0.0, -1.8975750585414897, -2.2336846581386007, 0.0, 0.0, -0.2529589041035185, -1.0420290641770713, 0.0, -10.994670395001116, 0.0, 60.0, -11.446483273564676, -0.6858406954710783, 0.0, 40.0, -29.34132558372735, 19.999479588302982, 39.48112936508759, -3.564919957995542, 79.87964132667625, -27.554001046906063, 0.0, 58.05802484799448, 0.0, 0.0, 80.0, 0.0, -5.620470603655518, 59.99368614145866, -17.944242265885897, 0.0, 20.0, -0.3873153668033358, 42.30874635202109, 0.0, 60.0, 0.0, 80.0, -6.333666291775099, 49.18069039775902, 0.0, -1.4132183876465298, 0.0, 48.39996201597944, 0.0, -9.572092896320843, 0.0, 0.0, -1.5282704309046014, 0.0, 60.0, -18.14816074058946, -1.6294108628693904, -0.3062541321533929, 33.46435049189778, 20.0, 40.0, -8.210147246331697, 60.0, 20.0, 0.0, 109.45574270534568, 20.0, 0.0, 0.0, 60.0, 0.0, 0.0, -20.48360709420502, 55.58419756950544, 0.0, 0.0, 100.0, 0.0, -0.20800088742753853, 34.8505211455574, -0.49976925153059626, 0.0, 0.0, -3.879511929493965, 0.0, 140.0, -0.1165335765737241, 39.59447483346453, 0.0, 0.0, 24.887977563149306, 0.0, 40.0, -18.89462409760916, -5.565898874801413, 0.0, -0.8083421641589472, 60.0, 37.05864962246618, 0.0, 173.60108949117364, 0.0, -0.20300247725726916, 20.0, 0.0, -4.583974774447355, 80.0, 40.0, 100.0, -14.387443717664137, 0.0, 0.0, 0.0, 0.0, 60.0, -7.900676801169457, 59.80705046711955, 39.045872986368714, -3.5483195483536023, 20.0, 0.0, 0.0, 40.0, 4.591450943986612, 0.0, 0.0, 0.0, 0.0, 0.0, 50.288387507476166, 20.0, 60.0, 58.92974787172169, -0.0833699850811831, 14.883746391449696, 0.0, -2.78964237644941, -2.0425153027103784, -0.49304492458773663], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-44.42372921489519, -21.585332449891002, 0.0, -1.546462280137605, -6.975662901488861, -0.032689642806364994, -2.455684644094526, 0.0, -1.2056664932089178, -30.0, -30.0, -10.0, 0.0, 0.0, -19.06066457846392, -36.80386251824837, 0.0, -0.7143818590711615, -20.0, 0.0, 0.0, 0.0, -67.30099040229783, -60.220675665084855, -10.0, -40.0, -1.7117268311621803, 0.0, -1.8975750585414897, -2.2336846581386007, 0.0, 0.0, -0.2529589041035185, -1.0420290641770713, 0.0, -10.994670395001116, 0.0, -30.0, -11.446483273564676, -0.6858406954710783, 0.0, -20.0, -29.34132558372735, -40.00052041169702, -20.518870634912414, -3.564919957995542, -40.12035867332376, -27.554001046906063, 0.0, -31.94197515200552, 0.0, 0.0, -40.0, 0.0, -5.620470603655518, -30.006313858541343, -17.944242265885897, 0.0, -10.0, -0.3873153668033358, -47.691253647978904, 0.0, -30.0, 0.0, -40.0, -6.333666291775099, -40.81930960224098, 0.0, -1.4132183876465298, 0.0, -41.600037984020574, 0.0, -9.572092896320843, 0.0, 0.0, -1.5282704309046014, 0.0, -30.0, -18.14816074058946, -1.6294108628693904, -0.3062541321533929, -26.535649508102217, -10.0, -20.0, -8.210147246331697, -30.0, -10.0, 0.0, -70.54425729465433, -10.0, 0.0, 0.0, -30.0, 0.0, 0.0, -20.48360709420502, -34.415802430494566, 0.0, 0.0, -50.0, 0.0, -0.20800088742753853, -25.149478854442602, -0.49976925153059626, 0.0, 0.0, -3.879511929493965, 0.0, -70.0, -0.1165335765737241, -20.40552516653547, 0.0, 0.0, -35.11202243685069, 0.0, -20.0, -18.89462409760916, -5.565898874801413, 0.0, -0.8083421641589472, -30.0, -52.94135037753382, 0.0, -96.39891050882638, 0.0, -0.20300247725726916, -10.0, 0.0, -4.583974774447355, -40.0, -20.0, -50.0, -14.387443717664137, 0.0, 0.0, 0.0, 0.0, -30.0, -7.900676801169457, -30.19294953288045, -20.954127013631286, -3.5483195483536023, -10.0, 0.0, 0.0, -20.0, -25.40854905601339, 0.0, 0.0, 0.0, 0.0, 0.0, -39.71161249252383, -10.0, -30.0, -31.070252128278312, -0.0833699850811831, -45.116253608550295, 0.0, -2.78964237644941, -2.0425153027103784, -0.49304492458773663]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6805411837687189, "mean_inference_ms": 1.180448353002124, "mean_action_processing_ms": 0.2446161079106231, "mean_env_wait_ms": 0.5098504663174805, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005164116988947362, "StateBufferConnector_ms": 0.003396802478366428, "ViewRequirementAgentConnector_ms": 0.0977388870568923}, "num_episodes": 162, "episode_return_max": 173.60108949117364, "episode_return_min": -29.34132558372735, "episode_return_mean": 17.547605398142146}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 275.0154717775009, "num_env_steps_trained_throughput_per_sec": 275.0154717775009, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 17308.312, "restore_workers_time_ms": 0.013, "training_step_time_ms": 17308.241, "sample_time_ms": 1263.33, "learn_time_ms": 16019.3, "learn_throughput": 249.699, "synch_weights_time_ms": 22.176}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "a5fdb_00000", "date": "2024-08-08_13-59-52", "timestamp": 1723139992, "time_this_iter_s": 14.595164060592651, "time_total_s": 1428.2136566638947, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d4daf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1428.2136566638947, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 41.96, "ram_util_percent": 81.68}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.250075095395247, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.172481624223292, "policy_loss": -0.0211766326414363, "vf_loss": 3.1920277314881482, "vf_explained_var": 0.07248815447092057, "kl": 0.008152652783763375, "entropy": 1.155568817257881, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 79200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.717026205762481, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.116056499582656, "policy_loss": -0.01987517608877879, "vf_loss": 2.1347055997408875, "vf_explained_var": 6.078194219169887e-07, "kl": 0.006130373058300443, "entropy": 0.5247412538486169, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 232650.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 114.56978784691643, "episode_reward_min": -27.605433381888542, "episode_reward_mean": 15.25393126249941, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -65.43021215308356}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.703703703703704, "agent_policy": -10.857179848611699}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -11.427199422086098, 0.0, -1.820809505866, 0.0, -14.362860464941573, 20.0, 20.0, 16.281814646824284, 39.31194808695876, 17.927231208349685, 0.0, 59.613151034595724, -1.2783924538046487, 19.901114720580097, 100.0, 55.884620474502, 20.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, -27.605433381888542, 0.0, 20.0, 0.0, 0.0, 60.0, 0.0, -11.412870224893902, 0.0, 60.0, 37.41175398215175, 0.0, 40.0, 99.61396204820178, -1.0174345525248452, 20.0, -0.2289868240223103, 31.76461723764462, 0.0, 0.0, 0.0, -3.8315512949988237, -0.059335647991990426, 40.0, 0.0, 20.0, 0.0, 19.682553215973318, -0.03265037671156379, 0.0, -10.618645579083633, 79.6406135190315, 95.71647054260374, -4.359615549542612, 0.0, 20.0, 44.58213628323103, 114.56978784691643, -5.095397213139924, 0.0, 0.0, -0.1358376350218815, -0.02930869845592432, -0.6078731469480148, 60.0, 20.0, 25.519365195531524, 0.0, 40.0, 0.0, 100.0, 0.0, 0.0, 13.205396027926312, -0.11145803799168186, 40.0, 0.0, 0.0, 33.57064285484345, 20.0, 60.0, -0.231506459017925, 0.0, -6.308213055404743, 0.0, 0.0, -14.36222523742118, 0.0, 0.0, 0.0, 40.0, 0.0, 48.5216331491812, 0.0, 0.0, 59.84027188540398, 0.0, 20.0, 12.189128623328328, 0.0, 39.511607771104714, 0.0, 0.0, 40.0, 0.0, -0.07976468168271467, 60.0, 40.0, 80.0, -20.764543612818464, 0.0, 40.0, -12.042296799543015, -0.695110177397219, 0.0, 51.74539861626696, 39.60470084929998, 0.0, 58.80400251397294, 0.0, -0.8776803698300939, 88.27818427168435, 20.0, -1.8478966987465684, 40.0, 0.0, 0.0, 0.0, 0.0, -18.89887537160436, 0.0, 40.0, 0.0, 0.0, -5.550125951317902, 0.0, -4.718486325394012, 0.0, 0.0, -0.2224526805320115, 0.0, -9.639428358947882, 57.56188785374874, -6.19127485354867, 0.0, 59.54537746153474, 20.0, 13.76531104319941, 0.0, 0.0, -9.206314979463455, -12.777304691993669, 0.0, 0.0, -0.02949556099004491, 56.05083743588121, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, 0.0, -11.427199422086098, 0.0, -1.820809505866, 0.0, -14.362860464941573, -10.0, -10.0, -13.718185353175716, -20.688051913041242, -12.072768791650315, 0.0, -30.38684896540428, -1.2783924538046487, -10.098885279419903, -50.0, -34.115379525498, -10.0, 0.0, 0.0, 0.0, 0.0, -10.0, -10.0, -27.605433381888542, 0.0, -10.0, 0.0, 0.0, -30.0, 0.0, -11.412870224893902, 0.0, -30.0, -22.588246017848256, 0.0, -20.0, -50.38603795179822, -1.0174345525248452, -10.0, -0.2289868240223103, -28.235382762355385, 0.0, 0.0, 0.0, -3.8315512949988237, -0.059335647991990426, -20.0, 0.0, -10.0, 0.0, -10.317446784026682, -0.03265037671156379, 0.0, -10.618645579083633, -40.35938648096849, -54.28352945739626, -4.359615549542612, 0.0, -10.0, -45.41786371676897, -65.43021215308356, -5.095397213139924, 0.0, 0.0, -0.1358376350218815, -0.02930869845592432, -0.6078731469480148, -30.0, -10.0, -34.48063480446848, 0.0, -20.0, 0.0, -50.0, 0.0, 0.0, -16.794603972073688, -0.11145803799168186, -20.0, 0.0, 0.0, -26.42935714515654, -10.0, -30.0, -0.231506459017925, 0.0, -6.308213055404743, 0.0, 0.0, -14.36222523742118, 0.0, 0.0, 0.0, -20.0, 0.0, -41.47836685081881, 0.0, 0.0, -30.159728114596014, 0.0, -10.0, -17.810871376671674, 0.0, -20.488392228895286, 0.0, 0.0, -20.0, 0.0, -0.07976468168271467, -30.0, -20.0, -40.0, -20.764543612818464, 0.0, -20.0, -12.042296799543015, -0.695110177397219, 0.0, -38.254601383733046, -20.395299150700023, 0.0, -31.19599748602707, 0.0, -0.8776803698300939, -61.72181572831565, -10.0, -1.8478966987465684, -20.0, 0.0, 0.0, 0.0, 0.0, -18.89887537160436, 0.0, -20.0, 0.0, 0.0, -5.550125951317902, 0.0, -4.718486325394012, 0.0, 0.0, -0.2224526805320115, 0.0, -9.639428358947882, -32.438112146251264, -6.19127485354867, 0.0, -30.45462253846525, -10.0, -16.23468895680059, 0.0, 0.0, -9.206314979463455, -12.777304691993669, 0.0, 0.0, -0.02949556099004491, -33.94916256411879, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6801337314197285, "mean_inference_ms": 1.1798864120247239, "mean_action_processing_ms": 0.2443737919015121, "mean_env_wait_ms": 0.5095847056055434, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004564612000076859, "StateBufferConnector_ms": 0.0032746497495674794, "ViewRequirementAgentConnector_ms": 0.09240500720930689}, "num_episodes": 162, "episode_return_max": 114.56978784691643, "episode_return_min": -27.605433381888542, "episode_return_mean": 15.25393126249941}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 223.36177523635044, "num_env_steps_trained_throughput_per_sec": 223.36177523635044, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 17091.703, "restore_workers_time_ms": 0.013, "training_step_time_ms": 17091.633, "sample_time_ms": 1249.618, "learn_time_ms": 15816.812, "learn_throughput": 252.895, "synch_weights_time_ms": 21.94}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-00-10", "timestamp": 1723140010, "time_this_iter_s": 17.92132306098938, "time_total_s": 1446.134979724884, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d60b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1446.134979724884, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 55.32692307692308, "ram_util_percent": 82.57692307692308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3300682875017324, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.08298048650225, "policy_loss": -0.02237391927386246, "vf_loss": 3.103274770701925, "vf_explained_var": 0.0646921166529258, "kl": 0.010398156623930772, "entropy": 1.1348278850317002, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 80160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6650542186507097, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0163985381312406, "policy_loss": -0.017075467207766277, "vf_loss": 2.032422798280175, "vf_explained_var": -7.736133345475434e-07, "kl": 0.005256025098177123, "entropy": 0.49697482134644866, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 235470.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -28.73271850818728, "episode_reward_mean": 14.87480112638721, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.662420382165605, "agent_policy": -11.112460020109607}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.7621255977225272, 58.594433357865135, -0.041961200428417555, 59.66845883978084, -9.23685304428454, 0.0, 40.0, -3.8532808420892364, 0.0, -21.157850034710005, 0.0, 0.0, 93.06686899822887, -0.03902513352949111, 0.0, -0.6468455151099983, 17.29441584662074, 18.50891869881594, -1.4727606523116732, 0.0, -9.435647852655869, 0.0, 40.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.2568272564638516, 0.0, 60.0, 0.0, 0.0, -2.169793772174444, -0.28250670709094816, 0.0, 0.0, 0.0, -28.73271850818728, 0.0, -1.9493739481898964, 0.0, 0.0, 0.0, 20.0, 0.0, -1.5235963211733394, 0.0, -0.005798106432751693, 0.0, -1.955083841450369, 0.0, 0.0, 60.0, -1.5672292542368438, 13.78057138805197, 0.0, 100.0, -3.489927729212351, -7.202042216115888, 20.0, 0.0, 0.0, 80.0, 0.0, -3.933087250748228, 0.0, -6.074114354810676, 0.0, -3.111692322053925, -6.603061439709148, 0.0, 0.0, 0.0, 19.354261748284223, -6.479941967118488, -12.118142937851841, 54.96860239396403, 0.0, 54.16041564046465, 0.0, 86.12435935887785, 36.1537558595324, 0.0, 20.0, 80.0, -0.11566839470656065, 0.0, 39.6270425965437, 0.0, 40.0, -0.9717633192236186, 0.0, -6.577767437375704, 20.0, 79.37326324506189, 40.0, -17.581677134708094, 40.0, 0.0, 0.0, -14.330193580457648, 17.659879722373837, 180.0, 0.0, -5.6107701999765105, 60.0, 79.16706558672335, 7.072408793037475, 0.0, -4.260826110766634, 28.606072308047708, -1.128458498223326, -15.136360688530381, 40.0, 0.0, 100.0, 0.0, 100.0, 0.0, 19.3298012899172, 40.0, 40.0, 35.63653987447219, -1.1186494388159995, -1.4083989515234796, -1.5343620885077414, 0.0, 140.0, 0.0, 14.17461834305194, -3.37487653511301, 20.0, -14.149423771689191, -21.52427321453336, 20.0, 0.0, 40.0, 0.0, -12.869777062548998, 0.0, 0.0, 0.0, 0.0, 80.0, 19.575139945430422, 57.456909273590526, 0.0, 19.64304083804143, 49.24057042651426, 20.0, 0.0, 60.0, -0.6728017974237299, -5.42630150051436], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.7621255977225272, -31.405566642134865, -0.041961200428417555, -30.331541160219164, -9.23685304428454, 0.0, -20.0, -3.8532808420892364, 0.0, -21.157850034710005, 0.0, 0.0, -56.93313100177113, -0.03902513352949111, 0.0, -0.6468455151099983, -12.70558415337926, -11.491081301184062, -1.4727606523116732, 0.0, -9.435647852655869, 0.0, -20.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.2568272564638516, 0.0, -30.0, 0.0, 0.0, -2.169793772174444, -0.28250670709094816, 0.0, 0.0, 0.0, -28.73271850818728, 0.0, -1.9493739481898964, 0.0, 0.0, 0.0, -10.0, 0.0, -1.5235963211733394, 0.0, -0.005798106432751693, 0.0, -1.955083841450369, 0.0, 0.0, -30.0, -1.5672292542368438, -16.219428611948025, 0.0, -50.0, -3.489927729212351, -7.202042216115888, -10.0, 0.0, 0.0, -40.0, 0.0, -3.933087250748228, 0.0, -6.074114354810676, 0.0, -3.111692322053925, -6.603061439709148, 0.0, 0.0, 0.0, -10.645738251715773, -6.479941967118488, -12.118142937851841, -35.03139760603597, 0.0, -35.83958435953535, 0.0, -63.875640641122175, -23.846244140467597, 0.0, -10.0, -40.0, -0.11566839470656065, 0.0, -20.372957403456294, 0.0, -20.0, -0.9717633192236186, 0.0, -6.577767437375704, -10.0, -40.626736754938115, -20.0, -17.581677134708094, -20.0, 0.0, 0.0, -14.330193580457648, -12.340120277626168, -90.0, 0.0, -5.6107701999765105, -30.0, -40.832934413276654, -22.927591206962525, 0.0, -4.260826110766634, -61.393927691952285, -1.128458498223326, -15.136360688530381, -20.0, 0.0, -50.0, 0.0, -50.0, 0.0, -10.6701987100828, -20.0, -20.0, -24.363460125527805, -1.1186494388159995, -1.4083989515234796, -1.5343620885077414, 0.0, -70.0, 0.0, -15.82538165694806, -3.37487653511301, -10.0, -14.149423771689191, -21.52427321453336, -10.0, 0.0, -20.0, 0.0, -12.869777062548998, 0.0, 0.0, 0.0, 0.0, -40.0, -10.42486005456958, -32.543090726409474, 0.0, -10.356959161958573, -40.75942957348574, -10.0, 0.0, -30.0, -0.6728017974237299, -5.42630150051436]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6804896775123079, "mean_inference_ms": 1.1808607059565142, "mean_action_processing_ms": 0.2444994226952762, "mean_env_wait_ms": 0.5098992550249908, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004753109755789398, "StateBufferConnector_ms": 0.0037825790939817003, "ViewRequirementAgentConnector_ms": 0.10534221199667378}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -28.73271850818728, "episode_return_mean": 14.87480112638721}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 219.75915194310002, "num_env_steps_trained_throughput_per_sec": 219.75915194310002, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 16890.006, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16889.924, "sample_time_ms": 1243.519, "learn_time_ms": 15620.879, "learn_throughput": 256.068, "synch_weights_time_ms": 22.248}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-00-29", "timestamp": 1723140029, "time_this_iter_s": 18.230751991271973, "time_total_s": 1464.365731716156, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d4d8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1464.365731716156, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 56.72692307692307, "ram_util_percent": 82.23076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2563536910961073, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0844819540778796, "policy_loss": -0.022339464495598805, "vf_loss": 3.1052103281021117, "vf_explained_var": 0.023357328275839487, "kl": 0.008055450441125494, "entropy": 1.1593593054761488, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 81120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7292146896745296, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.302017525493676, "policy_loss": -0.01892015733896484, "vf_loss": 2.319832298814828, "vf_explained_var": 2.8743388804983587e-07, "kl": 0.005526924370246646, "entropy": 0.5127908241875628, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 238290.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 152.20372316104172, "episode_reward_min": -30.812352326800028, "episode_reward_mean": 16.781870639636033, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -87.79627683895825}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.567901234567902, "agent_policy": -11.92183306406767}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.101543219571359, 0.0, 40.0, 99.58057573189785, -12.15372466424894, 0.0, -5.901394711223334, 0.0, 20.0, 60.0, 20.0, 0.0, -4.282036356153805, 152.20372316104172, 0.0, -18.706356432551747, 37.710491649637326, -2.2969070060268093, -1.8994809329563334, 40.0, 0.0, 40.0, 0.0, -1.8549860656111405, 39.544728724117995, 20.0, 0.0, 100.0, 0.0, -0.9340724679264301, -2.2986842945224515, 60.0, 40.0, 0.0, 0.0, 60.0, 40.0, 0.0, 0.0, 60.0, 60.0, -3.5449792987544626, -0.3895307845887064, 31.774634815642514, -6.50130765191695, 60.0, 37.576811436470166, 0.0, 15.140176571590928, -30.812352326800028, -9.897747895426342, 0.0, 60.0, 0.0, -0.03684994754489468, -18.998526507798545, 20.0, 35.55172732323765, 40.0, 60.0, 26.186609721381526, 18.76764483412353, 0.0, 0.0, 40.0, 0.0, 20.0, 40.0, -1.1562926984965582, 0.0, 46.12195305827539, -2.3340434207668803, 0.0, -15.31423836599799, -8.264826879767648, 0.0, 39.46347576566877, 40.0, 0.0, 0.0, 0.0, -0.87435774667871, 0.0, 0.0, 60.0, -3.81520040965234, 40.0, -3.1413198034158745, 37.40690225687603, 20.0, 0.0, -0.2345245014898545, 0.0, 60.0, 0.0, -0.06676246527051899, -0.40223160035611993, -3.902324225920763, 0.0, 20.0, 0.0, 0.0, 60.0, 120.0, 39.556356260390565, 0.0, 0.0, 40.0, 29.73439358763407, 60.0, 20.324831705876303, -0.41130448081601156, 100.0, -0.0701791131754359, 0.0, -6.38568418816975, -2.5570674844842833, 0.0, 0.0, -4.122608675768855, 0.0, 39.76031190725195, -7.571768379558571, -1.3706448597794096, 2.0701435231191576, 0.0, 0.0, -2.486094538733112, 19.614415524076023, -1.8066359376156993, 60.0, -23.867837096638258, 0.0, 18.604593506560793, 0.0, -0.2696709291803667, 20.0, 0.0, 60.0, 0.0, 60.0, 0.0, -0.3419597483320136, -5.545538250756024, 0.0, 79.12849038457763, 0.0, 18.91448458359144, 60.0, 0.0, 60.0, -0.5034691862378327, 20.0, -1.1101893836669052, 0.0, 36.95743169317677, 80.0, 0.0, 0.0, -0.9869149956640177, -13.847452660001954, -7.660241515164559], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-2.101543219571359, 0.0, -20.0, -50.41942426810214, -12.15372466424894, 0.0, -5.901394711223334, 0.0, -10.0, -30.0, -10.0, 0.0, -4.282036356153805, -87.79627683895825, 0.0, -18.706356432551747, -22.28950835036267, -2.2969070060268093, -1.8994809329563334, -20.0, 0.0, -20.0, 0.0, -1.8549860656111405, -20.455271275882005, -10.0, 0.0, -50.0, 0.0, -0.9340724679264301, -2.2986842945224515, -30.0, -20.0, 0.0, 0.0, -30.0, -20.0, 0.0, 0.0, -30.0, -30.0, -3.5449792987544626, -0.3895307845887064, -28.225365184357486, -6.50130765191695, -30.0, -22.423188563529834, 0.0, -14.859823428409072, -60.812352326800024, -9.897747895426342, 0.0, -30.0, 0.0, -0.03684994754489468, -18.998526507798545, -10.0, -24.448272676762347, -20.0, -30.0, -33.813390278618485, -11.23235516587647, 0.0, 0.0, -20.0, 0.0, -10.0, -20.0, -1.1562926984965582, 0.0, -43.87804694172461, -2.3340434207668803, 0.0, -15.31423836599799, -8.264826879767648, 0.0, -20.53652423433123, -20.0, 0.0, 0.0, 0.0, -0.87435774667871, 0.0, 0.0, -30.0, -3.81520040965234, -20.0, -3.1413198034158745, -22.59309774312397, -10.0, 0.0, -0.2345245014898545, 0.0, -30.0, 0.0, -0.06676246527051899, -0.40223160035611993, -3.902324225920763, 0.0, -10.0, 0.0, 0.0, -30.0, -60.0, -20.443643739609428, 0.0, 0.0, -20.0, -30.265606412365937, -30.0, -39.67516829412371, -0.41130448081601156, -50.0, -0.0701791131754359, 0.0, -6.38568418816975, -2.5570674844842833, 0.0, 0.0, -4.122608675768855, 0.0, -20.239688092748047, -7.571768379558571, -1.3706448597794096, -27.929856476880843, 0.0, 0.0, -2.486094538733112, -10.385584475923977, -1.8066359376156993, -30.0, -23.867837096638258, 0.0, -11.395406493439207, 0.0, -0.2696709291803667, -10.0, 0.0, -30.0, 0.0, -30.0, 0.0, -0.3419597483320136, -5.545538250756024, 0.0, -40.87150961542237, 0.0, -11.085515416408558, -30.0, 0.0, -30.0, -0.5034691862378327, -10.0, -1.1101893836669052, 0.0, -23.042568306823227, -40.0, 0.0, 0.0, -0.9869149956640177, -13.847452660001954, -7.660241515164559]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6812947907452122, "mean_inference_ms": 1.1818986922395898, "mean_action_processing_ms": 0.24458210987793158, "mean_env_wait_ms": 0.5103492870907258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005150209238499771, "StateBufferConnector_ms": 0.003469652599758572, "ViewRequirementAgentConnector_ms": 0.10915862189398871}, "num_episodes": 162, "episode_return_max": 152.20372316104172, "episode_return_min": -30.812352326800028, "episode_return_mean": 16.781870639636033}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 274.1668459205922, "num_env_steps_trained_throughput_per_sec": 274.1668459205922, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 16022.1, "restore_workers_time_ms": 0.015, "training_step_time_ms": 16022.018, "sample_time_ms": 1249.68, "learn_time_ms": 14747.078, "learn_throughput": 271.24, "synch_weights_time_ms": 21.949}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-00-43", "timestamp": 1723140043, "time_this_iter_s": 14.608679056167603, "time_total_s": 1478.9744107723236, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d4df70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1478.9744107723236, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 39.865, "ram_util_percent": 81.41}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.274137687931458, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6063932514439028, "policy_loss": -0.02472721633433442, "vf_loss": 3.6292794808745383, "vf_explained_var": 0.05122211420287689, "kl": 0.009204923434539276, "entropy": 1.143111860131224, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 82080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6438876136820367, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4161225677382014, "policy_loss": -0.017744805511328267, "vf_loss": 2.4326425828409532, "vf_explained_var": 7.386325944400002e-07, "kl": 0.006123966006661788, "entropy": 0.5105949522121578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 241110.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 157.01939624909082, "episode_reward_min": -27.577440458310967, "episode_reward_mean": 16.262045295243215, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -82.98060375090918}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.683544303797468, "agent_policy": -12.788587616149188}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.18374870812297717, 40.0, 32.72320196504403, -6.259372883913555, -6.10783118620451, 100.0, 0.0, -1.5349592614621321, -1.5731548928347872, 80.0, -2.3192786506404848, 20.0, 0.0, 0.0, 0.0, -0.6158614068403878, 40.0, -7.9253584165621405, 60.0, 0.0, 0.0, 52.15709692601262, 44.63125630689232, 15.473444117221213, 80.0, 40.0, -2.6600599703116456, 30.283320484779452, 0.0, -17.303423739354116, -7.171381492800218, -0.23933397456284866, 0.0, -1.748061794137531, 20.0, 37.29791333027426, 39.467416736194004, -7.060125327264299, -0.7712385905462116, 0.0, -3.5838022085926102, -0.09116573591682164, -20.95915402299108, -5.256967600586283, 106.49241579563444, 0.0, -5.2831964299336, 20.0, 33.62728454009307, 59.76883297086856, 39.81066953134027, -13.610272555535085, 40.0, 0.0, 0.0, 0.0, -9.667539684124813, 0.0, 0.0, 0.0, -0.1768312488366186, 0.0, 0.0, -0.6490570464358558, 0.0, 120.0, 40.0, 60.0, -0.4548996854961329, 20.0, -10.751099582542253, 40.0, -5.9681108960821385, 0.0, 19.405807497470256, -1.4063569417632982, 40.0, -19.944341204644786, -0.6270986313509752, -4.054867652330882, 40.0, 20.0, 0.0, 0.0, -1.1208952106833536, 54.35646961162845, 0.0, -0.04380384595042197, -0.499300445863875, 19.924520078572453, -3.79364562626308, -6.037475646515154, 19.989812179323838, 20.0, 40.0, 18.475528873547844, 0.0, 20.0, 60.0, 20.0, 0.0, 157.01939624909082, -8.048925818435045, 60.24180326924649, 0.0, -0.6419653960911798, 0.0, 0.0, -6.137953557325942, -27.577440458310967, 40.0, -3.200129164226598, 0.0, 46.27026060079679, 38.91430201689492, 0.0, 59.96992264611682, -1.8826290207310337, 40.0, -3.553264249629084, 20.0, 51.44361949033914, 0.0, 0.0, -4.249725937688014, 0.0, 20.0, 0.0, 0.0, -14.094054769961048, -2.8157861152497254, 0.0, 0.0, 0.0, 37.66325662910161, -14.656552162244438, 120.0, 40.0, 80.0, 38.0037184956953, 59.70657384332219, 0.0, 0.0, 0.0, 19.00789118567212, 0.0, 0.0, -14.037511848159514, -2.2768593994353035, 0.0, 19.504647598473472, -3.72006714902375, 0.0, -20.18564583278373, -9.57988515506112, 80.0, 79.97561650335732, 71.90862540777766], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-0.18374870812297717, -20.0, -27.276798034955974, -6.259372883913555, -6.10783118620451, -50.0, 0.0, -1.5349592614621321, -1.5731548928347872, -40.0, -2.3192786506404848, -10.0, 0.0, 0.0, 0.0, -30.615861406840388, -20.0, -7.9253584165621405, -30.0, 0.0, 0.0, -37.84290307398738, -45.36874369310768, -14.526555882778789, -40.0, -20.0, -2.6600599703116456, -29.716679515220534, 0.0, -17.303423739354116, -7.171381492800218, -0.23933397456284866, 0.0, -1.748061794137531, -10.0, -22.702086669725738, -20.532583263805996, -7.060125327264299, -0.7712385905462116, 0.0, -3.5838022085926102, -0.09116573591682164, -20.95915402299108, -5.256967600586283, -73.50758420436557, 0.0, -5.2831964299336, -10.0, -26.372715459906928, -30.231167029131445, -20.189330468659737, -13.610272555535085, -20.0, 0.0, 0.0, 0.0, -9.667539684124813, 0.0, 0.0, 0.0, -0.1768312488366186, 0.0, 0.0, -0.6490570464358558, 0.0, -60.0, -20.0, -30.0, -0.4548996854961329, -10.0, -10.751099582542253, -20.0, -5.9681108960821385, 0.0, -10.594192502529744, -1.4063569417632982, -20.0, -19.944341204644786, -0.6270986313509752, -4.054867652330882, -20.0, -10.0, 0.0, 0.0, -1.1208952106833536, -35.64353038837156, 0.0, -0.04380384595042197, -0.499300445863875, -10.075479921427547, -3.79364562626308, -6.037475646515154, -10.010187820676162, -10.0, -20.0, -41.524471126452156, 0.0, -10.0, -30.0, -10.0, 0.0, -82.98060375090918, -8.048925818435045, -59.75819673075351, 0.0, -0.6419653960911798, 0.0, 0.0, -6.137953557325942, -27.577440458310967, -20.0, -3.200129164226598, 0.0, -43.729739399203226, -21.085697983105078, 0.0, -30.030077353883176, -1.8826290207310337, -20.0, -3.553264249629084, -10.0, -38.55638050966086, 0.0, 0.0, -4.249725937688014, 0.0, -10.0, 0.0, 0.0, -14.094054769961048, -2.8157861152497254, 0.0, 0.0, 0.0, -22.336743370898393, -14.656552162244438, -60.0, -20.0, -40.0, -21.996281504304708, -30.293426156677818, 0.0, 0.0, 0.0, -10.992108814327882, 0.0, 0.0, -14.037511848159514, -2.2768593994353035, 0.0, -10.495352401526526, -3.72006714902375, 0.0, -20.18564583278373, -9.57988515506112, -40.0, -40.024383496642685, -48.091374592222344]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6814561426641664, "mean_inference_ms": 1.181886393282472, "mean_action_processing_ms": 0.24450646397168274, "mean_env_wait_ms": 0.5103903353878545, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004774181148673915, "StateBufferConnector_ms": 0.003451938870586926, "ViewRequirementAgentConnector_ms": 0.09833476211451277}, "num_episodes": 158, "episode_return_max": 157.01939624909082, "episode_return_min": -27.577440458310967, "episode_return_mean": 16.262045295243215}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 273.3505793272981, "num_env_steps_trained_throughput_per_sec": 273.3505793272981, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 15988.021, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15987.939, "sample_time_ms": 1237.876, "learn_time_ms": 14725.11, "learn_throughput": 271.645, "synch_weights_time_ms": 21.637}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-00-58", "timestamp": 1723140058, "time_this_iter_s": 14.641280889511108, "time_total_s": 1493.6156916618347, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf46e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1493.6156916618347, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 41.3952380952381, "ram_util_percent": 81.1904761904762}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5274226306627194, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.995777430261175, "policy_loss": -0.028525982531815923, "vf_loss": 3.0222869517902535, "vf_explained_var": 0.12066637842605511, "kl": 0.010082380812024587, "entropy": 1.1312663411100705, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 83040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7164364464211126, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7002359469943014, "policy_loss": -0.0187252756546694, "vf_loss": 1.7178450057269834, "vf_explained_var": -1.5842999126894254e-06, "kl": 0.005581091734136801, "entropy": 0.5187480401591207, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 243930.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 118.1302619419908, "episode_reward_min": -30.742863747821225, "episode_reward_mean": 12.628877050996156, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -63.68328174225836}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.777777777777778, "agent_policy": -10.704456282337178}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.097646129855354, 118.1302619419908, 40.0, -8.730895230922284, 45.880497422181286, -0.21628412806158015, -0.7171149384484532, -0.10454014675343237, 49.395989118178406, 60.0, -0.9761392653727952, 51.10333399854143, 20.0, -13.817957301986068, -1.0538263237083023, -0.8541921229010585, 40.0, 20.0, 0.0, 0.0, -26.871118029702654, -1.9962419935268882, -5.555667520761423, -0.10321225329719019, 0.0, -1.039034440218105, 0.0, -2.4572634550682695, 86.31671825774166, 0.0, 20.0, -0.38979383881158625, 20.0, 0.0, 40.0, 51.75840872366209, 20.0, 0.0, -7.946871872390771, 80.0, 0.0, 40.0, 0.0, -2.4434494792412496, -4.475959029138948, 20.0, 59.49729143935727, -0.3679898987728747, 0.0, 0.0, 53.26164403865643, 37.97229486263439, -3.0103788276711, 20.0, -0.09249527446698047, -5.3768863293428515, -0.5303646828366504, -1.9232198017223912, 0.0, 57.84003681971721, -25.666907638558975, -1.5655649006423655, 18.335854820685487, 0.0, 60.0, -3.7488868043151666, 0.0, -11.368934891705024, -5.553927296108432, 60.0, 0.0, 0.0, -2.4877872751865038, 39.3142290918119, 13.029808057527186, 0.0, -3.8100437021449585, 38.61063608434395, 15.78177112532378, -1.7973084795784855, -9.98635626369127, -30.742863747821225, -8.725193766861405, 0.0, -0.5478587962487103, -9.407739529353215, 0.0, 13.443267036663, 0.0, -0.1558680841519322, -3.658826742388611, 0.0, -22.569439668854326, 96.65734841638847, -11.424728571625717, 60.0, -5.81577281297714, 20.0, -7.6574430366126425, 0.0, 60.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 56.39329546452867, -0.022277781166880617, 0.0, -0.35650919231068556, 77.30192907483944, -4.686362502354811, -3.213177372501849, 0.0, -0.7871375532268887, 20.0, 0.0, 0.0, -0.2924018773831205, 79.8790563423835, -0.2235892263054573, -6.807796766608081, 0.0, 20.0, -4.008480226549083, 0.0, 0.0, 94.43101518737353, 20.0, 20.0, 0.0, 80.0, 0.0, 40.0, 0.0, 0.0, -7.725475352194017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7.6998534839574075, 59.057632823092234, -0.033644651113100554, 0.0, -4.57301233358911, 0.0, 0.0, 49.57420773605661, -4.377869675209056, 20.0, 54.317123021649834, 32.69601478356225, -17.45400110923862, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-4.097646129855354, -61.86973805800922, -20.0, -8.730895230922284, -44.119502577818714, -0.21628412806158015, -0.7171149384484532, -0.10454014675343237, -40.60401088182159, -30.0, -0.9761392653727952, -38.89666600145856, -10.0, -13.817957301986068, -1.0538263237083023, -0.8541921229010585, -20.0, -10.0, 0.0, 0.0, -26.871118029702654, -1.9962419935268882, -5.555667520761423, -0.10321225329719019, 0.0, -1.039034440218105, 0.0, -2.4572634550682695, -63.68328174225836, 0.0, -10.0, -0.38979383881158625, -10.0, 0.0, -20.0, -38.24159127633791, -10.0, 0.0, -7.946871872390771, -40.0, 0.0, -20.0, 0.0, -2.4434494792412496, -4.475959029138948, -10.0, -30.502708560642724, -0.3679898987728747, 0.0, 0.0, -36.73835596134357, -22.027705137365604, -3.0103788276711, -10.0, -0.09249527446698047, -5.3768863293428515, -0.5303646828366504, -1.9232198017223912, 0.0, -32.159963180282794, -25.666907638558975, -1.5655649006423655, -11.664145179314513, 0.0, -30.0, -3.7488868043151666, 0.0, -11.368934891705024, -5.553927296108432, -30.0, 0.0, 0.0, -2.4877872751865038, -20.685770908188097, -16.97019194247282, 0.0, -3.8100437021449585, -21.389363915656048, -14.21822887467622, -1.7973084795784855, -9.98635626369127, -30.742863747821225, -8.725193766861405, 0.0, -0.5478587962487103, -9.407739529353215, 0.0, -46.556732963337, 0.0, -0.1558680841519322, -3.658826742388611, 0.0, -22.569439668854326, -53.342651583611506, -11.424728571625717, -30.0, -5.81577281297714, -10.0, -7.6574430366126425, 0.0, -30.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -33.60670453547133, -0.022277781166880617, 0.0, -0.35650919231068556, -42.698070925160565, -4.686362502354811, -3.213177372501849, 0.0, -0.7871375532268887, -10.0, 0.0, 0.0, -0.2924018773831205, -40.120943657616486, -0.2235892263054573, -6.807796766608081, 0.0, -10.0, -4.008480226549083, 0.0, 0.0, -55.56898481262647, -10.0, -10.0, 0.0, -40.0, 0.0, -20.0, 0.0, 0.0, -7.725475352194017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7.6998534839574075, -30.942367176907773, -0.033644651113100554, 0.0, -4.57301233358911, 0.0, 0.0, -40.42579226394339, -4.377869675209056, -10.0, -35.682876978350166, -27.30398521643775, -17.45400110923862, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6810009673980294, "mean_inference_ms": 1.1812525629081316, "mean_action_processing_ms": 0.24432860677024268, "mean_env_wait_ms": 0.5100990492750834, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0048716127136607225, "StateBufferConnector_ms": 0.0037263205021987726, "ViewRequirementAgentConnector_ms": 0.09479603649657449}, "num_episodes": 162, "episode_return_max": 118.1302619419908, "episode_return_min": -30.742863747821225, "episode_return_mean": 12.628877050996156}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 260.0032832798717, "num_env_steps_trained_throughput_per_sec": 260.0032832798717, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 16110.586, "restore_workers_time_ms": 0.015, "training_step_time_ms": 16110.503, "sample_time_ms": 1241.116, "learn_time_ms": 14844.028, "learn_throughput": 269.469, "synch_weights_time_ms": 22.069}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-01-13", "timestamp": 1723140073, "time_this_iter_s": 15.391627073287964, "time_total_s": 1509.0073187351227, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf46820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1509.0073187351227, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 37.586363636363636, "ram_util_percent": 78.90909090909089}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.419703258325656, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7402877430121104, "policy_loss": -0.024890634711967626, "vf_loss": 3.7633443740506967, "vf_explained_var": 0.061361118343969186, "kl": 0.009170008150481834, "entropy": 1.1492270826051632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6750554890391675, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3325050845213817, "policy_loss": -0.018413449688533864, "vf_loss": 2.3497894502700643, "vf_explained_var": 5.438818153760112e-07, "kl": 0.005645411509594577, "entropy": 0.4912075415782049, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 246750.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -42.67611195311475, "episode_reward_mean": 15.659618625001736, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.617834394904458, "agent_policy": -13.19388455971164}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 20.0, 0.0, -0.5566705195478616, 18.850236230497956, -0.039589045627567154, 40.0, -1.4720919957272534, 0.0, 0.0, 19.47242788686824, -0.6288585952656844, 40.0, 0.0, 40.0, 16.302555532946727, 0.0, 77.40048868956669, 20.0, 59.394002350107044, -9.057843578750632, 6.179742851043358, 0.0, 55.27350483228965, 0.0, 37.13989801244237, 0.0, -0.7316213251888681, -1.978738791227449, 0.0, -9.37091499127749, 20.0, -38.209134684659396, 60.0, 23.04344668154717, -3.82961507433005, 60.0, 20.0, 0.0, 40.0, 60.0, -2.9443648101268414, 0.0, 29.748545092201567, -7.094198570464459, 0.0, -42.67611195311475, 0.0, 57.49531791127554, 0.0, 0.0, -1.7644138752481187, 20.0, 60.0, -0.3035222329198217, 55.677260836312946, 120.0, -8.214730044371919, -0.5710860158804798, 39.699490072695646, 0.0, 80.0, 40.0, 0.0, 40.0, 18.17249577006616, 0.0, -2.4425093233023443, 60.0, -10.774277278895854, -6.713762301452589, 0.0, 0.0, -4.587522687832648, 40.0, 20.0, 40.0, 0.0, -3.349009384011376, -6.662556597857238, 79.32154682915467, 40.0, 60.0, 0.0, -7.102277739354897, 0.0, 37.94257643429599, 57.64076308022916, 20.0, 180.0, 55.35630956262621, 58.8938977212745, 20.0, -0.5277101684871144, -1.173722320451247, 0.0, -1.1079957711142674, 0.0, -4.770203946418107, -18.769111027653747, -7.884875969712407, -5.626916963963672, -0.4995350417034383, 48.94352518516556, 14.6021256883922, 5.85145081346685, -0.469315246028118, -0.1808041665092075, 40.0, -1.0654007163789725, 0.0, 36.42012182596643, 0.0, 60.0, 0.0, -1.9618519416226055, 77.75378439323391, -13.115755146560977, -2.378345091089641, 20.0, 0.0, -16.035203389222634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.896576921773928, 60.0, 20.0, 40.0, 0.0, 0.0, -13.098265727514207, -8.232984565227722, 36.24637557666542, -16.56434802244335, 0.0, -1.207798434519315, -0.9713597127474416, 60.0, 0.0, 60.0, -13.272910298480678, 31.182718557353112, 0.0, 97.37736214162183, -1.7040357732534916, -22.501789409320274, -28.888467710688236, 0.0, 0.0, 19.820394057137555, 20.0, -2.678301553888719, 9.01676596203735], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [0.0, -10.0, 0.0, -0.5566705195478616, -11.149763769502044, -0.039589045627567154, -20.0, -1.4720919957272534, 0.0, 0.0, -10.527572113131763, -0.6288585952656844, -20.0, 0.0, -20.0, -13.69744446705327, 0.0, -42.59951131043329, -10.0, -30.60599764989296, -9.057843578750632, -23.820257148956635, 0.0, -64.72649516771035, 0.0, -22.86010198755763, 0.0, -0.7316213251888681, -1.978738791227449, 0.0, -9.37091499127749, -10.0, -38.209134684659396, -30.0, -36.956553318452826, -3.82961507433005, -30.0, -10.0, 0.0, -20.0, -30.0, -2.9443648101268414, 0.0, -30.25145490779843, -7.094198570464459, 0.0, -42.67611195311475, 0.0, -32.504682088724444, 0.0, 0.0, -1.7644138752481187, -10.0, -30.0, -0.3035222329198217, -34.322739163687054, -60.0, -8.214730044371919, -0.5710860158804798, -20.300509927304354, 0.0, -40.0, -20.0, 0.0, -20.0, -11.82750422993384, 0.0, -2.4425093233023443, -30.0, -10.774277278895854, -6.713762301452589, 0.0, 0.0, -4.587522687832648, -20.0, -10.0, -20.0, 0.0, -3.349009384011376, -6.662556597857238, -40.67845317084533, -20.0, -30.0, 0.0, -7.102277739354897, 0.0, -22.05742356570402, -62.35923691977084, -10.0, -90.0, -34.6436904373738, -31.106102278725505, -10.0, -0.5277101684871144, -1.173722320451247, 0.0, -1.1079957711142674, 0.0, -4.770203946418107, -18.769111027653747, -7.884875969712407, -5.626916963963672, -0.4995350417034383, -41.05647481483445, -15.3978743116078, -24.148549186533153, -0.469315246028118, -0.1808041665092075, -20.0, -1.0654007163789725, 0.0, -53.57987817403357, 0.0, -30.0, 0.0, -1.9618519416226055, -42.246215606766086, -13.115755146560977, -2.378345091089641, -10.0, 0.0, -16.035203389222634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.896576921773928, -30.0, -10.0, -20.0, 0.0, 0.0, -13.098265727514207, -8.232984565227722, -23.75362442333458, -16.56434802244335, 0.0, -1.207798434519315, -0.9713597127474416, -30.0, 0.0, -30.0, -13.272910298480678, -28.817281442646888, 0.0, -52.62263785837817, -1.7040357732534916, -22.501789409320274, -28.888467710688236, 0.0, 0.0, -10.179605942862443, -10.0, -2.678301553888719, -20.983234037962657]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6804748953612014, "mean_inference_ms": 1.1807936652990532, "mean_action_processing_ms": 0.24419868753155552, "mean_env_wait_ms": 0.5098875559914812, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055198456831039135, "StateBufferConnector_ms": 0.0037215317890142937, "ViewRequirementAgentConnector_ms": 0.09531283834177977}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -42.67611195311475, "episode_return_mean": 15.659618625001736}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.6385811530901, "num_env_steps_trained_throughput_per_sec": 268.6385811530901, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 16087.097, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16087.023, "sample_time_ms": 1247.546, "learn_time_ms": 14815.634, "learn_throughput": 269.985, "synch_weights_time_ms": 21.068}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-01-28", "timestamp": 1723140088, "time_this_iter_s": 14.897845983505249, "time_total_s": 1523.905164718628, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bceee940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1523.905164718628, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 32.62380952380952, "ram_util_percent": 78.3761904761905}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.671673892810941, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.794326516116659, "policy_loss": -0.023448099752810474, "vf_loss": 3.816049777219693, "vf_explained_var": 0.10208608023822308, "kl": 0.008624197203281987, "entropy": 1.1330255613972744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6471973496231627, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8923790253223256, "policy_loss": -0.019054350159907092, "vf_loss": 1.910257830983358, "vf_explained_var": -5.247745108097158e-07, "kl": 0.005877721241751396, "entropy": 0.4892977693930585, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 249570.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -30.9366439591705, "episode_reward_mean": 16.099242428020077, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -94.7931074361065}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.185185185185185, "agent_policy": -14.456313127535479}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.047171710479855244, 0.0, -0.8005395055441, -2.2204308588772337, -14.259402702979838, 20.0, 0.0, -0.7024383702321257, 0.0, 0.0, -0.9192963267435073, 0.0, 37.3736345042974, 0.0, 12.160416843977085, 39.98253299894386, 0.0, -3.9772052284713, 23.0746800301105, 20.0, -0.8069511778340788, 0.0, -6.183277429302621, 58.687367708511545, 0.0, 124.04638370380506, 3.313999853660601, 79.5532484037462, -16.142026292799734, 0.0, 0.0, -7.307954690048886, -5.769887159700486, -13.179180089646259, 39.121285455534355, 0.0, -30.597380771509886, 0.0, -12.662969502466007, 24.956788643340886, -2.9191306964712007, 0.0, -13.016308429618649, -9.259562378096895, 40.0, 0.0, 60.0, -16.294411179183644, 0.0, 0.0, -13.829917980293246, 57.45215736608764, 0.0, -12.237841765649314, -6.03225051227482, -19.671087891149003, 0.0, 0.0, 0.0, 59.99923011088248, 39.4351569198549, 60.0, 0.0, -7.297417688740298, -21.013001906799683, -11.598307593480119, 20.0, 100.0, 0.0, 0.0, -0.016710154256233123, 0.0, 0.0, 0.0, -0.27480488587448004, -27.37432502215985, 20.0, 39.509790741538815, 40.0, 20.0, -23.679711700949074, 140.0, 60.0, 38.60270879088699, 39.207727936478996, -5.440009320061581, -17.74291212148356, 40.0, 36.96022870263832, 39.096875359059595, 138.8417457002712, 0.0, 160.0, 58.18780425510667, -12.007422266363056, 20.0, 54.48733681002336, -14.712967303393794, 40.0, 0.0, 69.83497430157107, 20.0, 120.0, 0.0, 80.0, 37.07757770609774, -13.326856742952272, 79.83558445067332, 0.0, 15.343673732965728, 0.0, -0.38209581816521676, 0.0, 0.0, -1.370221685152363, -3.5355852142937287, 0.0, -10.66207006632049, 0.0, 60.0, 19.72825539888349, -6.698693996843341, 0.0, 60.0, -1.3616002052779863, -30.9366439591705, 0.0, -4.218108558469585, 39.01129388109201, 0.0, 0.0, 40.0, -4.894557284760595, -3.241844073071092, -0.2965284847526406, 145.20689256389352, 0.0, -7.40984173293975, -16.452655567363397, -1.247160736207994, 0.0, 100.0, 38.981076202682665, 0.0, 39.970335676727984, 0.0, 20.0, -3.815176906246954, -5.88126990171125, 19.91005652219796, 40.0, 39.60980753782991, 0.0, -18.363911250327636, 0.0, 0.0, 0.0, -11.772710389309228, 55.95553339709353, -0.5771436849426459, 60.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.047171710479855244, 0.0, -0.8005395055441, -2.2204308588772337, -14.259402702979838, -10.0, 0.0, -0.7024383702321257, 0.0, 0.0, -0.9192963267435073, 0.0, -22.626365495702597, 0.0, -47.839583156022904, -20.01746700105614, 0.0, -3.9772052284713, -36.92531996988951, -10.0, -0.8069511778340788, 0.0, -6.183277429302621, -31.31263229148845, 0.0, -85.95361629619494, -26.686000146339392, -70.4467515962538, -16.142026292799734, 0.0, 0.0, -7.307954690048886, -5.769887159700486, -13.179180089646259, -20.878714544465645, 0.0, -30.597380771509886, 0.0, -12.662969502466007, -35.04321135665911, -2.9191306964712007, 0.0, -13.016308429618649, -9.259562378096895, -20.0, 0.0, -30.0, -16.294411179183644, 0.0, 0.0, -13.829917980293246, -62.54784263391236, 0.0, -12.237841765649314, -6.03225051227482, -19.671087891149003, 0.0, 0.0, 0.0, -30.000769889117514, -20.564843080145103, -30.0, 0.0, -7.297417688740298, -21.013001906799683, -11.598307593480119, -10.0, -50.0, 0.0, 0.0, -0.016710154256233123, 0.0, 0.0, 0.0, -0.27480488587448004, -27.37432502215985, -10.0, -20.490209258461185, -20.0, -10.0, -23.679711700949074, -70.0, -30.0, -21.39729120911301, -20.792272063521, -5.440009320061581, -17.74291212148356, -20.0, -23.03977129736169, -20.903124640940405, -71.15825429972881, 0.0, -80.0, -31.812195744893337, -12.007422266363056, -10.0, -35.51266318997664, -14.712967303393794, -20.0, 0.0, -50.165025698428956, -10.0, -60.0, 0.0, -40.0, -22.922422293902258, -13.326856742952272, -40.16441554932668, 0.0, -14.656326267034276, 0.0, -0.38209581816521676, 0.0, 0.0, -1.370221685152363, -3.5355852142937287, 0.0, -10.66207006632049, 0.0, -30.0, -10.27174460111651, -6.698693996843341, 0.0, -30.0, -1.3616002052779863, -30.9366439591705, 0.0, -4.218108558469585, -20.988706118907995, 0.0, 0.0, -20.0, -4.894557284760595, -3.241844073071092, -0.2965284847526406, -94.7931074361065, 0.0, -7.40984173293975, -16.452655567363397, -1.247160736207994, 0.0, -50.0, -21.018923797317335, 0.0, -20.029664323272012, 0.0, -10.0, -3.815176906246954, -5.88126990171125, -10.08994347780204, -20.0, -20.390192462170095, 0.0, -18.363911250327636, 0.0, 0.0, 0.0, -11.772710389309228, -34.04446660290648, -0.5771436849426459, -30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6798975324412582, "mean_inference_ms": 1.1797886361089187, "mean_action_processing_ms": 0.24393140108808595, "mean_env_wait_ms": 0.5095571638135424, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004916426576214072, "StateBufferConnector_ms": 0.0032814196598382646, "ViewRequirementAgentConnector_ms": 0.08936855528089735}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -30.9366439591705, "episode_return_mean": 16.099242428020077}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 259.4859315335302, "num_env_steps_trained_throughput_per_sec": 259.4859315335302, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 15654.634, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15654.57, "sample_time_ms": 1236.614, "learn_time_ms": 14396.521, "learn_throughput": 277.845, "synch_weights_time_ms": 19.154}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-01-44", "timestamp": 1723140104, "time_this_iter_s": 15.422041177749634, "time_total_s": 1539.3272058963776, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bceeeb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1539.3272058963776, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 32.32727272727273, "ram_util_percent": 78.11818181818181}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6920700673013926, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9445423655211926, "policy_loss": -0.03107010397798149, "vf_loss": 2.973553943882386, "vf_explained_var": 0.11075038450459639, "kl": 0.010292632116135512, "entropy": 1.121531646947066, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 85920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6796718640054794, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4706696297894133, "policy_loss": -0.01783064657906673, "vf_loss": 1.4874501329787233, "vf_explained_var": -9.483268074955501e-07, "kl": 0.005250710501712821, "entropy": 0.4863590696707685, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 252390.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -30.398894196009543, "episode_reward_mean": 9.29550360150089, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -56.59069817529729}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.54320987654321, "agent_policy": -10.334126028128741}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.2992712907433448, -16.98293630136913, -15.576168347756212, 0.0, -16.070192317532218, 0.0, 0.0, 0.0, -29.55714182183356, -2.950279236725309, 0.0, 34.350426795581235, 0.0, -1.494330228152294, -8.151870387999256, 40.0, 0.0, 34.0347197123311, 0.0, 0.0, 76.96570416186069, -0.2217823286599807, -12.80213263201529, -19.578902967685167, 0.0, 20.0, 0.0, 40.0, 60.0, 0.0, -17.674850759670996, -1.2535843483390707, -8.289493882445685, 0.0, -3.4643705874134603, 51.25788098425902, -12.28518208995508, 60.0, -14.563905860139863, 0.0, 0.0, -0.020507555171305203, -0.859843832475985, -3.453205910099123, 0.0, 58.44103835105994, 0.0, 3.4093018247027276, 0.0, -23.22020630231529, 0.0, 0.0, 0.0, -0.8217546643382923, 40.0, 0.0, 0.0, 0.0, 0.0, 57.398808483937614, -1.5806112242870285, 0.0, -30.398894196009543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -11.406345050796663, 0.0, 0.0, 0.0, 38.37801568524975, -2.4200876176218635, -4.672096216007299, -0.9546414588787455, -2.818411732868506, -4.474650809719922, 0.0, 60.0, 40.0, -1.9327835587213993, 0.0, -6.460120490120675, -0.2557286567238781, 0.0, 0.0, 79.58850593322542, -1.3854854385577298, -3.041540113973012, -24.5447665940992, -7.937909275352514, -0.6230458183647569, 0.0, -2.5483356286984957, 0.0, 0.0, 0.0, 31.7547312879519, 0.0, 80.0, 53.991946144182194, 15.854826685139477, -4.2070438525766605, -19.074952657974656, 0.0, 60.0, 40.0, -10.637411988347825, -1.3530581700442246, 0.0, -18.157500272449916, 0.0, 0.0, -1.4658828548471947, 0.0, 43.00349592779582, 60.0, 60.0, 0.0, 0.0, 39.04905335498469, 39.361990189171394, -6.559865792638517, -2.2754864690759753, -18.198575766327334, 69.93503489858361, 40.0, -0.5379196967931477, 20.0, 14.23569154382845, 0.0, 53.63125629955096, -1.9993286714633884, -0.06615823852822555, 80.0, 0.0, 20.0, 40.0, -26.151144203146146, 0.0, 0.0, 19.04287474455443, 0.0, 20.0, 0.0, -0.9476276353503943, 0.0, -3.955086660687326, 80.0, 59.981171476206924, 60.0, 65.10208594061231, -16.618777938461555, -3.6437885792760207, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -0.2992712907433448, -16.98293630136913, -15.576168347756212, 0.0, -16.070192317532218, 0.0, 0.0, 0.0, -29.55714182183356, -2.950279236725309, 0.0, -25.649573204418765, 0.0, -1.494330228152294, -8.151870387999256, -20.0, 0.0, -25.965280287668907, 0.0, 0.0, -43.034295838139315, -0.2217823286599807, -12.80213263201529, -19.578902967685167, 0.0, -10.0, 0.0, -20.0, -30.0, 0.0, -17.674850759670996, -1.2535843483390707, -8.289493882445685, 0.0, -3.4643705874134603, -38.74211901574098, -12.28518208995508, -30.0, -14.563905860139863, 0.0, 0.0, -0.020507555171305203, -0.859843832475985, -3.453205910099123, 0.0, -31.558961648940066, 0.0, -56.59069817529729, 0.0, -23.22020630231529, 0.0, 0.0, 0.0, -0.8217546643382923, -20.0, 0.0, 0.0, 0.0, 0.0, -32.601191516062386, -1.5806112242870285, 0.0, -30.398894196009543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -11.406345050796663, 0.0, 0.0, 0.0, -21.62198431475025, -2.4200876176218635, -4.672096216007299, -0.9546414588787455, -2.818411732868506, -4.474650809719922, 0.0, -30.0, -20.0, -1.9327835587213993, 0.0, -6.460120490120675, -0.2557286567238781, 0.0, 0.0, -40.41149406677457, -1.3854854385577298, -3.041540113973012, -24.5447665940992, -7.937909275352514, -0.6230458183647569, 0.0, -2.5483356286984957, 0.0, 0.0, 0.0, -28.2452687120481, 0.0, -40.0, -36.008053855817806, -14.145173314860529, -4.2070438525766605, -19.074952657974656, 0.0, -30.0, -20.0, -10.637411988347825, -1.3530581700442246, 0.0, -18.157500272449916, 0.0, 0.0, -1.4658828548471947, 0.0, -46.99650407220418, -30.0, -30.0, 0.0, 0.0, -20.9509466450153, -20.638009810828606, -6.559865792638517, -32.27548646907597, -18.198575766327334, -50.06496510141639, -20.0, -0.5379196967931477, -10.0, -15.764308456171552, 0.0, -36.36874370044903, -1.9993286714633884, -0.06615823852822555, -40.0, 0.0, -10.0, -20.0, -26.151144203146146, 0.0, 0.0, -10.957125255445566, 0.0, -10.0, 0.0, -0.9476276353503943, 0.0, -3.955086660687326, -40.0, -30.018828523793076, -30.0, -54.897914059387645, -16.618777938461555, -3.6437885792760207, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6790084059383421, "mean_inference_ms": 1.1782575694436483, "mean_action_processing_ms": 0.2436169430551579, "mean_env_wait_ms": 0.5090366876008788, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004621126033641674, "StateBufferConnector_ms": 0.003449416454927421, "ViewRequirementAgentConnector_ms": 0.0860821317743372}, "num_episodes": 162, "episode_return_max": 80.0, "episode_return_min": -30.398894196009543, "episode_return_mean": 9.29550360150089}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.2261451889007, "num_env_steps_trained_throughput_per_sec": 269.2261451889007, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 15601.184, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15601.12, "sample_time_ms": 1228.348, "learn_time_ms": 14351.017, "learn_throughput": 278.726, "synch_weights_time_ms": 19.522}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-01-58", "timestamp": 1723140118, "time_this_iter_s": 14.865840911865234, "time_total_s": 1554.1930468082428, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf4e0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1554.1930468082428, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 38.00909090909091, "ram_util_percent": 78.64999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7154277910788855, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0178530858208736, "policy_loss": -0.02958185005603203, "vf_loss": 3.045229799176256, "vf_explained_var": 0.1218344800795118, "kl": 0.011025735816777646, "entropy": 1.0986405616626143, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 86880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6309971366896697, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5658942679352794, "policy_loss": -0.01773069877613415, "vf_loss": 1.5824006353921078, "vf_explained_var": -1.0694806457411313e-06, "kl": 0.006121666685589168, "entropy": 0.4770440524034466, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 255210.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 118.79426382444788, "episode_reward_min": -28.069334737393802, "episode_reward_mean": 11.397824614204673, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.20573617555211}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.2784810126582276, "agent_policy": -10.43761842377001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -4.2554732812872915, 20.0, 20.0, -21.390553231657275, 0.0, -24.471454732958343, -5.417541764181694, -6.879898678984308, -26.7015753750282, -3.638613464791299, -28.069334737393802, 0.0, 60.0, 40.0, 0.0, -7.567884609916253, -0.07443989042766552, -2.584284005155706, 37.16558444460037, 39.97438906667819, 11.054012953072084, -0.7552556029583735, 73.30486535371212, 0.0, -1.7192562858456162, 0.0, -0.4541683576672484, -5.014098423120118, 80.0, -1.3762748136027736, 0.0, 20.0, 77.04161340496456, 0.0, 20.0, -10.637774263942354, -11.735452597707111, -2.9557764944460967, -7.21862682008141, 0.0, 0.0, 55.375123520991316, 60.0, 0.0, 0.0, 17.8920618631304, 0.0, 0.0, 0.0, 52.5558877036183, 0.0, 58.17399888096757, 13.263147169073488, 0.0, -1.6941982602005845, 17.315054902369383, 0.0, 20.0, 0.0, 60.0, 0.0, 60.0, -8.495422282808697, 0.0, -0.5702817141319838, -6.69441097081149, -13.707171770645246, 0.0, -6.29998937590498, 0.0, -9.815106013438758, 0.0, -2.998432577003812, 0.0, 8.952253831978062, 56.36988711523344, -8.454771256722676, -0.30818821805090657, -1.3676601812011235, -3.5293873840333845, 60.0, 57.23708071499977, 0.0, 118.79426382444788, 0.0, 0.0, -2.985745897748039, 0.0, 40.0, 39.87118408719929, 48.390214273893136, 60.0, 60.0, 0.0, -9.725526667372957, -4.29388542606211, 79.45414201576116, 11.92624029576627, 0.0, -0.9167043871560043, 0.0, -0.23952109443400205, 51.56218376863776, 0.0, 19.90923016806523, -1.0789824551594507, 0.0, -9.968032640553258, 0.0, 40.0, 5.7612729602973065, 19.89409551146349, -0.6231673135757032, 0.0, 40.0, 0.0, 49.54574139717585, 79.02839423436552, 0.0, 0.0, -0.267823971514366, -0.5162692388337309, -1.3864845222985633, -0.20489874240011474, -1.2021093964880936, 0.0, 40.0, 0.0, -0.7618659601504152, -3.7739691073786874, 60.0, -15.597369374894082, 0.0, 0.0, -2.4910162274781875, 0.0, 0.0, 15.053067153225461, -20.92582091004949, -2.897510601076679, -18.0479275482776, -2.0190575467607585, 19.625357669570526, 0.0, 0.0, -1.742716472597322, 40.0, 9.095449794932524, 0.0, 19.433944808494196, -2.534667201938594, 20.0, 58.891971871410206, 0.0, -0.0015955754516761012], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -4.2554732812872915, -10.0, -10.0, -21.390553231657275, 0.0, -24.471454732958343, -5.417541764181694, -6.879898678984308, -26.7015753750282, -3.638613464791299, -28.069334737393802, 0.0, -30.0, -20.0, 0.0, -7.567884609916253, -0.07443989042766552, -2.584284005155706, -22.834415555399627, -20.025610933321808, -18.94598704692791, -0.7552556029583735, -46.69513464628789, 0.0, -1.7192562858456162, 0.0, -0.4541683576672484, -5.014098423120118, -40.0, -1.3762748136027736, 0.0, -10.0, -42.95838659503543, 0.0, -10.0, -10.637774263942354, -11.735452597707111, -2.9557764944460967, -7.21862682008141, 0.0, 0.0, -34.62487647900868, -30.0, 0.0, 0.0, -12.1079381368696, 0.0, 0.0, 0.0, -37.4441122963817, 0.0, -31.82600111903244, -16.736852830926512, 0.0, -1.6941982602005845, -12.684945097630617, 0.0, -10.0, 0.0, -30.0, 0.0, -30.0, -8.495422282808697, 0.0, -0.5702817141319838, -6.69441097081149, -13.707171770645246, 0.0, -6.29998937590498, 0.0, -9.815106013438758, 0.0, -2.998432577003812, 0.0, -21.047746168021934, -33.63011288476656, -8.454771256722676, -0.30818821805090657, -1.3676601812011235, -3.5293873840333845, -30.0, -32.76291928500023, 0.0, -61.20573617555211, 0.0, 0.0, -2.985745897748039, 0.0, -20.0, -20.12881591280071, -41.60978572610685, -30.0, -30.0, 0.0, -9.725526667372957, -4.29388542606211, -40.545857984238836, -18.07375970423373, 0.0, -0.9167043871560043, 0.0, -0.23952109443400205, -38.43781623136224, 0.0, -10.09076983193477, -1.0789824551594507, 0.0, -9.968032640553258, 0.0, -20.0, -54.238727039702695, -10.105904488536511, -0.6231673135757032, 0.0, -20.0, 0.0, -40.45425860282414, -40.97160576563447, 0.0, 0.0, -0.267823971514366, -0.5162692388337309, -1.3864845222985633, -0.20489874240011474, -1.2021093964880936, 0.0, -20.0, 0.0, -0.7618659601504152, -3.7739691073786874, -30.0, -15.597369374894082, 0.0, 0.0, -2.4910162274781875, 0.0, 0.0, -14.946932846774535, -20.92582091004949, -2.897510601076679, -18.0479275482776, -2.0190575467607585, -10.374642330429474, 0.0, 0.0, -1.742716472597322, -20.0, -20.904550205067473, 0.0, -10.566055191505807, -2.534667201938594, -10.0, -31.108028128589794, 0.0, -0.0015955754516761012]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6884099225272964, "mean_inference_ms": 1.177469293483309, "mean_action_processing_ms": 0.24337265302759722, "mean_env_wait_ms": 0.5088456696653483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004468613033053241, "StateBufferConnector_ms": 0.0032589405397825603, "ViewRequirementAgentConnector_ms": 0.09302859064898913}, "num_episodes": 158, "episode_return_max": 118.79426382444788, "episode_return_min": -28.069334737393802, "episode_return_mean": 11.397824614204673}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.5660908436438, "num_env_steps_trained_throughput_per_sec": 268.5660908436438, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 15531.827, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15531.772, "sample_time_ms": 1259.198, "learn_time_ms": 14251.467, "learn_throughput": 280.673, "synch_weights_time_ms": 19.399}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-02-13", "timestamp": 1723140133, "time_this_iter_s": 14.924405813217163, "time_total_s": 1569.11745262146, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf46820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1569.11745262146, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 35.50952380952381, "ram_util_percent": 79.56190476190476}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.396269032234947, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5594230124106008, "policy_loss": -0.02565898754570905, "vf_loss": 2.58324787504971, "vf_explained_var": 0.13056629622975985, "kl": 0.00917060819307475, "entropy": 1.1343069473902385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 87840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7090034719635832, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6093891540529035, "policy_loss": -0.01987913877196306, "vf_loss": 1.628010490346462, "vf_explained_var": 2.0160531321315903e-06, "kl": 0.0062890048269753675, "entropy": 0.4820702182591384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 258030.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -29.306561770197955, "episode_reward_mean": 10.477933078241202, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.78315067011718}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.305732484076433, "agent_policy": -8.439264373988099}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 0.0, 0.0, -28.009410700366004, 0.0, 19.405934066590607, -5.390804494683567, 60.0, 0.0, 0.0, -8.103554741230854, 0.0, 20.0, 0.0, 0.0, 0.0, -7.396350356186359, 99.67791501092098, 0.0, -3.9107779084925447, 0.0, -0.0672464823003105, 40.0, 0.0, 40.0, 0.0, -0.8923876104706752, 0.0, 51.25699289244394, 0.0, 34.1830216790279, 0.0, -0.10773536952597751, -8.209428331358698, 0.0, 0.0, -5.706002690690488, 80.0, -0.3595025376610417, 0.0, 79.96388577655642, 0.0, -2.310570474571354, 0.0, 0.0, 20.0, 0.0, -10.379997794634388, 0.0, 40.0, -0.5929207747890697, -3.783606523730838, 0.0, 79.30764277612182, -11.120215768647682, 100.0, -4.511819958666492, 0.0, 0.0, -3.1275638176326144, -3.28277249827247, 0.0, -0.6741073491653837, 0.0, 60.0, -9.140241781416757, 39.93811696859747, 0.0, 0.0, 0.0, 53.0642878328279, -7.59391509158946, 0.0, 0.0, -0.20648205922631724, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5147736736697206, -7.94602135186415, 0.0, 0.0, 0.0, 0.0, 0.0, 39.988105833916755, 80.0, -12.021289562173381, 39.341197571376235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.523323802242948, 0.0, 0.0, 0.0, 0.0, 39.21684932988283, 27.78687960307696, -7.301788568435778, 13.202088688160304, 40.0, 19.98370957643945, 0.0, -5.898783719990297, 20.0, -6.706435501775546, -0.1699676707602027, 0.0, 0.0, 40.0, 0.0, 0.0, -0.47185430096870373, 16.35616427216324, 0.0, 20.0, 40.0, 0.0, 20.0, 57.99738523841979, -5.263506334898886, 0.0, 80.0, 60.0, 0.0, 20.0, 0.0, -10.748379822330845, 59.68281359482875, -16.580879616411362, 0.0, -29.306561770197955, -1.8900980388472077, -11.16842594581728, 40.0, 80.0, -2.099683523087487, 0.0, 0.0, 37.23530597277912, 0.0, -3.9107891677470468, 0.0, 13.55130456829977, 0.0, 0.0, -1.5696079910448801, 0.0, -1.554957221728116, 17.42043473073966, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, 0.0, 0.0, -28.009410700366004, 0.0, -10.594065933409397, -5.390804494683567, -30.0, 0.0, 0.0, -8.103554741230854, 0.0, -10.0, 0.0, 0.0, 0.0, -7.396350356186359, -50.322084989079016, 0.0, -3.9107779084925447, 0.0, -0.0672464823003105, -20.0, 0.0, -20.0, 0.0, -0.8923876104706752, 0.0, -38.74300710755606, 0.0, -25.8169783209721, 0.0, -0.10773536952597751, -8.209428331358698, 0.0, 0.0, -5.706002690690488, -40.0, -0.3595025376610417, 0.0, -40.036114223443576, 0.0, -2.310570474571354, 0.0, 0.0, -10.0, 0.0, -10.379997794634388, 0.0, -20.0, -0.5929207747890697, -3.783606523730838, 0.0, -40.692357223878176, -11.120215768647682, -50.0, -4.511819958666492, 0.0, 0.0, -3.1275638176326144, -3.28277249827247, 0.0, -0.6741073491653837, 0.0, -30.0, -9.140241781416757, -20.06188303140253, 0.0, 0.0, 0.0, -36.9357121671721, -7.59391509158946, 0.0, 0.0, -0.20648205922631724, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5147736736697206, -7.94602135186415, 0.0, 0.0, 0.0, 0.0, 0.0, -20.011894166083245, -40.0, -12.021289562173381, -20.658802428623765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.523323802242948, 0.0, 0.0, 0.0, 0.0, -50.78315067011718, -32.21312039692304, -7.301788568435778, -16.797911311839705, -20.0, -10.016290423560553, 0.0, -5.898783719990297, -10.0, -6.706435501775546, -0.1699676707602027, 0.0, 0.0, -20.0, 0.0, 0.0, -0.47185430096870373, -13.643835727836759, 0.0, -10.0, -20.0, 0.0, -10.0, -32.00261476158022, -5.263506334898886, 0.0, -40.0, -30.0, 0.0, -10.0, 0.0, -10.748379822330845, -30.317186405171253, -16.580879616411362, 0.0, -29.306561770197955, -1.8900980388472077, -11.16842594581728, -20.0, -40.0, -2.099683523087487, 0.0, 0.0, -22.764694027220877, 0.0, -3.9107891677470468, 0.0, -16.44869543170023, 0.0, 0.0, -1.5696079910448801, 0.0, -1.554957221728116, -12.579565269260343, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6875357531808436, "mean_inference_ms": 1.1766512286872057, "mean_action_processing_ms": 0.2432108931997605, "mean_env_wait_ms": 0.5084582765639638, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004976038720197739, "StateBufferConnector_ms": 0.0033658780869404983, "ViewRequirementAgentConnector_ms": 0.09237117828077572}, "num_episodes": 157, "episode_return_max": 100.0, "episode_return_min": -29.306561770197955, "episode_return_mean": 10.477933078241202}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.513932944258, "num_env_steps_trained_throughput_per_sec": 287.513932944258, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 15468.6, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15468.545, "sample_time_ms": 1249.066, "learn_time_ms": 14199.542, "learn_throughput": 281.699, "synch_weights_time_ms": 19.06}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-02-27", "timestamp": 1723140147, "time_this_iter_s": 13.91812777519226, "time_total_s": 1583.0355803966522, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d4d9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1583.0355803966522, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 31.578947368421048, "ram_util_percent": 80.46315789473684}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.416380083809296, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.826371852805217, "policy_loss": -0.027634520838425183, "vf_loss": 2.851919402554631, "vf_explained_var": 0.06144286083678405, "kl": 0.01043490578353755, "entropy": 1.1380059530337652, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 88800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6553978943338631, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6337375634528222, "policy_loss": -0.016934173074526156, "vf_loss": 1.6496195330687449, "vf_explained_var": 8.224172795072515e-08, "kl": 0.005261006396273792, "entropy": 0.47369536081104413, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 260850.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -27.303513634933985, "episode_reward_mean": 14.579670711032273, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.580246913580247, "agent_policy": -11.161070029708466}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.3433597530332144, 0.0, 0.0, 35.003004587517054, 0.0, -0.9953549092057012, 0.0, 0.0, 20.0, -12.777622276761932, 96.13434832594828, -0.608931410075888, 58.06274622749186, -18.22904430065418, 0.0, -9.60343679416577, 14.015901528615863, 0.0, 0.0, -0.8210530192033783, 0.0, 0.0, 113.03555113812547, -0.05529174722665231, 20.0, 0.0, -6.971036341103556, 0.0, -0.30745236647650387, -0.32045810054529555, -1.9168783094576014, 59.140386797501094, 59.85519326961449, 0.0, -6.767932676604912, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 38.1134374786839, -0.11366376755426733, 38.3088588133927, 104.67279874132035, 160.0, -2.239705534829123, -12.343100738465065, 40.0, 79.79118024249823, -0.4962327951856771, 40.0, 20.0, -1.7083780142422156, -9.00630639714998, -0.19265600607142885, 20.0, 0.0, 0.0, 0.0, 80.0, -0.8217072591183516, 0.0, -1.1144560490544453, 74.05949386797796, 0.0, 56.642621208708874, -2.738655350247665, 0.0, 180.0, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, -2.2087390474863673, 0.0, 0.0, 0.0, -5.244515013005844, 60.0, 0.0, 0.0, -0.6488325578902043, 39.71267880192752, 60.0, 100.0, 0.0, 0.0, -1.9188480841314215, -11.578176404806701, -13.104745999058016, 0.0, 0.0, 0.0, -6.807780074658112, 60.0, 0.0, 0.0, 180.0, 0.0, -7.73321069406629, 0.0, 0.0, 17.18873772063509, -3.5008537894616722, 40.0, -8.183565781334304, -25.171303577368427, 0.0, -0.05906303467869578, -9.769914309610929, 0.0, 28.476234779112325, 0.0, 0.0, -0.6525252832318595, 0.0, -4.858093639489689, 22.73185442680011, -14.445417083675814, -4.859779905672283, -12.78152130764204, 0.0, -7.818302399715039, -0.16957621056315375, 58.59015398193155, 0.0, 55.271069410734356, 60.0, 40.0, 0.0, -5.729365387380046, -1.1612615564349804, 53.25957536075882, 0.0, 60.0, 0.0, 0.0, 40.0, 0.0, 0.0, -3.730858313241874, 27.500201326756205, 0.0, 59.545545388522456, -2.9793697843994176, 40.0, 0.0, -0.09427271228059753, 0.0, 0.0, -27.303513634933985, -0.481756678123777, 0.0, -3.8924459781314873, -6.325121918099409, -0.6403707187403751, 17.14089655839965, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.3433597530332144, 0.0, 0.0, -24.99699541248295, 0.0, -0.9953549092057012, 0.0, 0.0, -10.0, -12.777622276761932, -53.865651674051705, -0.608931410075888, -31.937253772508143, -18.22904430065418, 0.0, -9.60343679416577, -15.984098471384137, 0.0, 0.0, -0.8210530192033783, 0.0, 0.0, -66.96444886187453, -0.05529174722665231, -10.0, 0.0, -6.971036341103556, 0.0, -0.30745236647650387, -0.32045810054529555, -1.9168783094576014, -30.859613202498913, -30.14480673038551, 0.0, -6.767932676604912, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -21.8865625213161, -0.11366376755426733, -21.691141186607293, -75.32720125867965, -80.0, -2.239705534829123, -12.343100738465065, -20.0, -40.20881975750178, -0.4962327951856771, -20.0, -10.0, -1.7083780142422156, -9.00630639714998, -0.19265600607142885, -10.0, 0.0, 0.0, 0.0, -40.0, -0.8217072591183516, 0.0, -1.1144560490544453, -45.94050613202206, 0.0, -33.35737879129113, -2.738655350247665, 0.0, -90.0, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, -2.2087390474863673, 0.0, 0.0, 0.0, -5.244515013005844, -30.0, 0.0, 0.0, -0.6488325578902043, -20.287321198072483, -30.0, -50.0, 0.0, 0.0, -1.9188480841314215, -11.578176404806701, -13.104745999058016, 0.0, 0.0, 0.0, -6.807780074658112, -30.0, 0.0, 0.0, -90.0, 0.0, -7.73321069406629, 0.0, 0.0, -12.811262279364913, -3.5008537894616722, -20.0, -8.183565781334304, -25.171303577368427, 0.0, -0.05906303467869578, -9.769914309610929, 0.0, -31.523765220887675, 0.0, 0.0, -0.6525252832318595, 0.0, -4.858093639489689, -67.26814557319989, -14.445417083675814, -4.859779905672283, -12.78152130764204, 0.0, -7.818302399715039, -0.16957621056315375, -31.409846018068443, 0.0, -34.728930589265644, -30.0, -20.0, 0.0, -5.729365387380046, -1.1612615564349804, -36.74042463924118, 0.0, -30.0, 0.0, 0.0, -20.0, 0.0, 0.0, -3.730858313241874, -32.499798673243795, 0.0, -30.454454611477544, -2.9793697843994176, -20.0, 0.0, -0.09427271228059753, 0.0, 0.0, -27.303513634933985, -0.481756678123777, 0.0, -3.8924459781314873, -6.325121918099409, -0.6403707187403751, -12.859103441600345, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6864106923529126, "mean_inference_ms": 1.1745803853539383, "mean_action_processing_ms": 0.24279892864491504, "mean_env_wait_ms": 0.5078155466200646, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003869003719753689, "StateBufferConnector_ms": 0.002885159151053723, "ViewRequirementAgentConnector_ms": 0.08187308723543897}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -27.303513634933985, "episode_return_mean": 14.579670711032273}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.9811575813523, "num_env_steps_trained_throughput_per_sec": 291.9811575813523, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 15047.734, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15047.677, "sample_time_ms": 1246.511, "learn_time_ms": 13781.504, "learn_throughput": 290.244, "synch_weights_time_ms": 18.813}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-02-41", "timestamp": 1723140161, "time_this_iter_s": 13.711014032363892, "time_total_s": 1596.746594429016, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d60af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1596.746594429016, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 27.630000000000003, "ram_util_percent": 80.855}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3913736159602803, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9450417128081123, "policy_loss": -0.02861183225128722, "vf_loss": 2.971557820091645, "vf_explained_var": 0.06476729642599821, "kl": 0.010478620370869938, "entropy": 1.1326684885968765, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 89760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6578387194015878, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7521102706591287, "policy_loss": -0.01616596906637469, "vf_loss": 1.7673334070976745, "vf_explained_var": 5.530127396820285e-07, "kl": 0.004714140927106495, "entropy": 0.44967478632081487, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 263670.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -24.982625023394124, "episode_reward_mean": 15.737331092497394, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -65.27586412561973}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.320987654320987, "agent_policy": -12.225631870465568}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 58.024012701370154, 0.0, -0.02443672795686136, -24.722253209035824, 40.0, 0.0, 20.0, 0.0, -3.3421506647988353, 0.0, 38.83345156181702, 120.0, 0.0, 0.0, 60.0, -0.9251472824190432, 0.0, 39.636328504838445, 0.0, 0.0, -17.15878908858421, -3.2351682328616143, -0.561993004583714, 87.76309443052399, 80.0, -0.004174162608837628, -22.815743351539474, 0.0, -15.47670519371486, -0.41734918335931015, 40.0, -20.42933668078771, 19.882994449984206, 18.97426094917229, 0.0, 0.0, 0.0, 100.0, 0.0, 59.642411672211864, -21.07644528528356, 0.0, 40.0, 0.0, 0.0, -1.3030625257158035, 0.0, -1.4264828771595972, 0.0, -14.344744913784032, 0.0, 78.40663727420392, -1.3259103954994012, 15.452188120210486, 0.0, 0.0, 20.0, 17.293382803690818, 57.59625884207375, -8.510858703880949, 40.0, -6.69508407092205, -0.10879406504423539, -13.811424113619102, 79.18105017422764, 0.0, 0.0, 0.0, 0.0, 0.0, 97.62341337668103, 0.0, 25.870016215012114, 0.0, 60.0, -6.949802677478786, -10.12335208895573, 60.0, -6.119419722760483, -0.5710931633681082, 0.0, 39.621676571204006, -1.1423704258663214, 0.0, -7.200136574575117, -8.076153465865016, 0.0, 40.0, 0.0, 40.0, -5.5554277557037075, -4.705989050305505, 0.0, 40.0, -3.7056147237181607, 40.0, 59.503600226243144, 0.0, -0.7132546217881475, 39.879483955508306, 0.0, 60.0, 0.0, 0.0, 0.0, -12.060689242121557, 0.0, -24.982625023394124, 56.35021579503305, 36.0670673789784, 114.72413587438028, 60.0, -5.820492713210243, 20.0, -0.8399767098536226, 0.0, -0.6444829489836112, 60.0, 60.0, 80.0, 0.0, -0.4545859228049487, -2.614030388830467, -1.614929284328157, -4.8148519564878205, -7.652649200113558, 56.10223551970441, 0.0, 10.405720396016713, -3.2383333422987075, -8.073133377356944, 0.0, 0.0, -0.7212657749402074, -0.19288406272747638, -0.4408526172695437, 20.0, 71.6911395155587, 56.91572792732345, 0.0, 18.503378678676505, 0.0, 60.0, -0.4727892637322606, 0.0, 0.0, 0.0, 120.0, -5.341712419194589, 70.81923040076761, -4.285254461799319, -0.08963756495754316, 0.0, 0.0, 20.0, 85.39709471463144, 60.0, 20.0, 0.0, -8.999321930249476, -14.779404837267752], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -31.97598729862985, 0.0, -0.02443672795686136, -24.722253209035824, -20.0, 0.0, -10.0, 0.0, -3.3421506647988353, 0.0, -21.16654843818298, -60.0, 0.0, 0.0, -30.0, -0.9251472824190432, 0.0, -20.363671495161555, 0.0, 0.0, -17.15878908858421, -3.2351682328616143, -0.561993004583714, -62.23690556947602, -40.0, -0.004174162608837628, -22.815743351539474, 0.0, -15.47670519371486, -0.41734918335931015, -20.0, -20.42933668078771, -10.117005550015794, -11.025739050827713, 0.0, 0.0, 0.0, -50.0, 0.0, -30.357588327788136, -21.07644528528356, 0.0, -20.0, 0.0, 0.0, -1.3030625257158035, 0.0, -1.4264828771595972, 0.0, -14.344744913784032, 0.0, -41.593362725796084, -1.3259103954994012, -14.547811879789512, 0.0, 0.0, -10.0, -12.706617196309182, -32.40374115792625, -8.510858703880949, -20.0, -6.69508407092205, -0.10879406504423539, -13.811424113619102, -40.818949825772364, 0.0, 0.0, 0.0, 0.0, 0.0, -52.376586623318964, 0.0, -34.12998378498788, 0.0, -30.0, -6.949802677478786, -10.12335208895573, -30.0, -6.119419722760483, -0.5710931633681082, 0.0, -20.378323428795994, -1.1423704258663214, 0.0, -7.200136574575117, -8.076153465865016, 0.0, -20.0, 0.0, -20.0, -5.5554277557037075, -4.705989050305505, 0.0, -20.0, -3.7056147237181607, -20.0, -30.496399773756856, 0.0, -0.7132546217881475, -20.12051604449169, 0.0, -30.0, 0.0, 0.0, 0.0, -12.060689242121557, 0.0, -24.982625023394124, -33.64978420496695, -23.9329326210216, -65.27586412561973, -30.0, -5.820492713210243, -10.0, -0.8399767098536226, 0.0, -0.6444829489836112, -30.0, -30.0, -40.0, 0.0, -0.4545859228049487, -2.614030388830467, -1.614929284328157, -4.8148519564878205, -7.652649200113558, -63.89776448029558, 0.0, -19.59427960398329, -3.2383333422987075, -8.073133377356944, 0.0, 0.0, -0.7212657749402074, -0.19288406272747638, -0.4408526172695437, -10.0, -48.3088604844413, -33.08427207267654, 0.0, -11.496621321323495, 0.0, -30.0, -0.4727892637322606, 0.0, 0.0, 0.0, -60.0, -5.341712419194589, -49.18076959923242, -4.285254461799319, -0.08963756495754316, 0.0, 0.0, -10.0, -64.60290528536859, -30.0, -10.0, 0.0, -8.999321930249476, -14.779404837267752]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6853119058866495, "mean_inference_ms": 1.1727472018875573, "mean_action_processing_ms": 0.24240494475191984, "mean_env_wait_ms": 0.5071445142997898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004147894588517554, "StateBufferConnector_ms": 0.0036740008695625966, "ViewRequirementAgentConnector_ms": 0.08670695034074194}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -24.982625023394124, "episode_return_mean": 15.737331092497394}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.55575608805117, "num_env_steps_trained_throughput_per_sec": 268.55575608805117, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 14717.005, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14716.961, "sample_time_ms": 1225.751, "learn_time_ms": 13472.514, "learn_throughput": 296.901, "synch_weights_time_ms": 18.02}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-02-56", "timestamp": 1723140176, "time_this_iter_s": 14.904796838760376, "time_total_s": 1611.6513912677765, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf46820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1611.6513912677765, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 36.88571428571429, "ram_util_percent": 81.35714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4533279204120237, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5732064376274746, "policy_loss": -0.02991995030364099, "vf_loss": 3.6009302626053494, "vf_explained_var": 0.08043384148428838, "kl": 0.01098060416049624, "entropy": 1.110834098048508, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 90720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6187445792323308, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.637256250144742, "policy_loss": -0.0185549340401578, "vf_loss": 1.6551141399863765, "vf_explained_var": -5.686325384369979e-07, "kl": 0.006970430205118218, "entropy": 0.45943667392992804, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 266490.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 152.23993185687453, "episode_reward_min": -44.62028182220365, "episode_reward_mean": 9.996564353808422, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -87.76006814312545}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.839506172839506, "agent_policy": -13.521954164710097}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.7940507757565, 0.0, -2.731110626453617, -4.973810104261799, -2.23457848838669, -30.36738049776658, 0.0, 60.0, -15.712297487705078, -28.197204289795966, 0.0, -1.823507665383507, 33.98409952636406, 80.0, 58.68140330173685, 20.0, -5.912067157314802, 60.0, 0.0, 0.0, 40.0, 0.0, 40.0, 0.0, -20.419143075067907, 0.0, -29.413938792729688, -0.19915483442315973, 78.61933355980716, -26.367358632489683, -44.62028182220365, 0.0, 0.0, 60.0, -3.5354362001581086, 15.459461388166318, 40.0, 0.0, 0.0, -1.4648704573191407, 17.01002188274911, -9.675565562001735, 0.0, 0.0, 0.0, -8.970081477295158, -16.362856434575015, 34.952158106653805, 0.0, 54.726352658831786, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 9.774167379851304, -41.277354819908545, 41.886866559559664, -5.09183327288407, -1.521322691843009, 0.0, -1.5819831167693, -1.0560692799798266, 0.0, -24.691255014622943, 60.0, 20.0, -14.810768237718564, 0.0, 39.105374624877044, 27.02541515817333, 19.55858650947732, 17.691973729770712, 0.0, 40.0, -3.894789472241265, 60.0, -14.62593490620064, 36.98561769349377, -0.024599625850106888, 76.10150757888218, 36.138751498189805, -26.643430488289663, 51.181695024031804, 0.0, -11.560140520604211, 0.0, 0.0, -27.609832815775203, -3.9428691284980637, -13.70908733302919, 0.0, 30.52050110736603, -9.274175626585881, 46.31219931483775, -15.209900462089502, 58.78541658929146, 0.0, -17.694574849235032, 40.0, 0.0, 0.0, -11.757002314759218, -0.10497671547539111, 80.0, -10.163002976972852, -12.56405630780242, -2.8315645600649644, -0.9256402361081606, -25.378094233866733, 0.0, -3.052094868257842, 0.0, 40.0, 20.0, 74.05158082539764, 0.0, -2.9887439322917952, 0.0, 0.0, 0.0, -0.19330046760146713, -0.5000616153262749, 0.0, 0.0, -11.326390172543542, 19.999203542889543, 0.0, 0.0, 0.0, 152.23993185687453, 40.0, 11.859157920710611, 0.0, 42.46055521254628, -0.9032583999492094, -31.90906682693532, 0.0, 20.0, 59.96751893146033, 38.28534578896529, 52.72889666728675, -1.6875400829947662, -13.552930086571514, 0.0, 0.0, 40.0, 40.0, -0.3997112424887983, -11.161887575587896, -17.843831513980135, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -70.20594922424351, 0.0, -2.731110626453617, -4.973810104261799, -2.23457848838669, -30.36738049776658, 0.0, -30.0, -45.71229748770508, -28.197204289795966, 0.0, -1.823507665383507, -26.015900473635938, -40.0, -31.318596698263143, -10.0, -5.912067157314802, -30.0, 0.0, 0.0, -20.0, 0.0, -20.0, 0.0, -20.419143075067907, 0.0, -29.413938792729688, -0.19915483442315973, -41.38066644019284, -26.367358632489683, -44.62028182220365, 0.0, 0.0, -30.0, -3.5354362001581086, -14.540538611833684, -20.0, 0.0, 0.0, -1.4648704573191407, -12.989978117250889, -9.675565562001735, 0.0, 0.0, 0.0, -8.970081477295158, -46.36285643457502, -25.04784189334621, 0.0, -35.27364734116822, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -20.225832620148694, -41.277354819908545, -48.113133440440336, -5.09183327288407, -1.521322691843009, 0.0, -1.5819831167693, -1.0560692799798266, 0.0, -24.691255014622943, -30.0, -10.0, -14.810768237718564, 0.0, -20.894625375122956, -32.97458484182667, -10.441413490522681, -12.308026270229284, 0.0, -20.0, -3.894789472241265, -30.0, -14.62593490620064, -53.01438230650623, -0.024599625850106888, -73.89849242111784, -23.8612485018102, -26.643430488289663, -38.818304975968196, 0.0, -11.560140520604211, 0.0, 0.0, -27.609832815775203, -3.9428691284980637, -13.70908733302919, 0.0, -29.47949889263397, -9.274175626585881, -43.68780068516226, -15.209900462089502, -31.21458341070855, 0.0, -17.694574849235032, -20.0, 0.0, 0.0, -11.757002314759218, -0.10497671547539111, -40.0, -10.163002976972852, -12.56405630780242, -2.8315645600649644, -0.9256402361081606, -25.378094233866733, 0.0, -3.052094868257842, 0.0, -20.0, -10.0, -45.94841917460236, 0.0, -2.9887439322917952, 0.0, 0.0, 0.0, -0.19330046760146713, -0.5000616153262749, 0.0, 0.0, -11.326390172543542, -10.000796457110457, 0.0, 0.0, 0.0, -87.76006814312545, -20.0, -18.14084207928939, 0.0, -47.53944478745372, -0.9032583999492094, -31.90906682693532, 0.0, -10.0, -30.032481068539667, -21.714654211034713, -37.27110333271325, -1.6875400829947662, -13.552930086571514, 0.0, 0.0, -20.0, -20.0, -0.3997112424887983, -11.161887575587896, -17.843831513980135, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6844774504571646, "mean_inference_ms": 1.171618447004461, "mean_action_processing_ms": 0.24213850573406226, "mean_env_wait_ms": 0.5067236924818808, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004670355055067275, "StateBufferConnector_ms": 0.003156617835715965, "ViewRequirementAgentConnector_ms": 0.08818558704705885}, "num_episodes": 162, "episode_return_max": 152.23993185687453, "episode_return_min": -44.62028182220365, "episode_return_mean": 9.996564353808422}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 283.36031107653474, "num_env_steps_trained_throughput_per_sec": 283.36031107653474, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 14669.67, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14669.623, "sample_time_ms": 1211.078, "learn_time_ms": 13441.212, "learn_throughput": 297.592, "synch_weights_time_ms": 16.341}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-03-10", "timestamp": 1723140190, "time_this_iter_s": 14.162739038467407, "time_total_s": 1625.814130306244, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf7bd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1625.814130306244, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 33.925, "ram_util_percent": 82.33500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3649076867848633, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.698773967350523, "policy_loss": -0.023620074685216725, "vf_loss": 2.7205428685992956, "vf_explained_var": 0.04279289208352566, "kl": 0.009255854824140375, "entropy": 1.1333877235651015, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 91680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.64700922446048, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7044654675409303, "policy_loss": -0.0185414628500568, "vf_loss": 1.7223145683606467, "vf_explained_var": 3.30319641329718e-07, "kl": 0.00692363913434987, "entropy": 0.4451524147116546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 269310.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -39.869731763064316, "episode_reward_mean": 12.606530919246518, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.83104267449528}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.8431372549019605, "agent_policy": -10.922880845459364}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 0.0, -5.3721636985069425, -5.593220756068668, 0.0, 19.47867175930045, -1.0523820180133814, 0.0, 59.35117843796252, 0.0, 56.41395482702342, 0.0, 40.0, 0.0, 0.0, 60.0, 80.0, 40.0, 31.819586934862038, -1.5758043714188508, -15.586969960950226, 20.0, 0.0, 0.0, -7.12734560062009, 0.0, -39.869731763064316, 60.0, 58.88235511346955, -0.9104391697988923, 0.0, 79.06868694056294, 40.0, 0.0, -2.9770809683965815, 33.04954541860271, 0.0, -30.209676632919397, -2.456698705496252, 0.0, -2.563383805726237, 0.0, 0.0, -0.004176606334851396, -3.6931488402893495, 0.0, 58.5242851842648, 39.27498978672477, 80.92617678990915, 0.0, 0.0, -11.730568660112528, 40.0, 60.0, 100.0, -20.831042674495272, -2.0166428302665462, -3.9267567803984864, 0.0, 0.0, 18.55831617628073, -6.417764566639848, -4.85747125899973, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 100.0, -1.3045292919473384, 0.0, 20.0, 40.0, 54.21239651385124, 19.220493544193737, 40.0, -14.511087653228248, 38.162972384259675, 40.0, 0.0, -13.9706973896664, 0.0, 15.85549898492963, 0.0, 80.0, -1.7011835544955722, 0.0, 0.0, -0.022589589816176536, -1.579451007244178, -0.24926746654075127, -5.95820488349554, 0.0, -0.4003776491119715, 0.0, -24.118397223375858, 117.88449556368107, -0.1408434093216948, 60.0, -0.9502416671153158, -0.5012025774458939, 0.0, -16.614790217315647, 0.0, 0.0, 0.0, 20.0, 0.0, -4.299412451844765, -3.904674200353335, 0.0, -0.2130009248678466, -2.5625848313416384, -3.128128124084071, -1.0596387775525873, 0.0, 0.0, 40.0, -3.619790747056904, 0.0, 0.0, -0.4386213403024297, 38.870301448064865, 0.0, -0.5449855983528917, -1.1042273244227763, 0.0, 79.74985101838813, 0.0, -0.31602516129520364, 0.0, -5.4195389974208155, 0.0, -1.504797841403166, 17.81595571480232, 0.0, 40.0, -19.77778523376373, -3.70047074095526, 40.0, -3.7139223439120626, 40.0, -1.4994954771803792, 0.0, 0.0, 0.0, -0.7180485316697405], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -30.0, 0.0, -5.3721636985069425, -5.593220756068668, 0.0, -40.521328240699546, -1.0523820180133814, 0.0, -30.64882156203749, 0.0, -33.58604517297659, 0.0, -20.0, 0.0, 0.0, -30.0, -40.0, -20.0, -28.180413065137962, -1.5758043714188508, -15.586969960950226, -10.0, 0.0, 0.0, -7.12734560062009, 0.0, -39.869731763064316, -30.0, -31.117644886530446, -0.9104391697988923, 0.0, -40.93131305943705, -20.0, 0.0, -2.9770809683965815, -26.950454581397295, 0.0, -30.209676632919397, -2.456698705496252, 0.0, -2.563383805726237, 0.0, 0.0, -0.004176606334851396, -3.6931488402893495, 0.0, -31.475714815735206, -20.725010213275233, -69.07382321009084, 0.0, 0.0, -11.730568660112528, -20.0, -30.0, -50.0, -80.83104267449528, -32.01664283026654, -3.9267567803984864, 0.0, 0.0, -11.441683823719272, -6.417764566639848, -4.85747125899973, -70.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -50.0, -1.3045292919473384, 0.0, -10.0, -20.0, -35.78760348614876, -10.779506455806265, -20.0, -14.511087653228248, -21.837027615740332, -20.0, 0.0, -13.9706973896664, 0.0, -14.144501015070372, 0.0, -40.0, -1.7011835544955722, 0.0, 0.0, -0.022589589816176536, -1.579451007244178, -0.24926746654075127, -5.95820488349554, 0.0, -0.4003776491119715, 0.0, -24.118397223375858, -62.115504436318915, -0.1408434093216948, -30.0, -0.9502416671153158, -0.5012025774458939, 0.0, -16.614790217315647, 0.0, 0.0, 0.0, -10.0, 0.0, -4.299412451844765, -3.904674200353335, 0.0, -0.2130009248678466, -2.5625848313416384, -3.128128124084071, -1.0596387775525873, 0.0, 0.0, -20.0, -3.619790747056904, 0.0, 0.0, -0.4386213403024297, -51.129698551935135, 0.0, -0.5449855983528917, -1.1042273244227763, 0.0, -40.25014898161187, 0.0, -0.31602516129520364, 0.0, -5.4195389974208155, 0.0, -1.504797841403166, -12.184044285197679, 0.0, -20.0, -19.77778523376373, -3.70047074095526, -20.0, -3.7139223439120626, -20.0, -1.4994954771803792, 0.0, 0.0, 0.0, -0.7180485316697405]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6837816803020896, "mean_inference_ms": 1.1705123138551614, "mean_action_processing_ms": 0.24185509309151765, "mean_env_wait_ms": 0.5063585739250919, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004163364958918951, "StateBufferConnector_ms": 0.00310162313623366, "ViewRequirementAgentConnector_ms": 0.08667894438201305}, "num_episodes": 153, "episode_return_max": 140.0, "episode_return_min": -39.869731763064316, "episode_return_mean": 12.606530919246518}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 288.4921801346949, "num_env_steps_trained_throughput_per_sec": 288.4921801346949, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 14592.867, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14592.821, "sample_time_ms": 1203.363, "learn_time_ms": 13372.073, "learn_throughput": 299.131, "synch_weights_time_ms": 16.358}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-03-24", "timestamp": 1723140204, "time_this_iter_s": 13.872444152832031, "time_total_s": 1639.686574459076, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d4d9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1639.686574459076, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 28.640000000000004, "ram_util_percent": 83.38000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3381794878592093, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.848899257183075, "policy_loss": -0.0263412285012843, "vf_loss": 2.8733540258059898, "vf_explained_var": 0.11913337136308352, "kl": 0.009432305638217045, "entropy": 1.158801975597938, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 92640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6815280632769808, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.821391770518418, "policy_loss": -0.019033674230875038, "vf_loss": 1.8397975768603332, "vf_explained_var": -9.056946910019462e-08, "kl": 0.006278659282224551, "entropy": 0.45561878466648414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 272130.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -24.67396910115527, "episode_reward_mean": 13.938151328557973, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.271604938271604, "agent_policy": -10.876663486256842}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, 0.0, 51.48822551077946, 0.0, 0.0, -22.681331063956367, 59.15339333220642, 51.63373601665925, 60.0, 0.0, 59.753734050024875, 0.0, -1.0441360879591, 0.0, 14.942637760421736, -8.37523371766119, -1.5992912606108556, 0.0, -0.35761924816530954, 34.394844921807646, 0.0, 59.191353260668336, -24.633118400151464, 0.0, 0.0, 0.0, 0.0, -1.9457636966472314, 20.0, -4.672155887651636, 0.0, 0.0, -1.5634019370256735, 60.0, 18.570853668032143, -1.977653444651425, 0.0, -0.005332462395932769, 60.0, -1.97793417529199, -1.582094381517779, -1.4131980394479438, 20.0, 16.356141480104863, 0.0, 60.0, 20.0, -0.19227979226559833, -0.43923842003834146, -1.5146973032472832, 59.603871856242485, 60.0, 0.0, 0.0, 0.0, -24.67396910115527, -0.9626406533295495, 0.0, 40.0, -0.710499780418774, -3.2008222161663067, 11.023028848484293, 0.0, -1.5547899308193902, 39.60520133318393, -3.707076474094308, -5.1619032976947015, 0.0, 100.0, 5.295009382584765, -16.55697644002095, -0.661433410877168, -4.760499896689213, -0.5055208970741298, 0.0, -0.1139368923401407, 0.0, 0.0, 41.776175820835384, 40.0, 79.1283492682163, 0.0, 20.0, 0.0, 20.0, 0.0, 16.9782468130966, -4.845789748519013, -3.2691244441278524, 0.0, 0.0, 28.698190190785247, 0.0, -0.43933479513412754, -0.14912287808454994, 0.0, 100.0, 0.0, -4.363432085007639, -0.4965173447712057, 0.0, -1.2968298753444263, 0.0, 0.0, 39.83573944585297, 20.0, 0.0, -23.602194133912135, 0.0, -1.3872008011197368, 0.0, 0.0, -0.05733280518765316, -7.214977344682918, -1.7006211412266437, 0.0, 38.95488809813282, 20.0, 40.0, -2.599464865852444, 0.0, -8.94410107390939, 52.44320028845745, 100.0, 39.478875029154736, 0.0, 9.750687890747674, 0.0, 0.0, -14.984476088650128, 60.0, -7.151582706538793, 40.0, 38.92093978248651, 0.0, 79.89644535635685, 0.0, 0.0, 31.416497028069816, 30.32599119085446, 0.0, 60.0, 0.0, 0.0, 0.0, 38.94649436339264, 0.0, 0.0, -5.489410468808503, 72.94423441646236, 40.0, 0.0, 0.0, 58.90950182881662, 40.0, 56.88000976527177, -19.48649901647668, 60.0, 0.0, 0.0, 0.0, 27.706577154920147], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-40.0, 0.0, -38.51177448922054, 0.0, 0.0, -22.681331063956367, -30.84660666779358, -38.36626398334076, -30.0, 0.0, -30.24626594997513, 0.0, -1.0441360879591, 0.0, -15.057362239578264, -8.37523371766119, -1.5992912606108556, 0.0, -0.35761924816530954, -25.605155078192364, 0.0, -30.80864673933167, -24.633118400151464, 0.0, 0.0, 0.0, 0.0, -1.9457636966472314, -10.0, -4.672155887651636, 0.0, 0.0, -1.5634019370256735, -30.0, -41.42914633196785, -1.977653444651425, 0.0, -0.005332462395932769, -30.0, -1.97793417529199, -1.582094381517779, -1.4131980394479438, -10.0, -13.643858519895137, 0.0, -30.0, -10.0, -0.19227979226559833, -0.43923842003834146, -1.5146973032472832, -30.396128143757515, -30.0, 0.0, 0.0, 0.0, -24.67396910115527, -0.9626406533295495, 0.0, -20.0, -0.710499780418774, -3.2008222161663067, -18.97697115151571, 0.0, -1.5547899308193902, -20.394798666816072, -3.707076474094308, -5.1619032976947015, 0.0, -50.0, -24.704990617415234, -16.55697644002095, -0.661433410877168, -4.760499896689213, -0.5055208970741298, 0.0, -0.1139368923401407, 0.0, 0.0, -48.223824179164616, -20.0, -40.8716507317837, 0.0, -10.0, 0.0, -10.0, 0.0, -13.021753186903398, -4.845789748519013, -3.2691244441278524, 0.0, 0.0, -31.301809809214756, 0.0, -0.43933479513412754, -0.14912287808454994, 0.0, -50.0, 0.0, -4.363432085007639, -0.4965173447712057, 0.0, -1.2968298753444263, 0.0, 0.0, -20.164260554147027, -10.0, 0.0, -23.602194133912135, 0.0, -1.3872008011197368, 0.0, 0.0, -0.05733280518765316, -7.214977344682918, -1.7006211412266437, 0.0, -21.04511190186719, -10.0, -20.0, -2.599464865852444, 0.0, -8.94410107390939, -37.55679971154255, -50.0, -20.521124970845264, 0.0, -20.249312109252333, 0.0, 0.0, -14.984476088650128, -30.0, -7.151582706538793, -20.0, -21.079060217513483, 0.0, -40.10355464364316, 0.0, 0.0, -28.583502971930177, -29.674008809145548, 0.0, -30.0, 0.0, 0.0, 0.0, -21.053505636607362, 0.0, 0.0, -5.489410468808503, -47.05576558353764, -20.0, 0.0, 0.0, -31.090498171183373, -20.0, -33.11999023472823, -19.48649901647668, -30.0, 0.0, 0.0, 0.0, -32.29342284507985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6832527119911722, "mean_inference_ms": 1.1697586929541222, "mean_action_processing_ms": 0.24164868111184132, "mean_env_wait_ms": 0.5062220890569534, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004244586567819854, "StateBufferConnector_ms": 0.0035703182220458984, "ViewRequirementAgentConnector_ms": 0.09544977435359249}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -24.67396910115527, "episode_return_mean": 13.938151328557973}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 238.57422020673027, "num_env_steps_trained_throughput_per_sec": 238.57422020673027, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 14731.051, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14731.005, "sample_time_ms": 1202.37, "learn_time_ms": 13509.458, "learn_throughput": 296.089, "synch_weights_time_ms": 17.903}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-03-41", "timestamp": 1723140221, "time_this_iter_s": 16.80154585838318, "time_total_s": 1656.488120317459, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf46e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1656.488120317459, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 46.32916666666667, "ram_util_percent": 81.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1762403067201377, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.121107752248645, "policy_loss": -0.02748775000339568, "vf_loss": 3.1466859223941963, "vf_explained_var": 0.02995149828493595, "kl": 0.009547856555216692, "entropy": 1.1633899661401907, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 93600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6419195337287078, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.209103001474489, "policy_loss": -0.018964515590680273, "vf_loss": 2.22739361676764, "vf_explained_var": 2.977907234895314e-07, "kl": 0.006738996073089824, "entropy": 0.4420978407065074, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 274950.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -31.189222263720772, "episode_reward_mean": 17.85339626979309, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.246913580246913, "agent_policy": -12.887344470947646}, "custom_metrics": {}, "hist_stats": {"episode_reward": [99.78765849830047, 0.0, 97.92362361830156, -0.4854170154846149, 0.0, 60.0, 0.0, 0.0, 0.0, 40.0, -16.604374704338476, 20.0, 100.0, 58.145671679814484, 54.30742645048383, 37.673168274229006, 0.0, 0.0, -1.2535185012763561, 60.0, 46.72353296828663, 20.0, 0.0, 20.0, 0.0, -0.8725737822947066, 60.0, -1.2129427999454667, 20.0, 0.0, -0.7400377535377012, 0.0, 0.0, 180.0, -15.791017546005458, 60.0, 0.0, 0.0, -27.755882488508227, 120.0, 0.0, 31.78478297051037, 0.0, -2.6550810929951982, -0.233475942562531, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -1.0130850012211179, 0.0, -8.449025784619998, 9.293095810719008, -7.895096314777038, 26.339552289362977, 0.0, 36.840627938866305, -2.9821195012093087, 20.0, 0.0, 32.94788213456165, 40.0, 58.836598263755974, 100.0, -0.44008728537897057, 20.0, -15.156162100013479, 0.0, 20.0, 20.0, -31.189222263720772, -3.483514900482855, 0.0, 60.0, 28.94745341092541, 0.0, 60.0, -1.7995349615254286, -0.6869201105302714, 0.0, 0.0, 39.472145314333176, -0.8165711442028933, 0.0, 40.0, 60.0, -0.4656271587407834, 0.0, 38.86850456873661, -0.06709007928056065, -23.134681002184415, 80.0, 0.0, 0.0, -9.464398831905307, 20.0, 0.0, 0.0, -1.5424333751245134, -4.7323792525313175, 0.0, 80.0, -5.768134339355983, 0.0, -0.988789584690154, -0.2028696003588537, 40.0, 0.0, -15.877635732941073, 40.0, 37.303164833093355, 40.0, 0.0, 69.19363161531605, 0.0, 56.19306669716998, -14.276812315028463, 59.68045198119287, 60.0, -0.3313442561062785, 0.0, 0.0, 0.0, 60.0, 117.30298657708417, 20.0, 30.866815815395285, -2.802460824634542, -1.5453903546614134, 0.0, -2.353063335214684, 0.0, 0.0, 0.0, 0.0, 19.217916274589857, 0.0, 0.0, 0.0, 40.0, 100.0, -13.003015382554802, 80.0, 20.0, 0.0, 59.82454942110846, -15.630244961962681, -1.2628006233546496, 0.0, 0.0, 0.0, 15.177930091294524, -2.123578580514888, -1.6908093069333796, -0.37458188019288574, -11.248240018048255, 60.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-50.21234150169953, 0.0, -52.076376381698424, -0.4854170154846149, 0.0, -30.0, 0.0, 0.0, 0.0, -20.0, -16.604374704338476, -10.0, -50.0, -31.854328320185534, -35.69257354951617, -22.326831725770994, 0.0, 0.0, -1.2535185012763561, -30.0, -43.27646703171337, -10.0, 0.0, -10.0, 0.0, -0.8725737822947066, -30.0, -1.2129427999454667, -10.0, 0.0, -0.7400377535377012, 0.0, 0.0, -90.0, -15.791017546005458, -30.0, 0.0, 0.0, -27.755882488508227, -60.0, 0.0, -28.21521702948963, 0.0, -2.6550810929951982, -0.233475942562531, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -1.0130850012211179, 0.0, -8.449025784619998, -20.706904189280998, -7.895096314777038, -33.66044771063702, 0.0, -23.159372061133688, -2.9821195012093087, -10.0, 0.0, -27.052117865438333, -20.0, -31.163401736244026, -50.0, -0.44008728537897057, -10.0, -15.156162100013479, 0.0, -10.0, -10.0, -31.189222263720772, -3.483514900482855, 0.0, -30.0, -61.05254658907459, 0.0, -30.0, -1.7995349615254286, -0.6869201105302714, 0.0, 0.0, -20.527854685666828, -0.8165711442028933, 0.0, -20.0, -30.0, -0.4656271587407834, 0.0, -21.13149543126339, -0.06709007928056065, -23.134681002184415, -40.0, 0.0, 0.0, -9.464398831905307, -10.0, 0.0, 0.0, -1.5424333751245134, -4.7323792525313175, 0.0, -40.0, -5.768134339355983, 0.0, -0.988789584690154, -0.2028696003588537, -20.0, 0.0, -15.877635732941073, -20.0, -22.69683516690665, -20.0, 0.0, -50.80636838468395, 0.0, -33.80693330283002, -14.276812315028463, -30.319548018807133, -30.0, -0.3313442561062785, 0.0, 0.0, 0.0, -30.0, -62.697013422915816, -10.0, -29.133184184604715, -2.802460824634542, -1.5453903546614134, 0.0, -2.353063335214684, 0.0, 0.0, 0.0, 0.0, -10.782083725410144, 0.0, 0.0, 0.0, -20.0, -50.0, -43.00301538255481, -40.0, -10.0, 0.0, -30.17545057889154, -15.630244961962681, -1.2628006233546496, 0.0, 0.0, 0.0, -14.822069908705473, -2.123578580514888, -1.6908093069333796, -0.37458188019288574, -11.248240018048255, -30.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6828912306957847, "mean_inference_ms": 1.1694650137840494, "mean_action_processing_ms": 0.24149968477734343, "mean_env_wait_ms": 0.506062316326136, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0053639765138979315, "StateBufferConnector_ms": 0.003370311525132921, "ViewRequirementAgentConnector_ms": 0.09705247702421965}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -31.189222263720772, "episode_return_mean": 17.85339626979309}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 278.74935148453346, "num_env_steps_trained_throughput_per_sec": 278.74935148453346, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 14677.043, "restore_workers_time_ms": 0.012, "training_step_time_ms": 14676.996, "sample_time_ms": 1204.895, "learn_time_ms": 13452.707, "learn_throughput": 297.338, "synch_weights_time_ms": 18.11}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-03-55", "timestamp": 1723140235, "time_this_iter_s": 14.399501085281372, "time_total_s": 1670.8876214027405, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2d4dc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1670.8876214027405, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 35.575, "ram_util_percent": 81.58500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.414678441360593, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.654206902285417, "policy_loss": -0.029594297164779466, "vf_loss": 2.6816821224987506, "vf_explained_var": 0.04337209574878216, "kl": 0.010595362864608717, "entropy": 1.1256836726019779, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 94560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6327505341077104, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7354547035609578, "policy_loss": -0.02033248279575615, "vf_loss": 1.7550698138297873, "vf_explained_var": 1.6011244861792166e-06, "kl": 0.0071737387651471096, "entropy": 0.44198298910830885, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 277770.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -25.776355630408784, "episode_reward_mean": 14.402350689181512, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -69.22352643296551}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.703703703703704, "agent_policy": -11.708760421929597}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.396331357973978, 15.33470921536222, -10.121870308437385, 60.0, -9.984995413172866, -4.600591596975342, 14.049527746065225, 0.0, 50.52655129081104, 65.50333965730145, -1.0566436263054002, -0.8518987582681992, 33.23417305075551, -5.529440751121695, 16.150374884733676, -2.0788090091269886, 0.0, 80.0, -1.2912309044162606, -0.7449250220095327, 0.0, 0.0, 0.0, 120.0, 40.0, 0.0, 17.068630851670154, 50.77647356703449, -0.9538129797220685, 53.47406441661187, 120.0, -3.4649965551763007, 59.78248967867597, -0.2909649051151153, 0.0, -0.0917083344491898, -0.1624544154798857, 50.72047868490278, 50.026671809947764, 0.0, -18.40639137693759, 0.0, 0.0, -3.1917028605093067, 60.0, -1.4443296751579093, 36.98390875167415, 0.0, 20.0, 0.0, 37.89865795212099, 0.0, 21.795448303428934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -12.891618689842643, 100.0, 34.18540559925355, -25.776355630408784, -3.80994966866117, 0.0, 0.0, -0.6358343224273832, -1.4318716970792156, -1.94175776000316, 80.0, -4.102077184100015, -4.196200325035013, -2.931350966801194, 0.0, 39.875717612733126, 0.0, 0.0, 40.0, 0.0, -3.3478563348947405, -0.351288740802862, 0.0, 60.0, 0.0, 40.0, 0.0, -2.439941288455171, -3.0545369396643625, 31.856718051177772, -0.40711501971817055, 0.0, -0.6816841740805502, 0.0, 40.0, 59.994923644742784, -0.07193480774822514, 0.0, -5.4302394067447475, 71.09051704462823, 0.0, 0.0, 100.0, 0.0, -5.606930111631264, -3.84628585685895, 0.0, -2.333534335324834, 0.0, 40.24535879236395, 36.736764221241565, 60.0, 0.0, 40.0, 60.0, -1.057274697083086, -0.2341903217333674, 0.0, 60.0, -1.544262185740204, 99.86796478428909, 0.0, 0.0, 0.0, -19.836410566020977, -0.6137380269712067, -0.5634086515379244, 0.0, 0.0, 58.356714212376744, 20.0, 0.0, 0.0, 0.0, -0.7343101024016752, 0.0, 0.0, -9.489503743073097, -6.853602047423784, 0.0, 0.0, -1.845082148029601, 60.0, -1.9168811356751114, 0.0, 0.0, 0.0, 79.6713178895466, -2.0138163225374184, -22.00248953449155, 40.0, 0.0, -6.893561178208609, -14.37100756295901, 60.0, 0.0, 60.0, 39.79696445517068, -0.054175896696594394, 0.0, -2.3443937194412756, -9.503485570552929, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.396331357973978, -14.66529078463778, -10.121870308437385, -30.0, -9.984995413172866, -4.600591596975342, -15.950472253934771, 0.0, -39.47344870918896, -54.49666034269855, -1.0566436263054002, -0.8518987582681992, -26.76582694924448, -5.529440751121695, -43.84962511526632, -2.0788090091269886, 0.0, -40.0, -1.2912309044162606, -0.7449250220095327, 0.0, 0.0, 0.0, -60.0, -20.0, 0.0, -12.931369148329843, -69.22352643296551, -0.9538129797220685, -36.525935583388126, -60.0, -3.4649965551763007, -30.217510321324028, -0.2909649051151153, 0.0, -0.0917083344491898, -0.1624544154798857, -39.27952131509722, -39.973328190052236, 0.0, -18.40639137693759, 0.0, 0.0, -3.1917028605093067, -30.0, -1.4443296751579093, -23.016091248325854, 0.0, -10.0, 0.0, -22.101342047879, 0.0, -68.20455169657107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -12.891618689842643, -50.0, -25.814594400746458, -25.776355630408784, -3.80994966866117, 0.0, 0.0, -0.6358343224273832, -1.4318716970792156, -1.94175776000316, -40.0, -4.102077184100015, -4.196200325035013, -2.931350966801194, 0.0, -20.124282387266874, 0.0, 0.0, -20.0, 0.0, -3.3478563348947405, -0.351288740802862, 0.0, -30.0, 0.0, -20.0, 0.0, -2.439941288455171, -3.0545369396643625, -28.143281948822224, -0.40711501971817055, 0.0, -0.6816841740805502, 0.0, -20.0, -30.005076355257216, -0.07193480774822514, 0.0, -5.4302394067447475, -48.90948295537175, 0.0, 0.0, -50.0, 0.0, -5.606930111631264, -3.84628585685895, 0.0, -2.333534335324834, 0.0, -49.75464120763605, -23.263235778758425, -30.0, 0.0, -20.0, -30.0, -1.057274697083086, -0.2341903217333674, 0.0, -30.0, -1.544262185740204, -50.132035215710914, 0.0, 0.0, 0.0, -19.836410566020977, -0.6137380269712067, -0.5634086515379244, 0.0, 0.0, -31.643285787623253, -10.0, 0.0, 0.0, 0.0, -0.7343101024016752, 0.0, 0.0, -39.4895037430731, -6.853602047423784, 0.0, 0.0, -1.845082148029601, -30.0, -1.9168811356751114, 0.0, 0.0, 0.0, -40.3286821104534, -2.0138163225374184, -22.00248953449155, -20.0, 0.0, -6.893561178208609, -14.37100756295901, -30.0, 0.0, -30.0, -20.20303554482932, -0.054175896696594394, 0.0, -2.3443937194412756, -9.503485570552929, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6821743733204478, "mean_inference_ms": 1.1684510740602256, "mean_action_processing_ms": 0.24122017861400236, "mean_env_wait_ms": 0.5058340975947927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004423547674108435, "StateBufferConnector_ms": 0.0030420444629810474, "ViewRequirementAgentConnector_ms": 0.08815136956579891}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -25.776355630408784, "episode_return_mean": 14.402350689181512}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 286.0794300215702, "num_env_steps_trained_throughput_per_sec": 286.0794300215702, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 14533.748, "restore_workers_time_ms": 0.013, "training_step_time_ms": 14533.699, "sample_time_ms": 1210.027, "learn_time_ms": 13304.243, "learn_throughput": 300.656, "synch_weights_time_ms": 18.097}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-04-09", "timestamp": 1723140249, "time_this_iter_s": 13.990752220153809, "time_total_s": 1684.8783736228943, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf7bee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1684.8783736228943, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 36.545, "ram_util_percent": 81.005}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4193089085320634, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2461180448532105, "policy_loss": -0.02242561089757752, "vf_loss": 3.2669409944365424, "vf_explained_var": 0.11731963797161976, "kl": 0.00801330070689739, "entropy": 1.125541407801211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 95520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.641468155769803, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7617109658024834, "policy_loss": -0.01893203235066212, "vf_loss": 1.7799756205673758, "vf_explained_var": 2.889345723686489e-07, "kl": 0.006673777619138005, "entropy": 0.42337058039633096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 280590.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 147.2885790526632, "episode_reward_min": -33.14488031576407, "episode_reward_mean": 13.56755713392119, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -92.71142094733682}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.45679012345679, "agent_policy": -11.80281323644918}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.08794287787006083, 59.02313511867558, 0.0, 19.654190507954034, 20.0, 0.0, 0.0, 18.749122690130143, -5.098816169948272, -0.9984280484554431, -14.836758524525427, 20.0, 0.0, -6.33170302989822, 40.0, 80.0, 37.40201404441868, 0.0, 0.0, 0.0, 77.35256081953443, 0.0, -1.0978159509734475, 31.7714565214912, -2.17344799656199, 0.0, 97.95340545536746, 60.0, 0.0, -0.2822003656425476, -3.359677575532726, -16.245497967770596, -8.283157161962997, 20.0, 0.0, 0.0, -16.961711845550237, 0.0, 0.0, 0.0, 29.10474631351787, 0.0, 0.0, -3.8828899985570002, 19.34202744268618, 0.0, -14.386069850341388, 0.0, -5.468901898615068, 0.0, 100.0, 53.81331865905965, 40.0, 40.0, -0.11574708186787963, 60.0, 147.2885790526632, 59.35215361594484, 0.0, 60.0, 30.923653765058184, 120.0, 60.0, -0.810603586670402, 40.0, 60.0, 0.0, -26.0620259813703, 0.0, 27.361266860186724, 0.0, 0.0, -4.38381264172841, 0.0, 60.0, 20.0, 0.0, 0.0, -33.14488031576407, -2.094594518146197, 0.0, -5.336925386915214, 0.0, 0.0, 0.0, 20.0, -0.08784765622338764, 19.789651979841295, -24.454412074469754, 0.0, -0.8590383647326338, -2.1008092356890984, 0.0, 79.77204649950369, 59.922316096811244, 0.0, 77.68515388595813, 13.321183740104155, -10.817866540377612, 0.0, -4.4925448090828235, 40.0, 0.0, 40.0, -16.68693200085371, 0.0, -23.00859706192866, -11.449962993375738, 0.0, -24.592137306157145, 9.595477167786118, 19.18851530348849, 0.0, 40.0, 0.0, -0.5122681466542311, 0.0, -6.009781660410008, 0.0, 0.0, 0.0, 19.82858769785388, -4.504162786778652, 0.0, -1.1786543489783208, -11.735707056810321, 0.0, 0.0, 20.0, 73.48822290861929, -0.3826162256158061, -4.401721545880212, 0.0, 40.0, -7.636093208228367, 0.0, -12.752157589728172, 79.15044580790465, 12.76015648134084, 0.0, 100.0, -14.754542664526843, 20.0, 0.0, 0.0, 34.262773257568085, 19.096792937225622, 0.0, 19.86919673310015, 0.0, 0.0, 0.0, -3.9971569184747215, 19.41353175265854, -0.29709181586415556, 20.0, 0.0, 20.0, -10.13571663571146, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, 0.0, -0.08794287787006083, -30.976864881324424, 0.0, -10.345809492045964, -10.0, 0.0, 0.0, -11.250877309869855, -5.098816169948272, -0.9984280484554431, -14.836758524525427, -10.0, 0.0, -6.33170302989822, -20.0, -40.0, -22.597985955581322, 0.0, 0.0, 0.0, -42.64743918046557, 0.0, -1.0978159509734475, -28.228543478508797, -2.17344799656199, 0.0, -52.04659454463253, -30.0, 0.0, -0.2822003656425476, -3.359677575532726, -16.245497967770596, -8.283157161962997, -10.0, 0.0, 0.0, -16.961711845550237, 0.0, 0.0, 0.0, -30.89525368648213, 0.0, 0.0, -3.8828899985570002, -10.657972557313819, 0.0, -14.386069850341388, 0.0, -5.468901898615068, 0.0, -50.0, -36.18668134094035, -20.0, -20.0, -0.11574708186787963, -30.0, -92.71142094733682, -30.64784638405516, 0.0, -30.0, -29.076346234941823, -60.0, -30.0, -0.810603586670402, -20.0, -30.0, 0.0, -26.0620259813703, 0.0, -62.6387331398133, 0.0, 0.0, -4.38381264172841, 0.0, -30.0, -10.0, 0.0, 0.0, -33.14488031576407, -2.094594518146197, 0.0, -5.336925386915214, 0.0, 0.0, 0.0, -10.0, -0.08784765622338764, -10.210348020158706, -24.454412074469754, 0.0, -0.8590383647326338, -2.1008092356890984, 0.0, -40.22795350049631, -30.077683903188753, 0.0, -72.31484611404187, -16.678816259895843, -10.817866540377612, 0.0, -4.4925448090828235, -20.0, 0.0, -20.0, -16.68693200085371, 0.0, -23.00859706192866, -11.449962993375738, 0.0, -24.592137306157145, -20.40452283221388, -10.81148469651151, 0.0, -20.0, 0.0, -0.5122681466542311, 0.0, -6.009781660410008, 0.0, 0.0, 0.0, -10.171412302146122, -4.504162786778652, 0.0, -1.1786543489783208, -11.735707056810321, 0.0, 0.0, -10.0, -46.51177709138071, -0.3826162256158061, -4.401721545880212, 0.0, -20.0, -7.636093208228367, 0.0, -12.752157589728172, -40.84955419209536, -17.239843518659164, 0.0, -50.0, -44.75454266452683, -10.0, 0.0, 0.0, -25.73722674243192, -10.903207062774378, 0.0, -10.13080326689985, 0.0, 0.0, 0.0, -3.9971569184747215, -10.586468247341461, -0.29709181586415556, -10.0, 0.0, -10.0, -10.13571663571146, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.681536690063254, "mean_inference_ms": 1.1675507744512983, "mean_action_processing_ms": 0.24100736907351877, "mean_env_wait_ms": 0.5054175959220469, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004598682309374397, "StateBufferConnector_ms": 0.0030911263124442393, "ViewRequirementAgentConnector_ms": 0.0898122051615774}, "num_episodes": 162, "episode_return_max": 147.2885790526632, "episode_return_min": -33.14488031576407, "episode_return_mean": 13.56755713392119}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 265.6949844061999, "num_env_steps_trained_throughput_per_sec": 265.6949844061999, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 14553.494, "restore_workers_time_ms": 0.013, "training_step_time_ms": 14553.445, "sample_time_ms": 1222.526, "learn_time_ms": 13311.769, "learn_throughput": 300.486, "synch_weights_time_ms": 17.711}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "a5fdb_00000", "date": "2024-08-08_14-04-24", "timestamp": 1723140264, "time_this_iter_s": 15.067269086837769, "time_total_s": 1699.945642709732, "pid": 23280, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3bcf05ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1699.945642709732, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 39.78636363636363, "ram_util_percent": 80.02727272727272}}
