{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25166538683352646, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.019282529972218, "policy_loss": -0.0010124388712620925, "vf_loss": 4.019872407559995, "vf_explained_var": 0.0018055528244644247, "kl": 0.0021127734085552552, "entropy": 1.6072498739081085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.004733879824795, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.192077021624046, "policy_loss": -0.0025608086053075063, "vf_loss": 8.193156049112794, "vf_explained_var": 0.006292184193929036, "kl": 0.007408990801923123, "entropy": 1.6020818113019226, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 277.60000000000014, "episode_reward_min": -210.80000000000095, "episode_reward_mean": 62.9777777777775, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -274.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.69999999999996, "predator_policy": 140.0}, "policy_reward_mean": {"prey_policy": -3.9833333333334133, "predator_policy": 35.47222222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-210.80000000000095, -132.6000000000005, 62.999999999999794, -98.20000000000027, 255.9999999999991, -10.8999999999998, 35.00000000000036, 107.80000000000013, -2.199999999999984, 120.49999999999933, 183.09999999999954, 82.69999999999871, 277.60000000000014, 44.20000000000045, 193.09999999999928, 51.80000000000009, -35.79999999999972, 209.29999999999924], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-274.0, -164.8000000000006, -204.10000000000016, -59.499999999999964, 17.899999999999988, -10.900000000000006, -181.6000000000003, -127.60000000000008, 82.09999999999926, 173.89999999999984, -180.10000000000053, 72.19999999999965, 22.700000000000053, -21.6999999999999, 64.99999999999997, 39.800000000000225, -29.799999999999997, -135.4000000000001, -16.59999999999993, 61.099999999999994, 24.500000000000007, 158.60000000000005, 37.69999999999973, 20.000000000000014, 146.89999999999998, 130.7, -3.1000000000000436, 23.300000000000075, 20.000000000000014, 169.1, -238.30000000000027, 163.09999999999997, -118.29999999999993, -11.499999999999819, 181.69999999999996, 23.60000000000001], "policy_predator_policy_reward": [140.0, 88.0, 130.0, 1.0, 25.0, 31.0, 82.0, 129.0, 0.0, 0.0, 97.0, 0.0, 0.0, 34.0, 0.0, 3.0, 54.0, 109.0, 73.0, 3.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 4.0, 23.0, 104.0, 14.0, 80.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6149608530181117, "mean_inference_ms": 1.5978836659133182, "mean_action_processing_ms": 0.2585939799009508, "mean_env_wait_ms": 0.21585249050176236, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006266434987386067, "StateBufferConnector_ms": 0.004463063346015083, "ViewRequirementAgentConnector_ms": 0.09915431340535481}, "num_episodes": 18, "episode_return_max": 277.60000000000014, "episode_return_min": -210.80000000000095, "episode_return_mean": 62.9777777777775, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 406.5133567854703, "num_env_steps_trained_throughput_per_sec": 406.5133567854703, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 9839.787, "restore_workers_time_ms": 0.018, "training_step_time_ms": 9839.729, "sample_time_ms": 1274.089, "learn_time_ms": 8552.538, "learn_throughput": 467.697, "synch_weights_time_ms": 11.63}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "04dec_00002", "date": "2024-08-13_16-22-51", "timestamp": 1723580571, "time_this_iter_s": 9.881895780563354, "time_total_s": 9.881895780563354, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a2cdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9.881895780563354, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 39.826666666666675, "ram_util_percent": 83.76666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4752563706702656, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 4.174492299115216, "policy_loss": -0.0017706178569742454, "vf_loss": 4.175574903513389, "vf_explained_var": 0.007237635813062153, "kl": 0.00688016566822898, "entropy": 1.6074295880933287, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9356526640041796, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.01685653464504, "policy_loss": -0.0011111464183876122, "vf_loss": 7.016877358048051, "vf_explained_var": 0.00621254803642394, "kl": 0.005451614175395726, "entropy": 1.5943213654573631, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 277.60000000000014, "episode_reward_min": -210.80000000000095, "episode_reward_mean": 48.33611111111085, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -274.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.69999999999996, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -9.554166666666738, "predator_policy": 33.72222222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-210.80000000000095, -132.6000000000005, 62.999999999999794, -98.20000000000027, 255.9999999999991, -10.8999999999998, 35.00000000000036, 107.80000000000013, -2.199999999999984, 120.49999999999933, 183.09999999999954, 82.69999999999871, 277.60000000000014, 44.20000000000045, 193.09999999999928, 51.80000000000009, -35.79999999999972, 209.29999999999924, 98.29999999999899, -57.899999999999885, 26.800000000000082, -40.199999999999896, 31.500000000000238, -107.70000000000036, -83.7000000000001, 40.0000000000003, 58.4, 146.1999999999988, 230.3999999999993, 64.19999999999939, 4.299999999999953, 94.70000000000013, 17.300000000000203, -25.200000000000152, -18.799999999999997, 127.89999999999874], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-274.0, -164.8000000000006, -204.10000000000016, -59.499999999999964, 17.899999999999988, -10.900000000000006, -181.6000000000003, -127.60000000000008, 82.09999999999926, 173.89999999999984, -180.10000000000053, 72.19999999999965, 22.700000000000053, -21.6999999999999, 64.99999999999997, 39.800000000000225, -29.799999999999997, -135.4000000000001, -16.59999999999993, 61.099999999999994, 24.500000000000007, 158.60000000000005, 37.69999999999973, 20.000000000000014, 146.89999999999998, 130.7, -3.1000000000000436, 23.300000000000075, 20.000000000000014, 169.1, -238.30000000000027, 163.09999999999997, -118.29999999999993, -11.499999999999819, 181.69999999999996, 23.60000000000001, 20.000000000000014, 77.29999999999949, -127.00000000000011, -19.900000000000027, 33.500000000000085, -54.69999999999992, -59.49999999999986, -75.70000000000033, 20.000000000000014, -20.5, -267.70000000000016, 20.000000000000014, -240.39999999999992, 22.700000000000053, 20.000000000000014, 20.000000000000014, -8.800000000000042, -23.80000000000004, 20.000000000000014, 126.19999999999953, 70.39999999999971, 140.0, -137.2000000000001, 115.39999999999948, -24.099999999999802, -10.60000000000004, 79.1, -48.40000000000005, 13.399999999999977, -24.10000000000003, 32.60000000000023, -188.80000000000007, 32.0, -197.8000000000002, 40.70000000000023, 81.19999999999948], "policy_predator_policy_reward": [140.0, 88.0, 130.0, 1.0, 25.0, 31.0, 82.0, 129.0, 0.0, 0.0, 97.0, 0.0, 0.0, 34.0, 0.0, 3.0, 54.0, 109.0, 73.0, 3.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 4.0, 23.0, 104.0, 14.0, 80.0, 2.0, 2.0, 1.0, 0.0, 8.0, 81.0, 20.0, 28.0, 93.0, 2.0, 22.0, 10.0, 133.0, 7.0, 10.0, 124.0, 0.0, 0.0, 37.0, 54.0, 0.0, 0.0, 3.0, 17.0, 0.0, 86.0, 15.0, 24.0, 20.0, 44.0, 24.0, 4.0, 103.0, 28.0, 146.0, 1.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6041093123520354, "mean_inference_ms": 1.5936034640016474, "mean_action_processing_ms": 0.25605135672684265, "mean_env_wait_ms": 0.22776926838188727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006380677223205566, "StateBufferConnector_ms": 0.005154808362325032, "ViewRequirementAgentConnector_ms": 0.10345677534739177}, "num_episodes": 18, "episode_return_max": 277.60000000000014, "episode_return_min": -210.80000000000095, "episode_return_mean": 48.33611111111085, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 423.1404958677686, "num_env_steps_trained_throughput_per_sec": 423.1404958677686, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 9646.464, "restore_workers_time_ms": 0.026, "training_step_time_ms": 9646.395, "sample_time_ms": 1306.493, "learn_time_ms": 8327.537, "learn_throughput": 480.334, "synch_weights_time_ms": 11.134}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "04dec_00002", "date": "2024-08-13_16-23-03", "timestamp": 1723580583, "time_this_iter_s": 9.471184968948364, "time_total_s": 19.35308074951172, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b34ed280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 19.35308074951172, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 37.45, "ram_util_percent": 83.5875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45092064883343125, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.127445020246758, "policy_loss": -0.0009519070770010037, "vf_loss": 5.128064357036005, "vf_explained_var": 0.007913207818591405, "kl": 0.0033258797206202296, "entropy": 1.6064479487913625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7267134573724534, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.794799014752504, "policy_loss": -0.0005163693089757568, "vf_loss": 6.794550261926399, "vf_explained_var": 0.006058987107857195, "kl": 0.003825686830178932, "entropy": 1.5956182409215856, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 277.60000000000014, "episode_reward_min": -210.80000000000095, "episode_reward_mean": 32.83888888888867, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -274.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.69999999999996, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -20.025000000000063, "predator_policy": 36.44444444444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-210.80000000000095, -132.6000000000005, 62.999999999999794, -98.20000000000027, 255.9999999999991, -10.8999999999998, 35.00000000000036, 107.80000000000013, -2.199999999999984, 120.49999999999933, 183.09999999999954, 82.69999999999871, 277.60000000000014, 44.20000000000045, 193.09999999999928, 51.80000000000009, -35.79999999999972, 209.29999999999924, 98.29999999999899, -57.899999999999885, 26.800000000000082, -40.199999999999896, 31.500000000000238, -107.70000000000036, -83.7000000000001, 40.0000000000003, 58.4, 146.1999999999988, 230.3999999999993, 64.19999999999939, 4.299999999999953, 94.70000000000013, 17.300000000000203, -25.200000000000152, -18.799999999999997, 127.89999999999874, 98.39999999999966, -104.80000000000084, 58.900000000000254, 56.89999999999949, -10.699999999999722, 189.19999999999902, -28.499999999999787, 10.500000000000108, 153.3999999999996, -179.80000000000024, -76.80000000000086, 26.70000000000009, -42.19999999999972, -168.5, 31.100000000000406, 45.70000000000045, -42.80000000000071, 16.500000000000068], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-274.0, -164.8000000000006, -204.10000000000016, -59.499999999999964, 17.899999999999988, -10.900000000000006, -181.6000000000003, -127.60000000000008, 82.09999999999926, 173.89999999999984, -180.10000000000053, 72.19999999999965, 22.700000000000053, -21.6999999999999, 64.99999999999997, 39.800000000000225, -29.799999999999997, -135.4000000000001, -16.59999999999993, 61.099999999999994, 24.500000000000007, 158.60000000000005, 37.69999999999973, 20.000000000000014, 146.89999999999998, 130.7, -3.1000000000000436, 23.300000000000075, 20.000000000000014, 169.1, -238.30000000000027, 163.09999999999997, -118.29999999999993, -11.499999999999819, 181.69999999999996, 23.60000000000001, 20.000000000000014, 77.29999999999949, -127.00000000000011, -19.900000000000027, 33.500000000000085, -54.69999999999992, -59.49999999999986, -75.70000000000033, 20.000000000000014, -20.5, -267.70000000000016, 20.000000000000014, -240.39999999999992, 22.700000000000053, 20.000000000000014, 20.000000000000014, -8.800000000000042, -23.80000000000004, 20.000000000000014, 126.19999999999953, 70.39999999999971, 140.0, -137.2000000000001, 115.39999999999948, -24.099999999999802, -10.60000000000004, 79.1, -48.40000000000005, 13.399999999999977, -24.10000000000003, 32.60000000000023, -188.80000000000007, 32.0, -197.8000000000002, 40.70000000000023, 81.19999999999948, 20.000000000000014, 43.40000000000007, -29.199999999999797, -223.6000000000003, -7.899999999999988, 21.80000000000004, 20.000000000000014, -36.09999999999998, 20.000000000000014, -108.70000000000047, 64.10000000000018, 106.0999999999998, -116.49999999999997, 20.000000000000014, 24.50000000000008, -115.00000000000014, 34.40000000000019, 118.99999999999997, -254.20000000000022, -100.60000000000014, -7.899999999999952, -244.90000000000023, 3.1999999999999633, -20.499999999999964, -20.199999999999818, -127.00000000000074, -196.2999999999999, -140.20000000000002, -2.200000000000034, -15.700000000000035, 13.699999999999946, 29.000000000000167, -92.50000000000003, -16.299999999999898, -145.90000000000026, 7.400000000000027], "policy_predator_policy_reward": [140.0, 88.0, 130.0, 1.0, 25.0, 31.0, 82.0, 129.0, 0.0, 0.0, 97.0, 0.0, 0.0, 34.0, 0.0, 3.0, 54.0, 109.0, 73.0, 3.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 4.0, 23.0, 104.0, 14.0, 80.0, 2.0, 2.0, 1.0, 0.0, 8.0, 81.0, 20.0, 28.0, 93.0, 2.0, 22.0, 10.0, 133.0, 7.0, 10.0, 124.0, 0.0, 0.0, 37.0, 54.0, 0.0, 0.0, 3.0, 17.0, 0.0, 86.0, 15.0, 24.0, 20.0, 44.0, 24.0, 4.0, 103.0, 28.0, 146.0, 1.0, 6.0, 0.0, 31.0, 4.0, 32.0, 116.0, 45.0, 0.0, 0.0, 73.0, 77.0, 1.0, 0.0, 19.0, 68.0, 0.0, 23.0, 78.0, 0.0, 0.0, 76.0, 99.0, 45.0, 131.0, 44.0, 0.0, 37.0, 68.0, 61.0, 107.0, 0.0, 49.0, 0.0, 3.0, 55.0, 11.0, 44.0, 111.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5942286537058258, "mean_inference_ms": 1.56376458747726, "mean_action_processing_ms": 0.2510669045523541, "mean_env_wait_ms": 0.22607923286852416, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006518540558991609, "StateBufferConnector_ms": 0.0044133928087022566, "ViewRequirementAgentConnector_ms": 0.1006448710406268}, "num_episodes": 18, "episode_return_max": 277.60000000000014, "episode_return_min": -210.80000000000095, "episode_return_mean": 32.83888888888867, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 437.30983444685126, "num_env_steps_trained_throughput_per_sec": 437.30983444685126, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 9479.923, "restore_workers_time_ms": 0.022, "training_step_time_ms": 9479.864, "sample_time_ms": 1227.519, "learn_time_ms": 8239.955, "learn_throughput": 485.44, "synch_weights_time_ms": 11.314}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "04dec_00002", "date": "2024-08-13_16-23-12", "timestamp": 1723580592, "time_this_iter_s": 9.193910837173462, "time_total_s": 28.54699158668518, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b34ede50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 28.54699158668518, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 35.307692307692314, "ram_util_percent": 82.25384615384615}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.371993249435983, "cur_kl_coeff": 0.05, "cur_lr": 0.00010000000000000003, "total_loss": 4.5281356448218935, "policy_loss": -0.0014561129312607504, "vf_loss": 4.529331521508555, "vf_explained_var": 0.010934121110451915, "kl": 0.005204869111476578, "entropy": 1.6045687257297456, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6037189173398825, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 6.306227568722276, "policy_loss": -0.004900244177471866, "vf_loss": 6.309325020401566, "vf_explained_var": 0.005154697920279528, "kl": 0.01802791128185216, "entropy": 1.5865587401642371, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 277.60000000000014, "episode_reward_min": -210.80000000000095, "episode_reward_mean": 28.097222222222015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -275.19999999999925, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.69999999999996, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -22.64583333333339, "predator_policy": 36.69444444444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-210.80000000000095, -132.6000000000005, 62.999999999999794, -98.20000000000027, 255.9999999999991, -10.8999999999998, 35.00000000000036, 107.80000000000013, -2.199999999999984, 120.49999999999933, 183.09999999999954, 82.69999999999871, 277.60000000000014, 44.20000000000045, 193.09999999999928, 51.80000000000009, -35.79999999999972, 209.29999999999924, 98.29999999999899, -57.899999999999885, 26.800000000000082, -40.199999999999896, 31.500000000000238, -107.70000000000036, -83.7000000000001, 40.0000000000003, 58.4, 146.1999999999988, 230.3999999999993, 64.19999999999939, 4.299999999999953, 94.70000000000013, 17.300000000000203, -25.200000000000152, -18.799999999999997, 127.89999999999874, 98.39999999999966, -104.80000000000084, 58.900000000000254, 56.89999999999949, -10.699999999999722, 189.19999999999902, -28.499999999999787, 10.500000000000108, 153.3999999999996, -179.80000000000024, -76.80000000000086, 26.70000000000009, -42.19999999999972, -168.5, 31.100000000000406, 45.70000000000045, -42.80000000000071, 16.500000000000068, -17.399999999999913, 79.49999999999895, 153.79999999999947, -28.099999999999994, -142.80000000000106, -16.29999999999987, 187.59999999999928, -46.69999999999972, -9.899999999999903, -76.2999999999999, -193.5, 44.500000000000114, -8.6, 31.80000000000048, 58.90000000000039, 44.50000000000029, 74.99999999999908, 113.69999999999936], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-274.0, -164.8000000000006, -204.10000000000016, -59.499999999999964, 17.899999999999988, -10.900000000000006, -181.6000000000003, -127.60000000000008, 82.09999999999926, 173.89999999999984, -180.10000000000053, 72.19999999999965, 22.700000000000053, -21.6999999999999, 64.99999999999997, 39.800000000000225, -29.799999999999997, -135.4000000000001, -16.59999999999993, 61.099999999999994, 24.500000000000007, 158.60000000000005, 37.69999999999973, 20.000000000000014, 146.89999999999998, 130.7, -3.1000000000000436, 23.300000000000075, 20.000000000000014, 169.1, -238.30000000000027, 163.09999999999997, -118.29999999999993, -11.499999999999819, 181.69999999999996, 23.60000000000001, 20.000000000000014, 77.29999999999949, -127.00000000000011, -19.900000000000027, 33.500000000000085, -54.69999999999992, -59.49999999999986, -75.70000000000033, 20.000000000000014, -20.5, -267.70000000000016, 20.000000000000014, -240.39999999999992, 22.700000000000053, 20.000000000000014, 20.000000000000014, -8.800000000000042, -23.80000000000004, 20.000000000000014, 126.19999999999953, 70.39999999999971, 140.0, -137.2000000000001, 115.39999999999948, -24.099999999999802, -10.60000000000004, 79.1, -48.40000000000005, 13.399999999999977, -24.10000000000003, 32.60000000000023, -188.80000000000007, 32.0, -197.8000000000002, 40.70000000000023, 81.19999999999948, 20.000000000000014, 43.40000000000007, -29.199999999999797, -223.6000000000003, -7.899999999999988, 21.80000000000004, 20.000000000000014, -36.09999999999998, 20.000000000000014, -108.70000000000047, 64.10000000000018, 106.0999999999998, -116.49999999999997, 20.000000000000014, 24.50000000000008, -115.00000000000014, 34.40000000000019, 118.99999999999997, -254.20000000000022, -100.60000000000014, -7.899999999999952, -244.90000000000023, 3.1999999999999633, -20.499999999999964, -20.199999999999818, -127.00000000000074, -196.2999999999999, -140.20000000000002, -2.200000000000034, -15.700000000000035, 13.699999999999946, 29.000000000000167, -92.50000000000003, -16.299999999999898, -145.90000000000026, 7.400000000000027, -19.89999999999992, -113.50000000000011, 48.49999999999952, -27.999999999999858, 16.100000000000094, 103.70000000000005, -92.19999999999997, -97.90000000000023, -275.19999999999925, -55.60000000000025, 76.99999999999966, -217.30000000000047, 20.000000000000014, 167.5999999999999, 20.000000000000014, -156.70000000000041, -18.09999999999995, -101.80000000000048, -35.50000000000003, -101.80000000000004, -99.39999999999996, -249.10000000000002, -28.299999999999812, 0.8000000000000639, -82.60000000000028, 20.000000000000014, 36.20000000000025, -27.39999999999999, 38.90000000000018, 20.000000000000014, 24.500000000000007, 20.000000000000014, 90.7999999999995, -65.80000000000004, 46.10000000000019, 17.599999999999962], "policy_predator_policy_reward": [140.0, 88.0, 130.0, 1.0, 25.0, 31.0, 82.0, 129.0, 0.0, 0.0, 97.0, 0.0, 0.0, 34.0, 0.0, 3.0, 54.0, 109.0, 73.0, 3.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 4.0, 23.0, 104.0, 14.0, 80.0, 2.0, 2.0, 1.0, 0.0, 8.0, 81.0, 20.0, 28.0, 93.0, 2.0, 22.0, 10.0, 133.0, 7.0, 10.0, 124.0, 0.0, 0.0, 37.0, 54.0, 0.0, 0.0, 3.0, 17.0, 0.0, 86.0, 15.0, 24.0, 20.0, 44.0, 24.0, 4.0, 103.0, 28.0, 146.0, 1.0, 6.0, 0.0, 31.0, 4.0, 32.0, 116.0, 45.0, 0.0, 0.0, 73.0, 77.0, 1.0, 0.0, 19.0, 68.0, 0.0, 23.0, 78.0, 0.0, 0.0, 76.0, 99.0, 45.0, 131.0, 44.0, 0.0, 37.0, 68.0, 61.0, 107.0, 0.0, 49.0, 0.0, 3.0, 55.0, 11.0, 44.0, 111.0, 52.0, 64.0, 25.0, 34.0, 13.0, 21.0, 55.0, 107.0, 69.0, 119.0, 113.0, 11.0, 0.0, 0.0, 72.0, 18.0, 52.0, 58.0, 61.0, 0.0, 99.0, 56.0, 44.0, 28.0, 54.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5855783732173959, "mean_inference_ms": 1.5333179566645545, "mean_action_processing_ms": 0.24635694711110082, "mean_env_wait_ms": 0.22203549584183213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006240275171067979, "StateBufferConnector_ms": 0.003988875283135308, "ViewRequirementAgentConnector_ms": 0.09730060895284016}, "num_episodes": 18, "episode_return_max": 277.60000000000014, "episode_return_min": -210.80000000000095, "episode_return_mean": 28.097222222222015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 450.1412290867928, "num_env_steps_trained_throughput_per_sec": 450.1412290867928, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 9331.469, "restore_workers_time_ms": 0.02, "training_step_time_ms": 9331.414, "sample_time_ms": 1177.76, "learn_time_ms": 8141.136, "learn_throughput": 491.332, "synch_weights_time_ms": 11.513}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "04dec_00002", "date": "2024-08-13_16-23-21", "timestamp": 1723580601, "time_this_iter_s": 8.890668153762817, "time_total_s": 37.437659740448, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3575ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 37.437659740448, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 31.023076923076925, "ram_util_percent": 82.19230769230768}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3863796568657986, "cur_kl_coeff": 0.05, "cur_lr": 0.00010000000000000003, "total_loss": 4.780533406217263, "policy_loss": -0.002291438549697872, "vf_loss": 4.782437320613356, "vf_explained_var": 0.0036989014930826018, "kl": 0.007750541693157153, "entropy": 1.6046673480795806, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3354228532582364, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 6.924202614738828, "policy_loss": -0.0023607740893211, "vf_loss": 6.925578720607454, "vf_explained_var": 0.015680277852154284, "kl": 0.00984665342126119, "entropy": 1.573182756434042, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 277.60000000000014, "episode_reward_min": -210.80000000000095, "episode_reward_mean": 32.584848484848294, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -306.99999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.69999999999996, "predator_policy": 157.0}, "policy_reward_mean": {"prey_policy": -18.889393939393983, "predator_policy": 35.18181818181818}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-210.80000000000095, -132.6000000000005, 62.999999999999794, -98.20000000000027, 255.9999999999991, -10.8999999999998, 35.00000000000036, 107.80000000000013, -2.199999999999984, 120.49999999999933, 183.09999999999954, 82.69999999999871, 277.60000000000014, 44.20000000000045, 193.09999999999928, 51.80000000000009, -35.79999999999972, 209.29999999999924, 98.29999999999899, -57.899999999999885, 26.800000000000082, -40.199999999999896, 31.500000000000238, -107.70000000000036, -83.7000000000001, 40.0000000000003, 58.4, 146.1999999999988, 230.3999999999993, 64.19999999999939, 4.299999999999953, 94.70000000000013, 17.300000000000203, -25.200000000000152, -18.799999999999997, 127.89999999999874, 98.39999999999966, -104.80000000000084, 58.900000000000254, 56.89999999999949, -10.699999999999722, 189.19999999999902, -28.499999999999787, 10.500000000000108, 153.3999999999996, -179.80000000000024, -76.80000000000086, 26.70000000000009, -42.19999999999972, -168.5, 31.100000000000406, 45.70000000000045, -42.80000000000071, 16.500000000000068, -17.399999999999913, 79.49999999999895, 153.79999999999947, -28.099999999999994, -142.80000000000106, -16.29999999999987, 187.59999999999928, -46.69999999999972, -9.899999999999903, -76.2999999999999, -193.5, 44.500000000000114, -8.6, 31.80000000000048, 58.90000000000039, 44.50000000000029, 74.99999999999908, 113.69999999999936, 30.600000000000303, -60.899999999999814, 74.29999999999946, 127.19999999999928, 161.29999999999933, 24.900000000000134, -10.899999999999967, 88.79999999999997, 115.29999999999956, 55.30000000000034, -38.10000000000003, -50.399999999999885, 70.09999999999911, 1.600000000000124, 35.90000000000025, 0.3999999999999433, -25.499999999999872, 5.60000000000016, 70.39999999999964, 48.100000000000286, 144.2999999999989, 88.69999999999915, 21.900000000000304, 75.70000000000016, -33.199999999999676, 90.40000000000022, 91.10000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-274.0, -164.8000000000006, -204.10000000000016, -59.499999999999964, 17.899999999999988, -10.900000000000006, -181.6000000000003, -127.60000000000008, 82.09999999999926, 173.89999999999984, -180.10000000000053, 72.19999999999965, 22.700000000000053, -21.6999999999999, 64.99999999999997, 39.800000000000225, -29.799999999999997, -135.4000000000001, -16.59999999999993, 61.099999999999994, 24.500000000000007, 158.60000000000005, 37.69999999999973, 20.000000000000014, 146.89999999999998, 130.7, -3.1000000000000436, 23.300000000000075, 20.000000000000014, 169.1, -238.30000000000027, 163.09999999999997, -118.29999999999993, -11.499999999999819, 181.69999999999996, 23.60000000000001, 20.000000000000014, 77.29999999999949, -127.00000000000011, -19.900000000000027, 33.500000000000085, -54.69999999999992, -59.49999999999986, -75.70000000000033, 20.000000000000014, -20.5, -267.70000000000016, 20.000000000000014, -240.39999999999992, 22.700000000000053, 20.000000000000014, 20.000000000000014, -8.800000000000042, -23.80000000000004, 20.000000000000014, 126.19999999999953, 70.39999999999971, 140.0, -137.2000000000001, 115.39999999999948, -24.099999999999802, -10.60000000000004, 79.1, -48.40000000000005, 13.399999999999977, -24.10000000000003, 32.60000000000023, -188.80000000000007, 32.0, -197.8000000000002, 40.70000000000023, 81.19999999999948, 20.000000000000014, 43.40000000000007, -29.199999999999797, -223.6000000000003, -7.899999999999988, 21.80000000000004, 20.000000000000014, -36.09999999999998, 20.000000000000014, -108.70000000000047, 64.10000000000018, 106.0999999999998, -116.49999999999997, 20.000000000000014, 24.50000000000008, -115.00000000000014, 34.40000000000019, 118.99999999999997, -254.20000000000022, -100.60000000000014, -7.899999999999952, -244.90000000000023, 3.1999999999999633, -20.499999999999964, -20.199999999999818, -127.00000000000074, -196.2999999999999, -140.20000000000002, -2.200000000000034, -15.700000000000035, 13.699999999999946, 29.000000000000167, -92.50000000000003, -16.299999999999898, -145.90000000000026, 7.400000000000027, -19.89999999999992, -113.50000000000011, 48.49999999999952, -27.999999999999858, 16.100000000000094, 103.70000000000005, -92.19999999999997, -97.90000000000023, -275.19999999999925, -55.60000000000025, 76.99999999999966, -217.30000000000047, 20.000000000000014, 167.5999999999999, 20.000000000000014, -156.70000000000041, -18.09999999999995, -101.80000000000048, -35.50000000000003, -101.80000000000004, -99.39999999999996, -249.10000000000002, -28.299999999999812, 0.8000000000000639, -82.60000000000028, 20.000000000000014, 36.20000000000025, -27.39999999999999, 38.90000000000018, 20.000000000000014, 24.500000000000007, 20.000000000000014, 90.7999999999995, -65.80000000000004, 46.10000000000019, 17.599999999999962, 41.60000000000025, -39.99999999999984, -306.99999999999966, 88.09999999999971, 33.50000000000024, 36.80000000000012, 78.7999999999998, 34.40000000000012, -29.20000000000013, 117.49999999999957, 14.899999999999999, -106.00000000000003, -64.29999999999995, -55.599999999999895, 134.3, -200.50000000000014, 71.3, 20.000000000000014, -33.09999999999981, 52.400000000000226, -129.1, 20.000000000000014, -173.20000000000007, -41.20000000000002, 34.10000000000011, 20.000000000000014, -41.799999999999834, -49.59999999999998, 22.700000000000053, -20.800000000000033, 78.19999999999986, -179.7999999999999, -33.39999999999995, -63.100000000000044, 45.200000000000074, -97.60000000000072, -66.10000000000005, 24.500000000000064, 28.100000000000115, 20.000000000000014, 107.29999999999963, 32.00000000000022, 64.70000000000002, 20.000000000000014, -57.099999999999916, 20.000000000000014, -39.09999999999994, 81.8000000000001, -45.09999999999977, -24.099999999999746, 54.20000000000002, 36.19999999999999, 150.49999999999983, -165.4000000000005], "policy_predator_policy_reward": [140.0, 88.0, 130.0, 1.0, 25.0, 31.0, 82.0, 129.0, 0.0, 0.0, 97.0, 0.0, 0.0, 34.0, 0.0, 3.0, 54.0, 109.0, 73.0, 3.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 4.0, 23.0, 104.0, 14.0, 80.0, 2.0, 2.0, 1.0, 0.0, 8.0, 81.0, 20.0, 28.0, 93.0, 2.0, 22.0, 10.0, 133.0, 7.0, 10.0, 124.0, 0.0, 0.0, 37.0, 54.0, 0.0, 0.0, 3.0, 17.0, 0.0, 86.0, 15.0, 24.0, 20.0, 44.0, 24.0, 4.0, 103.0, 28.0, 146.0, 1.0, 6.0, 0.0, 31.0, 4.0, 32.0, 116.0, 45.0, 0.0, 0.0, 73.0, 77.0, 1.0, 0.0, 19.0, 68.0, 0.0, 23.0, 78.0, 0.0, 0.0, 76.0, 99.0, 45.0, 131.0, 44.0, 0.0, 37.0, 68.0, 61.0, 107.0, 0.0, 49.0, 0.0, 3.0, 55.0, 11.0, 44.0, 111.0, 52.0, 64.0, 25.0, 34.0, 13.0, 21.0, 55.0, 107.0, 69.0, 119.0, 113.0, 11.0, 0.0, 0.0, 72.0, 18.0, 52.0, 58.0, 61.0, 0.0, 99.0, 56.0, 44.0, 28.0, 54.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 50.0, 0.0, 29.0, 1.0, 157.0, 0.0, 4.0, 14.0, 0.0, 46.0, 27.0, 106.0, 10.0, 71.0, 38.0, 126.0, 29.0, 24.0, 0.0, 36.0, 0.0, 21.0, 50.0, 95.0, 69.0, 16.0, 0.0, 0.0, 93.0, 15.0, 19.0, 0.0, 102.0, 35.0, 36.0, 10.0, 48.0, 42.0, 70.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 59.0, 1.0, 32.0, 36.0, 0.0, 0.0, 0.0, 93.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.577207313609447, "mean_inference_ms": 1.5010063535577511, "mean_action_processing_ms": 0.24152153878441077, "mean_env_wait_ms": 0.21655830797691666, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005836920304731889, "StateBufferConnector_ms": 0.003780981506964173, "ViewRequirementAgentConnector_ms": 0.09323936520200787}, "num_episodes": 27, "episode_return_max": 277.60000000000014, "episode_return_min": -210.80000000000095, "episode_return_mean": 32.584848484848294, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 445.63170608713597, "num_env_steps_trained_throughput_per_sec": 445.63170608713597, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 9260.381, "restore_workers_time_ms": 0.019, "training_step_time_ms": 9260.33, "sample_time_ms": 1160.108, "learn_time_ms": 8087.56, "learn_throughput": 494.587, "synch_weights_time_ms": 11.689}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "04dec_00002", "date": "2024-08-13_16-23-30", "timestamp": 1723580610, "time_this_iter_s": 8.982545852661133, "time_total_s": 46.42020559310913, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0456a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 46.42020559310913, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 30.069230769230767, "ram_util_percent": 82.11538461538463}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45240152559425467, "cur_kl_coeff": 0.05, "cur_lr": 0.00010000000000000003, "total_loss": 3.0082109671421153, "policy_loss": -0.00391677051139552, "vf_loss": 3.011634240768574, "vf_explained_var": 0.014824669733249321, "kl": 0.009870022922614971, "entropy": 1.605280135296009, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.52337917717834, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.9791413186088445, "policy_loss": -0.0046871312093186785, "vf_loss": 5.982341317524986, "vf_explained_var": 0.01199484495889573, "kl": 0.014871318226735363, "entropy": 1.5896891059068146, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 230.3999999999993, "episode_reward_min": -193.5, "episode_reward_mean": 30.20399999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -306.99999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.69999999999996, "predator_policy": 157.0}, "policy_reward_mean": {"prey_policy": -17.788000000000032, "predator_policy": 32.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [209.29999999999924, 98.29999999999899, -57.899999999999885, 26.800000000000082, -40.199999999999896, 31.500000000000238, -107.70000000000036, -83.7000000000001, 40.0000000000003, 58.4, 146.1999999999988, 230.3999999999993, 64.19999999999939, 4.299999999999953, 94.70000000000013, 17.300000000000203, -25.200000000000152, -18.799999999999997, 127.89999999999874, 98.39999999999966, -104.80000000000084, 58.900000000000254, 56.89999999999949, -10.699999999999722, 189.19999999999902, -28.499999999999787, 10.500000000000108, 153.3999999999996, -179.80000000000024, -76.80000000000086, 26.70000000000009, -42.19999999999972, -168.5, 31.100000000000406, 45.70000000000045, -42.80000000000071, 16.500000000000068, -17.399999999999913, 79.49999999999895, 153.79999999999947, -28.099999999999994, -142.80000000000106, -16.29999999999987, 187.59999999999928, -46.69999999999972, -9.899999999999903, -76.2999999999999, -193.5, 44.500000000000114, -8.6, 31.80000000000048, 58.90000000000039, 44.50000000000029, 74.99999999999908, 113.69999999999936, 30.600000000000303, -60.899999999999814, 74.29999999999946, 127.19999999999928, 161.29999999999933, 24.900000000000134, -10.899999999999967, 88.79999999999997, 115.29999999999956, 55.30000000000034, -38.10000000000003, -50.399999999999885, 70.09999999999911, 1.600000000000124, 35.90000000000025, 0.3999999999999433, -25.499999999999872, 5.60000000000016, 70.39999999999964, 48.100000000000286, 144.2999999999989, 88.69999999999915, 21.900000000000304, 75.70000000000016, -33.199999999999676, 90.40000000000022, 91.10000000000007, -83.70000000000014, 167.59999999999945, -24.19999999999989, -6.499999999999718, 146.29999999999882, 120.29999999999887, 19.699999999999992, 31.90000000000018, 115.49999999999866, -18.2999999999996, -21.79999999999975, 88.19999999999993, 86.7999999999991, 74.59999999999985, 133.89999999999932, -43.39999999999985, 66.1999999999999, -134.30000000000123], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [181.69999999999996, 23.60000000000001, 20.000000000000014, 77.29999999999949, -127.00000000000011, -19.900000000000027, 33.500000000000085, -54.69999999999992, -59.49999999999986, -75.70000000000033, 20.000000000000014, -20.5, -267.70000000000016, 20.000000000000014, -240.39999999999992, 22.700000000000053, 20.000000000000014, 20.000000000000014, -8.800000000000042, -23.80000000000004, 20.000000000000014, 126.19999999999953, 70.39999999999971, 140.0, -137.2000000000001, 115.39999999999948, -24.099999999999802, -10.60000000000004, 79.1, -48.40000000000005, 13.399999999999977, -24.10000000000003, 32.60000000000023, -188.80000000000007, 32.0, -197.8000000000002, 40.70000000000023, 81.19999999999948, 20.000000000000014, 43.40000000000007, -29.199999999999797, -223.6000000000003, -7.899999999999988, 21.80000000000004, 20.000000000000014, -36.09999999999998, 20.000000000000014, -108.70000000000047, 64.10000000000018, 106.0999999999998, -116.49999999999997, 20.000000000000014, 24.50000000000008, -115.00000000000014, 34.40000000000019, 118.99999999999997, -254.20000000000022, -100.60000000000014, -7.899999999999952, -244.90000000000023, 3.1999999999999633, -20.499999999999964, -20.199999999999818, -127.00000000000074, -196.2999999999999, -140.20000000000002, -2.200000000000034, -15.700000000000035, 13.699999999999946, 29.000000000000167, -92.50000000000003, -16.299999999999898, -145.90000000000026, 7.400000000000027, -19.89999999999992, -113.50000000000011, 48.49999999999952, -27.999999999999858, 16.100000000000094, 103.70000000000005, -92.19999999999997, -97.90000000000023, -275.19999999999925, -55.60000000000025, 76.99999999999966, -217.30000000000047, 20.000000000000014, 167.5999999999999, 20.000000000000014, -156.70000000000041, -18.09999999999995, -101.80000000000048, -35.50000000000003, -101.80000000000004, -99.39999999999996, -249.10000000000002, -28.299999999999812, 0.8000000000000639, -82.60000000000028, 20.000000000000014, 36.20000000000025, -27.39999999999999, 38.90000000000018, 20.000000000000014, 24.500000000000007, 20.000000000000014, 90.7999999999995, -65.80000000000004, 46.10000000000019, 17.599999999999962, 41.60000000000025, -39.99999999999984, -306.99999999999966, 88.09999999999971, 33.50000000000024, 36.80000000000012, 78.7999999999998, 34.40000000000012, -29.20000000000013, 117.49999999999957, 14.899999999999999, -106.00000000000003, -64.29999999999995, -55.599999999999895, 134.3, -200.50000000000014, 71.3, 20.000000000000014, -33.09999999999981, 52.400000000000226, -129.1, 20.000000000000014, -173.20000000000007, -41.20000000000002, 34.10000000000011, 20.000000000000014, -41.799999999999834, -49.59999999999998, 22.700000000000053, -20.800000000000033, 78.19999999999986, -179.7999999999999, -33.39999999999995, -63.100000000000044, 45.200000000000074, -97.60000000000072, -66.10000000000005, 24.500000000000064, 28.100000000000115, 20.000000000000014, 107.29999999999963, 32.00000000000022, 64.70000000000002, 20.000000000000014, -57.099999999999916, 20.000000000000014, -39.09999999999994, 81.8000000000001, -45.09999999999977, -24.099999999999746, 54.20000000000002, 36.19999999999999, 150.49999999999983, -165.4000000000005, -87.09999999999985, -97.60000000000073, -22.89999999999987, 144.49999999999997, -165.70000000000016, 9.499999999999986, -55.300000000000324, -26.199999999999775, 91.69999999999948, 50.60000000000017, 91.69999999999987, 20.600000000000197, -20.799999999999883, -8.500000000000007, -3.099999999999958, 20.000000000000014, 19.400000000000023, 64.1000000000002, -1.5999999999997883, -93.70000000000076, -45.39999999999991, -51.40000000000005, 75.79999999999997, 1.4000000000000146, 20.000000000000014, 66.79999999999994, 20.000000000000014, 38.60000000000017, 98.29999999999959, -3.399999999999905, -57.69999999999977, -33.69999999999977, -43.29999999999989, 51.500000000000114, -112.60000000000056, -120.70000000000068], "policy_predator_policy_reward": [2.0, 2.0, 1.0, 0.0, 8.0, 81.0, 20.0, 28.0, 93.0, 2.0, 22.0, 10.0, 133.0, 7.0, 10.0, 124.0, 0.0, 0.0, 37.0, 54.0, 0.0, 0.0, 3.0, 17.0, 0.0, 86.0, 15.0, 24.0, 20.0, 44.0, 24.0, 4.0, 103.0, 28.0, 146.0, 1.0, 6.0, 0.0, 31.0, 4.0, 32.0, 116.0, 45.0, 0.0, 0.0, 73.0, 77.0, 1.0, 0.0, 19.0, 68.0, 0.0, 23.0, 78.0, 0.0, 0.0, 76.0, 99.0, 45.0, 131.0, 44.0, 0.0, 37.0, 68.0, 61.0, 107.0, 0.0, 49.0, 0.0, 3.0, 55.0, 11.0, 44.0, 111.0, 52.0, 64.0, 25.0, 34.0, 13.0, 21.0, 55.0, 107.0, 69.0, 119.0, 113.0, 11.0, 0.0, 0.0, 72.0, 18.0, 52.0, 58.0, 61.0, 0.0, 99.0, 56.0, 44.0, 28.0, 54.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 50.0, 0.0, 29.0, 1.0, 157.0, 0.0, 4.0, 14.0, 0.0, 46.0, 27.0, 106.0, 10.0, 71.0, 38.0, 126.0, 29.0, 24.0, 0.0, 36.0, 0.0, 21.0, 50.0, 95.0, 69.0, 16.0, 0.0, 0.0, 93.0, 15.0, 19.0, 0.0, 102.0, 35.0, 36.0, 10.0, 48.0, 42.0, 70.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 59.0, 1.0, 32.0, 36.0, 0.0, 0.0, 0.0, 93.0, 13.0, 57.0, 44.0, 46.0, 0.0, 54.0, 78.0, 43.0, 32.0, 4.0, 0.0, 7.0, 1.0, 0.0, 49.0, 4.0, 11.0, 29.0, 3.0, 19.0, 58.0, 34.0, 41.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 30.0, 42.0, 6.0, 27.0, 31.0, 0.0, 99.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5662198113895256, "mean_inference_ms": 1.4678422871629493, "mean_action_processing_ms": 0.2360128859099141, "mean_env_wait_ms": 0.21340568927507847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005327939987182617, "StateBufferConnector_ms": 0.003484368324279785, "ViewRequirementAgentConnector_ms": 0.09174776077270508}, "num_episodes": 18, "episode_return_max": 230.3999999999993, "episode_return_min": -193.5, "episode_return_mean": 30.20399999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 446.56011007111175, "num_env_steps_trained_throughput_per_sec": 446.56011007111175, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 9209.88, "restore_workers_time_ms": 0.018, "training_step_time_ms": 9209.829, "sample_time_ms": 1148.918, "learn_time_ms": 8048.239, "learn_throughput": 497.003, "synch_weights_time_ms": 11.71}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "04dec_00002", "date": "2024-08-13_16-23-39", "timestamp": 1723580619, "time_this_iter_s": 8.995664119720459, "time_total_s": 55.41586971282959, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b35871f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 55.41586971282959, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 29.800000000000004, "ram_util_percent": 81.12307692307694}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.385913170397124, "cur_kl_coeff": 0.05, "cur_lr": 0.00010000000000000003, "total_loss": 4.4157473757153465, "policy_loss": -0.0010743533501342412, "vf_loss": 4.416603891937821, "vf_explained_var": 0.0026709861225552027, "kl": 0.00435708359824737, "entropy": 1.5919417363625985, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4076305002604843, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 6.557260106101869, "policy_loss": -0.00314096868205717, "vf_loss": 6.558954638274258, "vf_explained_var": 0.016943079233169556, "kl": 0.014464441760720186, "entropy": 1.5974588628799196, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 198.89999999999966, "episode_reward_min": -193.5, "episode_reward_mean": 25.67099999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -311.80000000000024, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.5999999999999, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -21.884500000000035, "predator_policy": 34.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [127.89999999999874, 98.39999999999966, -104.80000000000084, 58.900000000000254, 56.89999999999949, -10.699999999999722, 189.19999999999902, -28.499999999999787, 10.500000000000108, 153.3999999999996, -179.80000000000024, -76.80000000000086, 26.70000000000009, -42.19999999999972, -168.5, 31.100000000000406, 45.70000000000045, -42.80000000000071, 16.500000000000068, -17.399999999999913, 79.49999999999895, 153.79999999999947, -28.099999999999994, -142.80000000000106, -16.29999999999987, 187.59999999999928, -46.69999999999972, -9.899999999999903, -76.2999999999999, -193.5, 44.500000000000114, -8.6, 31.80000000000048, 58.90000000000039, 44.50000000000029, 74.99999999999908, 113.69999999999936, 30.600000000000303, -60.899999999999814, 74.29999999999946, 127.19999999999928, 161.29999999999933, 24.900000000000134, -10.899999999999967, 88.79999999999997, 115.29999999999956, 55.30000000000034, -38.10000000000003, -50.399999999999885, 70.09999999999911, 1.600000000000124, 35.90000000000025, 0.3999999999999433, -25.499999999999872, 5.60000000000016, 70.39999999999964, 48.100000000000286, 144.2999999999989, 88.69999999999915, 21.900000000000304, 75.70000000000016, -33.199999999999676, 90.40000000000022, 91.10000000000007, -83.70000000000014, 167.59999999999945, -24.19999999999989, -6.499999999999718, 146.29999999999882, 120.29999999999887, 19.699999999999992, 31.90000000000018, 115.49999999999866, -18.2999999999996, -21.79999999999975, 88.19999999999993, 86.7999999999991, 74.59999999999985, 133.89999999999932, -43.39999999999985, 66.1999999999999, -134.30000000000123, 198.89999999999966, -44.500000000000014, -143.50000000000097, 55.20000000000005, -141.100000000001, -88.90000000000043, 110.19999999999888, -46.999999999999794, 33.60000000000019, 67.99999999999912, 82.29999999999917, 92.49999999999955, -35.099999999999646, 158.79999999999987, 15.300000000000246, 9.999999999999948, 32.5000000000001, -122.60000000000062], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.70000000000023, 81.19999999999948, 20.000000000000014, 43.40000000000007, -29.199999999999797, -223.6000000000003, -7.899999999999988, 21.80000000000004, 20.000000000000014, -36.09999999999998, 20.000000000000014, -108.70000000000047, 64.10000000000018, 106.0999999999998, -116.49999999999997, 20.000000000000014, 24.50000000000008, -115.00000000000014, 34.40000000000019, 118.99999999999997, -254.20000000000022, -100.60000000000014, -7.899999999999952, -244.90000000000023, 3.1999999999999633, -20.499999999999964, -20.199999999999818, -127.00000000000074, -196.2999999999999, -140.20000000000002, -2.200000000000034, -15.700000000000035, 13.699999999999946, 29.000000000000167, -92.50000000000003, -16.299999999999898, -145.90000000000026, 7.400000000000027, -19.89999999999992, -113.50000000000011, 48.49999999999952, -27.999999999999858, 16.100000000000094, 103.70000000000005, -92.19999999999997, -97.90000000000023, -275.19999999999925, -55.60000000000025, 76.99999999999966, -217.30000000000047, 20.000000000000014, 167.5999999999999, 20.000000000000014, -156.70000000000041, -18.09999999999995, -101.80000000000048, -35.50000000000003, -101.80000000000004, -99.39999999999996, -249.10000000000002, -28.299999999999812, 0.8000000000000639, -82.60000000000028, 20.000000000000014, 36.20000000000025, -27.39999999999999, 38.90000000000018, 20.000000000000014, 24.500000000000007, 20.000000000000014, 90.7999999999995, -65.80000000000004, 46.10000000000019, 17.599999999999962, 41.60000000000025, -39.99999999999984, -306.99999999999966, 88.09999999999971, 33.50000000000024, 36.80000000000012, 78.7999999999998, 34.40000000000012, -29.20000000000013, 117.49999999999957, 14.899999999999999, -106.00000000000003, -64.29999999999995, -55.599999999999895, 134.3, -200.50000000000014, 71.3, 20.000000000000014, -33.09999999999981, 52.400000000000226, -129.1, 20.000000000000014, -173.20000000000007, -41.20000000000002, 34.10000000000011, 20.000000000000014, -41.799999999999834, -49.59999999999998, 22.700000000000053, -20.800000000000033, 78.19999999999986, -179.7999999999999, -33.39999999999995, -63.100000000000044, 45.200000000000074, -97.60000000000072, -66.10000000000005, 24.500000000000064, 28.100000000000115, 20.000000000000014, 107.29999999999963, 32.00000000000022, 64.70000000000002, 20.000000000000014, -57.099999999999916, 20.000000000000014, -39.09999999999994, 81.8000000000001, -45.09999999999977, -24.099999999999746, 54.20000000000002, 36.19999999999999, 150.49999999999983, -165.4000000000005, -87.09999999999985, -97.60000000000073, -22.89999999999987, 144.49999999999997, -165.70000000000016, 9.499999999999986, -55.300000000000324, -26.199999999999775, 91.69999999999948, 50.60000000000017, 91.69999999999987, 20.600000000000197, -20.799999999999883, -8.500000000000007, -3.099999999999958, 20.000000000000014, 19.400000000000023, 64.1000000000002, -1.5999999999997883, -93.70000000000076, -45.39999999999991, -51.40000000000005, 75.79999999999997, 1.4000000000000146, 20.000000000000014, 66.79999999999994, 20.000000000000014, 38.60000000000017, 98.29999999999959, -3.399999999999905, -57.69999999999977, -33.69999999999977, -43.29999999999989, 51.500000000000114, -112.60000000000056, -120.70000000000068, 77.0, 53.900000000000084, -192.09999999999988, 35.60000000000009, -24.700000000000223, -311.80000000000024, 55.99999999999993, -92.79999999999998, -99.10000000000059, -199.00000000000014, -175.30000000000013, -31.599999999999945, 20.000000000000014, 90.19999999999948, -151.00000000000034, 20.000000000000014, -45.3999999999999, 20.000000000000014, 48.80000000000013, -47.80000000000006, 62.30000000000022, 20.000000000000014, 130.9999999999998, -113.50000000000014, -159.10000000000056, 29.00000000000024, 55.10000000000017, 103.6999999999999, 13.399999999999967, -81.09999999999985, -52.00000000000008, 20.000000000000014, -11.499999999999826, -33.999999999999936, -148.60000000000014, -166.0000000000004], "policy_predator_policy_reward": [6.0, 0.0, 31.0, 4.0, 32.0, 116.0, 45.0, 0.0, 0.0, 73.0, 77.0, 1.0, 0.0, 19.0, 68.0, 0.0, 23.0, 78.0, 0.0, 0.0, 76.0, 99.0, 45.0, 131.0, 44.0, 0.0, 37.0, 68.0, 61.0, 107.0, 0.0, 49.0, 0.0, 3.0, 55.0, 11.0, 44.0, 111.0, 52.0, 64.0, 25.0, 34.0, 13.0, 21.0, 55.0, 107.0, 69.0, 119.0, 113.0, 11.0, 0.0, 0.0, 72.0, 18.0, 52.0, 58.0, 61.0, 0.0, 99.0, 56.0, 44.0, 28.0, 54.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 50.0, 0.0, 29.0, 1.0, 157.0, 0.0, 4.0, 14.0, 0.0, 46.0, 27.0, 106.0, 10.0, 71.0, 38.0, 126.0, 29.0, 24.0, 0.0, 36.0, 0.0, 21.0, 50.0, 95.0, 69.0, 16.0, 0.0, 0.0, 93.0, 15.0, 19.0, 0.0, 102.0, 35.0, 36.0, 10.0, 48.0, 42.0, 70.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 59.0, 1.0, 32.0, 36.0, 0.0, 0.0, 0.0, 93.0, 13.0, 57.0, 44.0, 46.0, 0.0, 54.0, 78.0, 43.0, 32.0, 4.0, 0.0, 7.0, 1.0, 0.0, 49.0, 4.0, 11.0, 29.0, 3.0, 19.0, 58.0, 34.0, 41.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 30.0, 42.0, 6.0, 27.0, 31.0, 0.0, 99.0, 68.0, 0.0, 11.0, 101.0, 35.0, 158.0, 25.0, 67.0, 5.0, 152.0, 25.0, 93.0, 0.0, 0.0, 0.0, 84.0, 47.0, 12.0, 0.0, 67.0, 0.0, 0.0, 64.0, 11.0, 0.0, 95.0, 0.0, 0.0, 31.0, 52.0, 0.0, 42.0, 15.0, 63.0, 149.0, 43.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5592432873502098, "mean_inference_ms": 1.4328647520756095, "mean_action_processing_ms": 0.23122456693231336, "mean_env_wait_ms": 0.20594253056218526, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004759669303894043, "StateBufferConnector_ms": 0.002948760986328125, "ViewRequirementAgentConnector_ms": 0.08891510963439941}, "num_episodes": 18, "episode_return_max": 198.89999999999966, "episode_return_min": -193.5, "episode_return_mean": 25.67099999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 456.10028107018445, "num_env_steps_trained_throughput_per_sec": 456.10028107018445, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 9147.041, "restore_workers_time_ms": 0.018, "training_step_time_ms": 9146.992, "sample_time_ms": 1140.772, "learn_time_ms": 7993.769, "learn_throughput": 500.39, "synch_weights_time_ms": 11.491}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "04dec_00002", "date": "2024-08-13_16-23-48", "timestamp": 1723580628, "time_this_iter_s": 8.773728847503662, "time_total_s": 64.18959856033325, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3575c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 64.18959856033325, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 29.733333333333334, "ram_util_percent": 81.38333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3851670438413898, "cur_kl_coeff": 0.025, "cur_lr": 0.00010000000000000003, "total_loss": 5.8144676021797945, "policy_loss": -0.0017263601876539056, "vf_loss": 5.815964897347506, "vf_explained_var": -0.0006291479660720422, "kl": 0.00916223323476056, "entropy": 1.5674282375466886, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2347772272254425, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 6.957709883634376, "policy_loss": -0.005912559074177234, "vf_loss": 6.961783582697469, "vf_explained_var": 0.014098762929754913, "kl": 0.018388567126512264, "entropy": 1.5847048802350563, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 253.09999999999928, "episode_reward_min": -193.5, "episode_reward_mean": 29.339999999999804, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.5, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -21.610000000000042, "predator_policy": 36.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.500000000000068, -17.399999999999913, 79.49999999999895, 153.79999999999947, -28.099999999999994, -142.80000000000106, -16.29999999999987, 187.59999999999928, -46.69999999999972, -9.899999999999903, -76.2999999999999, -193.5, 44.500000000000114, -8.6, 31.80000000000048, 58.90000000000039, 44.50000000000029, 74.99999999999908, 113.69999999999936, 30.600000000000303, -60.899999999999814, 74.29999999999946, 127.19999999999928, 161.29999999999933, 24.900000000000134, -10.899999999999967, 88.79999999999997, 115.29999999999956, 55.30000000000034, -38.10000000000003, -50.399999999999885, 70.09999999999911, 1.600000000000124, 35.90000000000025, 0.3999999999999433, -25.499999999999872, 5.60000000000016, 70.39999999999964, 48.100000000000286, 144.2999999999989, 88.69999999999915, 21.900000000000304, 75.70000000000016, -33.199999999999676, 90.40000000000022, 91.10000000000007, -83.70000000000014, 167.59999999999945, -24.19999999999989, -6.499999999999718, 146.29999999999882, 120.29999999999887, 19.699999999999992, 31.90000000000018, 115.49999999999866, -18.2999999999996, -21.79999999999975, 88.19999999999993, 86.7999999999991, 74.59999999999985, 133.89999999999932, -43.39999999999985, 66.1999999999999, -134.30000000000123, 198.89999999999966, -44.500000000000014, -143.50000000000097, 55.20000000000005, -141.100000000001, -88.90000000000043, 110.19999999999888, -46.999999999999794, 33.60000000000019, 67.99999999999912, 82.29999999999917, 92.49999999999955, -35.099999999999646, 158.79999999999987, 15.300000000000246, 9.999999999999948, 32.5000000000001, -122.60000000000062, 42.700000000000315, -78.39999999999995, -95.50000000000024, 9.200000000000273, -129.00000000000054, -58.69999999999998, -47.50000000000001, 57.70000000000005, -43.49999999999962, 73.10000000000018, 253.09999999999928, 10.100000000000046, 131.49999999999977, 24.60000000000015, 142.3999999999985, 83.39999999999912, 10.900000000000247, 125.39999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-145.90000000000026, 7.400000000000027, -19.89999999999992, -113.50000000000011, 48.49999999999952, -27.999999999999858, 16.100000000000094, 103.70000000000005, -92.19999999999997, -97.90000000000023, -275.19999999999925, -55.60000000000025, 76.99999999999966, -217.30000000000047, 20.000000000000014, 167.5999999999999, 20.000000000000014, -156.70000000000041, -18.09999999999995, -101.80000000000048, -35.50000000000003, -101.80000000000004, -99.39999999999996, -249.10000000000002, -28.299999999999812, 0.8000000000000639, -82.60000000000028, 20.000000000000014, 36.20000000000025, -27.39999999999999, 38.90000000000018, 20.000000000000014, 24.500000000000007, 20.000000000000014, 90.7999999999995, -65.80000000000004, 46.10000000000019, 17.599999999999962, 41.60000000000025, -39.99999999999984, -306.99999999999966, 88.09999999999971, 33.50000000000024, 36.80000000000012, 78.7999999999998, 34.40000000000012, -29.20000000000013, 117.49999999999957, 14.899999999999999, -106.00000000000003, -64.29999999999995, -55.599999999999895, 134.3, -200.50000000000014, 71.3, 20.000000000000014, -33.09999999999981, 52.400000000000226, -129.1, 20.000000000000014, -173.20000000000007, -41.20000000000002, 34.10000000000011, 20.000000000000014, -41.799999999999834, -49.59999999999998, 22.700000000000053, -20.800000000000033, 78.19999999999986, -179.7999999999999, -33.39999999999995, -63.100000000000044, 45.200000000000074, -97.60000000000072, -66.10000000000005, 24.500000000000064, 28.100000000000115, 20.000000000000014, 107.29999999999963, 32.00000000000022, 64.70000000000002, 20.000000000000014, -57.099999999999916, 20.000000000000014, -39.09999999999994, 81.8000000000001, -45.09999999999977, -24.099999999999746, 54.20000000000002, 36.19999999999999, 150.49999999999983, -165.4000000000005, -87.09999999999985, -97.60000000000073, -22.89999999999987, 144.49999999999997, -165.70000000000016, 9.499999999999986, -55.300000000000324, -26.199999999999775, 91.69999999999948, 50.60000000000017, 91.69999999999987, 20.600000000000197, -20.799999999999883, -8.500000000000007, -3.099999999999958, 20.000000000000014, 19.400000000000023, 64.1000000000002, -1.5999999999997883, -93.70000000000076, -45.39999999999991, -51.40000000000005, 75.79999999999997, 1.4000000000000146, 20.000000000000014, 66.79999999999994, 20.000000000000014, 38.60000000000017, 98.29999999999959, -3.399999999999905, -57.69999999999977, -33.69999999999977, -43.29999999999989, 51.500000000000114, -112.60000000000056, -120.70000000000068, 77.0, 53.900000000000084, -192.09999999999988, 35.60000000000009, -24.700000000000223, -311.80000000000024, 55.99999999999993, -92.79999999999998, -99.10000000000059, -199.00000000000014, -175.30000000000013, -31.599999999999945, 20.000000000000014, 90.19999999999948, -151.00000000000034, 20.000000000000014, -45.3999999999999, 20.000000000000014, 48.80000000000013, -47.80000000000006, 62.30000000000022, 20.000000000000014, 130.9999999999998, -113.50000000000014, -159.10000000000056, 29.00000000000024, 55.10000000000017, 103.6999999999999, 13.399999999999967, -81.09999999999985, -52.00000000000008, 20.000000000000014, -11.499999999999826, -33.999999999999936, -148.60000000000014, -166.0000000000004, 20.000000000000014, 22.700000000000063, -250.90000000000015, 33.50000000000014, -93.10000000000002, -198.40000000000038, -53.199999999999996, 25.400000000000112, -1.0000000000000107, -319.0, -213.1000000000005, 43.400000000000205, -120.70000000000012, -107.79999999999994, 152.3, -253.60000000000005, -74.80000000000025, -57.69999999999979, 20.000000000000014, 16.100000000000062, 183.5, 68.59999999999985, -53.49999999999994, -51.39999999999998, -67.29999999999995, 90.80000000000001, 87.49999999999929, -208.90000000000052, 56.900000000000226, 84.49999999999936, -10.299999999999967, 40.70000000000018, -69.10000000000012, 20.000000000000014, 99.49999999999997, -21.10000000000003], "policy_predator_policy_reward": [44.0, 111.0, 52.0, 64.0, 25.0, 34.0, 13.0, 21.0, 55.0, 107.0, 69.0, 119.0, 113.0, 11.0, 0.0, 0.0, 72.0, 18.0, 52.0, 58.0, 61.0, 0.0, 99.0, 56.0, 44.0, 28.0, 54.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 50.0, 0.0, 29.0, 1.0, 157.0, 0.0, 4.0, 14.0, 0.0, 46.0, 27.0, 106.0, 10.0, 71.0, 38.0, 126.0, 29.0, 24.0, 0.0, 36.0, 0.0, 21.0, 50.0, 95.0, 69.0, 16.0, 0.0, 0.0, 93.0, 15.0, 19.0, 0.0, 102.0, 35.0, 36.0, 10.0, 48.0, 42.0, 70.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 59.0, 1.0, 32.0, 36.0, 0.0, 0.0, 0.0, 93.0, 13.0, 57.0, 44.0, 46.0, 0.0, 54.0, 78.0, 43.0, 32.0, 4.0, 0.0, 7.0, 1.0, 0.0, 49.0, 4.0, 11.0, 29.0, 3.0, 19.0, 58.0, 34.0, 41.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 30.0, 42.0, 6.0, 27.0, 31.0, 0.0, 99.0, 68.0, 0.0, 11.0, 101.0, 35.0, 158.0, 25.0, 67.0, 5.0, 152.0, 25.0, 93.0, 0.0, 0.0, 0.0, 84.0, 47.0, 12.0, 0.0, 67.0, 0.0, 0.0, 64.0, 11.0, 0.0, 95.0, 0.0, 0.0, 31.0, 52.0, 0.0, 42.0, 15.0, 63.0, 149.0, 43.0, 0.0, 0.0, 11.0, 128.0, 104.0, 92.0, 37.0, 0.0, 16.0, 175.0, 0.0, 111.0, 89.0, 92.0, 95.0, 64.0, 55.0, 34.0, 17.0, 20.0, 1.0, 0.0, 40.0, 75.0, 65.0, 43.0, 50.0, 96.0, 0.0, 1.0, 48.0, 5.0, 0.0, 60.0, 17.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5537139968508429, "mean_inference_ms": 1.4093186619486562, "mean_action_processing_ms": 0.22818652627704072, "mean_env_wait_ms": 0.20072458681473143, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004115104675292969, "StateBufferConnector_ms": 0.0029036998748779297, "ViewRequirementAgentConnector_ms": 0.08818042278289795}, "num_episodes": 18, "episode_return_max": 253.09999999999928, "episode_return_min": -193.5, "episode_return_mean": 29.339999999999804, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 454.2058290179778, "num_env_steps_trained_throughput_per_sec": 454.2058290179778, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 9104.484, "restore_workers_time_ms": 0.017, "training_step_time_ms": 9104.438, "sample_time_ms": 1122.399, "learn_time_ms": 7969.601, "learn_throughput": 501.907, "synch_weights_time_ms": 11.508}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "04dec_00002", "date": "2024-08-13_16-23-57", "timestamp": 1723580637, "time_this_iter_s": 8.809471845626831, "time_total_s": 72.99907040596008, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0456ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 72.99907040596008, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 28.530769230769234, "ram_util_percent": 81.32307692307691}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28999410291946437, "cur_kl_coeff": 0.025, "cur_lr": 0.00010000000000000003, "total_loss": 4.138738846778869, "policy_loss": -0.0026605852463198877, "vf_loss": 4.141212722107216, "vf_explained_var": 0.0014566280854442133, "kl": 0.007467885305262671, "entropy": 1.5811832330845021, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3906773692952892, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 7.113679254874981, "policy_loss": -0.003300148092220148, "vf_loss": 7.115483837026767, "vf_explained_var": 0.05270762320548769, "kl": 0.01495577308102926, "entropy": 1.5669755457570314, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 268.50000000000017, "episode_reward_min": -143.50000000000097, "episode_reward_mean": 40.917999999999815, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.5, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -14.236000000000045, "predator_policy": 34.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [127.19999999999928, 161.29999999999933, 24.900000000000134, -10.899999999999967, 88.79999999999997, 115.29999999999956, 55.30000000000034, -38.10000000000003, -50.399999999999885, 70.09999999999911, 1.600000000000124, 35.90000000000025, 0.3999999999999433, -25.499999999999872, 5.60000000000016, 70.39999999999964, 48.100000000000286, 144.2999999999989, 88.69999999999915, 21.900000000000304, 75.70000000000016, -33.199999999999676, 90.40000000000022, 91.10000000000007, -83.70000000000014, 167.59999999999945, -24.19999999999989, -6.499999999999718, 146.29999999999882, 120.29999999999887, 19.699999999999992, 31.90000000000018, 115.49999999999866, -18.2999999999996, -21.79999999999975, 88.19999999999993, 86.7999999999991, 74.59999999999985, 133.89999999999932, -43.39999999999985, 66.1999999999999, -134.30000000000123, 198.89999999999966, -44.500000000000014, -143.50000000000097, 55.20000000000005, -141.100000000001, -88.90000000000043, 110.19999999999888, -46.999999999999794, 33.60000000000019, 67.99999999999912, 82.29999999999917, 92.49999999999955, -35.099999999999646, 158.79999999999987, 15.300000000000246, 9.999999999999948, 32.5000000000001, -122.60000000000062, 42.700000000000315, -78.39999999999995, -95.50000000000024, 9.200000000000273, -129.00000000000054, -58.69999999999998, -47.50000000000001, 57.70000000000005, -43.49999999999962, 73.10000000000018, 253.09999999999928, 10.100000000000046, 131.49999999999977, 24.60000000000015, 142.3999999999985, 83.39999999999912, 10.900000000000247, 125.39999999999998, -123.60000000000056, -5.59999999999971, 114.69999999999891, 31.200000000000003, 166.4999999999995, 19.600000000000257, 0.19999999999998008, -13.400000000000022, 268.50000000000017, 81.30000000000013, 166.50000000000003, 29.900000000000126, -1.0999999999998353, 183.09999999999968, -43.099999999999866, 77.79999999999976, 43.00000000000047, 129.10000000000008, 114.99999999999974, 135.09999999999988, 20.000000000000178, 73.29999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [78.7999999999998, 34.40000000000012, -29.20000000000013, 117.49999999999957, 14.899999999999999, -106.00000000000003, -64.29999999999995, -55.599999999999895, 134.3, -200.50000000000014, 71.3, 20.000000000000014, -33.09999999999981, 52.400000000000226, -129.1, 20.000000000000014, -173.20000000000007, -41.20000000000002, 34.10000000000011, 20.000000000000014, -41.799999999999834, -49.59999999999998, 22.700000000000053, -20.800000000000033, 78.19999999999986, -179.7999999999999, -33.39999999999995, -63.100000000000044, 45.200000000000074, -97.60000000000072, -66.10000000000005, 24.500000000000064, 28.100000000000115, 20.000000000000014, 107.29999999999963, 32.00000000000022, 64.70000000000002, 20.000000000000014, -57.099999999999916, 20.000000000000014, -39.09999999999994, 81.8000000000001, -45.09999999999977, -24.099999999999746, 54.20000000000002, 36.19999999999999, 150.49999999999983, -165.4000000000005, -87.09999999999985, -97.60000000000073, -22.89999999999987, 144.49999999999997, -165.70000000000016, 9.499999999999986, -55.300000000000324, -26.199999999999775, 91.69999999999948, 50.60000000000017, 91.69999999999987, 20.600000000000197, -20.799999999999883, -8.500000000000007, -3.099999999999958, 20.000000000000014, 19.400000000000023, 64.1000000000002, -1.5999999999997883, -93.70000000000076, -45.39999999999991, -51.40000000000005, 75.79999999999997, 1.4000000000000146, 20.000000000000014, 66.79999999999994, 20.000000000000014, 38.60000000000017, 98.29999999999959, -3.399999999999905, -57.69999999999977, -33.69999999999977, -43.29999999999989, 51.500000000000114, -112.60000000000056, -120.70000000000068, 77.0, 53.900000000000084, -192.09999999999988, 35.60000000000009, -24.700000000000223, -311.80000000000024, 55.99999999999993, -92.79999999999998, -99.10000000000059, -199.00000000000014, -175.30000000000013, -31.599999999999945, 20.000000000000014, 90.19999999999948, -151.00000000000034, 20.000000000000014, -45.3999999999999, 20.000000000000014, 48.80000000000013, -47.80000000000006, 62.30000000000022, 20.000000000000014, 130.9999999999998, -113.50000000000014, -159.10000000000056, 29.00000000000024, 55.10000000000017, 103.6999999999999, 13.399999999999967, -81.09999999999985, -52.00000000000008, 20.000000000000014, -11.499999999999826, -33.999999999999936, -148.60000000000014, -166.0000000000004, 20.000000000000014, 22.700000000000063, -250.90000000000015, 33.50000000000014, -93.10000000000002, -198.40000000000038, -53.199999999999996, 25.400000000000112, -1.0000000000000107, -319.0, -213.1000000000005, 43.400000000000205, -120.70000000000012, -107.79999999999994, 152.3, -253.60000000000005, -74.80000000000025, -57.69999999999979, 20.000000000000014, 16.100000000000062, 183.5, 68.59999999999985, -53.49999999999994, -51.39999999999998, -67.29999999999995, 90.80000000000001, 87.49999999999929, -208.90000000000052, 56.900000000000226, 84.49999999999936, -10.299999999999967, 40.70000000000018, -69.10000000000012, 20.000000000000014, 99.49999999999997, -21.10000000000003, -91.3000000000001, -154.3000000000004, -14.199999999999783, -66.40000000000008, 22.700000000000035, 91.99999999999983, 15.799999999999963, -37.599999999999994, -92.50000000000023, 181.9999999999999, 36.50000000000008, -82.89999999999999, -215.20000000000005, 79.3999999999998, 41.600000000000165, -157.00000000000045, 163.7, 60.79999999999997, 22.70000000000001, 53.59999999999998, 154.99999999999972, -62.5, 20.000000000000014, -0.0999999999999816, -130.00000000000054, -0.10000000000000803, 171.2, -99.09999999999994, -229.60000000000025, 39.50000000000008, 39.500000000000036, 5.299999999999967, 3.200000000000209, 15.799999999999985, 87.5000000000001, 41.60000000000003, 108.19999999999996, -5.199999999999944, 74.89999999999998, 36.20000000000004, -154.30000000000018, 41.30000000000004, 20.90000000000003, 52.40000000000023], "policy_predator_policy_reward": [14.0, 0.0, 46.0, 27.0, 106.0, 10.0, 71.0, 38.0, 126.0, 29.0, 24.0, 0.0, 36.0, 0.0, 21.0, 50.0, 95.0, 69.0, 16.0, 0.0, 0.0, 93.0, 15.0, 19.0, 0.0, 102.0, 35.0, 36.0, 10.0, 48.0, 42.0, 70.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 59.0, 1.0, 32.0, 36.0, 0.0, 0.0, 0.0, 93.0, 13.0, 57.0, 44.0, 46.0, 0.0, 54.0, 78.0, 43.0, 32.0, 4.0, 0.0, 7.0, 1.0, 0.0, 49.0, 4.0, 11.0, 29.0, 3.0, 19.0, 58.0, 34.0, 41.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 30.0, 42.0, 6.0, 27.0, 31.0, 0.0, 99.0, 68.0, 0.0, 11.0, 101.0, 35.0, 158.0, 25.0, 67.0, 5.0, 152.0, 25.0, 93.0, 0.0, 0.0, 0.0, 84.0, 47.0, 12.0, 0.0, 67.0, 0.0, 0.0, 64.0, 11.0, 0.0, 95.0, 0.0, 0.0, 31.0, 52.0, 0.0, 42.0, 15.0, 63.0, 149.0, 43.0, 0.0, 0.0, 11.0, 128.0, 104.0, 92.0, 37.0, 0.0, 16.0, 175.0, 0.0, 111.0, 89.0, 92.0, 95.0, 64.0, 55.0, 34.0, 17.0, 20.0, 1.0, 0.0, 40.0, 75.0, 65.0, 43.0, 50.0, 96.0, 0.0, 1.0, 48.0, 5.0, 0.0, 60.0, 17.0, 30.0, 97.0, 25.0, 51.0, 24.0, 0.0, 0.0, 51.0, 2.0, 28.0, 49.0, 19.0, 47.0, 102.0, 34.0, 40.0, 62.0, 13.0, 31.0, 5.0, 0.0, 0.0, 74.0, 10.0, 0.0, 24.0, 105.0, 60.0, 51.0, 66.0, 81.0, 32.0, 1.0, 20.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 24.0, 50.0, 83.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5488509637474241, "mean_inference_ms": 1.3916307553415987, "mean_action_processing_ms": 0.22647218071496955, "mean_env_wait_ms": 0.1963413856707109, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003714919090270996, "StateBufferConnector_ms": 0.002934575080871582, "ViewRequirementAgentConnector_ms": 0.08841300010681152}, "num_episodes": 22, "episode_return_max": 268.50000000000017, "episode_return_min": -143.50000000000097, "episode_return_mean": 40.917999999999815, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 460.0431218036025, "num_env_steps_trained_throughput_per_sec": 460.0431218036025, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 9058.968, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9058.923, "sample_time_ms": 1108.2, "learn_time_ms": 7937.842, "learn_throughput": 503.915, "synch_weights_time_ms": 11.959}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "04dec_00002", "date": "2024-08-13_16-24-05", "timestamp": 1723580645, "time_this_iter_s": 8.702619791030884, "time_total_s": 81.70169019699097, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3575dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 81.70169019699097, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 29.425, "ram_util_percent": 81.10833333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2378537298943946, "cur_kl_coeff": 0.025, "cur_lr": 0.00010000000000000003, "total_loss": 2.9143087443851288, "policy_loss": -0.0022370342680169317, "vf_loss": 2.9162833008816635, "vf_explained_var": -0.0025764620808697253, "kl": 0.010498997258921856, "entropy": 1.5774593034118571, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.632277546909751, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.38647533711933, "policy_loss": -0.0017106145460198008, "vf_loss": 5.387487461705687, "vf_explained_var": 0.026878605601648804, "kl": 0.00698492716076522, "entropy": 1.5623948089029422, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 268.50000000000017, "episode_reward_min": -224.900000000001, "episode_reward_mean": 37.26899999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.5, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -15.56550000000005, "predator_policy": 34.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [91.10000000000007, -83.70000000000014, 167.59999999999945, -24.19999999999989, -6.499999999999718, 146.29999999999882, 120.29999999999887, 19.699999999999992, 31.90000000000018, 115.49999999999866, -18.2999999999996, -21.79999999999975, 88.19999999999993, 86.7999999999991, 74.59999999999985, 133.89999999999932, -43.39999999999985, 66.1999999999999, -134.30000000000123, 198.89999999999966, -44.500000000000014, -143.50000000000097, 55.20000000000005, -141.100000000001, -88.90000000000043, 110.19999999999888, -46.999999999999794, 33.60000000000019, 67.99999999999912, 82.29999999999917, 92.49999999999955, -35.099999999999646, 158.79999999999987, 15.300000000000246, 9.999999999999948, 32.5000000000001, -122.60000000000062, 42.700000000000315, -78.39999999999995, -95.50000000000024, 9.200000000000273, -129.00000000000054, -58.69999999999998, -47.50000000000001, 57.70000000000005, -43.49999999999962, 73.10000000000018, 253.09999999999928, 10.100000000000046, 131.49999999999977, 24.60000000000015, 142.3999999999985, 83.39999999999912, 10.900000000000247, 125.39999999999998, -123.60000000000056, -5.59999999999971, 114.69999999999891, 31.200000000000003, 166.4999999999995, 19.600000000000257, 0.19999999999998008, -13.400000000000022, 268.50000000000017, 81.30000000000013, 166.50000000000003, 29.900000000000126, -1.0999999999998353, 183.09999999999968, -43.099999999999866, 77.79999999999976, 43.00000000000047, 129.10000000000008, 114.99999999999974, 135.09999999999988, 20.000000000000178, 73.29999999999983, 101.39999999999904, -45.59999999999954, 44.89999999999996, 130.09999999999954, -23.9999999999999, 29.400000000000077, 153.79999999999953, 28.600000000000442, 246.9999999999997, 49.900000000000446, 49.80000000000002, -121.30000000000092, 82.99999999999982, -224.900000000001, -26.399999999999608, 85.19999999999897, 20.000000000000078, -48.99999999999988, -83.70000000000039, 31.400000000000283, 64.00000000000048, 101.0999999999993, 58.20000000000038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.49999999999983, -165.4000000000005, -87.09999999999985, -97.60000000000073, -22.89999999999987, 144.49999999999997, -165.70000000000016, 9.499999999999986, -55.300000000000324, -26.199999999999775, 91.69999999999948, 50.60000000000017, 91.69999999999987, 20.600000000000197, -20.799999999999883, -8.500000000000007, -3.099999999999958, 20.000000000000014, 19.400000000000023, 64.1000000000002, -1.5999999999997883, -93.70000000000076, -45.39999999999991, -51.40000000000005, 75.79999999999997, 1.4000000000000146, 20.000000000000014, 66.79999999999994, 20.000000000000014, 38.60000000000017, 98.29999999999959, -3.399999999999905, -57.69999999999977, -33.69999999999977, -43.29999999999989, 51.500000000000114, -112.60000000000056, -120.70000000000068, 77.0, 53.900000000000084, -192.09999999999988, 35.60000000000009, -24.700000000000223, -311.80000000000024, 55.99999999999993, -92.79999999999998, -99.10000000000059, -199.00000000000014, -175.30000000000013, -31.599999999999945, 20.000000000000014, 90.19999999999948, -151.00000000000034, 20.000000000000014, -45.3999999999999, 20.000000000000014, 48.80000000000013, -47.80000000000006, 62.30000000000022, 20.000000000000014, 130.9999999999998, -113.50000000000014, -159.10000000000056, 29.00000000000024, 55.10000000000017, 103.6999999999999, 13.399999999999967, -81.09999999999985, -52.00000000000008, 20.000000000000014, -11.499999999999826, -33.999999999999936, -148.60000000000014, -166.0000000000004, 20.000000000000014, 22.700000000000063, -250.90000000000015, 33.50000000000014, -93.10000000000002, -198.40000000000038, -53.199999999999996, 25.400000000000112, -1.0000000000000107, -319.0, -213.1000000000005, 43.400000000000205, -120.70000000000012, -107.79999999999994, 152.3, -253.60000000000005, -74.80000000000025, -57.69999999999979, 20.000000000000014, 16.100000000000062, 183.5, 68.59999999999985, -53.49999999999994, -51.39999999999998, -67.29999999999995, 90.80000000000001, 87.49999999999929, -208.90000000000052, 56.900000000000226, 84.49999999999936, -10.299999999999967, 40.70000000000018, -69.10000000000012, 20.000000000000014, 99.49999999999997, -21.10000000000003, -91.3000000000001, -154.3000000000004, -14.199999999999783, -66.40000000000008, 22.700000000000035, 91.99999999999983, 15.799999999999963, -37.599999999999994, -92.50000000000023, 181.9999999999999, 36.50000000000008, -82.89999999999999, -215.20000000000005, 79.3999999999998, 41.600000000000165, -157.00000000000045, 163.7, 60.79999999999997, 22.70000000000001, 53.59999999999998, 154.99999999999972, -62.5, 20.000000000000014, -0.0999999999999816, -130.00000000000054, -0.10000000000000803, 171.2, -99.09999999999994, -229.60000000000025, 39.50000000000008, 39.500000000000036, 5.299999999999967, 3.200000000000209, 15.799999999999985, 87.5000000000001, 41.60000000000003, 108.19999999999996, -5.199999999999944, 74.89999999999998, 36.20000000000004, -154.30000000000018, 41.30000000000004, 20.90000000000003, 52.40000000000023, 61.70000000000013, 22.700000000000053, -62.4999999999999, -45.09999999999976, 20.000000000000014, -30.099999999999945, 44.30000000000007, 36.80000000000016, -73.90000000000003, -42.0999999999999, 7.699999999999832, -91.30000000000047, 20.000000000000014, 108.79999999999998, -24.099999999999927, 31.700000000000212, 167.59999999999994, 79.39999999999966, 20.000000000000014, 29.90000000000019, -20.200000000000003, 20.000000000000014, -137.80000000000032, -116.50000000000061, 20.000000000000014, 44.00000000000002, -185.8, -174.10000000000053, -43.00000000000002, -54.39999999999985, -51.69999999999991, 83.89999999999928, -6.100000000000007, -25.899999999999842, -147.20000000000022, -20.799999999999873, -198.40000000000012, -4.29999999999985, -33.3999999999999, 15.799999999999946, 7.399999999999965, 50.600000000000236, 61.40000000000011, 1.6999999999999782, 36.50000000000018, 13.699999999999964], "policy_predator_policy_reward": [93.0, 13.0, 57.0, 44.0, 46.0, 0.0, 54.0, 78.0, 43.0, 32.0, 4.0, 0.0, 7.0, 1.0, 0.0, 49.0, 4.0, 11.0, 29.0, 3.0, 19.0, 58.0, 34.0, 41.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 30.0, 42.0, 6.0, 27.0, 31.0, 0.0, 99.0, 68.0, 0.0, 11.0, 101.0, 35.0, 158.0, 25.0, 67.0, 5.0, 152.0, 25.0, 93.0, 0.0, 0.0, 0.0, 84.0, 47.0, 12.0, 0.0, 67.0, 0.0, 0.0, 64.0, 11.0, 0.0, 95.0, 0.0, 0.0, 31.0, 52.0, 0.0, 42.0, 15.0, 63.0, 149.0, 43.0, 0.0, 0.0, 11.0, 128.0, 104.0, 92.0, 37.0, 0.0, 16.0, 175.0, 0.0, 111.0, 89.0, 92.0, 95.0, 64.0, 55.0, 34.0, 17.0, 20.0, 1.0, 0.0, 40.0, 75.0, 65.0, 43.0, 50.0, 96.0, 0.0, 1.0, 48.0, 5.0, 0.0, 60.0, 17.0, 30.0, 97.0, 25.0, 51.0, 24.0, 0.0, 0.0, 51.0, 2.0, 28.0, 49.0, 19.0, 47.0, 102.0, 34.0, 40.0, 62.0, 13.0, 31.0, 5.0, 0.0, 0.0, 74.0, 10.0, 0.0, 24.0, 105.0, 60.0, 51.0, 66.0, 81.0, 32.0, 1.0, 20.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 24.0, 50.0, 83.0, 0.0, 0.0, 0.0, 17.0, 7.0, 55.0, 33.0, 22.0, 40.0, 9.0, 64.0, 28.0, 59.0, 54.0, 2.0, 23.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 39.0, 11.0, 106.0, 27.0, 13.0, 6.0, 130.0, 5.0, 41.0, 30.0, 0.0, 53.0, 52.0, 0.0, 117.0, 2.0, 119.0, 0.0, 36.0, 13.0, 6.0, 0.0, 30.0, 8.0, 8.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5459519825136178, "mean_inference_ms": 1.3791452725905327, "mean_action_processing_ms": 0.2245750025527561, "mean_env_wait_ms": 0.1938824484259116, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004563093185424805, "StateBufferConnector_ms": 0.0030051469802856445, "ViewRequirementAgentConnector_ms": 0.09232461452484131}, "num_episodes": 23, "episode_return_max": 268.50000000000017, "episode_return_min": -224.900000000001, "episode_return_mean": 37.26899999999981, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 438.932821721686, "num_env_steps_trained_throughput_per_sec": 438.932821721686, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 9064.374, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9064.329, "sample_time_ms": 1105.411, "learn_time_ms": 7946.15, "learn_throughput": 503.388, "synch_weights_time_ms": 11.874}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "04dec_00002", "date": "2024-08-13_16-24-15", "timestamp": 1723580655, "time_this_iter_s": 9.11769700050354, "time_total_s": 90.8193871974945, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2995c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 90.8193871974945, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 33.58461538461539, "ram_util_percent": 81.0076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3604521131428777, "cur_kl_coeff": 0.025, "cur_lr": 0.00010000000000000003, "total_loss": 3.7665593943267903, "policy_loss": -0.004533483961193019, "vf_loss": 3.7707480131633697, "vf_explained_var": 0.02088257657787787, "kl": 0.013794646013851566, "entropy": 1.5965426645581684, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4239855411585676, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.005716877387314, "policy_loss": -0.006817833060354349, "vf_loss": 5.010643902026787, "vf_explained_var": -0.003077676434996267, "kl": 0.01890797720353564, "entropy": 1.5361256953900453, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 268.50000000000017, "episode_reward_min": -224.900000000001, "episode_reward_mean": 33.07799999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.5, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -18.876000000000047, "predator_policy": 35.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-134.30000000000123, 198.89999999999966, -44.500000000000014, -143.50000000000097, 55.20000000000005, -141.100000000001, -88.90000000000043, 110.19999999999888, -46.999999999999794, 33.60000000000019, 67.99999999999912, 82.29999999999917, 92.49999999999955, -35.099999999999646, 158.79999999999987, 15.300000000000246, 9.999999999999948, 32.5000000000001, -122.60000000000062, 42.700000000000315, -78.39999999999995, -95.50000000000024, 9.200000000000273, -129.00000000000054, -58.69999999999998, -47.50000000000001, 57.70000000000005, -43.49999999999962, 73.10000000000018, 253.09999999999928, 10.100000000000046, 131.49999999999977, 24.60000000000015, 142.3999999999985, 83.39999999999912, 10.900000000000247, 125.39999999999998, -123.60000000000056, -5.59999999999971, 114.69999999999891, 31.200000000000003, 166.4999999999995, 19.600000000000257, 0.19999999999998008, -13.400000000000022, 268.50000000000017, 81.30000000000013, 166.50000000000003, 29.900000000000126, -1.0999999999998353, 183.09999999999968, -43.099999999999866, 77.79999999999976, 43.00000000000047, 129.10000000000008, 114.99999999999974, 135.09999999999988, 20.000000000000178, 73.29999999999983, 101.39999999999904, -45.59999999999954, 44.89999999999996, 130.09999999999954, -23.9999999999999, 29.400000000000077, 153.79999999999953, 28.600000000000442, 246.9999999999997, 49.900000000000446, 49.80000000000002, -121.30000000000092, 82.99999999999982, -224.900000000001, -26.399999999999608, 85.19999999999897, 20.000000000000078, -48.99999999999988, -83.70000000000039, 31.400000000000283, 64.00000000000048, 101.0999999999993, 58.20000000000038, 40.90000000000031, 65.60000000000029, -64.59999999999992, 127.39999999999907, 40.0000000000003, -22.699999999999626, 24.999999999999936, -14.80000000000003, 97.09999999999854, 14.099999999999977, 24.599999999999852, -4.300000000000104, 43.30000000000035, 91.29999999999852, 100.99999999999879, -39.299999999999834, -2.100000000000162, 2.600000000000195], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-112.60000000000056, -120.70000000000068, 77.0, 53.900000000000084, -192.09999999999988, 35.60000000000009, -24.700000000000223, -311.80000000000024, 55.99999999999993, -92.79999999999998, -99.10000000000059, -199.00000000000014, -175.30000000000013, -31.599999999999945, 20.000000000000014, 90.19999999999948, -151.00000000000034, 20.000000000000014, -45.3999999999999, 20.000000000000014, 48.80000000000013, -47.80000000000006, 62.30000000000022, 20.000000000000014, 130.9999999999998, -113.50000000000014, -159.10000000000056, 29.00000000000024, 55.10000000000017, 103.6999999999999, 13.399999999999967, -81.09999999999985, -52.00000000000008, 20.000000000000014, -11.499999999999826, -33.999999999999936, -148.60000000000014, -166.0000000000004, 20.000000000000014, 22.700000000000063, -250.90000000000015, 33.50000000000014, -93.10000000000002, -198.40000000000038, -53.199999999999996, 25.400000000000112, -1.0000000000000107, -319.0, -213.1000000000005, 43.400000000000205, -120.70000000000012, -107.79999999999994, 152.3, -253.60000000000005, -74.80000000000025, -57.69999999999979, 20.000000000000014, 16.100000000000062, 183.5, 68.59999999999985, -53.49999999999994, -51.39999999999998, -67.29999999999995, 90.80000000000001, 87.49999999999929, -208.90000000000052, 56.900000000000226, 84.49999999999936, -10.299999999999967, 40.70000000000018, -69.10000000000012, 20.000000000000014, 99.49999999999997, -21.10000000000003, -91.3000000000001, -154.3000000000004, -14.199999999999783, -66.40000000000008, 22.700000000000035, 91.99999999999983, 15.799999999999963, -37.599999999999994, -92.50000000000023, 181.9999999999999, 36.50000000000008, -82.89999999999999, -215.20000000000005, 79.3999999999998, 41.600000000000165, -157.00000000000045, 163.7, 60.79999999999997, 22.70000000000001, 53.59999999999998, 154.99999999999972, -62.5, 20.000000000000014, -0.0999999999999816, -130.00000000000054, -0.10000000000000803, 171.2, -99.09999999999994, -229.60000000000025, 39.50000000000008, 39.500000000000036, 5.299999999999967, 3.200000000000209, 15.799999999999985, 87.5000000000001, 41.60000000000003, 108.19999999999996, -5.199999999999944, 74.89999999999998, 36.20000000000004, -154.30000000000018, 41.30000000000004, 20.90000000000003, 52.40000000000023, 61.70000000000013, 22.700000000000053, -62.4999999999999, -45.09999999999976, 20.000000000000014, -30.099999999999945, 44.30000000000007, 36.80000000000016, -73.90000000000003, -42.0999999999999, 7.699999999999832, -91.30000000000047, 20.000000000000014, 108.79999999999998, -24.099999999999927, 31.700000000000212, 167.59999999999994, 79.39999999999966, 20.000000000000014, 29.90000000000019, -20.200000000000003, 20.000000000000014, -137.80000000000032, -116.50000000000061, 20.000000000000014, 44.00000000000002, -185.8, -174.10000000000053, -43.00000000000002, -54.39999999999985, -51.69999999999991, 83.89999999999928, -6.100000000000007, -25.899999999999842, -147.20000000000022, -20.799999999999873, -198.40000000000012, -4.29999999999985, -33.3999999999999, 15.799999999999946, 7.399999999999965, 50.600000000000236, 61.40000000000011, 1.6999999999999782, 36.50000000000018, 13.699999999999964, 20.90000000000003, 20.000000000000014, 20.000000000000014, 38.60000000000018, -214.89999999999998, -15.699999999999921, 76.3999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -156.40000000000063, 49.69999999999998, -96.40000000000003, 28.400000000000126, -34.59999999999976, -47.19999999999983, 45.20000000000023, 35.90000000000018, -38.799999999999784, 17.900000000000013, -159.70000000000016, 98.29999999999939, 20.000000000000014, -85.30000000000055, 17.299999999999976, 20.000000000000014, 71.29999999999968, 20.000000000000014, 49.7000000000002, 23.300000000000082, -64.30000000000001, -202.00000000000037, 46.700000000000216, -176.8, -115.30000000000032, 17.900000000000013], "policy_predator_policy_reward": [0.0, 99.0, 68.0, 0.0, 11.0, 101.0, 35.0, 158.0, 25.0, 67.0, 5.0, 152.0, 25.0, 93.0, 0.0, 0.0, 0.0, 84.0, 47.0, 12.0, 0.0, 67.0, 0.0, 0.0, 64.0, 11.0, 0.0, 95.0, 0.0, 0.0, 31.0, 52.0, 0.0, 42.0, 15.0, 63.0, 149.0, 43.0, 0.0, 0.0, 11.0, 128.0, 104.0, 92.0, 37.0, 0.0, 16.0, 175.0, 0.0, 111.0, 89.0, 92.0, 95.0, 64.0, 55.0, 34.0, 17.0, 20.0, 1.0, 0.0, 40.0, 75.0, 65.0, 43.0, 50.0, 96.0, 0.0, 1.0, 48.0, 5.0, 0.0, 60.0, 17.0, 30.0, 97.0, 25.0, 51.0, 24.0, 0.0, 0.0, 51.0, 2.0, 28.0, 49.0, 19.0, 47.0, 102.0, 34.0, 40.0, 62.0, 13.0, 31.0, 5.0, 0.0, 0.0, 74.0, 10.0, 0.0, 24.0, 105.0, 60.0, 51.0, 66.0, 81.0, 32.0, 1.0, 20.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 24.0, 50.0, 83.0, 0.0, 0.0, 0.0, 17.0, 7.0, 55.0, 33.0, 22.0, 40.0, 9.0, 64.0, 28.0, 59.0, 54.0, 2.0, 23.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 39.0, 11.0, 106.0, 27.0, 13.0, 6.0, 130.0, 5.0, 41.0, 30.0, 0.0, 53.0, 52.0, 0.0, 117.0, 2.0, 119.0, 0.0, 36.0, 13.0, 6.0, 0.0, 30.0, 8.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 52.0, 114.0, 0.0, 31.0, 0.0, 0.0, 64.0, 20.0, 73.0, 20.0, 13.0, 54.0, 3.0, 13.0, 0.0, 35.0, 77.0, 9.0, 57.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 28.0, 128.0, 99.0, 110.0, 18.0, 54.0, 46.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.542782931083603, "mean_inference_ms": 1.370025281442725, "mean_action_processing_ms": 0.22335820374308432, "mean_env_wait_ms": 0.19211192115694126, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045375823974609375, "StateBufferConnector_ms": 0.0028971433639526367, "ViewRequirementAgentConnector_ms": 0.09290623664855957}, "num_episodes": 18, "episode_return_max": 268.50000000000017, "episode_return_min": -224.900000000001, "episode_return_mean": 33.07799999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 445.7522367363715, "num_env_steps_trained_throughput_per_sec": 445.7522367363715, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 8977.755, "restore_workers_time_ms": 0.016, "training_step_time_ms": 8977.713, "sample_time_ms": 1084.52, "learn_time_ms": 7880.415, "learn_throughput": 507.587, "synch_weights_time_ms": 11.934}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "04dec_00002", "date": "2024-08-13_16-24-24", "timestamp": 1723580664, "time_this_iter_s": 9.000160932540894, "time_total_s": 99.8195481300354, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3587f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 99.8195481300354, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 30.484615384615385, "ram_util_percent": 80.89999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4110945806459144, "cur_kl_coeff": 0.025, "cur_lr": 0.00010000000000000003, "total_loss": 3.5949488388798225, "policy_loss": -0.0035057484158733613, "vf_loss": 3.5981742360604505, "vf_explained_var": 0.012036239659344708, "kl": 0.011214130014615369, "entropy": 1.5988192394927696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2731012845559726, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 4.185484650778392, "policy_loss": -0.004161550090019961, "vf_loss": 4.187720094660603, "vf_explained_var": -0.0022889155874807367, "kl": 0.019261117417761008, "entropy": 1.4499975872418238, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 268.50000000000017, "episode_reward_min": -224.900000000001, "episode_reward_mean": 33.91299999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.5, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -17.053500000000046, "predator_policy": 34.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-122.60000000000062, 42.700000000000315, -78.39999999999995, -95.50000000000024, 9.200000000000273, -129.00000000000054, -58.69999999999998, -47.50000000000001, 57.70000000000005, -43.49999999999962, 73.10000000000018, 253.09999999999928, 10.100000000000046, 131.49999999999977, 24.60000000000015, 142.3999999999985, 83.39999999999912, 10.900000000000247, 125.39999999999998, -123.60000000000056, -5.59999999999971, 114.69999999999891, 31.200000000000003, 166.4999999999995, 19.600000000000257, 0.19999999999998008, -13.400000000000022, 268.50000000000017, 81.30000000000013, 166.50000000000003, 29.900000000000126, -1.0999999999998353, 183.09999999999968, -43.099999999999866, 77.79999999999976, 43.00000000000047, 129.10000000000008, 114.99999999999974, 135.09999999999988, 20.000000000000178, 73.29999999999983, 101.39999999999904, -45.59999999999954, 44.89999999999996, 130.09999999999954, -23.9999999999999, 29.400000000000077, 153.79999999999953, 28.600000000000442, 246.9999999999997, 49.900000000000446, 49.80000000000002, -121.30000000000092, 82.99999999999982, -224.900000000001, -26.399999999999608, 85.19999999999897, 20.000000000000078, -48.99999999999988, -83.70000000000039, 31.400000000000283, 64.00000000000048, 101.0999999999993, 58.20000000000038, 40.90000000000031, 65.60000000000029, -64.59999999999992, 127.39999999999907, 40.0000000000003, -22.699999999999626, 24.999999999999936, -14.80000000000003, 97.09999999999854, 14.099999999999977, 24.599999999999852, -4.300000000000104, 43.30000000000035, 91.29999999999852, 100.99999999999879, -39.299999999999834, -2.100000000000162, 2.600000000000195, 31.400000000000205, 41.60000000000032, -5.799999999999995, 165.09999999999917, -114.70000000000006, 63.40000000000051, -4.499999999999979, 152.29999999999916, -33.09999999999967, -82.50000000000014, 38.00000000000027, 3.700000000000023, 172.69999999999962, 15.100000000000362, -51.599999999999724, -55.600000000000485, -69.10000000000048, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-148.60000000000014, -166.0000000000004, 20.000000000000014, 22.700000000000063, -250.90000000000015, 33.50000000000014, -93.10000000000002, -198.40000000000038, -53.199999999999996, 25.400000000000112, -1.0000000000000107, -319.0, -213.1000000000005, 43.400000000000205, -120.70000000000012, -107.79999999999994, 152.3, -253.60000000000005, -74.80000000000025, -57.69999999999979, 20.000000000000014, 16.100000000000062, 183.5, 68.59999999999985, -53.49999999999994, -51.39999999999998, -67.29999999999995, 90.80000000000001, 87.49999999999929, -208.90000000000052, 56.900000000000226, 84.49999999999936, -10.299999999999967, 40.70000000000018, -69.10000000000012, 20.000000000000014, 99.49999999999997, -21.10000000000003, -91.3000000000001, -154.3000000000004, -14.199999999999783, -66.40000000000008, 22.700000000000035, 91.99999999999983, 15.799999999999963, -37.599999999999994, -92.50000000000023, 181.9999999999999, 36.50000000000008, -82.89999999999999, -215.20000000000005, 79.3999999999998, 41.600000000000165, -157.00000000000045, 163.7, 60.79999999999997, 22.70000000000001, 53.59999999999998, 154.99999999999972, -62.5, 20.000000000000014, -0.0999999999999816, -130.00000000000054, -0.10000000000000803, 171.2, -99.09999999999994, -229.60000000000025, 39.50000000000008, 39.500000000000036, 5.299999999999967, 3.200000000000209, 15.799999999999985, 87.5000000000001, 41.60000000000003, 108.19999999999996, -5.199999999999944, 74.89999999999998, 36.20000000000004, -154.30000000000018, 41.30000000000004, 20.90000000000003, 52.40000000000023, 61.70000000000013, 22.700000000000053, -62.4999999999999, -45.09999999999976, 20.000000000000014, -30.099999999999945, 44.30000000000007, 36.80000000000016, -73.90000000000003, -42.0999999999999, 7.699999999999832, -91.30000000000047, 20.000000000000014, 108.79999999999998, -24.099999999999927, 31.700000000000212, 167.59999999999994, 79.39999999999966, 20.000000000000014, 29.90000000000019, -20.200000000000003, 20.000000000000014, -137.80000000000032, -116.50000000000061, 20.000000000000014, 44.00000000000002, -185.8, -174.10000000000053, -43.00000000000002, -54.39999999999985, -51.69999999999991, 83.89999999999928, -6.100000000000007, -25.899999999999842, -147.20000000000022, -20.799999999999873, -198.40000000000012, -4.29999999999985, -33.3999999999999, 15.799999999999946, 7.399999999999965, 50.600000000000236, 61.40000000000011, 1.6999999999999782, 36.50000000000018, 13.699999999999964, 20.90000000000003, 20.000000000000014, 20.000000000000014, 38.60000000000018, -214.89999999999998, -15.699999999999921, 76.3999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -156.40000000000063, 49.69999999999998, -96.40000000000003, 28.400000000000126, -34.59999999999976, -47.19999999999983, 45.20000000000023, 35.90000000000018, -38.799999999999784, 17.900000000000013, -159.70000000000016, 98.29999999999939, 20.000000000000014, -85.30000000000055, 17.299999999999976, 20.000000000000014, 71.29999999999968, 20.000000000000014, 49.7000000000002, 23.300000000000082, -64.30000000000001, -202.00000000000037, 46.700000000000216, -176.8, -115.30000000000032, 17.900000000000013, 36.20000000000019, -56.80000000000014, 20.000000000000014, 20.600000000000026, 20.000000000000014, -74.80000000000044, 23.60000000000007, 141.4999999999998, -93.40000000000083, -199.29999999999987, 43.40000000000025, 20.000000000000014, -28.599999999999824, -46.899999999999864, 11.599999999999973, 85.69999999999928, -107.20000000000056, -7.899999999999942, -180.70000000000022, -56.799999999999926, 20.000000000000014, 7.99999999999997, -19.899999999999814, -12.399999999999858, 40.699999999999974, 62.000000000000085, -61.899999999999906, 20.000000000000014, -156.40000000000023, -8.199999999999973, -132.10000000000008, -8.499999999999906, -211.9000000000002, 15.799999999999962, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [149.0, 43.0, 0.0, 0.0, 11.0, 128.0, 104.0, 92.0, 37.0, 0.0, 16.0, 175.0, 0.0, 111.0, 89.0, 92.0, 95.0, 64.0, 55.0, 34.0, 17.0, 20.0, 1.0, 0.0, 40.0, 75.0, 65.0, 43.0, 50.0, 96.0, 0.0, 1.0, 48.0, 5.0, 0.0, 60.0, 17.0, 30.0, 97.0, 25.0, 51.0, 24.0, 0.0, 0.0, 51.0, 2.0, 28.0, 49.0, 19.0, 47.0, 102.0, 34.0, 40.0, 62.0, 13.0, 31.0, 5.0, 0.0, 0.0, 74.0, 10.0, 0.0, 24.0, 105.0, 60.0, 51.0, 66.0, 81.0, 32.0, 1.0, 20.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 24.0, 50.0, 83.0, 0.0, 0.0, 0.0, 17.0, 7.0, 55.0, 33.0, 22.0, 40.0, 9.0, 64.0, 28.0, 59.0, 54.0, 2.0, 23.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 39.0, 11.0, 106.0, 27.0, 13.0, 6.0, 130.0, 5.0, 41.0, 30.0, 0.0, 53.0, 52.0, 0.0, 117.0, 2.0, 119.0, 0.0, 36.0, 13.0, 6.0, 0.0, 30.0, 8.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 52.0, 114.0, 0.0, 31.0, 0.0, 0.0, 64.0, 20.0, 73.0, 20.0, 13.0, 54.0, 3.0, 13.0, 0.0, 35.0, 77.0, 9.0, 57.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 28.0, 128.0, 99.0, 110.0, 18.0, 54.0, 46.0, 15.0, 37.0, 0.0, 1.0, 1.0, 48.0, 0.0, 0.0, 68.0, 110.0, 0.0, 0.0, 0.0, 71.0, 55.0, 0.0, 82.0, 0.0, 67.0, 88.0, 0.0, 10.0, 0.0, 36.0, 0.0, 70.0, 57.0, 0.0, 98.0, 15.0, 13.0, 72.0, 48.0, 79.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.540277523317036, "mean_inference_ms": 1.3617731697587487, "mean_action_processing_ms": 0.22216881296303115, "mean_env_wait_ms": 0.19027117592993092, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004624724388122559, "StateBufferConnector_ms": 0.0029374361038208008, "ViewRequirementAgentConnector_ms": 0.09321773052215576}, "num_episodes": 18, "episode_return_max": 268.50000000000017, "episode_return_min": -224.900000000001, "episode_return_mean": 33.91299999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 429.97635480852665, "num_env_steps_trained_throughput_per_sec": 429.97635480852665, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 8962.725, "restore_workers_time_ms": 0.013, "training_step_time_ms": 8962.687, "sample_time_ms": 1056.705, "learn_time_ms": 7893.055, "learn_throughput": 506.775, "synch_weights_time_ms": 12.015}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "04dec_00002", "date": "2024-08-13_16-24-33", "timestamp": 1723580673, "time_this_iter_s": 9.312255859375, "time_total_s": 109.1318039894104, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359ca60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 109.1318039894104, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 34.2, "ram_util_percent": 80.94615384615386}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43633883299414444, "cur_kl_coeff": 0.025, "cur_lr": 0.00010000000000000003, "total_loss": 5.7267041857280425, "policy_loss": -0.0025733132165408246, "vf_loss": 5.72906939541852, "vf_explained_var": -0.0012847521633067458, "kl": 0.008324083269198363, "entropy": 1.5725239975742562, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0477123138529283, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 6.373536629147, "policy_loss": -0.0008322371129271766, "vf_loss": 6.373699762959959, "vf_explained_var": 0.003173697625518476, "kl": 0.0066909049985639365, "entropy": 1.4444653511047363, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 268.50000000000017, "episode_reward_min": -260.60000000000116, "episode_reward_mean": 28.299999999999855, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -269.8000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.9999999999999, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": -17.770000000000053, "predator_policy": 31.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [125.39999999999998, -123.60000000000056, -5.59999999999971, 114.69999999999891, 31.200000000000003, 166.4999999999995, 19.600000000000257, 0.19999999999998008, -13.400000000000022, 268.50000000000017, 81.30000000000013, 166.50000000000003, 29.900000000000126, -1.0999999999998353, 183.09999999999968, -43.099999999999866, 77.79999999999976, 43.00000000000047, 129.10000000000008, 114.99999999999974, 135.09999999999988, 20.000000000000178, 73.29999999999983, 101.39999999999904, -45.59999999999954, 44.89999999999996, 130.09999999999954, -23.9999999999999, 29.400000000000077, 153.79999999999953, 28.600000000000442, 246.9999999999997, 49.900000000000446, 49.80000000000002, -121.30000000000092, 82.99999999999982, -224.900000000001, -26.399999999999608, 85.19999999999897, 20.000000000000078, -48.99999999999988, -83.70000000000039, 31.400000000000283, 64.00000000000048, 101.0999999999993, 58.20000000000038, 40.90000000000031, 65.60000000000029, -64.59999999999992, 127.39999999999907, 40.0000000000003, -22.699999999999626, 24.999999999999936, -14.80000000000003, 97.09999999999854, 14.099999999999977, 24.599999999999852, -4.300000000000104, 43.30000000000035, 91.29999999999852, 100.99999999999879, -39.299999999999834, -2.100000000000162, 2.600000000000195, 31.400000000000205, 41.60000000000032, -5.799999999999995, 165.09999999999917, -114.70000000000006, 63.40000000000051, -4.499999999999979, 152.29999999999916, -33.09999999999967, -82.50000000000014, 38.00000000000027, 3.700000000000023, 172.69999999999962, 15.100000000000362, -51.599999999999724, -55.600000000000485, -69.10000000000048, 40.0000000000003, -260.60000000000116, -151.4000000000007, 10.200000000000225, 92.19999999999956, -113.40000000000114, -67.70000000000057, -36.09999999999995, -89.80000000000052, 40.0000000000003, 90.69999999999888, 119.69999999999942, 3.500000000000067, -27.700000000000024, -70.4, 38.40000000000027, 97.29999999999907, 40.0000000000003, -12.700000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [99.49999999999997, -21.10000000000003, -91.3000000000001, -154.3000000000004, -14.199999999999783, -66.40000000000008, 22.700000000000035, 91.99999999999983, 15.799999999999963, -37.599999999999994, -92.50000000000023, 181.9999999999999, 36.50000000000008, -82.89999999999999, -215.20000000000005, 79.3999999999998, 41.600000000000165, -157.00000000000045, 163.7, 60.79999999999997, 22.70000000000001, 53.59999999999998, 154.99999999999972, -62.5, 20.000000000000014, -0.0999999999999816, -130.00000000000054, -0.10000000000000803, 171.2, -99.09999999999994, -229.60000000000025, 39.50000000000008, 39.500000000000036, 5.299999999999967, 3.200000000000209, 15.799999999999985, 87.5000000000001, 41.60000000000003, 108.19999999999996, -5.199999999999944, 74.89999999999998, 36.20000000000004, -154.30000000000018, 41.30000000000004, 20.90000000000003, 52.40000000000023, 61.70000000000013, 22.700000000000053, -62.4999999999999, -45.09999999999976, 20.000000000000014, -30.099999999999945, 44.30000000000007, 36.80000000000016, -73.90000000000003, -42.0999999999999, 7.699999999999832, -91.30000000000047, 20.000000000000014, 108.79999999999998, -24.099999999999927, 31.700000000000212, 167.59999999999994, 79.39999999999966, 20.000000000000014, 29.90000000000019, -20.200000000000003, 20.000000000000014, -137.80000000000032, -116.50000000000061, 20.000000000000014, 44.00000000000002, -185.8, -174.10000000000053, -43.00000000000002, -54.39999999999985, -51.69999999999991, 83.89999999999928, -6.100000000000007, -25.899999999999842, -147.20000000000022, -20.799999999999873, -198.40000000000012, -4.29999999999985, -33.3999999999999, 15.799999999999946, 7.399999999999965, 50.600000000000236, 61.40000000000011, 1.6999999999999782, 36.50000000000018, 13.699999999999964, 20.90000000000003, 20.000000000000014, 20.000000000000014, 38.60000000000018, -214.89999999999998, -15.699999999999921, 76.3999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -156.40000000000063, 49.69999999999998, -96.40000000000003, 28.400000000000126, -34.59999999999976, -47.19999999999983, 45.20000000000023, 35.90000000000018, -38.799999999999784, 17.900000000000013, -159.70000000000016, 98.29999999999939, 20.000000000000014, -85.30000000000055, 17.299999999999976, 20.000000000000014, 71.29999999999968, 20.000000000000014, 49.7000000000002, 23.300000000000082, -64.30000000000001, -202.00000000000037, 46.700000000000216, -176.8, -115.30000000000032, 17.900000000000013, 36.20000000000019, -56.80000000000014, 20.000000000000014, 20.600000000000026, 20.000000000000014, -74.80000000000044, 23.60000000000007, 141.4999999999998, -93.40000000000083, -199.29999999999987, 43.40000000000025, 20.000000000000014, -28.599999999999824, -46.899999999999864, 11.599999999999973, 85.69999999999928, -107.20000000000056, -7.899999999999942, -180.70000000000022, -56.799999999999926, 20.000000000000014, 7.99999999999997, -19.899999999999814, -12.399999999999858, 40.699999999999974, 62.000000000000085, -61.899999999999906, 20.000000000000014, -156.40000000000023, -8.199999999999973, -132.10000000000008, -8.499999999999906, -211.9000000000002, 15.799999999999962, 20.000000000000014, 20.000000000000014, -175.3000000000006, -196.30000000000052, -269.8000000000002, -58.600000000000094, -104.80000000000013, 20.000000000000014, 72.19999999999978, 20.000000000000014, -137.1000000000006, -157.30000000000055, -194.20000000000053, -74.50000000000004, -45.10000000000004, -22.000000000000014, -163.30000000000055, -53.50000000000004, 20.000000000000014, 20.000000000000014, 31.69999999999981, 20.000000000000014, 5.000000000000014, 100.69999999999985, 20.000000000000014, -68.50000000000023, 21.800000000000047, -122.49999999999996, -124.60000000000036, -41.799999999999876, 20.000000000000014, -52.600000000000236, 38.9000000000001, 25.400000000000098, 20.000000000000014, 20.000000000000014, -130.60000000000002, 20.900000000000027], "policy_predator_policy_reward": [17.0, 30.0, 97.0, 25.0, 51.0, 24.0, 0.0, 0.0, 51.0, 2.0, 28.0, 49.0, 19.0, 47.0, 102.0, 34.0, 40.0, 62.0, 13.0, 31.0, 5.0, 0.0, 0.0, 74.0, 10.0, 0.0, 24.0, 105.0, 60.0, 51.0, 66.0, 81.0, 32.0, 1.0, 20.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 24.0, 50.0, 83.0, 0.0, 0.0, 0.0, 17.0, 7.0, 55.0, 33.0, 22.0, 40.0, 9.0, 64.0, 28.0, 59.0, 54.0, 2.0, 23.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 39.0, 11.0, 106.0, 27.0, 13.0, 6.0, 130.0, 5.0, 41.0, 30.0, 0.0, 53.0, 52.0, 0.0, 117.0, 2.0, 119.0, 0.0, 36.0, 13.0, 6.0, 0.0, 30.0, 8.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 52.0, 114.0, 0.0, 31.0, 0.0, 0.0, 64.0, 20.0, 73.0, 20.0, 13.0, 54.0, 3.0, 13.0, 0.0, 35.0, 77.0, 9.0, 57.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 28.0, 128.0, 99.0, 110.0, 18.0, 54.0, 46.0, 15.0, 37.0, 0.0, 1.0, 1.0, 48.0, 0.0, 0.0, 68.0, 110.0, 0.0, 0.0, 0.0, 71.0, 55.0, 0.0, 82.0, 0.0, 67.0, 88.0, 0.0, 10.0, 0.0, 36.0, 0.0, 70.0, 57.0, 0.0, 98.0, 15.0, 13.0, 72.0, 48.0, 79.0, 0.0, 0.0, 111.0, 0.0, 24.0, 153.0, 26.0, 69.0, 0.0, 0.0, 131.0, 50.0, 108.0, 93.0, 20.0, 11.0, 127.0, 0.0, 0.0, 0.0, 16.0, 23.0, 2.0, 12.0, 0.0, 52.0, 0.0, 73.0, 0.0, 96.0, 66.0, 5.0, 33.0, 0.0, 0.0, 0.0, 24.0, 73.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5387030096496704, "mean_inference_ms": 1.3568958958790855, "mean_action_processing_ms": 0.22146820886411933, "mean_env_wait_ms": 0.18908841174554777, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004720211029052734, "StateBufferConnector_ms": 0.002945542335510254, "ViewRequirementAgentConnector_ms": 0.09229815006256104}, "num_episodes": 18, "episode_return_max": 268.50000000000017, "episode_return_min": -260.60000000000116, "episode_return_mean": 28.299999999999855, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 442.1186118576651, "num_env_steps_trained_throughput_per_sec": 442.1186118576651, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 8952.777, "restore_workers_time_ms": 0.013, "training_step_time_ms": 8952.738, "sample_time_ms": 1066.91, "learn_time_ms": 7872.961, "learn_throughput": 508.068, "synch_weights_time_ms": 11.948}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "04dec_00002", "date": "2024-08-13_16-24-42", "timestamp": 1723580682, "time_this_iter_s": 9.050666093826294, "time_total_s": 118.1824700832367, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04615e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 118.1824700832367, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 30.84615384615385, "ram_util_percent": 81.55384615384615}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4202061658025419, "cur_kl_coeff": 0.025, "cur_lr": 0.00010000000000000003, "total_loss": 5.927460190101906, "policy_loss": -0.005996679210365213, "vf_loss": 5.932900270835432, "vf_explained_var": 0.002513835102162033, "kl": 0.02226376630826736, "entropy": 1.5203416977609907, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4097215837981336, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 6.4819215877977, "policy_loss": -0.006727913997219826, "vf_loss": 6.486982635972361, "vf_explained_var": 0.011162970747266496, "kl": 0.016668454048334343, "entropy": 1.4194891009381208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 246.9999999999997, "episode_reward_min": -304.99999999999915, "episode_reward_mean": -1.856000000000161, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.59999999999994, "predator_policy": 189.0}, "policy_reward_mean": {"prey_policy": -40.83800000000008, "predator_policy": 39.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.9999999999999, 29.400000000000077, 153.79999999999953, 28.600000000000442, 246.9999999999997, 49.900000000000446, 49.80000000000002, -121.30000000000092, 82.99999999999982, -224.900000000001, -26.399999999999608, 85.19999999999897, 20.000000000000078, -48.99999999999988, -83.70000000000039, 31.400000000000283, 64.00000000000048, 101.0999999999993, 58.20000000000038, 40.90000000000031, 65.60000000000029, -64.59999999999992, 127.39999999999907, 40.0000000000003, -22.699999999999626, 24.999999999999936, -14.80000000000003, 97.09999999999854, 14.099999999999977, 24.599999999999852, -4.300000000000104, 43.30000000000035, 91.29999999999852, 100.99999999999879, -39.299999999999834, -2.100000000000162, 2.600000000000195, 31.400000000000205, 41.60000000000032, -5.799999999999995, 165.09999999999917, -114.70000000000006, 63.40000000000051, -4.499999999999979, 152.29999999999916, -33.09999999999967, -82.50000000000014, 38.00000000000027, 3.700000000000023, 172.69999999999962, 15.100000000000362, -51.599999999999724, -55.600000000000485, -69.10000000000048, 40.0000000000003, -260.60000000000116, -151.4000000000007, 10.200000000000225, 92.19999999999956, -113.40000000000114, -67.70000000000057, -36.09999999999995, -89.80000000000052, 40.0000000000003, 90.69999999999888, 119.69999999999942, 3.500000000000067, -27.700000000000024, -70.4, 38.40000000000027, 97.29999999999907, 40.0000000000003, -12.700000000000001, -172.90000000000035, 63.59999999999944, 61.600000000000264, -73.70000000000088, -51.29999999999975, 6.300000000000235, 18.100000000000044, 35.600000000000236, 20.200000000000273, -217.40000000000015, -18.00000000000017, 36.7000000000003, 46.79999999999968, -14.700000000000038, 29.000000000000412, -123.90000000000043, 48.99999999999985, -169.9000000000009, -25.299999999999926, -172.60000000000005, -200.00000000000017, 68.29999999999933, -304.99999999999915, 5.500000000000005, -149.20000000000124, 110.19999999999874, -48.39999999999971], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-73.90000000000003, -42.0999999999999, 7.699999999999832, -91.30000000000047, 20.000000000000014, 108.79999999999998, -24.099999999999927, 31.700000000000212, 167.59999999999994, 79.39999999999966, 20.000000000000014, 29.90000000000019, -20.200000000000003, 20.000000000000014, -137.80000000000032, -116.50000000000061, 20.000000000000014, 44.00000000000002, -185.8, -174.10000000000053, -43.00000000000002, -54.39999999999985, -51.69999999999991, 83.89999999999928, -6.100000000000007, -25.899999999999842, -147.20000000000022, -20.799999999999873, -198.40000000000012, -4.29999999999985, -33.3999999999999, 15.799999999999946, 7.399999999999965, 50.600000000000236, 61.40000000000011, 1.6999999999999782, 36.50000000000018, 13.699999999999964, 20.90000000000003, 20.000000000000014, 20.000000000000014, 38.60000000000018, -214.89999999999998, -15.699999999999921, 76.3999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -156.40000000000063, 49.69999999999998, -96.40000000000003, 28.400000000000126, -34.59999999999976, -47.19999999999983, 45.20000000000023, 35.90000000000018, -38.799999999999784, 17.900000000000013, -159.70000000000016, 98.29999999999939, 20.000000000000014, -85.30000000000055, 17.299999999999976, 20.000000000000014, 71.29999999999968, 20.000000000000014, 49.7000000000002, 23.300000000000082, -64.30000000000001, -202.00000000000037, 46.700000000000216, -176.8, -115.30000000000032, 17.900000000000013, 36.20000000000019, -56.80000000000014, 20.000000000000014, 20.600000000000026, 20.000000000000014, -74.80000000000044, 23.60000000000007, 141.4999999999998, -93.40000000000083, -199.29999999999987, 43.40000000000025, 20.000000000000014, -28.599999999999824, -46.899999999999864, 11.599999999999973, 85.69999999999928, -107.20000000000056, -7.899999999999942, -180.70000000000022, -56.799999999999926, 20.000000000000014, 7.99999999999997, -19.899999999999814, -12.399999999999858, 40.699999999999974, 62.000000000000085, -61.899999999999906, 20.000000000000014, -156.40000000000023, -8.199999999999973, -132.10000000000008, -8.499999999999906, -211.9000000000002, 15.799999999999962, 20.000000000000014, 20.000000000000014, -175.3000000000006, -196.30000000000052, -269.8000000000002, -58.600000000000094, -104.80000000000013, 20.000000000000014, 72.19999999999978, 20.000000000000014, -137.1000000000006, -157.30000000000055, -194.20000000000053, -74.50000000000004, -45.10000000000004, -22.000000000000014, -163.30000000000055, -53.50000000000004, 20.000000000000014, 20.000000000000014, 31.69999999999981, 20.000000000000014, 5.000000000000014, 100.69999999999985, 20.000000000000014, -68.50000000000023, 21.800000000000047, -122.49999999999996, -124.60000000000036, -41.799999999999876, 20.000000000000014, -52.600000000000236, 38.9000000000001, 25.400000000000098, 20.000000000000014, 20.000000000000014, -130.60000000000002, 20.900000000000027, -387.39999999999986, -14.499999999999815, 95.2999999999995, -192.69999999999996, 20.000000000000014, 41.60000000000008, -201.40000000000043, 19.70000000000001, 15.799999999999946, -171.10000000000036, 64.40000000000012, -147.0999999999999, 52.09999999999992, -168.99999999999983, 11.59999999999997, 20.000000000000014, 11.599999999999946, -9.400000000000007, -181.60000000000002, -269.8000000000001, -53.5, -74.49999999999994, 66.80000000000001, -150.10000000000056, 44.90000000000021, -24.100000000000023, -201.7000000000001, 20.000000000000014, -49.300000000000004, 32.3000000000002, -171.10000000000045, -101.80000000000013, 82.99999999999926, -127.00000000000023, -298.4, -95.50000000000067, -49.599999999999845, -36.69999999999999, -177.40000000000003, -239.20000000000007, -232.00000000000009, -206.00000000000006, 40.10000000000015, -41.7999999999998, -255.10000000000014, -223.90000000000043, -154.30000000000038, 63.80000000000015, -103.90000000000077, -217.30000000000047, 20.000000000000014, 90.1999999999994, -1.300000000000042, -180.09999999999997], "policy_predator_policy_reward": [64.0, 28.0, 59.0, 54.0, 2.0, 23.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 39.0, 11.0, 106.0, 27.0, 13.0, 6.0, 130.0, 5.0, 41.0, 30.0, 0.0, 53.0, 52.0, 0.0, 117.0, 2.0, 119.0, 0.0, 36.0, 13.0, 6.0, 0.0, 30.0, 8.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 52.0, 114.0, 0.0, 31.0, 0.0, 0.0, 64.0, 20.0, 73.0, 20.0, 13.0, 54.0, 3.0, 13.0, 0.0, 35.0, 77.0, 9.0, 57.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 28.0, 128.0, 99.0, 110.0, 18.0, 54.0, 46.0, 15.0, 37.0, 0.0, 1.0, 1.0, 48.0, 0.0, 0.0, 68.0, 110.0, 0.0, 0.0, 0.0, 71.0, 55.0, 0.0, 82.0, 0.0, 67.0, 88.0, 0.0, 10.0, 0.0, 36.0, 0.0, 70.0, 57.0, 0.0, 98.0, 15.0, 13.0, 72.0, 48.0, 79.0, 0.0, 0.0, 111.0, 0.0, 24.0, 153.0, 26.0, 69.0, 0.0, 0.0, 131.0, 50.0, 108.0, 93.0, 20.0, 11.0, 127.0, 0.0, 0.0, 0.0, 16.0, 23.0, 2.0, 12.0, 0.0, 52.0, 0.0, 73.0, 0.0, 96.0, 66.0, 5.0, 33.0, 0.0, 0.0, 0.0, 24.0, 73.0, 185.0, 44.0, 72.0, 89.0, 0.0, 0.0, 0.0, 108.0, 58.0, 46.0, 0.0, 89.0, 72.0, 63.0, 4.0, 0.0, 18.0, 0.0, 138.0, 96.0, 98.0, 12.0, 64.0, 56.0, 26.0, 0.0, 69.0, 98.0, 43.0, 3.0, 91.0, 58.0, 36.0, 57.0, 189.0, 35.0, 0.0, 61.0, 123.0, 121.0, 120.0, 118.0, 25.0, 45.0, 174.0, 0.0, 95.0, 1.0, 59.0, 113.0, 0.0, 0.0, 35.0, 98.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5373643054854338, "mean_inference_ms": 1.3534686370350673, "mean_action_processing_ms": 0.22112171405076672, "mean_env_wait_ms": 0.18768732860790455, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004697561264038086, "StateBufferConnector_ms": 0.002926945686340332, "ViewRequirementAgentConnector_ms": 0.0919644832611084}, "num_episodes": 27, "episode_return_max": 246.9999999999997, "episode_return_min": -304.99999999999915, "episode_return_mean": -1.856000000000161, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 454.7112651808783, "num_env_steps_trained_throughput_per_sec": 454.7112651808783, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 8943.846, "restore_workers_time_ms": 0.013, "training_step_time_ms": 8943.808, "sample_time_ms": 1069.119, "learn_time_ms": 7861.863, "learn_throughput": 508.785, "synch_weights_time_ms": 11.901}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "04dec_00002", "date": "2024-08-13_16-24-51", "timestamp": 1723580691, "time_this_iter_s": 8.801056861877441, "time_total_s": 126.98352694511414, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0461f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 126.98352694511414, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 27.77692307692308, "ram_util_percent": 81.57692307692308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6100484844395724, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 0.00010000000000000003, "total_loss": 7.19759419204066, "policy_loss": -0.00724112792704353, "vf_loss": 7.203984232302065, "vf_explained_var": -0.0005596391107670213, "kl": 0.022695148692872345, "entropy": 1.4852161298353206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0971279263023346, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 7.842109878227194, "policy_loss": -0.006798875059626957, "vf_loss": 7.847136503300339, "vf_explained_var": 0.004674758261473721, "kl": 0.017722477566594872, "entropy": 1.4347694955174886, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 172.69999999999962, "episode_reward_min": -304.99999999999915, "episode_reward_mean": -15.84800000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 141.4999999999998, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": -57.51900000000007, "predator_policy": 49.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.20000000000038, 40.90000000000031, 65.60000000000029, -64.59999999999992, 127.39999999999907, 40.0000000000003, -22.699999999999626, 24.999999999999936, -14.80000000000003, 97.09999999999854, 14.099999999999977, 24.599999999999852, -4.300000000000104, 43.30000000000035, 91.29999999999852, 100.99999999999879, -39.299999999999834, -2.100000000000162, 2.600000000000195, 31.400000000000205, 41.60000000000032, -5.799999999999995, 165.09999999999917, -114.70000000000006, 63.40000000000051, -4.499999999999979, 152.29999999999916, -33.09999999999967, -82.50000000000014, 38.00000000000027, 3.700000000000023, 172.69999999999962, 15.100000000000362, -51.599999999999724, -55.600000000000485, -69.10000000000048, 40.0000000000003, -260.60000000000116, -151.4000000000007, 10.200000000000225, 92.19999999999956, -113.40000000000114, -67.70000000000057, -36.09999999999995, -89.80000000000052, 40.0000000000003, 90.69999999999888, 119.69999999999942, 3.500000000000067, -27.700000000000024, -70.4, 38.40000000000027, 97.29999999999907, 40.0000000000003, -12.700000000000001, -172.90000000000035, 63.59999999999944, 61.600000000000264, -73.70000000000088, -51.29999999999975, 6.300000000000235, 18.100000000000044, 35.600000000000236, 20.200000000000273, -217.40000000000015, -18.00000000000017, 36.7000000000003, 46.79999999999968, -14.700000000000038, 29.000000000000412, -123.90000000000043, 48.99999999999985, -169.9000000000009, -25.299999999999926, -172.60000000000005, -200.00000000000017, 68.29999999999933, -304.99999999999915, 5.500000000000005, -149.20000000000124, 110.19999999999874, -48.39999999999971, -234.60000000000065, 2.0000000000002647, 5.40000000000008, -57.199999999999825, -69.99999999999986, -2.0000000000000506, -139.39999999999995, -92.50000000000063, -127.60000000000022, 30.100000000000286, 10.799999999999697, -131.59999999999997, -12.499999999999888, 42.800000000000296, 21.499999999999737, -211.7000000000004, 97.89999999999893, -116.69999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [36.50000000000018, 13.699999999999964, 20.90000000000003, 20.000000000000014, 20.000000000000014, 38.60000000000018, -214.89999999999998, -15.699999999999921, 76.3999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -156.40000000000063, 49.69999999999998, -96.40000000000003, 28.400000000000126, -34.59999999999976, -47.19999999999983, 45.20000000000023, 35.90000000000018, -38.799999999999784, 17.900000000000013, -159.70000000000016, 98.29999999999939, 20.000000000000014, -85.30000000000055, 17.299999999999976, 20.000000000000014, 71.29999999999968, 20.000000000000014, 49.7000000000002, 23.300000000000082, -64.30000000000001, -202.00000000000037, 46.700000000000216, -176.8, -115.30000000000032, 17.900000000000013, 36.20000000000019, -56.80000000000014, 20.000000000000014, 20.600000000000026, 20.000000000000014, -74.80000000000044, 23.60000000000007, 141.4999999999998, -93.40000000000083, -199.29999999999987, 43.40000000000025, 20.000000000000014, -28.599999999999824, -46.899999999999864, 11.599999999999973, 85.69999999999928, -107.20000000000056, -7.899999999999942, -180.70000000000022, -56.799999999999926, 20.000000000000014, 7.99999999999997, -19.899999999999814, -12.399999999999858, 40.699999999999974, 62.000000000000085, -61.899999999999906, 20.000000000000014, -156.40000000000023, -8.199999999999973, -132.10000000000008, -8.499999999999906, -211.9000000000002, 15.799999999999962, 20.000000000000014, 20.000000000000014, -175.3000000000006, -196.30000000000052, -269.8000000000002, -58.600000000000094, -104.80000000000013, 20.000000000000014, 72.19999999999978, 20.000000000000014, -137.1000000000006, -157.30000000000055, -194.20000000000053, -74.50000000000004, -45.10000000000004, -22.000000000000014, -163.30000000000055, -53.50000000000004, 20.000000000000014, 20.000000000000014, 31.69999999999981, 20.000000000000014, 5.000000000000014, 100.69999999999985, 20.000000000000014, -68.50000000000023, 21.800000000000047, -122.49999999999996, -124.60000000000036, -41.799999999999876, 20.000000000000014, -52.600000000000236, 38.9000000000001, 25.400000000000098, 20.000000000000014, 20.000000000000014, -130.60000000000002, 20.900000000000027, -387.39999999999986, -14.499999999999815, 95.2999999999995, -192.69999999999996, 20.000000000000014, 41.60000000000008, -201.40000000000043, 19.70000000000001, 15.799999999999946, -171.10000000000036, 64.40000000000012, -147.0999999999999, 52.09999999999992, -168.99999999999983, 11.59999999999997, 20.000000000000014, 11.599999999999946, -9.400000000000007, -181.60000000000002, -269.8000000000001, -53.5, -74.49999999999994, 66.80000000000001, -150.10000000000056, 44.90000000000021, -24.100000000000023, -201.7000000000001, 20.000000000000014, -49.300000000000004, 32.3000000000002, -171.10000000000045, -101.80000000000013, 82.99999999999926, -127.00000000000023, -298.4, -95.50000000000067, -49.599999999999845, -36.69999999999999, -177.40000000000003, -239.20000000000007, -232.00000000000009, -206.00000000000006, 40.10000000000015, -41.7999999999998, -255.10000000000014, -223.90000000000043, -154.30000000000038, 63.80000000000015, -103.90000000000077, -217.30000000000047, 20.000000000000014, 90.1999999999994, -1.300000000000042, -180.09999999999997, -200.50000000000054, -303.1, 47.000000000000014, -256.00000000000034, -156.00000000000003, -7.60000000000008, -249.8000000000001, -6.400000000000029, -171.10000000000025, -16.899999999999906, -22.299999999999763, -36.70000000000003, -167.20000000000005, -266.1999999999999, 34.10000000000018, -360.60000000000014, -195.70000000000027, -166.90000000000003, 1.0999999999999837, 20.000000000000014, 31.700000000000202, -133.89999999999998, -57.70000000000004, -379.9000000000001, -50.19999999999987, -88.29999999999997, 54.79999999999994, -274.9999999999999, 30.500000000000163, -54.99999999999997, -152.20000000000024, -263.49999999999966, -23.199999999999747, 100.09999999999948, -145.60000000000045, -129.10000000000014], "policy_predator_policy_reward": [8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 52.0, 114.0, 0.0, 31.0, 0.0, 0.0, 64.0, 20.0, 73.0, 20.0, 13.0, 54.0, 3.0, 13.0, 0.0, 35.0, 77.0, 9.0, 57.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 28.0, 128.0, 99.0, 110.0, 18.0, 54.0, 46.0, 15.0, 37.0, 0.0, 1.0, 1.0, 48.0, 0.0, 0.0, 68.0, 110.0, 0.0, 0.0, 0.0, 71.0, 55.0, 0.0, 82.0, 0.0, 67.0, 88.0, 0.0, 10.0, 0.0, 36.0, 0.0, 70.0, 57.0, 0.0, 98.0, 15.0, 13.0, 72.0, 48.0, 79.0, 0.0, 0.0, 111.0, 0.0, 24.0, 153.0, 26.0, 69.0, 0.0, 0.0, 131.0, 50.0, 108.0, 93.0, 20.0, 11.0, 127.0, 0.0, 0.0, 0.0, 16.0, 23.0, 2.0, 12.0, 0.0, 52.0, 0.0, 73.0, 0.0, 96.0, 66.0, 5.0, 33.0, 0.0, 0.0, 0.0, 24.0, 73.0, 185.0, 44.0, 72.0, 89.0, 0.0, 0.0, 0.0, 108.0, 58.0, 46.0, 0.0, 89.0, 72.0, 63.0, 4.0, 0.0, 18.0, 0.0, 138.0, 96.0, 98.0, 12.0, 64.0, 56.0, 26.0, 0.0, 69.0, 98.0, 43.0, 3.0, 91.0, 58.0, 36.0, 57.0, 189.0, 35.0, 0.0, 61.0, 123.0, 121.0, 120.0, 118.0, 25.0, 45.0, 174.0, 0.0, 95.0, 1.0, 59.0, 113.0, 0.0, 0.0, 35.0, 98.0, 35.0, 234.0, 64.0, 147.0, 110.0, 59.0, 0.0, 199.0, 103.0, 15.0, 43.0, 14.0, 168.0, 126.0, 61.0, 173.0, 156.0, 79.0, 9.0, 0.0, 18.0, 95.0, 204.0, 102.0, 8.0, 118.0, 84.0, 179.0, 34.0, 12.0, 49.0, 155.0, 0.0, 21.0, 71.0, 87.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5357802413895876, "mean_inference_ms": 1.34773741950259, "mean_action_processing_ms": 0.22030715129974385, "mean_env_wait_ms": 0.18703542679264248, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035817623138427734, "StateBufferConnector_ms": 0.0029044151306152344, "ViewRequirementAgentConnector_ms": 0.09030663967132568}, "num_episodes": 18, "episode_return_max": 172.69999999999962, "episode_return_min": -304.99999999999915, "episode_return_mean": -15.84800000000016, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 415.05167743708233, "num_env_steps_trained_throughput_per_sec": 415.05167743708233, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 9009.979, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9009.941, "sample_time_ms": 1062.465, "learn_time_ms": 7934.665, "learn_throughput": 504.117, "synch_weights_time_ms": 11.858}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "04dec_00002", "date": "2024-08-13_16-25-01", "timestamp": 1723580701, "time_this_iter_s": 9.685243129730225, "time_total_s": 136.66877007484436, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359cb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 136.66877007484436, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 35.70769230769231, "ram_util_percent": 82.77692307692307}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4207938413731951, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 0.00010000000000000003, "total_loss": 3.1714979649851562, "policy_loss": -0.005646402285823589, "vf_loss": 3.1759266804135033, "vf_explained_var": -0.0007860302925109863, "kl": 0.021647818780872664, "entropy": 1.4579042517318928, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6687607734370484, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 4.359922770217613, "policy_loss": -0.004409344457878322, "vf_loss": 4.362973738473559, "vf_explained_var": 0.03369474414164427, "kl": 0.013583727492197143, "entropy": 1.3871875610301103, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 238.699999999999, "episode_reward_min": -304.99999999999915, "episode_reward_mean": -13.823000000000192, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 141.4999999999998, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": -57.0715000000001, "predator_policy": 50.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.600000000000195, 31.400000000000205, 41.60000000000032, -5.799999999999995, 165.09999999999917, -114.70000000000006, 63.40000000000051, -4.499999999999979, 152.29999999999916, -33.09999999999967, -82.50000000000014, 38.00000000000027, 3.700000000000023, 172.69999999999962, 15.100000000000362, -51.599999999999724, -55.600000000000485, -69.10000000000048, 40.0000000000003, -260.60000000000116, -151.4000000000007, 10.200000000000225, 92.19999999999956, -113.40000000000114, -67.70000000000057, -36.09999999999995, -89.80000000000052, 40.0000000000003, 90.69999999999888, 119.69999999999942, 3.500000000000067, -27.700000000000024, -70.4, 38.40000000000027, 97.29999999999907, 40.0000000000003, -12.700000000000001, -172.90000000000035, 63.59999999999944, 61.600000000000264, -73.70000000000088, -51.29999999999975, 6.300000000000235, 18.100000000000044, 35.600000000000236, 20.200000000000273, -217.40000000000015, -18.00000000000017, 36.7000000000003, 46.79999999999968, -14.700000000000038, 29.000000000000412, -123.90000000000043, 48.99999999999985, -169.9000000000009, -25.299999999999926, -172.60000000000005, -200.00000000000017, 68.29999999999933, -304.99999999999915, 5.500000000000005, -149.20000000000124, 110.19999999999874, -48.39999999999971, -234.60000000000065, 2.0000000000002647, 5.40000000000008, -57.199999999999825, -69.99999999999986, -2.0000000000000506, -139.39999999999995, -92.50000000000063, -127.60000000000022, 30.100000000000286, 10.799999999999697, -131.59999999999997, -12.499999999999888, 42.800000000000296, 21.499999999999737, -211.7000000000004, 97.89999999999893, -116.69999999999999, 50.80000000000045, 28.700000000000266, -74.40000000000038, 93.99999999999878, 89.79999999999974, 40.0000000000003, -153.30000000000075, 119.49999999999982, 21.600000000000264, -55.40000000000127, -156.40000000000114, 45.40000000000029, 238.699999999999, 117.3999999999987, 37.4000000000002, 1.0000000000002558, 208.9999999999996, 129.39999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-115.30000000000032, 17.900000000000013, 36.20000000000019, -56.80000000000014, 20.000000000000014, 20.600000000000026, 20.000000000000014, -74.80000000000044, 23.60000000000007, 141.4999999999998, -93.40000000000083, -199.29999999999987, 43.40000000000025, 20.000000000000014, -28.599999999999824, -46.899999999999864, 11.599999999999973, 85.69999999999928, -107.20000000000056, -7.899999999999942, -180.70000000000022, -56.799999999999926, 20.000000000000014, 7.99999999999997, -19.899999999999814, -12.399999999999858, 40.699999999999974, 62.000000000000085, -61.899999999999906, 20.000000000000014, -156.40000000000023, -8.199999999999973, -132.10000000000008, -8.499999999999906, -211.9000000000002, 15.799999999999962, 20.000000000000014, 20.000000000000014, -175.3000000000006, -196.30000000000052, -269.8000000000002, -58.600000000000094, -104.80000000000013, 20.000000000000014, 72.19999999999978, 20.000000000000014, -137.1000000000006, -157.30000000000055, -194.20000000000053, -74.50000000000004, -45.10000000000004, -22.000000000000014, -163.30000000000055, -53.50000000000004, 20.000000000000014, 20.000000000000014, 31.69999999999981, 20.000000000000014, 5.000000000000014, 100.69999999999985, 20.000000000000014, -68.50000000000023, 21.800000000000047, -122.49999999999996, -124.60000000000036, -41.799999999999876, 20.000000000000014, -52.600000000000236, 38.9000000000001, 25.400000000000098, 20.000000000000014, 20.000000000000014, -130.60000000000002, 20.900000000000027, -387.39999999999986, -14.499999999999815, 95.2999999999995, -192.69999999999996, 20.000000000000014, 41.60000000000008, -201.40000000000043, 19.70000000000001, 15.799999999999946, -171.10000000000036, 64.40000000000012, -147.0999999999999, 52.09999999999992, -168.99999999999983, 11.59999999999997, 20.000000000000014, 11.599999999999946, -9.400000000000007, -181.60000000000002, -269.8000000000001, -53.5, -74.49999999999994, 66.80000000000001, -150.10000000000056, 44.90000000000021, -24.100000000000023, -201.7000000000001, 20.000000000000014, -49.300000000000004, 32.3000000000002, -171.10000000000045, -101.80000000000013, 82.99999999999926, -127.00000000000023, -298.4, -95.50000000000067, -49.599999999999845, -36.69999999999999, -177.40000000000003, -239.20000000000007, -232.00000000000009, -206.00000000000006, 40.10000000000015, -41.7999999999998, -255.10000000000014, -223.90000000000043, -154.30000000000038, 63.80000000000015, -103.90000000000077, -217.30000000000047, 20.000000000000014, 90.1999999999994, -1.300000000000042, -180.09999999999997, -200.50000000000054, -303.1, 47.000000000000014, -256.00000000000034, -156.00000000000003, -7.60000000000008, -249.8000000000001, -6.400000000000029, -171.10000000000025, -16.899999999999906, -22.299999999999763, -36.70000000000003, -167.20000000000005, -266.1999999999999, 34.10000000000018, -360.60000000000014, -195.70000000000027, -166.90000000000003, 1.0999999999999837, 20.000000000000014, 31.700000000000202, -133.89999999999998, -57.70000000000004, -379.9000000000001, -50.19999999999987, -88.29999999999997, 54.79999999999994, -274.9999999999999, 30.500000000000163, -54.99999999999997, -152.20000000000024, -263.49999999999966, -23.199999999999747, 100.09999999999948, -145.60000000000045, -129.10000000000014, 29.000000000000167, 21.800000000000047, -28.30000000000002, 20.000000000000014, -228.4000000000001, 20.000000000000014, 73.99999999999947, 20.000000000000014, -37.89999999999998, 49.70000000000011, 20.000000000000014, 20.000000000000014, -291.9999999999997, -46.29999999999987, -17.800000000000125, 71.29999999999968, 20.000000000000014, -30.400000000000016, -99.70000000000081, -45.69999999999991, -183.70000000000059, -156.70000000000059, 25.400000000000055, 20.000000000000014, 109.99999999999943, 127.6999999999996, 20.000000000000014, 97.39999999999941, -288.00000000000006, 76.39999999999964, -118.60000000000012, 47.600000000000215, 133.09999999999982, 74.90000000000005, -12.099999999999753, 114.4999999999998], "policy_predator_policy_reward": [54.0, 46.0, 15.0, 37.0, 0.0, 1.0, 1.0, 48.0, 0.0, 0.0, 68.0, 110.0, 0.0, 0.0, 0.0, 71.0, 55.0, 0.0, 82.0, 0.0, 67.0, 88.0, 0.0, 10.0, 0.0, 36.0, 0.0, 70.0, 57.0, 0.0, 98.0, 15.0, 13.0, 72.0, 48.0, 79.0, 0.0, 0.0, 111.0, 0.0, 24.0, 153.0, 26.0, 69.0, 0.0, 0.0, 131.0, 50.0, 108.0, 93.0, 20.0, 11.0, 127.0, 0.0, 0.0, 0.0, 16.0, 23.0, 2.0, 12.0, 0.0, 52.0, 0.0, 73.0, 0.0, 96.0, 66.0, 5.0, 33.0, 0.0, 0.0, 0.0, 24.0, 73.0, 185.0, 44.0, 72.0, 89.0, 0.0, 0.0, 0.0, 108.0, 58.0, 46.0, 0.0, 89.0, 72.0, 63.0, 4.0, 0.0, 18.0, 0.0, 138.0, 96.0, 98.0, 12.0, 64.0, 56.0, 26.0, 0.0, 69.0, 98.0, 43.0, 3.0, 91.0, 58.0, 36.0, 57.0, 189.0, 35.0, 0.0, 61.0, 123.0, 121.0, 120.0, 118.0, 25.0, 45.0, 174.0, 0.0, 95.0, 1.0, 59.0, 113.0, 0.0, 0.0, 35.0, 98.0, 35.0, 234.0, 64.0, 147.0, 110.0, 59.0, 0.0, 199.0, 103.0, 15.0, 43.0, 14.0, 168.0, 126.0, 61.0, 173.0, 156.0, 79.0, 9.0, 0.0, 18.0, 95.0, 204.0, 102.0, 8.0, 118.0, 84.0, 179.0, 34.0, 12.0, 49.0, 155.0, 0.0, 21.0, 71.0, 87.0, 0.0, 0.0, 23.0, 14.0, 39.0, 95.0, 0.0, 0.0, 51.0, 27.0, 0.0, 0.0, 118.0, 67.0, 0.0, 66.0, 17.0, 15.0, 33.0, 57.0, 82.0, 102.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 163.0, 32.0, 40.0, 1.0, 0.0, 27.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5358648626329195, "mean_inference_ms": 1.3478848214988424, "mean_action_processing_ms": 0.2202082718546113, "mean_env_wait_ms": 0.18671560197549145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003847837448120117, "StateBufferConnector_ms": 0.0029277801513671875, "ViewRequirementAgentConnector_ms": 0.09113430976867676}, "num_episodes": 18, "episode_return_max": 238.699999999999, "episode_return_min": -304.99999999999915, "episode_return_mean": -13.823000000000192, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 415.93454295500817, "num_env_steps_trained_throughput_per_sec": 415.93454295500817, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 9075.932, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9075.895, "sample_time_ms": 1084.017, "learn_time_ms": 7978.993, "learn_throughput": 501.316, "synch_weights_time_ms": 11.899}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "04dec_00002", "date": "2024-08-13_16-25-10", "timestamp": 1723580710, "time_this_iter_s": 9.675058841705322, "time_total_s": 146.34382891654968, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b35870d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 146.34382891654968, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 37.24999999999999, "ram_util_percent": 82.42142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3289121628241249, "cur_kl_coeff": 0.084375, "cur_lr": 0.00010000000000000003, "total_loss": 0.9347514142119695, "policy_loss": -0.0062564642405107855, "vf_loss": 0.9399889117353177, "vf_explained_var": 0.00859367330238302, "kl": 0.012076652600126348, "entropy": 1.5106940766490957, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.481800318245219, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 2.1506965456816256, "policy_loss": -0.0010381645426922848, "vf_loss": 2.1512024075265916, "vf_explained_var": 0.07609214852095912, "kl": 0.005323028025293805, "entropy": 1.3631250445804899, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 238.699999999999, "episode_reward_min": -304.99999999999915, "episode_reward_mean": -4.6880000000002235, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.09999999999982, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": -47.79400000000009, "predator_policy": 45.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -260.60000000000116, -151.4000000000007, 10.200000000000225, 92.19999999999956, -113.40000000000114, -67.70000000000057, -36.09999999999995, -89.80000000000052, 40.0000000000003, 90.69999999999888, 119.69999999999942, 3.500000000000067, -27.700000000000024, -70.4, 38.40000000000027, 97.29999999999907, 40.0000000000003, -12.700000000000001, -172.90000000000035, 63.59999999999944, 61.600000000000264, -73.70000000000088, -51.29999999999975, 6.300000000000235, 18.100000000000044, 35.600000000000236, 20.200000000000273, -217.40000000000015, -18.00000000000017, 36.7000000000003, 46.79999999999968, -14.700000000000038, 29.000000000000412, -123.90000000000043, 48.99999999999985, -169.9000000000009, -25.299999999999926, -172.60000000000005, -200.00000000000017, 68.29999999999933, -304.99999999999915, 5.500000000000005, -149.20000000000124, 110.19999999999874, -48.39999999999971, -234.60000000000065, 2.0000000000002647, 5.40000000000008, -57.199999999999825, -69.99999999999986, -2.0000000000000506, -139.39999999999995, -92.50000000000063, -127.60000000000022, 30.100000000000286, 10.799999999999697, -131.59999999999997, -12.499999999999888, 42.800000000000296, 21.499999999999737, -211.7000000000004, 97.89999999999893, -116.69999999999999, 50.80000000000045, 28.700000000000266, -74.40000000000038, 93.99999999999878, 89.79999999999974, 40.0000000000003, -153.30000000000075, 119.49999999999982, 21.600000000000264, -55.40000000000127, -156.40000000000114, 45.40000000000029, 238.699999999999, 117.3999999999987, 37.4000000000002, 1.0000000000002558, 208.9999999999996, 129.39999999999944, 62.50000000000046, 66.6000000000003, -3.299999999999887, 71.79999999999993, 74.29999999999951, 53.100000000000485, 113.69999999999928, 36.70000000000025, 148.89999999999938, 131.49999999999875, 40.0000000000003, 66.09999999999945, 52.60000000000047, 111.09999999999819, 108.89999999999844, 40.0000000000003, -9.299999999999688, 17.299999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -175.3000000000006, -196.30000000000052, -269.8000000000002, -58.600000000000094, -104.80000000000013, 20.000000000000014, 72.19999999999978, 20.000000000000014, -137.1000000000006, -157.30000000000055, -194.20000000000053, -74.50000000000004, -45.10000000000004, -22.000000000000014, -163.30000000000055, -53.50000000000004, 20.000000000000014, 20.000000000000014, 31.69999999999981, 20.000000000000014, 5.000000000000014, 100.69999999999985, 20.000000000000014, -68.50000000000023, 21.800000000000047, -122.49999999999996, -124.60000000000036, -41.799999999999876, 20.000000000000014, -52.600000000000236, 38.9000000000001, 25.400000000000098, 20.000000000000014, 20.000000000000014, -130.60000000000002, 20.900000000000027, -387.39999999999986, -14.499999999999815, 95.2999999999995, -192.69999999999996, 20.000000000000014, 41.60000000000008, -201.40000000000043, 19.70000000000001, 15.799999999999946, -171.10000000000036, 64.40000000000012, -147.0999999999999, 52.09999999999992, -168.99999999999983, 11.59999999999997, 20.000000000000014, 11.599999999999946, -9.400000000000007, -181.60000000000002, -269.8000000000001, -53.5, -74.49999999999994, 66.80000000000001, -150.10000000000056, 44.90000000000021, -24.100000000000023, -201.7000000000001, 20.000000000000014, -49.300000000000004, 32.3000000000002, -171.10000000000045, -101.80000000000013, 82.99999999999926, -127.00000000000023, -298.4, -95.50000000000067, -49.599999999999845, -36.69999999999999, -177.40000000000003, -239.20000000000007, -232.00000000000009, -206.00000000000006, 40.10000000000015, -41.7999999999998, -255.10000000000014, -223.90000000000043, -154.30000000000038, 63.80000000000015, -103.90000000000077, -217.30000000000047, 20.000000000000014, 90.1999999999994, -1.300000000000042, -180.09999999999997, -200.50000000000054, -303.1, 47.000000000000014, -256.00000000000034, -156.00000000000003, -7.60000000000008, -249.8000000000001, -6.400000000000029, -171.10000000000025, -16.899999999999906, -22.299999999999763, -36.70000000000003, -167.20000000000005, -266.1999999999999, 34.10000000000018, -360.60000000000014, -195.70000000000027, -166.90000000000003, 1.0999999999999837, 20.000000000000014, 31.700000000000202, -133.89999999999998, -57.70000000000004, -379.9000000000001, -50.19999999999987, -88.29999999999997, 54.79999999999994, -274.9999999999999, 30.500000000000163, -54.99999999999997, -152.20000000000024, -263.49999999999966, -23.199999999999747, 100.09999999999948, -145.60000000000045, -129.10000000000014, 29.000000000000167, 21.800000000000047, -28.30000000000002, 20.000000000000014, -228.4000000000001, 20.000000000000014, 73.99999999999947, 20.000000000000014, -37.89999999999998, 49.70000000000011, 20.000000000000014, 20.000000000000014, -291.9999999999997, -46.29999999999987, -17.800000000000125, 71.29999999999968, 20.000000000000014, -30.400000000000016, -99.70000000000081, -45.69999999999991, -183.70000000000059, -156.70000000000059, 25.400000000000055, 20.000000000000014, 109.99999999999943, 127.6999999999996, 20.000000000000014, 97.39999999999941, -288.00000000000006, 76.39999999999964, -118.60000000000012, 47.600000000000215, 133.09999999999982, 74.90000000000005, -12.099999999999753, 114.4999999999998, 20.000000000000014, 42.50000000000022, 17.899999999999988, 46.70000000000024, 17.59999999999999, -61.90000000000051, 13.699999999999964, 55.10000000000023, 73.99999999999963, -63.700000000000635, 33.200000000000244, -0.10000000000004367, 88.69999999999976, 20.000000000000014, 20.000000000000014, 13.699999999999967, 67.69999999999982, 81.19999999999969, 82.09999999999948, 43.400000000000226, 20.000000000000014, 20.000000000000014, -39.69999999999982, 45.80000000000018, 20.000000000000014, 32.600000000000215, 53.30000000000023, 57.800000000000225, 61.7000000000002, 45.200000000000244, 20.000000000000014, 20.000000000000014, -91.9000000000008, 23.60000000000008, -0.9999999999999992, -15.699999999999747], "policy_predator_policy_reward": [0.0, 0.0, 111.0, 0.0, 24.0, 153.0, 26.0, 69.0, 0.0, 0.0, 131.0, 50.0, 108.0, 93.0, 20.0, 11.0, 127.0, 0.0, 0.0, 0.0, 16.0, 23.0, 2.0, 12.0, 0.0, 52.0, 0.0, 73.0, 0.0, 96.0, 66.0, 5.0, 33.0, 0.0, 0.0, 0.0, 24.0, 73.0, 185.0, 44.0, 72.0, 89.0, 0.0, 0.0, 0.0, 108.0, 58.0, 46.0, 0.0, 89.0, 72.0, 63.0, 4.0, 0.0, 18.0, 0.0, 138.0, 96.0, 98.0, 12.0, 64.0, 56.0, 26.0, 0.0, 69.0, 98.0, 43.0, 3.0, 91.0, 58.0, 36.0, 57.0, 189.0, 35.0, 0.0, 61.0, 123.0, 121.0, 120.0, 118.0, 25.0, 45.0, 174.0, 0.0, 95.0, 1.0, 59.0, 113.0, 0.0, 0.0, 35.0, 98.0, 35.0, 234.0, 64.0, 147.0, 110.0, 59.0, 0.0, 199.0, 103.0, 15.0, 43.0, 14.0, 168.0, 126.0, 61.0, 173.0, 156.0, 79.0, 9.0, 0.0, 18.0, 95.0, 204.0, 102.0, 8.0, 118.0, 84.0, 179.0, 34.0, 12.0, 49.0, 155.0, 0.0, 21.0, 71.0, 87.0, 0.0, 0.0, 23.0, 14.0, 39.0, 95.0, 0.0, 0.0, 51.0, 27.0, 0.0, 0.0, 118.0, 67.0, 0.0, 66.0, 17.0, 15.0, 33.0, 57.0, 82.0, 102.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 163.0, 32.0, 40.0, 1.0, 0.0, 27.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 41.0, 3.0, 0.0, 47.0, 17.0, 10.0, 10.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 19.0, 41.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 17.0, 42.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.537063868845626, "mean_inference_ms": 1.3509936724847522, "mean_action_processing_ms": 0.22048143269380455, "mean_env_wait_ms": 0.18685509446870158, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039528608322143555, "StateBufferConnector_ms": 0.0029358863830566406, "ViewRequirementAgentConnector_ms": 0.09215879440307617}, "num_episodes": 18, "episode_return_max": 238.699999999999, "episode_return_min": -304.99999999999915, "episode_return_mean": -4.6880000000002235, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 411.303444948673, "num_env_steps_trained_throughput_per_sec": 411.303444948673, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 9171.45, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9171.411, "sample_time_ms": 1101.173, "learn_time_ms": 8057.133, "learn_throughput": 496.454, "synch_weights_time_ms": 12.113}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "04dec_00002", "date": "2024-08-13_16-25-20", "timestamp": 1723580720, "time_this_iter_s": 9.767210960388184, "time_total_s": 156.11103987693787, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a2cca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 156.11103987693787, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 39.15714285714286, "ram_util_percent": 83.10714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.33645610672732196, "cur_kl_coeff": 0.084375, "cur_lr": 0.00010000000000000003, "total_loss": 1.367074326768754, "policy_loss": -0.010020802899081476, "vf_loss": 1.375373620441351, "vf_explained_var": 0.0016594424134209042, "kl": 0.020403068226758823, "entropy": 1.5426138284345152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4711819224848004, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 2.2285101248789085, "policy_loss": -0.004915725530208971, "vf_loss": 2.231879363236604, "vf_explained_var": 0.021887120115693916, "kl": 0.015464998848987903, "entropy": 1.2640900362736334, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 238.699999999999, "episode_reward_min": -304.99999999999915, "episode_reward_mean": 9.5539999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.09999999999982, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": -34.66300000000006, "predator_policy": 39.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-73.70000000000088, -51.29999999999975, 6.300000000000235, 18.100000000000044, 35.600000000000236, 20.200000000000273, -217.40000000000015, -18.00000000000017, 36.7000000000003, 46.79999999999968, -14.700000000000038, 29.000000000000412, -123.90000000000043, 48.99999999999985, -169.9000000000009, -25.299999999999926, -172.60000000000005, -200.00000000000017, 68.29999999999933, -304.99999999999915, 5.500000000000005, -149.20000000000124, 110.19999999999874, -48.39999999999971, -234.60000000000065, 2.0000000000002647, 5.40000000000008, -57.199999999999825, -69.99999999999986, -2.0000000000000506, -139.39999999999995, -92.50000000000063, -127.60000000000022, 30.100000000000286, 10.799999999999697, -131.59999999999997, -12.499999999999888, 42.800000000000296, 21.499999999999737, -211.7000000000004, 97.89999999999893, -116.69999999999999, 50.80000000000045, 28.700000000000266, -74.40000000000038, 93.99999999999878, 89.79999999999974, 40.0000000000003, -153.30000000000075, 119.49999999999982, 21.600000000000264, -55.40000000000127, -156.40000000000114, 45.40000000000029, 238.699999999999, 117.3999999999987, 37.4000000000002, 1.0000000000002558, 208.9999999999996, 129.39999999999944, 62.50000000000046, 66.6000000000003, -3.299999999999887, 71.79999999999993, 74.29999999999951, 53.100000000000485, 113.69999999999928, 36.70000000000025, 148.89999999999938, 131.49999999999875, 40.0000000000003, 66.09999999999945, 52.60000000000047, 111.09999999999819, 108.89999999999844, 40.0000000000003, -9.299999999999688, 17.299999999999972, 40.0000000000003, 45.60000000000036, -6.999999999999645, 111.09999999999843, 39.700000000000294, 32.20000000000019, 60.00000000000028, 37.800000000000274, 106.69999999999857, 9.699999999999958, 75.99999999999964, 56.999999999999915, 39.00000000000029, 12.499999999999927, 41.800000000000296, 106.29999999999865, 69.09999999999995, 57.600000000000506, 166.89999999999867, 62.000000000000476, -99.30000000000166, 54.000000000000455], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-201.40000000000043, 19.70000000000001, 15.799999999999946, -171.10000000000036, 64.40000000000012, -147.0999999999999, 52.09999999999992, -168.99999999999983, 11.59999999999997, 20.000000000000014, 11.599999999999946, -9.400000000000007, -181.60000000000002, -269.8000000000001, -53.5, -74.49999999999994, 66.80000000000001, -150.10000000000056, 44.90000000000021, -24.100000000000023, -201.7000000000001, 20.000000000000014, -49.300000000000004, 32.3000000000002, -171.10000000000045, -101.80000000000013, 82.99999999999926, -127.00000000000023, -298.4, -95.50000000000067, -49.599999999999845, -36.69999999999999, -177.40000000000003, -239.20000000000007, -232.00000000000009, -206.00000000000006, 40.10000000000015, -41.7999999999998, -255.10000000000014, -223.90000000000043, -154.30000000000038, 63.80000000000015, -103.90000000000077, -217.30000000000047, 20.000000000000014, 90.1999999999994, -1.300000000000042, -180.09999999999997, -200.50000000000054, -303.1, 47.000000000000014, -256.00000000000034, -156.00000000000003, -7.60000000000008, -249.8000000000001, -6.400000000000029, -171.10000000000025, -16.899999999999906, -22.299999999999763, -36.70000000000003, -167.20000000000005, -266.1999999999999, 34.10000000000018, -360.60000000000014, -195.70000000000027, -166.90000000000003, 1.0999999999999837, 20.000000000000014, 31.700000000000202, -133.89999999999998, -57.70000000000004, -379.9000000000001, -50.19999999999987, -88.29999999999997, 54.79999999999994, -274.9999999999999, 30.500000000000163, -54.99999999999997, -152.20000000000024, -263.49999999999966, -23.199999999999747, 100.09999999999948, -145.60000000000045, -129.10000000000014, 29.000000000000167, 21.800000000000047, -28.30000000000002, 20.000000000000014, -228.4000000000001, 20.000000000000014, 73.99999999999947, 20.000000000000014, -37.89999999999998, 49.70000000000011, 20.000000000000014, 20.000000000000014, -291.9999999999997, -46.29999999999987, -17.800000000000125, 71.29999999999968, 20.000000000000014, -30.400000000000016, -99.70000000000081, -45.69999999999991, -183.70000000000059, -156.70000000000059, 25.400000000000055, 20.000000000000014, 109.99999999999943, 127.6999999999996, 20.000000000000014, 97.39999999999941, -288.00000000000006, 76.39999999999964, -118.60000000000012, 47.600000000000215, 133.09999999999982, 74.90000000000005, -12.099999999999753, 114.4999999999998, 20.000000000000014, 42.50000000000022, 17.899999999999988, 46.70000000000024, 17.59999999999999, -61.90000000000051, 13.699999999999964, 55.10000000000023, 73.99999999999963, -63.700000000000635, 33.200000000000244, -0.10000000000004367, 88.69999999999976, 20.000000000000014, 20.000000000000014, 13.699999999999967, 67.69999999999982, 81.19999999999969, 82.09999999999948, 43.400000000000226, 20.000000000000014, 20.000000000000014, -39.69999999999982, 45.80000000000018, 20.000000000000014, 32.600000000000215, 53.30000000000023, 57.800000000000225, 61.7000000000002, 45.200000000000244, 20.000000000000014, 20.000000000000014, -91.9000000000008, 23.60000000000008, -0.9999999999999992, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999962, 3.7999999999999887, -161.99999999999986, 20.000000000000014, 53.30000000000023, 57.80000000000019, 18.19999999999999, 15.499999999999963, 2.5999999999999646, 8.599999999999975, 23.3000000000001, 19.70000000000002, 20.000000000000014, 6.799999999999988, 73.39999999999952, 2.2999999999999923, 16.09999999999997, -72.40000000000055, 47.00000000000022, 29.000000000000163, -39.69999999999991, 13.699999999999946, -13.899999999999853, 20.90000000000003, -32.499999999999766, 20.000000000000014, 20.000000000000014, 21.800000000000047, 59.60000000000016, 31.70000000000022, -8.199999999999958, 44.30000000000015, 20.90000000000003, 34.700000000000244, 61.40000000000018, 105.4999999999994, 28.700000000000166, 26.30000000000012, -97.60000000000082, -57.70000000000038, -21.999999999999996, 56.00000000000023], "policy_predator_policy_reward": [0.0, 108.0, 58.0, 46.0, 0.0, 89.0, 72.0, 63.0, 4.0, 0.0, 18.0, 0.0, 138.0, 96.0, 98.0, 12.0, 64.0, 56.0, 26.0, 0.0, 69.0, 98.0, 43.0, 3.0, 91.0, 58.0, 36.0, 57.0, 189.0, 35.0, 0.0, 61.0, 123.0, 121.0, 120.0, 118.0, 25.0, 45.0, 174.0, 0.0, 95.0, 1.0, 59.0, 113.0, 0.0, 0.0, 35.0, 98.0, 35.0, 234.0, 64.0, 147.0, 110.0, 59.0, 0.0, 199.0, 103.0, 15.0, 43.0, 14.0, 168.0, 126.0, 61.0, 173.0, 156.0, 79.0, 9.0, 0.0, 18.0, 95.0, 204.0, 102.0, 8.0, 118.0, 84.0, 179.0, 34.0, 12.0, 49.0, 155.0, 0.0, 21.0, 71.0, 87.0, 0.0, 0.0, 23.0, 14.0, 39.0, 95.0, 0.0, 0.0, 51.0, 27.0, 0.0, 0.0, 118.0, 67.0, 0.0, 66.0, 17.0, 15.0, 33.0, 57.0, 82.0, 102.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 163.0, 32.0, 40.0, 1.0, 0.0, 27.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 41.0, 3.0, 0.0, 47.0, 17.0, 10.0, 10.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 19.0, 41.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 17.0, 42.0, 17.0, 17.0, 0.0, 0.0, 24.0, 2.0, 0.0, 135.0, 0.0, 0.0, 6.0, 0.0, 0.0, 21.0, 16.0, 1.0, 11.0, 0.0, 29.0, 2.0, 44.0, 22.0, 0.0, 0.0, 23.0, 60.0, 0.0, 32.0, 25.0, 0.0, 0.0, 0.0, 3.0, 12.0, 2.0, 31.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 56.0, 0.0, 20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5391332892654013, "mean_inference_ms": 1.3555371156428384, "mean_action_processing_ms": 0.22087980586068867, "mean_env_wait_ms": 0.18703722702458286, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003952503204345703, "StateBufferConnector_ms": 0.0032432079315185547, "ViewRequirementAgentConnector_ms": 0.09667718410491943}, "num_episodes": 22, "episode_return_max": 238.699999999999, "episode_return_min": -304.99999999999915, "episode_return_mean": 9.5539999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 411.1041735639528, "num_env_steps_trained_throughput_per_sec": 411.1041735639528, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 9263.782, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9263.741, "sample_time_ms": 1119.122, "learn_time_ms": 8131.261, "learn_throughput": 491.929, "synch_weights_time_ms": 12.274}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "04dec_00002", "date": "2024-08-13_16-25-30", "timestamp": 1723580730, "time_this_iter_s": 9.794724941253662, "time_total_s": 165.90576481819153, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0456f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 165.90576481819153, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 37.06428571428571, "ram_util_percent": 82.74285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29271279265167854, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 3.811970218527254, "policy_loss": -0.007619084054407067, "vf_loss": 3.8181117590142306, "vf_explained_var": 0.0010337384289534634, "kl": 0.011674404754257114, "entropy": 1.5224253177642821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1396621943742193, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.1483975000482385, "policy_loss": -0.003985152956684707, "vf_loss": 5.151078314629812, "vf_explained_var": 0.00022148307038362695, "kl": 0.013043366198189424, "entropy": 1.1741263550425334, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 238.699999999999, "episode_reward_min": -305.60000000000014, "episode_reward_mean": 17.105999999999852, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -453.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.09999999999982, "predator_policy": 309.0}, "policy_reward_mean": {"prey_policy": -26.222000000000023, "predator_policy": 34.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-48.39999999999971, -234.60000000000065, 2.0000000000002647, 5.40000000000008, -57.199999999999825, -69.99999999999986, -2.0000000000000506, -139.39999999999995, -92.50000000000063, -127.60000000000022, 30.100000000000286, 10.799999999999697, -131.59999999999997, -12.499999999999888, 42.800000000000296, 21.499999999999737, -211.7000000000004, 97.89999999999893, -116.69999999999999, 50.80000000000045, 28.700000000000266, -74.40000000000038, 93.99999999999878, 89.79999999999974, 40.0000000000003, -153.30000000000075, 119.49999999999982, 21.600000000000264, -55.40000000000127, -156.40000000000114, 45.40000000000029, 238.699999999999, 117.3999999999987, 37.4000000000002, 1.0000000000002558, 208.9999999999996, 129.39999999999944, 62.50000000000046, 66.6000000000003, -3.299999999999887, 71.79999999999993, 74.29999999999951, 53.100000000000485, 113.69999999999928, 36.70000000000025, 148.89999999999938, 131.49999999999875, 40.0000000000003, 66.09999999999945, 52.60000000000047, 111.09999999999819, 108.89999999999844, 40.0000000000003, -9.299999999999688, 17.299999999999972, 40.0000000000003, 45.60000000000036, -6.999999999999645, 111.09999999999843, 39.700000000000294, 32.20000000000019, 60.00000000000028, 37.800000000000274, 106.69999999999857, 9.699999999999958, 75.99999999999964, 56.999999999999915, 39.00000000000029, 12.499999999999927, 41.800000000000296, 106.29999999999865, 69.09999999999995, 57.600000000000506, 166.89999999999867, 62.000000000000476, -99.30000000000166, 54.000000000000455, -89.9, 10.999999999999938, -127.89999999999989, 89.29999999999916, 62.19999999999971, -6.499999999999808, -203.4000000000004, -34.399999999999714, 75.49999999999959, 57.10000000000032, -41.99999999999982, 12.49999999999992, -25.599999999999643, -64.4, 40.0000000000003, -60.69999999999961, 42.20000000000033, 40.0000000000003, 40.0000000000003, 60.70000000000039, 57.500000000000185, 32.30000000000018, -305.60000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1.300000000000042, -180.09999999999997, -200.50000000000054, -303.1, 47.000000000000014, -256.00000000000034, -156.00000000000003, -7.60000000000008, -249.8000000000001, -6.400000000000029, -171.10000000000025, -16.899999999999906, -22.299999999999763, -36.70000000000003, -167.20000000000005, -266.1999999999999, 34.10000000000018, -360.60000000000014, -195.70000000000027, -166.90000000000003, 1.0999999999999837, 20.000000000000014, 31.700000000000202, -133.89999999999998, -57.70000000000004, -379.9000000000001, -50.19999999999987, -88.29999999999997, 54.79999999999994, -274.9999999999999, 30.500000000000163, -54.99999999999997, -152.20000000000024, -263.49999999999966, -23.199999999999747, 100.09999999999948, -145.60000000000045, -129.10000000000014, 29.000000000000167, 21.800000000000047, -28.30000000000002, 20.000000000000014, -228.4000000000001, 20.000000000000014, 73.99999999999947, 20.000000000000014, -37.89999999999998, 49.70000000000011, 20.000000000000014, 20.000000000000014, -291.9999999999997, -46.29999999999987, -17.800000000000125, 71.29999999999968, 20.000000000000014, -30.400000000000016, -99.70000000000081, -45.69999999999991, -183.70000000000059, -156.70000000000059, 25.400000000000055, 20.000000000000014, 109.99999999999943, 127.6999999999996, 20.000000000000014, 97.39999999999941, -288.00000000000006, 76.39999999999964, -118.60000000000012, 47.600000000000215, 133.09999999999982, 74.90000000000005, -12.099999999999753, 114.4999999999998, 20.000000000000014, 42.50000000000022, 17.899999999999988, 46.70000000000024, 17.59999999999999, -61.90000000000051, 13.699999999999964, 55.10000000000023, 73.99999999999963, -63.700000000000635, 33.200000000000244, -0.10000000000004367, 88.69999999999976, 20.000000000000014, 20.000000000000014, 13.699999999999967, 67.69999999999982, 81.19999999999969, 82.09999999999948, 43.400000000000226, 20.000000000000014, 20.000000000000014, -39.69999999999982, 45.80000000000018, 20.000000000000014, 32.600000000000215, 53.30000000000023, 57.800000000000225, 61.7000000000002, 45.200000000000244, 20.000000000000014, 20.000000000000014, -91.9000000000008, 23.60000000000008, -0.9999999999999992, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999962, 3.7999999999999887, -161.99999999999986, 20.000000000000014, 53.30000000000023, 57.80000000000019, 18.19999999999999, 15.499999999999963, 2.5999999999999646, 8.599999999999975, 23.3000000000001, 19.70000000000002, 20.000000000000014, 6.799999999999988, 73.39999999999952, 2.2999999999999923, 16.09999999999997, -72.40000000000055, 47.00000000000022, 29.000000000000163, -39.69999999999991, 13.699999999999946, -13.899999999999853, 20.90000000000003, -32.499999999999766, 20.000000000000014, 20.000000000000014, 21.800000000000047, 59.60000000000016, 31.70000000000022, -8.199999999999958, 44.30000000000015, 20.90000000000003, 34.700000000000244, 61.40000000000018, 105.4999999999994, 28.700000000000166, 26.30000000000012, -97.60000000000082, -57.70000000000038, -21.999999999999996, 56.00000000000023, -36.699999999999775, -181.20000000000002, -38.799999999999805, 21.80000000000004, -205.0, -191.8999999999999, 40.7000000000001, 20.600000000000023, -11.50000000000004, 58.700000000000195, 20.000000000000014, -98.50000000000004, -259.89999999999895, -177.5, -97.60000000000055, 3.1999999999999775, 9.499999999999984, 20.000000000000014, 22.700000000000063, 34.40000000000007, -89.20000000000002, -74.80000000000081, -32.499999999999844, 20.000000000000014, -125.80000000000001, -11.79999999999983, -214.29999999999998, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000004, -87.3999999999998, -2.800000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000019, 20.000000000000014, 59.600000000000094, -45.09999999999976, 7.399999999999965, 17.899999999999977, -160.90000000000018, -453.7], "policy_predator_policy_reward": [35.0, 98.0, 35.0, 234.0, 64.0, 147.0, 110.0, 59.0, 0.0, 199.0, 103.0, 15.0, 43.0, 14.0, 168.0, 126.0, 61.0, 173.0, 156.0, 79.0, 9.0, 0.0, 18.0, 95.0, 204.0, 102.0, 8.0, 118.0, 84.0, 179.0, 34.0, 12.0, 49.0, 155.0, 0.0, 21.0, 71.0, 87.0, 0.0, 0.0, 23.0, 14.0, 39.0, 95.0, 0.0, 0.0, 51.0, 27.0, 0.0, 0.0, 118.0, 67.0, 0.0, 66.0, 17.0, 15.0, 33.0, 57.0, 82.0, 102.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 163.0, 32.0, 40.0, 1.0, 0.0, 27.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 41.0, 3.0, 0.0, 47.0, 17.0, 10.0, 10.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 19.0, 41.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 17.0, 42.0, 17.0, 17.0, 0.0, 0.0, 24.0, 2.0, 0.0, 135.0, 0.0, 0.0, 6.0, 0.0, 0.0, 21.0, 16.0, 1.0, 11.0, 0.0, 29.0, 2.0, 44.0, 22.0, 0.0, 0.0, 23.0, 60.0, 0.0, 32.0, 25.0, 0.0, 0.0, 0.0, 3.0, 12.0, 2.0, 31.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 56.0, 0.0, 20.0, 0.0, 101.0, 27.0, 0.0, 28.0, 133.0, 136.0, 0.0, 28.0, 0.0, 15.0, 72.0, 0.0, 0.0, 234.0, 0.0, 60.0, 26.0, 20.0, 0.0, 0.0, 76.0, 46.0, 0.0, 25.0, 24.0, 88.0, 96.0, 33.0, 0.0, 0.0, 0.0, 97.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 12.0, 6.0, 1.0, 0.0, 309.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5446998493913285, "mean_inference_ms": 1.371195601229153, "mean_action_processing_ms": 0.22203426211866442, "mean_env_wait_ms": 0.18867908791338261, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005403757095336914, "StateBufferConnector_ms": 0.004140615463256836, "ViewRequirementAgentConnector_ms": 0.11843907833099365}, "num_episodes": 23, "episode_return_max": 238.699999999999, "episode_return_min": -305.60000000000014, "episode_return_mean": 17.105999999999852, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 401.4866660976001, "num_env_steps_trained_throughput_per_sec": 401.4866660976001, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 9390.596, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9390.554, "sample_time_ms": 1174.957, "learn_time_ms": 8201.749, "learn_throughput": 487.701, "synch_weights_time_ms": 12.57}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "04dec_00002", "date": "2024-08-13_16-25-40", "timestamp": 1723580740, "time_this_iter_s": 10.016837120056152, "time_total_s": 175.92260193824768, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359d700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 175.92260193824768, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 37.792857142857144, "ram_util_percent": 82.90714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5125093306813922, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 3.6007105302558373, "policy_loss": -0.00478092076715141, "vf_loss": 3.60442147683845, "vf_explained_var": 0.008071557396934145, "kl": 0.00845417045512662, "entropy": 1.4971373629317712, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3341819893470201, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 4.151768378101329, "policy_loss": -0.005162700219942188, "vf_loss": 4.155855073752226, "vf_explained_var": 0.002498491983565073, "kl": 0.010760185168800267, "entropy": 1.217000290073415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 238.699999999999, "episode_reward_min": -305.60000000000014, "episode_reward_mean": 26.586999999999875, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.09999999999982, "predator_policy": 309.0}, "policy_reward_mean": {"prey_policy": -15.051500000000015, "predator_policy": 28.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-116.69999999999999, 50.80000000000045, 28.700000000000266, -74.40000000000038, 93.99999999999878, 89.79999999999974, 40.0000000000003, -153.30000000000075, 119.49999999999982, 21.600000000000264, -55.40000000000127, -156.40000000000114, 45.40000000000029, 238.699999999999, 117.3999999999987, 37.4000000000002, 1.0000000000002558, 208.9999999999996, 129.39999999999944, 62.50000000000046, 66.6000000000003, -3.299999999999887, 71.79999999999993, 74.29999999999951, 53.100000000000485, 113.69999999999928, 36.70000000000025, 148.89999999999938, 131.49999999999875, 40.0000000000003, 66.09999999999945, 52.60000000000047, 111.09999999999819, 108.89999999999844, 40.0000000000003, -9.299999999999688, 17.299999999999972, 40.0000000000003, 45.60000000000036, -6.999999999999645, 111.09999999999843, 39.700000000000294, 32.20000000000019, 60.00000000000028, 37.800000000000274, 106.69999999999857, 9.699999999999958, 75.99999999999964, 56.999999999999915, 39.00000000000029, 12.499999999999927, 41.800000000000296, 106.29999999999865, 69.09999999999995, 57.600000000000506, 166.89999999999867, 62.000000000000476, -99.30000000000166, 54.000000000000455, -89.9, 10.999999999999938, -127.89999999999989, 89.29999999999916, 62.19999999999971, -6.499999999999808, -203.4000000000004, -34.399999999999714, 75.49999999999959, 57.10000000000032, -41.99999999999982, 12.49999999999992, -25.599999999999643, -64.4, 40.0000000000003, -60.69999999999961, 42.20000000000033, 40.0000000000003, 40.0000000000003, 60.70000000000039, 57.500000000000185, 32.30000000000018, -305.60000000000014, 46.00000000000037, 40.0000000000003, 11.400000000000254, -35.199999999999974, -28.4, 4.600000000000405, 41.800000000000296, -111.80000000000018, -42.59999999999965, -94.4000000000016, 50.70000000000025, 39.900000000000375, -30.099999999999604, 68.40000000000013, 48.50000000000037, -90.59999999999998, 93.79999999999833, 19.100000000000414], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-145.60000000000045, -129.10000000000014, 29.000000000000167, 21.800000000000047, -28.30000000000002, 20.000000000000014, -228.4000000000001, 20.000000000000014, 73.99999999999947, 20.000000000000014, -37.89999999999998, 49.70000000000011, 20.000000000000014, 20.000000000000014, -291.9999999999997, -46.29999999999987, -17.800000000000125, 71.29999999999968, 20.000000000000014, -30.400000000000016, -99.70000000000081, -45.69999999999991, -183.70000000000059, -156.70000000000059, 25.400000000000055, 20.000000000000014, 109.99999999999943, 127.6999999999996, 20.000000000000014, 97.39999999999941, -288.00000000000006, 76.39999999999964, -118.60000000000012, 47.600000000000215, 133.09999999999982, 74.90000000000005, -12.099999999999753, 114.4999999999998, 20.000000000000014, 42.50000000000022, 17.899999999999988, 46.70000000000024, 17.59999999999999, -61.90000000000051, 13.699999999999964, 55.10000000000023, 73.99999999999963, -63.700000000000635, 33.200000000000244, -0.10000000000004367, 88.69999999999976, 20.000000000000014, 20.000000000000014, 13.699999999999967, 67.69999999999982, 81.19999999999969, 82.09999999999948, 43.400000000000226, 20.000000000000014, 20.000000000000014, -39.69999999999982, 45.80000000000018, 20.000000000000014, 32.600000000000215, 53.30000000000023, 57.800000000000225, 61.7000000000002, 45.200000000000244, 20.000000000000014, 20.000000000000014, -91.9000000000008, 23.60000000000008, -0.9999999999999992, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999962, 3.7999999999999887, -161.99999999999986, 20.000000000000014, 53.30000000000023, 57.80000000000019, 18.19999999999999, 15.499999999999963, 2.5999999999999646, 8.599999999999975, 23.3000000000001, 19.70000000000002, 20.000000000000014, 6.799999999999988, 73.39999999999952, 2.2999999999999923, 16.09999999999997, -72.40000000000055, 47.00000000000022, 29.000000000000163, -39.69999999999991, 13.699999999999946, -13.899999999999853, 20.90000000000003, -32.499999999999766, 20.000000000000014, 20.000000000000014, 21.800000000000047, 59.60000000000016, 31.70000000000022, -8.199999999999958, 44.30000000000015, 20.90000000000003, 34.700000000000244, 61.40000000000018, 105.4999999999994, 28.700000000000166, 26.30000000000012, -97.60000000000082, -57.70000000000038, -21.999999999999996, 56.00000000000023, -36.699999999999775, -181.20000000000002, -38.799999999999805, 21.80000000000004, -205.0, -191.8999999999999, 40.7000000000001, 20.600000000000023, -11.50000000000004, 58.700000000000195, 20.000000000000014, -98.50000000000004, -259.89999999999895, -177.5, -97.60000000000055, 3.1999999999999775, 9.499999999999984, 20.000000000000014, 22.700000000000063, 34.40000000000007, -89.20000000000002, -74.80000000000081, -32.499999999999844, 20.000000000000014, -125.80000000000001, -11.79999999999983, -214.29999999999998, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000004, -87.3999999999998, -2.800000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000019, 20.000000000000014, 59.600000000000094, -45.09999999999976, 7.399999999999965, 17.899999999999977, -160.90000000000018, -453.7, 1.9999999999999956, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.60000000000002, -194.20000000000002, 20.000000000000014, -311.40000000000003, -0.9999999999999846, -89.79999999999998, 34.40000000000024, 21.800000000000047, 20.000000000000014, -39.69999999999982, -314.1, -50.19999999999983, -93.40000000000083, -113.80000000000071, -49.599999999999866, -456.1, 39.80000000000023, 24.50000000000008, 10.399999999999979, -26.199999999999825, -67.9000000000008, 32.90000000000021, 24.50000000000008, -30.69999999999979, 36.2, -189.00000000000006, -28.59999999999981, 56.60000000000022, 36.20000000000022, 4.399999999999972, -43.299999999999834], "policy_predator_policy_reward": [71.0, 87.0, 0.0, 0.0, 23.0, 14.0, 39.0, 95.0, 0.0, 0.0, 51.0, 27.0, 0.0, 0.0, 118.0, 67.0, 0.0, 66.0, 17.0, 15.0, 33.0, 57.0, 82.0, 102.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 163.0, 32.0, 40.0, 1.0, 0.0, 27.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 41.0, 3.0, 0.0, 47.0, 17.0, 10.0, 10.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 19.0, 41.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 17.0, 42.0, 17.0, 17.0, 0.0, 0.0, 24.0, 2.0, 0.0, 135.0, 0.0, 0.0, 6.0, 0.0, 0.0, 21.0, 16.0, 1.0, 11.0, 0.0, 29.0, 2.0, 44.0, 22.0, 0.0, 0.0, 23.0, 60.0, 0.0, 32.0, 25.0, 0.0, 0.0, 0.0, 3.0, 12.0, 2.0, 31.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 56.0, 0.0, 20.0, 0.0, 101.0, 27.0, 0.0, 28.0, 133.0, 136.0, 0.0, 28.0, 0.0, 15.0, 72.0, 0.0, 0.0, 234.0, 0.0, 60.0, 26.0, 20.0, 0.0, 0.0, 76.0, 46.0, 0.0, 25.0, 24.0, 88.0, 96.0, 33.0, 0.0, 0.0, 0.0, 97.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 12.0, 6.0, 1.0, 0.0, 309.0, 4.0, 20.0, 0.0, 0.0, 26.0, 0.0, 37.0, 102.0, 2.0, 282.0, 57.0, 3.0, 0.0, 0.0, 0.0, 242.0, 0.0, 101.0, 69.0, 0.0, 182.0, 285.0, 0.0, 5.0, 0.0, 64.0, 11.0, 0.0, 0.0, 43.0, 0.0, 127.0, 1.0, 0.0, 58.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.549227800785806, "mean_inference_ms": 1.3846998164030422, "mean_action_processing_ms": 0.22325149987865564, "mean_env_wait_ms": 0.19023679169761765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054503679275512695, "StateBufferConnector_ms": 0.004105091094970703, "ViewRequirementAgentConnector_ms": 0.11712360382080078}, "num_episodes": 18, "episode_return_max": 238.699999999999, "episode_return_min": -305.60000000000014, "episode_return_mean": 26.586999999999875, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 411.0520896769506, "num_env_steps_trained_throughput_per_sec": 411.0520896769506, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 9452.407, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9452.363, "sample_time_ms": 1189.834, "learn_time_ms": 8248.619, "learn_throughput": 484.93, "synch_weights_time_ms": 12.589}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "04dec_00002", "date": "2024-08-13_16-25-50", "timestamp": 1723580750, "time_this_iter_s": 9.769243001937866, "time_total_s": 185.69184494018555, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359d430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 185.69184494018555, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 35.67857142857142, "ram_util_percent": 82.84285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49988835109447044, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 2.650426392012803, "policy_loss": -0.003056149777498037, "vf_loss": 2.652380069159957, "vf_explained_var": 0.006544978467244951, "kl": 0.008710844370903057, "entropy": 1.4859996393244101, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1875776096311197, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 3.682196092984033, "policy_loss": -0.005703525619689749, "vf_loss": 3.686541172057863, "vf_explained_var": 0.00547455561854852, "kl": 0.013584366166679218, "entropy": 1.2594798069782358, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 166.89999999999867, "episode_reward_min": -305.60000000000014, "episode_reward_mean": 20.37499999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 114.4999999999998, "predator_policy": 309.0}, "policy_reward_mean": {"prey_policy": -19.022500000000008, "predator_policy": 29.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [129.39999999999944, 62.50000000000046, 66.6000000000003, -3.299999999999887, 71.79999999999993, 74.29999999999951, 53.100000000000485, 113.69999999999928, 36.70000000000025, 148.89999999999938, 131.49999999999875, 40.0000000000003, 66.09999999999945, 52.60000000000047, 111.09999999999819, 108.89999999999844, 40.0000000000003, -9.299999999999688, 17.299999999999972, 40.0000000000003, 45.60000000000036, -6.999999999999645, 111.09999999999843, 39.700000000000294, 32.20000000000019, 60.00000000000028, 37.800000000000274, 106.69999999999857, 9.699999999999958, 75.99999999999964, 56.999999999999915, 39.00000000000029, 12.499999999999927, 41.800000000000296, 106.29999999999865, 69.09999999999995, 57.600000000000506, 166.89999999999867, 62.000000000000476, -99.30000000000166, 54.000000000000455, -89.9, 10.999999999999938, -127.89999999999989, 89.29999999999916, 62.19999999999971, -6.499999999999808, -203.4000000000004, -34.399999999999714, 75.49999999999959, 57.10000000000032, -41.99999999999982, 12.49999999999992, -25.599999999999643, -64.4, 40.0000000000003, -60.69999999999961, 42.20000000000033, 40.0000000000003, 40.0000000000003, 60.70000000000039, 57.500000000000185, 32.30000000000018, -305.60000000000014, 46.00000000000037, 40.0000000000003, 11.400000000000254, -35.199999999999974, -28.4, 4.600000000000405, 41.800000000000296, -111.80000000000018, -42.59999999999965, -94.4000000000016, 50.70000000000025, 39.900000000000375, -30.099999999999604, 68.40000000000013, 48.50000000000037, -90.59999999999998, 93.79999999999833, 19.100000000000414, -21.699999999999932, -5.699999999999726, -25.899999999999665, 131.79999999999845, -146.70000000000084, -89.10000000000014, 37.60000000000031, 78.49999999999942, 19.599999999999977, 59.8000000000003, 28.000000000000384, 56.60000000000036, -27.999999999999808, -23.39999999999955, -66.20000000000141, -2.8999999999996984, -46.0999999999998, -40.299999999999706], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-12.099999999999753, 114.4999999999998, 20.000000000000014, 42.50000000000022, 17.899999999999988, 46.70000000000024, 17.59999999999999, -61.90000000000051, 13.699999999999964, 55.10000000000023, 73.99999999999963, -63.700000000000635, 33.200000000000244, -0.10000000000004367, 88.69999999999976, 20.000000000000014, 20.000000000000014, 13.699999999999967, 67.69999999999982, 81.19999999999969, 82.09999999999948, 43.400000000000226, 20.000000000000014, 20.000000000000014, -39.69999999999982, 45.80000000000018, 20.000000000000014, 32.600000000000215, 53.30000000000023, 57.800000000000225, 61.7000000000002, 45.200000000000244, 20.000000000000014, 20.000000000000014, -91.9000000000008, 23.60000000000008, -0.9999999999999992, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999962, 3.7999999999999887, -161.99999999999986, 20.000000000000014, 53.30000000000023, 57.80000000000019, 18.19999999999999, 15.499999999999963, 2.5999999999999646, 8.599999999999975, 23.3000000000001, 19.70000000000002, 20.000000000000014, 6.799999999999988, 73.39999999999952, 2.2999999999999923, 16.09999999999997, -72.40000000000055, 47.00000000000022, 29.000000000000163, -39.69999999999991, 13.699999999999946, -13.899999999999853, 20.90000000000003, -32.499999999999766, 20.000000000000014, 20.000000000000014, 21.800000000000047, 59.60000000000016, 31.70000000000022, -8.199999999999958, 44.30000000000015, 20.90000000000003, 34.700000000000244, 61.40000000000018, 105.4999999999994, 28.700000000000166, 26.30000000000012, -97.60000000000082, -57.70000000000038, -21.999999999999996, 56.00000000000023, -36.699999999999775, -181.20000000000002, -38.799999999999805, 21.80000000000004, -205.0, -191.8999999999999, 40.7000000000001, 20.600000000000023, -11.50000000000004, 58.700000000000195, 20.000000000000014, -98.50000000000004, -259.89999999999895, -177.5, -97.60000000000055, 3.1999999999999775, 9.499999999999984, 20.000000000000014, 22.700000000000063, 34.40000000000007, -89.20000000000002, -74.80000000000081, -32.499999999999844, 20.000000000000014, -125.80000000000001, -11.79999999999983, -214.29999999999998, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000004, -87.3999999999998, -2.800000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000019, 20.000000000000014, 59.600000000000094, -45.09999999999976, 7.399999999999965, 17.899999999999977, -160.90000000000018, -453.7, 1.9999999999999956, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.60000000000002, -194.20000000000002, 20.000000000000014, -311.40000000000003, -0.9999999999999846, -89.79999999999998, 34.40000000000024, 21.800000000000047, 20.000000000000014, -39.69999999999982, -314.1, -50.19999999999983, -93.40000000000083, -113.80000000000071, -49.599999999999866, -456.1, 39.80000000000023, 24.50000000000008, 10.399999999999979, -26.199999999999825, -67.9000000000008, 32.90000000000021, 24.50000000000008, -30.69999999999979, 36.2, -189.00000000000006, -28.59999999999981, 56.60000000000022, 36.20000000000022, 4.399999999999972, -43.299999999999834, -15.699999999999918, -43.0, -1.0000000000000275, -36.69999999999977, 20.900000000000027, -128.80000000000052, 92.89999999999932, 38.900000000000254, -158.2000000000005, -113.50000000000034, -204.70000000000002, -12.399999999999844, 20.90000000000003, 13.699999999999978, 4.39999999999999, 55.1000000000001, 20.000000000000014, -21.39999999999975, 82.09999999999944, -76.3000000000007, 20.000000000000014, -34.000000000000014, 3.1999999999999615, 28.40000000000017, -406.29999999999995, -78.70000000000056, -21.99999999999978, -42.399999999999764, -57.70000000000021, -83.50000000000077, -142.60000000000002, 46.70000000000021, 3.1999999999999615, -202.30000000000027, -70.30000000000048, -42.999999999999815], "policy_predator_policy_reward": [27.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 41.0, 3.0, 0.0, 47.0, 17.0, 10.0, 10.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 19.0, 41.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 17.0, 42.0, 17.0, 17.0, 0.0, 0.0, 24.0, 2.0, 0.0, 135.0, 0.0, 0.0, 6.0, 0.0, 0.0, 21.0, 16.0, 1.0, 11.0, 0.0, 29.0, 2.0, 44.0, 22.0, 0.0, 0.0, 23.0, 60.0, 0.0, 32.0, 25.0, 0.0, 0.0, 0.0, 3.0, 12.0, 2.0, 31.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 56.0, 0.0, 20.0, 0.0, 101.0, 27.0, 0.0, 28.0, 133.0, 136.0, 0.0, 28.0, 0.0, 15.0, 72.0, 0.0, 0.0, 234.0, 0.0, 60.0, 26.0, 20.0, 0.0, 0.0, 76.0, 46.0, 0.0, 25.0, 24.0, 88.0, 96.0, 33.0, 0.0, 0.0, 0.0, 97.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 12.0, 6.0, 1.0, 0.0, 309.0, 4.0, 20.0, 0.0, 0.0, 26.0, 0.0, 37.0, 102.0, 2.0, 282.0, 57.0, 3.0, 0.0, 0.0, 0.0, 242.0, 0.0, 101.0, 69.0, 0.0, 182.0, 285.0, 0.0, 5.0, 0.0, 64.0, 11.0, 0.0, 0.0, 43.0, 0.0, 127.0, 1.0, 0.0, 58.0, 0.0, 0.0, 37.0, 32.0, 0.0, 0.0, 82.0, 0.0, 0.0, 62.0, 63.0, 0.0, 128.0, 0.0, 3.0, 19.0, 0.0, 0.0, 21.0, 43.0, 11.0, 13.0, 29.0, 17.0, 8.0, 224.0, 233.0, 7.0, 34.0, 73.0, 2.0, 0.0, 93.0, 145.0, 8.0, 73.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5529423573784207, "mean_inference_ms": 1.395254982460028, "mean_action_processing_ms": 0.22425699381496542, "mean_env_wait_ms": 0.1915078243236003, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052193403244018555, "StateBufferConnector_ms": 0.004434823989868164, "ViewRequirementAgentConnector_ms": 0.12043869495391846}, "num_episodes": 18, "episode_return_max": 166.89999999999867, "episode_return_min": -305.60000000000014, "episode_return_mean": 20.37499999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 411.33604699992605, "num_env_steps_trained_throughput_per_sec": 411.33604699992605, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 9527.489, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9527.442, "sample_time_ms": 1195.562, "learn_time_ms": 8317.671, "learn_throughput": 480.904, "synch_weights_time_ms": 12.792}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "04dec_00002", "date": "2024-08-13_16-26-00", "timestamp": 1723580760, "time_this_iter_s": 9.801154851913452, "time_total_s": 195.492999792099, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0456f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 195.492999792099, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 35.97142857142857, "ram_util_percent": 82.04285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4094976904846373, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 1.8356572021883, "policy_loss": -0.008415891273469521, "vf_loss": 1.8423690876317402, "vf_explained_var": 0.008453004795407492, "kl": 0.013463724485703195, "entropy": 1.4813308905041407, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9733657851578698, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 2.030027082578215, "policy_loss": -0.0068424121322721325, "vf_loss": 2.0347159914238744, "vf_explained_var": -0.00010911005514639395, "kl": 0.02153505937251372, "entropy": 1.300025166784014, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 166.89999999999867, "episode_reward_min": -305.60000000000014, "episode_reward_mean": 10.145999999999958, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 105.4999999999994, "predator_policy": 309.0}, "policy_reward_mean": {"prey_policy": -27.262000000000015, "predator_policy": 32.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.299999999999972, 40.0000000000003, 45.60000000000036, -6.999999999999645, 111.09999999999843, 39.700000000000294, 32.20000000000019, 60.00000000000028, 37.800000000000274, 106.69999999999857, 9.699999999999958, 75.99999999999964, 56.999999999999915, 39.00000000000029, 12.499999999999927, 41.800000000000296, 106.29999999999865, 69.09999999999995, 57.600000000000506, 166.89999999999867, 62.000000000000476, -99.30000000000166, 54.000000000000455, -89.9, 10.999999999999938, -127.89999999999989, 89.29999999999916, 62.19999999999971, -6.499999999999808, -203.4000000000004, -34.399999999999714, 75.49999999999959, 57.10000000000032, -41.99999999999982, 12.49999999999992, -25.599999999999643, -64.4, 40.0000000000003, -60.69999999999961, 42.20000000000033, 40.0000000000003, 40.0000000000003, 60.70000000000039, 57.500000000000185, 32.30000000000018, -305.60000000000014, 46.00000000000037, 40.0000000000003, 11.400000000000254, -35.199999999999974, -28.4, 4.600000000000405, 41.800000000000296, -111.80000000000018, -42.59999999999965, -94.4000000000016, 50.70000000000025, 39.900000000000375, -30.099999999999604, 68.40000000000013, 48.50000000000037, -90.59999999999998, 93.79999999999833, 19.100000000000414, -21.699999999999932, -5.699999999999726, -25.899999999999665, 131.79999999999845, -146.70000000000084, -89.10000000000014, 37.60000000000031, 78.49999999999942, 19.599999999999977, 59.8000000000003, 28.000000000000384, 56.60000000000036, -27.999999999999808, -23.39999999999955, -66.20000000000141, -2.8999999999996984, -46.0999999999998, -40.299999999999706, 22.400000000000027, 38.40000000000034, -6.099999999999916, -93.5000000000004, 32.60000000000019, -3.9999999999997313, 27.400000000000105, -110.10000000000142, 78.69999999999942, 51.70000000000049, 15.699999999999976, -23.99999999999956, 97.89999999999841, 16.999999999999925, 40.0000000000003, 7.400000000000091, 40.20000000000032, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.9999999999999992, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999962, 3.7999999999999887, -161.99999999999986, 20.000000000000014, 53.30000000000023, 57.80000000000019, 18.19999999999999, 15.499999999999963, 2.5999999999999646, 8.599999999999975, 23.3000000000001, 19.70000000000002, 20.000000000000014, 6.799999999999988, 73.39999999999952, 2.2999999999999923, 16.09999999999997, -72.40000000000055, 47.00000000000022, 29.000000000000163, -39.69999999999991, 13.699999999999946, -13.899999999999853, 20.90000000000003, -32.499999999999766, 20.000000000000014, 20.000000000000014, 21.800000000000047, 59.60000000000016, 31.70000000000022, -8.199999999999958, 44.30000000000015, 20.90000000000003, 34.700000000000244, 61.40000000000018, 105.4999999999994, 28.700000000000166, 26.30000000000012, -97.60000000000082, -57.70000000000038, -21.999999999999996, 56.00000000000023, -36.699999999999775, -181.20000000000002, -38.799999999999805, 21.80000000000004, -205.0, -191.8999999999999, 40.7000000000001, 20.600000000000023, -11.50000000000004, 58.700000000000195, 20.000000000000014, -98.50000000000004, -259.89999999999895, -177.5, -97.60000000000055, 3.1999999999999775, 9.499999999999984, 20.000000000000014, 22.700000000000063, 34.40000000000007, -89.20000000000002, -74.80000000000081, -32.499999999999844, 20.000000000000014, -125.80000000000001, -11.79999999999983, -214.29999999999998, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000004, -87.3999999999998, -2.800000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000019, 20.000000000000014, 59.600000000000094, -45.09999999999976, 7.399999999999965, 17.899999999999977, -160.90000000000018, -453.7, 1.9999999999999956, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.60000000000002, -194.20000000000002, 20.000000000000014, -311.40000000000003, -0.9999999999999846, -89.79999999999998, 34.40000000000024, 21.800000000000047, 20.000000000000014, -39.69999999999982, -314.1, -50.19999999999983, -93.40000000000083, -113.80000000000071, -49.599999999999866, -456.1, 39.80000000000023, 24.50000000000008, 10.399999999999979, -26.199999999999825, -67.9000000000008, 32.90000000000021, 24.50000000000008, -30.69999999999979, 36.2, -189.00000000000006, -28.59999999999981, 56.60000000000022, 36.20000000000022, 4.399999999999972, -43.299999999999834, -15.699999999999918, -43.0, -1.0000000000000275, -36.69999999999977, 20.900000000000027, -128.80000000000052, 92.89999999999932, 38.900000000000254, -158.2000000000005, -113.50000000000034, -204.70000000000002, -12.399999999999844, 20.90000000000003, 13.699999999999978, 4.39999999999999, 55.1000000000001, 20.000000000000014, -21.39999999999975, 82.09999999999944, -76.3000000000007, 20.000000000000014, -34.000000000000014, 3.1999999999999615, 28.40000000000017, -406.29999999999995, -78.70000000000056, -21.99999999999978, -42.399999999999764, -57.70000000000021, -83.50000000000077, -142.60000000000002, 46.70000000000021, 3.1999999999999615, -202.30000000000027, -70.30000000000048, -42.999999999999815, -13.599999999999808, 20.000000000000014, 21.20000000000005, -17.799999999999784, -36.99999999999977, -339.1, 20.000000000000014, -239.50000000000014, -0.9999999999999846, 23.600000000000065, 20.000000000000014, -64.00000000000091, 12.499999999999966, -3.099999999999972, -129.7000000000007, -72.40000000000073, 20.000000000000014, 58.700000000000216, 29.90000000000018, 21.80000000000004, 40.70000000000025, -70.0000000000007, -55.60000000000005, -27.39999999999975, 41.60000000000019, 44.3000000000002, -27.99999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -55.60000000000032, 10.699999999999978, 3.4999999999999813, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [17.0, 17.0, 0.0, 0.0, 24.0, 2.0, 0.0, 135.0, 0.0, 0.0, 6.0, 0.0, 0.0, 21.0, 16.0, 1.0, 11.0, 0.0, 29.0, 2.0, 44.0, 22.0, 0.0, 0.0, 23.0, 60.0, 0.0, 32.0, 25.0, 0.0, 0.0, 0.0, 3.0, 12.0, 2.0, 31.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 56.0, 0.0, 20.0, 0.0, 101.0, 27.0, 0.0, 28.0, 133.0, 136.0, 0.0, 28.0, 0.0, 15.0, 72.0, 0.0, 0.0, 234.0, 0.0, 60.0, 26.0, 20.0, 0.0, 0.0, 76.0, 46.0, 0.0, 25.0, 24.0, 88.0, 96.0, 33.0, 0.0, 0.0, 0.0, 97.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 12.0, 6.0, 1.0, 0.0, 309.0, 4.0, 20.0, 0.0, 0.0, 26.0, 0.0, 37.0, 102.0, 2.0, 282.0, 57.0, 3.0, 0.0, 0.0, 0.0, 242.0, 0.0, 101.0, 69.0, 0.0, 182.0, 285.0, 0.0, 5.0, 0.0, 64.0, 11.0, 0.0, 0.0, 43.0, 0.0, 127.0, 1.0, 0.0, 58.0, 0.0, 0.0, 37.0, 32.0, 0.0, 0.0, 82.0, 0.0, 0.0, 62.0, 63.0, 0.0, 128.0, 0.0, 3.0, 19.0, 0.0, 0.0, 21.0, 43.0, 11.0, 13.0, 29.0, 17.0, 8.0, 224.0, 233.0, 7.0, 34.0, 73.0, 2.0, 0.0, 93.0, 145.0, 8.0, 73.0, 0.0, 0.0, 16.0, 17.0, 18.0, 179.0, 191.0, 35.0, 91.0, 0.0, 10.0, 40.0, 0.0, 4.0, 14.0, 85.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 1.0, 58.0, 4.0, 8.0, 25.0, 0.0, 0.0, 0.0, 25.0, 18.0, 16.0, 10.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5563489800052845, "mean_inference_ms": 1.4043639841789906, "mean_action_processing_ms": 0.22515598602000833, "mean_env_wait_ms": 0.19259674592295684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052253007888793945, "StateBufferConnector_ms": 0.0044814348220825195, "ViewRequirementAgentConnector_ms": 0.12375438213348389}, "num_episodes": 18, "episode_return_max": 166.89999999999867, "episode_return_min": -305.60000000000014, "episode_return_mean": 10.145999999999958, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.463185713875, "num_env_steps_trained_throughput_per_sec": 409.463185713875, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 9574.094, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9574.046, "sample_time_ms": 1220.224, "learn_time_ms": 8339.622, "learn_throughput": 479.638, "synch_weights_time_ms": 12.838}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "04dec_00002", "date": "2024-08-13_16-26-09", "timestamp": 1723580769, "time_this_iter_s": 9.81974196434021, "time_total_s": 205.3127417564392, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b34eddc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 205.3127417564392, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 38.99285714285714, "ram_util_percent": 82.41428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38600099792792686, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 0.9074263792662394, "policy_loss": -0.009721052536997135, "vf_loss": 0.9156011012023089, "vf_explained_var": 0.005231285883636071, "kl": 0.0122178967412192, "entropy": 1.4887830723530402, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.184481094852484, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 0.00010000000000000003, "total_loss": 2.2915264740822807, "policy_loss": -0.004469524972663118, "vf_loss": 2.294051291198327, "vf_explained_var": 0.03246897831164971, "kl": 0.012964720637783521, "entropy": 1.2577595629389324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 167.39999999999898, "episode_reward_min": -305.60000000000014, "episode_reward_mean": 14.20399999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.0999999999997, "predator_policy": 309.0}, "policy_reward_mean": {"prey_policy": -23.71800000000002, "predator_policy": 30.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [62.19999999999971, -6.499999999999808, -203.4000000000004, -34.399999999999714, 75.49999999999959, 57.10000000000032, -41.99999999999982, 12.49999999999992, -25.599999999999643, -64.4, 40.0000000000003, -60.69999999999961, 42.20000000000033, 40.0000000000003, 40.0000000000003, 60.70000000000039, 57.500000000000185, 32.30000000000018, -305.60000000000014, 46.00000000000037, 40.0000000000003, 11.400000000000254, -35.199999999999974, -28.4, 4.600000000000405, 41.800000000000296, -111.80000000000018, -42.59999999999965, -94.4000000000016, 50.70000000000025, 39.900000000000375, -30.099999999999604, 68.40000000000013, 48.50000000000037, -90.59999999999998, 93.79999999999833, 19.100000000000414, -21.699999999999932, -5.699999999999726, -25.899999999999665, 131.79999999999845, -146.70000000000084, -89.10000000000014, 37.60000000000031, 78.49999999999942, 19.599999999999977, 59.8000000000003, 28.000000000000384, 56.60000000000036, -27.999999999999808, -23.39999999999955, -66.20000000000141, -2.8999999999996984, -46.0999999999998, -40.299999999999706, 22.400000000000027, 38.40000000000034, -6.099999999999916, -93.5000000000004, 32.60000000000019, -3.9999999999997313, 27.400000000000105, -110.10000000000142, 78.69999999999942, 51.70000000000049, 15.699999999999976, -23.99999999999956, 97.89999999999841, 16.999999999999925, 40.0000000000003, 7.400000000000091, 40.20000000000032, 40.0000000000003, 22.80000000000003, 143.49999999999878, 55.300000000000516, -17.499999999999737, 44.80000000000038, -14.699999999999637, 34.50000000000022, 60.100000000000314, 46.3000000000004, 7.0000000000000995, 167.39999999999898, 146.59999999999914, 17.999999999999943, 57.00000000000049, 46.60000000000038, 65.20000000000041, 47.70000000000044, 73.09999999999984, -70.79999999999973, 87.49999999999882, 162.69999999999942, -26.09999999999956, 84.599999999999, 27.20000000000021, 28.900000000000187, 101.79999999999906, 24.800000000000264], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.50000000000004, 58.700000000000195, 20.000000000000014, -98.50000000000004, -259.89999999999895, -177.5, -97.60000000000055, 3.1999999999999775, 9.499999999999984, 20.000000000000014, 22.700000000000063, 34.40000000000007, -89.20000000000002, -74.80000000000081, -32.499999999999844, 20.000000000000014, -125.80000000000001, -11.79999999999983, -214.29999999999998, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000004, -87.3999999999998, -2.800000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000019, 20.000000000000014, 59.600000000000094, -45.09999999999976, 7.399999999999965, 17.899999999999977, -160.90000000000018, -453.7, 1.9999999999999956, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.60000000000002, -194.20000000000002, 20.000000000000014, -311.40000000000003, -0.9999999999999846, -89.79999999999998, 34.40000000000024, 21.800000000000047, 20.000000000000014, -39.69999999999982, -314.1, -50.19999999999983, -93.40000000000083, -113.80000000000071, -49.599999999999866, -456.1, 39.80000000000023, 24.50000000000008, 10.399999999999979, -26.199999999999825, -67.9000000000008, 32.90000000000021, 24.50000000000008, -30.69999999999979, 36.2, -189.00000000000006, -28.59999999999981, 56.60000000000022, 36.20000000000022, 4.399999999999972, -43.299999999999834, -15.699999999999918, -43.0, -1.0000000000000275, -36.69999999999977, 20.900000000000027, -128.80000000000052, 92.89999999999932, 38.900000000000254, -158.2000000000005, -113.50000000000034, -204.70000000000002, -12.399999999999844, 20.90000000000003, 13.699999999999978, 4.39999999999999, 55.1000000000001, 20.000000000000014, -21.39999999999975, 82.09999999999944, -76.3000000000007, 20.000000000000014, -34.000000000000014, 3.1999999999999615, 28.40000000000017, -406.29999999999995, -78.70000000000056, -21.99999999999978, -42.399999999999764, -57.70000000000021, -83.50000000000077, -142.60000000000002, 46.70000000000021, 3.1999999999999615, -202.30000000000027, -70.30000000000048, -42.999999999999815, -13.599999999999808, 20.000000000000014, 21.20000000000005, -17.799999999999784, -36.99999999999977, -339.1, 20.000000000000014, -239.50000000000014, -0.9999999999999846, 23.600000000000065, 20.000000000000014, -64.00000000000091, 12.499999999999966, -3.099999999999972, -129.7000000000007, -72.40000000000073, 20.000000000000014, 58.700000000000216, 29.90000000000018, 21.80000000000004, 40.70000000000025, -70.0000000000007, -55.60000000000005, -27.39999999999975, 41.60000000000019, 44.3000000000002, -27.99999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -55.60000000000032, 10.699999999999978, 3.4999999999999813, 20.000000000000014, 20.000000000000014, -28.299999999999763, 28.100000000000147, 20.000000000000014, 123.49999999999952, 20.000000000000014, 35.30000000000026, 72.19999999999959, -204.70000000000053, 12.799999999999974, 20.000000000000014, 23.60000000000007, -100.30000000000072, 20.000000000000014, 9.499999999999964, 43.40000000000014, 13.699999999999964, 22.700000000000053, 23.600000000000076, -38.79999999999977, 15.799999999999963, 145.0999999999997, -9.699999999999882, 2.2999999999999643, 128.29999999999973, -21.999999999999865, 20.000000000000014, 32.00000000000022, 20.000000000000014, -34.89999999999983, -17.499999999999794, 20.000000000000014, 45.200000000000244, 20.000000000000014, 16.69999999999997, 21.80000000000004, 50.30000000000023, -131.2000000000003, -43.59999999999977, 39.50000000000025, 47.00000000000024, 15.799999999999963, 125.89999999999996, -24.099999999999852, -67.00000000000082, 20.000000000000014, 62.60000000000021, -13.59999999999979, -14.199999999999909, -23.19999999999976, 28.100000000000158, 75.79999999999956, 20.000000000000014, -29.199999999999932, -4.000000000000044], "policy_predator_policy_reward": [0.0, 15.0, 72.0, 0.0, 0.0, 234.0, 0.0, 60.0, 26.0, 20.0, 0.0, 0.0, 76.0, 46.0, 0.0, 25.0, 24.0, 88.0, 96.0, 33.0, 0.0, 0.0, 0.0, 97.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 12.0, 6.0, 1.0, 0.0, 309.0, 4.0, 20.0, 0.0, 0.0, 26.0, 0.0, 37.0, 102.0, 2.0, 282.0, 57.0, 3.0, 0.0, 0.0, 0.0, 242.0, 0.0, 101.0, 69.0, 0.0, 182.0, 285.0, 0.0, 5.0, 0.0, 64.0, 11.0, 0.0, 0.0, 43.0, 0.0, 127.0, 1.0, 0.0, 58.0, 0.0, 0.0, 37.0, 32.0, 0.0, 0.0, 82.0, 0.0, 0.0, 62.0, 63.0, 0.0, 128.0, 0.0, 3.0, 19.0, 0.0, 0.0, 21.0, 43.0, 11.0, 13.0, 29.0, 17.0, 8.0, 224.0, 233.0, 7.0, 34.0, 73.0, 2.0, 0.0, 93.0, 145.0, 8.0, 73.0, 0.0, 0.0, 16.0, 17.0, 18.0, 179.0, 191.0, 35.0, 91.0, 0.0, 10.0, 40.0, 0.0, 4.0, 14.0, 85.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 1.0, 58.0, 4.0, 8.0, 25.0, 0.0, 0.0, 0.0, 25.0, 18.0, 16.0, 10.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0, 77.0, 0.0, 12.0, 0.0, 62.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 30.0, 21.0, 11.0, 11.0, 5.0, 0.0, 20.0, 5.0, 0.0, 47.0, 52.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 27.0, 77.0, 1.0, 0.0, 21.0, 0.0, 0.0, 65.0, 2.0, 0.0, 16.0, 39.0, 0.0, 24.0, 6.0, 0.0, 0.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5610255610218542, "mean_inference_ms": 1.415916157963563, "mean_action_processing_ms": 0.22666180390404014, "mean_env_wait_ms": 0.19387466783966156, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005570054054260254, "StateBufferConnector_ms": 0.00430905818939209, "ViewRequirementAgentConnector_ms": 0.12172806262969971}, "num_episodes": 27, "episode_return_max": 167.39999999999898, "episode_return_min": -305.60000000000014, "episode_return_mean": 14.20399999999999, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 431.70675875743336, "num_env_steps_trained_throughput_per_sec": 431.70675875743336, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 9595.914, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9595.866, "sample_time_ms": 1213.733, "learn_time_ms": 8367.708, "learn_throughput": 478.028, "synch_weights_time_ms": 12.895}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "04dec_00002", "date": "2024-08-13_16-26-19", "timestamp": 1723580779, "time_this_iter_s": 9.323348999023438, "time_total_s": 214.63609075546265, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3587550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 214.63609075546265, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 32.792307692307695, "ram_util_percent": 83.02307692307694}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.44479787585044667, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 1.4832651023511534, "policy_loss": -0.003963715259586929, "vf_loss": 1.486284452897531, "vf_explained_var": 0.008110620988109125, "kl": 0.0074616815037247255, "entropy": 1.4816147871118375, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2978496868853215, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 0.00010000000000000003, "total_loss": 3.409922791914965, "policy_loss": -0.000497533655947163, "vf_loss": 3.4099934548927995, "vf_explained_var": 0.06390812176245231, "kl": 0.002845762585479169, "entropy": 1.2459003274402922, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 234.89999999999938, "episode_reward_min": -305.60000000000014, "episode_reward_mean": 27.114999999999924, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.0999999999997, "predator_policy": 309.0}, "policy_reward_mean": {"prey_policy": -14.53750000000003, "predator_policy": 28.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-305.60000000000014, 46.00000000000037, 40.0000000000003, 11.400000000000254, -35.199999999999974, -28.4, 4.600000000000405, 41.800000000000296, -111.80000000000018, -42.59999999999965, -94.4000000000016, 50.70000000000025, 39.900000000000375, -30.099999999999604, 68.40000000000013, 48.50000000000037, -90.59999999999998, 93.79999999999833, 19.100000000000414, -21.699999999999932, -5.699999999999726, -25.899999999999665, 131.79999999999845, -146.70000000000084, -89.10000000000014, 37.60000000000031, 78.49999999999942, 19.599999999999977, 59.8000000000003, 28.000000000000384, 56.60000000000036, -27.999999999999808, -23.39999999999955, -66.20000000000141, -2.8999999999996984, -46.0999999999998, -40.299999999999706, 22.400000000000027, 38.40000000000034, -6.099999999999916, -93.5000000000004, 32.60000000000019, -3.9999999999997313, 27.400000000000105, -110.10000000000142, 78.69999999999942, 51.70000000000049, 15.699999999999976, -23.99999999999956, 97.89999999999841, 16.999999999999925, 40.0000000000003, 7.400000000000091, 40.20000000000032, 40.0000000000003, 22.80000000000003, 143.49999999999878, 55.300000000000516, -17.499999999999737, 44.80000000000038, -14.699999999999637, 34.50000000000022, 60.100000000000314, 46.3000000000004, 7.0000000000000995, 167.39999999999898, 146.59999999999914, 17.999999999999943, 57.00000000000049, 46.60000000000038, 65.20000000000041, 47.70000000000044, 73.09999999999984, -70.79999999999973, 87.49999999999882, 162.69999999999942, -26.09999999999956, 84.599999999999, 27.20000000000021, 28.900000000000187, 101.79999999999906, 24.800000000000264, 90.69999999999882, 13.900000000000013, 40.0000000000003, 64.30000000000047, 161.29999999999916, 40.0000000000003, 76.89999999999975, -1.199999999999807, 138.19999999999953, 234.89999999999938, 123.89999999999975, 85.29999999999941, 40.0000000000003, 74.19999999999976, 40.000000000000156, 40.400000000000084, 93.49999999999883, 17.799999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-160.90000000000018, -453.7, 1.9999999999999956, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.60000000000002, -194.20000000000002, 20.000000000000014, -311.40000000000003, -0.9999999999999846, -89.79999999999998, 34.40000000000024, 21.800000000000047, 20.000000000000014, -39.69999999999982, -314.1, -50.19999999999983, -93.40000000000083, -113.80000000000071, -49.599999999999866, -456.1, 39.80000000000023, 24.50000000000008, 10.399999999999979, -26.199999999999825, -67.9000000000008, 32.90000000000021, 24.50000000000008, -30.69999999999979, 36.2, -189.00000000000006, -28.59999999999981, 56.60000000000022, 36.20000000000022, 4.399999999999972, -43.299999999999834, -15.699999999999918, -43.0, -1.0000000000000275, -36.69999999999977, 20.900000000000027, -128.80000000000052, 92.89999999999932, 38.900000000000254, -158.2000000000005, -113.50000000000034, -204.70000000000002, -12.399999999999844, 20.90000000000003, 13.699999999999978, 4.39999999999999, 55.1000000000001, 20.000000000000014, -21.39999999999975, 82.09999999999944, -76.3000000000007, 20.000000000000014, -34.000000000000014, 3.1999999999999615, 28.40000000000017, -406.29999999999995, -78.70000000000056, -21.99999999999978, -42.399999999999764, -57.70000000000021, -83.50000000000077, -142.60000000000002, 46.70000000000021, 3.1999999999999615, -202.30000000000027, -70.30000000000048, -42.999999999999815, -13.599999999999808, 20.000000000000014, 21.20000000000005, -17.799999999999784, -36.99999999999977, -339.1, 20.000000000000014, -239.50000000000014, -0.9999999999999846, 23.600000000000065, 20.000000000000014, -64.00000000000091, 12.499999999999966, -3.099999999999972, -129.7000000000007, -72.40000000000073, 20.000000000000014, 58.700000000000216, 29.90000000000018, 21.80000000000004, 40.70000000000025, -70.0000000000007, -55.60000000000005, -27.39999999999975, 41.60000000000019, 44.3000000000002, -27.99999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -55.60000000000032, 10.699999999999978, 3.4999999999999813, 20.000000000000014, 20.000000000000014, -28.299999999999763, 28.100000000000147, 20.000000000000014, 123.49999999999952, 20.000000000000014, 35.30000000000026, 72.19999999999959, -204.70000000000053, 12.799999999999974, 20.000000000000014, 23.60000000000007, -100.30000000000072, 20.000000000000014, 9.499999999999964, 43.40000000000014, 13.699999999999964, 22.700000000000053, 23.600000000000076, -38.79999999999977, 15.799999999999963, 145.0999999999997, -9.699999999999882, 2.2999999999999643, 128.29999999999973, -21.999999999999865, 20.000000000000014, 32.00000000000022, 20.000000000000014, -34.89999999999983, -17.499999999999794, 20.000000000000014, 45.200000000000244, 20.000000000000014, 16.69999999999997, 21.80000000000004, 50.30000000000023, -131.2000000000003, -43.59999999999977, 39.50000000000025, 47.00000000000024, 15.799999999999963, 125.89999999999996, -24.099999999999852, -67.00000000000082, 20.000000000000014, 62.60000000000021, -13.59999999999979, -14.199999999999909, -23.19999999999976, 28.100000000000158, 75.79999999999956, 20.000000000000014, -29.199999999999932, -4.000000000000044, 67.69999999999987, 20.000000000000014, 20.000000000000014, -60.1000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.30000000000023, 140.29999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 56.90000000000006, 20.000000000000014, -65.80000000000075, 11.599999999999968, 20.000000000000014, 114.19999999999995, 77.59999999999982, 137.3, -31.900000000000084, 84.7999999999995, 47.00000000000018, 14.300000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000023, 21.500000000000043, -53.50000000000001, -58.600000000000165, 20.000000000000014, 79.69999999999942, -26.199999999999847, -23.199999999999747, 20.000000000000014], "policy_predator_policy_reward": [0.0, 309.0, 4.0, 20.0, 0.0, 0.0, 26.0, 0.0, 37.0, 102.0, 2.0, 282.0, 57.0, 3.0, 0.0, 0.0, 0.0, 242.0, 0.0, 101.0, 69.0, 0.0, 182.0, 285.0, 0.0, 5.0, 0.0, 64.0, 11.0, 0.0, 0.0, 43.0, 0.0, 127.0, 1.0, 0.0, 58.0, 0.0, 0.0, 37.0, 32.0, 0.0, 0.0, 82.0, 0.0, 0.0, 62.0, 63.0, 0.0, 128.0, 0.0, 3.0, 19.0, 0.0, 0.0, 21.0, 43.0, 11.0, 13.0, 29.0, 17.0, 8.0, 224.0, 233.0, 7.0, 34.0, 73.0, 2.0, 0.0, 93.0, 145.0, 8.0, 73.0, 0.0, 0.0, 16.0, 17.0, 18.0, 179.0, 191.0, 35.0, 91.0, 0.0, 10.0, 40.0, 0.0, 4.0, 14.0, 85.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 1.0, 58.0, 4.0, 8.0, 25.0, 0.0, 0.0, 0.0, 25.0, 18.0, 16.0, 10.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0, 77.0, 0.0, 12.0, 0.0, 62.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 30.0, 21.0, 11.0, 11.0, 5.0, 0.0, 20.0, 5.0, 0.0, 47.0, 52.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 27.0, 77.0, 1.0, 0.0, 21.0, 0.0, 0.0, 65.0, 2.0, 0.0, 16.0, 39.0, 0.0, 24.0, 6.0, 0.0, 0.0, 58.0, 3.0, 0.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 4.0, 6.0, 14.0, 36.0, 35.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0, 26.0, 46.0, 28.0, 51.0, 0.0, 40.0, 21.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5611294970095974, "mean_inference_ms": 1.414907254361081, "mean_action_processing_ms": 0.22649258447840037, "mean_env_wait_ms": 0.194108559507645, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004720091819763184, "StateBufferConnector_ms": 0.0035049915313720703, "ViewRequirementAgentConnector_ms": 0.10243630409240723}, "num_episodes": 18, "episode_return_max": 234.89999999999938, "episode_return_min": -305.60000000000014, "episode_return_mean": 27.114999999999924, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 443.5415398785689, "num_env_steps_trained_throughput_per_sec": 443.5415398785689, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 9618.067, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9618.019, "sample_time_ms": 1219.858, "learn_time_ms": 8383.727, "learn_throughput": 477.115, "synch_weights_time_ms": 12.905}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "04dec_00002", "date": "2024-08-13_16-26-28", "timestamp": 1723580788, "time_this_iter_s": 9.022750854492188, "time_total_s": 223.65884160995483, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0456f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 223.65884160995483, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 30.96923076923077, "ram_util_percent": 82.71538461538464}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.406456147765041, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 1.0428760336189673, "policy_loss": -0.003128448312500955, "vf_loss": 1.045291618111903, "vf_explained_var": 0.0035545437424271196, "kl": 0.005632518333947272, "entropy": 1.4924536453353034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2333557473367485, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.657506602655643, "policy_loss": -0.0011291179716064737, "vf_loss": 2.6579747459245104, "vf_explained_var": 0.04358720019380882, "kl": 0.008812981846847631, "entropy": 1.2077179157544695, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 234.89999999999938, "episode_reward_min": -146.70000000000084, "episode_reward_mean": 39.18699999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -406.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.0999999999997, "predator_policy": 233.0}, "policy_reward_mean": {"prey_policy": -0.3565000000000441, "predator_policy": 19.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.100000000000414, -21.699999999999932, -5.699999999999726, -25.899999999999665, 131.79999999999845, -146.70000000000084, -89.10000000000014, 37.60000000000031, 78.49999999999942, 19.599999999999977, 59.8000000000003, 28.000000000000384, 56.60000000000036, -27.999999999999808, -23.39999999999955, -66.20000000000141, -2.8999999999996984, -46.0999999999998, -40.299999999999706, 22.400000000000027, 38.40000000000034, -6.099999999999916, -93.5000000000004, 32.60000000000019, -3.9999999999997313, 27.400000000000105, -110.10000000000142, 78.69999999999942, 51.70000000000049, 15.699999999999976, -23.99999999999956, 97.89999999999841, 16.999999999999925, 40.0000000000003, 7.400000000000091, 40.20000000000032, 40.0000000000003, 22.80000000000003, 143.49999999999878, 55.300000000000516, -17.499999999999737, 44.80000000000038, -14.699999999999637, 34.50000000000022, 60.100000000000314, 46.3000000000004, 7.0000000000000995, 167.39999999999898, 146.59999999999914, 17.999999999999943, 57.00000000000049, 46.60000000000038, 65.20000000000041, 47.70000000000044, 73.09999999999984, -70.79999999999973, 87.49999999999882, 162.69999999999942, -26.09999999999956, 84.599999999999, 27.20000000000021, 28.900000000000187, 101.79999999999906, 24.800000000000264, 90.69999999999882, 13.900000000000013, 40.0000000000003, 64.30000000000047, 161.29999999999916, 40.0000000000003, 76.89999999999975, -1.199999999999807, 138.19999999999953, 234.89999999999938, 123.89999999999975, 85.29999999999941, 40.0000000000003, 74.19999999999976, 40.000000000000156, 40.400000000000084, 93.49999999999883, 17.799999999999944, 130.89999999999873, 40.0000000000003, 100.69999999999882, 26.800000000000086, 40.0000000000003, 27.70000000000023, -110.40000000000126, 78.69999999999945, 40.0000000000003, 4.800000000000157, 100.29999999999828, 40.0000000000003, 83.39999999999951, 106.59999999999889, 14.000000000000005, 128.19999999999914, 36.70000000000025, 25.200000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [4.399999999999972, -43.299999999999834, -15.699999999999918, -43.0, -1.0000000000000275, -36.69999999999977, 20.900000000000027, -128.80000000000052, 92.89999999999932, 38.900000000000254, -158.2000000000005, -113.50000000000034, -204.70000000000002, -12.399999999999844, 20.90000000000003, 13.699999999999978, 4.39999999999999, 55.1000000000001, 20.000000000000014, -21.39999999999975, 82.09999999999944, -76.3000000000007, 20.000000000000014, -34.000000000000014, 3.1999999999999615, 28.40000000000017, -406.29999999999995, -78.70000000000056, -21.99999999999978, -42.399999999999764, -57.70000000000021, -83.50000000000077, -142.60000000000002, 46.70000000000021, 3.1999999999999615, -202.30000000000027, -70.30000000000048, -42.999999999999815, -13.599999999999808, 20.000000000000014, 21.20000000000005, -17.799999999999784, -36.99999999999977, -339.1, 20.000000000000014, -239.50000000000014, -0.9999999999999846, 23.600000000000065, 20.000000000000014, -64.00000000000091, 12.499999999999966, -3.099999999999972, -129.7000000000007, -72.40000000000073, 20.000000000000014, 58.700000000000216, 29.90000000000018, 21.80000000000004, 40.70000000000025, -70.0000000000007, -55.60000000000005, -27.39999999999975, 41.60000000000019, 44.3000000000002, -27.99999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -55.60000000000032, 10.699999999999978, 3.4999999999999813, 20.000000000000014, 20.000000000000014, -28.299999999999763, 28.100000000000147, 20.000000000000014, 123.49999999999952, 20.000000000000014, 35.30000000000026, 72.19999999999959, -204.70000000000053, 12.799999999999974, 20.000000000000014, 23.60000000000007, -100.30000000000072, 20.000000000000014, 9.499999999999964, 43.40000000000014, 13.699999999999964, 22.700000000000053, 23.600000000000076, -38.79999999999977, 15.799999999999963, 145.0999999999997, -9.699999999999882, 2.2999999999999643, 128.29999999999973, -21.999999999999865, 20.000000000000014, 32.00000000000022, 20.000000000000014, -34.89999999999983, -17.499999999999794, 20.000000000000014, 45.200000000000244, 20.000000000000014, 16.69999999999997, 21.80000000000004, 50.30000000000023, -131.2000000000003, -43.59999999999977, 39.50000000000025, 47.00000000000024, 15.799999999999963, 125.89999999999996, -24.099999999999852, -67.00000000000082, 20.000000000000014, 62.60000000000021, -13.59999999999979, -14.199999999999909, -23.19999999999976, 28.100000000000158, 75.79999999999956, 20.000000000000014, -29.199999999999932, -4.000000000000044, 67.69999999999987, 20.000000000000014, 20.000000000000014, -60.1000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.30000000000023, 140.29999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 56.90000000000006, 20.000000000000014, -65.80000000000075, 11.599999999999968, 20.000000000000014, 114.19999999999995, 77.59999999999982, 137.3, -31.900000000000084, 84.7999999999995, 47.00000000000018, 14.300000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000023, 21.500000000000043, -53.50000000000001, -58.600000000000165, 20.000000000000014, 79.69999999999942, -26.199999999999847, -23.199999999999747, 20.000000000000014, 20.000000000000014, 110.89999999999947, 20.000000000000014, 20.000000000000014, 4.699999999999967, 79.99999999999942, 20.000000000000014, -5.200000000000015, 20.000000000000014, 20.000000000000014, -73.30000000000035, 20.000000000000014, -84.10000000000053, -112.30000000000072, 20.000000000000014, 58.700000000000095, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 38.90000000000023, 61.40000000000021, 20.000000000000014, 20.000000000000014, 29.90000000000005, 36.50000000000018, 20.000000000000014, 86.59999999999948, 20.000000000000014, -54.999999999999915, 100.09999999999962, 28.100000000000104, 20.000000000000014, 13.699999999999966, 13.39999999999998, -35.199999999999775], "policy_predator_policy_reward": [58.0, 0.0, 0.0, 37.0, 32.0, 0.0, 0.0, 82.0, 0.0, 0.0, 62.0, 63.0, 0.0, 128.0, 0.0, 3.0, 19.0, 0.0, 0.0, 21.0, 43.0, 11.0, 13.0, 29.0, 17.0, 8.0, 224.0, 233.0, 7.0, 34.0, 73.0, 2.0, 0.0, 93.0, 145.0, 8.0, 73.0, 0.0, 0.0, 16.0, 17.0, 18.0, 179.0, 191.0, 35.0, 91.0, 0.0, 10.0, 40.0, 0.0, 4.0, 14.0, 85.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 1.0, 58.0, 4.0, 8.0, 25.0, 0.0, 0.0, 0.0, 25.0, 18.0, 16.0, 10.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0, 77.0, 0.0, 12.0, 0.0, 62.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 30.0, 21.0, 11.0, 11.0, 5.0, 0.0, 20.0, 5.0, 0.0, 47.0, 52.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 27.0, 77.0, 1.0, 0.0, 21.0, 0.0, 0.0, 65.0, 2.0, 0.0, 16.0, 39.0, 0.0, 24.0, 6.0, 0.0, 0.0, 58.0, 3.0, 0.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 4.0, 6.0, 14.0, 36.0, 35.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0, 26.0, 46.0, 28.0, 51.0, 0.0, 40.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 12.0, 0.0, 0.0, 28.0, 53.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 49.0, 0.0, 0.0, 3.0, 0.0, 28.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.562820675103782, "mean_inference_ms": 1.4188012174316469, "mean_action_processing_ms": 0.23346884939572596, "mean_env_wait_ms": 0.194569424865792, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005529999732971191, "StateBufferConnector_ms": 0.003742218017578125, "ViewRequirementAgentConnector_ms": 0.11272239685058594}, "num_episodes": 18, "episode_return_max": 234.89999999999938, "episode_return_min": -146.70000000000084, "episode_return_mean": 39.18699999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 407.01335856102776, "num_env_steps_trained_throughput_per_sec": 407.01335856102776, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 9637.101, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9637.052, "sample_time_ms": 1308.277, "learn_time_ms": 8314.299, "learn_throughput": 481.099, "synch_weights_time_ms": 12.944}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "04dec_00002", "date": "2024-08-13_16-26-38", "timestamp": 1723580798, "time_this_iter_s": 9.833369731903076, "time_total_s": 233.4922113418579, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0461700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 233.4922113418579, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 35.47142857142857, "ram_util_percent": 82.22142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4240673782254653, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 1.061676788881973, "policy_loss": -0.008653088029173434, "vf_loss": 1.0690626398596184, "vf_explained_var": 0.004757588439517551, "kl": 0.010012736841067899, "entropy": 1.5275781999189386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2084473949812709, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.3577916001516677, "policy_loss": -0.00537337131561741, "vf_loss": 2.3618329613297075, "vf_explained_var": 0.0357445514391339, "kl": 0.01776022999333482, "entropy": 1.2710314833928669, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 234.89999999999938, "episode_reward_min": -110.40000000000126, "episode_reward_mean": 47.05299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -339.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.0999999999997, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 8.27149999999997, "predator_policy": 15.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.299999999999706, 22.400000000000027, 38.40000000000034, -6.099999999999916, -93.5000000000004, 32.60000000000019, -3.9999999999997313, 27.400000000000105, -110.10000000000142, 78.69999999999942, 51.70000000000049, 15.699999999999976, -23.99999999999956, 97.89999999999841, 16.999999999999925, 40.0000000000003, 7.400000000000091, 40.20000000000032, 40.0000000000003, 22.80000000000003, 143.49999999999878, 55.300000000000516, -17.499999999999737, 44.80000000000038, -14.699999999999637, 34.50000000000022, 60.100000000000314, 46.3000000000004, 7.0000000000000995, 167.39999999999898, 146.59999999999914, 17.999999999999943, 57.00000000000049, 46.60000000000038, 65.20000000000041, 47.70000000000044, 73.09999999999984, -70.79999999999973, 87.49999999999882, 162.69999999999942, -26.09999999999956, 84.599999999999, 27.20000000000021, 28.900000000000187, 101.79999999999906, 24.800000000000264, 90.69999999999882, 13.900000000000013, 40.0000000000003, 64.30000000000047, 161.29999999999916, 40.0000000000003, 76.89999999999975, -1.199999999999807, 138.19999999999953, 234.89999999999938, 123.89999999999975, 85.29999999999941, 40.0000000000003, 74.19999999999976, 40.000000000000156, 40.400000000000084, 93.49999999999883, 17.799999999999944, 130.89999999999873, 40.0000000000003, 100.69999999999882, 26.800000000000086, 40.0000000000003, 27.70000000000023, -110.40000000000126, 78.69999999999945, 40.0000000000003, 4.800000000000157, 100.29999999999828, 40.0000000000003, 83.39999999999951, 106.59999999999889, 14.000000000000005, 128.19999999999914, 36.70000000000025, 25.200000000000003, -10.19999999999966, 49.90000000000046, 37.40000000000027, -7.29999999999977, -5.599999999999783, -33.8999999999998, 88.69999999999868, 36.50000000000026, 21.900000000000038, 38.20000000000031, 94.89999999999915, 80.49999999999919, 83.89999999999905, 68.59999999999991, 19.40000000000013, 54.400000000000524, 104.79999999999876, 39.800000000000296], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-70.30000000000048, -42.999999999999815, -13.599999999999808, 20.000000000000014, 21.20000000000005, -17.799999999999784, -36.99999999999977, -339.1, 20.000000000000014, -239.50000000000014, -0.9999999999999846, 23.600000000000065, 20.000000000000014, -64.00000000000091, 12.499999999999966, -3.099999999999972, -129.7000000000007, -72.40000000000073, 20.000000000000014, 58.700000000000216, 29.90000000000018, 21.80000000000004, 40.70000000000025, -70.0000000000007, -55.60000000000005, -27.39999999999975, 41.60000000000019, 44.3000000000002, -27.99999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -55.60000000000032, 10.699999999999978, 3.4999999999999813, 20.000000000000014, 20.000000000000014, -28.299999999999763, 28.100000000000147, 20.000000000000014, 123.49999999999952, 20.000000000000014, 35.30000000000026, 72.19999999999959, -204.70000000000053, 12.799999999999974, 20.000000000000014, 23.60000000000007, -100.30000000000072, 20.000000000000014, 9.499999999999964, 43.40000000000014, 13.699999999999964, 22.700000000000053, 23.600000000000076, -38.79999999999977, 15.799999999999963, 145.0999999999997, -9.699999999999882, 2.2999999999999643, 128.29999999999973, -21.999999999999865, 20.000000000000014, 32.00000000000022, 20.000000000000014, -34.89999999999983, -17.499999999999794, 20.000000000000014, 45.200000000000244, 20.000000000000014, 16.69999999999997, 21.80000000000004, 50.30000000000023, -131.2000000000003, -43.59999999999977, 39.50000000000025, 47.00000000000024, 15.799999999999963, 125.89999999999996, -24.099999999999852, -67.00000000000082, 20.000000000000014, 62.60000000000021, -13.59999999999979, -14.199999999999909, -23.19999999999976, 28.100000000000158, 75.79999999999956, 20.000000000000014, -29.199999999999932, -4.000000000000044, 67.69999999999987, 20.000000000000014, 20.000000000000014, -60.1000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.30000000000023, 140.29999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 56.90000000000006, 20.000000000000014, -65.80000000000075, 11.599999999999968, 20.000000000000014, 114.19999999999995, 77.59999999999982, 137.3, -31.900000000000084, 84.7999999999995, 47.00000000000018, 14.300000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000023, 21.500000000000043, -53.50000000000001, -58.600000000000165, 20.000000000000014, 79.69999999999942, -26.199999999999847, -23.199999999999747, 20.000000000000014, 20.000000000000014, 110.89999999999947, 20.000000000000014, 20.000000000000014, 4.699999999999967, 79.99999999999942, 20.000000000000014, -5.200000000000015, 20.000000000000014, 20.000000000000014, -73.30000000000035, 20.000000000000014, -84.10000000000053, -112.30000000000072, 20.000000000000014, 58.700000000000095, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 38.90000000000023, 61.40000000000021, 20.000000000000014, 20.000000000000014, 29.90000000000005, 36.50000000000018, 20.000000000000014, 86.59999999999948, 20.000000000000014, -54.999999999999915, 100.09999999999962, 28.100000000000104, 20.000000000000014, 13.699999999999966, 13.39999999999998, -35.199999999999775, -19.89999999999977, -28.299999999999777, 29.90000000000018, 20.000000000000014, 4.399999999999995, 20.000000000000014, 20.000000000000014, -70.30000000000072, -0.10000000000000281, -53.50000000000011, -36.09999999999988, -56.799999999999926, 22.40000000000005, 59.30000000000019, -0.9999999999999846, 15.499999999999956, -64.00000000000088, -0.09999999999997983, 20.000000000000014, -44.79999999999987, 20.000000000000014, 65.89999999999999, 60.50000000000017, 20.000000000000014, 32.90000000000013, 20.000000000000014, 20.000000000000014, 38.60000000000009, -76.60000000000002, 20.000000000000014, 34.40000000000026, 20.000000000000014, 84.7999999999994, 20.000000000000014, 20.000000000000014, 18.799999999999997], "policy_predator_policy_reward": [73.0, 0.0, 0.0, 16.0, 17.0, 18.0, 179.0, 191.0, 35.0, 91.0, 0.0, 10.0, 40.0, 0.0, 4.0, 14.0, 85.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 1.0, 58.0, 4.0, 8.0, 25.0, 0.0, 0.0, 0.0, 25.0, 18.0, 16.0, 10.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0, 77.0, 0.0, 12.0, 0.0, 62.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 30.0, 21.0, 11.0, 11.0, 5.0, 0.0, 20.0, 5.0, 0.0, 47.0, 52.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 27.0, 77.0, 1.0, 0.0, 21.0, 0.0, 0.0, 65.0, 2.0, 0.0, 16.0, 39.0, 0.0, 24.0, 6.0, 0.0, 0.0, 58.0, 3.0, 0.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 4.0, 6.0, 14.0, 36.0, 35.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0, 26.0, 46.0, 28.0, 51.0, 0.0, 40.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 12.0, 0.0, 0.0, 28.0, 53.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 49.0, 0.0, 0.0, 3.0, 0.0, 28.0, 19.0, 16.0, 22.0, 0.0, 0.0, 0.0, 13.0, 0.0, 43.0, 0.0, 48.0, 59.0, 0.0, 7.0, 0.0, 12.0, 10.0, 57.0, 29.0, 35.0, 28.0, 0.0, 9.0, 0.0, 0.0, 17.0, 14.0, 0.0, 10.0, 41.0, 35.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5642631949802615, "mean_inference_ms": 1.4229742114546828, "mean_action_processing_ms": 0.24024118236718536, "mean_env_wait_ms": 0.1950343943204532, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0061893463134765625, "StateBufferConnector_ms": 0.0034247636795043945, "ViewRequirementAgentConnector_ms": 0.1101987361907959}, "num_episodes": 18, "episode_return_max": 234.89999999999938, "episode_return_min": -110.40000000000126, "episode_return_mean": 47.05299999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 446.61963178539577, "num_env_steps_trained_throughput_per_sec": 446.61963178539577, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 9571.028, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9570.979, "sample_time_ms": 1297.143, "learn_time_ms": 8259.546, "learn_throughput": 484.288, "synch_weights_time_ms": 12.791}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "04dec_00002", "date": "2024-08-13_16-26-47", "timestamp": 1723580807, "time_this_iter_s": 8.959773778915405, "time_total_s": 242.45198512077332, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04b95e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 242.45198512077332, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 31.361538461538466, "ram_util_percent": 81.96153846153847}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5111998083099486, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 1.0241914892322803, "policy_loss": -0.005343321229025682, "vf_loss": 1.028487971298909, "vf_explained_var": 0.016168131210185864, "kl": 0.008271333202669203, "entropy": 1.5424242856010557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2605041611919958, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.3533247687198497, "policy_loss": -0.00047190901724789193, "vf_loss": 2.35341351253015, "vf_explained_var": 0.08814593701766281, "kl": 0.00510881566557776, "entropy": 1.2530234867933565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 234.89999999999938, "episode_reward_min": -110.40000000000126, "episode_reward_mean": 57.8479999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -204.70000000000053, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.0999999999997, "predator_policy": 86.0}, "policy_reward_mean": {"prey_policy": 16.513999999999974, "predator_policy": 12.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.499999999999737, 44.80000000000038, -14.699999999999637, 34.50000000000022, 60.100000000000314, 46.3000000000004, 7.0000000000000995, 167.39999999999898, 146.59999999999914, 17.999999999999943, 57.00000000000049, 46.60000000000038, 65.20000000000041, 47.70000000000044, 73.09999999999984, -70.79999999999973, 87.49999999999882, 162.69999999999942, -26.09999999999956, 84.599999999999, 27.20000000000021, 28.900000000000187, 101.79999999999906, 24.800000000000264, 90.69999999999882, 13.900000000000013, 40.0000000000003, 64.30000000000047, 161.29999999999916, 40.0000000000003, 76.89999999999975, -1.199999999999807, 138.19999999999953, 234.89999999999938, 123.89999999999975, 85.29999999999941, 40.0000000000003, 74.19999999999976, 40.000000000000156, 40.400000000000084, 93.49999999999883, 17.799999999999944, 130.89999999999873, 40.0000000000003, 100.69999999999882, 26.800000000000086, 40.0000000000003, 27.70000000000023, -110.40000000000126, 78.69999999999945, 40.0000000000003, 4.800000000000157, 100.29999999999828, 40.0000000000003, 83.39999999999951, 106.59999999999889, 14.000000000000005, 128.19999999999914, 36.70000000000025, 25.200000000000003, -10.19999999999966, 49.90000000000046, 37.40000000000027, -7.29999999999977, -5.599999999999783, -33.8999999999998, 88.69999999999868, 36.50000000000026, 21.900000000000038, 38.20000000000031, 94.89999999999915, 80.49999999999919, 83.89999999999905, 68.59999999999991, 19.40000000000013, 54.400000000000524, 104.79999999999876, 39.800000000000296, 63.6000000000004, -21.099999999999554, 201.09999999999926, -15.199999999999571, 43.000000000000306, 142.69999999999882, 83.59999999999928, 42.30000000000027, 90.09999999999933, 112.89999999999861, 82.39999999999999, 52.70000000000044, 14.499999999999995, 55.30000000000051, 126.39999999999876, 52.400000000000446, 9.900000000000057, 91.29999999999859, 89.49999999999862, 58.00000000000035, 35.10000000000023, 121.99999999999908], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [72.19999999999959, -204.70000000000053, 12.799999999999974, 20.000000000000014, 23.60000000000007, -100.30000000000072, 20.000000000000014, 9.499999999999964, 43.40000000000014, 13.699999999999964, 22.700000000000053, 23.600000000000076, -38.79999999999977, 15.799999999999963, 145.0999999999997, -9.699999999999882, 2.2999999999999643, 128.29999999999973, -21.999999999999865, 20.000000000000014, 32.00000000000022, 20.000000000000014, -34.89999999999983, -17.499999999999794, 20.000000000000014, 45.200000000000244, 20.000000000000014, 16.69999999999997, 21.80000000000004, 50.30000000000023, -131.2000000000003, -43.59999999999977, 39.50000000000025, 47.00000000000024, 15.799999999999963, 125.89999999999996, -24.099999999999852, -67.00000000000082, 20.000000000000014, 62.60000000000021, -13.59999999999979, -14.199999999999909, -23.19999999999976, 28.100000000000158, 75.79999999999956, 20.000000000000014, -29.199999999999932, -4.000000000000044, 67.69999999999987, 20.000000000000014, 20.000000000000014, -60.1000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.30000000000023, 140.29999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 56.90000000000006, 20.000000000000014, -65.80000000000075, 11.599999999999968, 20.000000000000014, 114.19999999999995, 77.59999999999982, 137.3, -31.900000000000084, 84.7999999999995, 47.00000000000018, 14.300000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000023, 21.500000000000043, -53.50000000000001, -58.600000000000165, 20.000000000000014, 79.69999999999942, -26.199999999999847, -23.199999999999747, 20.000000000000014, 20.000000000000014, 110.89999999999947, 20.000000000000014, 20.000000000000014, 4.699999999999967, 79.99999999999942, 20.000000000000014, -5.200000000000015, 20.000000000000014, 20.000000000000014, -73.30000000000035, 20.000000000000014, -84.10000000000053, -112.30000000000072, 20.000000000000014, 58.700000000000095, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 38.90000000000023, 61.40000000000021, 20.000000000000014, 20.000000000000014, 29.90000000000005, 36.50000000000018, 20.000000000000014, 86.59999999999948, 20.000000000000014, -54.999999999999915, 100.09999999999962, 28.100000000000104, 20.000000000000014, 13.699999999999966, 13.39999999999998, -35.199999999999775, -19.89999999999977, -28.299999999999777, 29.90000000000018, 20.000000000000014, 4.399999999999995, 20.000000000000014, 20.000000000000014, -70.30000000000072, -0.10000000000000281, -53.50000000000011, -36.09999999999988, -56.799999999999926, 22.40000000000005, 59.30000000000019, -0.9999999999999846, 15.499999999999956, -64.00000000000088, -0.09999999999997983, 20.000000000000014, -44.79999999999987, 20.000000000000014, 65.89999999999999, 60.50000000000017, 20.000000000000014, 32.90000000000013, 20.000000000000014, 20.000000000000014, 38.60000000000009, -76.60000000000002, 20.000000000000014, 34.40000000000026, 20.000000000000014, 84.7999999999994, 20.000000000000014, 20.000000000000014, 18.799999999999997, 26.60000000000014, 20.000000000000014, -13.5999999999998, -53.50000000000008, 58.700000000000216, 142.39999999999995, -38.79999999999977, -9.399999999999897, 20.000000000000014, 11.000000000000027, 127.09999999999954, 11.599999999999966, -32.49999999999975, 91.09999999999957, -21.699999999999854, 1.9999999999999998, -27.699999999999754, 93.7999999999996, 28.100000000000147, 84.7999999999993, 31.40000000000002, 20.000000000000014, 28.700000000000163, 20.000000000000014, 20.90000000000003, -30.39999999999975, 20.000000000000014, 35.30000000000025, 106.39999999999947, 20.000000000000014, 27.200000000000134, 18.19999999999999, -87.70000000000059, 26.600000000000072, 20.000000000000014, 71.29999999999968, 20.000000000000014, 69.4999999999998, 15.799999999999963, 24.20000000000013, -11.49999999999984, 23.600000000000076, 31.100000000000115, 47.90000000000024], "policy_predator_policy_reward": [38.0, 77.0, 0.0, 12.0, 0.0, 62.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 30.0, 21.0, 11.0, 11.0, 5.0, 0.0, 20.0, 5.0, 0.0, 47.0, 52.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 27.0, 77.0, 1.0, 0.0, 21.0, 0.0, 0.0, 65.0, 2.0, 0.0, 16.0, 39.0, 0.0, 24.0, 6.0, 0.0, 0.0, 58.0, 3.0, 0.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 4.0, 6.0, 14.0, 36.0, 35.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0, 26.0, 46.0, 28.0, 51.0, 0.0, 40.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 12.0, 0.0, 0.0, 28.0, 53.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 49.0, 0.0, 0.0, 3.0, 0.0, 28.0, 19.0, 16.0, 22.0, 0.0, 0.0, 0.0, 13.0, 0.0, 43.0, 0.0, 48.0, 59.0, 0.0, 7.0, 0.0, 12.0, 10.0, 57.0, 29.0, 35.0, 28.0, 0.0, 9.0, 0.0, 0.0, 17.0, 14.0, 0.0, 10.0, 41.0, 35.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 33.0, 12.0, 0.0, 4.0, 0.0, 8.0, 17.0, 20.0, 42.0, 24.0, 0.0, 0.0, 0.0, 24.0, 7.0, 0.0, 4.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 34.0, 37.0, 0.0, 0.0, 0.0, 0.0, 2.0, 16.0, 13.0, 10.0, 12.0, 31.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5650555734826674, "mean_inference_ms": 1.4251955179612494, "mean_action_processing_ms": 0.24775609127131645, "mean_env_wait_ms": 0.1952265956609927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0066297054290771484, "StateBufferConnector_ms": 0.0033500194549560547, "ViewRequirementAgentConnector_ms": 0.10819363594055176}, "num_episodes": 22, "episode_return_max": 234.89999999999938, "episode_return_min": -110.40000000000126, "episode_return_mean": 57.8479999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 461.6455546639689, "num_env_steps_trained_throughput_per_sec": 461.6455546639689, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 9464.975, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9464.928, "sample_time_ms": 1275.75, "learn_time_ms": 8175.008, "learn_throughput": 489.296, "synch_weights_time_ms": 12.695}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "04dec_00002", "date": "2024-08-13_16-26-55", "timestamp": 1723580815, "time_this_iter_s": 8.668697118759155, "time_total_s": 251.12068223953247, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04b9f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 251.12068223953247, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 28.076923076923077, "ram_util_percent": 81.86923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5459649289017001, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 1.9757052273346634, "policy_loss": -0.004723679810200655, "vf_loss": 1.9792769088316216, "vf_explained_var": 0.012385152887415003, "kl": 0.009102158229498777, "entropy": 1.5063230924505406, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.266261865301107, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 0.00010000000000000003, "total_loss": 3.7813076155526297, "policy_loss": -0.0011856621035212088, "vf_loss": 3.782170493640597, "vf_explained_var": 0.041946009763334166, "kl": 0.004303851747515119, "entropy": 1.2082537063845882, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 234.89999999999938, "episode_reward_min": -205.2000000000009, "episode_reward_mean": 57.43999999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 142.39999999999995, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 15.469999999999946, "predator_policy": 13.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.800000000000264, 90.69999999999882, 13.900000000000013, 40.0000000000003, 64.30000000000047, 161.29999999999916, 40.0000000000003, 76.89999999999975, -1.199999999999807, 138.19999999999953, 234.89999999999938, 123.89999999999975, 85.29999999999941, 40.0000000000003, 74.19999999999976, 40.000000000000156, 40.400000000000084, 93.49999999999883, 17.799999999999944, 130.89999999999873, 40.0000000000003, 100.69999999999882, 26.800000000000086, 40.0000000000003, 27.70000000000023, -110.40000000000126, 78.69999999999945, 40.0000000000003, 4.800000000000157, 100.29999999999828, 40.0000000000003, 83.39999999999951, 106.59999999999889, 14.000000000000005, 128.19999999999914, 36.70000000000025, 25.200000000000003, -10.19999999999966, 49.90000000000046, 37.40000000000027, -7.29999999999977, -5.599999999999783, -33.8999999999998, 88.69999999999868, 36.50000000000026, 21.900000000000038, 38.20000000000031, 94.89999999999915, 80.49999999999919, 83.89999999999905, 68.59999999999991, 19.40000000000013, 54.400000000000524, 104.79999999999876, 39.800000000000296, 63.6000000000004, -21.099999999999554, 201.09999999999926, -15.199999999999571, 43.000000000000306, 142.69999999999882, 83.59999999999928, 42.30000000000027, 90.09999999999933, 112.89999999999861, 82.39999999999999, 52.70000000000044, 14.499999999999995, 55.30000000000051, 126.39999999999876, 52.400000000000446, 9.900000000000057, 91.29999999999859, 89.49999999999862, 58.00000000000035, 35.10000000000023, 121.99999999999908, 69.69999999999997, 54.9000000000003, -2.7999999999998937, 113.79999999999944, 40.0000000000003, -6.099999999999689, -205.2000000000009, 160.09999999999917, 29.500000000000153, 129.799999999999, 57.10000000000051, 24.600000000000065, 62.000000000000355, 159.1999999999986, -2.8999999999998085, 189.399999999999, 22.400000000000233, 76.89999999999947, 23.600000000000033, 35.900000000000254, 106.59999999999891, -8.899999999999912, 7.500000000000098], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.199999999999932, -4.000000000000044, 67.69999999999987, 20.000000000000014, 20.000000000000014, -60.1000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.30000000000023, 140.29999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 56.90000000000006, 20.000000000000014, -65.80000000000075, 11.599999999999968, 20.000000000000014, 114.19999999999995, 77.59999999999982, 137.3, -31.900000000000084, 84.7999999999995, 47.00000000000018, 14.300000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000023, 21.500000000000043, -53.50000000000001, -58.600000000000165, 20.000000000000014, 79.69999999999942, -26.199999999999847, -23.199999999999747, 20.000000000000014, 20.000000000000014, 110.89999999999947, 20.000000000000014, 20.000000000000014, 4.699999999999967, 79.99999999999942, 20.000000000000014, -5.200000000000015, 20.000000000000014, 20.000000000000014, -73.30000000000035, 20.000000000000014, -84.10000000000053, -112.30000000000072, 20.000000000000014, 58.700000000000095, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 38.90000000000023, 61.40000000000021, 20.000000000000014, 20.000000000000014, 29.90000000000005, 36.50000000000018, 20.000000000000014, 86.59999999999948, 20.000000000000014, -54.999999999999915, 100.09999999999962, 28.100000000000104, 20.000000000000014, 13.699999999999966, 13.39999999999998, -35.199999999999775, -19.89999999999977, -28.299999999999777, 29.90000000000018, 20.000000000000014, 4.399999999999995, 20.000000000000014, 20.000000000000014, -70.30000000000072, -0.10000000000000281, -53.50000000000011, -36.09999999999988, -56.799999999999926, 22.40000000000005, 59.30000000000019, -0.9999999999999846, 15.499999999999956, -64.00000000000088, -0.09999999999997983, 20.000000000000014, -44.79999999999987, 20.000000000000014, 65.89999999999999, 60.50000000000017, 20.000000000000014, 32.90000000000013, 20.000000000000014, 20.000000000000014, 38.60000000000009, -76.60000000000002, 20.000000000000014, 34.40000000000026, 20.000000000000014, 84.7999999999994, 20.000000000000014, 20.000000000000014, 18.799999999999997, 26.60000000000014, 20.000000000000014, -13.5999999999998, -53.50000000000008, 58.700000000000216, 142.39999999999995, -38.79999999999977, -9.399999999999897, 20.000000000000014, 11.000000000000027, 127.09999999999954, 11.599999999999966, -32.49999999999975, 91.09999999999957, -21.699999999999854, 1.9999999999999998, -27.699999999999754, 93.7999999999996, 28.100000000000147, 84.7999999999993, 31.40000000000002, 20.000000000000014, 28.700000000000163, 20.000000000000014, 20.90000000000003, -30.39999999999975, 20.000000000000014, 35.30000000000025, 106.39999999999947, 20.000000000000014, 27.200000000000134, 18.19999999999999, -87.70000000000059, 26.600000000000072, 20.000000000000014, 71.29999999999968, 20.000000000000014, 69.4999999999998, 15.799999999999963, 24.20000000000013, -11.49999999999984, 23.600000000000076, 31.100000000000115, 47.90000000000024, 49.70000000000019, 20.000000000000014, 73.99999999999949, -87.10000000000085, -108.10000000000052, 44.30000000000015, -30.999999999999957, 75.79999999999977, 20.000000000000014, 20.000000000000014, 17.899999999999988, -64.00000000000091, -150.10000000000053, -171.10000000000036, 119.59999999999978, 33.50000000000024, 5.899999999999967, 2.59999999999997, -14.499999999999936, 89.29999999999941, 20.000000000000014, 37.10000000000026, -9.399999999999876, 20.000000000000014, 39.80000000000013, -20.799999999999798, 54.20000000000023, 97.9999999999995, -61.90000000000065, 20.000000000000014, 57.800000000000225, 131.5999999999998, -79.6000000000003, 1.9999999999999767, 38.90000000000016, 20.000000000000014, -0.9999999999999704, -12.399999999999908, -108.10000000000078, 82.99999999999926, 20.000000000000014, 86.5999999999995, 20.000000000000014, -97.9000000000002, -7.299999999999891, -17.19999999999977], "policy_predator_policy_reward": [0.0, 58.0, 3.0, 0.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 4.0, 6.0, 14.0, 36.0, 35.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0, 26.0, 46.0, 28.0, 51.0, 0.0, 40.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 12.0, 0.0, 0.0, 28.0, 53.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 49.0, 0.0, 0.0, 3.0, 0.0, 28.0, 19.0, 16.0, 22.0, 0.0, 0.0, 0.0, 13.0, 0.0, 43.0, 0.0, 48.0, 59.0, 0.0, 7.0, 0.0, 12.0, 10.0, 57.0, 29.0, 35.0, 28.0, 0.0, 9.0, 0.0, 0.0, 17.0, 14.0, 0.0, 10.0, 41.0, 35.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 33.0, 12.0, 0.0, 4.0, 0.0, 8.0, 17.0, 20.0, 42.0, 24.0, 0.0, 0.0, 0.0, 24.0, 7.0, 0.0, 4.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 34.0, 37.0, 0.0, 0.0, 0.0, 0.0, 2.0, 16.0, 13.0, 10.0, 12.0, 31.0, 0.0, 0.0, 36.0, 32.0, 61.0, 0.0, 29.0, 40.0, 0.0, 0.0, 0.0, 40.0, 0.0, 116.0, 0.0, 7.0, 0.0, 21.0, 34.0, 21.0, 0.0, 0.0, 14.0, 0.0, 12.0, 31.0, 7.0, 0.0, 39.0, 0.0, 0.0, 0.0, 32.0, 68.0, 0.0, 18.0, 21.0, 16.0, 61.0, 0.0, 0.0, 0.0, 69.0, 0.0, 32.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5650407742161443, "mean_inference_ms": 1.4282028294705094, "mean_action_processing_ms": 0.2556168393973113, "mean_env_wait_ms": 0.1953785831051056, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006509900093078613, "StateBufferConnector_ms": 0.0033545494079589844, "ViewRequirementAgentConnector_ms": 0.10836982727050781}, "num_episodes": 23, "episode_return_max": 234.89999999999938, "episode_return_min": -205.2000000000009, "episode_return_mean": 57.43999999999977, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 455.32821462750945, "num_env_steps_trained_throughput_per_sec": 455.32821462750945, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 9370.472, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9370.427, "sample_time_ms": 1261.341, "learn_time_ms": 8095.187, "learn_throughput": 494.121, "synch_weights_time_ms": 12.521}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "04dec_00002", "date": "2024-08-13_16-27-04", "timestamp": 1723580824, "time_this_iter_s": 8.787722110748291, "time_total_s": 259.90840435028076, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04613a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 259.90840435028076, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 30.349999999999998, "ram_util_percent": 81.75833333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6567899949336178, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 1.9060367941225647, "policy_loss": -0.006412803260338488, "vf_loss": 1.9116968578762479, "vf_explained_var": 0.017888522085058627, "kl": 0.005947600041297303, "entropy": 1.4854623049024551, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4052320318917433, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 0.00010000000000000003, "total_loss": 3.173268923557625, "policy_loss": -0.00112686990341418, "vf_loss": 3.174088055746896, "vf_explained_var": 0.03471339852721603, "kl": 0.00820625839836631, "entropy": 1.199846821361118, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 201.09999999999926, "episode_reward_min": -205.2000000000009, "episode_reward_mean": 49.7379999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 142.39999999999995, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 10.543999999999947, "predator_policy": 14.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.799999999999944, 130.89999999999873, 40.0000000000003, 100.69999999999882, 26.800000000000086, 40.0000000000003, 27.70000000000023, -110.40000000000126, 78.69999999999945, 40.0000000000003, 4.800000000000157, 100.29999999999828, 40.0000000000003, 83.39999999999951, 106.59999999999889, 14.000000000000005, 128.19999999999914, 36.70000000000025, 25.200000000000003, -10.19999999999966, 49.90000000000046, 37.40000000000027, -7.29999999999977, -5.599999999999783, -33.8999999999998, 88.69999999999868, 36.50000000000026, 21.900000000000038, 38.20000000000031, 94.89999999999915, 80.49999999999919, 83.89999999999905, 68.59999999999991, 19.40000000000013, 54.400000000000524, 104.79999999999876, 39.800000000000296, 63.6000000000004, -21.099999999999554, 201.09999999999926, -15.199999999999571, 43.000000000000306, 142.69999999999882, 83.59999999999928, 42.30000000000027, 90.09999999999933, 112.89999999999861, 82.39999999999999, 52.70000000000044, 14.499999999999995, 55.30000000000051, 126.39999999999876, 52.400000000000446, 9.900000000000057, 91.29999999999859, 89.49999999999862, 58.00000000000035, 35.10000000000023, 121.99999999999908, 69.69999999999997, 54.9000000000003, -2.7999999999998937, 113.79999999999944, 40.0000000000003, -6.099999999999689, -205.2000000000009, 160.09999999999917, 29.500000000000153, 129.799999999999, 57.10000000000051, 24.600000000000065, 62.000000000000355, 159.1999999999986, -2.8999999999998085, 189.399999999999, 22.400000000000233, 76.89999999999947, 23.600000000000033, 35.900000000000254, 106.59999999999891, -8.899999999999912, 7.500000000000098, 84.19999999999902, 91.19999999999902, 71.69999999999987, 116.69999999999933, 65.00000000000026, 37.40000000000046, 120.19999999999875, 40.0000000000003, 21.800000000000015, 54.000000000000256, 31.800000000000185, -6.199999999999703, 42.30000000000044, 48.100000000000435, -187.6000000000006, -0.899999999999942, 34.80000000000027, -53.600000000000534], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-23.199999999999747, 20.000000000000014, 20.000000000000014, 110.89999999999947, 20.000000000000014, 20.000000000000014, 4.699999999999967, 79.99999999999942, 20.000000000000014, -5.200000000000015, 20.000000000000014, 20.000000000000014, -73.30000000000035, 20.000000000000014, -84.10000000000053, -112.30000000000072, 20.000000000000014, 58.700000000000095, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 38.90000000000023, 61.40000000000021, 20.000000000000014, 20.000000000000014, 29.90000000000005, 36.50000000000018, 20.000000000000014, 86.59999999999948, 20.000000000000014, -54.999999999999915, 100.09999999999962, 28.100000000000104, 20.000000000000014, 13.699999999999966, 13.39999999999998, -35.199999999999775, -19.89999999999977, -28.299999999999777, 29.90000000000018, 20.000000000000014, 4.399999999999995, 20.000000000000014, 20.000000000000014, -70.30000000000072, -0.10000000000000281, -53.50000000000011, -36.09999999999988, -56.799999999999926, 22.40000000000005, 59.30000000000019, -0.9999999999999846, 15.499999999999956, -64.00000000000088, -0.09999999999997983, 20.000000000000014, -44.79999999999987, 20.000000000000014, 65.89999999999999, 60.50000000000017, 20.000000000000014, 32.90000000000013, 20.000000000000014, 20.000000000000014, 38.60000000000009, -76.60000000000002, 20.000000000000014, 34.40000000000026, 20.000000000000014, 84.7999999999994, 20.000000000000014, 20.000000000000014, 18.799999999999997, 26.60000000000014, 20.000000000000014, -13.5999999999998, -53.50000000000008, 58.700000000000216, 142.39999999999995, -38.79999999999977, -9.399999999999897, 20.000000000000014, 11.000000000000027, 127.09999999999954, 11.599999999999966, -32.49999999999975, 91.09999999999957, -21.699999999999854, 1.9999999999999998, -27.699999999999754, 93.7999999999996, 28.100000000000147, 84.7999999999993, 31.40000000000002, 20.000000000000014, 28.700000000000163, 20.000000000000014, 20.90000000000003, -30.39999999999975, 20.000000000000014, 35.30000000000025, 106.39999999999947, 20.000000000000014, 27.200000000000134, 18.19999999999999, -87.70000000000059, 26.600000000000072, 20.000000000000014, 71.29999999999968, 20.000000000000014, 69.4999999999998, 15.799999999999963, 24.20000000000013, -11.49999999999984, 23.600000000000076, 31.100000000000115, 47.90000000000024, 49.70000000000019, 20.000000000000014, 73.99999999999949, -87.10000000000085, -108.10000000000052, 44.30000000000015, -30.999999999999957, 75.79999999999977, 20.000000000000014, 20.000000000000014, 17.899999999999988, -64.00000000000091, -150.10000000000053, -171.10000000000036, 119.59999999999978, 33.50000000000024, 5.899999999999967, 2.59999999999997, -14.499999999999936, 89.29999999999941, 20.000000000000014, 37.10000000000026, -9.399999999999876, 20.000000000000014, 39.80000000000013, -20.799999999999798, 54.20000000000023, 97.9999999999995, -61.90000000000065, 20.000000000000014, 57.800000000000225, 131.5999999999998, -79.6000000000003, 1.9999999999999767, 38.90000000000016, 20.000000000000014, -0.9999999999999704, -12.399999999999908, -108.10000000000078, 82.99999999999926, 20.000000000000014, 86.5999999999995, 20.000000000000014, -97.9000000000002, -7.299999999999891, -17.19999999999977, 47.00000000000024, 24.20000000000009, 66.19999999999999, 20.000000000000014, 17.899999999999984, 36.800000000000196, 22.9999999999999, 49.70000000000021, 20.000000000000014, 35.000000000000156, -35.49999999999987, 29.90000000000018, -74.50000000000075, 112.69999999999946, 20.000000000000014, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, -0.9999999999999295, -8.199999999999887, 20.000000000000014, -7.299999999999891, -40.89999999999978, -6.699999999999999, 20.000000000000014, 20.000000000000014, 28.10000000000015, -151.30000000000032, -154.30000000000024, -131.2000000000007, 56.30000000000019, 47.900000000000155, -84.10000000000083, -40.89999999999977, -96.70000000000061], "policy_predator_policy_reward": [21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 12.0, 0.0, 0.0, 28.0, 53.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 49.0, 0.0, 0.0, 3.0, 0.0, 28.0, 19.0, 16.0, 22.0, 0.0, 0.0, 0.0, 13.0, 0.0, 43.0, 0.0, 48.0, 59.0, 0.0, 7.0, 0.0, 12.0, 10.0, 57.0, 29.0, 35.0, 28.0, 0.0, 9.0, 0.0, 0.0, 17.0, 14.0, 0.0, 10.0, 41.0, 35.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 33.0, 12.0, 0.0, 4.0, 0.0, 8.0, 17.0, 20.0, 42.0, 24.0, 0.0, 0.0, 0.0, 24.0, 7.0, 0.0, 4.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 34.0, 37.0, 0.0, 0.0, 0.0, 0.0, 2.0, 16.0, 13.0, 10.0, 12.0, 31.0, 0.0, 0.0, 36.0, 32.0, 61.0, 0.0, 29.0, 40.0, 0.0, 0.0, 0.0, 40.0, 0.0, 116.0, 0.0, 7.0, 0.0, 21.0, 34.0, 21.0, 0.0, 0.0, 14.0, 0.0, 12.0, 31.0, 7.0, 0.0, 39.0, 0.0, 0.0, 0.0, 32.0, 68.0, 0.0, 18.0, 21.0, 16.0, 61.0, 0.0, 0.0, 0.0, 69.0, 0.0, 32.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 17.0, 38.0, 6.0, 10.0, 0.0, 34.0, 9.0, 39.0, 43.0, 0.0, 0.0, 0.0, 7.0, 18.0, 17.0, 4.0, 16.0, 20.0, 22.0, 26.0, 3.0, 0.0, 0.0, 69.0, 49.0, 74.0, 0.0, 48.0, 23.0, 64.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5650464212662604, "mean_inference_ms": 1.4293978241279428, "mean_action_processing_ms": 0.2613650038301001, "mean_env_wait_ms": 0.19534284293612308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005951523780822754, "StateBufferConnector_ms": 0.003329157829284668, "ViewRequirementAgentConnector_ms": 0.10686349868774414}, "num_episodes": 18, "episode_return_max": 201.09999999999926, "episode_return_min": -205.2000000000009, "episode_return_mean": 49.7379999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 460.0268998616839, "num_env_steps_trained_throughput_per_sec": 460.0268998616839, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 9243.689, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9243.645, "sample_time_ms": 1208.162, "learn_time_ms": 8022.458, "learn_throughput": 498.6, "synch_weights_time_ms": 11.842}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "04dec_00002", "date": "2024-08-13_16-27-13", "timestamp": 1723580833, "time_this_iter_s": 8.701704978942871, "time_total_s": 268.61010932922363, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359c9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 268.61010932922363, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 28.483333333333334, "ram_util_percent": 81.49166666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7907565841993327, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 3.0701328349491908, "policy_loss": -0.005653313488980371, "vf_loss": 3.074816469351451, "vf_explained_var": 0.016785980027819437, "kl": 0.007661736013886403, "entropy": 1.46967853768162, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4188517279647015, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 0.00010000000000000003, "total_loss": 5.245381731204886, "policy_loss": -0.002638517331736034, "vf_loss": 5.247503652522173, "vf_explained_var": 0.0425583594059818, "kl": 0.013775944856951277, "entropy": 1.0922561103074009, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 201.09999999999926, "episode_reward_min": -205.2000000000009, "episode_reward_mean": 52.585999999999764, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -246.7000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 142.39999999999995, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": 8.962999999999948, "predator_policy": 17.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.200000000000003, -10.19999999999966, 49.90000000000046, 37.40000000000027, -7.29999999999977, -5.599999999999783, -33.8999999999998, 88.69999999999868, 36.50000000000026, 21.900000000000038, 38.20000000000031, 94.89999999999915, 80.49999999999919, 83.89999999999905, 68.59999999999991, 19.40000000000013, 54.400000000000524, 104.79999999999876, 39.800000000000296, 63.6000000000004, -21.099999999999554, 201.09999999999926, -15.199999999999571, 43.000000000000306, 142.69999999999882, 83.59999999999928, 42.30000000000027, 90.09999999999933, 112.89999999999861, 82.39999999999999, 52.70000000000044, 14.499999999999995, 55.30000000000051, 126.39999999999876, 52.400000000000446, 9.900000000000057, 91.29999999999859, 89.49999999999862, 58.00000000000035, 35.10000000000023, 121.99999999999908, 69.69999999999997, 54.9000000000003, -2.7999999999998937, 113.79999999999944, 40.0000000000003, -6.099999999999689, -205.2000000000009, 160.09999999999917, 29.500000000000153, 129.799999999999, 57.10000000000051, 24.600000000000065, 62.000000000000355, 159.1999999999986, -2.8999999999998085, 189.399999999999, 22.400000000000233, 76.89999999999947, 23.600000000000033, 35.900000000000254, 106.59999999999891, -8.899999999999912, 7.500000000000098, 84.19999999999902, 91.19999999999902, 71.69999999999987, 116.69999999999933, 65.00000000000026, 37.40000000000046, 120.19999999999875, 40.0000000000003, 21.800000000000015, 54.000000000000256, 31.800000000000185, -6.199999999999703, 42.30000000000044, 48.100000000000435, -187.6000000000006, -0.899999999999942, 34.80000000000027, -53.600000000000534, -139.30000000000052, 112.99999999999963, 67.00000000000028, 125.49999999999912, 113.79999999999897, 97.6999999999997, -100.10000000000043, 40.0000000000003, -78.20000000000005, 159.59999999999928, 124.49999999999852, 135.19999999999973, 78.69999999999906, 128.69999999999865, 105.29999999999939, 186.799999999999, 22.900000000000137, 9.900000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.39999999999998, -35.199999999999775, -19.89999999999977, -28.299999999999777, 29.90000000000018, 20.000000000000014, 4.399999999999995, 20.000000000000014, 20.000000000000014, -70.30000000000072, -0.10000000000000281, -53.50000000000011, -36.09999999999988, -56.799999999999926, 22.40000000000005, 59.30000000000019, -0.9999999999999846, 15.499999999999956, -64.00000000000088, -0.09999999999997983, 20.000000000000014, -44.79999999999987, 20.000000000000014, 65.89999999999999, 60.50000000000017, 20.000000000000014, 32.90000000000013, 20.000000000000014, 20.000000000000014, 38.60000000000009, -76.60000000000002, 20.000000000000014, 34.40000000000026, 20.000000000000014, 84.7999999999994, 20.000000000000014, 20.000000000000014, 18.799999999999997, 26.60000000000014, 20.000000000000014, -13.5999999999998, -53.50000000000008, 58.700000000000216, 142.39999999999995, -38.79999999999977, -9.399999999999897, 20.000000000000014, 11.000000000000027, 127.09999999999954, 11.599999999999966, -32.49999999999975, 91.09999999999957, -21.699999999999854, 1.9999999999999998, -27.699999999999754, 93.7999999999996, 28.100000000000147, 84.7999999999993, 31.40000000000002, 20.000000000000014, 28.700000000000163, 20.000000000000014, 20.90000000000003, -30.39999999999975, 20.000000000000014, 35.30000000000025, 106.39999999999947, 20.000000000000014, 27.200000000000134, 18.19999999999999, -87.70000000000059, 26.600000000000072, 20.000000000000014, 71.29999999999968, 20.000000000000014, 69.4999999999998, 15.799999999999963, 24.20000000000013, -11.49999999999984, 23.600000000000076, 31.100000000000115, 47.90000000000024, 49.70000000000019, 20.000000000000014, 73.99999999999949, -87.10000000000085, -108.10000000000052, 44.30000000000015, -30.999999999999957, 75.79999999999977, 20.000000000000014, 20.000000000000014, 17.899999999999988, -64.00000000000091, -150.10000000000053, -171.10000000000036, 119.59999999999978, 33.50000000000024, 5.899999999999967, 2.59999999999997, -14.499999999999936, 89.29999999999941, 20.000000000000014, 37.10000000000026, -9.399999999999876, 20.000000000000014, 39.80000000000013, -20.799999999999798, 54.20000000000023, 97.9999999999995, -61.90000000000065, 20.000000000000014, 57.800000000000225, 131.5999999999998, -79.6000000000003, 1.9999999999999767, 38.90000000000016, 20.000000000000014, -0.9999999999999704, -12.399999999999908, -108.10000000000078, 82.99999999999926, 20.000000000000014, 86.5999999999995, 20.000000000000014, -97.9000000000002, -7.299999999999891, -17.19999999999977, 47.00000000000024, 24.20000000000009, 66.19999999999999, 20.000000000000014, 17.899999999999984, 36.800000000000196, 22.9999999999999, 49.70000000000021, 20.000000000000014, 35.000000000000156, -35.49999999999987, 29.90000000000018, -74.50000000000075, 112.69999999999946, 20.000000000000014, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, -0.9999999999999295, -8.199999999999887, 20.000000000000014, -7.299999999999891, -40.89999999999978, -6.699999999999999, 20.000000000000014, 20.000000000000014, 28.10000000000015, -151.30000000000032, -154.30000000000024, -131.2000000000007, 56.30000000000019, 47.900000000000155, -84.10000000000083, -40.89999999999977, -96.70000000000061, -246.7000000000004, -61.59999999999997, 111.7999999999999, -110.80000000000057, 20.000000000000014, 47.00000000000024, 67.69999999999983, 57.80000000000013, 20.000000000000014, 93.79999999999956, -64.90000000000012, 35.600000000000165, -219.4000000000004, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -40.900000000000034, -91.29999999999993, 14.29999999999999, 116.29999999999976, 75.79999999999936, 34.70000000000017, 3.4999999999999973, 91.69999999999997, 22.700000000000102, 20.000000000000014, 41.90000000000002, 57.800000000000225, -34.29999999999994, 62.599999999999774, 27.800000000000153, 136.9999999999996, -40.29999999999979, 15.200000000000028, -0.39999999999999936, -36.699999999999854], "policy_predator_policy_reward": [28.0, 19.0, 16.0, 22.0, 0.0, 0.0, 0.0, 13.0, 0.0, 43.0, 0.0, 48.0, 59.0, 0.0, 7.0, 0.0, 12.0, 10.0, 57.0, 29.0, 35.0, 28.0, 0.0, 9.0, 0.0, 0.0, 17.0, 14.0, 0.0, 10.0, 41.0, 35.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 33.0, 12.0, 0.0, 4.0, 0.0, 8.0, 17.0, 20.0, 42.0, 24.0, 0.0, 0.0, 0.0, 24.0, 7.0, 0.0, 4.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 34.0, 37.0, 0.0, 0.0, 0.0, 0.0, 2.0, 16.0, 13.0, 10.0, 12.0, 31.0, 0.0, 0.0, 36.0, 32.0, 61.0, 0.0, 29.0, 40.0, 0.0, 0.0, 0.0, 40.0, 0.0, 116.0, 0.0, 7.0, 0.0, 21.0, 34.0, 21.0, 0.0, 0.0, 14.0, 0.0, 12.0, 31.0, 7.0, 0.0, 39.0, 0.0, 0.0, 0.0, 32.0, 68.0, 0.0, 18.0, 21.0, 16.0, 61.0, 0.0, 0.0, 0.0, 69.0, 0.0, 32.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 17.0, 38.0, 6.0, 10.0, 0.0, 34.0, 9.0, 39.0, 43.0, 0.0, 0.0, 0.0, 7.0, 18.0, 17.0, 4.0, 16.0, 20.0, 22.0, 26.0, 3.0, 0.0, 0.0, 69.0, 49.0, 74.0, 0.0, 48.0, 23.0, 64.0, 20.0, 169.0, 0.0, 61.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 51.0, 0.0, 114.0, 0.0, 0.0, 1.0, 53.0, 11.0, 18.0, 0.0, 14.0, 0.0, 40.0, 19.0, 17.0, 0.0, 29.0, 76.0, 1.0, 5.0, 17.0, 22.0, 26.0, 47.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5637161154108087, "mean_inference_ms": 1.4262767869269086, "mean_action_processing_ms": 0.2604154975831277, "mean_env_wait_ms": 0.19478447034171836, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00509035587310791, "StateBufferConnector_ms": 0.003157377243041992, "ViewRequirementAgentConnector_ms": 0.09811735153198242}, "num_episodes": 18, "episode_return_max": 201.09999999999926, "episode_return_min": -205.2000000000009, "episode_return_mean": 52.585999999999764, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 451.15145669597405, "num_env_steps_trained_throughput_per_sec": 451.15145669597405, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 9157.197, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9157.15, "sample_time_ms": 1188.69, "learn_time_ms": 7955.575, "learn_throughput": 502.792, "synch_weights_time_ms": 11.734}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "04dec_00002", "date": "2024-08-13_16-27-22", "timestamp": 1723580842, "time_this_iter_s": 8.870903968811035, "time_total_s": 277.48101329803467, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b35754c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 277.48101329803467, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 29.107692307692307, "ram_util_percent": 81.6076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7516580535700081, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 3.0536037065364696, "policy_loss": -0.004645757778256974, "vf_loss": 3.0573178300781856, "vf_explained_var": 0.03444669240366214, "kl": 0.007361053396429, "entropy": 1.4880079459891749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6533975499647635, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 0.00010000000000000003, "total_loss": 4.998029682875941, "policy_loss": -0.006998849414269287, "vf_loss": 5.004372235833022, "vf_explained_var": 0.0002912556998944156, "kl": 0.017500828390521864, "entropy": 1.1071585967427209, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 253.49999999999966, "episode_reward_min": -205.2000000000009, "episode_reward_mean": 49.55199999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -279.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.1, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": 5.23099999999993, "predator_policy": 19.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.800000000000296, 63.6000000000004, -21.099999999999554, 201.09999999999926, -15.199999999999571, 43.000000000000306, 142.69999999999882, 83.59999999999928, 42.30000000000027, 90.09999999999933, 112.89999999999861, 82.39999999999999, 52.70000000000044, 14.499999999999995, 55.30000000000051, 126.39999999999876, 52.400000000000446, 9.900000000000057, 91.29999999999859, 89.49999999999862, 58.00000000000035, 35.10000000000023, 121.99999999999908, 69.69999999999997, 54.9000000000003, -2.7999999999998937, 113.79999999999944, 40.0000000000003, -6.099999999999689, -205.2000000000009, 160.09999999999917, 29.500000000000153, 129.799999999999, 57.10000000000051, 24.600000000000065, 62.000000000000355, 159.1999999999986, -2.8999999999998085, 189.399999999999, 22.400000000000233, 76.89999999999947, 23.600000000000033, 35.900000000000254, 106.59999999999891, -8.899999999999912, 7.500000000000098, 84.19999999999902, 91.19999999999902, 71.69999999999987, 116.69999999999933, 65.00000000000026, 37.40000000000046, 120.19999999999875, 40.0000000000003, 21.800000000000015, 54.000000000000256, 31.800000000000185, -6.199999999999703, 42.30000000000044, 48.100000000000435, -187.6000000000006, -0.899999999999942, 34.80000000000027, -53.600000000000534, -139.30000000000052, 112.99999999999963, 67.00000000000028, 125.49999999999912, 113.79999999999897, 97.6999999999997, -100.10000000000043, 40.0000000000003, -78.20000000000005, 159.59999999999928, 124.49999999999852, 135.19999999999973, 78.69999999999906, 128.69999999999865, 105.29999999999939, 186.799999999999, 22.900000000000137, 9.900000000000025, 253.49999999999966, -35.69999999999968, 40.0000000000003, 114.6999999999986, 36.099999999999966, 119.29999999999913, 40.0000000000003, -100.79999999999995, -103.90000000000015, 51.40000000000043, 12.299999999999951, 40.0000000000003, -62.99999999999975, 35.600000000000236, -16.09999999999996, 57.80000000000044, 3.100000000000152, -40.399999999999764], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 18.799999999999997, 26.60000000000014, 20.000000000000014, -13.5999999999998, -53.50000000000008, 58.700000000000216, 142.39999999999995, -38.79999999999977, -9.399999999999897, 20.000000000000014, 11.000000000000027, 127.09999999999954, 11.599999999999966, -32.49999999999975, 91.09999999999957, -21.699999999999854, 1.9999999999999998, -27.699999999999754, 93.7999999999996, 28.100000000000147, 84.7999999999993, 31.40000000000002, 20.000000000000014, 28.700000000000163, 20.000000000000014, 20.90000000000003, -30.39999999999975, 20.000000000000014, 35.30000000000025, 106.39999999999947, 20.000000000000014, 27.200000000000134, 18.19999999999999, -87.70000000000059, 26.600000000000072, 20.000000000000014, 71.29999999999968, 20.000000000000014, 69.4999999999998, 15.799999999999963, 24.20000000000013, -11.49999999999984, 23.600000000000076, 31.100000000000115, 47.90000000000024, 49.70000000000019, 20.000000000000014, 73.99999999999949, -87.10000000000085, -108.10000000000052, 44.30000000000015, -30.999999999999957, 75.79999999999977, 20.000000000000014, 20.000000000000014, 17.899999999999988, -64.00000000000091, -150.10000000000053, -171.10000000000036, 119.59999999999978, 33.50000000000024, 5.899999999999967, 2.59999999999997, -14.499999999999936, 89.29999999999941, 20.000000000000014, 37.10000000000026, -9.399999999999876, 20.000000000000014, 39.80000000000013, -20.799999999999798, 54.20000000000023, 97.9999999999995, -61.90000000000065, 20.000000000000014, 57.800000000000225, 131.5999999999998, -79.6000000000003, 1.9999999999999767, 38.90000000000016, 20.000000000000014, -0.9999999999999704, -12.399999999999908, -108.10000000000078, 82.99999999999926, 20.000000000000014, 86.5999999999995, 20.000000000000014, -97.9000000000002, -7.299999999999891, -17.19999999999977, 47.00000000000024, 24.20000000000009, 66.19999999999999, 20.000000000000014, 17.899999999999984, 36.800000000000196, 22.9999999999999, 49.70000000000021, 20.000000000000014, 35.000000000000156, -35.49999999999987, 29.90000000000018, -74.50000000000075, 112.69999999999946, 20.000000000000014, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, -0.9999999999999295, -8.199999999999887, 20.000000000000014, -7.299999999999891, -40.89999999999978, -6.699999999999999, 20.000000000000014, 20.000000000000014, 28.10000000000015, -151.30000000000032, -154.30000000000024, -131.2000000000007, 56.30000000000019, 47.900000000000155, -84.10000000000083, -40.89999999999977, -96.70000000000061, -246.7000000000004, -61.59999999999997, 111.7999999999999, -110.80000000000057, 20.000000000000014, 47.00000000000024, 67.69999999999983, 57.80000000000013, 20.000000000000014, 93.79999999999956, -64.90000000000012, 35.600000000000165, -219.4000000000004, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -40.900000000000034, -91.29999999999993, 14.29999999999999, 116.29999999999976, 75.79999999999936, 34.70000000000017, 3.4999999999999973, 91.69999999999997, 22.700000000000102, 20.000000000000014, 41.90000000000002, 57.800000000000225, -34.29999999999994, 62.599999999999774, 27.800000000000153, 136.9999999999996, -40.29999999999979, 15.200000000000028, -0.39999999999999936, -36.699999999999854, 82.39999999999964, 154.1, -141.69999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 68.59999999999982, 46.100000000000186, 38.299999999999834, -89.20000000000041, 64.70000000000006, 41.60000000000025, 20.000000000000014, 20.000000000000014, -82.6, -131.2000000000004, 27.800000000000118, -279.7000000000003, 16.399999999999967, 20.000000000000014, 78.49999999999937, -146.20000000000067, 20.000000000000014, 20.000000000000014, -232.00000000000045, 20.000000000000014, 20.000000000000014, 11.599999999999973, -20.2, -103.9000000000003, 20.000000000000014, 27.800000000000153, -61.90000000000071, 20.000000000000014, -36.09999999999989, -124.30000000000024], "policy_predator_policy_reward": [1.0, 0.0, 17.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 33.0, 12.0, 0.0, 4.0, 0.0, 8.0, 17.0, 20.0, 42.0, 24.0, 0.0, 0.0, 0.0, 24.0, 7.0, 0.0, 4.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 34.0, 37.0, 0.0, 0.0, 0.0, 0.0, 2.0, 16.0, 13.0, 10.0, 12.0, 31.0, 0.0, 0.0, 36.0, 32.0, 61.0, 0.0, 29.0, 40.0, 0.0, 0.0, 0.0, 40.0, 0.0, 116.0, 0.0, 7.0, 0.0, 21.0, 34.0, 21.0, 0.0, 0.0, 14.0, 0.0, 12.0, 31.0, 7.0, 0.0, 39.0, 0.0, 0.0, 0.0, 32.0, 68.0, 0.0, 18.0, 21.0, 16.0, 61.0, 0.0, 0.0, 0.0, 69.0, 0.0, 32.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 17.0, 38.0, 6.0, 10.0, 0.0, 34.0, 9.0, 39.0, 43.0, 0.0, 0.0, 0.0, 7.0, 18.0, 17.0, 4.0, 16.0, 20.0, 22.0, 26.0, 3.0, 0.0, 0.0, 69.0, 49.0, 74.0, 0.0, 48.0, 23.0, 64.0, 20.0, 169.0, 0.0, 61.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 51.0, 0.0, 114.0, 0.0, 0.0, 1.0, 53.0, 11.0, 18.0, 0.0, 14.0, 0.0, 40.0, 19.0, 17.0, 0.0, 29.0, 76.0, 1.0, 5.0, 17.0, 22.0, 26.0, 47.0, 0.0, 17.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.0, 13.0, 0.0, 0.0, 0.0, 113.0, 0.0, 0.0, 148.0, 11.0, 4.0, 80.0, 0.0, 0.0, 0.0, 46.0, 103.0, 0.0, 4.0, 108.0, 0.0, 10.0, 0.0, 27.0, 18.0, 0.0, 120.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5621395846002719, "mean_inference_ms": 1.421978495346284, "mean_action_processing_ms": 0.25891666197229407, "mean_env_wait_ms": 0.19407977417966138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004341721534729004, "StateBufferConnector_ms": 0.0030205249786376953, "ViewRequirementAgentConnector_ms": 0.09308362007141113}, "num_episodes": 18, "episode_return_max": 253.49999999999966, "episode_return_min": -205.2000000000009, "episode_return_mean": 49.55199999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 443.1574837590037, "num_env_steps_trained_throughput_per_sec": 443.1574837590037, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 9087.37, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9087.324, "sample_time_ms": 1182.98, "learn_time_ms": 7891.627, "learn_throughput": 506.866, "synch_weights_time_ms": 11.564}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "04dec_00002", "date": "2024-08-13_16-27-31", "timestamp": 1723580851, "time_this_iter_s": 9.085654020309448, "time_total_s": 286.5666673183441, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359d8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 286.5666673183441, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 30.153846153846157, "ram_util_percent": 82.12307692307694}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7774946842717115, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 3.107733685503561, "policy_loss": -0.007567745284793317, "vf_loss": 3.1141874681074153, "vf_explained_var": -0.002290457045590436, "kl": 0.00880176624198701, "entropy": 1.4994662159334415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.751967705589123, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 0.00010000000000000003, "total_loss": 6.028917704688178, "policy_loss": -0.011092823857402123, "vf_loss": 6.039100311420582, "vf_explained_var": 0.05587410185702894, "kl": 0.02427228157032689, "entropy": 1.0826234437801219, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 270.60000000000025, "episode_reward_min": -271.80000000000007, "episode_reward_mean": 42.759999999999806, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -279.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -4.135000000000071, "predator_policy": 25.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -6.099999999999689, -205.2000000000009, 160.09999999999917, 29.500000000000153, 129.799999999999, 57.10000000000051, 24.600000000000065, 62.000000000000355, 159.1999999999986, -2.8999999999998085, 189.399999999999, 22.400000000000233, 76.89999999999947, 23.600000000000033, 35.900000000000254, 106.59999999999891, -8.899999999999912, 7.500000000000098, 84.19999999999902, 91.19999999999902, 71.69999999999987, 116.69999999999933, 65.00000000000026, 37.40000000000046, 120.19999999999875, 40.0000000000003, 21.800000000000015, 54.000000000000256, 31.800000000000185, -6.199999999999703, 42.30000000000044, 48.100000000000435, -187.6000000000006, -0.899999999999942, 34.80000000000027, -53.600000000000534, -139.30000000000052, 112.99999999999963, 67.00000000000028, 125.49999999999912, 113.79999999999897, 97.6999999999997, -100.10000000000043, 40.0000000000003, -78.20000000000005, 159.59999999999928, 124.49999999999852, 135.19999999999973, 78.69999999999906, 128.69999999999865, 105.29999999999939, 186.799999999999, 22.900000000000137, 9.900000000000025, 253.49999999999966, -35.69999999999968, 40.0000000000003, 114.6999999999986, 36.099999999999966, 119.29999999999913, 40.0000000000003, -100.79999999999995, -103.90000000000015, 51.40000000000043, 12.299999999999951, 40.0000000000003, -62.99999999999975, 35.600000000000236, -16.09999999999996, 57.80000000000044, 3.100000000000152, -40.399999999999764, 27.799999999999947, 29.70000000000018, 40.0000000000003, -32.19999999999989, 110.60000000000008, -24.999999999999844, 169.99999999999903, 195.6999999999995, 257.7999999999996, -10.599999999999932, 171.99999999999977, -5.799999999999837, -1.8000000000000353, -31.500000000000128, 4.4000000000001585, -79.80000000000038, 270.60000000000025, -134.09999999999997, -122.60000000000096, 101.99999999999925, 219.09999999999926, -5.900000000000112, 40.9000000000003, 130.19999999999987, -271.80000000000007, -9.299999999999887, 88.29999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 17.899999999999988, -64.00000000000091, -150.10000000000053, -171.10000000000036, 119.59999999999978, 33.50000000000024, 5.899999999999967, 2.59999999999997, -14.499999999999936, 89.29999999999941, 20.000000000000014, 37.10000000000026, -9.399999999999876, 20.000000000000014, 39.80000000000013, -20.799999999999798, 54.20000000000023, 97.9999999999995, -61.90000000000065, 20.000000000000014, 57.800000000000225, 131.5999999999998, -79.6000000000003, 1.9999999999999767, 38.90000000000016, 20.000000000000014, -0.9999999999999704, -12.399999999999908, -108.10000000000078, 82.99999999999926, 20.000000000000014, 86.5999999999995, 20.000000000000014, -97.9000000000002, -7.299999999999891, -17.19999999999977, 47.00000000000024, 24.20000000000009, 66.19999999999999, 20.000000000000014, 17.899999999999984, 36.800000000000196, 22.9999999999999, 49.70000000000021, 20.000000000000014, 35.000000000000156, -35.49999999999987, 29.90000000000018, -74.50000000000075, 112.69999999999946, 20.000000000000014, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, -0.9999999999999295, -8.199999999999887, 20.000000000000014, -7.299999999999891, -40.89999999999978, -6.699999999999999, 20.000000000000014, 20.000000000000014, 28.10000000000015, -151.30000000000032, -154.30000000000024, -131.2000000000007, 56.30000000000019, 47.900000000000155, -84.10000000000083, -40.89999999999977, -96.70000000000061, -246.7000000000004, -61.59999999999997, 111.7999999999999, -110.80000000000057, 20.000000000000014, 47.00000000000024, 67.69999999999983, 57.80000000000013, 20.000000000000014, 93.79999999999956, -64.90000000000012, 35.600000000000165, -219.4000000000004, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -40.900000000000034, -91.29999999999993, 14.29999999999999, 116.29999999999976, 75.79999999999936, 34.70000000000017, 3.4999999999999973, 91.69999999999997, 22.700000000000102, 20.000000000000014, 41.90000000000002, 57.800000000000225, -34.29999999999994, 62.599999999999774, 27.800000000000153, 136.9999999999996, -40.29999999999979, 15.200000000000028, -0.39999999999999936, -36.699999999999854, 82.39999999999964, 154.1, -141.69999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 68.59999999999982, 46.100000000000186, 38.299999999999834, -89.20000000000041, 64.70000000000006, 41.60000000000025, 20.000000000000014, 20.000000000000014, -82.6, -131.2000000000004, 27.800000000000118, -279.7000000000003, 16.399999999999967, 20.000000000000014, 78.49999999999937, -146.20000000000067, 20.000000000000014, 20.000000000000014, -232.00000000000045, 20.000000000000014, 20.000000000000014, 11.599999999999973, -20.2, -103.9000000000003, 20.000000000000014, 27.800000000000153, -61.90000000000071, 20.000000000000014, -36.09999999999989, -124.30000000000024, -21.999999999999932, 24.79999999999997, 55.400000000000055, -123.70000000000047, 20.000000000000014, 20.000000000000014, -7.299999999999969, -142.90000000000006, 37.10000000000026, 54.49999999999999, 48.80000000000024, -239.79999999999967, 54.800000000000125, 84.19999999999959, 66.19999999999996, 96.49999999999997, 172.99999999999983, 84.79999999999927, -24.999999999999986, -64.60000000000048, -24.999999999999936, 155.0, -34.89999999999996, -43.900000000000254, -11.49999999999984, -28.30000000000002, 26.900000000000013, -135.40000000000035, 20.000000000000014, -49.59999999999984, -91.30000000000018, -188.50000000000028, 86.89999999999998, 148.69999999999996, -64.00000000000003, -165.1000000000001, -13.600000000000035, -232.00000000000045, 33.50000000000024, 42.50000000000007, 199.1, 20.000000000000014, -140.80000000000013, 14.900000000000112, 20.000000000000014, 20.90000000000003, -58.0, 126.19999999999989, -206.8, -202.00000000000009, 22.700000000000063, -196.00000000000023, -33.09999999999976, 79.39999999999998], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 40.0, 0.0, 116.0, 0.0, 7.0, 0.0, 21.0, 34.0, 21.0, 0.0, 0.0, 14.0, 0.0, 12.0, 31.0, 7.0, 0.0, 39.0, 0.0, 0.0, 0.0, 32.0, 68.0, 0.0, 18.0, 21.0, 16.0, 61.0, 0.0, 0.0, 0.0, 69.0, 0.0, 32.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 17.0, 38.0, 6.0, 10.0, 0.0, 34.0, 9.0, 39.0, 43.0, 0.0, 0.0, 0.0, 7.0, 18.0, 17.0, 4.0, 16.0, 20.0, 22.0, 26.0, 3.0, 0.0, 0.0, 69.0, 49.0, 74.0, 0.0, 48.0, 23.0, 64.0, 20.0, 169.0, 0.0, 61.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 51.0, 0.0, 114.0, 0.0, 0.0, 1.0, 53.0, 11.0, 18.0, 0.0, 14.0, 0.0, 40.0, 19.0, 17.0, 0.0, 29.0, 76.0, 1.0, 5.0, 17.0, 22.0, 26.0, 47.0, 0.0, 17.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.0, 13.0, 0.0, 0.0, 0.0, 113.0, 0.0, 0.0, 148.0, 11.0, 4.0, 80.0, 0.0, 0.0, 0.0, 46.0, 103.0, 0.0, 4.0, 108.0, 0.0, 10.0, 0.0, 27.0, 18.0, 0.0, 120.0, 20.0, 5.0, 98.0, 0.0, 0.0, 0.0, 28.0, 90.0, 4.0, 15.0, 134.0, 32.0, 8.0, 23.0, 33.0, 0.0, 0.0, 0.0, 0.0, 79.0, 0.0, 42.0, 0.0, 73.0, 38.0, 0.0, 77.0, 0.0, 0.0, 34.0, 107.0, 93.0, 35.0, 0.0, 9.0, 86.0, 0.0, 123.0, 17.0, 9.0, 0.0, 0.0, 6.0, 114.0, 0.0, 0.0, 0.0, 62.0, 17.0, 120.0, 73.0, 91.0, 17.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5605922790267595, "mean_inference_ms": 1.4187796460932245, "mean_action_processing_ms": 0.2576475346596889, "mean_env_wait_ms": 0.19339904473242966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004652261734008789, "StateBufferConnector_ms": 0.003015875816345215, "ViewRequirementAgentConnector_ms": 0.08849048614501953}, "num_episodes": 27, "episode_return_max": 270.60000000000025, "episode_return_min": -271.80000000000007, "episode_return_mean": 42.759999999999806, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 424.82503002312285, "num_env_steps_trained_throughput_per_sec": 424.82503002312285, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 9052.045, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9052.0, "sample_time_ms": 1165.983, "learn_time_ms": 7872.397, "learn_throughput": 508.104, "synch_weights_time_ms": 12.153}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "04dec_00002", "date": "2024-08-13_16-27-41", "timestamp": 1723580861, "time_this_iter_s": 9.47716498374939, "time_total_s": 296.0438323020935, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a74c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 296.0438323020935, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 34.00714285714286, "ram_util_percent": 82.56428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6826912349967099, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 3.207955052486803, "policy_loss": -0.0057417207441869235, "vf_loss": 3.212737673931021, "vf_explained_var": 0.014812618935549702, "kl": 0.007578084517930186, "entropy": 1.4769937616807443, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8134497410642407, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 0.00010000000000000003, "total_loss": 4.736644819300011, "policy_loss": -0.00521028261501145, "vf_loss": 4.741036912246987, "vf_explained_var": 0.012539176808463202, "kl": 0.014545518276801965, "entropy": 1.1063542666258634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 270.60000000000025, "episode_reward_min": -271.80000000000007, "episode_reward_mean": 35.23899999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -279.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -10.835500000000058, "predator_policy": 28.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.500000000000098, 84.19999999999902, 91.19999999999902, 71.69999999999987, 116.69999999999933, 65.00000000000026, 37.40000000000046, 120.19999999999875, 40.0000000000003, 21.800000000000015, 54.000000000000256, 31.800000000000185, -6.199999999999703, 42.30000000000044, 48.100000000000435, -187.6000000000006, -0.899999999999942, 34.80000000000027, -53.600000000000534, -139.30000000000052, 112.99999999999963, 67.00000000000028, 125.49999999999912, 113.79999999999897, 97.6999999999997, -100.10000000000043, 40.0000000000003, -78.20000000000005, 159.59999999999928, 124.49999999999852, 135.19999999999973, 78.69999999999906, 128.69999999999865, 105.29999999999939, 186.799999999999, 22.900000000000137, 9.900000000000025, 253.49999999999966, -35.69999999999968, 40.0000000000003, 114.6999999999986, 36.099999999999966, 119.29999999999913, 40.0000000000003, -100.79999999999995, -103.90000000000015, 51.40000000000043, 12.299999999999951, 40.0000000000003, -62.99999999999975, 35.600000000000236, -16.09999999999996, 57.80000000000044, 3.100000000000152, -40.399999999999764, 27.799999999999947, 29.70000000000018, 40.0000000000003, -32.19999999999989, 110.60000000000008, -24.999999999999844, 169.99999999999903, 195.6999999999995, 257.7999999999996, -10.599999999999932, 171.99999999999977, -5.799999999999837, -1.8000000000000353, -31.500000000000128, 4.4000000000001585, -79.80000000000038, 270.60000000000025, -134.09999999999997, -122.60000000000096, 101.99999999999925, 219.09999999999926, -5.900000000000112, 40.9000000000003, 130.19999999999987, -271.80000000000007, -9.299999999999887, 88.29999999999993, 133.49999999999974, 43.60000000000036, 101.19999999999851, 40.0000000000003, 151.59999999999943, 57.000000000000256, -87.60000000000106, 32.60000000000032, -80.09999999999982, -211.60000000000076, 126.29999999999986, 40.0000000000003, 40.90000000000031, 40.90000000000031, -41.29999999999994, -195.00000000000045, 56.2000000000005, -106.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-7.299999999999891, -17.19999999999977, 47.00000000000024, 24.20000000000009, 66.19999999999999, 20.000000000000014, 17.899999999999984, 36.800000000000196, 22.9999999999999, 49.70000000000021, 20.000000000000014, 35.000000000000156, -35.49999999999987, 29.90000000000018, -74.50000000000075, 112.69999999999946, 20.000000000000014, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, -0.9999999999999295, -8.199999999999887, 20.000000000000014, -7.299999999999891, -40.89999999999978, -6.699999999999999, 20.000000000000014, 20.000000000000014, 28.10000000000015, -151.30000000000032, -154.30000000000024, -131.2000000000007, 56.30000000000019, 47.900000000000155, -84.10000000000083, -40.89999999999977, -96.70000000000061, -246.7000000000004, -61.59999999999997, 111.7999999999999, -110.80000000000057, 20.000000000000014, 47.00000000000024, 67.69999999999983, 57.80000000000013, 20.000000000000014, 93.79999999999956, -64.90000000000012, 35.600000000000165, -219.4000000000004, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -40.900000000000034, -91.29999999999993, 14.29999999999999, 116.29999999999976, 75.79999999999936, 34.70000000000017, 3.4999999999999973, 91.69999999999997, 22.700000000000102, 20.000000000000014, 41.90000000000002, 57.800000000000225, -34.29999999999994, 62.599999999999774, 27.800000000000153, 136.9999999999996, -40.29999999999979, 15.200000000000028, -0.39999999999999936, -36.699999999999854, 82.39999999999964, 154.1, -141.69999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 68.59999999999982, 46.100000000000186, 38.299999999999834, -89.20000000000041, 64.70000000000006, 41.60000000000025, 20.000000000000014, 20.000000000000014, -82.6, -131.2000000000004, 27.800000000000118, -279.7000000000003, 16.399999999999967, 20.000000000000014, 78.49999999999937, -146.20000000000067, 20.000000000000014, 20.000000000000014, -232.00000000000045, 20.000000000000014, 20.000000000000014, 11.599999999999973, -20.2, -103.9000000000003, 20.000000000000014, 27.800000000000153, -61.90000000000071, 20.000000000000014, -36.09999999999989, -124.30000000000024, -21.999999999999932, 24.79999999999997, 55.400000000000055, -123.70000000000047, 20.000000000000014, 20.000000000000014, -7.299999999999969, -142.90000000000006, 37.10000000000026, 54.49999999999999, 48.80000000000024, -239.79999999999967, 54.800000000000125, 84.19999999999959, 66.19999999999996, 96.49999999999997, 172.99999999999983, 84.79999999999927, -24.999999999999986, -64.60000000000048, -24.999999999999936, 155.0, -34.89999999999996, -43.900000000000254, -11.49999999999984, -28.30000000000002, 26.900000000000013, -135.40000000000035, 20.000000000000014, -49.59999999999984, -91.30000000000018, -188.50000000000028, 86.89999999999998, 148.69999999999996, -64.00000000000003, -165.1000000000001, -13.600000000000035, -232.00000000000045, 33.50000000000024, 42.50000000000007, 199.1, 20.000000000000014, -140.80000000000013, 14.900000000000112, 20.000000000000014, 20.90000000000003, -58.0, 126.19999999999989, -206.8, -202.00000000000009, 22.700000000000063, -196.00000000000023, -33.09999999999976, 79.39999999999998, 121.69999999999979, -95.20000000000002, 14.599999999999978, 20.000000000000014, 20.000000000000014, 81.19999999999939, 20.000000000000014, 20.000000000000014, 20.000000000000014, 131.5999999999999, 9.499999999999947, 42.50000000000012, -223.60000000000045, 20.000000000000014, -87.40000000000002, -1.00000000000004, -189.99999999999994, -30.09999999999979, -141.70000000000056, -253.9000000000002, 28.400000000000134, 92.89999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.90000000000003, -232.60000000000042, 59.300000000000175, -119.20000000000027, -248.8000000000002, 36.200000000000244, 20.000000000000014, -270.09999999999997, -59.2], "policy_predator_policy_reward": [32.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 17.0, 38.0, 6.0, 10.0, 0.0, 34.0, 9.0, 39.0, 43.0, 0.0, 0.0, 0.0, 7.0, 18.0, 17.0, 4.0, 16.0, 20.0, 22.0, 26.0, 3.0, 0.0, 0.0, 69.0, 49.0, 74.0, 0.0, 48.0, 23.0, 64.0, 20.0, 169.0, 0.0, 61.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 51.0, 0.0, 114.0, 0.0, 0.0, 1.0, 53.0, 11.0, 18.0, 0.0, 14.0, 0.0, 40.0, 19.0, 17.0, 0.0, 29.0, 76.0, 1.0, 5.0, 17.0, 22.0, 26.0, 47.0, 0.0, 17.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.0, 13.0, 0.0, 0.0, 0.0, 113.0, 0.0, 0.0, 148.0, 11.0, 4.0, 80.0, 0.0, 0.0, 0.0, 46.0, 103.0, 0.0, 4.0, 108.0, 0.0, 10.0, 0.0, 27.0, 18.0, 0.0, 120.0, 20.0, 5.0, 98.0, 0.0, 0.0, 0.0, 28.0, 90.0, 4.0, 15.0, 134.0, 32.0, 8.0, 23.0, 33.0, 0.0, 0.0, 0.0, 0.0, 79.0, 0.0, 42.0, 0.0, 73.0, 38.0, 0.0, 77.0, 0.0, 0.0, 34.0, 107.0, 93.0, 35.0, 0.0, 9.0, 86.0, 0.0, 123.0, 17.0, 9.0, 0.0, 0.0, 6.0, 114.0, 0.0, 0.0, 0.0, 62.0, 17.0, 120.0, 73.0, 91.0, 17.0, 25.0, 61.0, 46.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 116.0, 53.0, 68.0, 45.0, 95.0, 41.0, 143.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 123.0, 9.0, 173.0, 0.0, 0.0, 0.0, 87.0, 136.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5597076301526774, "mean_inference_ms": 1.417489300537284, "mean_action_processing_ms": 0.25612195631961093, "mean_env_wait_ms": 0.19329931072523734, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004518628120422363, "StateBufferConnector_ms": 0.003009796142578125, "ViewRequirementAgentConnector_ms": 0.09002280235290527}, "num_episodes": 18, "episode_return_max": 270.60000000000025, "episode_return_min": -271.80000000000007, "episode_return_mean": 35.23899999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.94092243201544, "num_env_steps_trained_throughput_per_sec": 378.94092243201544, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 9181.064, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9181.018, "sample_time_ms": 1197.161, "learn_time_ms": 7969.979, "learn_throughput": 501.883, "synch_weights_time_ms": 12.346}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "04dec_00002", "date": "2024-08-13_16-27-51", "timestamp": 1723580871, "time_this_iter_s": 10.630826950073242, "time_total_s": 306.67465925216675, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a7dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 306.67465925216675, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 43.63333333333333, "ram_util_percent": 83.60666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7942807822867676, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 0.00010000000000000003, "total_loss": 4.301018886339097, "policy_loss": -0.0023742875393489918, "vf_loss": 4.302906014805749, "vf_explained_var": 0.003722242104313361, "kl": 0.0038491965576520513, "entropy": 1.4934462611637418, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7305804707780086, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 0.00010000000000000003, "total_loss": 6.810436055016896, "policy_loss": -0.0019374898554160994, "vf_loss": 6.811712502171754, "vf_explained_var": 0.06858345156624204, "kl": 0.011751619457621019, "entropy": 1.0653211312319235, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 291.7, "episode_reward_min": -271.80000000000007, "episode_reward_mean": 45.36499999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -279.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -7.112500000000067, "predator_policy": 29.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-53.600000000000534, -139.30000000000052, 112.99999999999963, 67.00000000000028, 125.49999999999912, 113.79999999999897, 97.6999999999997, -100.10000000000043, 40.0000000000003, -78.20000000000005, 159.59999999999928, 124.49999999999852, 135.19999999999973, 78.69999999999906, 128.69999999999865, 105.29999999999939, 186.799999999999, 22.900000000000137, 9.900000000000025, 253.49999999999966, -35.69999999999968, 40.0000000000003, 114.6999999999986, 36.099999999999966, 119.29999999999913, 40.0000000000003, -100.79999999999995, -103.90000000000015, 51.40000000000043, 12.299999999999951, 40.0000000000003, -62.99999999999975, 35.600000000000236, -16.09999999999996, 57.80000000000044, 3.100000000000152, -40.399999999999764, 27.799999999999947, 29.70000000000018, 40.0000000000003, -32.19999999999989, 110.60000000000008, -24.999999999999844, 169.99999999999903, 195.6999999999995, 257.7999999999996, -10.599999999999932, 171.99999999999977, -5.799999999999837, -1.8000000000000353, -31.500000000000128, 4.4000000000001585, -79.80000000000038, 270.60000000000025, -134.09999999999997, -122.60000000000096, 101.99999999999925, 219.09999999999926, -5.900000000000112, 40.9000000000003, 130.19999999999987, -271.80000000000007, -9.299999999999887, 88.29999999999993, 133.49999999999974, 43.60000000000036, 101.19999999999851, 40.0000000000003, 151.59999999999943, 57.000000000000256, -87.60000000000106, 32.60000000000032, -80.09999999999982, -211.60000000000076, 126.29999999999986, 40.0000000000003, 40.90000000000031, 40.90000000000031, -41.29999999999994, -195.00000000000045, 56.2000000000005, -106.29999999999995, 120.19999999999916, 201.49999999999906, -89.50000000000034, 71.09999999999954, 133.59999999999988, 139.49999999999937, 139.90000000000026, 291.7, 92.39999999999907, -63.19999999999989, -63.400000000001015, 111.99999999999977, -12.399999999999926, 248.3999999999995, 212.7999999999993, -22.899999999999693, 117.39999999999954, 55.49999999999961], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-40.89999999999977, -96.70000000000061, -246.7000000000004, -61.59999999999997, 111.7999999999999, -110.80000000000057, 20.000000000000014, 47.00000000000024, 67.69999999999983, 57.80000000000013, 20.000000000000014, 93.79999999999956, -64.90000000000012, 35.600000000000165, -219.4000000000004, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -40.900000000000034, -91.29999999999993, 14.29999999999999, 116.29999999999976, 75.79999999999936, 34.70000000000017, 3.4999999999999973, 91.69999999999997, 22.700000000000102, 20.000000000000014, 41.90000000000002, 57.800000000000225, -34.29999999999994, 62.599999999999774, 27.800000000000153, 136.9999999999996, -40.29999999999979, 15.200000000000028, -0.39999999999999936, -36.699999999999854, 82.39999999999964, 154.1, -141.69999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 68.59999999999982, 46.100000000000186, 38.299999999999834, -89.20000000000041, 64.70000000000006, 41.60000000000025, 20.000000000000014, 20.000000000000014, -82.6, -131.2000000000004, 27.800000000000118, -279.7000000000003, 16.399999999999967, 20.000000000000014, 78.49999999999937, -146.20000000000067, 20.000000000000014, 20.000000000000014, -232.00000000000045, 20.000000000000014, 20.000000000000014, 11.599999999999973, -20.2, -103.9000000000003, 20.000000000000014, 27.800000000000153, -61.90000000000071, 20.000000000000014, -36.09999999999989, -124.30000000000024, -21.999999999999932, 24.79999999999997, 55.400000000000055, -123.70000000000047, 20.000000000000014, 20.000000000000014, -7.299999999999969, -142.90000000000006, 37.10000000000026, 54.49999999999999, 48.80000000000024, -239.79999999999967, 54.800000000000125, 84.19999999999959, 66.19999999999996, 96.49999999999997, 172.99999999999983, 84.79999999999927, -24.999999999999986, -64.60000000000048, -24.999999999999936, 155.0, -34.89999999999996, -43.900000000000254, -11.49999999999984, -28.30000000000002, 26.900000000000013, -135.40000000000035, 20.000000000000014, -49.59999999999984, -91.30000000000018, -188.50000000000028, 86.89999999999998, 148.69999999999996, -64.00000000000003, -165.1000000000001, -13.600000000000035, -232.00000000000045, 33.50000000000024, 42.50000000000007, 199.1, 20.000000000000014, -140.80000000000013, 14.900000000000112, 20.000000000000014, 20.90000000000003, -58.0, 126.19999999999989, -206.8, -202.00000000000009, 22.700000000000063, -196.00000000000023, -33.09999999999976, 79.39999999999998, 121.69999999999979, -95.20000000000002, 14.599999999999978, 20.000000000000014, 20.000000000000014, 81.19999999999939, 20.000000000000014, 20.000000000000014, 20.000000000000014, 131.5999999999999, 9.499999999999947, 42.50000000000012, -223.60000000000045, 20.000000000000014, -87.40000000000002, -1.00000000000004, -189.99999999999994, -30.09999999999979, -141.70000000000056, -253.9000000000002, 28.400000000000134, 92.89999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.90000000000003, -232.60000000000042, 59.300000000000175, -119.20000000000027, -248.8000000000002, 36.200000000000244, 20.000000000000014, -270.09999999999997, -59.2, 1.699999999999987, 60.49999999999983, 44.89999999999978, 86.59999999999948, -85.59999999999988, -97.90000000000033, -52.90000000000004, 23.0, 41.60000000000003, 92.00000000000006, 32.0, 42.50000000000014, 96.49999999999997, 7.400000000000075, 142.39999999999992, 134.29999999999998, 20.000000000000014, 1.3999999999999972, -19.899999999999743, -157.29999999999995, -177.40000000000055, 20.000000000000014, 91.99999999999994, 20.000000000000014, -66.10000000000082, -28.299999999999947, 56.90000000000003, 159.49999999999974, 20.000000000000014, 192.8, -64.0000000000006, 1.0999999999999759, 20.000000000000014, 97.39999999999986, 20.000000000000014, -2.499999999999851], "policy_predator_policy_reward": [64.0, 20.0, 169.0, 0.0, 61.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 51.0, 0.0, 114.0, 0.0, 0.0, 1.0, 53.0, 11.0, 18.0, 0.0, 14.0, 0.0, 40.0, 19.0, 17.0, 0.0, 29.0, 76.0, 1.0, 5.0, 17.0, 22.0, 26.0, 47.0, 0.0, 17.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.0, 13.0, 0.0, 0.0, 0.0, 113.0, 0.0, 0.0, 148.0, 11.0, 4.0, 80.0, 0.0, 0.0, 0.0, 46.0, 103.0, 0.0, 4.0, 108.0, 0.0, 10.0, 0.0, 27.0, 18.0, 0.0, 120.0, 20.0, 5.0, 98.0, 0.0, 0.0, 0.0, 28.0, 90.0, 4.0, 15.0, 134.0, 32.0, 8.0, 23.0, 33.0, 0.0, 0.0, 0.0, 0.0, 79.0, 0.0, 42.0, 0.0, 73.0, 38.0, 0.0, 77.0, 0.0, 0.0, 34.0, 107.0, 93.0, 35.0, 0.0, 9.0, 86.0, 0.0, 123.0, 17.0, 9.0, 0.0, 0.0, 6.0, 114.0, 0.0, 0.0, 0.0, 62.0, 17.0, 120.0, 73.0, 91.0, 17.0, 25.0, 61.0, 46.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 116.0, 53.0, 68.0, 45.0, 95.0, 41.0, 143.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 123.0, 9.0, 173.0, 0.0, 0.0, 0.0, 87.0, 136.0, 33.0, 25.0, 34.0, 36.0, 0.0, 94.0, 20.0, 81.0, 0.0, 0.0, 3.0, 62.0, 35.0, 1.0, 2.0, 13.0, 26.0, 45.0, 0.0, 114.0, 94.0, 0.0, 0.0, 0.0, 0.0, 82.0, 10.0, 22.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 25.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5596898933925832, "mean_inference_ms": 1.4196703760353067, "mean_action_processing_ms": 0.25546475757202836, "mean_env_wait_ms": 0.1935712209907363, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005069375038146973, "StateBufferConnector_ms": 0.0030982494354248047, "ViewRequirementAgentConnector_ms": 0.09686088562011719}, "num_episodes": 18, "episode_return_max": 291.7, "episode_return_min": -271.80000000000007, "episode_return_mean": 45.36499999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 27.347306660515336, "num_env_steps_trained_throughput_per_sec": 27.347306660515336, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 22905.901, "restore_workers_time_ms": 0.013, "training_step_time_ms": 22905.854, "sample_time_ms": 1213.388, "learn_time_ms": 21674.569, "learn_throughput": 184.548, "synch_weights_time_ms": 16.223}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "04dec_00002", "date": "2024-08-13_16-30-18", "timestamp": 1723581018, "time_this_iter_s": 146.36186981201172, "time_total_s": 453.03652906417847, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 453.03652906417847, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 71.87826086956522, "ram_util_percent": 84.23478260869565}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8232628713997584, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 3.0064915904923093, "policy_loss": -0.0051871882094977, "vf_loss": 3.0107959406716485, "vf_explained_var": 0.007418934314969986, "kl": 0.01395099119955621, "entropy": 1.4590514116186313, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.066717452071016, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 0.00010000000000000003, "total_loss": 5.486563160179784, "policy_loss": -0.006982353969265229, "vf_loss": 5.4926159682097255, "vf_explained_var": 0.0632536234363677, "kl": 0.016525230993760194, "entropy": 1.1175971627235413, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 291.7, "episode_reward_min": -271.80000000000007, "episode_reward_mean": 43.92199999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.9999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 206.0}, "policy_reward_mean": {"prey_policy": -9.074000000000053, "predator_policy": 31.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.900000000000025, 253.49999999999966, -35.69999999999968, 40.0000000000003, 114.6999999999986, 36.099999999999966, 119.29999999999913, 40.0000000000003, -100.79999999999995, -103.90000000000015, 51.40000000000043, 12.299999999999951, 40.0000000000003, -62.99999999999975, 35.600000000000236, -16.09999999999996, 57.80000000000044, 3.100000000000152, -40.399999999999764, 27.799999999999947, 29.70000000000018, 40.0000000000003, -32.19999999999989, 110.60000000000008, -24.999999999999844, 169.99999999999903, 195.6999999999995, 257.7999999999996, -10.599999999999932, 171.99999999999977, -5.799999999999837, -1.8000000000000353, -31.500000000000128, 4.4000000000001585, -79.80000000000038, 270.60000000000025, -134.09999999999997, -122.60000000000096, 101.99999999999925, 219.09999999999926, -5.900000000000112, 40.9000000000003, 130.19999999999987, -271.80000000000007, -9.299999999999887, 88.29999999999993, 133.49999999999974, 43.60000000000036, 101.19999999999851, 40.0000000000003, 151.59999999999943, 57.000000000000256, -87.60000000000106, 32.60000000000032, -80.09999999999982, -211.60000000000076, 126.29999999999986, 40.0000000000003, 40.90000000000031, 40.90000000000031, -41.29999999999994, -195.00000000000045, 56.2000000000005, -106.29999999999995, 120.19999999999916, 201.49999999999906, -89.50000000000034, 71.09999999999954, 133.59999999999988, 139.49999999999937, 139.90000000000026, 291.7, 92.39999999999907, -63.19999999999989, -63.400000000001015, 111.99999999999977, -12.399999999999926, 248.3999999999995, 212.7999999999993, -22.899999999999693, 117.39999999999954, 55.49999999999961, 75.79999999999922, 62.000000000000206, 17.00000000000001, -51.299999999999905, 163.29999999999956, 76.59999999999962, -170.60000000000016, 47.70000000000041, 171.39999999999935, 112.99999999999878, 201.40000000000006, -5.90000000000005, 65.30000000000013, -25.999999999999964, 119.29999999999976, 62.30000000000024, -40.19999999999972, 102.09999999999843], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.39999999999999936, -36.699999999999854, 82.39999999999964, 154.1, -141.69999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 68.59999999999982, 46.100000000000186, 38.299999999999834, -89.20000000000041, 64.70000000000006, 41.60000000000025, 20.000000000000014, 20.000000000000014, -82.6, -131.2000000000004, 27.800000000000118, -279.7000000000003, 16.399999999999967, 20.000000000000014, 78.49999999999937, -146.20000000000067, 20.000000000000014, 20.000000000000014, -232.00000000000045, 20.000000000000014, 20.000000000000014, 11.599999999999973, -20.2, -103.9000000000003, 20.000000000000014, 27.800000000000153, -61.90000000000071, 20.000000000000014, -36.09999999999989, -124.30000000000024, -21.999999999999932, 24.79999999999997, 55.400000000000055, -123.70000000000047, 20.000000000000014, 20.000000000000014, -7.299999999999969, -142.90000000000006, 37.10000000000026, 54.49999999999999, 48.80000000000024, -239.79999999999967, 54.800000000000125, 84.19999999999959, 66.19999999999996, 96.49999999999997, 172.99999999999983, 84.79999999999927, -24.999999999999986, -64.60000000000048, -24.999999999999936, 155.0, -34.89999999999996, -43.900000000000254, -11.49999999999984, -28.30000000000002, 26.900000000000013, -135.40000000000035, 20.000000000000014, -49.59999999999984, -91.30000000000018, -188.50000000000028, 86.89999999999998, 148.69999999999996, -64.00000000000003, -165.1000000000001, -13.600000000000035, -232.00000000000045, 33.50000000000024, 42.50000000000007, 199.1, 20.000000000000014, -140.80000000000013, 14.900000000000112, 20.000000000000014, 20.90000000000003, -58.0, 126.19999999999989, -206.8, -202.00000000000009, 22.700000000000063, -196.00000000000023, -33.09999999999976, 79.39999999999998, 121.69999999999979, -95.20000000000002, 14.599999999999978, 20.000000000000014, 20.000000000000014, 81.19999999999939, 20.000000000000014, 20.000000000000014, 20.000000000000014, 131.5999999999999, 9.499999999999947, 42.50000000000012, -223.60000000000045, 20.000000000000014, -87.40000000000002, -1.00000000000004, -189.99999999999994, -30.09999999999979, -141.70000000000056, -253.9000000000002, 28.400000000000134, 92.89999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.90000000000003, -232.60000000000042, 59.300000000000175, -119.20000000000027, -248.8000000000002, 36.200000000000244, 20.000000000000014, -270.09999999999997, -59.2, 1.699999999999987, 60.49999999999983, 44.89999999999978, 86.59999999999948, -85.59999999999988, -97.90000000000033, -52.90000000000004, 23.0, 41.60000000000003, 92.00000000000006, 32.0, 42.50000000000014, 96.49999999999997, 7.400000000000075, 142.39999999999992, 134.29999999999998, 20.000000000000014, 1.3999999999999972, -19.899999999999743, -157.29999999999995, -177.40000000000055, 20.000000000000014, 91.99999999999994, 20.000000000000014, -66.10000000000082, -28.299999999999947, 56.90000000000003, 159.49999999999974, 20.000000000000014, 192.8, -64.0000000000006, 1.0999999999999759, 20.000000000000014, 97.39999999999986, 20.000000000000014, -2.499999999999851, -1.00000000000012, 39.80000000000009, 47.900000000000205, -292.9, -72.99999999999997, 20.000000000000014, -154.3, 20.000000000000014, 143.3, 20.000000000000014, 50.60000000000021, 20.000000000000014, -339.0999999999998, -47.499999999999986, 6.799999999999981, 20.90000000000003, 75.79999999999968, 95.59999999999967, 78.5000000000002, 21.5000000000002, 125.30000000000004, 73.09999999999997, -93.40000000000032, 33.500000000000135, 13.69999999999997, -3.400000000000058, 136.9999999999997, -368.9999999999996, 41.29999999999999, 38.00000000000015, 43.400000000000055, 17.899999999999984, 17.90000000000006, -150.10000000000053, 50.600000000000236, 51.50000000000019], "policy_predator_policy_reward": [47.0, 0.0, 17.0, 0.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.0, 13.0, 0.0, 0.0, 0.0, 113.0, 0.0, 0.0, 148.0, 11.0, 4.0, 80.0, 0.0, 0.0, 0.0, 46.0, 103.0, 0.0, 4.0, 108.0, 0.0, 10.0, 0.0, 27.0, 18.0, 0.0, 120.0, 20.0, 5.0, 98.0, 0.0, 0.0, 0.0, 28.0, 90.0, 4.0, 15.0, 134.0, 32.0, 8.0, 23.0, 33.0, 0.0, 0.0, 0.0, 0.0, 79.0, 0.0, 42.0, 0.0, 73.0, 38.0, 0.0, 77.0, 0.0, 0.0, 34.0, 107.0, 93.0, 35.0, 0.0, 9.0, 86.0, 0.0, 123.0, 17.0, 9.0, 0.0, 0.0, 6.0, 114.0, 0.0, 0.0, 0.0, 62.0, 17.0, 120.0, 73.0, 91.0, 17.0, 25.0, 61.0, 46.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 116.0, 53.0, 68.0, 45.0, 95.0, 41.0, 143.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 123.0, 9.0, 173.0, 0.0, 0.0, 0.0, 87.0, 136.0, 33.0, 25.0, 34.0, 36.0, 0.0, 94.0, 20.0, 81.0, 0.0, 0.0, 3.0, 62.0, 35.0, 1.0, 2.0, 13.0, 26.0, 45.0, 0.0, 114.0, 94.0, 0.0, 0.0, 0.0, 0.0, 82.0, 10.0, 22.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 25.0, 13.0, 0.0, 37.0, 178.0, 129.0, 0.0, 70.0, 73.0, 10.0, 0.0, 0.0, 6.0, 0.0, 174.0, 42.0, 14.0, 6.0, 0.0, 0.0, 3.0, 10.0, 3.0, 0.0, 0.0, 54.0, 19.0, 36.0, 0.0, 206.0, 25.0, 15.0, 0.0, 1.0, 66.0, 26.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5622259157087137, "mean_inference_ms": 1.4281342084390116, "mean_action_processing_ms": 0.25546880494335084, "mean_env_wait_ms": 0.1947761502735436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0051544904708862305, "StateBufferConnector_ms": 0.0032951831817626953, "ViewRequirementAgentConnector_ms": 0.14920413494110107}, "num_episodes": 18, "episode_return_max": 291.7, "episode_return_min": -271.80000000000007, "episode_return_mean": 43.92199999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.7584809510743, "num_env_steps_trained_throughput_per_sec": 371.7584809510743, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 22999.099, "restore_workers_time_ms": 0.013, "training_step_time_ms": 22999.052, "sample_time_ms": 1217.074, "learn_time_ms": 21763.584, "learn_throughput": 183.793, "synch_weights_time_ms": 16.212}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "04dec_00002", "date": "2024-08-13_16-30-29", "timestamp": 1723581029, "time_this_iter_s": 10.826140880584717, "time_total_s": 463.8626699447632, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359caf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 463.8626699447632, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 62.52666666666667, "ram_util_percent": 84.80666666666669}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8131829638093236, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 4.4900997778726, "policy_loss": -0.00896985522316148, "vf_loss": 4.497996756260988, "vf_explained_var": 0.00317726765990888, "kl": 0.01695394890092099, "entropy": 1.4071633499135416, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8878286851540445, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 0.00010000000000000003, "total_loss": 7.521458658844075, "policy_loss": -0.003003383828228507, "vf_loss": 7.523801545995884, "vf_explained_var": 0.07350502894038245, "kl": 0.011742165043366323, "entropy": 1.0717039743428507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 301.5000000000006, "episode_reward_min": -271.80000000000007, "episode_reward_mean": 53.87099999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.9999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 206.0}, "policy_reward_mean": {"prey_policy": -6.434500000000055, "predator_policy": 33.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.19999999999989, 110.60000000000008, -24.999999999999844, 169.99999999999903, 195.6999999999995, 257.7999999999996, -10.599999999999932, 171.99999999999977, -5.799999999999837, -1.8000000000000353, -31.500000000000128, 4.4000000000001585, -79.80000000000038, 270.60000000000025, -134.09999999999997, -122.60000000000096, 101.99999999999925, 219.09999999999926, -5.900000000000112, 40.9000000000003, 130.19999999999987, -271.80000000000007, -9.299999999999887, 88.29999999999993, 133.49999999999974, 43.60000000000036, 101.19999999999851, 40.0000000000003, 151.59999999999943, 57.000000000000256, -87.60000000000106, 32.60000000000032, -80.09999999999982, -211.60000000000076, 126.29999999999986, 40.0000000000003, 40.90000000000031, 40.90000000000031, -41.29999999999994, -195.00000000000045, 56.2000000000005, -106.29999999999995, 120.19999999999916, 201.49999999999906, -89.50000000000034, 71.09999999999954, 133.59999999999988, 139.49999999999937, 139.90000000000026, 291.7, 92.39999999999907, -63.19999999999989, -63.400000000001015, 111.99999999999977, -12.399999999999926, 248.3999999999995, 212.7999999999993, -22.899999999999693, 117.39999999999954, 55.49999999999961, 75.79999999999922, 62.000000000000206, 17.00000000000001, -51.299999999999905, 163.29999999999956, 76.59999999999962, -170.60000000000016, 47.70000000000041, 171.39999999999935, 112.99999999999878, 201.40000000000006, -5.90000000000005, 65.30000000000013, -25.999999999999964, 119.29999999999976, 62.30000000000024, -40.19999999999972, 102.09999999999843, 56.200000000000294, 274.49999999999966, -50.69999999999975, -25.799999999999898, 39.20000000000017, 301.5000000000006, 40.0000000000003, -30.89999999999967, 62.9000000000003, 44.00000000000042, -43.49999999999998, -105.99999999999997, 99.99999999999991, 55.00000000000007, 48.19999999999998, 173.7999999999996, 254.1999999999992, -76.39999999999992, -8.699999999999925, 189.19999999999936, 114.29999999999941, 135.19999999999968], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-7.299999999999969, -142.90000000000006, 37.10000000000026, 54.49999999999999, 48.80000000000024, -239.79999999999967, 54.800000000000125, 84.19999999999959, 66.19999999999996, 96.49999999999997, 172.99999999999983, 84.79999999999927, -24.999999999999986, -64.60000000000048, -24.999999999999936, 155.0, -34.89999999999996, -43.900000000000254, -11.49999999999984, -28.30000000000002, 26.900000000000013, -135.40000000000035, 20.000000000000014, -49.59999999999984, -91.30000000000018, -188.50000000000028, 86.89999999999998, 148.69999999999996, -64.00000000000003, -165.1000000000001, -13.600000000000035, -232.00000000000045, 33.50000000000024, 42.50000000000007, 199.1, 20.000000000000014, -140.80000000000013, 14.900000000000112, 20.000000000000014, 20.90000000000003, -58.0, 126.19999999999989, -206.8, -202.00000000000009, 22.700000000000063, -196.00000000000023, -33.09999999999976, 79.39999999999998, 121.69999999999979, -95.20000000000002, 14.599999999999978, 20.000000000000014, 20.000000000000014, 81.19999999999939, 20.000000000000014, 20.000000000000014, 20.000000000000014, 131.5999999999999, 9.499999999999947, 42.50000000000012, -223.60000000000045, 20.000000000000014, -87.40000000000002, -1.00000000000004, -189.99999999999994, -30.09999999999979, -141.70000000000056, -253.9000000000002, 28.400000000000134, 92.89999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.90000000000003, -232.60000000000042, 59.300000000000175, -119.20000000000027, -248.8000000000002, 36.200000000000244, 20.000000000000014, -270.09999999999997, -59.2, 1.699999999999987, 60.49999999999983, 44.89999999999978, 86.59999999999948, -85.59999999999988, -97.90000000000033, -52.90000000000004, 23.0, 41.60000000000003, 92.00000000000006, 32.0, 42.50000000000014, 96.49999999999997, 7.400000000000075, 142.39999999999992, 134.29999999999998, 20.000000000000014, 1.3999999999999972, -19.899999999999743, -157.29999999999995, -177.40000000000055, 20.000000000000014, 91.99999999999994, 20.000000000000014, -66.10000000000082, -28.299999999999947, 56.90000000000003, 159.49999999999974, 20.000000000000014, 192.8, -64.0000000000006, 1.0999999999999759, 20.000000000000014, 97.39999999999986, 20.000000000000014, -2.499999999999851, -1.00000000000012, 39.80000000000009, 47.900000000000205, -292.9, -72.99999999999997, 20.000000000000014, -154.3, 20.000000000000014, 143.3, 20.000000000000014, 50.60000000000021, 20.000000000000014, -339.0999999999998, -47.499999999999986, 6.799999999999981, 20.90000000000003, 75.79999999999968, 95.59999999999967, 78.5000000000002, 21.5000000000002, 125.30000000000004, 73.09999999999997, -93.40000000000032, 33.500000000000135, 13.69999999999997, -3.400000000000058, 136.9999999999997, -368.9999999999996, 41.29999999999999, 38.00000000000015, 43.400000000000055, 17.899999999999984, 17.90000000000006, -150.10000000000053, 50.600000000000236, 51.50000000000019, 20.000000000000014, 36.200000000000095, 72.49999999999937, 200.0, -156.40000000000038, -4.300000000000054, -160.60000000000025, 24.800000000000075, -68.20000000000024, 13.399999999999972, 152.29999999999984, 147.20000000000002, 20.000000000000014, 20.000000000000014, -139.90000000000057, 7.999999999999986, 39.20000000000012, -49.2999999999999, -3.7000000000000153, 13.70000000000001, 5.2999999999999865, -122.8000000000001, -243.40000000000032, -16.59999999999987, 180.7999999999999, -319.7999999999996, -235.50000000000026, 132.50000000000003, 94.39999999999976, -152.2, 21.500000000000064, 71.2999999999999, 120.79999999999953, 133.39999999999995, 68.59999999999988, -295.0000000000001, -122.80000000000014, 46.09999999999997, 98.29999999999968, 89.89999999999968, -29.200000000000166, 69.49999999999966, 17.899999999999988, 116.29999999999998], "policy_predator_policy_reward": [28.0, 90.0, 4.0, 15.0, 134.0, 32.0, 8.0, 23.0, 33.0, 0.0, 0.0, 0.0, 0.0, 79.0, 0.0, 42.0, 0.0, 73.0, 38.0, 0.0, 77.0, 0.0, 0.0, 34.0, 107.0, 93.0, 35.0, 0.0, 9.0, 86.0, 0.0, 123.0, 17.0, 9.0, 0.0, 0.0, 6.0, 114.0, 0.0, 0.0, 0.0, 62.0, 17.0, 120.0, 73.0, 91.0, 17.0, 25.0, 61.0, 46.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 116.0, 53.0, 68.0, 45.0, 95.0, 41.0, 143.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 123.0, 9.0, 173.0, 0.0, 0.0, 0.0, 87.0, 136.0, 33.0, 25.0, 34.0, 36.0, 0.0, 94.0, 20.0, 81.0, 0.0, 0.0, 3.0, 62.0, 35.0, 1.0, 2.0, 13.0, 26.0, 45.0, 0.0, 114.0, 94.0, 0.0, 0.0, 0.0, 0.0, 82.0, 10.0, 22.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 25.0, 13.0, 0.0, 37.0, 178.0, 129.0, 0.0, 70.0, 73.0, 10.0, 0.0, 0.0, 6.0, 0.0, 174.0, 42.0, 14.0, 6.0, 0.0, 0.0, 3.0, 10.0, 3.0, 0.0, 0.0, 54.0, 19.0, 36.0, 0.0, 206.0, 25.0, 15.0, 0.0, 1.0, 66.0, 26.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 63.0, 47.0, 73.0, 37.0, 75.0, 19.0, 0.0, 2.0, 0.0, 0.0, 83.0, 18.0, 25.0, 48.0, 26.0, 8.0, 6.0, 68.0, 52.0, 102.0, 140.0, 99.0, 158.0, 0.0, 92.0, 14.0, 35.0, 46.0, 0.0, 0.0, 0.0, 150.0, 0.0, 68.0, 1.0, 0.0, 0.0, 74.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5663589145160947, "mean_inference_ms": 1.440374927582444, "mean_action_processing_ms": 0.2556574933785315, "mean_env_wait_ms": 0.19651664160124213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005342006683349609, "StateBufferConnector_ms": 0.003542661666870117, "ViewRequirementAgentConnector_ms": 0.15421628952026367}, "num_episodes": 22, "episode_return_max": 301.5000000000006, "episode_return_min": -271.80000000000007, "episode_return_mean": 53.87099999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 382.44778521997966, "num_env_steps_trained_throughput_per_sec": 382.44778521997966, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 23149.377, "restore_workers_time_ms": 0.013, "training_step_time_ms": 23149.329, "sample_time_ms": 1231.744, "learn_time_ms": 21898.612, "learn_throughput": 182.66, "synch_weights_time_ms": 16.583}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "04dec_00002", "date": "2024-08-13_16-30-39", "timestamp": 1723581039, "time_this_iter_s": 10.551900863647461, "time_total_s": 474.41457080841064, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04615e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 474.41457080841064, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 55.333333333333336, "ram_util_percent": 85.56666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8685357931350904, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 3.8009531602657662, "policy_loss": -0.0029229516275572002, "vf_loss": 3.803304025861952, "vf_explained_var": 0.00562308979412866, "kl": 0.009040400623410862, "entropy": 1.3455664112454369, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2218053084674967, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 0.00010000000000000003, "total_loss": 7.289514410432685, "policy_loss": -0.004466102068268117, "vf_loss": 7.293236772345487, "vf_explained_var": 0.0851792381869422, "kl": 0.013221930086540861, "entropy": 1.0323583738198356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 352.29999999999984, "episode_reward_min": -366.1999999999997, "episode_reward_mean": 54.54499999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.9999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 206.0}, "policy_reward_mean": {"prey_policy": -6.362500000000068, "predator_policy": 33.635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.29999999999993, 133.49999999999974, 43.60000000000036, 101.19999999999851, 40.0000000000003, 151.59999999999943, 57.000000000000256, -87.60000000000106, 32.60000000000032, -80.09999999999982, -211.60000000000076, 126.29999999999986, 40.0000000000003, 40.90000000000031, 40.90000000000031, -41.29999999999994, -195.00000000000045, 56.2000000000005, -106.29999999999995, 120.19999999999916, 201.49999999999906, -89.50000000000034, 71.09999999999954, 133.59999999999988, 139.49999999999937, 139.90000000000026, 291.7, 92.39999999999907, -63.19999999999989, -63.400000000001015, 111.99999999999977, -12.399999999999926, 248.3999999999995, 212.7999999999993, -22.899999999999693, 117.39999999999954, 55.49999999999961, 75.79999999999922, 62.000000000000206, 17.00000000000001, -51.299999999999905, 163.29999999999956, 76.59999999999962, -170.60000000000016, 47.70000000000041, 171.39999999999935, 112.99999999999878, 201.40000000000006, -5.90000000000005, 65.30000000000013, -25.999999999999964, 119.29999999999976, 62.30000000000024, -40.19999999999972, 102.09999999999843, 56.200000000000294, 274.49999999999966, -50.69999999999975, -25.799999999999898, 39.20000000000017, 301.5000000000006, 40.0000000000003, -30.89999999999967, 62.9000000000003, 44.00000000000042, -43.49999999999998, -105.99999999999997, 99.99999999999991, 55.00000000000007, 48.19999999999998, 173.7999999999996, 254.1999999999992, -76.39999999999992, -8.699999999999925, 189.19999999999936, 114.29999999999941, 135.19999999999968, 208.29999999999941, -59.4999999999997, 43.000000000000185, 134.29999999999916, 42.600000000000215, -26.59999999999995, 1.4999999999999711, 29.00000000000027, -123.40000000000018, 352.29999999999984, 114.19999999999965, -366.1999999999997, 116.69999999999956, 56.20000000000032, -88.70000000000016, 124.5999999999988, 160.59999999999923, 121.79999999999939, 81.59999999999992, 182.2, 79.30000000000001, -143.40000000000026, -30.09999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-33.09999999999976, 79.39999999999998, 121.69999999999979, -95.20000000000002, 14.599999999999978, 20.000000000000014, 20.000000000000014, 81.19999999999939, 20.000000000000014, 20.000000000000014, 20.000000000000014, 131.5999999999999, 9.499999999999947, 42.50000000000012, -223.60000000000045, 20.000000000000014, -87.40000000000002, -1.00000000000004, -189.99999999999994, -30.09999999999979, -141.70000000000056, -253.9000000000002, 28.400000000000134, 92.89999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.90000000000003, -232.60000000000042, 59.300000000000175, -119.20000000000027, -248.8000000000002, 36.200000000000244, 20.000000000000014, -270.09999999999997, -59.2, 1.699999999999987, 60.49999999999983, 44.89999999999978, 86.59999999999948, -85.59999999999988, -97.90000000000033, -52.90000000000004, 23.0, 41.60000000000003, 92.00000000000006, 32.0, 42.50000000000014, 96.49999999999997, 7.400000000000075, 142.39999999999992, 134.29999999999998, 20.000000000000014, 1.3999999999999972, -19.899999999999743, -157.29999999999995, -177.40000000000055, 20.000000000000014, 91.99999999999994, 20.000000000000014, -66.10000000000082, -28.299999999999947, 56.90000000000003, 159.49999999999974, 20.000000000000014, 192.8, -64.0000000000006, 1.0999999999999759, 20.000000000000014, 97.39999999999986, 20.000000000000014, -2.499999999999851, -1.00000000000012, 39.80000000000009, 47.900000000000205, -292.9, -72.99999999999997, 20.000000000000014, -154.3, 20.000000000000014, 143.3, 20.000000000000014, 50.60000000000021, 20.000000000000014, -339.0999999999998, -47.499999999999986, 6.799999999999981, 20.90000000000003, 75.79999999999968, 95.59999999999967, 78.5000000000002, 21.5000000000002, 125.30000000000004, 73.09999999999997, -93.40000000000032, 33.500000000000135, 13.69999999999997, -3.400000000000058, 136.9999999999997, -368.9999999999996, 41.29999999999999, 38.00000000000015, 43.400000000000055, 17.899999999999984, 17.90000000000006, -150.10000000000053, 50.600000000000236, 51.50000000000019, 20.000000000000014, 36.200000000000095, 72.49999999999937, 200.0, -156.40000000000038, -4.300000000000054, -160.60000000000025, 24.800000000000075, -68.20000000000024, 13.399999999999972, 152.29999999999984, 147.20000000000002, 20.000000000000014, 20.000000000000014, -139.90000000000057, 7.999999999999986, 39.20000000000012, -49.2999999999999, -3.7000000000000153, 13.70000000000001, 5.2999999999999865, -122.8000000000001, -243.40000000000032, -16.59999999999987, 180.7999999999999, -319.7999999999996, -235.50000000000026, 132.50000000000003, 94.39999999999976, -152.2, 21.500000000000064, 71.2999999999999, 120.79999999999953, 133.39999999999995, 68.59999999999988, -295.0000000000001, -122.80000000000014, 46.09999999999997, 98.29999999999968, 89.89999999999968, -29.200000000000166, 69.49999999999966, 17.899999999999988, 116.29999999999998, 137.89999999999975, 70.39999999999972, -73.89999999999993, -97.60000000000036, 112.09999999999968, -171.1000000000002, 34.99999999999987, 71.29999999999997, -183.70000000000022, 122.2999999999997, -139.5999999999999, 20.000000000000014, -41.199999999999804, -43.29999999999999, -1.0000000000000355, 20.000000000000014, -125.50000000000026, -136.9000000000004, 182.89999999999992, 169.39999999999986, 115.39999999999992, -35.200000000000045, -307.59999999999974, -265.60000000000025, 61.100000000000016, 11.59999999999999, 20.900000000000027, 35.300000000000146, -5.200000000000049, -200.50000000000003, 104.59999999999948, 20.000000000000014, 20.000000000000014, 140.59999999999994, -66.10000000000045, 146.8999999999998, -154.30000000000067, 146.8999999999998, 109.09999999999997, 73.09999999999994, 49.40000000000002, -21.09999999999979, -144.40000000000026, -253.00000000000009, -267.40000000000015, 23.299999999999905], "policy_predator_policy_reward": [17.0, 25.0, 61.0, 46.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 116.0, 53.0, 68.0, 45.0, 95.0, 41.0, 143.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 123.0, 9.0, 173.0, 0.0, 0.0, 0.0, 87.0, 136.0, 33.0, 25.0, 34.0, 36.0, 0.0, 94.0, 20.0, 81.0, 0.0, 0.0, 3.0, 62.0, 35.0, 1.0, 2.0, 13.0, 26.0, 45.0, 0.0, 114.0, 94.0, 0.0, 0.0, 0.0, 0.0, 82.0, 10.0, 22.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 25.0, 13.0, 0.0, 37.0, 178.0, 129.0, 0.0, 70.0, 73.0, 10.0, 0.0, 0.0, 6.0, 0.0, 174.0, 42.0, 14.0, 6.0, 0.0, 0.0, 3.0, 10.0, 3.0, 0.0, 0.0, 54.0, 19.0, 36.0, 0.0, 206.0, 25.0, 15.0, 0.0, 1.0, 66.0, 26.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 63.0, 47.0, 73.0, 37.0, 75.0, 19.0, 0.0, 2.0, 0.0, 0.0, 83.0, 18.0, 25.0, 48.0, 26.0, 8.0, 6.0, 68.0, 52.0, 102.0, 140.0, 99.0, 158.0, 0.0, 92.0, 14.0, 35.0, 46.0, 0.0, 0.0, 0.0, 150.0, 0.0, 68.0, 1.0, 0.0, 0.0, 74.0, 1.0, 0.0, 0.0, 0.0, 45.0, 67.0, 0.0, 102.0, 0.0, 28.0, 0.0, 104.0, 76.0, 17.0, 60.0, 26.0, 0.0, 10.0, 79.0, 60.0, 0.0, 0.0, 18.0, 16.0, 180.0, 27.0, 44.0, 0.0, 0.0, 0.0, 105.0, 12.0, 0.0, 0.0, 0.0, 0.0, 38.0, 3.0, 6.0, 83.0, 0.0, 0.0, 51.0, 0.0, 93.0, 161.0, 46.0, 168.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5719010968545039, "mean_inference_ms": 1.4558079829734722, "mean_action_processing_ms": 0.25650571631132424, "mean_env_wait_ms": 0.19877502442959055, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004508256912231445, "StateBufferConnector_ms": 0.003811478614807129, "ViewRequirementAgentConnector_ms": 0.1595231294631958}, "num_episodes": 23, "episode_return_max": 352.29999999999984, "episode_return_min": -366.1999999999997, "episode_return_mean": 54.54499999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 385.503233789823, "num_env_steps_trained_throughput_per_sec": 385.503233789823, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 23320.517, "restore_workers_time_ms": 0.014, "training_step_time_ms": 23320.468, "sample_time_ms": 1269.202, "learn_time_ms": 22032.182, "learn_throughput": 181.553, "synch_weights_time_ms": 16.607}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "04dec_00002", "date": "2024-08-13_16-30-50", "timestamp": 1723581050, "time_this_iter_s": 10.435462713241577, "time_total_s": 484.8500335216522, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04b9790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 484.8500335216522, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 48.260000000000005, "ram_util_percent": 86.67999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8406896183178538, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 3.1486448626038888, "policy_loss": -0.00399411199368024, "vf_loss": 3.1520292092883397, "vf_explained_var": 0.0029000235297692517, "kl": 0.00963580468166971, "entropy": 1.350668422002641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8247983812812776, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 0.00010000000000000003, "total_loss": 8.083115818134692, "policy_loss": -0.0027231146205738974, "vf_loss": 8.085297675864407, "vf_explained_var": 0.1400260602355634, "kl": 0.009622556233132913, "entropy": 0.9819534876674572, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 352.29999999999984, "episode_reward_min": -366.1999999999997, "episode_reward_mean": 76.68899999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.9999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 206.0}, "policy_reward_mean": {"prey_policy": 5.064499999999928, "predator_policy": 33.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-106.29999999999995, 120.19999999999916, 201.49999999999906, -89.50000000000034, 71.09999999999954, 133.59999999999988, 139.49999999999937, 139.90000000000026, 291.7, 92.39999999999907, -63.19999999999989, -63.400000000001015, 111.99999999999977, -12.399999999999926, 248.3999999999995, 212.7999999999993, -22.899999999999693, 117.39999999999954, 55.49999999999961, 75.79999999999922, 62.000000000000206, 17.00000000000001, -51.299999999999905, 163.29999999999956, 76.59999999999962, -170.60000000000016, 47.70000000000041, 171.39999999999935, 112.99999999999878, 201.40000000000006, -5.90000000000005, 65.30000000000013, -25.999999999999964, 119.29999999999976, 62.30000000000024, -40.19999999999972, 102.09999999999843, 56.200000000000294, 274.49999999999966, -50.69999999999975, -25.799999999999898, 39.20000000000017, 301.5000000000006, 40.0000000000003, -30.89999999999967, 62.9000000000003, 44.00000000000042, -43.49999999999998, -105.99999999999997, 99.99999999999991, 55.00000000000007, 48.19999999999998, 173.7999999999996, 254.1999999999992, -76.39999999999992, -8.699999999999925, 189.19999999999936, 114.29999999999941, 135.19999999999968, 208.29999999999941, -59.4999999999997, 43.000000000000185, 134.29999999999916, 42.600000000000215, -26.59999999999995, 1.4999999999999711, 29.00000000000027, -123.40000000000018, 352.29999999999984, 114.19999999999965, -366.1999999999997, 116.69999999999956, 56.20000000000032, -88.70000000000016, 124.5999999999988, 160.59999999999923, 121.79999999999939, 81.59999999999992, 182.2, 79.30000000000001, -143.40000000000026, -30.09999999999991, 173.1999999999996, -36.799999999999905, 54.400000000000276, 343.10000000000014, 122.79999999999973, 171.39999999999918, 342.20000000000005, 124.5999999999998, 122.79999999999978, -4.799999999999995, 74.39999999999999, 135.0999999999994, 28.300000000000086, 165.1999999999994, 273.0999999999998, 64.10000000000015, 87.79999999999998, 309.9999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-270.09999999999997, -59.2, 1.699999999999987, 60.49999999999983, 44.89999999999978, 86.59999999999948, -85.59999999999988, -97.90000000000033, -52.90000000000004, 23.0, 41.60000000000003, 92.00000000000006, 32.0, 42.50000000000014, 96.49999999999997, 7.400000000000075, 142.39999999999992, 134.29999999999998, 20.000000000000014, 1.3999999999999972, -19.899999999999743, -157.29999999999995, -177.40000000000055, 20.000000000000014, 91.99999999999994, 20.000000000000014, -66.10000000000082, -28.299999999999947, 56.90000000000003, 159.49999999999974, 20.000000000000014, 192.8, -64.0000000000006, 1.0999999999999759, 20.000000000000014, 97.39999999999986, 20.000000000000014, -2.499999999999851, -1.00000000000012, 39.80000000000009, 47.900000000000205, -292.9, -72.99999999999997, 20.000000000000014, -154.3, 20.000000000000014, 143.3, 20.000000000000014, 50.60000000000021, 20.000000000000014, -339.0999999999998, -47.499999999999986, 6.799999999999981, 20.90000000000003, 75.79999999999968, 95.59999999999967, 78.5000000000002, 21.5000000000002, 125.30000000000004, 73.09999999999997, -93.40000000000032, 33.500000000000135, 13.69999999999997, -3.400000000000058, 136.9999999999997, -368.9999999999996, 41.29999999999999, 38.00000000000015, 43.400000000000055, 17.899999999999984, 17.90000000000006, -150.10000000000053, 50.600000000000236, 51.50000000000019, 20.000000000000014, 36.200000000000095, 72.49999999999937, 200.0, -156.40000000000038, -4.300000000000054, -160.60000000000025, 24.800000000000075, -68.20000000000024, 13.399999999999972, 152.29999999999984, 147.20000000000002, 20.000000000000014, 20.000000000000014, -139.90000000000057, 7.999999999999986, 39.20000000000012, -49.2999999999999, -3.7000000000000153, 13.70000000000001, 5.2999999999999865, -122.8000000000001, -243.40000000000032, -16.59999999999987, 180.7999999999999, -319.7999999999996, -235.50000000000026, 132.50000000000003, 94.39999999999976, -152.2, 21.500000000000064, 71.2999999999999, 120.79999999999953, 133.39999999999995, 68.59999999999988, -295.0000000000001, -122.80000000000014, 46.09999999999997, 98.29999999999968, 89.89999999999968, -29.200000000000166, 69.49999999999966, 17.899999999999988, 116.29999999999998, 137.89999999999975, 70.39999999999972, -73.89999999999993, -97.60000000000036, 112.09999999999968, -171.1000000000002, 34.99999999999987, 71.29999999999997, -183.70000000000022, 122.2999999999997, -139.5999999999999, 20.000000000000014, -41.199999999999804, -43.29999999999999, -1.0000000000000355, 20.000000000000014, -125.50000000000026, -136.9000000000004, 182.89999999999992, 169.39999999999986, 115.39999999999992, -35.200000000000045, -307.59999999999974, -265.60000000000025, 61.100000000000016, 11.59999999999999, 20.900000000000027, 35.300000000000146, -5.200000000000049, -200.50000000000003, 104.59999999999948, 20.000000000000014, 20.000000000000014, 140.59999999999994, -66.10000000000045, 146.8999999999998, -154.30000000000067, 146.8999999999998, 109.09999999999997, 73.09999999999994, 49.40000000000002, -21.09999999999979, -144.40000000000026, -253.00000000000009, -267.40000000000015, 23.299999999999905, 122.59999999999987, 50.600000000000044, 70.3999999999998, -257.2000000000001, 20.000000000000014, 34.39999999999999, 166.69999999999993, 175.39999999999986, -131.2000000000004, 181.99999999999997, 136.09999999999977, 26.300000000000004, 195.2, 146.0, 181.09999999999994, -179.5000000000004, 20.000000000000014, 102.79999999999998, 32.600000000000136, -114.40000000000055, 187.4, -295.0, -5.2000000000000295, 98.29999999999987, 67.39999999999988, -165.10000000000016, 100.99999999999994, 51.20000000000017, 179.29999999999998, 93.80000000000001, 160.40000000000006, -205.30000000000015, 38.90000000000002, -9.099999999999998, 189.19999999999996, 120.80000000000008], "policy_predator_policy_reward": [87.0, 136.0, 33.0, 25.0, 34.0, 36.0, 0.0, 94.0, 20.0, 81.0, 0.0, 0.0, 3.0, 62.0, 35.0, 1.0, 2.0, 13.0, 26.0, 45.0, 0.0, 114.0, 94.0, 0.0, 0.0, 0.0, 0.0, 82.0, 10.0, 22.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 25.0, 13.0, 0.0, 37.0, 178.0, 129.0, 0.0, 70.0, 73.0, 10.0, 0.0, 0.0, 6.0, 0.0, 174.0, 42.0, 14.0, 6.0, 0.0, 0.0, 3.0, 10.0, 3.0, 0.0, 0.0, 54.0, 19.0, 36.0, 0.0, 206.0, 25.0, 15.0, 0.0, 1.0, 66.0, 26.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 63.0, 47.0, 73.0, 37.0, 75.0, 19.0, 0.0, 2.0, 0.0, 0.0, 83.0, 18.0, 25.0, 48.0, 26.0, 8.0, 6.0, 68.0, 52.0, 102.0, 140.0, 99.0, 158.0, 0.0, 92.0, 14.0, 35.0, 46.0, 0.0, 0.0, 0.0, 150.0, 0.0, 68.0, 1.0, 0.0, 0.0, 74.0, 1.0, 0.0, 0.0, 0.0, 45.0, 67.0, 0.0, 102.0, 0.0, 28.0, 0.0, 104.0, 76.0, 17.0, 60.0, 26.0, 0.0, 10.0, 79.0, 60.0, 0.0, 0.0, 18.0, 16.0, 180.0, 27.0, 44.0, 0.0, 0.0, 0.0, 105.0, 12.0, 0.0, 0.0, 0.0, 0.0, 38.0, 3.0, 6.0, 83.0, 0.0, 0.0, 51.0, 0.0, 93.0, 161.0, 46.0, 168.0, 0.0, 0.0, 93.0, 57.0, 0.0, 0.0, 1.0, 0.0, 0.0, 72.0, 0.0, 9.0, 1.0, 0.0, 76.0, 47.0, 0.0, 0.0, 3.0, 74.0, 77.0, 105.0, 6.0, 36.0, 72.0, 54.0, 13.0, 0.0, 0.0, 0.0, 46.0, 63.0, 3.0, 55.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.575692888490488, "mean_inference_ms": 1.46578770934769, "mean_action_processing_ms": 0.2569672820131471, "mean_env_wait_ms": 0.200453477665367, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004469037055969238, "StateBufferConnector_ms": 0.0037461519241333008, "ViewRequirementAgentConnector_ms": 0.15845739841461182}, "num_episodes": 18, "episode_return_max": 352.29999999999984, "episode_return_min": -366.1999999999997, "episode_return_mean": 76.68899999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 405.272185793877, "num_env_steps_trained_throughput_per_sec": 405.272185793877, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 23429.021, "restore_workers_time_ms": 0.014, "training_step_time_ms": 23428.971, "sample_time_ms": 1291.092, "learn_time_ms": 22118.346, "learn_throughput": 180.845, "synch_weights_time_ms": 16.884}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "04dec_00002", "date": "2024-08-13_16-31-00", "timestamp": 1723581060, "time_this_iter_s": 9.932672023773193, "time_total_s": 494.7827055454254, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06163a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 494.7827055454254, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 43.778571428571425, "ram_util_percent": 86.57857142857144}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8117625235880493, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 5.449441345406588, "policy_loss": -0.007040996206480832, "vf_loss": 5.455471442490028, "vf_explained_var": 0.0002490408521480661, "kl": 0.015974733516106857, "entropy": 1.2768784506611093, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.546324911067095, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 0.00010000000000000003, "total_loss": 8.670113112182214, "policy_loss": -0.006648251942787615, "vf_loss": 8.675610954547054, "vf_explained_var": 0.1351655478830691, "kl": 0.02045161614752114, "entropy": 0.9879567283486563, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 352.29999999999984, "episode_reward_min": -366.1999999999997, "episode_reward_mean": 76.29599999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -437.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": 0.9229999999999322, "predator_policy": 37.225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.49999999999961, 75.79999999999922, 62.000000000000206, 17.00000000000001, -51.299999999999905, 163.29999999999956, 76.59999999999962, -170.60000000000016, 47.70000000000041, 171.39999999999935, 112.99999999999878, 201.40000000000006, -5.90000000000005, 65.30000000000013, -25.999999999999964, 119.29999999999976, 62.30000000000024, -40.19999999999972, 102.09999999999843, 56.200000000000294, 274.49999999999966, -50.69999999999975, -25.799999999999898, 39.20000000000017, 301.5000000000006, 40.0000000000003, -30.89999999999967, 62.9000000000003, 44.00000000000042, -43.49999999999998, -105.99999999999997, 99.99999999999991, 55.00000000000007, 48.19999999999998, 173.7999999999996, 254.1999999999992, -76.39999999999992, -8.699999999999925, 189.19999999999936, 114.29999999999941, 135.19999999999968, 208.29999999999941, -59.4999999999997, 43.000000000000185, 134.29999999999916, 42.600000000000215, -26.59999999999995, 1.4999999999999711, 29.00000000000027, -123.40000000000018, 352.29999999999984, 114.19999999999965, -366.1999999999997, 116.69999999999956, 56.20000000000032, -88.70000000000016, 124.5999999999988, 160.59999999999923, 121.79999999999939, 81.59999999999992, 182.2, 79.30000000000001, -143.40000000000026, -30.09999999999991, 173.1999999999996, -36.799999999999905, 54.400000000000276, 343.10000000000014, 122.79999999999973, 171.39999999999918, 342.20000000000005, 124.5999999999998, 122.79999999999978, -4.799999999999995, 74.39999999999999, 135.0999999999994, 28.300000000000086, 165.1999999999994, 273.0999999999998, 64.10000000000015, 87.79999999999998, 309.9999999999998, -27.299999999999592, 32.000000000000064, 55.30000000000002, 121.79999999999995, 175.99999999999935, 34.299999999999216, 141.2999999999998, -258.30000000000007, 25.800000000000075, 122.80000000000022, 59.90000000000004, 174.19999999999956, 250.7999999999997, 9.400000000000169, 87.70000000000007, 188.09999999999917, 122.79999999999899, 166.89999999999958], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -2.499999999999851, -1.00000000000012, 39.80000000000009, 47.900000000000205, -292.9, -72.99999999999997, 20.000000000000014, -154.3, 20.000000000000014, 143.3, 20.000000000000014, 50.60000000000021, 20.000000000000014, -339.0999999999998, -47.499999999999986, 6.799999999999981, 20.90000000000003, 75.79999999999968, 95.59999999999967, 78.5000000000002, 21.5000000000002, 125.30000000000004, 73.09999999999997, -93.40000000000032, 33.500000000000135, 13.69999999999997, -3.400000000000058, 136.9999999999997, -368.9999999999996, 41.29999999999999, 38.00000000000015, 43.400000000000055, 17.899999999999984, 17.90000000000006, -150.10000000000053, 50.600000000000236, 51.50000000000019, 20.000000000000014, 36.200000000000095, 72.49999999999937, 200.0, -156.40000000000038, -4.300000000000054, -160.60000000000025, 24.800000000000075, -68.20000000000024, 13.399999999999972, 152.29999999999984, 147.20000000000002, 20.000000000000014, 20.000000000000014, -139.90000000000057, 7.999999999999986, 39.20000000000012, -49.2999999999999, -3.7000000000000153, 13.70000000000001, 5.2999999999999865, -122.8000000000001, -243.40000000000032, -16.59999999999987, 180.7999999999999, -319.7999999999996, -235.50000000000026, 132.50000000000003, 94.39999999999976, -152.2, 21.500000000000064, 71.2999999999999, 120.79999999999953, 133.39999999999995, 68.59999999999988, -295.0000000000001, -122.80000000000014, 46.09999999999997, 98.29999999999968, 89.89999999999968, -29.200000000000166, 69.49999999999966, 17.899999999999988, 116.29999999999998, 137.89999999999975, 70.39999999999972, -73.89999999999993, -97.60000000000036, 112.09999999999968, -171.1000000000002, 34.99999999999987, 71.29999999999997, -183.70000000000022, 122.2999999999997, -139.5999999999999, 20.000000000000014, -41.199999999999804, -43.29999999999999, -1.0000000000000355, 20.000000000000014, -125.50000000000026, -136.9000000000004, 182.89999999999992, 169.39999999999986, 115.39999999999992, -35.200000000000045, -307.59999999999974, -265.60000000000025, 61.100000000000016, 11.59999999999999, 20.900000000000027, 35.300000000000146, -5.200000000000049, -200.50000000000003, 104.59999999999948, 20.000000000000014, 20.000000000000014, 140.59999999999994, -66.10000000000045, 146.8999999999998, -154.30000000000067, 146.8999999999998, 109.09999999999997, 73.09999999999994, 49.40000000000002, -21.09999999999979, -144.40000000000026, -253.00000000000009, -267.40000000000015, 23.299999999999905, 122.59999999999987, 50.600000000000044, 70.3999999999998, -257.2000000000001, 20.000000000000014, 34.39999999999999, 166.69999999999993, 175.39999999999986, -131.2000000000004, 181.99999999999997, 136.09999999999977, 26.300000000000004, 195.2, 146.0, 181.09999999999994, -179.5000000000004, 20.000000000000014, 102.79999999999998, 32.600000000000136, -114.40000000000055, 187.4, -295.0, -5.2000000000000295, 98.29999999999987, 67.39999999999988, -165.10000000000016, 100.99999999999994, 51.20000000000017, 179.29999999999998, 93.80000000000001, 160.40000000000006, -205.30000000000015, 38.90000000000002, -9.099999999999998, 189.19999999999996, 120.80000000000008, -112.3000000000007, 20.000000000000014, 65.90000000000016, -103.90000000000073, -265.20000000000016, 150.5, 94.69999999999997, -58.89999999999999, -26.20000000000002, 180.19999999999993, -40.00000000000004, 35.30000000000015, -83.19999999999999, 132.50000000000006, -289.9000000000002, -240.40000000000003, -437.80000000000007, 113.59999999999948, 84.80000000000001, -166.99999999999994, -284.4999999999994, 142.39999999999998, -112.59999999999988, 171.79999999999995, -22.600000000000158, 187.39999999999998, -59.80000000000004, -20.79999999999992, 66.80000000000001, 20.900000000000027, 15.800000000000002, 170.29999999999987, 93.19999999999959, 11.599999999999966, 137.89999999999998, 29.000000000000075], "policy_predator_policy_reward": [25.0, 13.0, 0.0, 37.0, 178.0, 129.0, 0.0, 70.0, 73.0, 10.0, 0.0, 0.0, 6.0, 0.0, 174.0, 42.0, 14.0, 6.0, 0.0, 0.0, 3.0, 10.0, 3.0, 0.0, 0.0, 54.0, 19.0, 36.0, 0.0, 206.0, 25.0, 15.0, 0.0, 1.0, 66.0, 26.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 63.0, 47.0, 73.0, 37.0, 75.0, 19.0, 0.0, 2.0, 0.0, 0.0, 83.0, 18.0, 25.0, 48.0, 26.0, 8.0, 6.0, 68.0, 52.0, 102.0, 140.0, 99.0, 158.0, 0.0, 92.0, 14.0, 35.0, 46.0, 0.0, 0.0, 0.0, 150.0, 0.0, 68.0, 1.0, 0.0, 0.0, 74.0, 1.0, 0.0, 0.0, 0.0, 45.0, 67.0, 0.0, 102.0, 0.0, 28.0, 0.0, 104.0, 76.0, 17.0, 60.0, 26.0, 0.0, 10.0, 79.0, 60.0, 0.0, 0.0, 18.0, 16.0, 180.0, 27.0, 44.0, 0.0, 0.0, 0.0, 105.0, 12.0, 0.0, 0.0, 0.0, 0.0, 38.0, 3.0, 6.0, 83.0, 0.0, 0.0, 51.0, 0.0, 93.0, 161.0, 46.0, 168.0, 0.0, 0.0, 93.0, 57.0, 0.0, 0.0, 1.0, 0.0, 0.0, 72.0, 0.0, 9.0, 1.0, 0.0, 76.0, 47.0, 0.0, 0.0, 3.0, 74.0, 77.0, 105.0, 6.0, 36.0, 72.0, 54.0, 13.0, 0.0, 0.0, 0.0, 46.0, 63.0, 3.0, 55.0, 0.0, 0.0, 63.0, 2.0, 59.0, 11.0, 14.0, 156.0, 61.0, 25.0, 0.0, 22.0, 0.0, 39.0, 21.0, 71.0, 91.0, 181.0, 235.0, 115.0, 115.0, 90.0, 110.0, 92.0, 79.0, 36.0, 35.0, 51.0, 38.0, 52.0, 0.0, 0.0, 2.0, 0.0, 0.0, 18.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5794430335897963, "mean_inference_ms": 1.4753815471742422, "mean_action_processing_ms": 0.25738579464070477, "mean_env_wait_ms": 0.20198058610997274, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003912448883056641, "StateBufferConnector_ms": 0.0036063194274902344, "ViewRequirementAgentConnector_ms": 0.1509917974472046}, "num_episodes": 18, "episode_return_max": 352.29999999999984, "episode_return_min": -366.1999999999997, "episode_return_mean": 76.29599999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 394.04677373865786, "num_env_steps_trained_throughput_per_sec": 394.04677373865786, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 23574.614, "restore_workers_time_ms": 0.014, "training_step_time_ms": 23574.563, "sample_time_ms": 1316.397, "learn_time_ms": 22238.706, "learn_throughput": 179.867, "synch_weights_time_ms": 16.756}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "04dec_00002", "date": "2024-08-13_16-31-10", "timestamp": 1723581070, "time_this_iter_s": 10.191259860992432, "time_total_s": 504.97396540641785, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04613a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 504.97396540641785, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 44.82, "ram_util_percent": 86.56}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8299288206709126, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 3.2864485222195823, "policy_loss": -0.002855196795253842, "vf_loss": 3.28898213805345, "vf_explained_var": 0.005358346934041018, "kl": 0.00508191189122152, "entropy": 1.2171481141968379, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9361150251336827, "cur_kl_coeff": 0.084375, "cur_lr": 0.00010000000000000003, "total_loss": 8.324928960093745, "policy_loss": -0.001143336472244411, "vf_loss": 8.32571993378735, "vf_explained_var": 0.21326907050041927, "kl": 0.004176225579923427, "entropy": 0.9520480260647163, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 362.20000000000005, "episode_reward_min": -366.1999999999997, "episode_reward_mean": 102.09599999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -548.3999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 416.0}, "policy_reward_mean": {"prey_policy": 9.99799999999992, "predator_policy": 41.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.799999999999898, 39.20000000000017, 301.5000000000006, 40.0000000000003, -30.89999999999967, 62.9000000000003, 44.00000000000042, -43.49999999999998, -105.99999999999997, 99.99999999999991, 55.00000000000007, 48.19999999999998, 173.7999999999996, 254.1999999999992, -76.39999999999992, -8.699999999999925, 189.19999999999936, 114.29999999999941, 135.19999999999968, 208.29999999999941, -59.4999999999997, 43.000000000000185, 134.29999999999916, 42.600000000000215, -26.59999999999995, 1.4999999999999711, 29.00000000000027, -123.40000000000018, 352.29999999999984, 114.19999999999965, -366.1999999999997, 116.69999999999956, 56.20000000000032, -88.70000000000016, 124.5999999999988, 160.59999999999923, 121.79999999999939, 81.59999999999992, 182.2, 79.30000000000001, -143.40000000000026, -30.09999999999991, 173.1999999999996, -36.799999999999905, 54.400000000000276, 343.10000000000014, 122.79999999999973, 171.39999999999918, 342.20000000000005, 124.5999999999998, 122.79999999999978, -4.799999999999995, 74.39999999999999, 135.0999999999994, 28.300000000000086, 165.1999999999994, 273.0999999999998, 64.10000000000015, 87.79999999999998, 309.9999999999998, -27.299999999999592, 32.000000000000064, 55.30000000000002, 121.79999999999995, 175.99999999999935, 34.299999999999216, 141.2999999999998, -258.30000000000007, 25.800000000000075, 122.80000000000022, 59.90000000000004, 174.19999999999956, 250.7999999999997, 9.400000000000169, 87.70000000000007, 188.09999999999917, 122.79999999999899, 166.89999999999958, 168.69999999999985, 172.09999999999908, 296.90000000000003, 278.5000000000002, 207.39999999999932, 208.8999999999998, 84.29999999999953, 84.59999999999997, -119.20000000000111, 63.500000000000085, 296.79999999999984, 150.59999999999897, 317.2000000000008, 362.20000000000005, 285.4999999999995, 307.29999999999984, 348.7000000000002, 151.99999999999943, -24.699999999999818, 35.000000000000135, 147.0999999999999, 75.30000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-160.60000000000025, 24.800000000000075, -68.20000000000024, 13.399999999999972, 152.29999999999984, 147.20000000000002, 20.000000000000014, 20.000000000000014, -139.90000000000057, 7.999999999999986, 39.20000000000012, -49.2999999999999, -3.7000000000000153, 13.70000000000001, 5.2999999999999865, -122.8000000000001, -243.40000000000032, -16.59999999999987, 180.7999999999999, -319.7999999999996, -235.50000000000026, 132.50000000000003, 94.39999999999976, -152.2, 21.500000000000064, 71.2999999999999, 120.79999999999953, 133.39999999999995, 68.59999999999988, -295.0000000000001, -122.80000000000014, 46.09999999999997, 98.29999999999968, 89.89999999999968, -29.200000000000166, 69.49999999999966, 17.899999999999988, 116.29999999999998, 137.89999999999975, 70.39999999999972, -73.89999999999993, -97.60000000000036, 112.09999999999968, -171.1000000000002, 34.99999999999987, 71.29999999999997, -183.70000000000022, 122.2999999999997, -139.5999999999999, 20.000000000000014, -41.199999999999804, -43.29999999999999, -1.0000000000000355, 20.000000000000014, -125.50000000000026, -136.9000000000004, 182.89999999999992, 169.39999999999986, 115.39999999999992, -35.200000000000045, -307.59999999999974, -265.60000000000025, 61.100000000000016, 11.59999999999999, 20.900000000000027, 35.300000000000146, -5.200000000000049, -200.50000000000003, 104.59999999999948, 20.000000000000014, 20.000000000000014, 140.59999999999994, -66.10000000000045, 146.8999999999998, -154.30000000000067, 146.8999999999998, 109.09999999999997, 73.09999999999994, 49.40000000000002, -21.09999999999979, -144.40000000000026, -253.00000000000009, -267.40000000000015, 23.299999999999905, 122.59999999999987, 50.600000000000044, 70.3999999999998, -257.2000000000001, 20.000000000000014, 34.39999999999999, 166.69999999999993, 175.39999999999986, -131.2000000000004, 181.99999999999997, 136.09999999999977, 26.300000000000004, 195.2, 146.0, 181.09999999999994, -179.5000000000004, 20.000000000000014, 102.79999999999998, 32.600000000000136, -114.40000000000055, 187.4, -295.0, -5.2000000000000295, 98.29999999999987, 67.39999999999988, -165.10000000000016, 100.99999999999994, 51.20000000000017, 179.29999999999998, 93.80000000000001, 160.40000000000006, -205.30000000000015, 38.90000000000002, -9.099999999999998, 189.19999999999996, 120.80000000000008, -112.3000000000007, 20.000000000000014, 65.90000000000016, -103.90000000000073, -265.20000000000016, 150.5, 94.69999999999997, -58.89999999999999, -26.20000000000002, 180.19999999999993, -40.00000000000004, 35.30000000000015, -83.19999999999999, 132.50000000000006, -289.9000000000002, -240.40000000000003, -437.80000000000007, 113.59999999999948, 84.80000000000001, -166.99999999999994, -284.4999999999994, 142.39999999999998, -112.59999999999988, 171.79999999999995, -22.600000000000158, 187.39999999999998, -59.80000000000004, -20.79999999999992, 66.80000000000001, 20.900000000000027, 15.800000000000002, 170.29999999999987, 93.19999999999959, 11.599999999999966, 137.89999999999998, 29.000000000000075, 173.8999999999999, -263.19999999999993, 65.89999999999999, 96.19999999999982, 86.3, 176.59999999999997, 154.1, 124.39999999999955, 187.4, 20.000000000000014, 76.70000000000005, 99.2, -166.90000000000003, 162.19999999999976, -278.19999999999993, 147.8, -191.20000000000056, -85.0000000000002, -366.0, 102.49999999999966, 151.39999999999986, 124.4, 20.000000000000014, 125.59999999999965, 154.9999999999998, 162.19999999999985, 194.59999999999997, 167.59999999999994, 130.4000000000001, 154.0999999999999, 198.2, 109.1, 199.1, 149.59999999999985, 77.00000000000003, 20.000000000000014, -19.900000000000013, -146.79999999999995, 20.000000000000014, -125.0000000000001, -548.3999999999996, 186.5, -124.9000000000004, 78.19999999999999], "policy_predator_policy_reward": [73.0, 37.0, 75.0, 19.0, 0.0, 2.0, 0.0, 0.0, 83.0, 18.0, 25.0, 48.0, 26.0, 8.0, 6.0, 68.0, 52.0, 102.0, 140.0, 99.0, 158.0, 0.0, 92.0, 14.0, 35.0, 46.0, 0.0, 0.0, 0.0, 150.0, 0.0, 68.0, 1.0, 0.0, 0.0, 74.0, 1.0, 0.0, 0.0, 0.0, 45.0, 67.0, 0.0, 102.0, 0.0, 28.0, 0.0, 104.0, 76.0, 17.0, 60.0, 26.0, 0.0, 10.0, 79.0, 60.0, 0.0, 0.0, 18.0, 16.0, 180.0, 27.0, 44.0, 0.0, 0.0, 0.0, 105.0, 12.0, 0.0, 0.0, 0.0, 0.0, 38.0, 3.0, 6.0, 83.0, 0.0, 0.0, 51.0, 0.0, 93.0, 161.0, 46.0, 168.0, 0.0, 0.0, 93.0, 57.0, 0.0, 0.0, 1.0, 0.0, 0.0, 72.0, 0.0, 9.0, 1.0, 0.0, 76.0, 47.0, 0.0, 0.0, 3.0, 74.0, 77.0, 105.0, 6.0, 36.0, 72.0, 54.0, 13.0, 0.0, 0.0, 0.0, 46.0, 63.0, 3.0, 55.0, 0.0, 0.0, 63.0, 2.0, 59.0, 11.0, 14.0, 156.0, 61.0, 25.0, 0.0, 22.0, 0.0, 39.0, 21.0, 71.0, 91.0, 181.0, 235.0, 115.0, 115.0, 90.0, 110.0, 92.0, 79.0, 36.0, 35.0, 51.0, 38.0, 52.0, 0.0, 0.0, 2.0, 0.0, 0.0, 18.0, 0.0, 0.0, 109.0, 149.0, 6.0, 4.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 1.0, 32.0, 0.0, 89.0, 84.0, 131.0, 84.0, 73.0, 146.0, 181.0, 0.0, 21.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 73.0, 69.0, 77.0, 63.0, 416.0, 93.0, 53.0, 69.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5815469630129967, "mean_inference_ms": 1.4807709457402785, "mean_action_processing_ms": 0.2573280636767157, "mean_env_wait_ms": 0.20294028599779965, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003896474838256836, "StateBufferConnector_ms": 0.0036803483963012695, "ViewRequirementAgentConnector_ms": 0.1003565788269043}, "num_episodes": 22, "episode_return_max": 362.20000000000005, "episode_return_min": -366.1999999999997, "episode_return_mean": 102.09599999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.8361369345604, "num_env_steps_trained_throughput_per_sec": 416.8361369345604, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 23647.604, "restore_workers_time_ms": 0.014, "training_step_time_ms": 23647.556, "sample_time_ms": 1343.265, "learn_time_ms": 22284.404, "learn_throughput": 179.498, "synch_weights_time_ms": 17.128}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "04dec_00002", "date": "2024-08-13_16-31-19", "timestamp": 1723581079, "time_this_iter_s": 9.657779932022095, "time_total_s": 514.6317453384399, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359c040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 514.6317453384399, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 42.25714285714286, "ram_util_percent": 86.55714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9801762485236087, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 3.6302081293529933, "policy_loss": -0.005873106195586462, "vf_loss": 3.6351573151886147, "vf_explained_var": -0.0003911238814157153, "kl": 0.014600390655691029, "entropy": 1.171476558087364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8023990696857846, "cur_kl_coeff": 0.0421875, "cur_lr": 0.00010000000000000003, "total_loss": 8.529998678378957, "policy_loss": -0.003510653413339424, "vf_loss": 8.533304344409357, "vf_explained_var": 0.2263164843516375, "kl": 0.004858454023397365, "entropy": 0.9734532649554903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 374.10000000000014, "episode_reward_min": -366.1999999999997, "episode_reward_mean": 122.55399999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -548.3999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 416.0}, "policy_reward_mean": {"prey_policy": 21.30699999999992, "predator_policy": 39.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.600000000000215, -26.59999999999995, 1.4999999999999711, 29.00000000000027, -123.40000000000018, 352.29999999999984, 114.19999999999965, -366.1999999999997, 116.69999999999956, 56.20000000000032, -88.70000000000016, 124.5999999999988, 160.59999999999923, 121.79999999999939, 81.59999999999992, 182.2, 79.30000000000001, -143.40000000000026, -30.09999999999991, 173.1999999999996, -36.799999999999905, 54.400000000000276, 343.10000000000014, 122.79999999999973, 171.39999999999918, 342.20000000000005, 124.5999999999998, 122.79999999999978, -4.799999999999995, 74.39999999999999, 135.0999999999994, 28.300000000000086, 165.1999999999994, 273.0999999999998, 64.10000000000015, 87.79999999999998, 309.9999999999998, -27.299999999999592, 32.000000000000064, 55.30000000000002, 121.79999999999995, 175.99999999999935, 34.299999999999216, 141.2999999999998, -258.30000000000007, 25.800000000000075, 122.80000000000022, 59.90000000000004, 174.19999999999956, 250.7999999999997, 9.400000000000169, 87.70000000000007, 188.09999999999917, 122.79999999999899, 166.89999999999958, 168.69999999999985, 172.09999999999908, 296.90000000000003, 278.5000000000002, 207.39999999999932, 208.8999999999998, 84.29999999999953, 84.59999999999997, -119.20000000000111, 63.500000000000085, 296.79999999999984, 150.59999999999897, 317.2000000000008, 362.20000000000005, 285.4999999999995, 307.29999999999984, 348.7000000000002, 151.99999999999943, -24.699999999999818, 35.000000000000135, 147.0999999999999, 75.30000000000004, 126.09999999999982, -18.99999999999976, 101.19999999999987, 203.69999999999928, 230.79999999999964, 149.69999999999948, 101.5999999999999, 186.59999999999943, 163.0, 85.10000000000005, 88.69999999999936, 53.8000000000003, -57.79999999999997, 98.59999999999962, 123.49999999999986, 157.99999999999955, 320.80000000000047, 293.50000000000006, 123.59999999999974, 279.1000000000004, 137.79999999999984, 374.10000000000014, 315.59999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-183.70000000000022, 122.2999999999997, -139.5999999999999, 20.000000000000014, -41.199999999999804, -43.29999999999999, -1.0000000000000355, 20.000000000000014, -125.50000000000026, -136.9000000000004, 182.89999999999992, 169.39999999999986, 115.39999999999992, -35.200000000000045, -307.59999999999974, -265.60000000000025, 61.100000000000016, 11.59999999999999, 20.900000000000027, 35.300000000000146, -5.200000000000049, -200.50000000000003, 104.59999999999948, 20.000000000000014, 20.000000000000014, 140.59999999999994, -66.10000000000045, 146.8999999999998, -154.30000000000067, 146.8999999999998, 109.09999999999997, 73.09999999999994, 49.40000000000002, -21.09999999999979, -144.40000000000026, -253.00000000000009, -267.40000000000015, 23.299999999999905, 122.59999999999987, 50.600000000000044, 70.3999999999998, -257.2000000000001, 20.000000000000014, 34.39999999999999, 166.69999999999993, 175.39999999999986, -131.2000000000004, 181.99999999999997, 136.09999999999977, 26.300000000000004, 195.2, 146.0, 181.09999999999994, -179.5000000000004, 20.000000000000014, 102.79999999999998, 32.600000000000136, -114.40000000000055, 187.4, -295.0, -5.2000000000000295, 98.29999999999987, 67.39999999999988, -165.10000000000016, 100.99999999999994, 51.20000000000017, 179.29999999999998, 93.80000000000001, 160.40000000000006, -205.30000000000015, 38.90000000000002, -9.099999999999998, 189.19999999999996, 120.80000000000008, -112.3000000000007, 20.000000000000014, 65.90000000000016, -103.90000000000073, -265.20000000000016, 150.5, 94.69999999999997, -58.89999999999999, -26.20000000000002, 180.19999999999993, -40.00000000000004, 35.30000000000015, -83.19999999999999, 132.50000000000006, -289.9000000000002, -240.40000000000003, -437.80000000000007, 113.59999999999948, 84.80000000000001, -166.99999999999994, -284.4999999999994, 142.39999999999998, -112.59999999999988, 171.79999999999995, -22.600000000000158, 187.39999999999998, -59.80000000000004, -20.79999999999992, 66.80000000000001, 20.900000000000027, 15.800000000000002, 170.29999999999987, 93.19999999999959, 11.599999999999966, 137.89999999999998, 29.000000000000075, 173.8999999999999, -263.19999999999993, 65.89999999999999, 96.19999999999982, 86.3, 176.59999999999997, 154.1, 124.39999999999955, 187.4, 20.000000000000014, 76.70000000000005, 99.2, -166.90000000000003, 162.19999999999976, -278.19999999999993, 147.8, -191.20000000000056, -85.0000000000002, -366.0, 102.49999999999966, 151.39999999999986, 124.4, 20.000000000000014, 125.59999999999965, 154.9999999999998, 162.19999999999985, 194.59999999999997, 167.59999999999994, 130.4000000000001, 154.0999999999999, 198.2, 109.1, 199.1, 149.59999999999985, 77.00000000000003, 20.000000000000014, -19.900000000000013, -146.79999999999995, 20.000000000000014, -125.0000000000001, -548.3999999999996, 186.5, -124.9000000000004, 78.19999999999999, 134.0, -124.90000000000003, -21.999999999999982, -21.99999999999997, -206.80000000000027, 200.0, 178.69999999999996, 20.000000000000014, 54.8, 166.99999999999997, 164.59999999999994, -61.90000000000017, 86.59999999999997, -10.000000000000004, 200.0, -72.40000000000089, 74.0, 13.999999999999972, 86.3, -83.20000000000024, 75.49999999999969, -38.79999999999983, 75.79999999999998, -85.00000000000006, -126.50000000000013, -459.29999999999995, -89.20000000000083, 102.79999999999973, 25.100000000000165, 79.4, -68.20000000000061, 177.2, 180.19999999999993, 140.59999999999962, 181.1, 79.4, 165.2, -118.60000000000025, 117.19999999999985, 146.89999999999995, 65.9, 29.900000000000027, 192.79999999999995, 173.3, 162.2, 130.4], "policy_predator_policy_reward": [0.0, 104.0, 76.0, 17.0, 60.0, 26.0, 0.0, 10.0, 79.0, 60.0, 0.0, 0.0, 18.0, 16.0, 180.0, 27.0, 44.0, 0.0, 0.0, 0.0, 105.0, 12.0, 0.0, 0.0, 0.0, 0.0, 38.0, 3.0, 6.0, 83.0, 0.0, 0.0, 51.0, 0.0, 93.0, 161.0, 46.0, 168.0, 0.0, 0.0, 93.0, 57.0, 0.0, 0.0, 1.0, 0.0, 0.0, 72.0, 0.0, 9.0, 1.0, 0.0, 76.0, 47.0, 0.0, 0.0, 3.0, 74.0, 77.0, 105.0, 6.0, 36.0, 72.0, 54.0, 13.0, 0.0, 0.0, 0.0, 46.0, 63.0, 3.0, 55.0, 0.0, 0.0, 63.0, 2.0, 59.0, 11.0, 14.0, 156.0, 61.0, 25.0, 0.0, 22.0, 0.0, 39.0, 21.0, 71.0, 91.0, 181.0, 235.0, 115.0, 115.0, 90.0, 110.0, 92.0, 79.0, 36.0, 35.0, 51.0, 38.0, 52.0, 0.0, 0.0, 2.0, 0.0, 0.0, 18.0, 0.0, 0.0, 109.0, 149.0, 6.0, 4.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 1.0, 32.0, 0.0, 89.0, 84.0, 131.0, 84.0, 73.0, 146.0, 181.0, 0.0, 21.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 73.0, 69.0, 77.0, 63.0, 416.0, 93.0, 53.0, 69.0, 29.0, 88.0, 25.0, 0.0, 15.0, 93.0, 0.0, 5.0, 9.0, 0.0, 35.0, 12.0, 9.0, 16.0, 43.0, 16.0, 0.0, 75.0, 82.0, 0.0, 40.0, 12.0, 22.0, 41.0, 179.0, 349.0, 50.0, 35.0, 16.0, 3.0, 7.0, 42.0, 0.0, 0.0, 0.0, 33.0, 47.0, 30.0, 0.0, 15.0, 42.0, 0.0, 8.0, 0.0, 8.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5836336208933964, "mean_inference_ms": 1.4865852063135427, "mean_action_processing_ms": 0.2578936574267858, "mean_env_wait_ms": 0.20387032726705548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003895998001098633, "StateBufferConnector_ms": 0.0033571720123291016, "ViewRequirementAgentConnector_ms": 0.1000286340713501}, "num_episodes": 23, "episode_return_max": 374.10000000000014, "episode_return_min": -366.1999999999997, "episode_return_mean": 122.55399999999985, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.52439261758565, "num_env_steps_trained_throughput_per_sec": 416.52439261758565, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 23705.319, "restore_workers_time_ms": 0.016, "training_step_time_ms": 23705.269, "sample_time_ms": 1361.944, "learn_time_ms": 22323.252, "learn_throughput": 179.185, "synch_weights_time_ms": 17.388}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "04dec_00002", "date": "2024-08-13_16-31-29", "timestamp": 1723581089, "time_this_iter_s": 9.637779951095581, "time_total_s": 524.2695252895355, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359ddc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 524.2695252895355, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 38.776923076923076, "ram_util_percent": 86.04615384615384}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7406687258885651, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.8090174369711094, "policy_loss": -0.005914650090216171, "vf_loss": 2.8141517268917546, "vf_explained_var": 0.01229507604604045, "kl": 0.012331579226774463, "entropy": 1.0639193375589986, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.843286528505345, "cur_kl_coeff": 0.02109375, "cur_lr": 0.00010000000000000003, "total_loss": 8.022343703678676, "policy_loss": -0.007012110076125258, "vf_loss": 8.0289564783611, "vf_explained_var": 0.14229624807519256, "kl": 0.018930930689044837, "entropy": 0.9352057456339478, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 388.09999999999997, "episode_reward_min": -258.30000000000007, "episode_reward_mean": 138.26999999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -548.3999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 416.0}, "policy_reward_mean": {"prey_policy": 29.68499999999993, "predator_policy": 39.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.09999999999991, 173.1999999999996, -36.799999999999905, 54.400000000000276, 343.10000000000014, 122.79999999999973, 171.39999999999918, 342.20000000000005, 124.5999999999998, 122.79999999999978, -4.799999999999995, 74.39999999999999, 135.0999999999994, 28.300000000000086, 165.1999999999994, 273.0999999999998, 64.10000000000015, 87.79999999999998, 309.9999999999998, -27.299999999999592, 32.000000000000064, 55.30000000000002, 121.79999999999995, 175.99999999999935, 34.299999999999216, 141.2999999999998, -258.30000000000007, 25.800000000000075, 122.80000000000022, 59.90000000000004, 174.19999999999956, 250.7999999999997, 9.400000000000169, 87.70000000000007, 188.09999999999917, 122.79999999999899, 166.89999999999958, 168.69999999999985, 172.09999999999908, 296.90000000000003, 278.5000000000002, 207.39999999999932, 208.8999999999998, 84.29999999999953, 84.59999999999997, -119.20000000000111, 63.500000000000085, 296.79999999999984, 150.59999999999897, 317.2000000000008, 362.20000000000005, 285.4999999999995, 307.29999999999984, 348.7000000000002, 151.99999999999943, -24.699999999999818, 35.000000000000135, 147.0999999999999, 75.30000000000004, 126.09999999999982, -18.99999999999976, 101.19999999999987, 203.69999999999928, 230.79999999999964, 149.69999999999948, 101.5999999999999, 186.59999999999943, 163.0, 85.10000000000005, 88.69999999999936, 53.8000000000003, -57.79999999999997, 98.59999999999962, 123.49999999999986, 157.99999999999955, 320.80000000000047, 293.50000000000006, 123.59999999999974, 279.1000000000004, 137.79999999999984, 374.10000000000014, 315.59999999999997, 308.3, 388.09999999999997, 10.399999999999972, 151.6999999999997, 183.29999999999944, 344.2000000000014, -180.60000000000105, 247.89999999999944, 193.89999999999932, 36.8, -64.40000000000063, 136.10000000000016, 20.20000000000004, 293.69999999999993, 195.6999999999993, 22.40000000000012, 177.0, -178.80000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-267.40000000000015, 23.299999999999905, 122.59999999999987, 50.600000000000044, 70.3999999999998, -257.2000000000001, 20.000000000000014, 34.39999999999999, 166.69999999999993, 175.39999999999986, -131.2000000000004, 181.99999999999997, 136.09999999999977, 26.300000000000004, 195.2, 146.0, 181.09999999999994, -179.5000000000004, 20.000000000000014, 102.79999999999998, 32.600000000000136, -114.40000000000055, 187.4, -295.0, -5.2000000000000295, 98.29999999999987, 67.39999999999988, -165.10000000000016, 100.99999999999994, 51.20000000000017, 179.29999999999998, 93.80000000000001, 160.40000000000006, -205.30000000000015, 38.90000000000002, -9.099999999999998, 189.19999999999996, 120.80000000000008, -112.3000000000007, 20.000000000000014, 65.90000000000016, -103.90000000000073, -265.20000000000016, 150.5, 94.69999999999997, -58.89999999999999, -26.20000000000002, 180.19999999999993, -40.00000000000004, 35.30000000000015, -83.19999999999999, 132.50000000000006, -289.9000000000002, -240.40000000000003, -437.80000000000007, 113.59999999999948, 84.80000000000001, -166.99999999999994, -284.4999999999994, 142.39999999999998, -112.59999999999988, 171.79999999999995, -22.600000000000158, 187.39999999999998, -59.80000000000004, -20.79999999999992, 66.80000000000001, 20.900000000000027, 15.800000000000002, 170.29999999999987, 93.19999999999959, 11.599999999999966, 137.89999999999998, 29.000000000000075, 173.8999999999999, -263.19999999999993, 65.89999999999999, 96.19999999999982, 86.3, 176.59999999999997, 154.1, 124.39999999999955, 187.4, 20.000000000000014, 76.70000000000005, 99.2, -166.90000000000003, 162.19999999999976, -278.19999999999993, 147.8, -191.20000000000056, -85.0000000000002, -366.0, 102.49999999999966, 151.39999999999986, 124.4, 20.000000000000014, 125.59999999999965, 154.9999999999998, 162.19999999999985, 194.59999999999997, 167.59999999999994, 130.4000000000001, 154.0999999999999, 198.2, 109.1, 199.1, 149.59999999999985, 77.00000000000003, 20.000000000000014, -19.900000000000013, -146.79999999999995, 20.000000000000014, -125.0000000000001, -548.3999999999996, 186.5, -124.9000000000004, 78.19999999999999, 134.0, -124.90000000000003, -21.999999999999982, -21.99999999999997, -206.80000000000027, 200.0, 178.69999999999996, 20.000000000000014, 54.8, 166.99999999999997, 164.59999999999994, -61.90000000000017, 86.59999999999997, -10.000000000000004, 200.0, -72.40000000000089, 74.0, 13.999999999999972, 86.3, -83.20000000000024, 75.49999999999969, -38.79999999999983, 75.79999999999998, -85.00000000000006, -126.50000000000013, -459.29999999999995, -89.20000000000083, 102.79999999999973, 25.100000000000165, 79.4, -68.20000000000061, 177.2, 180.19999999999993, 140.59999999999962, 181.1, 79.4, 165.2, -118.60000000000025, 117.19999999999985, 146.89999999999995, 65.9, 29.900000000000027, 192.79999999999995, 173.3, 162.2, 130.4, 122.30000000000001, 158.0, 190.10000000000002, 197.0, -201.10000000000022, -11.500000000000044, 7.999999999999987, 85.69999999999996, -21.999999999999975, 179.3, 193.69999999999996, 150.4999999999997, -137.50000000000057, -182.10000000000053, 172.09999999999982, 75.79999999999997, 193.69999999999996, -17.79999999999974, -34.30000000000001, -46.900000000000006, -174.4, -42.99999999999978, 81.79999999999998, 53.29999999999998, 31.400000000000247, -47.199999999999804, 63.5, 189.2, 20.000000000000014, 175.69999999999996, 20.000000000000014, -13.599999999999968, 134.0, -52.0, -259.8999999999994, -130.9], "policy_predator_policy_reward": [46.0, 168.0, 0.0, 0.0, 93.0, 57.0, 0.0, 0.0, 1.0, 0.0, 0.0, 72.0, 0.0, 9.0, 1.0, 0.0, 76.0, 47.0, 0.0, 0.0, 3.0, 74.0, 77.0, 105.0, 6.0, 36.0, 72.0, 54.0, 13.0, 0.0, 0.0, 0.0, 46.0, 63.0, 3.0, 55.0, 0.0, 0.0, 63.0, 2.0, 59.0, 11.0, 14.0, 156.0, 61.0, 25.0, 0.0, 22.0, 0.0, 39.0, 21.0, 71.0, 91.0, 181.0, 235.0, 115.0, 115.0, 90.0, 110.0, 92.0, 79.0, 36.0, 35.0, 51.0, 38.0, 52.0, 0.0, 0.0, 2.0, 0.0, 0.0, 18.0, 0.0, 0.0, 109.0, 149.0, 6.0, 4.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 1.0, 32.0, 0.0, 89.0, 84.0, 131.0, 84.0, 73.0, 146.0, 181.0, 0.0, 21.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 73.0, 69.0, 77.0, 63.0, 416.0, 93.0, 53.0, 69.0, 29.0, 88.0, 25.0, 0.0, 15.0, 93.0, 0.0, 5.0, 9.0, 0.0, 35.0, 12.0, 9.0, 16.0, 43.0, 16.0, 0.0, 75.0, 82.0, 0.0, 40.0, 12.0, 22.0, 41.0, 179.0, 349.0, 50.0, 35.0, 16.0, 3.0, 7.0, 42.0, 0.0, 0.0, 0.0, 33.0, 47.0, 30.0, 0.0, 15.0, 42.0, 0.0, 8.0, 0.0, 8.0, 15.0, 28.0, 0.0, 1.0, 0.0, 108.0, 115.0, 39.0, 19.0, 0.0, 26.0, 0.0, 0.0, 44.0, 95.0, 0.0, 0.0, 18.0, 0.0, 33.0, 85.0, 123.0, 30.0, 1.0, 0.0, 27.0, 9.0, 0.0, 41.0, 0.0, 0.0, 16.0, 0.0, 75.0, 20.0, 58.0, 154.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5841598979537814, "mean_inference_ms": 1.4896117333312953, "mean_action_processing_ms": 0.257345915422261, "mean_env_wait_ms": 0.20445719611285362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039882659912109375, "StateBufferConnector_ms": 0.0034110546112060547, "ViewRequirementAgentConnector_ms": 0.10311758518218994}, "num_episodes": 18, "episode_return_max": 388.09999999999997, "episode_return_min": -258.30000000000007, "episode_return_mean": 138.26999999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 392.9151957907725, "num_env_steps_trained_throughput_per_sec": 392.9151957907725, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 23781.787, "restore_workers_time_ms": 0.017, "training_step_time_ms": 23781.735, "sample_time_ms": 1400.937, "learn_time_ms": 22361.56, "learn_throughput": 178.878, "synch_weights_time_ms": 16.78}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "04dec_00002", "date": "2024-08-13_16-31-39", "timestamp": 1723581099, "time_this_iter_s": 10.209574937820435, "time_total_s": 534.479100227356, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a7280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 534.479100227356, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 43.986666666666665, "ram_util_percent": 86.51333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8449758243860391, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 1.4253485194274358, "policy_loss": -0.004932946620740627, "vf_loss": 1.4297200426222787, "vf_explained_var": 0.035570770375943056, "kl": 0.008871841067162609, "entropy": 1.057387802588246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.817975524935142, "cur_kl_coeff": 0.02109375, "cur_lr": 0.00010000000000000003, "total_loss": 7.500651430452942, "policy_loss": -0.001348848962693145, "vf_loss": 7.501928336027438, "vf_explained_var": 0.36787921411019786, "kl": 0.0034109279434183216, "entropy": 0.9095351598250172, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 388.09999999999997, "episode_reward_min": -258.30000000000007, "episode_reward_mean": 151.8409999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -548.3999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 416.0}, "policy_reward_mean": {"prey_policy": 40.180499999999945, "predator_policy": 35.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [309.9999999999998, -27.299999999999592, 32.000000000000064, 55.30000000000002, 121.79999999999995, 175.99999999999935, 34.299999999999216, 141.2999999999998, -258.30000000000007, 25.800000000000075, 122.80000000000022, 59.90000000000004, 174.19999999999956, 250.7999999999997, 9.400000000000169, 87.70000000000007, 188.09999999999917, 122.79999999999899, 166.89999999999958, 168.69999999999985, 172.09999999999908, 296.90000000000003, 278.5000000000002, 207.39999999999932, 208.8999999999998, 84.29999999999953, 84.59999999999997, -119.20000000000111, 63.500000000000085, 296.79999999999984, 150.59999999999897, 317.2000000000008, 362.20000000000005, 285.4999999999995, 307.29999999999984, 348.7000000000002, 151.99999999999943, -24.699999999999818, 35.000000000000135, 147.0999999999999, 75.30000000000004, 126.09999999999982, -18.99999999999976, 101.19999999999987, 203.69999999999928, 230.79999999999964, 149.69999999999948, 101.5999999999999, 186.59999999999943, 163.0, 85.10000000000005, 88.69999999999936, 53.8000000000003, -57.79999999999997, 98.59999999999962, 123.49999999999986, 157.99999999999955, 320.80000000000047, 293.50000000000006, 123.59999999999974, 279.1000000000004, 137.79999999999984, 374.10000000000014, 315.59999999999997, 308.3, 388.09999999999997, 10.399999999999972, 151.6999999999997, 183.29999999999944, 344.2000000000014, -180.60000000000105, 247.89999999999944, 193.89999999999932, 36.8, -64.40000000000063, 136.10000000000016, 20.20000000000004, 293.69999999999993, 195.6999999999993, 22.40000000000012, 177.0, -178.80000000000018, 272.1999999999997, 211.29999999999927, 82.70000000000003, 194.69999999999933, 349.49999999999994, 335.2000000000006, 110.30000000000007, 350.5, 134.59999999999968, 204.29999999999927, 32.30000000000019, 283.89999999999986, 136.19999999999968, 71.80000000000011, 298.49999999999994, 167.2999999999995, 235.69999999999982, 96.89999999999893], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [189.19999999999996, 120.80000000000008, -112.3000000000007, 20.000000000000014, 65.90000000000016, -103.90000000000073, -265.20000000000016, 150.5, 94.69999999999997, -58.89999999999999, -26.20000000000002, 180.19999999999993, -40.00000000000004, 35.30000000000015, -83.19999999999999, 132.50000000000006, -289.9000000000002, -240.40000000000003, -437.80000000000007, 113.59999999999948, 84.80000000000001, -166.99999999999994, -284.4999999999994, 142.39999999999998, -112.59999999999988, 171.79999999999995, -22.600000000000158, 187.39999999999998, -59.80000000000004, -20.79999999999992, 66.80000000000001, 20.900000000000027, 15.800000000000002, 170.29999999999987, 93.19999999999959, 11.599999999999966, 137.89999999999998, 29.000000000000075, 173.8999999999999, -263.19999999999993, 65.89999999999999, 96.19999999999982, 86.3, 176.59999999999997, 154.1, 124.39999999999955, 187.4, 20.000000000000014, 76.70000000000005, 99.2, -166.90000000000003, 162.19999999999976, -278.19999999999993, 147.8, -191.20000000000056, -85.0000000000002, -366.0, 102.49999999999966, 151.39999999999986, 124.4, 20.000000000000014, 125.59999999999965, 154.9999999999998, 162.19999999999985, 194.59999999999997, 167.59999999999994, 130.4000000000001, 154.0999999999999, 198.2, 109.1, 199.1, 149.59999999999985, 77.00000000000003, 20.000000000000014, -19.900000000000013, -146.79999999999995, 20.000000000000014, -125.0000000000001, -548.3999999999996, 186.5, -124.9000000000004, 78.19999999999999, 134.0, -124.90000000000003, -21.999999999999982, -21.99999999999997, -206.80000000000027, 200.0, 178.69999999999996, 20.000000000000014, 54.8, 166.99999999999997, 164.59999999999994, -61.90000000000017, 86.59999999999997, -10.000000000000004, 200.0, -72.40000000000089, 74.0, 13.999999999999972, 86.3, -83.20000000000024, 75.49999999999969, -38.79999999999983, 75.79999999999998, -85.00000000000006, -126.50000000000013, -459.29999999999995, -89.20000000000083, 102.79999999999973, 25.100000000000165, 79.4, -68.20000000000061, 177.2, 180.19999999999993, 140.59999999999962, 181.1, 79.4, 165.2, -118.60000000000025, 117.19999999999985, 146.89999999999995, 65.9, 29.900000000000027, 192.79999999999995, 173.3, 162.2, 130.4, 122.30000000000001, 158.0, 190.10000000000002, 197.0, -201.10000000000022, -11.500000000000044, 7.999999999999987, 85.69999999999996, -21.999999999999975, 179.3, 193.69999999999996, 150.4999999999997, -137.50000000000057, -182.10000000000053, 172.09999999999982, 75.79999999999997, 193.69999999999996, -17.79999999999974, -34.30000000000001, -46.900000000000006, -174.4, -42.99999999999978, 81.79999999999998, 53.29999999999998, 31.400000000000247, -47.199999999999804, 63.5, 189.2, 20.000000000000014, 175.69999999999996, 20.000000000000014, -13.599999999999968, 134.0, -52.0, -259.8999999999994, -130.9, 82.09999999999997, 190.1, 188.29999999999998, 20.000000000000014, 89.29999999999993, -34.59999999999975, 169.69999999999996, 20.000000000000014, 177.50000000000003, 158.0, 173.9, 161.29999999999984, 60.499999999999964, -29.20000000000003, 156.8, 193.7, 3.199999999999975, 85.39999999999998, 25.100000000000108, 159.2, 5.299999999999965, 20.000000000000014, 108.19999999999999, 175.69999999999996, -109.30000000000001, 150.5, -34.59999999999977, 76.39999999999998, 135.8, 139.70000000000002, 5.2999999999999705, 155.0, 178.10000000000002, -3.399999999999995, -5.199999999999962, 85.0999999999995], "policy_predator_policy_reward": [0.0, 0.0, 63.0, 2.0, 59.0, 11.0, 14.0, 156.0, 61.0, 25.0, 0.0, 22.0, 0.0, 39.0, 21.0, 71.0, 91.0, 181.0, 235.0, 115.0, 115.0, 90.0, 110.0, 92.0, 79.0, 36.0, 35.0, 51.0, 38.0, 52.0, 0.0, 0.0, 2.0, 0.0, 0.0, 18.0, 0.0, 0.0, 109.0, 149.0, 6.0, 4.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 1.0, 32.0, 0.0, 89.0, 84.0, 131.0, 84.0, 73.0, 146.0, 181.0, 0.0, 21.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 73.0, 69.0, 77.0, 63.0, 416.0, 93.0, 53.0, 69.0, 29.0, 88.0, 25.0, 0.0, 15.0, 93.0, 0.0, 5.0, 9.0, 0.0, 35.0, 12.0, 9.0, 16.0, 43.0, 16.0, 0.0, 75.0, 82.0, 0.0, 40.0, 12.0, 22.0, 41.0, 179.0, 349.0, 50.0, 35.0, 16.0, 3.0, 7.0, 42.0, 0.0, 0.0, 0.0, 33.0, 47.0, 30.0, 0.0, 15.0, 42.0, 0.0, 8.0, 0.0, 8.0, 15.0, 28.0, 0.0, 1.0, 0.0, 108.0, 115.0, 39.0, 19.0, 0.0, 26.0, 0.0, 0.0, 44.0, 95.0, 0.0, 0.0, 18.0, 0.0, 33.0, 85.0, 123.0, 30.0, 1.0, 0.0, 27.0, 9.0, 0.0, 41.0, 0.0, 0.0, 16.0, 0.0, 75.0, 20.0, 58.0, 154.0, 0.0, 0.0, 3.0, 0.0, 11.0, 17.0, 3.0, 2.0, 14.0, 0.0, 0.0, 0.0, 47.0, 32.0, 0.0, 0.0, 7.0, 39.0, 14.0, 6.0, 4.0, 3.0, 0.0, 0.0, 40.0, 55.0, 25.0, 5.0, 0.0, 23.0, 7.0, 0.0, 57.0, 4.0, 12.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5854086516074192, "mean_inference_ms": 1.4940118161943712, "mean_action_processing_ms": 0.257309942875878, "mean_env_wait_ms": 0.2050275509137512, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004012703895568848, "StateBufferConnector_ms": 0.0034389495849609375, "ViewRequirementAgentConnector_ms": 0.10576796531677246}, "num_episodes": 18, "episode_return_max": 388.09999999999997, "episode_return_min": -258.30000000000007, "episode_return_mean": 151.8409999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.0679501185644, "num_env_steps_trained_throughput_per_sec": 380.0679501185644, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 23778.657, "restore_workers_time_ms": 0.017, "training_step_time_ms": 23778.605, "sample_time_ms": 1389.91, "learn_time_ms": 22368.895, "learn_throughput": 178.82, "synch_weights_time_ms": 16.871}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "04dec_00002", "date": "2024-08-13_16-31-50", "timestamp": 1723581110, "time_this_iter_s": 10.564457893371582, "time_total_s": 545.0435581207275, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359c040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 545.0435581207275, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 46.42, "ram_util_percent": 86.67333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.933204840998801, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.4662927776417405, "policy_loss": -0.007620714472547647, "vf_loss": 2.472863258571221, "vf_explained_var": 0.023537660055059605, "kl": 0.016596372567925732, "entropy": 1.0176355124466003, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.028378047261919, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 7.307049855227193, "policy_loss": -0.0003850328430493988, "vf_loss": 7.30736336506233, "vf_explained_var": 0.3371128931878105, "kl": 0.006781558558034909, "entropy": 0.9068238345088151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 388.09999999999997, "episode_reward_min": -180.60000000000105, "episode_reward_mean": 169.82899999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -548.3999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 416.0}, "policy_reward_mean": {"prey_policy": 55.17449999999995, "predator_policy": 29.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [166.89999999999958, 168.69999999999985, 172.09999999999908, 296.90000000000003, 278.5000000000002, 207.39999999999932, 208.8999999999998, 84.29999999999953, 84.59999999999997, -119.20000000000111, 63.500000000000085, 296.79999999999984, 150.59999999999897, 317.2000000000008, 362.20000000000005, 285.4999999999995, 307.29999999999984, 348.7000000000002, 151.99999999999943, -24.699999999999818, 35.000000000000135, 147.0999999999999, 75.30000000000004, 126.09999999999982, -18.99999999999976, 101.19999999999987, 203.69999999999928, 230.79999999999964, 149.69999999999948, 101.5999999999999, 186.59999999999943, 163.0, 85.10000000000005, 88.69999999999936, 53.8000000000003, -57.79999999999997, 98.59999999999962, 123.49999999999986, 157.99999999999955, 320.80000000000047, 293.50000000000006, 123.59999999999974, 279.1000000000004, 137.79999999999984, 374.10000000000014, 315.59999999999997, 308.3, 388.09999999999997, 10.399999999999972, 151.6999999999997, 183.29999999999944, 344.2000000000014, -180.60000000000105, 247.89999999999944, 193.89999999999932, 36.8, -64.40000000000063, 136.10000000000016, 20.20000000000004, 293.69999999999993, 195.6999999999993, 22.40000000000012, 177.0, -178.80000000000018, 272.1999999999997, 211.29999999999927, 82.70000000000003, 194.69999999999933, 349.49999999999994, 335.2000000000006, 110.30000000000007, 350.5, 134.59999999999968, 204.29999999999927, 32.30000000000019, 283.89999999999986, 136.19999999999968, 71.80000000000011, 298.49999999999994, 167.2999999999995, 235.69999999999982, 96.89999999999893, 201.09999999999926, -46.69999999999972, 189.29999999999936, 185.19999999999942, 135.69999999999942, 103.29999999999978, 177.69999999999948, 300.5999999999999, 382.9, 311.2, 385.6000000000001, 169.9999999999993, 340.4999999999999, 201.49999999999997, 18.800000000000136, 347.5, 50.6000000000001, -29.40000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [137.89999999999998, 29.000000000000075, 173.8999999999999, -263.19999999999993, 65.89999999999999, 96.19999999999982, 86.3, 176.59999999999997, 154.1, 124.39999999999955, 187.4, 20.000000000000014, 76.70000000000005, 99.2, -166.90000000000003, 162.19999999999976, -278.19999999999993, 147.8, -191.20000000000056, -85.0000000000002, -366.0, 102.49999999999966, 151.39999999999986, 124.4, 20.000000000000014, 125.59999999999965, 154.9999999999998, 162.19999999999985, 194.59999999999997, 167.59999999999994, 130.4000000000001, 154.0999999999999, 198.2, 109.1, 199.1, 149.59999999999985, 77.00000000000003, 20.000000000000014, -19.900000000000013, -146.79999999999995, 20.000000000000014, -125.0000000000001, -548.3999999999996, 186.5, -124.9000000000004, 78.19999999999999, 134.0, -124.90000000000003, -21.999999999999982, -21.99999999999997, -206.80000000000027, 200.0, 178.69999999999996, 20.000000000000014, 54.8, 166.99999999999997, 164.59999999999994, -61.90000000000017, 86.59999999999997, -10.000000000000004, 200.0, -72.40000000000089, 74.0, 13.999999999999972, 86.3, -83.20000000000024, 75.49999999999969, -38.79999999999983, 75.79999999999998, -85.00000000000006, -126.50000000000013, -459.29999999999995, -89.20000000000083, 102.79999999999973, 25.100000000000165, 79.4, -68.20000000000061, 177.2, 180.19999999999993, 140.59999999999962, 181.1, 79.4, 165.2, -118.60000000000025, 117.19999999999985, 146.89999999999995, 65.9, 29.900000000000027, 192.79999999999995, 173.3, 162.2, 130.4, 122.30000000000001, 158.0, 190.10000000000002, 197.0, -201.10000000000022, -11.500000000000044, 7.999999999999987, 85.69999999999996, -21.999999999999975, 179.3, 193.69999999999996, 150.4999999999997, -137.50000000000057, -182.10000000000053, 172.09999999999982, 75.79999999999997, 193.69999999999996, -17.79999999999974, -34.30000000000001, -46.900000000000006, -174.4, -42.99999999999978, 81.79999999999998, 53.29999999999998, 31.400000000000247, -47.199999999999804, 63.5, 189.2, 20.000000000000014, 175.69999999999996, 20.000000000000014, -13.599999999999968, 134.0, -52.0, -259.8999999999994, -130.9, 82.09999999999997, 190.1, 188.29999999999998, 20.000000000000014, 89.29999999999993, -34.59999999999975, 169.69999999999996, 20.000000000000014, 177.50000000000003, 158.0, 173.9, 161.29999999999984, 60.499999999999964, -29.20000000000003, 156.8, 193.7, 3.199999999999975, 85.39999999999998, 25.100000000000108, 159.2, 5.299999999999965, 20.000000000000014, 108.19999999999999, 175.69999999999996, -109.30000000000001, 150.5, -34.59999999999977, 76.39999999999998, 135.8, 139.70000000000002, 5.2999999999999705, 155.0, 178.10000000000002, -3.399999999999995, -5.199999999999962, 85.0999999999995, 5.299999999999981, 186.79999999999995, -89.20000000000061, -53.49999999999986, -28.299999999999955, 194.59999999999997, 161.0, 3.1999999999999615, 112.0999999999999, 11.600000000000005, 17.899999999999988, 64.39999999999999, 162.2, -11.499999999999904, 133.39999999999995, 132.2, 194.6, 188.3, 106.4, 174.8, 188.29999999999998, 197.29999999999998, -49.29999999999979, 179.29999999999987, 164.89999999999986, 164.59999999999997, -108.39999999999999, 182.9, 5.299999999999972, -17.4999999999998, 169.1, 169.4, -42.4, 20.000000000000014, -86.19999999999996, -62.200000000000045], "policy_predator_policy_reward": [0.0, 0.0, 109.0, 149.0, 6.0, 4.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 1.0, 32.0, 0.0, 89.0, 84.0, 131.0, 84.0, 73.0, 146.0, 181.0, 0.0, 21.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 73.0, 69.0, 77.0, 63.0, 416.0, 93.0, 53.0, 69.0, 29.0, 88.0, 25.0, 0.0, 15.0, 93.0, 0.0, 5.0, 9.0, 0.0, 35.0, 12.0, 9.0, 16.0, 43.0, 16.0, 0.0, 75.0, 82.0, 0.0, 40.0, 12.0, 22.0, 41.0, 179.0, 349.0, 50.0, 35.0, 16.0, 3.0, 7.0, 42.0, 0.0, 0.0, 0.0, 33.0, 47.0, 30.0, 0.0, 15.0, 42.0, 0.0, 8.0, 0.0, 8.0, 15.0, 28.0, 0.0, 1.0, 0.0, 108.0, 115.0, 39.0, 19.0, 0.0, 26.0, 0.0, 0.0, 44.0, 95.0, 0.0, 0.0, 18.0, 0.0, 33.0, 85.0, 123.0, 30.0, 1.0, 0.0, 27.0, 9.0, 0.0, 41.0, 0.0, 0.0, 16.0, 0.0, 75.0, 20.0, 58.0, 154.0, 0.0, 0.0, 3.0, 0.0, 11.0, 17.0, 3.0, 2.0, 14.0, 0.0, 0.0, 0.0, 47.0, 32.0, 0.0, 0.0, 7.0, 39.0, 14.0, 6.0, 4.0, 3.0, 0.0, 0.0, 40.0, 55.0, 25.0, 5.0, 0.0, 23.0, 7.0, 0.0, 57.0, 4.0, 12.0, 5.0, 2.0, 7.0, 25.0, 71.0, 6.0, 17.0, 8.0, 13.0, 4.0, 8.0, 20.0, 1.0, 27.0, 0.0, 35.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 24.0, 16.0, 11.0, 0.0, 63.0, 64.0, 23.0, 8.0, 0.0, 9.0, 0.0, 73.0, 119.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5867130420974026, "mean_inference_ms": 1.4983494499809544, "mean_action_processing_ms": 0.25737893780991394, "mean_env_wait_ms": 0.20562634782160913, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004154324531555176, "StateBufferConnector_ms": 0.0035086870193481445, "ViewRequirementAgentConnector_ms": 0.11016654968261719}, "num_episodes": 18, "episode_return_max": 388.09999999999997, "episode_return_min": -180.60000000000105, "episode_return_mean": 169.82899999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 419.4763326584261, "num_env_steps_trained_throughput_per_sec": 419.4763326584261, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 10105.558, "restore_workers_time_ms": 0.017, "training_step_time_ms": 10105.504, "sample_time_ms": 1392.691, "learn_time_ms": 8695.149, "learn_throughput": 460.027, "synch_weights_time_ms": 12.904}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "04dec_00002", "date": "2024-08-13_16-32-00", "timestamp": 1723581120, "time_this_iter_s": 9.560412883758545, "time_total_s": 554.6039710044861, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 554.6039710044861, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 38.79285714285714, "ram_util_percent": 86.13571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7984747564429959, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.2334136010477783, "policy_loss": -0.006939171863690255, "vf_loss": 2.2395471123475876, "vf_explained_var": 0.011424885382727972, "kl": 0.012731583428487434, "entropy": 0.9721791446208954, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.836236882603988, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 6.937239304799882, "policy_loss": -0.0018183627895143612, "vf_loss": 6.938954322552555, "vf_explained_var": 0.20830865688424893, "kl": 0.00979748102741499, "entropy": 0.9561811741382357, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 393.70000000000016, "episode_reward_min": -180.60000000000105, "episode_reward_mean": 162.49299999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -459.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 349.0}, "policy_reward_mean": {"prey_policy": 57.20649999999996, "predator_policy": 24.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [75.30000000000004, 126.09999999999982, -18.99999999999976, 101.19999999999987, 203.69999999999928, 230.79999999999964, 149.69999999999948, 101.5999999999999, 186.59999999999943, 163.0, 85.10000000000005, 88.69999999999936, 53.8000000000003, -57.79999999999997, 98.59999999999962, 123.49999999999986, 157.99999999999955, 320.80000000000047, 293.50000000000006, 123.59999999999974, 279.1000000000004, 137.79999999999984, 374.10000000000014, 315.59999999999997, 308.3, 388.09999999999997, 10.399999999999972, 151.6999999999997, 183.29999999999944, 344.2000000000014, -180.60000000000105, 247.89999999999944, 193.89999999999932, 36.8, -64.40000000000063, 136.10000000000016, 20.20000000000004, 293.69999999999993, 195.6999999999993, 22.40000000000012, 177.0, -178.80000000000018, 272.1999999999997, 211.29999999999927, 82.70000000000003, 194.69999999999933, 349.49999999999994, 335.2000000000006, 110.30000000000007, 350.5, 134.59999999999968, 204.29999999999927, 32.30000000000019, 283.89999999999986, 136.19999999999968, 71.80000000000011, 298.49999999999994, 167.2999999999995, 235.69999999999982, 96.89999999999893, 201.09999999999926, -46.69999999999972, 189.29999999999936, 185.19999999999942, 135.69999999999942, 103.29999999999978, 177.69999999999948, 300.5999999999999, 382.9, 311.2, 385.6000000000001, 169.9999999999993, 340.4999999999999, 201.49999999999997, 18.800000000000136, 347.5, 50.6000000000001, -29.40000000000005, 144.59999999999948, 238.89999999999938, 40.0000000000003, 264.0999999999996, 81.39999999999905, 193.89999999999918, 28.999999999999982, 9.000000000000169, -14.999999999999838, 109.39999999999979, 170.99999999999991, -14.599999999999609, 171.99999999999946, 40.0000000000003, 171.09999999999948, 153.2999999999996, 94.99999999999987, 335.5, 219.99999999999937, 156.29999999999956, 268.0999999999999, 393.70000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-124.9000000000004, 78.19999999999999, 134.0, -124.90000000000003, -21.999999999999982, -21.99999999999997, -206.80000000000027, 200.0, 178.69999999999996, 20.000000000000014, 54.8, 166.99999999999997, 164.59999999999994, -61.90000000000017, 86.59999999999997, -10.000000000000004, 200.0, -72.40000000000089, 74.0, 13.999999999999972, 86.3, -83.20000000000024, 75.49999999999969, -38.79999999999983, 75.79999999999998, -85.00000000000006, -126.50000000000013, -459.29999999999995, -89.20000000000083, 102.79999999999973, 25.100000000000165, 79.4, -68.20000000000061, 177.2, 180.19999999999993, 140.59999999999962, 181.1, 79.4, 165.2, -118.60000000000025, 117.19999999999985, 146.89999999999995, 65.9, 29.900000000000027, 192.79999999999995, 173.3, 162.2, 130.4, 122.30000000000001, 158.0, 190.10000000000002, 197.0, -201.10000000000022, -11.500000000000044, 7.999999999999987, 85.69999999999996, -21.999999999999975, 179.3, 193.69999999999996, 150.4999999999997, -137.50000000000057, -182.10000000000053, 172.09999999999982, 75.79999999999997, 193.69999999999996, -17.79999999999974, -34.30000000000001, -46.900000000000006, -174.4, -42.99999999999978, 81.79999999999998, 53.29999999999998, 31.400000000000247, -47.199999999999804, 63.5, 189.2, 20.000000000000014, 175.69999999999996, 20.000000000000014, -13.599999999999968, 134.0, -52.0, -259.8999999999994, -130.9, 82.09999999999997, 190.1, 188.29999999999998, 20.000000000000014, 89.29999999999993, -34.59999999999975, 169.69999999999996, 20.000000000000014, 177.50000000000003, 158.0, 173.9, 161.29999999999984, 60.499999999999964, -29.20000000000003, 156.8, 193.7, 3.199999999999975, 85.39999999999998, 25.100000000000108, 159.2, 5.299999999999965, 20.000000000000014, 108.19999999999999, 175.69999999999996, -109.30000000000001, 150.5, -34.59999999999977, 76.39999999999998, 135.8, 139.70000000000002, 5.2999999999999705, 155.0, 178.10000000000002, -3.399999999999995, -5.199999999999962, 85.0999999999995, 5.299999999999981, 186.79999999999995, -89.20000000000061, -53.49999999999986, -28.299999999999955, 194.59999999999997, 161.0, 3.1999999999999615, 112.0999999999999, 11.600000000000005, 17.899999999999988, 64.39999999999999, 162.2, -11.499999999999904, 133.39999999999995, 132.2, 194.6, 188.3, 106.4, 174.8, 188.29999999999998, 197.29999999999998, -49.29999999999979, 179.29999999999987, 164.89999999999986, 164.59999999999997, -108.39999999999999, 182.9, 5.299999999999972, -17.4999999999998, 169.1, 169.4, -42.4, 20.000000000000014, -86.19999999999996, -62.200000000000045, 143.29999999999993, -15.699999999999775, 104.59999999999941, 134.29999999999998, 20.000000000000014, 20.000000000000014, 88.99999999999945, 163.1, 20.000000000000014, 61.40000000000012, 172.09999999999988, 21.80000000000004, -19.899999999999793, 29.9, 57.20000000000006, -131.20000000000036, -54.999999999999986, -67.0, -38.79999999999977, 81.19999999999999, 145.09999999999994, -87.10000000000001, -76.60000000000073, -1.0000000000000133, -30.3999999999998, 178.39999999999998, 20.000000000000014, 20.000000000000014, 162.2, -24.099999999999998, -47.19999999999983, 159.5, 29.0, -1.000000000000019, 179.0, 138.49999999999994, 177.49999999999994, 42.49999999999998, 168.4999999999999, -92.20000000000024, -30.400000000000034, 186.49999999999997, 195.49999999999997, 198.2], "policy_predator_policy_reward": [53.0, 69.0, 29.0, 88.0, 25.0, 0.0, 15.0, 93.0, 0.0, 5.0, 9.0, 0.0, 35.0, 12.0, 9.0, 16.0, 43.0, 16.0, 0.0, 75.0, 82.0, 0.0, 40.0, 12.0, 22.0, 41.0, 179.0, 349.0, 50.0, 35.0, 16.0, 3.0, 7.0, 42.0, 0.0, 0.0, 0.0, 33.0, 47.0, 30.0, 0.0, 15.0, 42.0, 0.0, 8.0, 0.0, 8.0, 15.0, 28.0, 0.0, 1.0, 0.0, 108.0, 115.0, 39.0, 19.0, 0.0, 26.0, 0.0, 0.0, 44.0, 95.0, 0.0, 0.0, 18.0, 0.0, 33.0, 85.0, 123.0, 30.0, 1.0, 0.0, 27.0, 9.0, 0.0, 41.0, 0.0, 0.0, 16.0, 0.0, 75.0, 20.0, 58.0, 154.0, 0.0, 0.0, 3.0, 0.0, 11.0, 17.0, 3.0, 2.0, 14.0, 0.0, 0.0, 0.0, 47.0, 32.0, 0.0, 0.0, 7.0, 39.0, 14.0, 6.0, 4.0, 3.0, 0.0, 0.0, 40.0, 55.0, 25.0, 5.0, 0.0, 23.0, 7.0, 0.0, 57.0, 4.0, 12.0, 5.0, 2.0, 7.0, 25.0, 71.0, 6.0, 17.0, 8.0, 13.0, 4.0, 8.0, 20.0, 1.0, 27.0, 0.0, 35.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 24.0, 16.0, 11.0, 0.0, 63.0, 64.0, 23.0, 8.0, 0.0, 9.0, 0.0, 73.0, 119.0, 0.0, 3.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 72.0, 11.0, 107.0, 0.0, 39.0, 28.0, 54.0, 59.0, 31.0, 32.0, 0.0, 24.0, 0.0, 0.0, 4.0, 29.0, 32.0, 9.0, 67.0, 0.0, 8.0, 10.0, 0.0, 0.0, 74.0, 6.0, 67.0, 45.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5882619879359773, "mean_inference_ms": 1.5033721323243647, "mean_action_processing_ms": 0.25747884671775995, "mean_env_wait_ms": 0.2064044892421602, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004729151725769043, "StateBufferConnector_ms": 0.0032830238342285156, "ViewRequirementAgentConnector_ms": 0.10962021350860596}, "num_episodes": 22, "episode_return_max": 393.70000000000016, "episode_return_min": -180.60000000000105, "episode_return_mean": 162.49299999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 413.19718615772524, "num_env_steps_trained_throughput_per_sec": 413.19718615772524, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 9997.652, "restore_workers_time_ms": 0.019, "training_step_time_ms": 9997.596, "sample_time_ms": 1327.763, "learn_time_ms": 8652.665, "learn_throughput": 462.285, "synch_weights_time_ms": 12.876}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "04dec_00002", "date": "2024-08-13_16-32-09", "timestamp": 1723581129, "time_this_iter_s": 9.739257097244263, "time_total_s": 564.3432281017303, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a7dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 564.3432281017303, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 37.728571428571435, "ram_util_percent": 85.92857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8541519460066286, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.1508963858009014, "policy_loss": -0.004747908371845605, "vf_loss": 2.1549287219842275, "vf_explained_var": 0.0032397721494947162, "kl": 0.011307853762115917, "entropy": 0.9174298295899043, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.64921649631369, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 6.436416788454409, "policy_loss": -0.005256230549556672, "vf_loss": 6.441529570937788, "vf_explained_var": 0.14405054585643545, "kl": 0.013599628589360244, "entropy": 0.9628790357756236, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 393.70000000000016, "episode_reward_min": -194.20000000000087, "episode_reward_mean": 158.36899999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -365.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": 56.744499999999974, "predator_policy": 22.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [315.59999999999997, 308.3, 388.09999999999997, 10.399999999999972, 151.6999999999997, 183.29999999999944, 344.2000000000014, -180.60000000000105, 247.89999999999944, 193.89999999999932, 36.8, -64.40000000000063, 136.10000000000016, 20.20000000000004, 293.69999999999993, 195.6999999999993, 22.40000000000012, 177.0, -178.80000000000018, 272.1999999999997, 211.29999999999927, 82.70000000000003, 194.69999999999933, 349.49999999999994, 335.2000000000006, 110.30000000000007, 350.5, 134.59999999999968, 204.29999999999927, 32.30000000000019, 283.89999999999986, 136.19999999999968, 71.80000000000011, 298.49999999999994, 167.2999999999995, 235.69999999999982, 96.89999999999893, 201.09999999999926, -46.69999999999972, 189.29999999999936, 185.19999999999942, 135.69999999999942, 103.29999999999978, 177.69999999999948, 300.5999999999999, 382.9, 311.2, 385.6000000000001, 169.9999999999993, 340.4999999999999, 201.49999999999997, 18.800000000000136, 347.5, 50.6000000000001, -29.40000000000005, 144.59999999999948, 238.89999999999938, 40.0000000000003, 264.0999999999996, 81.39999999999905, 193.89999999999918, 28.999999999999982, 9.000000000000169, -14.999999999999838, 109.39999999999979, 170.99999999999991, -14.599999999999609, 171.99999999999946, 40.0000000000003, 171.09999999999948, 153.2999999999996, 94.99999999999987, 335.5, 219.99999999999937, 156.29999999999956, 268.0999999999999, 393.70000000000016, 362.30000000000007, -6.599999999999659, 55.80000000000001, 183.2999999999994, 381.7, 210.0999999999993, 210.09999999999926, 215.99999999999926, 335.1, -83.20000000000115, 73.8, 143.49999999999915, 177.29999999999947, 126.29999999999973, -19.69999999999972, -9.300000000000008, 251.20000000000005, 160.59999999999954, 130.89999999999938, -194.20000000000087, 111.89999999999995, 183.99999999999946, -15.499999999999577], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [162.2, 130.4, 122.30000000000001, 158.0, 190.10000000000002, 197.0, -201.10000000000022, -11.500000000000044, 7.999999999999987, 85.69999999999996, -21.999999999999975, 179.3, 193.69999999999996, 150.4999999999997, -137.50000000000057, -182.10000000000053, 172.09999999999982, 75.79999999999997, 193.69999999999996, -17.79999999999974, -34.30000000000001, -46.900000000000006, -174.4, -42.99999999999978, 81.79999999999998, 53.29999999999998, 31.400000000000247, -47.199999999999804, 63.5, 189.2, 20.000000000000014, 175.69999999999996, 20.000000000000014, -13.599999999999968, 134.0, -52.0, -259.8999999999994, -130.9, 82.09999999999997, 190.1, 188.29999999999998, 20.000000000000014, 89.29999999999993, -34.59999999999975, 169.69999999999996, 20.000000000000014, 177.50000000000003, 158.0, 173.9, 161.29999999999984, 60.499999999999964, -29.20000000000003, 156.8, 193.7, 3.199999999999975, 85.39999999999998, 25.100000000000108, 159.2, 5.299999999999965, 20.000000000000014, 108.19999999999999, 175.69999999999996, -109.30000000000001, 150.5, -34.59999999999977, 76.39999999999998, 135.8, 139.70000000000002, 5.2999999999999705, 155.0, 178.10000000000002, -3.399999999999995, -5.199999999999962, 85.0999999999995, 5.299999999999981, 186.79999999999995, -89.20000000000061, -53.49999999999986, -28.299999999999955, 194.59999999999997, 161.0, 3.1999999999999615, 112.0999999999999, 11.600000000000005, 17.899999999999988, 64.39999999999999, 162.2, -11.499999999999904, 133.39999999999995, 132.2, 194.6, 188.3, 106.4, 174.8, 188.29999999999998, 197.29999999999998, -49.29999999999979, 179.29999999999987, 164.89999999999986, 164.59999999999997, -108.39999999999999, 182.9, 5.299999999999972, -17.4999999999998, 169.1, 169.4, -42.4, 20.000000000000014, -86.19999999999996, -62.200000000000045, 143.29999999999993, -15.699999999999775, 104.59999999999941, 134.29999999999998, 20.000000000000014, 20.000000000000014, 88.99999999999945, 163.1, 20.000000000000014, 61.40000000000012, 172.09999999999988, 21.80000000000004, -19.899999999999793, 29.9, 57.20000000000006, -131.20000000000036, -54.999999999999986, -67.0, -38.79999999999977, 81.19999999999999, 145.09999999999994, -87.10000000000001, -76.60000000000073, -1.0000000000000133, -30.3999999999998, 178.39999999999998, 20.000000000000014, 20.000000000000014, 162.2, -24.099999999999998, -47.19999999999983, 159.5, 29.0, -1.000000000000019, 179.0, 138.49999999999994, 177.49999999999994, 42.49999999999998, 168.4999999999999, -92.20000000000024, -30.400000000000034, 186.49999999999997, 195.49999999999997, 198.2, 180.2, 172.1, -7.299999999999891, -28.299999999999756, 195.5, -303.70000000000005, 20.000000000000014, 155.29999999999995, 175.7, 200.0, 190.1, 20.000000000000014, 20.000000000000014, 190.09999999999997, 194.0, 20.000000000000014, 168.49999999999997, 161.59999999999997, -106.0000000000008, -89.2000000000005, -21.999999999999744, 75.79999999999997, 76.69999999999995, 66.80000000000001, -26.19999999999976, 168.5, 111.50000000000006, -26.199999999999825, -147.70000000000056, 20.000000000000014, 168.5, -365.79999999999995, 137.89999999999998, 107.29999999999998, 140.6, 20.000000000000014, -4.899999999999917, 78.79999999999978, -294.9999999999992, -152.20000000000059, 124.39999999999995, -233.50000000000006, 164.0, 20.000000000000014, -80.80000000000078, 5.2999999999999705], "policy_predator_policy_reward": [8.0, 15.0, 28.0, 0.0, 1.0, 0.0, 108.0, 115.0, 39.0, 19.0, 0.0, 26.0, 0.0, 0.0, 44.0, 95.0, 0.0, 0.0, 18.0, 0.0, 33.0, 85.0, 123.0, 30.0, 1.0, 0.0, 27.0, 9.0, 0.0, 41.0, 0.0, 0.0, 16.0, 0.0, 75.0, 20.0, 58.0, 154.0, 0.0, 0.0, 3.0, 0.0, 11.0, 17.0, 3.0, 2.0, 14.0, 0.0, 0.0, 0.0, 47.0, 32.0, 0.0, 0.0, 7.0, 39.0, 14.0, 6.0, 4.0, 3.0, 0.0, 0.0, 40.0, 55.0, 25.0, 5.0, 0.0, 23.0, 7.0, 0.0, 57.0, 4.0, 12.0, 5.0, 2.0, 7.0, 25.0, 71.0, 6.0, 17.0, 8.0, 13.0, 4.0, 8.0, 20.0, 1.0, 27.0, 0.0, 35.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 24.0, 16.0, 11.0, 0.0, 63.0, 64.0, 23.0, 8.0, 0.0, 9.0, 0.0, 73.0, 119.0, 0.0, 3.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 72.0, 11.0, 107.0, 0.0, 39.0, 28.0, 54.0, 59.0, 31.0, 32.0, 0.0, 24.0, 0.0, 0.0, 4.0, 29.0, 32.0, 9.0, 67.0, 0.0, 8.0, 10.0, 0.0, 0.0, 74.0, 6.0, 67.0, 45.0, 0.0, 0.0, 10.0, 0.0, 2.0, 27.0, 0.0, 164.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 112.0, 0.0, 20.0, 0.0, 0.0, 20.0, 15.0, 19.0, 22.0, 35.0, 73.0, 0.0, 188.0, 0.0, 6.0, 0.0, 0.0, 13.0, 44.0, 128.0, 125.0, 129.0, 92.0, 0.0, 0.0, 49.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5902525554343419, "mean_inference_ms": 1.5104682192064554, "mean_action_processing_ms": 0.2577489823098346, "mean_env_wait_ms": 0.20734748934153133, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005324721336364746, "StateBufferConnector_ms": 0.003195047378540039, "ViewRequirementAgentConnector_ms": 0.10665011405944824}, "num_episodes": 23, "episode_return_max": 393.70000000000016, "episode_return_min": -194.20000000000087, "episode_return_mean": 158.36899999999977, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 401.3664897290903, "num_env_steps_trained_throughput_per_sec": 401.3664897290903, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 9948.353, "restore_workers_time_ms": 0.019, "training_step_time_ms": 9948.296, "sample_time_ms": 1343.498, "learn_time_ms": 8587.928, "learn_throughput": 465.77, "synch_weights_time_ms": 12.612}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "04dec_00002", "date": "2024-08-13_16-32-20", "timestamp": 1723581140, "time_this_iter_s": 10.014045000076294, "time_total_s": 574.3572731018066, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 574.3572731018066, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 44.29285714285714, "ram_util_percent": 86.37857142857145}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0226627916334168, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 4.449103377357361, "policy_loss": -0.0050021731479477785, "vf_loss": 4.453685696162875, "vf_explained_var": 0.004522247793813231, "kl": 0.006634712108618816, "entropy": 0.8922694644599996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.232521956827906, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 7.388039232687976, "policy_loss": -0.002226088985199572, "vf_loss": 7.390128703092141, "vf_explained_var": 0.030423248634136542, "kl": 0.012954049757834304, "entropy": 0.9344923431280429, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 393.70000000000016, "episode_reward_min": -291.0, "episode_reward_mean": 139.26799999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -380.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 227.0}, "policy_reward_mean": {"prey_policy": 40.778999999999975, "predator_policy": 28.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-178.80000000000018, 272.1999999999997, 211.29999999999927, 82.70000000000003, 194.69999999999933, 349.49999999999994, 335.2000000000006, 110.30000000000007, 350.5, 134.59999999999968, 204.29999999999927, 32.30000000000019, 283.89999999999986, 136.19999999999968, 71.80000000000011, 298.49999999999994, 167.2999999999995, 235.69999999999982, 96.89999999999893, 201.09999999999926, -46.69999999999972, 189.29999999999936, 185.19999999999942, 135.69999999999942, 103.29999999999978, 177.69999999999948, 300.5999999999999, 382.9, 311.2, 385.6000000000001, 169.9999999999993, 340.4999999999999, 201.49999999999997, 18.800000000000136, 347.5, 50.6000000000001, -29.40000000000005, 144.59999999999948, 238.89999999999938, 40.0000000000003, 264.0999999999996, 81.39999999999905, 193.89999999999918, 28.999999999999982, 9.000000000000169, -14.999999999999838, 109.39999999999979, 170.99999999999991, -14.599999999999609, 171.99999999999946, 40.0000000000003, 171.09999999999948, 153.2999999999996, 94.99999999999987, 335.5, 219.99999999999937, 156.29999999999956, 268.0999999999999, 393.70000000000016, 362.30000000000007, -6.599999999999659, 55.80000000000001, 183.2999999999994, 381.7, 210.0999999999993, 210.09999999999926, 215.99999999999926, 335.1, -83.20000000000115, 73.8, 143.49999999999915, 177.29999999999947, 126.29999999999973, -19.69999999999972, -9.300000000000008, 251.20000000000005, 160.59999999999954, 130.89999999999938, -194.20000000000087, 111.89999999999995, 183.99999999999946, -15.499999999999577, -79.80000000000017, 131.3999999999997, 193.4999999999995, 68.40000000000002, -27.399999999999935, 40.0000000000003, -110.0000000000002, 92.20000000000005, -190.40000000000057, 159.49999999999963, 9.200000000000042, -291.0, 385.4, 196.2, 142.79999999999964, -104.19999999999995, 210.0, 44.40000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-259.8999999999994, -130.9, 82.09999999999997, 190.1, 188.29999999999998, 20.000000000000014, 89.29999999999993, -34.59999999999975, 169.69999999999996, 20.000000000000014, 177.50000000000003, 158.0, 173.9, 161.29999999999984, 60.499999999999964, -29.20000000000003, 156.8, 193.7, 3.199999999999975, 85.39999999999998, 25.100000000000108, 159.2, 5.299999999999965, 20.000000000000014, 108.19999999999999, 175.69999999999996, -109.30000000000001, 150.5, -34.59999999999977, 76.39999999999998, 135.8, 139.70000000000002, 5.2999999999999705, 155.0, 178.10000000000002, -3.399999999999995, -5.199999999999962, 85.0999999999995, 5.299999999999981, 186.79999999999995, -89.20000000000061, -53.49999999999986, -28.299999999999955, 194.59999999999997, 161.0, 3.1999999999999615, 112.0999999999999, 11.600000000000005, 17.899999999999988, 64.39999999999999, 162.2, -11.499999999999904, 133.39999999999995, 132.2, 194.6, 188.3, 106.4, 174.8, 188.29999999999998, 197.29999999999998, -49.29999999999979, 179.29999999999987, 164.89999999999986, 164.59999999999997, -108.39999999999999, 182.9, 5.299999999999972, -17.4999999999998, 169.1, 169.4, -42.4, 20.000000000000014, -86.19999999999996, -62.200000000000045, 143.29999999999993, -15.699999999999775, 104.59999999999941, 134.29999999999998, 20.000000000000014, 20.000000000000014, 88.99999999999945, 163.1, 20.000000000000014, 61.40000000000012, 172.09999999999988, 21.80000000000004, -19.899999999999793, 29.9, 57.20000000000006, -131.20000000000036, -54.999999999999986, -67.0, -38.79999999999977, 81.19999999999999, 145.09999999999994, -87.10000000000001, -76.60000000000073, -1.0000000000000133, -30.3999999999998, 178.39999999999998, 20.000000000000014, 20.000000000000014, 162.2, -24.099999999999998, -47.19999999999983, 159.5, 29.0, -1.000000000000019, 179.0, 138.49999999999994, 177.49999999999994, 42.49999999999998, 168.4999999999999, -92.20000000000024, -30.400000000000034, 186.49999999999997, 195.49999999999997, 198.2, 180.2, 172.1, -7.299999999999891, -28.299999999999756, 195.5, -303.70000000000005, 20.000000000000014, 155.29999999999995, 175.7, 200.0, 190.1, 20.000000000000014, 20.000000000000014, 190.09999999999997, 194.0, 20.000000000000014, 168.49999999999997, 161.59999999999997, -106.0000000000008, -89.2000000000005, -21.999999999999744, 75.79999999999997, 76.69999999999995, 66.80000000000001, -26.19999999999976, 168.5, 111.50000000000006, -26.199999999999825, -147.70000000000056, 20.000000000000014, 168.5, -365.79999999999995, 137.89999999999998, 107.29999999999998, 140.6, 20.000000000000014, -4.899999999999917, 78.79999999999978, -294.9999999999992, -152.20000000000059, 124.39999999999995, -233.50000000000006, 164.0, 20.000000000000014, -80.80000000000078, 5.2999999999999705, -101.80000000000017, -154.0, 21.200000000000003, 30.200000000000205, -8.500000000000046, 182.0, 196.4, -380.0, 104.59999999999998, -298.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 72.19999999999996, -310.0, -114.4000000000006, -244.60000000000036, 178.1, 20.000000000000014, -38.79999999999978, -319.0, -325.0, 197.0, 187.4, -230.8, 167.0, 161.3, -53.49999999999991, -175.0, -80.2, -85.0, 200.0, 17.899999999999984, 9.499999999999975], "policy_predator_policy_reward": [58.0, 154.0, 0.0, 0.0, 3.0, 0.0, 11.0, 17.0, 3.0, 2.0, 14.0, 0.0, 0.0, 0.0, 47.0, 32.0, 0.0, 0.0, 7.0, 39.0, 14.0, 6.0, 4.0, 3.0, 0.0, 0.0, 40.0, 55.0, 25.0, 5.0, 0.0, 23.0, 7.0, 0.0, 57.0, 4.0, 12.0, 5.0, 2.0, 7.0, 25.0, 71.0, 6.0, 17.0, 8.0, 13.0, 4.0, 8.0, 20.0, 1.0, 27.0, 0.0, 35.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 24.0, 16.0, 11.0, 0.0, 63.0, 64.0, 23.0, 8.0, 0.0, 9.0, 0.0, 73.0, 119.0, 0.0, 3.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 72.0, 11.0, 107.0, 0.0, 39.0, 28.0, 54.0, 59.0, 31.0, 32.0, 0.0, 24.0, 0.0, 0.0, 4.0, 29.0, 32.0, 9.0, 67.0, 0.0, 8.0, 10.0, 0.0, 0.0, 74.0, 6.0, 67.0, 45.0, 0.0, 0.0, 10.0, 0.0, 2.0, 27.0, 0.0, 164.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 112.0, 0.0, 20.0, 0.0, 0.0, 20.0, 15.0, 19.0, 22.0, 35.0, 73.0, 0.0, 188.0, 0.0, 6.0, 0.0, 0.0, 13.0, 44.0, 128.0, 125.0, 129.0, 92.0, 0.0, 0.0, 49.0, 11.0, 58.0, 118.0, 63.0, 17.0, 16.0, 4.0, 25.0, 227.0, 166.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 0.0, 170.0, 64.0, 103.0, 123.0, 28.0, 0.0, 188.0, 165.0, 0.0, 1.0, 143.0, 117.0, 0.0, 35.0, 0.0, 151.0, 86.0, 9.0, 10.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5914124818753659, "mean_inference_ms": 1.5144176034896168, "mean_action_processing_ms": 0.2578675188332904, "mean_env_wait_ms": 0.20791649057271364, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005769491195678711, "StateBufferConnector_ms": 0.0032292604446411133, "ViewRequirementAgentConnector_ms": 0.10669279098510742}, "num_episodes": 18, "episode_return_max": 393.70000000000016, "episode_return_min": -291.0, "episode_return_mean": 139.26799999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.90460635762486, "num_env_steps_trained_throughput_per_sec": 409.90460635762486, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 9886.585, "restore_workers_time_ms": 0.018, "training_step_time_ms": 9886.529, "sample_time_ms": 1329.851, "learn_time_ms": 8539.699, "learn_throughput": 468.401, "synch_weights_time_ms": 12.804}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "04dec_00002", "date": "2024-08-13_16-32-29", "timestamp": 1723581149, "time_this_iter_s": 9.829647064208984, "time_total_s": 584.1869201660156, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359df70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 584.1869201660156, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 42.892857142857146, "ram_util_percent": 85.68571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1382075176431388, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 4.790008650633393, "policy_loss": -0.008521325354311595, "vf_loss": 4.797569788574542, "vf_explained_var": -0.004012894851190073, "kl": 0.015173044396498072, "entropy": 0.9500982953442467, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.593613092861478, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 7.3006493114289785, "policy_loss": -0.00094654397896082, "vf_loss": 7.301539864363494, "vf_explained_var": 0.20016984097541324, "kl": 0.005309250139908983, "entropy": 1.0161709885117869, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 393.70000000000016, "episode_reward_min": -460.6, "episode_reward_mean": 110.70099999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -422.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 300.0}, "policy_reward_mean": {"prey_policy": 16.175499999999964, "predator_policy": 39.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [96.89999999999893, 201.09999999999926, -46.69999999999972, 189.29999999999936, 185.19999999999942, 135.69999999999942, 103.29999999999978, 177.69999999999948, 300.5999999999999, 382.9, 311.2, 385.6000000000001, 169.9999999999993, 340.4999999999999, 201.49999999999997, 18.800000000000136, 347.5, 50.6000000000001, -29.40000000000005, 144.59999999999948, 238.89999999999938, 40.0000000000003, 264.0999999999996, 81.39999999999905, 193.89999999999918, 28.999999999999982, 9.000000000000169, -14.999999999999838, 109.39999999999979, 170.99999999999991, -14.599999999999609, 171.99999999999946, 40.0000000000003, 171.09999999999948, 153.2999999999996, 94.99999999999987, 335.5, 219.99999999999937, 156.29999999999956, 268.0999999999999, 393.70000000000016, 362.30000000000007, -6.599999999999659, 55.80000000000001, 183.2999999999994, 381.7, 210.0999999999993, 210.09999999999926, 215.99999999999926, 335.1, -83.20000000000115, 73.8, 143.49999999999915, 177.29999999999947, 126.29999999999973, -19.69999999999972, -9.300000000000008, 251.20000000000005, 160.59999999999954, 130.89999999999938, -194.20000000000087, 111.89999999999995, 183.99999999999946, -15.499999999999577, -79.80000000000017, 131.3999999999997, 193.4999999999995, 68.40000000000002, -27.399999999999935, 40.0000000000003, -110.0000000000002, 92.20000000000005, -190.40000000000057, 159.49999999999963, 9.200000000000042, -291.0, 385.4, 196.2, 142.79999999999964, -104.19999999999995, 210.0, 44.40000000000019, -190.9, 169.79999999999995, 219.09999999999926, -346.6, -460.6, 42.90000000000008, 207.6999999999993, -205.9000000000004, 40.0000000000003, 189.49999999999972, 110.80000000000001, 166.89999999999944, 79.7, 46.600000000000286, 169.59999999999908, 146.59999999999997, 174.39999999999947, -124.10000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.199999999999962, 85.0999999999995, 5.299999999999981, 186.79999999999995, -89.20000000000061, -53.49999999999986, -28.299999999999955, 194.59999999999997, 161.0, 3.1999999999999615, 112.0999999999999, 11.600000000000005, 17.899999999999988, 64.39999999999999, 162.2, -11.499999999999904, 133.39999999999995, 132.2, 194.6, 188.3, 106.4, 174.8, 188.29999999999998, 197.29999999999998, -49.29999999999979, 179.29999999999987, 164.89999999999986, 164.59999999999997, -108.39999999999999, 182.9, 5.299999999999972, -17.4999999999998, 169.1, 169.4, -42.4, 20.000000000000014, -86.19999999999996, -62.200000000000045, 143.29999999999993, -15.699999999999775, 104.59999999999941, 134.29999999999998, 20.000000000000014, 20.000000000000014, 88.99999999999945, 163.1, 20.000000000000014, 61.40000000000012, 172.09999999999988, 21.80000000000004, -19.899999999999793, 29.9, 57.20000000000006, -131.20000000000036, -54.999999999999986, -67.0, -38.79999999999977, 81.19999999999999, 145.09999999999994, -87.10000000000001, -76.60000000000073, -1.0000000000000133, -30.3999999999998, 178.39999999999998, 20.000000000000014, 20.000000000000014, 162.2, -24.099999999999998, -47.19999999999983, 159.5, 29.0, -1.000000000000019, 179.0, 138.49999999999994, 177.49999999999994, 42.49999999999998, 168.4999999999999, -92.20000000000024, -30.400000000000034, 186.49999999999997, 195.49999999999997, 198.2, 180.2, 172.1, -7.299999999999891, -28.299999999999756, 195.5, -303.70000000000005, 20.000000000000014, 155.29999999999995, 175.7, 200.0, 190.1, 20.000000000000014, 20.000000000000014, 190.09999999999997, 194.0, 20.000000000000014, 168.49999999999997, 161.59999999999997, -106.0000000000008, -89.2000000000005, -21.999999999999744, 75.79999999999997, 76.69999999999995, 66.80000000000001, -26.19999999999976, 168.5, 111.50000000000006, -26.199999999999825, -147.70000000000056, 20.000000000000014, 168.5, -365.79999999999995, 137.89999999999998, 107.29999999999998, 140.6, 20.000000000000014, -4.899999999999917, 78.79999999999978, -294.9999999999992, -152.20000000000059, 124.39999999999995, -233.50000000000006, 164.0, 20.000000000000014, -80.80000000000078, 5.2999999999999705, -101.80000000000017, -154.0, 21.200000000000003, 30.200000000000205, -8.500000000000046, 182.0, 196.4, -380.0, 104.59999999999998, -298.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 72.19999999999996, -310.0, -114.4000000000006, -244.60000000000036, 178.1, 20.000000000000014, -38.79999999999978, -319.0, -325.0, 197.0, 187.4, -230.8, 167.0, 161.3, -53.49999999999991, -175.0, -80.2, -85.0, 200.0, 17.899999999999984, 9.499999999999975, -295.0, -232.9, 200.0, -364.19999999999993, 199.1, 20.000000000000014, -360.1, -398.5, -422.5, -338.1, -150.10000000000065, 68.0, 20.000000000000014, 184.7, -344.3000000000002, -76.60000000000004, 20.000000000000014, 20.000000000000014, 150.19999999999982, -78.69999999999999, -199.60000000000002, 178.4, 20.000000000000014, 146.89999999999995, -394.4999999999999, 168.2, 20.000000000000014, 8.60000000000002, 20.000000000000014, 149.59999999999974, 200.0, -177.40000000000003, 195.2, -59.800000000000594, -100.0, -255.10000000000016], "policy_predator_policy_reward": [12.0, 5.0, 2.0, 7.0, 25.0, 71.0, 6.0, 17.0, 8.0, 13.0, 4.0, 8.0, 20.0, 1.0, 27.0, 0.0, 35.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 24.0, 16.0, 11.0, 0.0, 63.0, 64.0, 23.0, 8.0, 0.0, 9.0, 0.0, 73.0, 119.0, 0.0, 3.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 72.0, 11.0, 107.0, 0.0, 39.0, 28.0, 54.0, 59.0, 31.0, 32.0, 0.0, 24.0, 0.0, 0.0, 4.0, 29.0, 32.0, 9.0, 67.0, 0.0, 8.0, 10.0, 0.0, 0.0, 74.0, 6.0, 67.0, 45.0, 0.0, 0.0, 10.0, 0.0, 2.0, 27.0, 0.0, 164.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 112.0, 0.0, 20.0, 0.0, 0.0, 20.0, 15.0, 19.0, 22.0, 35.0, 73.0, 0.0, 188.0, 0.0, 6.0, 0.0, 0.0, 13.0, 44.0, 128.0, 125.0, 129.0, 92.0, 0.0, 0.0, 49.0, 11.0, 58.0, 118.0, 63.0, 17.0, 16.0, 4.0, 25.0, 227.0, 166.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 0.0, 170.0, 64.0, 103.0, 123.0, 28.0, 0.0, 188.0, 165.0, 0.0, 1.0, 143.0, 117.0, 0.0, 35.0, 0.0, 151.0, 86.0, 9.0, 10.0, 7.0, 167.0, 170.0, 193.0, 141.0, 0.0, 0.0, 180.0, 232.0, 0.0, 300.0, 81.0, 44.0, 2.0, 1.0, 215.0, 0.0, 0.0, 0.0, 52.0, 66.0, 0.0, 132.0, 0.0, 0.0, 10.0, 296.0, 14.0, 4.0, 0.0, 0.0, 0.0, 124.0, 38.0, 1.0, 131.0, 100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5923719899908714, "mean_inference_ms": 1.51774657016852, "mean_action_processing_ms": 0.25791863325961817, "mean_env_wait_ms": 0.2084403551992649, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006269335746765137, "StateBufferConnector_ms": 0.003272533416748047, "ViewRequirementAgentConnector_ms": 0.10631966590881348}, "num_episodes": 18, "episode_return_max": 393.70000000000016, "episode_return_min": -460.6, "episode_return_mean": 110.70099999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 405.8411441084717, "num_env_steps_trained_throughput_per_sec": 405.8411441084717, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 9885.202, "restore_workers_time_ms": 0.018, "training_step_time_ms": 9885.144, "sample_time_ms": 1329.534, "learn_time_ms": 8537.776, "learn_throughput": 468.506, "synch_weights_time_ms": 13.757}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "04dec_00002", "date": "2024-08-13_16-32-39", "timestamp": 1723581159, "time_this_iter_s": 9.950374841690063, "time_total_s": 594.1372950077057, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04b9820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 594.1372950077057, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 41.75714285714286, "ram_util_percent": 85.60714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1348254633880166, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 4.539571382507446, "policy_loss": -0.0052471062441962575, "vf_loss": 4.544165903046018, "vf_explained_var": -0.0016969231701401807, "kl": 0.010312536944319413, "entropy": 1.0079484703364197, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.709757994927427, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 8.038645084825143, "policy_loss": -0.0021310076533900524, "vf_loss": 8.040682148302674, "vf_explained_var": 0.19308260846390296, "kl": 0.008907141229018943, "entropy": 1.0200610678031963, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 393.70000000000016, "episode_reward_min": -460.6, "episode_reward_mean": 99.8249999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -712.0999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 560.0}, "policy_reward_mean": {"prey_policy": -2.5675000000000385, "predator_policy": 52.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [264.0999999999996, 81.39999999999905, 193.89999999999918, 28.999999999999982, 9.000000000000169, -14.999999999999838, 109.39999999999979, 170.99999999999991, -14.599999999999609, 171.99999999999946, 40.0000000000003, 171.09999999999948, 153.2999999999996, 94.99999999999987, 335.5, 219.99999999999937, 156.29999999999956, 268.0999999999999, 393.70000000000016, 362.30000000000007, -6.599999999999659, 55.80000000000001, 183.2999999999994, 381.7, 210.0999999999993, 210.09999999999926, 215.99999999999926, 335.1, -83.20000000000115, 73.8, 143.49999999999915, 177.29999999999947, 126.29999999999973, -19.69999999999972, -9.300000000000008, 251.20000000000005, 160.59999999999954, 130.89999999999938, -194.20000000000087, 111.89999999999995, 183.99999999999946, -15.499999999999577, -79.80000000000017, 131.3999999999997, 193.4999999999995, 68.40000000000002, -27.399999999999935, 40.0000000000003, -110.0000000000002, 92.20000000000005, -190.40000000000057, 159.49999999999963, 9.200000000000042, -291.0, 385.4, 196.2, 142.79999999999964, -104.19999999999995, 210.0, 44.40000000000019, -190.9, 169.79999999999995, 219.09999999999926, -346.6, -460.6, 42.90000000000008, 207.6999999999993, -205.9000000000004, 40.0000000000003, 189.49999999999972, 110.80000000000001, 166.89999999999944, 79.7, 46.600000000000286, 169.59999999999908, 146.59999999999997, 174.39999999999947, -124.10000000000016, -45.1999999999999, -34.19999999999981, 284.99999999999955, -1.3999999999998414, 164.2999999999994, -98.99999999999991, 159.79999999999956, 38.9000000000003, 194.39999999999972, 183.99999999999943, -43.59999999999975, 203.59999999999934, 181.9999999999996, 322.00000000000034, 56.99999999999993, 121.60000000000015, 20.10000000000017, 330.7000000000003, 79.79999999999994, 348.4999999999999, 329.9, 60.00000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [88.99999999999945, 163.1, 20.000000000000014, 61.40000000000012, 172.09999999999988, 21.80000000000004, -19.899999999999793, 29.9, 57.20000000000006, -131.20000000000036, -54.999999999999986, -67.0, -38.79999999999977, 81.19999999999999, 145.09999999999994, -87.10000000000001, -76.60000000000073, -1.0000000000000133, -30.3999999999998, 178.39999999999998, 20.000000000000014, 20.000000000000014, 162.2, -24.099999999999998, -47.19999999999983, 159.5, 29.0, -1.000000000000019, 179.0, 138.49999999999994, 177.49999999999994, 42.49999999999998, 168.4999999999999, -92.20000000000024, -30.400000000000034, 186.49999999999997, 195.49999999999997, 198.2, 180.2, 172.1, -7.299999999999891, -28.299999999999756, 195.5, -303.70000000000005, 20.000000000000014, 155.29999999999995, 175.7, 200.0, 190.1, 20.000000000000014, 20.000000000000014, 190.09999999999997, 194.0, 20.000000000000014, 168.49999999999997, 161.59999999999997, -106.0000000000008, -89.2000000000005, -21.999999999999744, 75.79999999999997, 76.69999999999995, 66.80000000000001, -26.19999999999976, 168.5, 111.50000000000006, -26.199999999999825, -147.70000000000056, 20.000000000000014, 168.5, -365.79999999999995, 137.89999999999998, 107.29999999999998, 140.6, 20.000000000000014, -4.899999999999917, 78.79999999999978, -294.9999999999992, -152.20000000000059, 124.39999999999995, -233.50000000000006, 164.0, 20.000000000000014, -80.80000000000078, 5.2999999999999705, -101.80000000000017, -154.0, 21.200000000000003, 30.200000000000205, -8.500000000000046, 182.0, 196.4, -380.0, 104.59999999999998, -298.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 72.19999999999996, -310.0, -114.4000000000006, -244.60000000000036, 178.1, 20.000000000000014, -38.79999999999978, -319.0, -325.0, 197.0, 187.4, -230.8, 167.0, 161.3, -53.49999999999991, -175.0, -80.2, -85.0, 200.0, 17.899999999999984, 9.499999999999975, -295.0, -232.9, 200.0, -364.19999999999993, 199.1, 20.000000000000014, -360.1, -398.5, -422.5, -338.1, -150.10000000000065, 68.0, 20.000000000000014, 184.7, -344.3000000000002, -76.60000000000004, 20.000000000000014, 20.000000000000014, 150.19999999999982, -78.69999999999999, -199.60000000000002, 178.4, 20.000000000000014, 146.89999999999995, -394.4999999999999, 168.2, 20.000000000000014, 8.60000000000002, 20.000000000000014, 149.59999999999974, 200.0, -177.40000000000003, 195.2, -59.800000000000594, -100.0, -255.10000000000016, -236.20000000000002, 20.000000000000014, -7.300000000000033, -330.9, 118.99999999999964, 149.0, 20.000000000000014, -192.40000000000003, 131.3, 20.000000000000014, -68.20000000000005, -80.80000000000003, 11.59999999999997, 144.20000000000002, 20.000000000000014, 17.900000000000013, -180.90000000000018, 101.2999999999999, 20.000000000000014, 164.0, 15.799999999999963, -189.40000000000003, 186.49999999999991, -40.90000000000003, 184.6999999999999, -325.70000000000005, 126.49999999999994, 168.5, 172.09999999999982, -712.0999999999999, 93.79999999999998, -575.2, 9.499999999999991, -9.400000000000025, 152.29999999999995, 178.39999999999992, 38.60000000000001, -38.799999999999756, 190.69999999999996, 156.79999999999998, 178.39999999999986, 129.49999999999997, 169.1, -622.1], "policy_predator_policy_reward": [0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 72.0, 11.0, 107.0, 0.0, 39.0, 28.0, 54.0, 59.0, 31.0, 32.0, 0.0, 24.0, 0.0, 0.0, 4.0, 29.0, 32.0, 9.0, 67.0, 0.0, 8.0, 10.0, 0.0, 0.0, 74.0, 6.0, 67.0, 45.0, 0.0, 0.0, 10.0, 0.0, 2.0, 27.0, 0.0, 164.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 112.0, 0.0, 20.0, 0.0, 0.0, 20.0, 15.0, 19.0, 22.0, 35.0, 73.0, 0.0, 188.0, 0.0, 6.0, 0.0, 0.0, 13.0, 44.0, 128.0, 125.0, 129.0, 92.0, 0.0, 0.0, 49.0, 11.0, 58.0, 118.0, 63.0, 17.0, 16.0, 4.0, 25.0, 227.0, 166.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 0.0, 170.0, 64.0, 103.0, 123.0, 28.0, 0.0, 188.0, 165.0, 0.0, 1.0, 143.0, 117.0, 0.0, 35.0, 0.0, 151.0, 86.0, 9.0, 10.0, 7.0, 167.0, 170.0, 193.0, 141.0, 0.0, 0.0, 180.0, 232.0, 0.0, 300.0, 81.0, 44.0, 2.0, 1.0, 215.0, 0.0, 0.0, 0.0, 52.0, 66.0, 0.0, 132.0, 0.0, 0.0, 10.0, 296.0, 14.0, 4.0, 0.0, 0.0, 0.0, 124.0, 38.0, 1.0, 131.0, 100.0, 115.0, 56.0, 206.0, 98.0, 17.0, 0.0, 65.0, 106.0, 13.0, 0.0, 0.0, 50.0, 4.0, 0.0, 1.0, 0.0, 197.0, 77.0, 0.0, 0.0, 130.0, 0.0, 29.0, 29.0, 40.0, 283.0, 5.0, 22.0, 37.0, 560.0, 282.0, 321.0, 0.0, 20.0, 0.0, 0.0, 28.0, 52.0, 1.0, 0.0, 0.0, 22.0, 10.0, 503.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.593836223183156, "mean_inference_ms": 1.5218601540197665, "mean_action_processing_ms": 0.2579160795994775, "mean_env_wait_ms": 0.2090343501271725, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006978511810302734, "StateBufferConnector_ms": 0.0033332109451293945, "ViewRequirementAgentConnector_ms": 0.10709524154663086}, "num_episodes": 22, "episode_return_max": 393.70000000000016, "episode_return_min": -460.6, "episode_return_mean": 99.8249999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 397.9803250757848, "num_env_steps_trained_throughput_per_sec": 397.9803250757848, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 9875.169, "restore_workers_time_ms": 0.019, "training_step_time_ms": 9875.111, "sample_time_ms": 1344.125, "learn_time_ms": 8512.912, "learn_throughput": 469.874, "synch_weights_time_ms": 13.831}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "04dec_00002", "date": "2024-08-13_16-32-49", "timestamp": 1723581169, "time_this_iter_s": 10.082101821899414, "time_total_s": 604.2193968296051, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 604.2193968296051, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 44.84285714285714, "ram_util_percent": 86.59285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0959609007788083, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 4.871334356984134, "policy_loss": -0.004457558037358381, "vf_loss": 4.874940104585476, "vf_explained_var": -0.000740070696230288, "kl": 0.013460558658106326, "entropy": 0.9924086679857244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.006738439265383, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 9.113226571158757, "policy_loss": -0.0015524845203217217, "vf_loss": 9.114669391087123, "vf_explained_var": 0.21713130950296997, "kl": 0.010398504255580279, "entropy": 0.9734610248495031, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 385.4, "episode_reward_min": -590.0999999999999, "episode_reward_mean": 91.19999999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -760.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": -23.030000000000037, "predator_policy": 68.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [381.7, 210.0999999999993, 210.09999999999926, 215.99999999999926, 335.1, -83.20000000000115, 73.8, 143.49999999999915, 177.29999999999947, 126.29999999999973, -19.69999999999972, -9.300000000000008, 251.20000000000005, 160.59999999999954, 130.89999999999938, -194.20000000000087, 111.89999999999995, 183.99999999999946, -15.499999999999577, -79.80000000000017, 131.3999999999997, 193.4999999999995, 68.40000000000002, -27.399999999999935, 40.0000000000003, -110.0000000000002, 92.20000000000005, -190.40000000000057, 159.49999999999963, 9.200000000000042, -291.0, 385.4, 196.2, 142.79999999999964, -104.19999999999995, 210.0, 44.40000000000019, -190.9, 169.79999999999995, 219.09999999999926, -346.6, -460.6, 42.90000000000008, 207.6999999999993, -205.9000000000004, 40.0000000000003, 189.49999999999972, 110.80000000000001, 166.89999999999944, 79.7, 46.600000000000286, 169.59999999999908, 146.59999999999997, 174.39999999999947, -124.10000000000016, -45.1999999999999, -34.19999999999981, 284.99999999999955, -1.3999999999998414, 164.2999999999994, -98.99999999999991, 159.79999999999956, 38.9000000000003, 194.39999999999972, 183.99999999999943, -43.59999999999975, 203.59999999999934, 181.9999999999996, 322.00000000000034, 56.99999999999993, 121.60000000000015, 20.10000000000017, 330.7000000000003, 79.79999999999994, 348.4999999999999, 329.9, 60.00000000000001, 203.19999999999936, 365.1, 335.5000000000002, -43.89999999999995, -590.0999999999999, 61.200000000000045, 104.89999999999998, 78.6000000000001, 306.5999999999998, -33.79999999999981, 49.100000000000016, 328.8999999999999, 121.99999999999972, -30.5, -149.3, 370.20000000000005, 277.4, 79.69999999999881, 164.39999999999952, 156.09999999999962, -28.199999999999903, 105.59999999999988, 332.800000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [175.7, 200.0, 190.1, 20.000000000000014, 20.000000000000014, 190.09999999999997, 194.0, 20.000000000000014, 168.49999999999997, 161.59999999999997, -106.0000000000008, -89.2000000000005, -21.999999999999744, 75.79999999999997, 76.69999999999995, 66.80000000000001, -26.19999999999976, 168.5, 111.50000000000006, -26.199999999999825, -147.70000000000056, 20.000000000000014, 168.5, -365.79999999999995, 137.89999999999998, 107.29999999999998, 140.6, 20.000000000000014, -4.899999999999917, 78.79999999999978, -294.9999999999992, -152.20000000000059, 124.39999999999995, -233.50000000000006, 164.0, 20.000000000000014, -80.80000000000078, 5.2999999999999705, -101.80000000000017, -154.0, 21.200000000000003, 30.200000000000205, -8.500000000000046, 182.0, 196.4, -380.0, 104.59999999999998, -298.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 72.19999999999996, -310.0, -114.4000000000006, -244.60000000000036, 178.1, 20.000000000000014, -38.79999999999978, -319.0, -325.0, 197.0, 187.4, -230.8, 167.0, 161.3, -53.49999999999991, -175.0, -80.2, -85.0, 200.0, 17.899999999999984, 9.499999999999975, -295.0, -232.9, 200.0, -364.19999999999993, 199.1, 20.000000000000014, -360.1, -398.5, -422.5, -338.1, -150.10000000000065, 68.0, 20.000000000000014, 184.7, -344.3000000000002, -76.60000000000004, 20.000000000000014, 20.000000000000014, 150.19999999999982, -78.69999999999999, -199.60000000000002, 178.4, 20.000000000000014, 146.89999999999995, -394.4999999999999, 168.2, 20.000000000000014, 8.60000000000002, 20.000000000000014, 149.59999999999974, 200.0, -177.40000000000003, 195.2, -59.800000000000594, -100.0, -255.10000000000016, -236.20000000000002, 20.000000000000014, -7.300000000000033, -330.9, 118.99999999999964, 149.0, 20.000000000000014, -192.40000000000003, 131.3, 20.000000000000014, -68.20000000000005, -80.80000000000003, 11.59999999999997, 144.20000000000002, 20.000000000000014, 17.900000000000013, -180.90000000000018, 101.2999999999999, 20.000000000000014, 164.0, 15.799999999999963, -189.40000000000003, 186.49999999999991, -40.90000000000003, 184.6999999999999, -325.70000000000005, 126.49999999999994, 168.5, 172.09999999999982, -712.0999999999999, 93.79999999999998, -575.2, 9.499999999999991, -9.400000000000025, 152.29999999999995, 178.39999999999992, 38.60000000000001, -38.799999999999756, 190.69999999999996, 156.79999999999998, 178.39999999999986, 129.49999999999997, 169.1, -622.1, 169.39999999999995, -14.199999999999822, 182.0, 175.1, 163.9999999999998, 159.49999999999997, -437.8999999999998, -130.0, -670.2, -760.9, -355.0, 144.2, -415.20000000000005, 67.09999999999997, 38.899999999999984, -88.30000000000001, 125.00000000000006, 173.6, -59.400000000000034, -51.40000000000004, 185.89999999999995, -649.8, 131.6, 197.3, 89.0, 20.000000000000014, -29.5, -133.0, -499.20000000000005, -209.10000000000002, 186.49999999999997, 175.7, 140.29999999999998, 79.1, 28.700000000000138, 20.000000000000014, -100.90000000000063, 161.3, 175.7, -164.60000000000002, -129.10000000000022, -27.100000000000016, -244.90000000000003, 144.5, 129.79999999999976, 191.0], "policy_predator_policy_reward": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 112.0, 0.0, 20.0, 0.0, 0.0, 20.0, 15.0, 19.0, 22.0, 35.0, 73.0, 0.0, 188.0, 0.0, 6.0, 0.0, 0.0, 13.0, 44.0, 128.0, 125.0, 129.0, 92.0, 0.0, 0.0, 49.0, 11.0, 58.0, 118.0, 63.0, 17.0, 16.0, 4.0, 25.0, 227.0, 166.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 0.0, 170.0, 64.0, 103.0, 123.0, 28.0, 0.0, 188.0, 165.0, 0.0, 1.0, 143.0, 117.0, 0.0, 35.0, 0.0, 151.0, 86.0, 9.0, 10.0, 7.0, 167.0, 170.0, 193.0, 141.0, 0.0, 0.0, 180.0, 232.0, 0.0, 300.0, 81.0, 44.0, 2.0, 1.0, 215.0, 0.0, 0.0, 0.0, 52.0, 66.0, 0.0, 132.0, 0.0, 0.0, 10.0, 296.0, 14.0, 4.0, 0.0, 0.0, 0.0, 124.0, 38.0, 1.0, 131.0, 100.0, 115.0, 56.0, 206.0, 98.0, 17.0, 0.0, 65.0, 106.0, 13.0, 0.0, 0.0, 50.0, 4.0, 0.0, 1.0, 0.0, 197.0, 77.0, 0.0, 0.0, 130.0, 0.0, 29.0, 29.0, 40.0, 283.0, 5.0, 22.0, 37.0, 560.0, 282.0, 321.0, 0.0, 20.0, 0.0, 0.0, 28.0, 52.0, 1.0, 0.0, 0.0, 22.0, 10.0, 503.0, 24.0, 24.0, 0.0, 8.0, 12.0, 0.0, 137.0, 387.0, 839.0, 2.0, 108.0, 164.0, 281.0, 172.0, 94.0, 34.0, 0.0, 8.0, 35.0, 42.0, 511.0, 2.0, 0.0, 0.0, 0.0, 13.0, 132.0, 0.0, 203.0, 356.0, 0.0, 8.0, 0.0, 58.0, 16.0, 15.0, 38.0, 66.0, 145.0, 0.0, 114.0, 14.0, 204.0, 2.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5955858943629968, "mean_inference_ms": 1.5276759471453003, "mean_action_processing_ms": 0.25858452557343187, "mean_env_wait_ms": 0.20978013189288355, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010595440864562988, "StateBufferConnector_ms": 0.003428339958190918, "ViewRequirementAgentConnector_ms": 0.11049377918243408}, "num_episodes": 23, "episode_return_max": 385.4, "episode_return_min": -590.0999999999999, "episode_return_mean": 91.19999999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 422.59969699258835, "num_env_steps_trained_throughput_per_sec": 422.59969699258835, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 9862.081, "restore_workers_time_ms": 0.019, "training_step_time_ms": 9862.024, "sample_time_ms": 1341.057, "learn_time_ms": 8501.846, "learn_throughput": 470.486, "synch_weights_time_ms": 14.832}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "04dec_00002", "date": "2024-08-13_16-32-59", "timestamp": 1723581179, "time_this_iter_s": 9.543647050857544, "time_total_s": 613.7630438804626, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04520d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 613.7630438804626, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 37.49285714285714, "ram_util_percent": 86.21428571428574}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.091469144970967, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 4.372010863521112, "policy_loss": -0.0017788633775636159, "vf_loss": 4.373294280319618, "vf_explained_var": -0.0008008602750364435, "kl": 0.007829163969881446, "entropy": 1.0462251423843323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.099725459460858, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 8.81315441510034, "policy_loss": -0.0022317132819567134, "vf_loss": 8.815290571646715, "vf_explained_var": 0.27023054124817014, "kl": 0.009062296855627058, "entropy": 1.0229906099498587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 385.4, "episode_reward_min": -590.0999999999999, "episode_reward_mean": 95.8789999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -760.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": -36.59050000000004, "predator_policy": 84.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.499999999999577, -79.80000000000017, 131.3999999999997, 193.4999999999995, 68.40000000000002, -27.399999999999935, 40.0000000000003, -110.0000000000002, 92.20000000000005, -190.40000000000057, 159.49999999999963, 9.200000000000042, -291.0, 385.4, 196.2, 142.79999999999964, -104.19999999999995, 210.0, 44.40000000000019, -190.9, 169.79999999999995, 219.09999999999926, -346.6, -460.6, 42.90000000000008, 207.6999999999993, -205.9000000000004, 40.0000000000003, 189.49999999999972, 110.80000000000001, 166.89999999999944, 79.7, 46.600000000000286, 169.59999999999908, 146.59999999999997, 174.39999999999947, -124.10000000000016, -45.1999999999999, -34.19999999999981, 284.99999999999955, -1.3999999999998414, 164.2999999999994, -98.99999999999991, 159.79999999999956, 38.9000000000003, 194.39999999999972, 183.99999999999943, -43.59999999999975, 203.59999999999934, 181.9999999999996, 322.00000000000034, 56.99999999999993, 121.60000000000015, 20.10000000000017, 330.7000000000003, 79.79999999999994, 348.4999999999999, 329.9, 60.00000000000001, 203.19999999999936, 365.1, 335.5000000000002, -43.89999999999995, -590.0999999999999, 61.200000000000045, 104.89999999999998, 78.6000000000001, 306.5999999999998, -33.79999999999981, 49.100000000000016, 328.8999999999999, 121.99999999999972, -30.5, -149.3, 370.20000000000005, 277.4, 79.69999999999881, 164.39999999999952, 156.09999999999962, -28.199999999999903, 105.59999999999988, 332.800000000001, 347.99999999999994, 305.4999999999999, 246.39999999999972, 132.7, 40.0000000000003, -2.3000000000000016, 140.89999999999972, 288.8, 113.20000000000005, -127.00000000000003, 359.0, 140.70000000000013, 359.5, 330.79999999999995, 283.89999999999964, -511.4999999999998, 137.99999999999972, 287.39999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-80.80000000000078, 5.2999999999999705, -101.80000000000017, -154.0, 21.200000000000003, 30.200000000000205, -8.500000000000046, 182.0, 196.4, -380.0, 104.59999999999998, -298.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 72.19999999999996, -310.0, -114.4000000000006, -244.60000000000036, 178.1, 20.000000000000014, -38.79999999999978, -319.0, -325.0, 197.0, 187.4, -230.8, 167.0, 161.3, -53.49999999999991, -175.0, -80.2, -85.0, 200.0, 17.899999999999984, 9.499999999999975, -295.0, -232.9, 200.0, -364.19999999999993, 199.1, 20.000000000000014, -360.1, -398.5, -422.5, -338.1, -150.10000000000065, 68.0, 20.000000000000014, 184.7, -344.3000000000002, -76.60000000000004, 20.000000000000014, 20.000000000000014, 150.19999999999982, -78.69999999999999, -199.60000000000002, 178.4, 20.000000000000014, 146.89999999999995, -394.4999999999999, 168.2, 20.000000000000014, 8.60000000000002, 20.000000000000014, 149.59999999999974, 200.0, -177.40000000000003, 195.2, -59.800000000000594, -100.0, -255.10000000000016, -236.20000000000002, 20.000000000000014, -7.300000000000033, -330.9, 118.99999999999964, 149.0, 20.000000000000014, -192.40000000000003, 131.3, 20.000000000000014, -68.20000000000005, -80.80000000000003, 11.59999999999997, 144.20000000000002, 20.000000000000014, 17.900000000000013, -180.90000000000018, 101.2999999999999, 20.000000000000014, 164.0, 15.799999999999963, -189.40000000000003, 186.49999999999991, -40.90000000000003, 184.6999999999999, -325.70000000000005, 126.49999999999994, 168.5, 172.09999999999982, -712.0999999999999, 93.79999999999998, -575.2, 9.499999999999991, -9.400000000000025, 152.29999999999995, 178.39999999999992, 38.60000000000001, -38.799999999999756, 190.69999999999996, 156.79999999999998, 178.39999999999986, 129.49999999999997, 169.1, -622.1, 169.39999999999995, -14.199999999999822, 182.0, 175.1, 163.9999999999998, 159.49999999999997, -437.8999999999998, -130.0, -670.2, -760.9, -355.0, 144.2, -415.20000000000005, 67.09999999999997, 38.899999999999984, -88.30000000000001, 125.00000000000006, 173.6, -59.400000000000034, -51.40000000000004, 185.89999999999995, -649.8, 131.6, 197.3, 89.0, 20.000000000000014, -29.5, -133.0, -499.20000000000005, -209.10000000000002, 186.49999999999997, 175.7, 140.29999999999998, 79.1, 28.700000000000138, 20.000000000000014, -100.90000000000063, 161.3, 175.7, -164.60000000000002, -129.10000000000022, -27.100000000000016, -244.90000000000003, 144.5, 129.79999999999976, 191.0, 162.2, 165.8, 110.89999999999998, 194.6, 175.10000000000002, 68.29999999999998, -4.299999999999997, 38.0, 20.000000000000014, 20.000000000000014, 56.89999999999996, -131.20000000000002, 129.79999999999998, -37.89999999999988, 116.0, 144.8, -383.80000000000007, -583.0, -352.99999999999994, -271.0, 199.1, 143.9, 134.29999999999998, -443.60000000000025, -528.6, 187.09999999999997, 165.8, 143.0, 83.89999999999998, 200.0, -459.50000000000006, -720.0, 20.000000000000014, 77.0, -357.70000000000005, 157.1], "policy_predator_policy_reward": [49.0, 11.0, 58.0, 118.0, 63.0, 17.0, 16.0, 4.0, 25.0, 227.0, 166.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 0.0, 170.0, 64.0, 103.0, 123.0, 28.0, 0.0, 188.0, 165.0, 0.0, 1.0, 143.0, 117.0, 0.0, 35.0, 0.0, 151.0, 86.0, 9.0, 10.0, 7.0, 167.0, 170.0, 193.0, 141.0, 0.0, 0.0, 180.0, 232.0, 0.0, 300.0, 81.0, 44.0, 2.0, 1.0, 215.0, 0.0, 0.0, 0.0, 52.0, 66.0, 0.0, 132.0, 0.0, 0.0, 10.0, 296.0, 14.0, 4.0, 0.0, 0.0, 0.0, 124.0, 38.0, 1.0, 131.0, 100.0, 115.0, 56.0, 206.0, 98.0, 17.0, 0.0, 65.0, 106.0, 13.0, 0.0, 0.0, 50.0, 4.0, 0.0, 1.0, 0.0, 197.0, 77.0, 0.0, 0.0, 130.0, 0.0, 29.0, 29.0, 40.0, 283.0, 5.0, 22.0, 37.0, 560.0, 282.0, 321.0, 0.0, 20.0, 0.0, 0.0, 28.0, 52.0, 1.0, 0.0, 0.0, 22.0, 10.0, 503.0, 24.0, 24.0, 0.0, 8.0, 12.0, 0.0, 137.0, 387.0, 839.0, 2.0, 108.0, 164.0, 281.0, 172.0, 94.0, 34.0, 0.0, 8.0, 35.0, 42.0, 511.0, 2.0, 0.0, 0.0, 0.0, 13.0, 132.0, 0.0, 203.0, 356.0, 0.0, 8.0, 0.0, 58.0, 16.0, 15.0, 38.0, 66.0, 145.0, 0.0, 114.0, 14.0, 204.0, 2.0, 0.0, 12.0, 6.0, 14.0, 0.0, 0.0, 1.0, 2.0, 57.0, 42.0, 0.0, 0.0, 0.0, 72.0, 0.0, 49.0, 0.0, 28.0, 555.0, 525.0, 358.0, 139.0, 0.0, 16.0, 177.0, 273.0, 329.0, 372.0, 13.0, 9.0, 0.0, 0.0, 0.0, 668.0, 0.0, 41.0, 319.0, 169.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.595964175472449, "mean_inference_ms": 1.5294663089002711, "mean_action_processing_ms": 0.25841590489179717, "mean_env_wait_ms": 0.21027539334580553, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00998985767364502, "StateBufferConnector_ms": 0.0034623146057128906, "ViewRequirementAgentConnector_ms": 0.11705386638641357}, "num_episodes": 18, "episode_return_max": 385.4, "episode_return_min": -590.0999999999999, "episode_return_mean": 95.8789999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 406.006043621142, "num_env_steps_trained_throughput_per_sec": 406.006043621142, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 9886.959, "restore_workers_time_ms": 0.017, "training_step_time_ms": 9886.904, "sample_time_ms": 1362.566, "learn_time_ms": 8505.149, "learn_throughput": 470.303, "synch_weights_time_ms": 14.731}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "04dec_00002", "date": "2024-08-13_16-33-09", "timestamp": 1723581189, "time_this_iter_s": 9.895419836044312, "time_total_s": 623.658463716507, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359c040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 623.658463716507, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 41.85, "ram_util_percent": 86.47857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0499161523564782, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 4.503489909853254, "policy_loss": -0.0020924036270352424, "vf_loss": 4.504987052761058, "vf_explained_var": -0.0006955841230967688, "kl": 0.009406543163975201, "entropy": 1.1248396195431867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.643465700761351, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 8.97817196568484, "policy_loss": 0.0015489890291872951, "vf_loss": 8.976484515174986, "vf_explained_var": 0.42379049513705824, "kl": 0.013129522873954996, "entropy": 0.9564960904222317, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 392.5000000000001, "episode_reward_min": -590.0999999999999, "episode_reward_mean": 128.45499999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -760.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": -33.80250000000003, "predator_policy": 98.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.40000000000019, -190.9, 169.79999999999995, 219.09999999999926, -346.6, -460.6, 42.90000000000008, 207.6999999999993, -205.9000000000004, 40.0000000000003, 189.49999999999972, 110.80000000000001, 166.89999999999944, 79.7, 46.600000000000286, 169.59999999999908, 146.59999999999997, 174.39999999999947, -124.10000000000016, -45.1999999999999, -34.19999999999981, 284.99999999999955, -1.3999999999998414, 164.2999999999994, -98.99999999999991, 159.79999999999956, 38.9000000000003, 194.39999999999972, 183.99999999999943, -43.59999999999975, 203.59999999999934, 181.9999999999996, 322.00000000000034, 56.99999999999993, 121.60000000000015, 20.10000000000017, 330.7000000000003, 79.79999999999994, 348.4999999999999, 329.9, 60.00000000000001, 203.19999999999936, 365.1, 335.5000000000002, -43.89999999999995, -590.0999999999999, 61.200000000000045, 104.89999999999998, 78.6000000000001, 306.5999999999998, -33.79999999999981, 49.100000000000016, 328.8999999999999, 121.99999999999972, -30.5, -149.3, 370.20000000000005, 277.4, 79.69999999999881, 164.39999999999952, 156.09999999999962, -28.199999999999903, 105.59999999999988, 332.800000000001, 347.99999999999994, 305.4999999999999, 246.39999999999972, 132.7, 40.0000000000003, -2.3000000000000016, 140.89999999999972, 288.8, 113.20000000000005, -127.00000000000003, 359.0, 140.70000000000013, 359.5, 330.79999999999995, 283.89999999999964, -511.4999999999998, 137.99999999999972, 287.39999999999986, 215.4, 183.80000000000004, 268.5999999999999, 311.0, 244.99999999999997, 345.1, -169.8999999999999, 356.8, 334.7, 207.0999999999999, 178.90000000000003, 336.1, -120.69999999999999, 282.0999999999997, 224.19999999999956, 237.99999999999997, 392.5000000000001, 239.20000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999984, 9.499999999999975, -295.0, -232.9, 200.0, -364.19999999999993, 199.1, 20.000000000000014, -360.1, -398.5, -422.5, -338.1, -150.10000000000065, 68.0, 20.000000000000014, 184.7, -344.3000000000002, -76.60000000000004, 20.000000000000014, 20.000000000000014, 150.19999999999982, -78.69999999999999, -199.60000000000002, 178.4, 20.000000000000014, 146.89999999999995, -394.4999999999999, 168.2, 20.000000000000014, 8.60000000000002, 20.000000000000014, 149.59999999999974, 200.0, -177.40000000000003, 195.2, -59.800000000000594, -100.0, -255.10000000000016, -236.20000000000002, 20.000000000000014, -7.300000000000033, -330.9, 118.99999999999964, 149.0, 20.000000000000014, -192.40000000000003, 131.3, 20.000000000000014, -68.20000000000005, -80.80000000000003, 11.59999999999997, 144.20000000000002, 20.000000000000014, 17.900000000000013, -180.90000000000018, 101.2999999999999, 20.000000000000014, 164.0, 15.799999999999963, -189.40000000000003, 186.49999999999991, -40.90000000000003, 184.6999999999999, -325.70000000000005, 126.49999999999994, 168.5, 172.09999999999982, -712.0999999999999, 93.79999999999998, -575.2, 9.499999999999991, -9.400000000000025, 152.29999999999995, 178.39999999999992, 38.60000000000001, -38.799999999999756, 190.69999999999996, 156.79999999999998, 178.39999999999986, 129.49999999999997, 169.1, -622.1, 169.39999999999995, -14.199999999999822, 182.0, 175.1, 163.9999999999998, 159.49999999999997, -437.8999999999998, -130.0, -670.2, -760.9, -355.0, 144.2, -415.20000000000005, 67.09999999999997, 38.899999999999984, -88.30000000000001, 125.00000000000006, 173.6, -59.400000000000034, -51.40000000000004, 185.89999999999995, -649.8, 131.6, 197.3, 89.0, 20.000000000000014, -29.5, -133.0, -499.20000000000005, -209.10000000000002, 186.49999999999997, 175.7, 140.29999999999998, 79.1, 28.700000000000138, 20.000000000000014, -100.90000000000063, 161.3, 175.7, -164.60000000000002, -129.10000000000022, -27.100000000000016, -244.90000000000003, 144.5, 129.79999999999976, 191.0, 162.2, 165.8, 110.89999999999998, 194.6, 175.10000000000002, 68.29999999999998, -4.299999999999997, 38.0, 20.000000000000014, 20.000000000000014, 56.89999999999996, -131.20000000000002, 129.79999999999998, -37.89999999999988, 116.0, 144.8, -383.80000000000007, -583.0, -352.99999999999994, -271.0, 199.1, 143.9, 134.29999999999998, -443.60000000000025, -528.6, 187.09999999999997, 165.8, 143.0, 83.89999999999998, 200.0, -459.50000000000006, -720.0, 20.000000000000014, 77.0, -357.70000000000005, 157.1, -549.7, 190.1, -91.90000000000023, 193.7, 150.49999999999994, 70.1, 71.0, 191.0, 197.29999999999998, -527.3000000000002, 189.2, 155.9, -334.0, -672.9000000000001, 194.6, 162.2, 133.4, 176.29999999999998, -344.39999999999964, 168.5, -295.5, 172.39999999999998, 190.1, 146.0, -251.0, -99.70000000000002, 82.09999999999997, 200.0, 170.0, 39.199999999999974, 196.4, -478.3999999999999, 194.6, -635.0999999999999, -458.8, 170.0], "policy_predator_policy_reward": [10.0, 7.0, 167.0, 170.0, 193.0, 141.0, 0.0, 0.0, 180.0, 232.0, 0.0, 300.0, 81.0, 44.0, 2.0, 1.0, 215.0, 0.0, 0.0, 0.0, 52.0, 66.0, 0.0, 132.0, 0.0, 0.0, 10.0, 296.0, 14.0, 4.0, 0.0, 0.0, 0.0, 124.0, 38.0, 1.0, 131.0, 100.0, 115.0, 56.0, 206.0, 98.0, 17.0, 0.0, 65.0, 106.0, 13.0, 0.0, 0.0, 50.0, 4.0, 0.0, 1.0, 0.0, 197.0, 77.0, 0.0, 0.0, 130.0, 0.0, 29.0, 29.0, 40.0, 283.0, 5.0, 22.0, 37.0, 560.0, 282.0, 321.0, 0.0, 20.0, 0.0, 0.0, 28.0, 52.0, 1.0, 0.0, 0.0, 22.0, 10.0, 503.0, 24.0, 24.0, 0.0, 8.0, 12.0, 0.0, 137.0, 387.0, 839.0, 2.0, 108.0, 164.0, 281.0, 172.0, 94.0, 34.0, 0.0, 8.0, 35.0, 42.0, 511.0, 2.0, 0.0, 0.0, 0.0, 13.0, 132.0, 0.0, 203.0, 356.0, 0.0, 8.0, 0.0, 58.0, 16.0, 15.0, 38.0, 66.0, 145.0, 0.0, 114.0, 14.0, 204.0, 2.0, 0.0, 12.0, 6.0, 14.0, 0.0, 0.0, 1.0, 2.0, 57.0, 42.0, 0.0, 0.0, 0.0, 72.0, 0.0, 49.0, 0.0, 28.0, 555.0, 525.0, 358.0, 139.0, 0.0, 16.0, 177.0, 273.0, 329.0, 372.0, 13.0, 9.0, 0.0, 0.0, 0.0, 668.0, 0.0, 41.0, 319.0, 169.0, 338.0, 237.0, 75.0, 7.0, 29.0, 19.0, 31.0, 18.0, 329.0, 246.0, 0.0, 0.0, 407.0, 430.0, 0.0, 0.0, 25.0, 0.0, 223.0, 160.0, 132.0, 170.0, 0.0, 0.0, 164.0, 66.0, 0.0, 0.0, 10.0, 5.0, 214.0, 306.0, 396.0, 437.0, 336.0, 192.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5970847374312943, "mean_inference_ms": 1.5332280687754454, "mean_action_processing_ms": 0.2586775269304756, "mean_env_wait_ms": 0.21089558468904618, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009537816047668457, "StateBufferConnector_ms": 0.0034748315811157227, "ViewRequirementAgentConnector_ms": 0.11650848388671875}, "num_episodes": 18, "episode_return_max": 392.5000000000001, "episode_return_min": -590.0999999999999, "episode_return_mean": 128.45499999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 410.46256262397117, "num_env_steps_trained_throughput_per_sec": 410.46256262397117, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 9843.438, "restore_workers_time_ms": 0.017, "training_step_time_ms": 9843.384, "sample_time_ms": 1353.923, "learn_time_ms": 8469.784, "learn_throughput": 472.267, "synch_weights_time_ms": 15.065}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "04dec_00002", "date": "2024-08-13_16-33-19", "timestamp": 1723581199, "time_this_iter_s": 9.81590986251831, "time_total_s": 633.4743735790253, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044ae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 633.4743735790253, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 41.57142857142857, "ram_util_percent": 86.48571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.033948535184381, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 3.9498860677083334, "policy_loss": -0.004108991710809133, "vf_loss": 3.953392232284344, "vf_explained_var": -0.00031995612477499344, "kl": 0.009526157096542958, "entropy": 1.1248760730501206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.082599004393533, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 7.90153106356424, "policy_loss": -0.0020338893042650646, "vf_loss": 7.903409859743068, "vf_explained_var": 0.5022485046475021, "kl": 0.014705783683333355, "entropy": 0.9662429593227527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 392.5000000000001, "episode_reward_min": -590.0999999999999, "episode_reward_mean": 165.72999999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -760.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": -15.805000000000017, "predator_policy": 98.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-124.10000000000016, -45.1999999999999, -34.19999999999981, 284.99999999999955, -1.3999999999998414, 164.2999999999994, -98.99999999999991, 159.79999999999956, 38.9000000000003, 194.39999999999972, 183.99999999999943, -43.59999999999975, 203.59999999999934, 181.9999999999996, 322.00000000000034, 56.99999999999993, 121.60000000000015, 20.10000000000017, 330.7000000000003, 79.79999999999994, 348.4999999999999, 329.9, 60.00000000000001, 203.19999999999936, 365.1, 335.5000000000002, -43.89999999999995, -590.0999999999999, 61.200000000000045, 104.89999999999998, 78.6000000000001, 306.5999999999998, -33.79999999999981, 49.100000000000016, 328.8999999999999, 121.99999999999972, -30.5, -149.3, 370.20000000000005, 277.4, 79.69999999999881, 164.39999999999952, 156.09999999999962, -28.199999999999903, 105.59999999999988, 332.800000000001, 347.99999999999994, 305.4999999999999, 246.39999999999972, 132.7, 40.0000000000003, -2.3000000000000016, 140.89999999999972, 288.8, 113.20000000000005, -127.00000000000003, 359.0, 140.70000000000013, 359.5, 330.79999999999995, 283.89999999999964, -511.4999999999998, 137.99999999999972, 287.39999999999986, 215.4, 183.80000000000004, 268.5999999999999, 311.0, 244.99999999999997, 345.1, -169.8999999999999, 356.8, 334.7, 207.0999999999999, 178.90000000000003, 336.1, -120.69999999999999, 282.0999999999997, 224.19999999999956, 237.99999999999997, 392.5000000000001, 239.20000000000002, 287.29999999999995, 303.70000000000005, 224.10000000000002, 199.59999999999988, 347.40000000000003, 269.49999999999955, 228.7999999999997, 281.69999999999993, 102.2999999999999, 92.89999999999986, 260.49999999999955, 341.5, 343.30000000000035, 267.49999999999966, 320.2, 168.6, 253.2, 39.400000000000055], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-100.0, -255.10000000000016, -236.20000000000002, 20.000000000000014, -7.300000000000033, -330.9, 118.99999999999964, 149.0, 20.000000000000014, -192.40000000000003, 131.3, 20.000000000000014, -68.20000000000005, -80.80000000000003, 11.59999999999997, 144.20000000000002, 20.000000000000014, 17.900000000000013, -180.90000000000018, 101.2999999999999, 20.000000000000014, 164.0, 15.799999999999963, -189.40000000000003, 186.49999999999991, -40.90000000000003, 184.6999999999999, -325.70000000000005, 126.49999999999994, 168.5, 172.09999999999982, -712.0999999999999, 93.79999999999998, -575.2, 9.499999999999991, -9.400000000000025, 152.29999999999995, 178.39999999999992, 38.60000000000001, -38.799999999999756, 190.69999999999996, 156.79999999999998, 178.39999999999986, 129.49999999999997, 169.1, -622.1, 169.39999999999995, -14.199999999999822, 182.0, 175.1, 163.9999999999998, 159.49999999999997, -437.8999999999998, -130.0, -670.2, -760.9, -355.0, 144.2, -415.20000000000005, 67.09999999999997, 38.899999999999984, -88.30000000000001, 125.00000000000006, 173.6, -59.400000000000034, -51.40000000000004, 185.89999999999995, -649.8, 131.6, 197.3, 89.0, 20.000000000000014, -29.5, -133.0, -499.20000000000005, -209.10000000000002, 186.49999999999997, 175.7, 140.29999999999998, 79.1, 28.700000000000138, 20.000000000000014, -100.90000000000063, 161.3, 175.7, -164.60000000000002, -129.10000000000022, -27.100000000000016, -244.90000000000003, 144.5, 129.79999999999976, 191.0, 162.2, 165.8, 110.89999999999998, 194.6, 175.10000000000002, 68.29999999999998, -4.299999999999997, 38.0, 20.000000000000014, 20.000000000000014, 56.89999999999996, -131.20000000000002, 129.79999999999998, -37.89999999999988, 116.0, 144.8, -383.80000000000007, -583.0, -352.99999999999994, -271.0, 199.1, 143.9, 134.29999999999998, -443.60000000000025, -528.6, 187.09999999999997, 165.8, 143.0, 83.89999999999998, 200.0, -459.50000000000006, -720.0, 20.000000000000014, 77.0, -357.70000000000005, 157.1, -549.7, 190.1, -91.90000000000023, 193.7, 150.49999999999994, 70.1, 71.0, 191.0, 197.29999999999998, -527.3000000000002, 189.2, 155.9, -334.0, -672.9000000000001, 194.6, 162.2, 133.4, 176.29999999999998, -344.39999999999964, 168.5, -295.5, 172.39999999999998, 190.1, 146.0, -251.0, -99.70000000000002, 82.09999999999997, 200.0, 170.0, 39.199999999999974, 196.4, -478.3999999999999, 194.6, -635.0999999999999, -458.8, 170.0, 144.2, 115.1, 139.7, 164.0, 24.8, 143.29999999999998, -237.60000000000008, 180.2, 187.4, 140.0, 196.39999999999998, 73.09999999999997, 126.19999999999999, 20.600000000000062, 193.69999999999996, -485.0, -292.99999999999943, 134.3, -360.7, -0.3999999999997641, 64.99999999999997, 195.5, 119.0, 195.5, 143.29999999999978, 200.0, 192.5, 73.99999999999997, 113.9, 167.29999999999998, 119.89999999999998, -434.3000000000002, -32.8, 200.0, -221.60000000000002, 20.000000000000014], "policy_predator_policy_reward": [131.0, 100.0, 115.0, 56.0, 206.0, 98.0, 17.0, 0.0, 65.0, 106.0, 13.0, 0.0, 0.0, 50.0, 4.0, 0.0, 1.0, 0.0, 197.0, 77.0, 0.0, 0.0, 130.0, 0.0, 29.0, 29.0, 40.0, 283.0, 5.0, 22.0, 37.0, 560.0, 282.0, 321.0, 0.0, 20.0, 0.0, 0.0, 28.0, 52.0, 1.0, 0.0, 0.0, 22.0, 10.0, 503.0, 24.0, 24.0, 0.0, 8.0, 12.0, 0.0, 137.0, 387.0, 839.0, 2.0, 108.0, 164.0, 281.0, 172.0, 94.0, 34.0, 0.0, 8.0, 35.0, 42.0, 511.0, 2.0, 0.0, 0.0, 0.0, 13.0, 132.0, 0.0, 203.0, 356.0, 0.0, 8.0, 0.0, 58.0, 16.0, 15.0, 38.0, 66.0, 145.0, 0.0, 114.0, 14.0, 204.0, 2.0, 0.0, 12.0, 6.0, 14.0, 0.0, 0.0, 1.0, 2.0, 57.0, 42.0, 0.0, 0.0, 0.0, 72.0, 0.0, 49.0, 0.0, 28.0, 555.0, 525.0, 358.0, 139.0, 0.0, 16.0, 177.0, 273.0, 329.0, 372.0, 13.0, 9.0, 0.0, 0.0, 0.0, 668.0, 0.0, 41.0, 319.0, 169.0, 338.0, 237.0, 75.0, 7.0, 29.0, 19.0, 31.0, 18.0, 329.0, 246.0, 0.0, 0.0, 407.0, 430.0, 0.0, 0.0, 25.0, 0.0, 223.0, 160.0, 132.0, 170.0, 0.0, 0.0, 164.0, 66.0, 0.0, 0.0, 10.0, 5.0, 214.0, 306.0, 396.0, 437.0, 336.0, 192.0, 28.0, 0.0, 0.0, 0.0, 0.0, 56.0, 107.0, 150.0, 0.0, 20.0, 0.0, 0.0, 53.0, 29.0, 274.0, 299.0, 172.0, 89.0, 218.0, 236.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 1.0, 0.0, 19.0, 20.0, 229.0, 254.0, 70.0, 16.0, 134.0, 107.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6013270084592376, "mean_inference_ms": 1.5473115689287695, "mean_action_processing_ms": 0.2601298754412708, "mean_env_wait_ms": 0.2131053836835723, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01288604736328125, "StateBufferConnector_ms": 0.013983964920043945, "ViewRequirementAgentConnector_ms": 0.14308691024780273}, "num_episodes": 18, "episode_return_max": 392.5000000000001, "episode_return_min": -590.0999999999999, "episode_return_mean": 165.72999999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.9452069692746, "num_env_steps_trained_throughput_per_sec": 322.9452069692746, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 10029.595, "restore_workers_time_ms": 0.017, "training_step_time_ms": 10029.541, "sample_time_ms": 1569.355, "learn_time_ms": 8441.487, "learn_throughput": 473.85, "synch_weights_time_ms": 14.775}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "04dec_00002", "date": "2024-08-13_16-33-31", "timestamp": 1723581211, "time_this_iter_s": 12.446483850479126, "time_total_s": 645.9208574295044, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04b9820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 645.9208574295044, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 53.93529411764706, "ram_util_percent": 84.7764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.059028850740226, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.8651198704406697, "policy_loss": -0.0030623286888594664, "vf_loss": 2.8675169227615234, "vf_explained_var": 0.0024722979182288762, "kl": 0.010513103104827322, "entropy": 1.0506678816502688, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.552797961108897, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 7.266263147888991, "policy_loss": -0.0025951887096559243, "vf_loss": 7.2687228556032535, "vf_explained_var": 0.538347301596687, "kl": 0.012844852454489518, "entropy": 0.9683946455281879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 392.5000000000001, "episode_reward_min": -590.0999999999999, "episode_reward_mean": 184.83599999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -760.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": -3.3220000000000116, "predator_policy": 95.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.00000000000001, 203.19999999999936, 365.1, 335.5000000000002, -43.89999999999995, -590.0999999999999, 61.200000000000045, 104.89999999999998, 78.6000000000001, 306.5999999999998, -33.79999999999981, 49.100000000000016, 328.8999999999999, 121.99999999999972, -30.5, -149.3, 370.20000000000005, 277.4, 79.69999999999881, 164.39999999999952, 156.09999999999962, -28.199999999999903, 105.59999999999988, 332.800000000001, 347.99999999999994, 305.4999999999999, 246.39999999999972, 132.7, 40.0000000000003, -2.3000000000000016, 140.89999999999972, 288.8, 113.20000000000005, -127.00000000000003, 359.0, 140.70000000000013, 359.5, 330.79999999999995, 283.89999999999964, -511.4999999999998, 137.99999999999972, 287.39999999999986, 215.4, 183.80000000000004, 268.5999999999999, 311.0, 244.99999999999997, 345.1, -169.8999999999999, 356.8, 334.7, 207.0999999999999, 178.90000000000003, 336.1, -120.69999999999999, 282.0999999999997, 224.19999999999956, 237.99999999999997, 392.5000000000001, 239.20000000000002, 287.29999999999995, 303.70000000000005, 224.10000000000002, 199.59999999999988, 347.40000000000003, 269.49999999999955, 228.7999999999997, 281.69999999999993, 102.2999999999999, 92.89999999999986, 260.49999999999955, 341.5, 343.30000000000035, 267.49999999999966, 320.2, 168.6, 253.2, 39.400000000000055, 300.69999999999993, 155.9, 205.79999999999998, 295.90000000000003, 130.50000000000003, 333.39999999999975, 280.30000000000007, 264.09999999999957, 114.79999999999976, 313.5999999999999, 177.90000000000003, 32.30000000000007, 71.39999999999998, 315.3000000000002, -96.20000000000073, 332.1, 315.4000000000008, 21.70000000000001, 209.09999999999994, 199.29999999999936, 239.8999999999999, 371.49999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [169.1, -622.1, 169.39999999999995, -14.199999999999822, 182.0, 175.1, 163.9999999999998, 159.49999999999997, -437.8999999999998, -130.0, -670.2, -760.9, -355.0, 144.2, -415.20000000000005, 67.09999999999997, 38.899999999999984, -88.30000000000001, 125.00000000000006, 173.6, -59.400000000000034, -51.40000000000004, 185.89999999999995, -649.8, 131.6, 197.3, 89.0, 20.000000000000014, -29.5, -133.0, -499.20000000000005, -209.10000000000002, 186.49999999999997, 175.7, 140.29999999999998, 79.1, 28.700000000000138, 20.000000000000014, -100.90000000000063, 161.3, 175.7, -164.60000000000002, -129.10000000000022, -27.100000000000016, -244.90000000000003, 144.5, 129.79999999999976, 191.0, 162.2, 165.8, 110.89999999999998, 194.6, 175.10000000000002, 68.29999999999998, -4.299999999999997, 38.0, 20.000000000000014, 20.000000000000014, 56.89999999999996, -131.20000000000002, 129.79999999999998, -37.89999999999988, 116.0, 144.8, -383.80000000000007, -583.0, -352.99999999999994, -271.0, 199.1, 143.9, 134.29999999999998, -443.60000000000025, -528.6, 187.09999999999997, 165.8, 143.0, 83.89999999999998, 200.0, -459.50000000000006, -720.0, 20.000000000000014, 77.0, -357.70000000000005, 157.1, -549.7, 190.1, -91.90000000000023, 193.7, 150.49999999999994, 70.1, 71.0, 191.0, 197.29999999999998, -527.3000000000002, 189.2, 155.9, -334.0, -672.9000000000001, 194.6, 162.2, 133.4, 176.29999999999998, -344.39999999999964, 168.5, -295.5, 172.39999999999998, 190.1, 146.0, -251.0, -99.70000000000002, 82.09999999999997, 200.0, 170.0, 39.199999999999974, 196.4, -478.3999999999999, 194.6, -635.0999999999999, -458.8, 170.0, 144.2, 115.1, 139.7, 164.0, 24.8, 143.29999999999998, -237.60000000000008, 180.2, 187.4, 140.0, 196.39999999999998, 73.09999999999997, 126.19999999999999, 20.600000000000062, 193.69999999999996, -485.0, -292.99999999999943, 134.3, -360.7, -0.3999999999997641, 64.99999999999997, 195.5, 119.0, 195.5, 143.29999999999978, 200.0, 192.5, 73.99999999999997, 113.9, 167.29999999999998, 119.89999999999998, -434.3000000000002, -32.8, 200.0, -221.60000000000002, 20.000000000000014, 164.0, 100.70000000000002, -397.0, 68.9, 43.40000000000002, 112.39999999999999, 104.6, 161.3, 68.00000000000003, 42.49999999999998, 173.9, 159.4999999999999, 129.2, 109.10000000000001, 185.59999999999997, 78.49999999999997, 103.99999999999997, -5.199999999999934, 115.39999999999999, 198.2, 135.5, -337.6, -31.299999999999976, -204.40000000000003, 75.79999999999998, -364.4, 142.0999999999999, 156.2, -520.1999999999991, 20.000000000000014, 155.29999999999998, 156.8, 190.99999999999994, 124.39999999999986, 20.000000000000014, -154.30000000000035, -13.0, 154.09999999999994, 179.29999999999998, 20.000000000000014, 166.09999999999997, -83.20000000000007, 170.29999999999998, 198.2], "policy_predator_policy_reward": [10.0, 503.0, 24.0, 24.0, 0.0, 8.0, 12.0, 0.0, 137.0, 387.0, 839.0, 2.0, 108.0, 164.0, 281.0, 172.0, 94.0, 34.0, 0.0, 8.0, 35.0, 42.0, 511.0, 2.0, 0.0, 0.0, 0.0, 13.0, 132.0, 0.0, 203.0, 356.0, 0.0, 8.0, 0.0, 58.0, 16.0, 15.0, 38.0, 66.0, 145.0, 0.0, 114.0, 14.0, 204.0, 2.0, 0.0, 12.0, 6.0, 14.0, 0.0, 0.0, 1.0, 2.0, 57.0, 42.0, 0.0, 0.0, 0.0, 72.0, 0.0, 49.0, 0.0, 28.0, 555.0, 525.0, 358.0, 139.0, 0.0, 16.0, 177.0, 273.0, 329.0, 372.0, 13.0, 9.0, 0.0, 0.0, 0.0, 668.0, 0.0, 41.0, 319.0, 169.0, 338.0, 237.0, 75.0, 7.0, 29.0, 19.0, 31.0, 18.0, 329.0, 246.0, 0.0, 0.0, 407.0, 430.0, 0.0, 0.0, 25.0, 0.0, 223.0, 160.0, 132.0, 170.0, 0.0, 0.0, 164.0, 66.0, 0.0, 0.0, 10.0, 5.0, 214.0, 306.0, 396.0, 437.0, 336.0, 192.0, 28.0, 0.0, 0.0, 0.0, 0.0, 56.0, 107.0, 150.0, 0.0, 20.0, 0.0, 0.0, 53.0, 29.0, 274.0, 299.0, 172.0, 89.0, 218.0, 236.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 1.0, 0.0, 19.0, 20.0, 229.0, 254.0, 70.0, 16.0, 134.0, 107.0, 33.0, 3.0, 219.0, 265.0, 50.0, 0.0, 0.0, 30.0, 9.0, 11.0, 0.0, 0.0, 29.0, 13.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 171.0, 209.0, 134.0, 134.0, 189.0, 171.0, 0.0, 17.0, 368.0, 36.0, 16.0, 4.0, 0.0, 0.0, 83.0, 73.0, 68.0, 0.0, 0.0, 0.0, 77.0, 80.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6062082491617222, "mean_inference_ms": 1.5632130316476756, "mean_action_processing_ms": 0.2617470980044033, "mean_env_wait_ms": 0.21576619833429628, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01214742660522461, "StateBufferConnector_ms": 0.014005661010742188, "ViewRequirementAgentConnector_ms": 0.14374864101409912}, "num_episodes": 22, "episode_return_max": 392.5000000000001, "episode_return_min": -590.0999999999999, "episode_return_mean": 184.83599999999996, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.43018760477247, "num_env_steps_trained_throughput_per_sec": 301.43018760477247, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 10403.033, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10402.978, "sample_time_ms": 1579.245, "learn_time_ms": 8805.513, "learn_throughput": 454.261, "synch_weights_time_ms": 15.986}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "04dec_00002", "date": "2024-08-13_16-33-45", "timestamp": 1723581225, "time_this_iter_s": 13.396048069000244, "time_total_s": 659.3169054985046, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 659.3169054985046, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 63.694736842105264, "ram_util_percent": 86.74736842105263}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9559271406953928, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.120564963262548, "policy_loss": -0.003474650686734883, "vf_loss": 2.1234846909840903, "vf_explained_var": 0.002231684689799314, "kl": 0.008769144506063711, "entropy": 1.0332602288672532, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.250911967527298, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 7.550470267401801, "policy_loss": -0.002695738200699447, "vf_loss": 7.553042381276529, "vf_explained_var": 0.5441844609364, "kl": 0.011722680544866422, "entropy": 1.0404532275187275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 392.5000000000001, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 199.601, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -720.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 668.0}, "policy_reward_mean": {"prey_policy": 21.505499999999984, "predator_policy": 78.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [332.800000000001, 347.99999999999994, 305.4999999999999, 246.39999999999972, 132.7, 40.0000000000003, -2.3000000000000016, 140.89999999999972, 288.8, 113.20000000000005, -127.00000000000003, 359.0, 140.70000000000013, 359.5, 330.79999999999995, 283.89999999999964, -511.4999999999998, 137.99999999999972, 287.39999999999986, 215.4, 183.80000000000004, 268.5999999999999, 311.0, 244.99999999999997, 345.1, -169.8999999999999, 356.8, 334.7, 207.0999999999999, 178.90000000000003, 336.1, -120.69999999999999, 282.0999999999997, 224.19999999999956, 237.99999999999997, 392.5000000000001, 239.20000000000002, 287.29999999999995, 303.70000000000005, 224.10000000000002, 199.59999999999988, 347.40000000000003, 269.49999999999955, 228.7999999999997, 281.69999999999993, 102.2999999999999, 92.89999999999986, 260.49999999999955, 341.5, 343.30000000000035, 267.49999999999966, 320.2, 168.6, 253.2, 39.400000000000055, 300.69999999999993, 155.9, 205.79999999999998, 295.90000000000003, 130.50000000000003, 333.39999999999975, 280.30000000000007, 264.09999999999957, 114.79999999999976, 313.5999999999999, 177.90000000000003, 32.30000000000007, 71.39999999999998, 315.3000000000002, -96.20000000000073, 332.1, 315.4000000000008, 21.70000000000001, 209.09999999999994, 199.29999999999936, 239.8999999999999, 371.49999999999994, 254.6, 88.5, 192.1999999999993, 184.4999999999995, 44.8, 164.59999999999914, 82.30000000000011, 37.80000000000027, 236.99999999999997, 185.59999999999943, 74.20000000000023, 167.19999999999968, 213.69999999999993, 40.0000000000003, 74.20000000000007, 293.1999999999997, 368.5000000000001, 320.1000000000002, -70.90000000000009, 123.89999999999978, 214.59999999999928, 218.19999999999925, 260.3999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [129.79999999999976, 191.0, 162.2, 165.8, 110.89999999999998, 194.6, 175.10000000000002, 68.29999999999998, -4.299999999999997, 38.0, 20.000000000000014, 20.000000000000014, 56.89999999999996, -131.20000000000002, 129.79999999999998, -37.89999999999988, 116.0, 144.8, -383.80000000000007, -583.0, -352.99999999999994, -271.0, 199.1, 143.9, 134.29999999999998, -443.60000000000025, -528.6, 187.09999999999997, 165.8, 143.0, 83.89999999999998, 200.0, -459.50000000000006, -720.0, 20.000000000000014, 77.0, -357.70000000000005, 157.1, -549.7, 190.1, -91.90000000000023, 193.7, 150.49999999999994, 70.1, 71.0, 191.0, 197.29999999999998, -527.3000000000002, 189.2, 155.9, -334.0, -672.9000000000001, 194.6, 162.2, 133.4, 176.29999999999998, -344.39999999999964, 168.5, -295.5, 172.39999999999998, 190.1, 146.0, -251.0, -99.70000000000002, 82.09999999999997, 200.0, 170.0, 39.199999999999974, 196.4, -478.3999999999999, 194.6, -635.0999999999999, -458.8, 170.0, 144.2, 115.1, 139.7, 164.0, 24.8, 143.29999999999998, -237.60000000000008, 180.2, 187.4, 140.0, 196.39999999999998, 73.09999999999997, 126.19999999999999, 20.600000000000062, 193.69999999999996, -485.0, -292.99999999999943, 134.3, -360.7, -0.3999999999997641, 64.99999999999997, 195.5, 119.0, 195.5, 143.29999999999978, 200.0, 192.5, 73.99999999999997, 113.9, 167.29999999999998, 119.89999999999998, -434.3000000000002, -32.8, 200.0, -221.60000000000002, 20.000000000000014, 164.0, 100.70000000000002, -397.0, 68.9, 43.40000000000002, 112.39999999999999, 104.6, 161.3, 68.00000000000003, 42.49999999999998, 173.9, 159.4999999999999, 129.2, 109.10000000000001, 185.59999999999997, 78.49999999999997, 103.99999999999997, -5.199999999999934, 115.39999999999999, 198.2, 135.5, -337.6, -31.299999999999976, -204.40000000000003, 75.79999999999998, -364.4, 142.0999999999999, 156.2, -520.1999999999991, 20.000000000000014, 155.29999999999998, 156.8, 190.99999999999994, 124.39999999999986, 20.000000000000014, -154.30000000000035, -13.0, 154.09999999999994, 179.29999999999998, 20.000000000000014, 166.09999999999997, -83.20000000000007, 170.29999999999998, 198.2, 120.5, 118.1, 94.09999999999998, -142.60000000000045, 170.29999999999998, 17.899999999999988, 41.59999999999998, 131.89999999999995, 37.1, -217.30000000000013, -45.099999999999824, 166.6999999999998, 62.29999999999996, 20.000000000000014, 20.000000000000014, 15.799999999999963, 50.0, 130.99999999999997, 20.000000000000014, 140.6, 23.60000000000001, 50.59999999999999, 12.499999999999961, 100.69999999999999, 115.39999999999995, 62.300000000000004, 20.000000000000014, 20.000000000000014, -17.799999999999997, 20.000000000000014, 145.09999999999982, 127.09999999999995, 197.29999999999998, 171.19999999999982, 159.7999999999999, 152.29999999999995, -395.5000000000001, -199.40000000000066, 20.000000000000014, 59.9, 20.000000000000014, 194.6, 198.2, 20.000000000000014, 141.8, 104.60000000000002], "policy_predator_policy_reward": [0.0, 12.0, 6.0, 14.0, 0.0, 0.0, 1.0, 2.0, 57.0, 42.0, 0.0, 0.0, 0.0, 72.0, 0.0, 49.0, 0.0, 28.0, 555.0, 525.0, 358.0, 139.0, 0.0, 16.0, 177.0, 273.0, 329.0, 372.0, 13.0, 9.0, 0.0, 0.0, 0.0, 668.0, 0.0, 41.0, 319.0, 169.0, 338.0, 237.0, 75.0, 7.0, 29.0, 19.0, 31.0, 18.0, 329.0, 246.0, 0.0, 0.0, 407.0, 430.0, 0.0, 0.0, 25.0, 0.0, 223.0, 160.0, 132.0, 170.0, 0.0, 0.0, 164.0, 66.0, 0.0, 0.0, 10.0, 5.0, 214.0, 306.0, 396.0, 437.0, 336.0, 192.0, 28.0, 0.0, 0.0, 0.0, 0.0, 56.0, 107.0, 150.0, 0.0, 20.0, 0.0, 0.0, 53.0, 29.0, 274.0, 299.0, 172.0, 89.0, 218.0, 236.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 1.0, 0.0, 19.0, 20.0, 229.0, 254.0, 70.0, 16.0, 134.0, 107.0, 33.0, 3.0, 219.0, 265.0, 50.0, 0.0, 0.0, 30.0, 9.0, 11.0, 0.0, 0.0, 29.0, 13.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 171.0, 209.0, 134.0, 134.0, 189.0, 171.0, 0.0, 17.0, 368.0, 36.0, 16.0, 4.0, 0.0, 0.0, 83.0, 73.0, 68.0, 0.0, 0.0, 0.0, 77.0, 80.0, 0.0, 3.0, 16.0, 0.0, 58.0, 79.0, 0.0, 4.0, 11.0, 0.0, 113.0, 112.0, 26.0, 17.0, 0.0, 0.0, 2.0, 0.0, 0.0, 56.0, 8.0, 17.0, 0.0, 0.0, 34.0, 20.0, 14.0, 22.0, 0.0, 0.0, 72.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 8.0, 292.0, 232.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6122623538673927, "mean_inference_ms": 1.5842664152021704, "mean_action_processing_ms": 0.26396798933364424, "mean_env_wait_ms": 0.2188793705287573, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008082747459411621, "StateBufferConnector_ms": 0.014127373695373535, "ViewRequirementAgentConnector_ms": 0.15471768379211426}, "num_episodes": 23, "episode_return_max": 392.5000000000001, "episode_return_min": -511.4999999999998, "episode_return_mean": 199.601, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.6019916135968, "num_env_steps_trained_throughput_per_sec": 329.6019916135968, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 10648.557, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10648.502, "sample_time_ms": 1649.632, "learn_time_ms": 8979.423, "learn_throughput": 445.463, "synch_weights_time_ms": 16.454}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "04dec_00002", "date": "2024-08-13_16-33-57", "timestamp": 1723581237, "time_this_iter_s": 12.203553915023804, "time_total_s": 671.5204594135284, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0616550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 671.5204594135284, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 67.7388888888889, "ram_util_percent": 84.56111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1137403778298192, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 1.8078886676086952, "policy_loss": -0.004892488837330824, "vf_loss": 1.812197881117069, "vf_explained_var": 0.027091014259075993, "kl": 0.009217155567519454, "entropy": 1.0637175336716667, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.6777207908807, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 8.256076855381961, "policy_loss": -0.0004958988005965553, "vf_loss": 8.256466216637344, "vf_explained_var": 0.336584015624233, "kl": 0.010101379554945323, "entropy": 0.889887005406082, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 392.5000000000001, "episode_reward_min": -169.8999999999999, "episode_reward_mean": 197.47599999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -672.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 437.0}, "policy_reward_mean": {"prey_policy": 35.88799999999998, "predator_policy": 62.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [287.39999999999986, 215.4, 183.80000000000004, 268.5999999999999, 311.0, 244.99999999999997, 345.1, -169.8999999999999, 356.8, 334.7, 207.0999999999999, 178.90000000000003, 336.1, -120.69999999999999, 282.0999999999997, 224.19999999999956, 237.99999999999997, 392.5000000000001, 239.20000000000002, 287.29999999999995, 303.70000000000005, 224.10000000000002, 199.59999999999988, 347.40000000000003, 269.49999999999955, 228.7999999999997, 281.69999999999993, 102.2999999999999, 92.89999999999986, 260.49999999999955, 341.5, 343.30000000000035, 267.49999999999966, 320.2, 168.6, 253.2, 39.400000000000055, 300.69999999999993, 155.9, 205.79999999999998, 295.90000000000003, 130.50000000000003, 333.39999999999975, 280.30000000000007, 264.09999999999957, 114.79999999999976, 313.5999999999999, 177.90000000000003, 32.30000000000007, 71.39999999999998, 315.3000000000002, -96.20000000000073, 332.1, 315.4000000000008, 21.70000000000001, 209.09999999999994, 199.29999999999936, 239.8999999999999, 371.49999999999994, 254.6, 88.5, 192.1999999999993, 184.4999999999995, 44.8, 164.59999999999914, 82.30000000000011, 37.80000000000027, 236.99999999999997, 185.59999999999943, 74.20000000000023, 167.19999999999968, 213.69999999999993, 40.0000000000003, 74.20000000000007, 293.1999999999997, 368.5000000000001, 320.1000000000002, -70.90000000000009, 123.89999999999978, 214.59999999999928, 218.19999999999925, 260.3999999999999, 96.99999999999996, 83.09999999999997, 172.79999999999941, 317.19999999999993, 157.1999999999992, 238.69999999999985, 139.69999999999962, 243.89999999999978, 24.90000000000014, 277.5999999999998, 40.0000000000003, 129.0999999999996, 128.8999999999998, 57.70000000000022, 174.09999999999897, 100.8999999999986, 120.29999999999978, 203.79999999999916], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-357.70000000000005, 157.1, -549.7, 190.1, -91.90000000000023, 193.7, 150.49999999999994, 70.1, 71.0, 191.0, 197.29999999999998, -527.3000000000002, 189.2, 155.9, -334.0, -672.9000000000001, 194.6, 162.2, 133.4, 176.29999999999998, -344.39999999999964, 168.5, -295.5, 172.39999999999998, 190.1, 146.0, -251.0, -99.70000000000002, 82.09999999999997, 200.0, 170.0, 39.199999999999974, 196.4, -478.3999999999999, 194.6, -635.0999999999999, -458.8, 170.0, 144.2, 115.1, 139.7, 164.0, 24.8, 143.29999999999998, -237.60000000000008, 180.2, 187.4, 140.0, 196.39999999999998, 73.09999999999997, 126.19999999999999, 20.600000000000062, 193.69999999999996, -485.0, -292.99999999999943, 134.3, -360.7, -0.3999999999997641, 64.99999999999997, 195.5, 119.0, 195.5, 143.29999999999978, 200.0, 192.5, 73.99999999999997, 113.9, 167.29999999999998, 119.89999999999998, -434.3000000000002, -32.8, 200.0, -221.60000000000002, 20.000000000000014, 164.0, 100.70000000000002, -397.0, 68.9, 43.40000000000002, 112.39999999999999, 104.6, 161.3, 68.00000000000003, 42.49999999999998, 173.9, 159.4999999999999, 129.2, 109.10000000000001, 185.59999999999997, 78.49999999999997, 103.99999999999997, -5.199999999999934, 115.39999999999999, 198.2, 135.5, -337.6, -31.299999999999976, -204.40000000000003, 75.79999999999998, -364.4, 142.0999999999999, 156.2, -520.1999999999991, 20.000000000000014, 155.29999999999998, 156.8, 190.99999999999994, 124.39999999999986, 20.000000000000014, -154.30000000000035, -13.0, 154.09999999999994, 179.29999999999998, 20.000000000000014, 166.09999999999997, -83.20000000000007, 170.29999999999998, 198.2, 120.5, 118.1, 94.09999999999998, -142.60000000000045, 170.29999999999998, 17.899999999999988, 41.59999999999998, 131.89999999999995, 37.1, -217.30000000000013, -45.099999999999824, 166.6999999999998, 62.29999999999996, 20.000000000000014, 20.000000000000014, 15.799999999999963, 50.0, 130.99999999999997, 20.000000000000014, 140.6, 23.60000000000001, 50.59999999999999, 12.499999999999961, 100.69999999999999, 115.39999999999995, 62.300000000000004, 20.000000000000014, 20.000000000000014, -17.799999999999997, 20.000000000000014, 145.09999999999982, 127.09999999999995, 197.29999999999998, 171.19999999999982, 159.7999999999999, 152.29999999999995, -395.5000000000001, -199.40000000000066, 20.000000000000014, 59.9, 20.000000000000014, 194.6, 198.2, 20.000000000000014, 141.8, 104.60000000000002, 5.599999999999945, 19.40000000000009, 22.70000000000001, 16.400000000000055, 114.8, 20.000000000000014, 128.30000000000004, 173.89999999999998, 20.000000000000014, 129.1999999999998, 172.3999999999999, 5.300000000000004, 32.30000000000001, 22.39999999999999, 147.19999999999993, 85.70000000000003, -150.10000000000014, 20.000000000000014, 166.70000000000002, 74.9, 20.000000000000014, 20.000000000000014, 100.1, 20.000000000000014, 24.799999999999958, 91.1, 43.400000000000084, -3.6999999999998945, 154.0999999999997, 20.000000000000014, 7.399999999999965, 87.4999999999993, -118.6, 140.8999999999998, 20.000000000000014, 183.7999999999999], "policy_predator_policy_reward": [319.0, 169.0, 338.0, 237.0, 75.0, 7.0, 29.0, 19.0, 31.0, 18.0, 329.0, 246.0, 0.0, 0.0, 407.0, 430.0, 0.0, 0.0, 25.0, 0.0, 223.0, 160.0, 132.0, 170.0, 0.0, 0.0, 164.0, 66.0, 0.0, 0.0, 10.0, 5.0, 214.0, 306.0, 396.0, 437.0, 336.0, 192.0, 28.0, 0.0, 0.0, 0.0, 0.0, 56.0, 107.0, 150.0, 0.0, 20.0, 0.0, 0.0, 53.0, 29.0, 274.0, 299.0, 172.0, 89.0, 218.0, 236.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 1.0, 0.0, 19.0, 20.0, 229.0, 254.0, 70.0, 16.0, 134.0, 107.0, 33.0, 3.0, 219.0, 265.0, 50.0, 0.0, 0.0, 30.0, 9.0, 11.0, 0.0, 0.0, 29.0, 13.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 171.0, 209.0, 134.0, 134.0, 189.0, 171.0, 0.0, 17.0, 368.0, 36.0, 16.0, 4.0, 0.0, 0.0, 83.0, 73.0, 68.0, 0.0, 0.0, 0.0, 77.0, 80.0, 0.0, 3.0, 16.0, 0.0, 58.0, 79.0, 0.0, 4.0, 11.0, 0.0, 113.0, 112.0, 26.0, 17.0, 0.0, 0.0, 2.0, 0.0, 0.0, 56.0, 8.0, 17.0, 0.0, 0.0, 34.0, 20.0, 14.0, 22.0, 0.0, 0.0, 72.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 8.0, 292.0, 232.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 17.0, 55.0, 7.0, 37.0, 15.0, 23.0, 15.0, 0.0, 8.0, 0.0, 0.0, 61.0, 59.0, 26.0, 9.0, 2.0, 77.0, 78.0, 18.0, 18.0, 0.0, 0.0, 9.0, 0.0, 12.0, 1.0, 3.0, 15.0, 0.0, 0.0, 6.0, 0.0, 69.0, 29.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6186183710429628, "mean_inference_ms": 1.604916103884124, "mean_action_processing_ms": 0.2662092875731133, "mean_env_wait_ms": 0.22172005404815784, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008498668670654297, "StateBufferConnector_ms": 0.014253854751586914, "ViewRequirementAgentConnector_ms": 0.16835856437683105}, "num_episodes": 18, "episode_return_max": 392.5000000000001, "episode_return_min": -169.8999999999999, "episode_return_mean": 197.47599999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.75216432816376, "num_env_steps_trained_throughput_per_sec": 333.75216432816376, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 10850.456, "restore_workers_time_ms": 0.019, "training_step_time_ms": 10850.399, "sample_time_ms": 1744.636, "learn_time_ms": 9085.735, "learn_throughput": 440.251, "synch_weights_time_ms": 16.853}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "04dec_00002", "date": "2024-08-13_16-34-09", "timestamp": 1723581249, "time_this_iter_s": 12.058748960494995, "time_total_s": 683.5792083740234, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06164c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 683.5792083740234, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 58.705882352941174, "ram_util_percent": 84.12352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.879666531306726, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 1.4485678506591333, "policy_loss": -0.004453695002603271, "vf_loss": 1.452633846184564, "vf_explained_var": 0.014371869204536317, "kl": 0.006126522114140217, "entropy": 1.0427824775693277, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.574280168928166, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 8.471887259003978, "policy_loss": -0.0015863208103895424, "vf_loss": 8.473348931660729, "vf_explained_var": 0.2636417324896212, "kl": 0.011817143317288411, "entropy": 0.8798196033195212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 371.49999999999994, "episode_reward_min": -96.20000000000073, "episode_reward_mean": 188.94499999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -520.1999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 368.0}, "policy_reward_mean": {"prey_policy": 54.03749999999997, "predator_policy": 40.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [239.20000000000002, 287.29999999999995, 303.70000000000005, 224.10000000000002, 199.59999999999988, 347.40000000000003, 269.49999999999955, 228.7999999999997, 281.69999999999993, 102.2999999999999, 92.89999999999986, 260.49999999999955, 341.5, 343.30000000000035, 267.49999999999966, 320.2, 168.6, 253.2, 39.400000000000055, 300.69999999999993, 155.9, 205.79999999999998, 295.90000000000003, 130.50000000000003, 333.39999999999975, 280.30000000000007, 264.09999999999957, 114.79999999999976, 313.5999999999999, 177.90000000000003, 32.30000000000007, 71.39999999999998, 315.3000000000002, -96.20000000000073, 332.1, 315.4000000000008, 21.70000000000001, 209.09999999999994, 199.29999999999936, 239.8999999999999, 371.49999999999994, 254.6, 88.5, 192.1999999999993, 184.4999999999995, 44.8, 164.59999999999914, 82.30000000000011, 37.80000000000027, 236.99999999999997, 185.59999999999943, 74.20000000000023, 167.19999999999968, 213.69999999999993, 40.0000000000003, 74.20000000000007, 293.1999999999997, 368.5000000000001, 320.1000000000002, -70.90000000000009, 123.89999999999978, 214.59999999999928, 218.19999999999925, 260.3999999999999, 96.99999999999996, 83.09999999999997, 172.79999999999941, 317.19999999999993, 157.1999999999992, 238.69999999999985, 139.69999999999962, 243.89999999999978, 24.90000000000014, 277.5999999999998, 40.0000000000003, 129.0999999999996, 128.8999999999998, 57.70000000000022, 174.09999999999897, 100.8999999999986, 120.29999999999978, 203.79999999999916, 269.1999999999998, 163.9999999999995, 152.3999999999994, 306.8000000000006, 40.0000000000003, 40.0000000000003, 191.9999999999998, 100.29999999999936, 317.9000000000002, 125.49999999999909, 318.09999999999974, 277.09999999999985, 201.09999999999928, 173.6999999999999, -50.499999999999964, 250.5999999999996, 252.8, 131.9999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-458.8, 170.0, 144.2, 115.1, 139.7, 164.0, 24.8, 143.29999999999998, -237.60000000000008, 180.2, 187.4, 140.0, 196.39999999999998, 73.09999999999997, 126.19999999999999, 20.600000000000062, 193.69999999999996, -485.0, -292.99999999999943, 134.3, -360.7, -0.3999999999997641, 64.99999999999997, 195.5, 119.0, 195.5, 143.29999999999978, 200.0, 192.5, 73.99999999999997, 113.9, 167.29999999999998, 119.89999999999998, -434.3000000000002, -32.8, 200.0, -221.60000000000002, 20.000000000000014, 164.0, 100.70000000000002, -397.0, 68.9, 43.40000000000002, 112.39999999999999, 104.6, 161.3, 68.00000000000003, 42.49999999999998, 173.9, 159.4999999999999, 129.2, 109.10000000000001, 185.59999999999997, 78.49999999999997, 103.99999999999997, -5.199999999999934, 115.39999999999999, 198.2, 135.5, -337.6, -31.299999999999976, -204.40000000000003, 75.79999999999998, -364.4, 142.0999999999999, 156.2, -520.1999999999991, 20.000000000000014, 155.29999999999998, 156.8, 190.99999999999994, 124.39999999999986, 20.000000000000014, -154.30000000000035, -13.0, 154.09999999999994, 179.29999999999998, 20.000000000000014, 166.09999999999997, -83.20000000000007, 170.29999999999998, 198.2, 120.5, 118.1, 94.09999999999998, -142.60000000000045, 170.29999999999998, 17.899999999999988, 41.59999999999998, 131.89999999999995, 37.1, -217.30000000000013, -45.099999999999824, 166.6999999999998, 62.29999999999996, 20.000000000000014, 20.000000000000014, 15.799999999999963, 50.0, 130.99999999999997, 20.000000000000014, 140.6, 23.60000000000001, 50.59999999999999, 12.499999999999961, 100.69999999999999, 115.39999999999995, 62.300000000000004, 20.000000000000014, 20.000000000000014, -17.799999999999997, 20.000000000000014, 145.09999999999982, 127.09999999999995, 197.29999999999998, 171.19999999999982, 159.7999999999999, 152.29999999999995, -395.5000000000001, -199.40000000000066, 20.000000000000014, 59.9, 20.000000000000014, 194.6, 198.2, 20.000000000000014, 141.8, 104.60000000000002, 5.599999999999945, 19.40000000000009, 22.70000000000001, 16.400000000000055, 114.8, 20.000000000000014, 128.30000000000004, 173.89999999999998, 20.000000000000014, 129.1999999999998, 172.3999999999999, 5.300000000000004, 32.30000000000001, 22.39999999999999, 147.19999999999993, 85.70000000000003, -150.10000000000014, 20.000000000000014, 166.70000000000002, 74.9, 20.000000000000014, 20.000000000000014, 100.1, 20.000000000000014, 24.799999999999958, 91.1, 43.400000000000084, -3.6999999999998945, 154.0999999999997, 20.000000000000014, 7.399999999999965, 87.4999999999993, -118.6, 140.8999999999998, 20.000000000000014, 183.7999999999999, 108.50000000000003, 133.69999999999993, 121.99999999999997, 20.000000000000014, 12.200000000000006, 69.19999999999976, 133.99999999999994, 165.79999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, 94.0999999999998, 51.50000000000005, 48.80000000000013, 127.69999999999989, 180.19999999999993, 105.49999999999964, 20.000000000000014, 188.29999999999993, 129.8, 118.69999999999999, 127.39999999999986, 20.000000000000014, 181.09999999999997, 63.8, 59.900000000000055, 17.899999999999984, -201.40000000000003, 151.99999999999983, 71.60000000000005, 126.19999999999999, 119.60000000000002, 39.20000000000001, 3.8000000000000504], "policy_predator_policy_reward": [336.0, 192.0, 28.0, 0.0, 0.0, 0.0, 0.0, 56.0, 107.0, 150.0, 0.0, 20.0, 0.0, 0.0, 53.0, 29.0, 274.0, 299.0, 172.0, 89.0, 218.0, 236.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 1.0, 0.0, 19.0, 20.0, 229.0, 254.0, 70.0, 16.0, 134.0, 107.0, 33.0, 3.0, 219.0, 265.0, 50.0, 0.0, 0.0, 30.0, 9.0, 11.0, 0.0, 0.0, 29.0, 13.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 171.0, 209.0, 134.0, 134.0, 189.0, 171.0, 0.0, 17.0, 368.0, 36.0, 16.0, 4.0, 0.0, 0.0, 83.0, 73.0, 68.0, 0.0, 0.0, 0.0, 77.0, 80.0, 0.0, 3.0, 16.0, 0.0, 58.0, 79.0, 0.0, 4.0, 11.0, 0.0, 113.0, 112.0, 26.0, 17.0, 0.0, 0.0, 2.0, 0.0, 0.0, 56.0, 8.0, 17.0, 0.0, 0.0, 34.0, 20.0, 14.0, 22.0, 0.0, 0.0, 72.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 8.0, 292.0, 232.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 17.0, 55.0, 7.0, 37.0, 15.0, 23.0, 15.0, 0.0, 8.0, 0.0, 0.0, 61.0, 59.0, 26.0, 9.0, 2.0, 77.0, 78.0, 18.0, 18.0, 0.0, 0.0, 9.0, 0.0, 12.0, 1.0, 3.0, 15.0, 0.0, 0.0, 6.0, 0.0, 69.0, 29.0, 0.0, 0.0, 15.0, 12.0, 13.0, 9.0, 56.0, 15.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 33.0, 17.0, 0.0, 133.0, 27.0, 0.0, 6.0, 1.0, 19.0, 70.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6250514635994583, "mean_inference_ms": 1.6251593268043942, "mean_action_processing_ms": 0.2684389147219146, "mean_env_wait_ms": 0.22455210295279876, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008566856384277344, "StateBufferConnector_ms": 0.014295339584350586, "ViewRequirementAgentConnector_ms": 0.17659437656402588}, "num_episodes": 18, "episode_return_max": 371.49999999999994, "episode_return_min": -96.20000000000073, "episode_return_mean": 188.94499999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.2414861036469, "num_env_steps_trained_throughput_per_sec": 388.2414861036469, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 10904.907, "restore_workers_time_ms": 0.02, "training_step_time_ms": 10904.848, "sample_time_ms": 1769.038, "learn_time_ms": 9115.468, "learn_throughput": 438.815, "synch_weights_time_ms": 16.836}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "04dec_00002", "date": "2024-08-13_16-34-20", "timestamp": 1723581260, "time_this_iter_s": 10.378809928894043, "time_total_s": 693.9580183029175, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b064bdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 693.9580183029175, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 45.28666666666666, "ram_util_percent": 85.68666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9798672804204875, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.535152317354919, "policy_loss": -0.005394877771669556, "vf_loss": 2.5397200135957627, "vf_explained_var": 0.005851482115094624, "kl": 0.013071392688562325, "entropy": 1.001079087408762, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.05431374494361, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 9.19831564968856, "policy_loss": -0.0012678399190513623, "vf_loss": 9.199509542959708, "vf_explained_var": -0.577723138862186, "kl": 0.007010242574895567, "entropy": 0.949758164151005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 371.49999999999994, "episode_reward_min": -258.4999999999999, "episode_reward_mean": 140.88399999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -520.1999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 368.0}, "policy_reward_mean": {"prey_policy": 41.96699999999996, "predator_policy": 28.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [295.90000000000003, 130.50000000000003, 333.39999999999975, 280.30000000000007, 264.09999999999957, 114.79999999999976, 313.5999999999999, 177.90000000000003, 32.30000000000007, 71.39999999999998, 315.3000000000002, -96.20000000000073, 332.1, 315.4000000000008, 21.70000000000001, 209.09999999999994, 199.29999999999936, 239.8999999999999, 371.49999999999994, 254.6, 88.5, 192.1999999999993, 184.4999999999995, 44.8, 164.59999999999914, 82.30000000000011, 37.80000000000027, 236.99999999999997, 185.59999999999943, 74.20000000000023, 167.19999999999968, 213.69999999999993, 40.0000000000003, 74.20000000000007, 293.1999999999997, 368.5000000000001, 320.1000000000002, -70.90000000000009, 123.89999999999978, 214.59999999999928, 218.19999999999925, 260.3999999999999, 96.99999999999996, 83.09999999999997, 172.79999999999941, 317.19999999999993, 157.1999999999992, 238.69999999999985, 139.69999999999962, 243.89999999999978, 24.90000000000014, 277.5999999999998, 40.0000000000003, 129.0999999999996, 128.8999999999998, 57.70000000000022, 174.09999999999897, 100.8999999999986, 120.29999999999978, 203.79999999999916, 269.1999999999998, 163.9999999999995, 152.3999999999994, 306.8000000000006, 40.0000000000003, 40.0000000000003, 191.9999999999998, 100.29999999999936, 317.9000000000002, 125.49999999999909, 318.09999999999974, 277.09999999999985, 201.09999999999928, 173.6999999999999, -50.499999999999964, 250.5999999999996, 252.8, 131.9999999999998, 133.89999999999915, -48.299999999999926, 40.0000000000003, 22.800000000000004, 58.900000000000404, 214.59999999999945, 36.70000000000025, 252.3999999999993, 19.500000000000192, -38.09999999999976, 38.90000000000028, -244.7000000000004, 172.29999999999913, 40.0000000000003, 40.0000000000003, -258.4999999999999, 36.70000000000025, -37.69999999999969, -95.10000000000021, -68.00000000000071, 126.19999999999936, -15.499999999999874], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [104.6, 161.3, 68.00000000000003, 42.49999999999998, 173.9, 159.4999999999999, 129.2, 109.10000000000001, 185.59999999999997, 78.49999999999997, 103.99999999999997, -5.199999999999934, 115.39999999999999, 198.2, 135.5, -337.6, -31.299999999999976, -204.40000000000003, 75.79999999999998, -364.4, 142.0999999999999, 156.2, -520.1999999999991, 20.000000000000014, 155.29999999999998, 156.8, 190.99999999999994, 124.39999999999986, 20.000000000000014, -154.30000000000035, -13.0, 154.09999999999994, 179.29999999999998, 20.000000000000014, 166.09999999999997, -83.20000000000007, 170.29999999999998, 198.2, 120.5, 118.1, 94.09999999999998, -142.60000000000045, 170.29999999999998, 17.899999999999988, 41.59999999999998, 131.89999999999995, 37.1, -217.30000000000013, -45.099999999999824, 166.6999999999998, 62.29999999999996, 20.000000000000014, 20.000000000000014, 15.799999999999963, 50.0, 130.99999999999997, 20.000000000000014, 140.6, 23.60000000000001, 50.59999999999999, 12.499999999999961, 100.69999999999999, 115.39999999999995, 62.300000000000004, 20.000000000000014, 20.000000000000014, -17.799999999999997, 20.000000000000014, 145.09999999999982, 127.09999999999995, 197.29999999999998, 171.19999999999982, 159.7999999999999, 152.29999999999995, -395.5000000000001, -199.40000000000066, 20.000000000000014, 59.9, 20.000000000000014, 194.6, 198.2, 20.000000000000014, 141.8, 104.60000000000002, 5.599999999999945, 19.40000000000009, 22.70000000000001, 16.400000000000055, 114.8, 20.000000000000014, 128.30000000000004, 173.89999999999998, 20.000000000000014, 129.1999999999998, 172.3999999999999, 5.300000000000004, 32.30000000000001, 22.39999999999999, 147.19999999999993, 85.70000000000003, -150.10000000000014, 20.000000000000014, 166.70000000000002, 74.9, 20.000000000000014, 20.000000000000014, 100.1, 20.000000000000014, 24.799999999999958, 91.1, 43.400000000000084, -3.6999999999998945, 154.0999999999997, 20.000000000000014, 7.399999999999965, 87.4999999999993, -118.6, 140.8999999999998, 20.000000000000014, 183.7999999999999, 108.50000000000003, 133.69999999999993, 121.99999999999997, 20.000000000000014, 12.200000000000006, 69.19999999999976, 133.99999999999994, 165.79999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, 94.0999999999998, 51.50000000000005, 48.80000000000013, 127.69999999999989, 180.19999999999993, 105.49999999999964, 20.000000000000014, 188.29999999999993, 129.8, 118.69999999999999, 127.39999999999986, 20.000000000000014, 181.09999999999997, 63.8, 59.900000000000055, 17.899999999999984, -201.40000000000003, 151.99999999999983, 71.60000000000005, 126.19999999999999, 119.60000000000002, 39.20000000000001, 3.8000000000000504, 13.699999999999964, 117.1999999999997, -63.099999999999945, -209.20000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -56.19999999999998, 20.000000000000014, 38.9000000000002, 104.59999999999977, 109.99999999999979, 13.699999999999964, 20.000000000000014, 145.99999999999991, 106.39999999999979, -36.69999999999992, -23.79999999999997, -213.10000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, -162.09999999999997, -259.60000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -298.9, -130.60000000000005, 20.000000000000014, 13.699999999999964, -24.099999999999937, -82.6, -130.00000000000026, -84.10000000000008, -1.6000000000000276, -171.40000000000043, 78.19999999999985, 20.000000000000014, -92.50000000000006, -40.000000000000284], "policy_predator_policy_reward": [0.0, 30.0, 9.0, 11.0, 0.0, 0.0, 29.0, 13.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 171.0, 209.0, 134.0, 134.0, 189.0, 171.0, 0.0, 17.0, 368.0, 36.0, 16.0, 4.0, 0.0, 0.0, 83.0, 73.0, 68.0, 0.0, 0.0, 0.0, 77.0, 80.0, 0.0, 3.0, 16.0, 0.0, 58.0, 79.0, 0.0, 4.0, 11.0, 0.0, 113.0, 112.0, 26.0, 17.0, 0.0, 0.0, 2.0, 0.0, 0.0, 56.0, 8.0, 17.0, 0.0, 0.0, 34.0, 20.0, 14.0, 22.0, 0.0, 0.0, 72.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 8.0, 292.0, 232.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 17.0, 55.0, 7.0, 37.0, 15.0, 23.0, 15.0, 0.0, 8.0, 0.0, 0.0, 61.0, 59.0, 26.0, 9.0, 2.0, 77.0, 78.0, 18.0, 18.0, 0.0, 0.0, 9.0, 0.0, 12.0, 1.0, 3.0, 15.0, 0.0, 0.0, 6.0, 0.0, 69.0, 29.0, 0.0, 0.0, 15.0, 12.0, 13.0, 9.0, 56.0, 15.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 33.0, 17.0, 0.0, 133.0, 27.0, 0.0, 6.0, 1.0, 19.0, 70.0, 0.0, 3.0, 123.0, 101.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 80.0, 22.0, 133.0, 1.0, 0.0, 20.0, 157.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 0.0, 3.0, 69.0, 0.0, 19.0, 100.0, 0.0, 105.0, 0.0, 28.0, 0.0, 117.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6298498457488316, "mean_inference_ms": 1.6385143707058871, "mean_action_processing_ms": 0.26983294946039776, "mean_env_wait_ms": 0.2259981066686214, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004933714866638184, "StateBufferConnector_ms": 0.003880143165588379, "ViewRequirementAgentConnector_ms": 0.15052759647369385}, "num_episodes": 22, "episode_return_max": 371.49999999999994, "episode_return_min": -258.4999999999999, "episode_return_mean": 140.88399999999984, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 405.4707711951395, "num_env_steps_trained_throughput_per_sec": 405.4707711951395, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 10905.807, "restore_workers_time_ms": 0.019, "training_step_time_ms": 10905.748, "sample_time_ms": 1798.511, "learn_time_ms": 9087.761, "learn_throughput": 440.152, "synch_weights_time_ms": 15.902}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "04dec_00002", "date": "2024-08-13_16-34-30", "timestamp": 1723581270, "time_this_iter_s": 9.912162065505981, "time_total_s": 703.8701803684235, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0616ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 703.8701803684235, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 40.23571428571428, "ram_util_percent": 86.39999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0444864172389898, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 4.463080994288126, "policy_loss": -0.003416072497164052, "vf_loss": 4.465892654751975, "vf_explained_var": 0.01652285377815287, "kl": 0.009551176509727767, "entropy": 0.9703466913372121, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.4973411204796, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 9.260945915545106, "policy_loss": -0.0031263883098733253, "vf_loss": 9.263865190839011, "vf_explained_var": -0.32865924690135573, "kl": 0.019637534630375743, "entropy": 0.8584845567191088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 371.49999999999994, "episode_reward_min": -272.8000000000001, "episode_reward_mean": 109.32199999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.5000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 292.0}, "policy_reward_mean": {"prey_policy": 27.42599999999995, "predator_policy": 27.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [371.49999999999994, 254.6, 88.5, 192.1999999999993, 184.4999999999995, 44.8, 164.59999999999914, 82.30000000000011, 37.80000000000027, 236.99999999999997, 185.59999999999943, 74.20000000000023, 167.19999999999968, 213.69999999999993, 40.0000000000003, 74.20000000000007, 293.1999999999997, 368.5000000000001, 320.1000000000002, -70.90000000000009, 123.89999999999978, 214.59999999999928, 218.19999999999925, 260.3999999999999, 96.99999999999996, 83.09999999999997, 172.79999999999941, 317.19999999999993, 157.1999999999992, 238.69999999999985, 139.69999999999962, 243.89999999999978, 24.90000000000014, 277.5999999999998, 40.0000000000003, 129.0999999999996, 128.8999999999998, 57.70000000000022, 174.09999999999897, 100.8999999999986, 120.29999999999978, 203.79999999999916, 269.1999999999998, 163.9999999999995, 152.3999999999994, 306.8000000000006, 40.0000000000003, 40.0000000000003, 191.9999999999998, 100.29999999999936, 317.9000000000002, 125.49999999999909, 318.09999999999974, 277.09999999999985, 201.09999999999928, 173.6999999999999, -50.499999999999964, 250.5999999999996, 252.8, 131.9999999999998, 133.89999999999915, -48.299999999999926, 40.0000000000003, 22.800000000000004, 58.900000000000404, 214.59999999999945, 36.70000000000025, 252.3999999999993, 19.500000000000192, -38.09999999999976, 38.90000000000028, -244.7000000000004, 172.29999999999913, 40.0000000000003, 40.0000000000003, -258.4999999999999, 36.70000000000025, -37.69999999999969, -95.10000000000021, -68.00000000000071, 126.19999999999936, -15.499999999999874, -272.8000000000001, 82.79999999999939, -82.39999999999993, 201.0999999999995, 153.8, -209.79999999999998, -32.400000000000055, 23.100000000000083, 35.10000000000014, 22.300000000000175, 165.6999999999992, 150.59999999999965, 287.29999999999956, -171.8000000000003, 75.99999999999963, -164.39999999999998, -105.79999999999995, 236.19999999999902], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.29999999999998, 198.2, 120.5, 118.1, 94.09999999999998, -142.60000000000045, 170.29999999999998, 17.899999999999988, 41.59999999999998, 131.89999999999995, 37.1, -217.30000000000013, -45.099999999999824, 166.6999999999998, 62.29999999999996, 20.000000000000014, 20.000000000000014, 15.799999999999963, 50.0, 130.99999999999997, 20.000000000000014, 140.6, 23.60000000000001, 50.59999999999999, 12.499999999999961, 100.69999999999999, 115.39999999999995, 62.300000000000004, 20.000000000000014, 20.000000000000014, -17.799999999999997, 20.000000000000014, 145.09999999999982, 127.09999999999995, 197.29999999999998, 171.19999999999982, 159.7999999999999, 152.29999999999995, -395.5000000000001, -199.40000000000066, 20.000000000000014, 59.9, 20.000000000000014, 194.6, 198.2, 20.000000000000014, 141.8, 104.60000000000002, 5.599999999999945, 19.40000000000009, 22.70000000000001, 16.400000000000055, 114.8, 20.000000000000014, 128.30000000000004, 173.89999999999998, 20.000000000000014, 129.1999999999998, 172.3999999999999, 5.300000000000004, 32.30000000000001, 22.39999999999999, 147.19999999999993, 85.70000000000003, -150.10000000000014, 20.000000000000014, 166.70000000000002, 74.9, 20.000000000000014, 20.000000000000014, 100.1, 20.000000000000014, 24.799999999999958, 91.1, 43.400000000000084, -3.6999999999998945, 154.0999999999997, 20.000000000000014, 7.399999999999965, 87.4999999999993, -118.6, 140.8999999999998, 20.000000000000014, 183.7999999999999, 108.50000000000003, 133.69999999999993, 121.99999999999997, 20.000000000000014, 12.200000000000006, 69.19999999999976, 133.99999999999994, 165.79999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, 94.0999999999998, 51.50000000000005, 48.80000000000013, 127.69999999999989, 180.19999999999993, 105.49999999999964, 20.000000000000014, 188.29999999999993, 129.8, 118.69999999999999, 127.39999999999986, 20.000000000000014, 181.09999999999997, 63.8, 59.900000000000055, 17.899999999999984, -201.40000000000003, 151.99999999999983, 71.60000000000005, 126.19999999999999, 119.60000000000002, 39.20000000000001, 3.8000000000000504, 13.699999999999964, 117.1999999999997, -63.099999999999945, -209.20000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -56.19999999999998, 20.000000000000014, 38.9000000000002, 104.59999999999977, 109.99999999999979, 13.699999999999964, 20.000000000000014, 145.99999999999991, 106.39999999999979, -36.69999999999992, -23.79999999999997, -213.10000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, -162.09999999999997, -259.60000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -298.9, -130.60000000000005, 20.000000000000014, 13.699999999999964, -24.099999999999937, -82.6, -130.00000000000026, -84.10000000000008, -1.6000000000000276, -171.40000000000043, 78.19999999999985, 20.000000000000014, -92.50000000000006, -40.000000000000284, -140.19999999999993, -337.5999999999998, 25.400000000000055, 10.39999999999998, -223.6000000000001, 9.200000000000056, 60.20000000000002, 98.8999999999996, 81.79999999999987, 8.0, -240.4, -111.39999999999998, -44.19999999999999, -104.20000000000026, 26.900000000000013, -251.8000000000001, -61.9000000000005, 20.000000000000014, 20.000000000000014, -72.70000000000014, 152.2999999999998, 7.399999999999965, 14.900000000000151, 112.69999999999978, 169.39999999999986, 116.89999999999966, -206.2000000000003, -190.60000000000002, 20.000000000000014, 56.00000000000023, -227.80000000000015, -76.60000000000004, -30.099999999999817, -222.70000000000005, 162.19999999999985, 73.99999999999949], "policy_predator_policy_reward": [0.0, 3.0, 16.0, 0.0, 58.0, 79.0, 0.0, 4.0, 11.0, 0.0, 113.0, 112.0, 26.0, 17.0, 0.0, 0.0, 2.0, 0.0, 0.0, 56.0, 8.0, 17.0, 0.0, 0.0, 34.0, 20.0, 14.0, 22.0, 0.0, 0.0, 72.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 8.0, 292.0, 232.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 17.0, 55.0, 7.0, 37.0, 15.0, 23.0, 15.0, 0.0, 8.0, 0.0, 0.0, 61.0, 59.0, 26.0, 9.0, 2.0, 77.0, 78.0, 18.0, 18.0, 0.0, 0.0, 9.0, 0.0, 12.0, 1.0, 3.0, 15.0, 0.0, 0.0, 6.0, 0.0, 69.0, 29.0, 0.0, 0.0, 15.0, 12.0, 13.0, 9.0, 56.0, 15.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 33.0, 17.0, 0.0, 133.0, 27.0, 0.0, 6.0, 1.0, 19.0, 70.0, 0.0, 3.0, 123.0, 101.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 80.0, 22.0, 133.0, 1.0, 0.0, 20.0, 157.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 0.0, 3.0, 69.0, 0.0, 19.0, 100.0, 0.0, 105.0, 0.0, 28.0, 0.0, 117.0, 18.0, 187.0, 39.0, 8.0, 0.0, 132.0, 42.0, 0.0, 64.0, 0.0, 8.0, 134.0, 116.0, 0.0, 130.0, 118.0, 38.0, 39.0, 0.0, 75.0, 6.0, 0.0, 9.0, 14.0, 1.0, 0.0, 162.0, 63.0, 0.0, 0.0, 0.0, 140.0, 16.0, 131.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6336792804247187, "mean_inference_ms": 1.6503312792604492, "mean_action_processing_ms": 0.2712594342080583, "mean_env_wait_ms": 0.22756216967959156, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004836916923522949, "StateBufferConnector_ms": 0.003956198692321777, "ViewRequirementAgentConnector_ms": 0.14983975887298584}, "num_episodes": 18, "episode_return_max": 371.49999999999994, "episode_return_min": -272.8000000000001, "episode_return_mean": 109.32199999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 377.93512619946733, "num_env_steps_trained_throughput_per_sec": 377.93512619946733, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 10959.115, "restore_workers_time_ms": 0.019, "training_step_time_ms": 10959.056, "sample_time_ms": 1805.18, "learn_time_ms": 9133.617, "learn_throughput": 437.943, "synch_weights_time_ms": 16.475}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "04dec_00002", "date": "2024-08-13_16-34-40", "timestamp": 1723581280, "time_this_iter_s": 10.679258823394775, "time_total_s": 714.5494391918182, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0616c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 714.5494391918182, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 50.35333333333333, "ram_util_percent": 86.06666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9791784144583202, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.6979427302325214, "policy_loss": -0.003361378529320949, "vf_loss": 2.7007412491021334, "vf_explained_var": 0.009578495776211773, "kl": 0.008894573126624448, "entropy": 0.9699549305060553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.49992995943342, "cur_kl_coeff": 0.010546875, "cur_lr": 0.00010000000000000003, "total_loss": 8.400904192747893, "policy_loss": -0.003910891425416426, "vf_loss": 8.40459301383407, "vf_explained_var": 0.2736454752387193, "kl": 0.021055478062818204, "entropy": 0.8204492755037136, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 340.4000000000002, "episode_reward_min": -272.8000000000001, "episode_reward_mean": 92.80199999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": 18.11599999999996, "predator_policy": 28.285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [260.3999999999999, 96.99999999999996, 83.09999999999997, 172.79999999999941, 317.19999999999993, 157.1999999999992, 238.69999999999985, 139.69999999999962, 243.89999999999978, 24.90000000000014, 277.5999999999998, 40.0000000000003, 129.0999999999996, 128.8999999999998, 57.70000000000022, 174.09999999999897, 100.8999999999986, 120.29999999999978, 203.79999999999916, 269.1999999999998, 163.9999999999995, 152.3999999999994, 306.8000000000006, 40.0000000000003, 40.0000000000003, 191.9999999999998, 100.29999999999936, 317.9000000000002, 125.49999999999909, 318.09999999999974, 277.09999999999985, 201.09999999999928, 173.6999999999999, -50.499999999999964, 250.5999999999996, 252.8, 131.9999999999998, 133.89999999999915, -48.299999999999926, 40.0000000000003, 22.800000000000004, 58.900000000000404, 214.59999999999945, 36.70000000000025, 252.3999999999993, 19.500000000000192, -38.09999999999976, 38.90000000000028, -244.7000000000004, 172.29999999999913, 40.0000000000003, 40.0000000000003, -258.4999999999999, 36.70000000000025, -37.69999999999969, -95.10000000000021, -68.00000000000071, 126.19999999999936, -15.499999999999874, -272.8000000000001, 82.79999999999939, -82.39999999999993, 201.0999999999995, 153.8, -209.79999999999998, -32.400000000000055, 23.100000000000083, 35.10000000000014, 22.300000000000175, 165.6999999999992, 150.59999999999965, 287.29999999999956, -171.8000000000003, 75.99999999999963, -164.39999999999998, -105.79999999999995, 236.19999999999902, -54.69999999999999, 163.19999999999948, -5.099999999999941, 35.600000000000236, 340.4000000000002, 199.3999999999999, 28.600000000000165, 291.10000000000014, -93.5000000000005, 198.29999999999964, 40.0000000000003, 72.10000000000011, 117.1, 215.39999999999972, -29.099999999999937, 166.6999999999997, 48.000000000000206, 40.0000000000003, 193.09999999999957, 40.0000000000003, 21.500000000000156, 40.0000000000003, 160.19999999999962], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [141.8, 104.60000000000002, 5.599999999999945, 19.40000000000009, 22.70000000000001, 16.400000000000055, 114.8, 20.000000000000014, 128.30000000000004, 173.89999999999998, 20.000000000000014, 129.1999999999998, 172.3999999999999, 5.300000000000004, 32.30000000000001, 22.39999999999999, 147.19999999999993, 85.70000000000003, -150.10000000000014, 20.000000000000014, 166.70000000000002, 74.9, 20.000000000000014, 20.000000000000014, 100.1, 20.000000000000014, 24.799999999999958, 91.1, 43.400000000000084, -3.6999999999998945, 154.0999999999997, 20.000000000000014, 7.399999999999965, 87.4999999999993, -118.6, 140.8999999999998, 20.000000000000014, 183.7999999999999, 108.50000000000003, 133.69999999999993, 121.99999999999997, 20.000000000000014, 12.200000000000006, 69.19999999999976, 133.99999999999994, 165.79999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, 94.0999999999998, 51.50000000000005, 48.80000000000013, 127.69999999999989, 180.19999999999993, 105.49999999999964, 20.000000000000014, 188.29999999999993, 129.8, 118.69999999999999, 127.39999999999986, 20.000000000000014, 181.09999999999997, 63.8, 59.900000000000055, 17.899999999999984, -201.40000000000003, 151.99999999999983, 71.60000000000005, 126.19999999999999, 119.60000000000002, 39.20000000000001, 3.8000000000000504, 13.699999999999964, 117.1999999999997, -63.099999999999945, -209.20000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -56.19999999999998, 20.000000000000014, 38.9000000000002, 104.59999999999977, 109.99999999999979, 13.699999999999964, 20.000000000000014, 145.99999999999991, 106.39999999999979, -36.69999999999992, -23.79999999999997, -213.10000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, -162.09999999999997, -259.60000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -298.9, -130.60000000000005, 20.000000000000014, 13.699999999999964, -24.099999999999937, -82.6, -130.00000000000026, -84.10000000000008, -1.6000000000000276, -171.40000000000043, 78.19999999999985, 20.000000000000014, -92.50000000000006, -40.000000000000284, -140.19999999999993, -337.5999999999998, 25.400000000000055, 10.39999999999998, -223.6000000000001, 9.200000000000056, 60.20000000000002, 98.8999999999996, 81.79999999999987, 8.0, -240.4, -111.39999999999998, -44.19999999999999, -104.20000000000026, 26.900000000000013, -251.8000000000001, -61.9000000000005, 20.000000000000014, 20.000000000000014, -72.70000000000014, 152.2999999999998, 7.399999999999965, 14.900000000000151, 112.69999999999978, 169.39999999999986, 116.89999999999966, -206.2000000000003, -190.60000000000002, 20.000000000000014, 56.00000000000023, -227.80000000000015, -76.60000000000004, -30.099999999999817, -222.70000000000005, 162.19999999999985, 73.99999999999949, -184.00000000000006, -48.69999999999999, 17.899999999999988, 122.3, 20.000000000000014, -120.1, 11.599999999999964, 20.000000000000014, 196.39999999999998, 133.9999999999999, 33.19999999999999, 108.2, 13.699999999999966, -90.10000000000002, 128.29999999999993, 129.79999999999998, -252.40000000000018, 17.899999999999988, 85.70000000000002, 71.59999999999997, 20.000000000000014, 20.000000000000014, 50.00000000000012, -34.89999999999978, 48.49999999999999, -111.40000000000003, 60.799999999999976, 113.59999999999974, -48.09999999999998, -226.00000000000017, 36.8, 56.900000000000006, 17.899999999999988, -46.89999999999999, 20.000000000000014, 20.000000000000014, 80.90000000000006, 72.19999999999996, 20.000000000000014, 20.000000000000014, -24.69999999999996, -29.799999999999827, 20.000000000000014, 20.000000000000014, 126.20000000000002, 20.000000000000014], "policy_predator_policy_reward": [5.0, 9.0, 17.0, 55.0, 7.0, 37.0, 15.0, 23.0, 15.0, 0.0, 8.0, 0.0, 0.0, 61.0, 59.0, 26.0, 9.0, 2.0, 77.0, 78.0, 18.0, 18.0, 0.0, 0.0, 9.0, 0.0, 12.0, 1.0, 3.0, 15.0, 0.0, 0.0, 6.0, 0.0, 69.0, 29.0, 0.0, 0.0, 15.0, 12.0, 13.0, 9.0, 56.0, 15.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 33.0, 17.0, 0.0, 133.0, 27.0, 0.0, 6.0, 1.0, 19.0, 70.0, 0.0, 3.0, 123.0, 101.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 80.0, 22.0, 133.0, 1.0, 0.0, 20.0, 157.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 0.0, 3.0, 69.0, 0.0, 19.0, 100.0, 0.0, 105.0, 0.0, 28.0, 0.0, 117.0, 18.0, 187.0, 39.0, 8.0, 0.0, 132.0, 42.0, 0.0, 64.0, 0.0, 8.0, 134.0, 116.0, 0.0, 130.0, 118.0, 38.0, 39.0, 0.0, 75.0, 6.0, 0.0, 9.0, 14.0, 1.0, 0.0, 162.0, 63.0, 0.0, 0.0, 0.0, 140.0, 16.0, 131.0, 0.0, 0.0, 36.0, 142.0, 22.0, 1.0, 95.0, 0.0, 0.0, 4.0, 0.0, 10.0, 0.0, 58.0, 9.0, 96.0, 7.0, 26.0, 140.0, 1.0, 27.0, 14.0, 0.0, 0.0, 31.0, 26.0, 94.0, 86.0, 0.0, 41.0, 102.0, 143.0, 39.0, 34.0, 76.0, 1.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 12.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6402519982145316, "mean_inference_ms": 1.6677555437857514, "mean_action_processing_ms": 0.27358246922784085, "mean_env_wait_ms": 0.2296456452665205, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0063707828521728516, "StateBufferConnector_ms": 0.003861546516418457, "ViewRequirementAgentConnector_ms": 0.17389905452728271}, "num_episodes": 23, "episode_return_max": 340.4000000000002, "episode_return_min": -272.8000000000001, "episode_return_mean": 92.80199999999982, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.53352920181976, "num_env_steps_trained_throughput_per_sec": 290.53352920181976, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 11389.37, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11389.312, "sample_time_ms": 1957.04, "learn_time_ms": 9412.858, "learn_throughput": 424.951, "synch_weights_time_ms": 15.227}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "04dec_00002", "date": "2024-08-13_16-34-54", "timestamp": 1723581294, "time_this_iter_s": 13.811206817626953, "time_total_s": 728.3606460094452, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a7790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 728.3606460094452, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 81.49999999999999, "ram_util_percent": 84.7578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9500972827906331, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 1.1745597802457355, "policy_loss": -0.007262328259336452, "vf_loss": 1.1809677675918298, "vf_explained_var": 0.02259229263931355, "kl": 0.013500729901431956, "entropy": 0.9054665570536619, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.27279382802191, "cur_kl_coeff": 0.015820312499999996, "cur_lr": 0.00010000000000000003, "total_loss": 9.129066019714195, "policy_loss": -0.0087407631835304, "vf_loss": 9.137392746960675, "vf_explained_var": -0.2805851150442053, "kl": 0.02617155299082447, "entropy": 0.875492582781605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 340.4000000000002, "episode_reward_min": -272.8000000000001, "episode_reward_mean": 81.90499999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": 13.572499999999952, "predator_policy": 27.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [203.79999999999916, 269.1999999999998, 163.9999999999995, 152.3999999999994, 306.8000000000006, 40.0000000000003, 40.0000000000003, 191.9999999999998, 100.29999999999936, 317.9000000000002, 125.49999999999909, 318.09999999999974, 277.09999999999985, 201.09999999999928, 173.6999999999999, -50.499999999999964, 250.5999999999996, 252.8, 131.9999999999998, 133.89999999999915, -48.299999999999926, 40.0000000000003, 22.800000000000004, 58.900000000000404, 214.59999999999945, 36.70000000000025, 252.3999999999993, 19.500000000000192, -38.09999999999976, 38.90000000000028, -244.7000000000004, 172.29999999999913, 40.0000000000003, 40.0000000000003, -258.4999999999999, 36.70000000000025, -37.69999999999969, -95.10000000000021, -68.00000000000071, 126.19999999999936, -15.499999999999874, -272.8000000000001, 82.79999999999939, -82.39999999999993, 201.0999999999995, 153.8, -209.79999999999998, -32.400000000000055, 23.100000000000083, 35.10000000000014, 22.300000000000175, 165.6999999999992, 150.59999999999965, 287.29999999999956, -171.8000000000003, 75.99999999999963, -164.39999999999998, -105.79999999999995, 236.19999999999902, -54.69999999999999, 163.19999999999948, -5.099999999999941, 35.600000000000236, 340.4000000000002, 199.3999999999999, 28.600000000000165, 291.10000000000014, -93.5000000000005, 198.29999999999964, 40.0000000000003, 72.10000000000011, 117.1, 215.39999999999972, -29.099999999999937, 166.6999999999997, 48.000000000000206, 40.0000000000003, 193.09999999999957, 40.0000000000003, 21.500000000000156, 40.0000000000003, 160.19999999999962, 228.39999999999938, 34.100000000000094, 40.0000000000003, 47.20000000000029, 40.0000000000003, 132.99999999999886, 141.3999999999992, 121.79999999999954, 59.40000000000028, 45.10000000000032, 87.59999999999954, 104.79999999999903, 182.99999999999926, 55.600000000000364, 117.39999999999921, 106.00000000000017, 46.00000000000001, 82.99999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 183.7999999999999, 108.50000000000003, 133.69999999999993, 121.99999999999997, 20.000000000000014, 12.200000000000006, 69.19999999999976, 133.99999999999994, 165.79999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, 94.0999999999998, 51.50000000000005, 48.80000000000013, 127.69999999999989, 180.19999999999993, 105.49999999999964, 20.000000000000014, 188.29999999999993, 129.8, 118.69999999999999, 127.39999999999986, 20.000000000000014, 181.09999999999997, 63.8, 59.900000000000055, 17.899999999999984, -201.40000000000003, 151.99999999999983, 71.60000000000005, 126.19999999999999, 119.60000000000002, 39.20000000000001, 3.8000000000000504, 13.699999999999964, 117.1999999999997, -63.099999999999945, -209.20000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -56.19999999999998, 20.000000000000014, 38.9000000000002, 104.59999999999977, 109.99999999999979, 13.699999999999964, 20.000000000000014, 145.99999999999991, 106.39999999999979, -36.69999999999992, -23.79999999999997, -213.10000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, -162.09999999999997, -259.60000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -298.9, -130.60000000000005, 20.000000000000014, 13.699999999999964, -24.099999999999937, -82.6, -130.00000000000026, -84.10000000000008, -1.6000000000000276, -171.40000000000043, 78.19999999999985, 20.000000000000014, -92.50000000000006, -40.000000000000284, -140.19999999999993, -337.5999999999998, 25.400000000000055, 10.39999999999998, -223.6000000000001, 9.200000000000056, 60.20000000000002, 98.8999999999996, 81.79999999999987, 8.0, -240.4, -111.39999999999998, -44.19999999999999, -104.20000000000026, 26.900000000000013, -251.8000000000001, -61.9000000000005, 20.000000000000014, 20.000000000000014, -72.70000000000014, 152.2999999999998, 7.399999999999965, 14.900000000000151, 112.69999999999978, 169.39999999999986, 116.89999999999966, -206.2000000000003, -190.60000000000002, 20.000000000000014, 56.00000000000023, -227.80000000000015, -76.60000000000004, -30.099999999999817, -222.70000000000005, 162.19999999999985, 73.99999999999949, -184.00000000000006, -48.69999999999999, 17.899999999999988, 122.3, 20.000000000000014, -120.1, 11.599999999999964, 20.000000000000014, 196.39999999999998, 133.9999999999999, 33.19999999999999, 108.2, 13.699999999999966, -90.10000000000002, 128.29999999999993, 129.79999999999998, -252.40000000000018, 17.899999999999988, 85.70000000000002, 71.59999999999997, 20.000000000000014, 20.000000000000014, 50.00000000000012, -34.89999999999978, 48.49999999999999, -111.40000000000003, 60.799999999999976, 113.59999999999974, -48.09999999999998, -226.00000000000017, 36.8, 56.900000000000006, 17.899999999999988, -46.89999999999999, 20.000000000000014, 20.000000000000014, 80.90000000000006, 72.19999999999996, 20.000000000000014, 20.000000000000014, -24.69999999999996, -29.799999999999827, 20.000000000000014, 20.000000000000014, 126.20000000000002, 20.000000000000014, 85.69999999999962, 139.6999999999997, -19.899999999999814, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 96.49999999999955, 33.50000000000012, 9.499999999999964, 107.89999999999989, 93.79999999999993, 22.999999999999986, 45.200000000000124, -65.80000000000075, 19.400000000000016, 13.699999999999964, -93.7000000000005, 74.29999999999997, 84.79999999999967, 20.000000000000014, 75.20000000000006, 93.79999999999987, -40.900000000000034, 60.50000000000016, 60.20000000000013, 27.20000000000002, 46.09999999999997, -12.100000000000083, 14.299999999999965, 4.700000000000194, -9.399999999999963, 37.40000000000008], "policy_predator_policy_reward": [0.0, 0.0, 15.0, 12.0, 13.0, 9.0, 56.0, 15.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 33.0, 17.0, 0.0, 133.0, 27.0, 0.0, 6.0, 1.0, 19.0, 70.0, 0.0, 3.0, 123.0, 101.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 80.0, 22.0, 133.0, 1.0, 0.0, 20.0, 157.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 0.0, 3.0, 69.0, 0.0, 19.0, 100.0, 0.0, 105.0, 0.0, 28.0, 0.0, 117.0, 18.0, 187.0, 39.0, 8.0, 0.0, 132.0, 42.0, 0.0, 64.0, 0.0, 8.0, 134.0, 116.0, 0.0, 130.0, 118.0, 38.0, 39.0, 0.0, 75.0, 6.0, 0.0, 9.0, 14.0, 1.0, 0.0, 162.0, 63.0, 0.0, 0.0, 0.0, 140.0, 16.0, 131.0, 0.0, 0.0, 36.0, 142.0, 22.0, 1.0, 95.0, 0.0, 0.0, 4.0, 0.0, 10.0, 0.0, 58.0, 9.0, 96.0, 7.0, 26.0, 140.0, 1.0, 27.0, 14.0, 0.0, 0.0, 31.0, 26.0, 94.0, 86.0, 0.0, 41.0, 102.0, 143.0, 39.0, 34.0, 76.0, 1.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 3.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 13.0, 11.0, 0.0, 5.0, 45.0, 35.0, 12.0, 0.0, 55.0, 52.0, 0.0, 0.0, 0.0, 14.0, 25.0, 11.0, 0.0, 30.0, 32.0, 40.0, 20.0, 7.0, 0.0, 55.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6452132665296638, "mean_inference_ms": 1.6806168596880686, "mean_action_processing_ms": 0.2752372688902477, "mean_env_wait_ms": 0.23129877612007163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006133675575256348, "StateBufferConnector_ms": 0.0038205385208129883, "ViewRequirementAgentConnector_ms": 0.15770411491394043}, "num_episodes": 18, "episode_return_max": 340.4000000000002, "episode_return_min": -272.8000000000001, "episode_return_mean": 81.90499999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.42610537946587, "num_env_steps_trained_throughput_per_sec": 342.42610537946587, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 11572.298, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11572.241, "sample_time_ms": 2060.426, "learn_time_ms": 9492.608, "learn_throughput": 421.381, "synch_weights_time_ms": 15.077}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "04dec_00002", "date": "2024-08-13_16-35-06", "timestamp": 1723581306, "time_this_iter_s": 11.790437936782837, "time_total_s": 740.151083946228, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 740.151083946228, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 53.211764705882345, "ram_util_percent": 84.99411764705883}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.794542340279887, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 0.00010000000000000003, "total_loss": 1.7799516339150687, "policy_loss": -0.0011719364761596635, "vf_loss": 1.7808813359686937, "vf_explained_var": 0.019601364867397088, "kl": 0.0038279661442345504, "entropy": 0.9094507310440931, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 39.152668600233774, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 0.00010000000000000003, "total_loss": 7.472045916602725, "policy_loss": -0.002696387186799218, "vf_loss": 7.474200463673425, "vf_explained_var": 0.47389464255363223, "kl": 0.022833106813614723, "entropy": 0.8731646605900356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 340.4000000000002, "episode_reward_min": -272.8000000000001, "episode_reward_mean": 74.12499999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": 9.41749999999996, "predator_policy": 27.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.9999999999998, 133.89999999999915, -48.299999999999926, 40.0000000000003, 22.800000000000004, 58.900000000000404, 214.59999999999945, 36.70000000000025, 252.3999999999993, 19.500000000000192, -38.09999999999976, 38.90000000000028, -244.7000000000004, 172.29999999999913, 40.0000000000003, 40.0000000000003, -258.4999999999999, 36.70000000000025, -37.69999999999969, -95.10000000000021, -68.00000000000071, 126.19999999999936, -15.499999999999874, -272.8000000000001, 82.79999999999939, -82.39999999999993, 201.0999999999995, 153.8, -209.79999999999998, -32.400000000000055, 23.100000000000083, 35.10000000000014, 22.300000000000175, 165.6999999999992, 150.59999999999965, 287.29999999999956, -171.8000000000003, 75.99999999999963, -164.39999999999998, -105.79999999999995, 236.19999999999902, -54.69999999999999, 163.19999999999948, -5.099999999999941, 35.600000000000236, 340.4000000000002, 199.3999999999999, 28.600000000000165, 291.10000000000014, -93.5000000000005, 198.29999999999964, 40.0000000000003, 72.10000000000011, 117.1, 215.39999999999972, -29.099999999999937, 166.6999999999997, 48.000000000000206, 40.0000000000003, 193.09999999999957, 40.0000000000003, 21.500000000000156, 40.0000000000003, 160.19999999999962, 228.39999999999938, 34.100000000000094, 40.0000000000003, 47.20000000000029, 40.0000000000003, 132.99999999999886, 141.3999999999992, 121.79999999999954, 59.40000000000028, 45.10000000000032, 87.59999999999954, 104.79999999999903, 182.99999999999926, 55.600000000000364, 117.39999999999921, 106.00000000000017, 46.00000000000001, 82.99999999999982, 40.0000000000003, 207.39999999999935, 77.79999999999993, 226.49999999999986, 104.59999999999968, 86.90000000000003, 226.2999999999989, 278.60000000000014, 32.30000000000018, 136.79999999999876, 273.0999999999998, 106.29999999999974, 153.39999999999958, 210.0999999999992, 24.500000000000043, 153.29999999999944, 130.6999999999993, 88.19999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [39.20000000000001, 3.8000000000000504, 13.699999999999964, 117.1999999999997, -63.099999999999945, -209.20000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -56.19999999999998, 20.000000000000014, 38.9000000000002, 104.59999999999977, 109.99999999999979, 13.699999999999964, 20.000000000000014, 145.99999999999991, 106.39999999999979, -36.69999999999992, -23.79999999999997, -213.10000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, -162.09999999999997, -259.60000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -298.9, -130.60000000000005, 20.000000000000014, 13.699999999999964, -24.099999999999937, -82.6, -130.00000000000026, -84.10000000000008, -1.6000000000000276, -171.40000000000043, 78.19999999999985, 20.000000000000014, -92.50000000000006, -40.000000000000284, -140.19999999999993, -337.5999999999998, 25.400000000000055, 10.39999999999998, -223.6000000000001, 9.200000000000056, 60.20000000000002, 98.8999999999996, 81.79999999999987, 8.0, -240.4, -111.39999999999998, -44.19999999999999, -104.20000000000026, 26.900000000000013, -251.8000000000001, -61.9000000000005, 20.000000000000014, 20.000000000000014, -72.70000000000014, 152.2999999999998, 7.399999999999965, 14.900000000000151, 112.69999999999978, 169.39999999999986, 116.89999999999966, -206.2000000000003, -190.60000000000002, 20.000000000000014, 56.00000000000023, -227.80000000000015, -76.60000000000004, -30.099999999999817, -222.70000000000005, 162.19999999999985, 73.99999999999949, -184.00000000000006, -48.69999999999999, 17.899999999999988, 122.3, 20.000000000000014, -120.1, 11.599999999999964, 20.000000000000014, 196.39999999999998, 133.9999999999999, 33.19999999999999, 108.2, 13.699999999999966, -90.10000000000002, 128.29999999999993, 129.79999999999998, -252.40000000000018, 17.899999999999988, 85.70000000000002, 71.59999999999997, 20.000000000000014, 20.000000000000014, 50.00000000000012, -34.89999999999978, 48.49999999999999, -111.40000000000003, 60.799999999999976, 113.59999999999974, -48.09999999999998, -226.00000000000017, 36.8, 56.900000000000006, 17.899999999999988, -46.89999999999999, 20.000000000000014, 20.000000000000014, 80.90000000000006, 72.19999999999996, 20.000000000000014, 20.000000000000014, -24.69999999999996, -29.799999999999827, 20.000000000000014, 20.000000000000014, 126.20000000000002, 20.000000000000014, 85.69999999999962, 139.6999999999997, -19.899999999999814, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 96.49999999999955, 33.50000000000012, 9.499999999999964, 107.89999999999989, 93.79999999999993, 22.999999999999986, 45.200000000000124, -65.80000000000075, 19.400000000000016, 13.699999999999964, -93.7000000000005, 74.29999999999997, 84.79999999999967, 20.000000000000014, 75.20000000000006, 93.79999999999987, -40.900000000000034, 60.50000000000016, 60.20000000000013, 27.20000000000002, 46.09999999999997, -12.100000000000083, 14.299999999999965, 4.700000000000194, -9.399999999999963, 37.40000000000008, 20.000000000000014, 20.000000000000014, 187.40000000000003, 20.000000000000014, 39.80000000000017, 20.000000000000014, 158.6, 59.89999999999996, 38.90000000000016, 43.70000000000004, 17.900000000000055, 20.000000000000014, 118.9999999999996, 107.2999999999997, 129.5, 118.09999999999994, 51.50000000000009, -143.2, 114.7999999999995, 20.000000000000014, 140.59999999999994, 132.49999999999977, -43.300000000000004, 68.6, 133.39999999999995, 20.000000000000014, 190.09999999999994, 20.000000000000014, 10.700000000000005, -68.20000000000007, 20.000000000000014, 128.29999999999993, 35.30000000000019, 85.40000000000003, 57.200000000000045, 20.000000000000014], "policy_predator_policy_reward": [19.0, 70.0, 0.0, 3.0, 123.0, 101.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 80.0, 22.0, 133.0, 1.0, 0.0, 20.0, 157.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 0.0, 3.0, 69.0, 0.0, 19.0, 100.0, 0.0, 105.0, 0.0, 28.0, 0.0, 117.0, 18.0, 187.0, 39.0, 8.0, 0.0, 132.0, 42.0, 0.0, 64.0, 0.0, 8.0, 134.0, 116.0, 0.0, 130.0, 118.0, 38.0, 39.0, 0.0, 75.0, 6.0, 0.0, 9.0, 14.0, 1.0, 0.0, 162.0, 63.0, 0.0, 0.0, 0.0, 140.0, 16.0, 131.0, 0.0, 0.0, 36.0, 142.0, 22.0, 1.0, 95.0, 0.0, 0.0, 4.0, 0.0, 10.0, 0.0, 58.0, 9.0, 96.0, 7.0, 26.0, 140.0, 1.0, 27.0, 14.0, 0.0, 0.0, 31.0, 26.0, 94.0, 86.0, 0.0, 41.0, 102.0, 143.0, 39.0, 34.0, 76.0, 1.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 3.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 13.0, 11.0, 0.0, 5.0, 45.0, 35.0, 12.0, 0.0, 55.0, 52.0, 0.0, 0.0, 0.0, 14.0, 25.0, 11.0, 0.0, 30.0, 32.0, 40.0, 20.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 8.0, 0.0, 22.0, 0.0, 39.0, 10.0, 0.0, 0.0, 21.0, 10.0, 43.0, 81.0, 0.0, 2.0, 0.0, 0.0, 43.0, 38.0, 0.0, 0.0, 0.0, 0.0, 20.0, 62.0, 0.0, 5.0, 10.0, 0.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6503382023865752, "mean_inference_ms": 1.6942901525102718, "mean_action_processing_ms": 0.27704026343797716, "mean_env_wait_ms": 0.23302352335787607, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006168007850646973, "StateBufferConnector_ms": 0.003952383995056152, "ViewRequirementAgentConnector_ms": 0.15788841247558594}, "num_episodes": 18, "episode_return_max": 340.4000000000002, "episode_return_min": -272.8000000000001, "episode_return_mean": 74.12499999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.61988888804814, "num_env_steps_trained_throughput_per_sec": 358.61988888804814, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 11713.174, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11713.118, "sample_time_ms": 2100.289, "learn_time_ms": 9593.981, "learn_throughput": 416.928, "synch_weights_time_ms": 14.938}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "04dec_00002", "date": "2024-08-13_16-35-17", "timestamp": 1723581317, "time_this_iter_s": 11.20789384841919, "time_total_s": 751.3589777946472, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 751.3589777946472, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 51.375, "ram_util_percent": 86.675}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9562683585932645, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 0.00010000000000000003, "total_loss": 3.7730298345051114, "policy_loss": -0.00749426758737259, "vf_loss": 3.7798955644880023, "vf_explained_var": 0.020338061656901444, "kl": 0.019864590436834556, "entropy": 0.9002609379392452, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.60730223652547, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 0.00010000000000000003, "total_loss": 7.31475490539793, "policy_loss": -0.0017436303819219272, "vf_loss": 7.316125672456448, "vf_explained_var": -0.13241195167813982, "kl": 0.01047470646533929, "entropy": 0.8344012605450141, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 341.3999999999999, "episode_reward_min": -272.8000000000001, "episode_reward_mean": 91.5219999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": 17.71099999999996, "predator_policy": 28.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.499999999999874, -272.8000000000001, 82.79999999999939, -82.39999999999993, 201.0999999999995, 153.8, -209.79999999999998, -32.400000000000055, 23.100000000000083, 35.10000000000014, 22.300000000000175, 165.6999999999992, 150.59999999999965, 287.29999999999956, -171.8000000000003, 75.99999999999963, -164.39999999999998, -105.79999999999995, 236.19999999999902, -54.69999999999999, 163.19999999999948, -5.099999999999941, 35.600000000000236, 340.4000000000002, 199.3999999999999, 28.600000000000165, 291.10000000000014, -93.5000000000005, 198.29999999999964, 40.0000000000003, 72.10000000000011, 117.1, 215.39999999999972, -29.099999999999937, 166.6999999999997, 48.000000000000206, 40.0000000000003, 193.09999999999957, 40.0000000000003, 21.500000000000156, 40.0000000000003, 160.19999999999962, 228.39999999999938, 34.100000000000094, 40.0000000000003, 47.20000000000029, 40.0000000000003, 132.99999999999886, 141.3999999999992, 121.79999999999954, 59.40000000000028, 45.10000000000032, 87.59999999999954, 104.79999999999903, 182.99999999999926, 55.600000000000364, 117.39999999999921, 106.00000000000017, 46.00000000000001, 82.99999999999982, 40.0000000000003, 207.39999999999935, 77.79999999999993, 226.49999999999986, 104.59999999999968, 86.90000000000003, 226.2999999999989, 278.60000000000014, 32.30000000000018, 136.79999999999876, 273.0999999999998, 106.29999999999974, 153.39999999999958, 210.0999999999992, 24.500000000000043, 153.29999999999944, 130.6999999999993, 88.19999999999989, 156.0999999999991, 68.69999999999999, 249.8999999999999, 161.49999999999957, 46.00000000000003, 341.3999999999999, 186.69999999999922, -171.59999999999997, 179.09999999999948, 147.29999999999916, 55.30000000000019, 121.39999999999964, 330.29999999999995, -68.10000000000002, -146.29999999999993, 85.30000000000001, 143.6999999999996, 118.09999999999977, 244.2999999999995, 261.0999999999997, -91.5, -104.49999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-92.50000000000006, -40.000000000000284, -140.19999999999993, -337.5999999999998, 25.400000000000055, 10.39999999999998, -223.6000000000001, 9.200000000000056, 60.20000000000002, 98.8999999999996, 81.79999999999987, 8.0, -240.4, -111.39999999999998, -44.19999999999999, -104.20000000000026, 26.900000000000013, -251.8000000000001, -61.9000000000005, 20.000000000000014, 20.000000000000014, -72.70000000000014, 152.2999999999998, 7.399999999999965, 14.900000000000151, 112.69999999999978, 169.39999999999986, 116.89999999999966, -206.2000000000003, -190.60000000000002, 20.000000000000014, 56.00000000000023, -227.80000000000015, -76.60000000000004, -30.099999999999817, -222.70000000000005, 162.19999999999985, 73.99999999999949, -184.00000000000006, -48.69999999999999, 17.899999999999988, 122.3, 20.000000000000014, -120.1, 11.599999999999964, 20.000000000000014, 196.39999999999998, 133.9999999999999, 33.19999999999999, 108.2, 13.699999999999966, -90.10000000000002, 128.29999999999993, 129.79999999999998, -252.40000000000018, 17.899999999999988, 85.70000000000002, 71.59999999999997, 20.000000000000014, 20.000000000000014, 50.00000000000012, -34.89999999999978, 48.49999999999999, -111.40000000000003, 60.799999999999976, 113.59999999999974, -48.09999999999998, -226.00000000000017, 36.8, 56.900000000000006, 17.899999999999988, -46.89999999999999, 20.000000000000014, 20.000000000000014, 80.90000000000006, 72.19999999999996, 20.000000000000014, 20.000000000000014, -24.69999999999996, -29.799999999999827, 20.000000000000014, 20.000000000000014, 126.20000000000002, 20.000000000000014, 85.69999999999962, 139.6999999999997, -19.899999999999814, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 96.49999999999955, 33.50000000000012, 9.499999999999964, 107.89999999999989, 93.79999999999993, 22.999999999999986, 45.200000000000124, -65.80000000000075, 19.400000000000016, 13.699999999999964, -93.7000000000005, 74.29999999999997, 84.79999999999967, 20.000000000000014, 75.20000000000006, 93.79999999999987, -40.900000000000034, 60.50000000000016, 60.20000000000013, 27.20000000000002, 46.09999999999997, -12.100000000000083, 14.299999999999965, 4.700000000000194, -9.399999999999963, 37.40000000000008, 20.000000000000014, 20.000000000000014, 187.40000000000003, 20.000000000000014, 39.80000000000017, 20.000000000000014, 158.6, 59.89999999999996, 38.90000000000016, 43.70000000000004, 17.900000000000055, 20.000000000000014, 118.9999999999996, 107.2999999999997, 129.5, 118.09999999999994, 51.50000000000009, -143.2, 114.7999999999995, 20.000000000000014, 140.59999999999994, 132.49999999999977, -43.300000000000004, 68.6, 133.39999999999995, 20.000000000000014, 190.09999999999994, 20.000000000000014, 10.700000000000005, -68.20000000000007, 20.000000000000014, 128.29999999999993, 35.30000000000019, 85.40000000000003, 57.200000000000045, 20.000000000000014, 20.000000000000014, 136.09999999999974, 34.700000000000145, 20.000000000000014, 21.200000000000017, 184.69999999999996, 141.5, 20.000000000000014, -214.30000000000004, 71.3, 163.1, 164.29999999999995, 166.69999999999987, 20.000000000000014, -166.60000000000002, -193.00000000000009, 157.10000000000002, 20.000000000000014, 136.09999999999977, 3.1999999999999615, -102.40000000000006, 13.699999999999964, 76.40000000000003, 20.000000000000014, 172.39999999999992, 155.89999999999986, -25.599999999999994, -176.50000000000009, -142.6, -171.7, 19.10000000000002, -14.79999999999999, 91.69999999999999, 20.000000000000014, 20.000000000000014, 61.100000000000016, 44.60000000000001, 193.7, 73.09999999999997, 181.99999999999994, -113.5, -175.0, -108.10000000000025, -72.40000000000015], "policy_predator_policy_reward": [0.0, 117.0, 18.0, 187.0, 39.0, 8.0, 0.0, 132.0, 42.0, 0.0, 64.0, 0.0, 8.0, 134.0, 116.0, 0.0, 130.0, 118.0, 38.0, 39.0, 0.0, 75.0, 6.0, 0.0, 9.0, 14.0, 1.0, 0.0, 162.0, 63.0, 0.0, 0.0, 0.0, 140.0, 16.0, 131.0, 0.0, 0.0, 36.0, 142.0, 22.0, 1.0, 95.0, 0.0, 0.0, 4.0, 0.0, 10.0, 0.0, 58.0, 9.0, 96.0, 7.0, 26.0, 140.0, 1.0, 27.0, 14.0, 0.0, 0.0, 31.0, 26.0, 94.0, 86.0, 0.0, 41.0, 102.0, 143.0, 39.0, 34.0, 76.0, 1.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 3.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 13.0, 11.0, 0.0, 5.0, 45.0, 35.0, 12.0, 0.0, 55.0, 52.0, 0.0, 0.0, 0.0, 14.0, 25.0, 11.0, 0.0, 30.0, 32.0, 40.0, 20.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 8.0, 0.0, 22.0, 0.0, 39.0, 10.0, 0.0, 0.0, 21.0, 10.0, 43.0, 81.0, 0.0, 2.0, 0.0, 0.0, 43.0, 38.0, 0.0, 0.0, 0.0, 0.0, 20.0, 62.0, 0.0, 5.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 44.0, 0.0, 0.0, 61.0, 128.0, 14.0, 0.0, 0.0, 0.0, 60.0, 128.0, 0.0, 2.0, 8.0, 0.0, 70.0, 74.0, 0.0, 25.0, 2.0, 0.0, 11.0, 123.0, 86.0, 82.0, 78.0, 3.0, 19.0, 13.0, 29.0, 8.0, 1.0, 5.0, 6.0, 0.0, 47.0, 150.0, 40.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6581615569141284, "mean_inference_ms": 1.7148574797882616, "mean_action_processing_ms": 0.27981105725526395, "mean_env_wait_ms": 0.23569921711633854, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0164109468460083, "StateBufferConnector_ms": 0.004662752151489258, "ViewRequirementAgentConnector_ms": 0.1912369728088379}, "num_episodes": 22, "episode_return_max": 341.3999999999999, "episode_return_min": -272.8000000000001, "episode_return_mean": 91.5219999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.05427422343746, "num_env_steps_trained_throughput_per_sec": 319.05427422343746, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 11728.28, "restore_workers_time_ms": 0.019, "training_step_time_ms": 11728.223, "sample_time_ms": 2008.321, "learn_time_ms": 9700.152, "learn_throughput": 412.365, "synch_weights_time_ms": 15.316}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "04dec_00002", "date": "2024-08-13_16-35-30", "timestamp": 1723581330, "time_this_iter_s": 12.584885597229004, "time_total_s": 763.9438633918762, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b064be50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 763.9438633918762, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 56.02222222222222, "ram_util_percent": 85.98333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8580286292014299, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 0.00010000000000000003, "total_loss": 3.5675968784503835, "policy_loss": -0.007137445716443595, "vf_loss": 3.5738834147730834, "vf_explained_var": 0.011570824864049437, "kl": 0.026892865141349653, "entropy": 0.9608604035680256, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 33.78570142823553, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 0.00010000000000000003, "total_loss": 6.977088920906107, "policy_loss": -0.004061208086743675, "vf_loss": 6.980436095232686, "vf_explained_var": -0.034657185670559996, "kl": 0.020059865009065172, "entropy": 0.8461914540598632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 341.3999999999999, "episode_reward_min": -307.6, "episode_reward_mean": 103.84999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -330.40000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 26.239999999999974, "predator_policy": 25.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [340.4000000000002, 199.3999999999999, 28.600000000000165, 291.10000000000014, -93.5000000000005, 198.29999999999964, 40.0000000000003, 72.10000000000011, 117.1, 215.39999999999972, -29.099999999999937, 166.6999999999997, 48.000000000000206, 40.0000000000003, 193.09999999999957, 40.0000000000003, 21.500000000000156, 40.0000000000003, 160.19999999999962, 228.39999999999938, 34.100000000000094, 40.0000000000003, 47.20000000000029, 40.0000000000003, 132.99999999999886, 141.3999999999992, 121.79999999999954, 59.40000000000028, 45.10000000000032, 87.59999999999954, 104.79999999999903, 182.99999999999926, 55.600000000000364, 117.39999999999921, 106.00000000000017, 46.00000000000001, 82.99999999999982, 40.0000000000003, 207.39999999999935, 77.79999999999993, 226.49999999999986, 104.59999999999968, 86.90000000000003, 226.2999999999989, 278.60000000000014, 32.30000000000018, 136.79999999999876, 273.0999999999998, 106.29999999999974, 153.39999999999958, 210.0999999999992, 24.500000000000043, 153.29999999999944, 130.6999999999993, 88.19999999999989, 156.0999999999991, 68.69999999999999, 249.8999999999999, 161.49999999999957, 46.00000000000003, 341.3999999999999, 186.69999999999922, -171.59999999999997, 179.09999999999948, 147.29999999999916, 55.30000000000019, 121.39999999999964, 330.29999999999995, -68.10000000000002, -146.29999999999993, 85.30000000000001, 143.6999999999996, 118.09999999999977, 244.2999999999995, 261.0999999999997, -91.5, -104.49999999999999, 75.60000000000005, 40.0000000000003, -50.19999999999957, 157.3999999999994, -197.7, 194.89999999999938, -3.7999999999999936, 258.3, 320.79999999999995, 193.8999999999994, 77.29999999999987, 162.69999999999945, 61.8000000000001, 136.89999999999975, 40.0000000000003, 177.49999999999932, 91.29999999999902, 12.899999999999963, 154.29999999999964, 40.0000000000003, -307.6, -50.70000000000002, 165.29999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [196.39999999999998, 133.9999999999999, 33.19999999999999, 108.2, 13.699999999999966, -90.10000000000002, 128.29999999999993, 129.79999999999998, -252.40000000000018, 17.899999999999988, 85.70000000000002, 71.59999999999997, 20.000000000000014, 20.000000000000014, 50.00000000000012, -34.89999999999978, 48.49999999999999, -111.40000000000003, 60.799999999999976, 113.59999999999974, -48.09999999999998, -226.00000000000017, 36.8, 56.900000000000006, 17.899999999999988, -46.89999999999999, 20.000000000000014, 20.000000000000014, 80.90000000000006, 72.19999999999996, 20.000000000000014, 20.000000000000014, -24.69999999999996, -29.799999999999827, 20.000000000000014, 20.000000000000014, 126.20000000000002, 20.000000000000014, 85.69999999999962, 139.6999999999997, -19.899999999999814, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 96.49999999999955, 33.50000000000012, 9.499999999999964, 107.89999999999989, 93.79999999999993, 22.999999999999986, 45.200000000000124, -65.80000000000075, 19.400000000000016, 13.699999999999964, -93.7000000000005, 74.29999999999997, 84.79999999999967, 20.000000000000014, 75.20000000000006, 93.79999999999987, -40.900000000000034, 60.50000000000016, 60.20000000000013, 27.20000000000002, 46.09999999999997, -12.100000000000083, 14.299999999999965, 4.700000000000194, -9.399999999999963, 37.40000000000008, 20.000000000000014, 20.000000000000014, 187.40000000000003, 20.000000000000014, 39.80000000000017, 20.000000000000014, 158.6, 59.89999999999996, 38.90000000000016, 43.70000000000004, 17.900000000000055, 20.000000000000014, 118.9999999999996, 107.2999999999997, 129.5, 118.09999999999994, 51.50000000000009, -143.2, 114.7999999999995, 20.000000000000014, 140.59999999999994, 132.49999999999977, -43.300000000000004, 68.6, 133.39999999999995, 20.000000000000014, 190.09999999999994, 20.000000000000014, 10.700000000000005, -68.20000000000007, 20.000000000000014, 128.29999999999993, 35.30000000000019, 85.40000000000003, 57.200000000000045, 20.000000000000014, 20.000000000000014, 136.09999999999974, 34.700000000000145, 20.000000000000014, 21.200000000000017, 184.69999999999996, 141.5, 20.000000000000014, -214.30000000000004, 71.3, 163.1, 164.29999999999995, 166.69999999999987, 20.000000000000014, -166.60000000000002, -193.00000000000009, 157.10000000000002, 20.000000000000014, 136.09999999999977, 3.1999999999999615, -102.40000000000006, 13.699999999999964, 76.40000000000003, 20.000000000000014, 172.39999999999992, 155.89999999999986, -25.599999999999994, -176.50000000000009, -142.6, -171.7, 19.10000000000002, -14.79999999999999, 91.69999999999999, 20.000000000000014, 20.000000000000014, 61.100000000000016, 44.60000000000001, 193.7, 73.09999999999997, 181.99999999999994, -113.5, -175.0, -108.10000000000025, -72.40000000000015, 30.799999999999997, -110.2000000000001, 20.000000000000014, 20.000000000000014, 7.399999999999965, -139.6000000000003, 20.000000000000014, 112.39999999999999, -201.7, -208.0, 170.89999999999998, 20.000000000000014, 124.4, -299.20000000000005, 130.39999999999998, 98.9, 191.89999999999995, 128.9, 173.90000000000003, 20.000000000000014, 132.79999999999995, -224.50000000000026, 20.000000000000014, 130.70000000000005, -82.89999999999998, 10.699999999999996, 99.49999999999999, -46.60000000000004, 20.000000000000014, 20.000000000000014, 156.49999999999991, 20.000000000000014, 71.29999999999966, 20.000000000000014, -222.10000000000002, 20.000000000000014, 134.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.40000000000003, -167.2, -12.699999999999996, -166.0, 113.89999999999996, 28.400000000000173], "policy_predator_policy_reward": [0.0, 10.0, 0.0, 58.0, 9.0, 96.0, 7.0, 26.0, 140.0, 1.0, 27.0, 14.0, 0.0, 0.0, 31.0, 26.0, 94.0, 86.0, 0.0, 41.0, 102.0, 143.0, 39.0, 34.0, 76.0, 1.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 3.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 13.0, 11.0, 0.0, 5.0, 45.0, 35.0, 12.0, 0.0, 55.0, 52.0, 0.0, 0.0, 0.0, 14.0, 25.0, 11.0, 0.0, 30.0, 32.0, 40.0, 20.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 8.0, 0.0, 22.0, 0.0, 39.0, 10.0, 0.0, 0.0, 21.0, 10.0, 43.0, 81.0, 0.0, 2.0, 0.0, 0.0, 43.0, 38.0, 0.0, 0.0, 0.0, 0.0, 20.0, 62.0, 0.0, 5.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 44.0, 0.0, 0.0, 61.0, 128.0, 14.0, 0.0, 0.0, 0.0, 60.0, 128.0, 0.0, 2.0, 8.0, 0.0, 70.0, 74.0, 0.0, 25.0, 2.0, 0.0, 11.0, 123.0, 86.0, 82.0, 78.0, 3.0, 19.0, 13.0, 29.0, 8.0, 1.0, 5.0, 6.0, 0.0, 47.0, 150.0, 40.0, 36.0, 89.0, 66.0, 0.0, 0.0, 21.0, 61.0, 25.0, 0.0, 173.0, 39.0, 0.0, 4.0, 171.0, 0.0, 3.0, 26.0, 0.0, 0.0, 0.0, 0.0, 63.0, 106.0, 12.0, 0.0, 72.0, 62.0, 65.0, 19.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 129.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 128.0, 0.0, 23.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6667933964902722, "mean_inference_ms": 1.7363685087637517, "mean_action_processing_ms": 0.2830349645639007, "mean_env_wait_ms": 0.23835992583833807, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015178203582763672, "StateBufferConnector_ms": 0.004446744918823242, "ViewRequirementAgentConnector_ms": 0.1895308494567871}, "num_episodes": 23, "episode_return_max": 341.3999999999999, "episode_return_min": -307.6, "episode_return_mean": 103.84999999999978, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.12547903474825, "num_env_steps_trained_throughput_per_sec": 368.12547903474825, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 11487.857, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11487.803, "sample_time_ms": 2040.04, "learn_time_ms": 9429.114, "learn_throughput": 424.218, "synch_weights_time_ms": 14.293}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "04dec_00002", "date": "2024-08-13_16-35-41", "timestamp": 1723581341, "time_this_iter_s": 10.918512105941772, "time_total_s": 774.862375497818, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04b9ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 774.862375497818, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 47.1875, "ram_util_percent": 85.63125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8571556402734979, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 2.8810516273533855, "policy_loss": -0.0027100557011734477, "vf_loss": 2.8833983404926524, "vf_explained_var": 0.009731461289067747, "kl": 0.007655494732526705, "entropy": 0.9308138308701692, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 35.102889983679255, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 7.199144023057645, "policy_loss": 0.0022046733499755935, "vf_loss": 7.196579509815842, "vf_explained_var": 0.18951040383369203, "kl": 0.0067393841828871474, "entropy": 0.8390824601763771, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 341.3999999999999, "episode_reward_min": -307.6, "episode_reward_mean": 104.64199999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -330.40000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 27.685999999999957, "predator_policy": 24.635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [160.19999999999962, 228.39999999999938, 34.100000000000094, 40.0000000000003, 47.20000000000029, 40.0000000000003, 132.99999999999886, 141.3999999999992, 121.79999999999954, 59.40000000000028, 45.10000000000032, 87.59999999999954, 104.79999999999903, 182.99999999999926, 55.600000000000364, 117.39999999999921, 106.00000000000017, 46.00000000000001, 82.99999999999982, 40.0000000000003, 207.39999999999935, 77.79999999999993, 226.49999999999986, 104.59999999999968, 86.90000000000003, 226.2999999999989, 278.60000000000014, 32.30000000000018, 136.79999999999876, 273.0999999999998, 106.29999999999974, 153.39999999999958, 210.0999999999992, 24.500000000000043, 153.29999999999944, 130.6999999999993, 88.19999999999989, 156.0999999999991, 68.69999999999999, 249.8999999999999, 161.49999999999957, 46.00000000000003, 341.3999999999999, 186.69999999999922, -171.59999999999997, 179.09999999999948, 147.29999999999916, 55.30000000000019, 121.39999999999964, 330.29999999999995, -68.10000000000002, -146.29999999999993, 85.30000000000001, 143.6999999999996, 118.09999999999977, 244.2999999999995, 261.0999999999997, -91.5, -104.49999999999999, 75.60000000000005, 40.0000000000003, -50.19999999999957, 157.3999999999994, -197.7, 194.89999999999938, -3.7999999999999936, 258.3, 320.79999999999995, 193.8999999999994, 77.29999999999987, 162.69999999999945, 61.8000000000001, 136.89999999999975, 40.0000000000003, 177.49999999999932, 91.29999999999902, 12.899999999999963, 154.29999999999964, 40.0000000000003, -307.6, -50.70000000000002, 165.29999999999944, 211.8999999999992, 67.00000000000004, 113.29999999999944, 223.29999999999993, 29.600000000000144, 230.39999999999932, 111.6999999999996, 188.79999999999953, 85.49999999999991, 31.100000000000172, 167.19999999999987, 78.29999999999944, 116.3999999999996, -28.299999999999834, 287.4999999999998, 124.59999999999899, -70.0, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [126.20000000000002, 20.000000000000014, 85.69999999999962, 139.6999999999997, -19.899999999999814, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 96.49999999999955, 33.50000000000012, 9.499999999999964, 107.89999999999989, 93.79999999999993, 22.999999999999986, 45.200000000000124, -65.80000000000075, 19.400000000000016, 13.699999999999964, -93.7000000000005, 74.29999999999997, 84.79999999999967, 20.000000000000014, 75.20000000000006, 93.79999999999987, -40.900000000000034, 60.50000000000016, 60.20000000000013, 27.20000000000002, 46.09999999999997, -12.100000000000083, 14.299999999999965, 4.700000000000194, -9.399999999999963, 37.40000000000008, 20.000000000000014, 20.000000000000014, 187.40000000000003, 20.000000000000014, 39.80000000000017, 20.000000000000014, 158.6, 59.89999999999996, 38.90000000000016, 43.70000000000004, 17.900000000000055, 20.000000000000014, 118.9999999999996, 107.2999999999997, 129.5, 118.09999999999994, 51.50000000000009, -143.2, 114.7999999999995, 20.000000000000014, 140.59999999999994, 132.49999999999977, -43.300000000000004, 68.6, 133.39999999999995, 20.000000000000014, 190.09999999999994, 20.000000000000014, 10.700000000000005, -68.20000000000007, 20.000000000000014, 128.29999999999993, 35.30000000000019, 85.40000000000003, 57.200000000000045, 20.000000000000014, 20.000000000000014, 136.09999999999974, 34.700000000000145, 20.000000000000014, 21.200000000000017, 184.69999999999996, 141.5, 20.000000000000014, -214.30000000000004, 71.3, 163.1, 164.29999999999995, 166.69999999999987, 20.000000000000014, -166.60000000000002, -193.00000000000009, 157.10000000000002, 20.000000000000014, 136.09999999999977, 3.1999999999999615, -102.40000000000006, 13.699999999999964, 76.40000000000003, 20.000000000000014, 172.39999999999992, 155.89999999999986, -25.599999999999994, -176.50000000000009, -142.6, -171.7, 19.10000000000002, -14.79999999999999, 91.69999999999999, 20.000000000000014, 20.000000000000014, 61.100000000000016, 44.60000000000001, 193.7, 73.09999999999997, 181.99999999999994, -113.5, -175.0, -108.10000000000025, -72.40000000000015, 30.799999999999997, -110.2000000000001, 20.000000000000014, 20.000000000000014, 7.399999999999965, -139.6000000000003, 20.000000000000014, 112.39999999999999, -201.7, -208.0, 170.89999999999998, 20.000000000000014, 124.4, -299.20000000000005, 130.39999999999998, 98.9, 191.89999999999995, 128.9, 173.90000000000003, 20.000000000000014, 132.79999999999995, -224.50000000000026, 20.000000000000014, 130.70000000000005, -82.89999999999998, 10.699999999999996, 99.49999999999999, -46.60000000000004, 20.000000000000014, 20.000000000000014, 156.49999999999991, 20.000000000000014, 71.29999999999966, 20.000000000000014, -222.10000000000002, 20.000000000000014, 134.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.40000000000003, -167.2, -12.699999999999996, -166.0, 113.89999999999996, 28.400000000000173, 191.89999999999995, 20.000000000000014, 20.000000000000014, 47.00000000000007, 59.30000000000004, 20.000000000000014, 118.10000000000001, 57.20000000000001, -145.00000000000017, 68.59999999999988, 140.59999999999977, 78.79999999999988, 1.6999999999999615, 20.000000000000014, 74.00000000000003, 84.80000000000003, 20.000000000000014, 15.500000000000055, -73.90000000000009, 20.000000000000014, 60.49999999999998, 64.70000000000002, 83.89999999999951, -79.60000000000008, -122.80000000000005, 162.19999999999976, -223.30000000000018, 20.000000000000014, 142.39999999999966, 145.09999999999968, 20.000000000000014, 104.59999999999957, -235.0, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [12.0, 2.0, 0.0, 3.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 13.0, 11.0, 0.0, 5.0, 45.0, 35.0, 12.0, 0.0, 55.0, 52.0, 0.0, 0.0, 0.0, 14.0, 25.0, 11.0, 0.0, 30.0, 32.0, 40.0, 20.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 8.0, 0.0, 22.0, 0.0, 39.0, 10.0, 0.0, 0.0, 21.0, 10.0, 43.0, 81.0, 0.0, 2.0, 0.0, 0.0, 43.0, 38.0, 0.0, 0.0, 0.0, 0.0, 20.0, 62.0, 0.0, 5.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 44.0, 0.0, 0.0, 61.0, 128.0, 14.0, 0.0, 0.0, 0.0, 60.0, 128.0, 0.0, 2.0, 8.0, 0.0, 70.0, 74.0, 0.0, 25.0, 2.0, 0.0, 11.0, 123.0, 86.0, 82.0, 78.0, 3.0, 19.0, 13.0, 29.0, 8.0, 1.0, 5.0, 6.0, 0.0, 47.0, 150.0, 40.0, 36.0, 89.0, 66.0, 0.0, 0.0, 21.0, 61.0, 25.0, 0.0, 173.0, 39.0, 0.0, 4.0, 171.0, 0.0, 3.0, 26.0, 0.0, 0.0, 0.0, 0.0, 63.0, 106.0, 12.0, 0.0, 72.0, 62.0, 65.0, 19.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 129.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 128.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 18.0, 30.0, 0.0, 106.0, 9.0, 2.0, 50.0, 40.0, 8.0, 22.0, 48.0, 2.0, 51.0, 34.0, 0.0, 42.0, 74.0, 0.0, 0.0, 77.0, 60.0, 115.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.670994502318571, "mean_inference_ms": 1.7476258143368733, "mean_action_processing_ms": 0.284087505662563, "mean_env_wait_ms": 0.24019534928183553, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014995932579040527, "StateBufferConnector_ms": 0.004337906837463379, "ViewRequirementAgentConnector_ms": 0.18844294548034668}, "num_episodes": 18, "episode_return_max": 341.3999999999999, "episode_return_min": -307.6, "episode_return_mean": 104.64199999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 384.42531332367713, "num_env_steps_trained_throughput_per_sec": 384.42531332367713, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 11314.785, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11314.735, "sample_time_ms": 1997.425, "learn_time_ms": 9299.861, "learn_throughput": 430.114, "synch_weights_time_ms": 13.749}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "04dec_00002", "date": "2024-08-13_16-35-51", "timestamp": 1723581351, "time_this_iter_s": 10.482392072677612, "time_total_s": 785.3447675704956, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b064b160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 785.3447675704956, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 47.04, "ram_util_percent": 86.69333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0773487217369533, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 3.9074989608986668, "policy_loss": -0.0045283528461204795, "vf_loss": 3.9114832413890372, "vf_explained_var": -0.00315950213285981, "kl": 0.011463575501000463, "entropy": 0.8800627972083117, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.036861641665617, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 6.808901276916423, "policy_loss": -0.0010500453934861869, "vf_loss": 6.809534946320549, "vf_explained_var": 0.008925868562920384, "kl": 0.0077984870802054644, "entropy": 0.8410874293910132, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 341.3999999999999, "episode_reward_min": -307.6, "episode_reward_mean": 105.09099999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -330.40000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 24.735499999999966, "predator_policy": 27.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [82.99999999999982, 40.0000000000003, 207.39999999999935, 77.79999999999993, 226.49999999999986, 104.59999999999968, 86.90000000000003, 226.2999999999989, 278.60000000000014, 32.30000000000018, 136.79999999999876, 273.0999999999998, 106.29999999999974, 153.39999999999958, 210.0999999999992, 24.500000000000043, 153.29999999999944, 130.6999999999993, 88.19999999999989, 156.0999999999991, 68.69999999999999, 249.8999999999999, 161.49999999999957, 46.00000000000003, 341.3999999999999, 186.69999999999922, -171.59999999999997, 179.09999999999948, 147.29999999999916, 55.30000000000019, 121.39999999999964, 330.29999999999995, -68.10000000000002, -146.29999999999993, 85.30000000000001, 143.6999999999996, 118.09999999999977, 244.2999999999995, 261.0999999999997, -91.5, -104.49999999999999, 75.60000000000005, 40.0000000000003, -50.19999999999957, 157.3999999999994, -197.7, 194.89999999999938, -3.7999999999999936, 258.3, 320.79999999999995, 193.8999999999994, 77.29999999999987, 162.69999999999945, 61.8000000000001, 136.89999999999975, 40.0000000000003, 177.49999999999932, 91.29999999999902, 12.899999999999963, 154.29999999999964, 40.0000000000003, -307.6, -50.70000000000002, 165.29999999999944, 211.8999999999992, 67.00000000000004, 113.29999999999944, 223.29999999999993, 29.600000000000144, 230.39999999999932, 111.6999999999996, 188.79999999999953, 85.49999999999991, 31.100000000000172, 167.19999999999987, 78.29999999999944, 116.3999999999996, -28.299999999999834, 287.4999999999998, 124.59999999999899, -70.0, 40.0000000000003, 107.49999999999972, 40.0000000000003, 114.49999999999943, -84.6000000000005, 174.0999999999999, 144.09999999999926, 177.29999999999916, 280.9999999999996, -34.89999999999997, -52.300000000000416, 122.69999999999989, 80.69999999999999, 136.09999999999943, 226.19999999999973, 21.600000000000072, 175.9999999999995, 40.0000000000003, 125.89999999999961], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.399999999999963, 37.40000000000008, 20.000000000000014, 20.000000000000014, 187.40000000000003, 20.000000000000014, 39.80000000000017, 20.000000000000014, 158.6, 59.89999999999996, 38.90000000000016, 43.70000000000004, 17.900000000000055, 20.000000000000014, 118.9999999999996, 107.2999999999997, 129.5, 118.09999999999994, 51.50000000000009, -143.2, 114.7999999999995, 20.000000000000014, 140.59999999999994, 132.49999999999977, -43.300000000000004, 68.6, 133.39999999999995, 20.000000000000014, 190.09999999999994, 20.000000000000014, 10.700000000000005, -68.20000000000007, 20.000000000000014, 128.29999999999993, 35.30000000000019, 85.40000000000003, 57.200000000000045, 20.000000000000014, 20.000000000000014, 136.09999999999974, 34.700000000000145, 20.000000000000014, 21.200000000000017, 184.69999999999996, 141.5, 20.000000000000014, -214.30000000000004, 71.3, 163.1, 164.29999999999995, 166.69999999999987, 20.000000000000014, -166.60000000000002, -193.00000000000009, 157.10000000000002, 20.000000000000014, 136.09999999999977, 3.1999999999999615, -102.40000000000006, 13.699999999999964, 76.40000000000003, 20.000000000000014, 172.39999999999992, 155.89999999999986, -25.599999999999994, -176.50000000000009, -142.6, -171.7, 19.10000000000002, -14.79999999999999, 91.69999999999999, 20.000000000000014, 20.000000000000014, 61.100000000000016, 44.60000000000001, 193.7, 73.09999999999997, 181.99999999999994, -113.5, -175.0, -108.10000000000025, -72.40000000000015, 30.799999999999997, -110.2000000000001, 20.000000000000014, 20.000000000000014, 7.399999999999965, -139.6000000000003, 20.000000000000014, 112.39999999999999, -201.7, -208.0, 170.89999999999998, 20.000000000000014, 124.4, -299.20000000000005, 130.39999999999998, 98.9, 191.89999999999995, 128.9, 173.90000000000003, 20.000000000000014, 132.79999999999995, -224.50000000000026, 20.000000000000014, 130.70000000000005, -82.89999999999998, 10.699999999999996, 99.49999999999999, -46.60000000000004, 20.000000000000014, 20.000000000000014, 156.49999999999991, 20.000000000000014, 71.29999999999966, 20.000000000000014, -222.10000000000002, 20.000000000000014, 134.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.40000000000003, -167.2, -12.699999999999996, -166.0, 113.89999999999996, 28.400000000000173, 191.89999999999995, 20.000000000000014, 20.000000000000014, 47.00000000000007, 59.30000000000004, 20.000000000000014, 118.10000000000001, 57.20000000000001, -145.00000000000017, 68.59999999999988, 140.59999999999977, 78.79999999999988, 1.6999999999999615, 20.000000000000014, 74.00000000000003, 84.80000000000003, 20.000000000000014, 15.500000000000055, -73.90000000000009, 20.000000000000014, 60.49999999999998, 64.70000000000002, 83.89999999999951, -79.60000000000008, -122.80000000000005, 162.19999999999976, -223.30000000000018, 20.000000000000014, 142.39999999999966, 145.09999999999968, 20.000000000000014, 104.59999999999957, -235.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.500000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000002, 20.000000000000014, -250.60000000000005, 20.000000000000014, 59.00000000000003, 58.099999999999994, 20.000000000000014, 118.09999999999984, 159.49999999999986, 15.799999999999963, 136.09999999999994, 143.8999999999997, 71.30000000000008, -281.2, 20.000000000000014, -208.29999999999998, 125.59999999999988, -232.89999999999998, 7.699999999999996, 20.000000000000014, 106.09999999999985, 20.000000000000014, 128.29999999999978, 47.900000000000006, -90.69999999999997, 8.300000000000011, 117.19999999999999, 45.80000000000014, 20.000000000000014, 20.000000000000014, 89.89999999999995, 20.000000000000014], "policy_predator_policy_reward": [0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 8.0, 0.0, 22.0, 0.0, 39.0, 10.0, 0.0, 0.0, 21.0, 10.0, 43.0, 81.0, 0.0, 2.0, 0.0, 0.0, 43.0, 38.0, 0.0, 0.0, 0.0, 0.0, 20.0, 62.0, 0.0, 5.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 44.0, 0.0, 0.0, 61.0, 128.0, 14.0, 0.0, 0.0, 0.0, 60.0, 128.0, 0.0, 2.0, 8.0, 0.0, 70.0, 74.0, 0.0, 25.0, 2.0, 0.0, 11.0, 123.0, 86.0, 82.0, 78.0, 3.0, 19.0, 13.0, 29.0, 8.0, 1.0, 5.0, 6.0, 0.0, 47.0, 150.0, 40.0, 36.0, 89.0, 66.0, 0.0, 0.0, 21.0, 61.0, 25.0, 0.0, 173.0, 39.0, 0.0, 4.0, 171.0, 0.0, 3.0, 26.0, 0.0, 0.0, 0.0, 0.0, 63.0, 106.0, 12.0, 0.0, 72.0, 62.0, 65.0, 19.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 129.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 128.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 18.0, 30.0, 0.0, 106.0, 9.0, 2.0, 50.0, 40.0, 8.0, 22.0, 48.0, 2.0, 51.0, 34.0, 0.0, 42.0, 74.0, 0.0, 0.0, 77.0, 60.0, 115.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 7.0, 45.0, 98.0, 48.0, 40.0, 17.0, 6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 158.0, 17.0, 124.0, 12.0, 122.0, 108.0, 53.0, 0.0, 10.0, 0.0, 2.0, 48.0, 0.0, 104.0, 13.0, 0.0, 0.0, 0.0, 0.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6742849421720615, "mean_inference_ms": 1.756074703618244, "mean_action_processing_ms": 0.2851046283200455, "mean_env_wait_ms": 0.2414148689677858, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015047550201416016, "StateBufferConnector_ms": 0.004292726516723633, "ViewRequirementAgentConnector_ms": 0.17084956169128418}, "num_episodes": 18, "episode_return_max": 341.3999999999999, "episode_return_min": -307.6, "episode_return_mean": 105.09099999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 389.7149923218285, "num_env_steps_trained_throughput_per_sec": 389.7149923218285, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 11142.682, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11142.634, "sample_time_ms": 1900.43, "learn_time_ms": 9224.712, "learn_throughput": 433.618, "synch_weights_time_ms": 13.874}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "04dec_00002", "date": "2024-08-13_16-36-02", "timestamp": 1723581362, "time_this_iter_s": 10.320681810379028, "time_total_s": 795.6654493808746, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b359d940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 795.6654493808746, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 46.49999999999999, "ram_util_percent": 86.54285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8793882008898195, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 3.535927179376915, "policy_loss": -0.0030222219703275534, "vf_loss": 3.5386091932417854, "vf_explained_var": 0.001925446116735065, "kl": 0.007168367336475365, "entropy": 0.8152231147680333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.183810189602866, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 8.340419785181682, "policy_loss": -0.0023162017684804385, "vf_loss": 8.341998419433674, "vf_explained_var": 0.22486175021166524, "kl": 0.013813879887055656, "entropy": 0.7610140165323933, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 341.3999999999999, "episode_reward_min": -307.6, "episode_reward_mean": 93.06399999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -330.40000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 14.551999999999957, "predator_policy": 31.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [161.49999999999957, 46.00000000000003, 341.3999999999999, 186.69999999999922, -171.59999999999997, 179.09999999999948, 147.29999999999916, 55.30000000000019, 121.39999999999964, 330.29999999999995, -68.10000000000002, -146.29999999999993, 85.30000000000001, 143.6999999999996, 118.09999999999977, 244.2999999999995, 261.0999999999997, -91.5, -104.49999999999999, 75.60000000000005, 40.0000000000003, -50.19999999999957, 157.3999999999994, -197.7, 194.89999999999938, -3.7999999999999936, 258.3, 320.79999999999995, 193.8999999999994, 77.29999999999987, 162.69999999999945, 61.8000000000001, 136.89999999999975, 40.0000000000003, 177.49999999999932, 91.29999999999902, 12.899999999999963, 154.29999999999964, 40.0000000000003, -307.6, -50.70000000000002, 165.29999999999944, 211.8999999999992, 67.00000000000004, 113.29999999999944, 223.29999999999993, 29.600000000000144, 230.39999999999932, 111.6999999999996, 188.79999999999953, 85.49999999999991, 31.100000000000172, 167.19999999999987, 78.29999999999944, 116.3999999999996, -28.299999999999834, 287.4999999999998, 124.59999999999899, -70.0, 40.0000000000003, 107.49999999999972, 40.0000000000003, 114.49999999999943, -84.6000000000005, 174.0999999999999, 144.09999999999926, 177.29999999999916, 280.9999999999996, -34.89999999999997, -52.300000000000416, 122.69999999999989, 80.69999999999999, 136.09999999999943, 226.19999999999973, 21.600000000000072, 175.9999999999995, 40.0000000000003, 125.89999999999961, 142.59999999999934, -27.099999999999973, 125.49999999999922, 66.90000000000003, 158.89999999999893, 119.79999999999966, 63.90000000000003, 257.7999999999995, 114.7999999999994, -52.49999999999985, 110.29999999999917, -84.90000000000003, 32.600000000000044, 94.89999999999867, 30.100000000000286, 204.69999999999942, 115.59999999999948, 163.99999999999915, -0.9999999999998167, 152.10000000000008, 140.59999999999982, -17.80000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [141.5, 20.000000000000014, -214.30000000000004, 71.3, 163.1, 164.29999999999995, 166.69999999999987, 20.000000000000014, -166.60000000000002, -193.00000000000009, 157.10000000000002, 20.000000000000014, 136.09999999999977, 3.1999999999999615, -102.40000000000006, 13.699999999999964, 76.40000000000003, 20.000000000000014, 172.39999999999992, 155.89999999999986, -25.599999999999994, -176.50000000000009, -142.6, -171.7, 19.10000000000002, -14.79999999999999, 91.69999999999999, 20.000000000000014, 20.000000000000014, 61.100000000000016, 44.60000000000001, 193.7, 73.09999999999997, 181.99999999999994, -113.5, -175.0, -108.10000000000025, -72.40000000000015, 30.799999999999997, -110.2000000000001, 20.000000000000014, 20.000000000000014, 7.399999999999965, -139.6000000000003, 20.000000000000014, 112.39999999999999, -201.7, -208.0, 170.89999999999998, 20.000000000000014, 124.4, -299.20000000000005, 130.39999999999998, 98.9, 191.89999999999995, 128.9, 173.90000000000003, 20.000000000000014, 132.79999999999995, -224.50000000000026, 20.000000000000014, 130.70000000000005, -82.89999999999998, 10.699999999999996, 99.49999999999999, -46.60000000000004, 20.000000000000014, 20.000000000000014, 156.49999999999991, 20.000000000000014, 71.29999999999966, 20.000000000000014, -222.10000000000002, 20.000000000000014, 134.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.40000000000003, -167.2, -12.699999999999996, -166.0, 113.89999999999996, 28.400000000000173, 191.89999999999995, 20.000000000000014, 20.000000000000014, 47.00000000000007, 59.30000000000004, 20.000000000000014, 118.10000000000001, 57.20000000000001, -145.00000000000017, 68.59999999999988, 140.59999999999977, 78.79999999999988, 1.6999999999999615, 20.000000000000014, 74.00000000000003, 84.80000000000003, 20.000000000000014, 15.500000000000055, -73.90000000000009, 20.000000000000014, 60.49999999999998, 64.70000000000002, 83.89999999999951, -79.60000000000008, -122.80000000000005, 162.19999999999976, -223.30000000000018, 20.000000000000014, 142.39999999999966, 145.09999999999968, 20.000000000000014, 104.59999999999957, -235.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.500000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000002, 20.000000000000014, -250.60000000000005, 20.000000000000014, 59.00000000000003, 58.099999999999994, 20.000000000000014, 118.09999999999984, 159.49999999999986, 15.799999999999963, 136.09999999999994, 143.8999999999997, 71.30000000000008, -281.2, 20.000000000000014, -208.29999999999998, 125.59999999999988, -232.89999999999998, 7.699999999999996, 20.000000000000014, 106.09999999999985, 20.000000000000014, 128.29999999999978, 47.900000000000006, -90.69999999999997, 8.300000000000011, 117.19999999999999, 45.80000000000014, 20.000000000000014, 20.000000000000014, 89.89999999999995, 20.000000000000014, 115.6999999999999, 17.899999999999988, 98.29999999999978, -309.4, 20.000000000000014, 105.49999999999984, -12.1, 20.000000000000014, 86.59999999999974, 44.300000000000146, 134.5999999999998, -107.80000000000001, -153.10000000000016, 29.00000000000001, 131.59999999999974, 126.19999999999997, 9.499999999999964, 95.2999999999999, -216.7, 27.200000000000003, 115.39999999999958, -87.10000000000021, -227.79999999999993, 20.90000000000003, 20.000000000000014, -42.399999999999956, 74.89999999999951, 20.000000000000014, -19.8999999999998, -3.9999999999999014, 91.09999999999995, 95.59999999999977, 20.000000000000014, 95.59999999999982, 71.90000000000003, 70.09999999999991, -109.00000000000017, 20.000000000000014, 146.00000000000006, -73.9, 113.8999999999998, -55.30000000000003, -29.50000000000002, -67.30000000000001], "policy_predator_policy_reward": [0.0, 0.0, 61.0, 128.0, 14.0, 0.0, 0.0, 0.0, 60.0, 128.0, 0.0, 2.0, 8.0, 0.0, 70.0, 74.0, 0.0, 25.0, 2.0, 0.0, 11.0, 123.0, 86.0, 82.0, 78.0, 3.0, 19.0, 13.0, 29.0, 8.0, 1.0, 5.0, 6.0, 0.0, 47.0, 150.0, 40.0, 36.0, 89.0, 66.0, 0.0, 0.0, 21.0, 61.0, 25.0, 0.0, 173.0, 39.0, 0.0, 4.0, 171.0, 0.0, 3.0, 26.0, 0.0, 0.0, 0.0, 0.0, 63.0, 106.0, 12.0, 0.0, 72.0, 62.0, 65.0, 19.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 129.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 128.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 18.0, 30.0, 0.0, 106.0, 9.0, 2.0, 50.0, 40.0, 8.0, 22.0, 48.0, 2.0, 51.0, 34.0, 0.0, 42.0, 74.0, 0.0, 0.0, 77.0, 60.0, 115.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 7.0, 45.0, 98.0, 48.0, 40.0, 17.0, 6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 158.0, 17.0, 124.0, 12.0, 122.0, 108.0, 53.0, 0.0, 10.0, 0.0, 2.0, 48.0, 0.0, 104.0, 13.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 0.0, 82.0, 102.0, 0.0, 0.0, 0.0, 59.0, 13.0, 15.0, 16.0, 77.0, 98.0, 90.0, 0.0, 0.0, 4.0, 6.0, 118.0, 19.0, 48.0, 34.0, 51.0, 71.0, 18.0, 37.0, 0.0, 0.0, 37.0, 17.0, 18.0, 0.0, 0.0, 0.0, 9.0, 13.0, 88.0, 0.0, 67.0, 13.0, 82.0, 0.0, 0.0, 79.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6774009729954876, "mean_inference_ms": 1.7634757978036122, "mean_action_processing_ms": 0.2859059227323422, "mean_env_wait_ms": 0.24233749528194565, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014811038970947266, "StateBufferConnector_ms": 0.003946423530578613, "ViewRequirementAgentConnector_ms": 0.16343367099761963}, "num_episodes": 22, "episode_return_max": 341.3999999999999, "episode_return_min": -307.6, "episode_return_mean": 93.06399999999977, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.3763329188997, "num_env_steps_trained_throughput_per_sec": 374.3763329188997, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 11180.838, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11180.787, "sample_time_ms": 1904.673, "learn_time_ms": 9258.193, "learn_throughput": 432.05, "synch_weights_time_ms": 14.21}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "04dec_00002", "date": "2024-08-13_16-36-13", "timestamp": 1723581373, "time_this_iter_s": 10.736721992492676, "time_total_s": 806.4021713733673, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06163a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 806.4021713733673, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 45.45, "ram_util_percent": 86.35}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0220750239948746, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 4.532266121818906, "policy_loss": -0.004273275349279323, "vf_loss": 4.536054498177988, "vf_explained_var": 0.007980651672555026, "kl": 0.01021664448288316, "entropy": 0.7745274228709085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 24.32344107501721, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 7.395249716440836, "policy_loss": -0.006000823330715614, "vf_loss": 7.400531305585589, "vf_explained_var": 0.14350150788902605, "kl": 0.013470389545193834, "entropy": 0.8546841232864945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 320.79999999999995, "episode_reward_min": -307.6, "episode_reward_mean": 97.36599999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -330.40000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.89999999999995, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 14.482999999999953, "predator_policy": 34.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-104.49999999999999, 75.60000000000005, 40.0000000000003, -50.19999999999957, 157.3999999999994, -197.7, 194.89999999999938, -3.7999999999999936, 258.3, 320.79999999999995, 193.8999999999994, 77.29999999999987, 162.69999999999945, 61.8000000000001, 136.89999999999975, 40.0000000000003, 177.49999999999932, 91.29999999999902, 12.899999999999963, 154.29999999999964, 40.0000000000003, -307.6, -50.70000000000002, 165.29999999999944, 211.8999999999992, 67.00000000000004, 113.29999999999944, 223.29999999999993, 29.600000000000144, 230.39999999999932, 111.6999999999996, 188.79999999999953, 85.49999999999991, 31.100000000000172, 167.19999999999987, 78.29999999999944, 116.3999999999996, -28.299999999999834, 287.4999999999998, 124.59999999999899, -70.0, 40.0000000000003, 107.49999999999972, 40.0000000000003, 114.49999999999943, -84.6000000000005, 174.0999999999999, 144.09999999999926, 177.29999999999916, 280.9999999999996, -34.89999999999997, -52.300000000000416, 122.69999999999989, 80.69999999999999, 136.09999999999943, 226.19999999999973, 21.600000000000072, 175.9999999999995, 40.0000000000003, 125.89999999999961, 142.59999999999934, -27.099999999999973, 125.49999999999922, 66.90000000000003, 158.89999999999893, 119.79999999999966, 63.90000000000003, 257.7999999999995, 114.7999999999994, -52.49999999999985, 110.29999999999917, -84.90000000000003, 32.600000000000044, 94.89999999999867, 30.100000000000286, 204.69999999999942, 115.59999999999948, 163.99999999999915, -0.9999999999998167, 152.10000000000008, 140.59999999999982, -17.80000000000002, 35.600000000000236, 12.599999999999964, 183.5999999999999, 104.6999999999998, 119.29999999999964, 171.09999999999985, 272.2000000000005, 136.99999999999974, 187.4999999999997, 133.79999999999976, 141.9999999999999, 167.79999999999998, 174.3999999999998, 81.10000000000008, 180.8999999999988, 151.69999999999962, 152.49999999999886, -33.599999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-108.10000000000025, -72.40000000000015, 30.799999999999997, -110.2000000000001, 20.000000000000014, 20.000000000000014, 7.399999999999965, -139.6000000000003, 20.000000000000014, 112.39999999999999, -201.7, -208.0, 170.89999999999998, 20.000000000000014, 124.4, -299.20000000000005, 130.39999999999998, 98.9, 191.89999999999995, 128.9, 173.90000000000003, 20.000000000000014, 132.79999999999995, -224.50000000000026, 20.000000000000014, 130.70000000000005, -82.89999999999998, 10.699999999999996, 99.49999999999999, -46.60000000000004, 20.000000000000014, 20.000000000000014, 156.49999999999991, 20.000000000000014, 71.29999999999966, 20.000000000000014, -222.10000000000002, 20.000000000000014, 134.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.40000000000003, -167.2, -12.699999999999996, -166.0, 113.89999999999996, 28.400000000000173, 191.89999999999995, 20.000000000000014, 20.000000000000014, 47.00000000000007, 59.30000000000004, 20.000000000000014, 118.10000000000001, 57.20000000000001, -145.00000000000017, 68.59999999999988, 140.59999999999977, 78.79999999999988, 1.6999999999999615, 20.000000000000014, 74.00000000000003, 84.80000000000003, 20.000000000000014, 15.500000000000055, -73.90000000000009, 20.000000000000014, 60.49999999999998, 64.70000000000002, 83.89999999999951, -79.60000000000008, -122.80000000000005, 162.19999999999976, -223.30000000000018, 20.000000000000014, 142.39999999999966, 145.09999999999968, 20.000000000000014, 104.59999999999957, -235.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.500000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000002, 20.000000000000014, -250.60000000000005, 20.000000000000014, 59.00000000000003, 58.099999999999994, 20.000000000000014, 118.09999999999984, 159.49999999999986, 15.799999999999963, 136.09999999999994, 143.8999999999997, 71.30000000000008, -281.2, 20.000000000000014, -208.29999999999998, 125.59999999999988, -232.89999999999998, 7.699999999999996, 20.000000000000014, 106.09999999999985, 20.000000000000014, 128.29999999999978, 47.900000000000006, -90.69999999999997, 8.300000000000011, 117.19999999999999, 45.80000000000014, 20.000000000000014, 20.000000000000014, 89.89999999999995, 20.000000000000014, 115.6999999999999, 17.899999999999988, 98.29999999999978, -309.4, 20.000000000000014, 105.49999999999984, -12.1, 20.000000000000014, 86.59999999999974, 44.300000000000146, 134.5999999999998, -107.80000000000001, -153.10000000000016, 29.00000000000001, 131.59999999999974, 126.19999999999997, 9.499999999999964, 95.2999999999999, -216.7, 27.200000000000003, 115.39999999999958, -87.10000000000021, -227.79999999999993, 20.90000000000003, 20.000000000000014, -42.399999999999956, 74.89999999999951, 20.000000000000014, -19.8999999999998, -3.9999999999999014, 91.09999999999995, 95.59999999999977, 20.000000000000014, 95.59999999999982, 71.90000000000003, 70.09999999999991, -109.00000000000017, 20.000000000000014, 146.00000000000006, -73.9, 113.8999999999998, -55.30000000000003, -29.50000000000002, -67.30000000000001, 17.899999999999988, 13.699999999999967, 13.09999999999997, -263.5, -15.100000000000367, 148.7, 4.700000000000022, 20.000000000000014, 41.300000000000026, 20.000000000000014, 64.4, -124.30000000000001, 140.59999999999982, 131.5999999999996, 86.59999999999988, -91.6000000000002, 41.90000000000002, 122.5999999999998, 148.0999999999998, -103.30000000000021, 111.19999999999987, -137.20000000000002, 82.10000000000002, -100.30000000000001, 50.90000000000003, 57.50000000000005, 20.000000000000014, 1.0999999999999979, 131.59999999999988, 38.3000000000002, 7.399999999999965, 128.3, 132.4999999999996, 20.000000000000014, -118.90000000000003, -144.70000000000002], "policy_predator_policy_reward": [40.0, 36.0, 89.0, 66.0, 0.0, 0.0, 21.0, 61.0, 25.0, 0.0, 173.0, 39.0, 0.0, 4.0, 171.0, 0.0, 3.0, 26.0, 0.0, 0.0, 0.0, 0.0, 63.0, 106.0, 12.0, 0.0, 72.0, 62.0, 65.0, 19.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 129.0, 86.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 128.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 18.0, 30.0, 0.0, 106.0, 9.0, 2.0, 50.0, 40.0, 8.0, 22.0, 48.0, 2.0, 51.0, 34.0, 0.0, 42.0, 74.0, 0.0, 0.0, 77.0, 60.0, 115.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 7.0, 45.0, 98.0, 48.0, 40.0, 17.0, 6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 158.0, 17.0, 124.0, 12.0, 122.0, 108.0, 53.0, 0.0, 10.0, 0.0, 2.0, 48.0, 0.0, 104.0, 13.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 0.0, 82.0, 102.0, 0.0, 0.0, 0.0, 59.0, 13.0, 15.0, 16.0, 77.0, 98.0, 90.0, 0.0, 0.0, 4.0, 6.0, 118.0, 19.0, 48.0, 34.0, 51.0, 71.0, 18.0, 37.0, 0.0, 0.0, 37.0, 17.0, 18.0, 0.0, 0.0, 0.0, 9.0, 13.0, 88.0, 0.0, 67.0, 13.0, 82.0, 0.0, 0.0, 79.0, 0.0, 4.0, 121.0, 142.0, 28.0, 22.0, 25.0, 55.0, 36.0, 22.0, 127.0, 104.0, 0.0, 0.0, 63.0, 79.0, 14.0, 9.0, 89.0, 0.0, 85.0, 83.0, 111.0, 75.0, 44.0, 22.0, 54.0, 6.0, 0.0, 11.0, 0.0, 16.0, 0.0, 0.0, 121.0, 109.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6781805733235987, "mean_inference_ms": 1.7669027463708573, "mean_action_processing_ms": 0.28614390219233243, "mean_env_wait_ms": 0.2430139061106874, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005408167839050293, "StateBufferConnector_ms": 0.0034227371215820312, "ViewRequirementAgentConnector_ms": 0.12990903854370117}, "num_episodes": 18, "episode_return_max": 320.79999999999995, "episode_return_min": -307.6, "episode_return_mean": 97.36599999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 385.98903383773694, "num_env_steps_trained_throughput_per_sec": 385.98903383773694, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 11230.63, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11230.578, "sample_time_ms": 1895.229, "learn_time_ms": 9317.61, "learn_throughput": 429.295, "synch_weights_time_ms": 13.958}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "04dec_00002", "date": "2024-08-13_16-36-23", "timestamp": 1723581383, "time_this_iter_s": 10.41935396194458, "time_total_s": 816.8215253353119, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0452d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 816.8215253353119, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 47.949999999999996, "ram_util_percent": 86.4857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9626688964546672, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 3.2974902961619947, "policy_loss": -0.005929527392551776, "vf_loss": 3.3030053245958197, "vf_explained_var": -0.0025819464650734393, "kl": 0.008733558472230863, "entropy": 0.7874777415442088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 31.994312454894107, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 7.433187747632385, "policy_loss": -0.0001539847419336044, "vf_loss": 7.43300654017736, "vf_explained_var": 0.09651838304504516, "kl": 0.006277628385072784, "entropy": 0.8698762608268273, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 287.4999999999998, "episode_reward_min": -122.70000000000059, "episode_reward_mean": 101.44699999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -359.7999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.89999999999995, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": 17.493499999999944, "predator_policy": 33.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [165.29999999999944, 211.8999999999992, 67.00000000000004, 113.29999999999944, 223.29999999999993, 29.600000000000144, 230.39999999999932, 111.6999999999996, 188.79999999999953, 85.49999999999991, 31.100000000000172, 167.19999999999987, 78.29999999999944, 116.3999999999996, -28.299999999999834, 287.4999999999998, 124.59999999999899, -70.0, 40.0000000000003, 107.49999999999972, 40.0000000000003, 114.49999999999943, -84.6000000000005, 174.0999999999999, 144.09999999999926, 177.29999999999916, 280.9999999999996, -34.89999999999997, -52.300000000000416, 122.69999999999989, 80.69999999999999, 136.09999999999943, 226.19999999999973, 21.600000000000072, 175.9999999999995, 40.0000000000003, 125.89999999999961, 142.59999999999934, -27.099999999999973, 125.49999999999922, 66.90000000000003, 158.89999999999893, 119.79999999999966, 63.90000000000003, 257.7999999999995, 114.7999999999994, -52.49999999999985, 110.29999999999917, -84.90000000000003, 32.600000000000044, 94.89999999999867, 30.100000000000286, 204.69999999999942, 115.59999999999948, 163.99999999999915, -0.9999999999998167, 152.10000000000008, 140.59999999999982, -17.80000000000002, 35.600000000000236, 12.599999999999964, 183.5999999999999, 104.6999999999998, 119.29999999999964, 171.09999999999985, 272.2000000000005, 136.99999999999974, 187.4999999999997, 133.79999999999976, 141.9999999999999, 167.79999999999998, 174.3999999999998, 81.10000000000008, 180.8999999999988, 151.69999999999962, 152.49999999999886, -33.599999999999994, -35.79999999999993, 85.69999999999993, 6.800000000000124, 139.6999999999991, 162.29999999999956, 113.79999999999927, 7.700000000000033, 138.99999999999915, 40.0000000000003, -4.9000000000000075, 138.99999999999923, 43.300000000000175, 237.99999999999915, 40.0000000000003, 182.7999999999992, -122.70000000000059, 277.5999999999998, 40.0000000000003, -56.79999999999979, 198.69999999999993, 118.49999999999973, 30.800000000000033, 105.69999999999865], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [113.89999999999996, 28.400000000000173, 191.89999999999995, 20.000000000000014, 20.000000000000014, 47.00000000000007, 59.30000000000004, 20.000000000000014, 118.10000000000001, 57.20000000000001, -145.00000000000017, 68.59999999999988, 140.59999999999977, 78.79999999999988, 1.6999999999999615, 20.000000000000014, 74.00000000000003, 84.80000000000003, 20.000000000000014, 15.500000000000055, -73.90000000000009, 20.000000000000014, 60.49999999999998, 64.70000000000002, 83.89999999999951, -79.60000000000008, -122.80000000000005, 162.19999999999976, -223.30000000000018, 20.000000000000014, 142.39999999999966, 145.09999999999968, 20.000000000000014, 104.59999999999957, -235.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.500000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000002, 20.000000000000014, -250.60000000000005, 20.000000000000014, 59.00000000000003, 58.099999999999994, 20.000000000000014, 118.09999999999984, 159.49999999999986, 15.799999999999963, 136.09999999999994, 143.8999999999997, 71.30000000000008, -281.2, 20.000000000000014, -208.29999999999998, 125.59999999999988, -232.89999999999998, 7.699999999999996, 20.000000000000014, 106.09999999999985, 20.000000000000014, 128.29999999999978, 47.900000000000006, -90.69999999999997, 8.300000000000011, 117.19999999999999, 45.80000000000014, 20.000000000000014, 20.000000000000014, 89.89999999999995, 20.000000000000014, 115.6999999999999, 17.899999999999988, 98.29999999999978, -309.4, 20.000000000000014, 105.49999999999984, -12.1, 20.000000000000014, 86.59999999999974, 44.300000000000146, 134.5999999999998, -107.80000000000001, -153.10000000000016, 29.00000000000001, 131.59999999999974, 126.19999999999997, 9.499999999999964, 95.2999999999999, -216.7, 27.200000000000003, 115.39999999999958, -87.10000000000021, -227.79999999999993, 20.90000000000003, 20.000000000000014, -42.399999999999956, 74.89999999999951, 20.000000000000014, -19.8999999999998, -3.9999999999999014, 91.09999999999995, 95.59999999999977, 20.000000000000014, 95.59999999999982, 71.90000000000003, 70.09999999999991, -109.00000000000017, 20.000000000000014, 146.00000000000006, -73.9, 113.8999999999998, -55.30000000000003, -29.50000000000002, -67.30000000000001, 17.899999999999988, 13.699999999999967, 13.09999999999997, -263.5, -15.100000000000367, 148.7, 4.700000000000022, 20.000000000000014, 41.300000000000026, 20.000000000000014, 64.4, -124.30000000000001, 140.59999999999982, 131.5999999999996, 86.59999999999988, -91.6000000000002, 41.90000000000002, 122.5999999999998, 148.0999999999998, -103.30000000000021, 111.19999999999987, -137.20000000000002, 82.10000000000002, -100.30000000000001, 50.90000000000003, 57.50000000000005, 20.000000000000014, 1.0999999999999979, 131.59999999999988, 38.3000000000002, 7.399999999999965, 128.3, 132.4999999999996, 20.000000000000014, -118.90000000000003, -144.70000000000002, -359.7999999999999, 109.99999999999979, 3.1999999999999615, 36.49999999999999, -93.70000000000002, -32.49999999999975, 20.000000000000014, 118.69999999999969, 9.499999999999964, 147.79999999999998, 20.000000000000014, 93.79999999999973, 83.60000000000002, -292.90000000000003, 20.000000000000014, 118.99999999999974, 20.000000000000014, 20.000000000000014, 116.29999999999954, -350.20000000000005, 118.99999999999983, 20.000000000000014, 11.599999999999964, -130.3, 129.7999999999999, 108.19999999999979, 20.000000000000014, 20.000000000000014, 7.399999999999965, 169.39999999999984, -327.70000000000005, 20.000000000000014, 144.19999999999987, 133.39999999999986, 20.000000000000014, 20.000000000000014, 29.900000000000183, -222.70000000000002, 124.39999999999992, 17.29999999999999, 51.50000000000001, 20.000000000000014, -44.19999999999989, 20.000000000000014, 20.000000000000014, 85.69999999999942], "policy_predator_policy_reward": [23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 18.0, 30.0, 0.0, 106.0, 9.0, 2.0, 50.0, 40.0, 8.0, 22.0, 48.0, 2.0, 51.0, 34.0, 0.0, 42.0, 74.0, 0.0, 0.0, 77.0, 60.0, 115.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 7.0, 45.0, 98.0, 48.0, 40.0, 17.0, 6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 158.0, 17.0, 124.0, 12.0, 122.0, 108.0, 53.0, 0.0, 10.0, 0.0, 2.0, 48.0, 0.0, 104.0, 13.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 0.0, 82.0, 102.0, 0.0, 0.0, 0.0, 59.0, 13.0, 15.0, 16.0, 77.0, 98.0, 90.0, 0.0, 0.0, 4.0, 6.0, 118.0, 19.0, 48.0, 34.0, 51.0, 71.0, 18.0, 37.0, 0.0, 0.0, 37.0, 17.0, 18.0, 0.0, 0.0, 0.0, 9.0, 13.0, 88.0, 0.0, 67.0, 13.0, 82.0, 0.0, 0.0, 79.0, 0.0, 4.0, 121.0, 142.0, 28.0, 22.0, 25.0, 55.0, 36.0, 22.0, 127.0, 104.0, 0.0, 0.0, 63.0, 79.0, 14.0, 9.0, 89.0, 0.0, 85.0, 83.0, 111.0, 75.0, 44.0, 22.0, 54.0, 6.0, 0.0, 11.0, 0.0, 16.0, 0.0, 0.0, 121.0, 109.0, 156.0, 58.0, 19.0, 27.0, 82.0, 51.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 84.0, 133.0, 0.0, 0.0, 0.0, 0.0, 61.0, 168.0, 0.0, 0.0, 71.0, 91.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 163.0, 0.0, 0.0, 0.0, 0.0, 50.0, 86.0, 50.0, 7.0, 22.0, 25.0, 39.0, 16.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6787774704933098, "mean_inference_ms": 1.7695146202476462, "mean_action_processing_ms": 0.28615265382278526, "mean_env_wait_ms": 0.2433511592216061, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009778261184692383, "StateBufferConnector_ms": 0.005003929138183594, "ViewRequirementAgentConnector_ms": 0.14191603660583496}, "num_episodes": 23, "episode_return_max": 287.4999999999998, "episode_return_min": -122.70000000000059, "episode_return_mean": 101.44699999999973, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 375.5650247871516, "num_env_steps_trained_throughput_per_sec": 375.5650247871516, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 11237.309, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11237.257, "sample_time_ms": 1889.652, "learn_time_ms": 9330.204, "learn_throughput": 428.715, "synch_weights_time_ms": 13.452}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "04dec_00002", "date": "2024-08-13_16-36-34", "timestamp": 1723581394, "time_this_iter_s": 10.70121693611145, "time_total_s": 827.5227422714233, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3587ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 827.5227422714233, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 46.15625, "ram_util_percent": 86.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0171056618135441, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 5.196032071996618, "policy_loss": -0.0034598655462826765, "vf_loss": 5.199075426121868, "vf_explained_var": 0.0022720009876937464, "kl": 0.008775787008441614, "entropy": 0.7294030821827985, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.77017769050346, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 7.764103445678792, "policy_loss": -0.001384102664740076, "vf_loss": 7.764949383306756, "vf_explained_var": 0.046173571341882935, "kl": 0.01007923082063311, "entropy": 0.7888010397474602, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 280.9999999999996, "episode_reward_min": -441.19999999999965, "episode_reward_mean": 91.89099999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -359.7999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.39999999999984, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 7.9654999999999525, "predator_policy": 37.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 107.49999999999972, 40.0000000000003, 114.49999999999943, -84.6000000000005, 174.0999999999999, 144.09999999999926, 177.29999999999916, 280.9999999999996, -34.89999999999997, -52.300000000000416, 122.69999999999989, 80.69999999999999, 136.09999999999943, 226.19999999999973, 21.600000000000072, 175.9999999999995, 40.0000000000003, 125.89999999999961, 142.59999999999934, -27.099999999999973, 125.49999999999922, 66.90000000000003, 158.89999999999893, 119.79999999999966, 63.90000000000003, 257.7999999999995, 114.7999999999994, -52.49999999999985, 110.29999999999917, -84.90000000000003, 32.600000000000044, 94.89999999999867, 30.100000000000286, 204.69999999999942, 115.59999999999948, 163.99999999999915, -0.9999999999998167, 152.10000000000008, 140.59999999999982, -17.80000000000002, 35.600000000000236, 12.599999999999964, 183.5999999999999, 104.6999999999998, 119.29999999999964, 171.09999999999985, 272.2000000000005, 136.99999999999974, 187.4999999999997, 133.79999999999976, 141.9999999999999, 167.79999999999998, 174.3999999999998, 81.10000000000008, 180.8999999999988, 151.69999999999962, 152.49999999999886, -33.599999999999994, -35.79999999999993, 85.69999999999993, 6.800000000000124, 139.6999999999991, 162.29999999999956, 113.79999999999927, 7.700000000000033, 138.99999999999915, 40.0000000000003, -4.9000000000000075, 138.99999999999923, 43.300000000000175, 237.99999999999915, 40.0000000000003, 182.7999999999992, -122.70000000000059, 277.5999999999998, 40.0000000000003, -56.79999999999979, 198.69999999999993, 118.49999999999973, 30.800000000000033, 105.69999999999865, -108.40000000000003, 63.9000000000001, 166.30000000000004, 183.0999999999992, 147.49999999999923, 172.09999999999977, 157.89999999999958, 164.1999999999993, -441.19999999999965, -62.599999999999746, 163.89999999999998, 167.09999999999926, -32.19999999999998, 98.99999999999983, 6.499999999999991, 27.70000000000008, 109.20000000000005, 194.00000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 42.500000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000002, 20.000000000000014, -250.60000000000005, 20.000000000000014, 59.00000000000003, 58.099999999999994, 20.000000000000014, 118.09999999999984, 159.49999999999986, 15.799999999999963, 136.09999999999994, 143.8999999999997, 71.30000000000008, -281.2, 20.000000000000014, -208.29999999999998, 125.59999999999988, -232.89999999999998, 7.699999999999996, 20.000000000000014, 106.09999999999985, 20.000000000000014, 128.29999999999978, 47.900000000000006, -90.69999999999997, 8.300000000000011, 117.19999999999999, 45.80000000000014, 20.000000000000014, 20.000000000000014, 89.89999999999995, 20.000000000000014, 115.6999999999999, 17.899999999999988, 98.29999999999978, -309.4, 20.000000000000014, 105.49999999999984, -12.1, 20.000000000000014, 86.59999999999974, 44.300000000000146, 134.5999999999998, -107.80000000000001, -153.10000000000016, 29.00000000000001, 131.59999999999974, 126.19999999999997, 9.499999999999964, 95.2999999999999, -216.7, 27.200000000000003, 115.39999999999958, -87.10000000000021, -227.79999999999993, 20.90000000000003, 20.000000000000014, -42.399999999999956, 74.89999999999951, 20.000000000000014, -19.8999999999998, -3.9999999999999014, 91.09999999999995, 95.59999999999977, 20.000000000000014, 95.59999999999982, 71.90000000000003, 70.09999999999991, -109.00000000000017, 20.000000000000014, 146.00000000000006, -73.9, 113.8999999999998, -55.30000000000003, -29.50000000000002, -67.30000000000001, 17.899999999999988, 13.699999999999967, 13.09999999999997, -263.5, -15.100000000000367, 148.7, 4.700000000000022, 20.000000000000014, 41.300000000000026, 20.000000000000014, 64.4, -124.30000000000001, 140.59999999999982, 131.5999999999996, 86.59999999999988, -91.6000000000002, 41.90000000000002, 122.5999999999998, 148.0999999999998, -103.30000000000021, 111.19999999999987, -137.20000000000002, 82.10000000000002, -100.30000000000001, 50.90000000000003, 57.50000000000005, 20.000000000000014, 1.0999999999999979, 131.59999999999988, 38.3000000000002, 7.399999999999965, 128.3, 132.4999999999996, 20.000000000000014, -118.90000000000003, -144.70000000000002, -359.7999999999999, 109.99999999999979, 3.1999999999999615, 36.49999999999999, -93.70000000000002, -32.49999999999975, 20.000000000000014, 118.69999999999969, 9.499999999999964, 147.79999999999998, 20.000000000000014, 93.79999999999973, 83.60000000000002, -292.90000000000003, 20.000000000000014, 118.99999999999974, 20.000000000000014, 20.000000000000014, 116.29999999999954, -350.20000000000005, 118.99999999999983, 20.000000000000014, 11.599999999999964, -130.3, 129.7999999999999, 108.19999999999979, 20.000000000000014, 20.000000000000014, 7.399999999999965, 169.39999999999984, -327.70000000000005, 20.000000000000014, 144.19999999999987, 133.39999999999986, 20.000000000000014, 20.000000000000014, 29.900000000000183, -222.70000000000002, 124.39999999999992, 17.29999999999999, 51.50000000000001, 20.000000000000014, -44.19999999999989, 20.000000000000014, 20.000000000000014, 85.69999999999942, -118.00000000000003, -168.40000000000003, 20.000000000000014, -36.10000000000014, 2.299999999999997, 107.0, 20.000000000000014, 163.09999999999988, 84.49999999999994, 20.000000000000014, 123.49999999999969, -6.399999999999949, 20.000000000000014, 137.90000000000003, 105.2, 20.000000000000014, -323.79999999999984, -300.4, 20.000000000000014, -271.6, 145.09999999999988, -107.20000000000002, 139.09999999999985, 20.000000000000014, 20.000000000000014, -326.20000000000005, 7.399999999999965, 62.6, 151.4, -322.9, -118.3000000000001, 20.000000000000014, 168.50000000000003, -298.3, -90.40000000000003, 148.39999999999998], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 7.0, 45.0, 98.0, 48.0, 40.0, 17.0, 6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 158.0, 17.0, 124.0, 12.0, 122.0, 108.0, 53.0, 0.0, 10.0, 0.0, 2.0, 48.0, 0.0, 104.0, 13.0, 0.0, 0.0, 0.0, 0.0, 16.0, 9.0, 0.0, 82.0, 102.0, 0.0, 0.0, 0.0, 59.0, 13.0, 15.0, 16.0, 77.0, 98.0, 90.0, 0.0, 0.0, 4.0, 6.0, 118.0, 19.0, 48.0, 34.0, 51.0, 71.0, 18.0, 37.0, 0.0, 0.0, 37.0, 17.0, 18.0, 0.0, 0.0, 0.0, 9.0, 13.0, 88.0, 0.0, 67.0, 13.0, 82.0, 0.0, 0.0, 79.0, 0.0, 4.0, 121.0, 142.0, 28.0, 22.0, 25.0, 55.0, 36.0, 22.0, 127.0, 104.0, 0.0, 0.0, 63.0, 79.0, 14.0, 9.0, 89.0, 0.0, 85.0, 83.0, 111.0, 75.0, 44.0, 22.0, 54.0, 6.0, 0.0, 11.0, 0.0, 16.0, 0.0, 0.0, 121.0, 109.0, 156.0, 58.0, 19.0, 27.0, 82.0, 51.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 84.0, 133.0, 0.0, 0.0, 0.0, 0.0, 61.0, 168.0, 0.0, 0.0, 71.0, 91.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 163.0, 0.0, 0.0, 0.0, 0.0, 50.0, 86.0, 50.0, 7.0, 22.0, 25.0, 39.0, 16.0, 0.0, 0.0, 47.0, 131.0, 26.0, 54.0, 0.0, 57.0, 0.0, 0.0, 15.0, 28.0, 27.0, 28.0, 0.0, 0.0, 28.0, 11.0, 183.0, 0.0, 117.0, 72.0, 73.0, 53.0, 0.0, 8.0, 121.0, 153.0, 29.0, 0.0, 167.0, 11.0, 34.0, 92.0, 118.0, 121.0, 64.0, 72.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6791275377639795, "mean_inference_ms": 1.7712251945991062, "mean_action_processing_ms": 0.2861322796973596, "mean_env_wait_ms": 0.24352130394151494, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010567903518676758, "StateBufferConnector_ms": 0.005127429962158203, "ViewRequirementAgentConnector_ms": 0.14350616931915283}, "num_episodes": 18, "episode_return_max": 280.9999999999996, "episode_return_min": -441.19999999999965, "episode_return_mean": 91.89099999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.28241136549644, "num_env_steps_trained_throughput_per_sec": 361.28241136549644, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 10967.699, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10967.646, "sample_time_ms": 1760.029, "learn_time_ms": 9190.69, "learn_throughput": 435.223, "synch_weights_time_ms": 13.415}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "04dec_00002", "date": "2024-08-13_16-36-46", "timestamp": 1723581406, "time_this_iter_s": 11.092465162277222, "time_total_s": 838.6152074337006, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a7280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 838.6152074337006, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 49.98125, "ram_util_percent": 85.79375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1679219981980702, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 2.6371309778046985, "policy_loss": -0.0027919607414376166, "vf_loss": 2.639415955354297, "vf_explained_var": 0.006137066543417633, "kl": 0.010682090948605017, "entropy": 0.7138417364743651, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.889272264071874, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 8.121486460973346, "policy_loss": -0.0007481299845807294, "vf_loss": 8.121889276605435, "vf_explained_var": 0.3820211165796512, "kl": 0.006467040875417988, "entropy": 0.7685687982216083, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 277.5999999999998, "episode_reward_min": -441.19999999999965, "episode_reward_mean": 94.76299999999968, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -359.7999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.39999999999984, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 10.926499999999942, "predator_policy": 36.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [125.89999999999961, 142.59999999999934, -27.099999999999973, 125.49999999999922, 66.90000000000003, 158.89999999999893, 119.79999999999966, 63.90000000000003, 257.7999999999995, 114.7999999999994, -52.49999999999985, 110.29999999999917, -84.90000000000003, 32.600000000000044, 94.89999999999867, 30.100000000000286, 204.69999999999942, 115.59999999999948, 163.99999999999915, -0.9999999999998167, 152.10000000000008, 140.59999999999982, -17.80000000000002, 35.600000000000236, 12.599999999999964, 183.5999999999999, 104.6999999999998, 119.29999999999964, 171.09999999999985, 272.2000000000005, 136.99999999999974, 187.4999999999997, 133.79999999999976, 141.9999999999999, 167.79999999999998, 174.3999999999998, 81.10000000000008, 180.8999999999988, 151.69999999999962, 152.49999999999886, -33.599999999999994, -35.79999999999993, 85.69999999999993, 6.800000000000124, 139.6999999999991, 162.29999999999956, 113.79999999999927, 7.700000000000033, 138.99999999999915, 40.0000000000003, -4.9000000000000075, 138.99999999999923, 43.300000000000175, 237.99999999999915, 40.0000000000003, 182.7999999999992, -122.70000000000059, 277.5999999999998, 40.0000000000003, -56.79999999999979, 198.69999999999993, 118.49999999999973, 30.800000000000033, 105.69999999999865, -108.40000000000003, 63.9000000000001, 166.30000000000004, 183.0999999999992, 147.49999999999923, 172.09999999999977, 157.89999999999958, 164.1999999999993, -441.19999999999965, -62.599999999999746, 163.89999999999998, 167.09999999999926, -32.19999999999998, 98.99999999999983, 6.499999999999991, 27.70000000000008, 109.20000000000005, 194.00000000000003, 16.799999999999926, 38.90000000000028, 175.29999999999922, 100.99999999999898, 40.0000000000003, 126.69999999999945, 116.49999999999936, 122.09999999999927, 228.4999999999994, 145.39999999999915, 206.69999999999902, 69.40000000000012, 154.49999999999915, 236.7999999999995, -275.5, 190.59999999999943, 135.0999999999992, 168.39999999999964], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [89.89999999999995, 20.000000000000014, 115.6999999999999, 17.899999999999988, 98.29999999999978, -309.4, 20.000000000000014, 105.49999999999984, -12.1, 20.000000000000014, 86.59999999999974, 44.300000000000146, 134.5999999999998, -107.80000000000001, -153.10000000000016, 29.00000000000001, 131.59999999999974, 126.19999999999997, 9.499999999999964, 95.2999999999999, -216.7, 27.200000000000003, 115.39999999999958, -87.10000000000021, -227.79999999999993, 20.90000000000003, 20.000000000000014, -42.399999999999956, 74.89999999999951, 20.000000000000014, -19.8999999999998, -3.9999999999999014, 91.09999999999995, 95.59999999999977, 20.000000000000014, 95.59999999999982, 71.90000000000003, 70.09999999999991, -109.00000000000017, 20.000000000000014, 146.00000000000006, -73.9, 113.8999999999998, -55.30000000000003, -29.50000000000002, -67.30000000000001, 17.899999999999988, 13.699999999999967, 13.09999999999997, -263.5, -15.100000000000367, 148.7, 4.700000000000022, 20.000000000000014, 41.300000000000026, 20.000000000000014, 64.4, -124.30000000000001, 140.59999999999982, 131.5999999999996, 86.59999999999988, -91.6000000000002, 41.90000000000002, 122.5999999999998, 148.0999999999998, -103.30000000000021, 111.19999999999987, -137.20000000000002, 82.10000000000002, -100.30000000000001, 50.90000000000003, 57.50000000000005, 20.000000000000014, 1.0999999999999979, 131.59999999999988, 38.3000000000002, 7.399999999999965, 128.3, 132.4999999999996, 20.000000000000014, -118.90000000000003, -144.70000000000002, -359.7999999999999, 109.99999999999979, 3.1999999999999615, 36.49999999999999, -93.70000000000002, -32.49999999999975, 20.000000000000014, 118.69999999999969, 9.499999999999964, 147.79999999999998, 20.000000000000014, 93.79999999999973, 83.60000000000002, -292.90000000000003, 20.000000000000014, 118.99999999999974, 20.000000000000014, 20.000000000000014, 116.29999999999954, -350.20000000000005, 118.99999999999983, 20.000000000000014, 11.599999999999964, -130.3, 129.7999999999999, 108.19999999999979, 20.000000000000014, 20.000000000000014, 7.399999999999965, 169.39999999999984, -327.70000000000005, 20.000000000000014, 144.19999999999987, 133.39999999999986, 20.000000000000014, 20.000000000000014, 29.900000000000183, -222.70000000000002, 124.39999999999992, 17.29999999999999, 51.50000000000001, 20.000000000000014, -44.19999999999989, 20.000000000000014, 20.000000000000014, 85.69999999999942, -118.00000000000003, -168.40000000000003, 20.000000000000014, -36.10000000000014, 2.299999999999997, 107.0, 20.000000000000014, 163.09999999999988, 84.49999999999994, 20.000000000000014, 123.49999999999969, -6.399999999999949, 20.000000000000014, 137.90000000000003, 105.2, 20.000000000000014, -323.79999999999984, -300.4, 20.000000000000014, -271.6, 145.09999999999988, -107.20000000000002, 139.09999999999985, 20.000000000000014, 20.000000000000014, -326.20000000000005, 7.399999999999965, 62.6, 151.4, -322.9, -118.3000000000001, 20.000000000000014, 168.50000000000003, -298.3, -90.40000000000003, 148.39999999999998, -140.20000000000007, 20.000000000000014, 17.899999999999988, 20.000000000000014, 96.4999999999994, 15.80000000000001, 47.90000000000019, 34.10000000000013, 20.000000000000014, 20.000000000000014, 32.300000000000225, 61.40000000000007, 90.49999999999986, -0.9999999999999846, 85.09999999999997, 20.000000000000014, 67.40000000000003, 127.09999999999957, 20.000000000000014, 121.39999999999976, 94.69999999999945, 103.99999999999963, 26.300000000000114, -52.89999999999999, 20.000000000000014, 129.4999999999999, 138.79999999999973, 56.00000000000003, -220.00000000000009, -230.50000000000014, 112.69999999999985, 14.900000000000007, 106.09999999999988, 20.000000000000014, 136.09999999999977, -9.700000000000262], "policy_predator_policy_reward": [0.0, 16.0, 9.0, 0.0, 82.0, 102.0, 0.0, 0.0, 0.0, 59.0, 13.0, 15.0, 16.0, 77.0, 98.0, 90.0, 0.0, 0.0, 4.0, 6.0, 118.0, 19.0, 48.0, 34.0, 51.0, 71.0, 18.0, 37.0, 0.0, 0.0, 37.0, 17.0, 18.0, 0.0, 0.0, 0.0, 9.0, 13.0, 88.0, 0.0, 67.0, 13.0, 82.0, 0.0, 0.0, 79.0, 0.0, 4.0, 121.0, 142.0, 28.0, 22.0, 25.0, 55.0, 36.0, 22.0, 127.0, 104.0, 0.0, 0.0, 63.0, 79.0, 14.0, 9.0, 89.0, 0.0, 85.0, 83.0, 111.0, 75.0, 44.0, 22.0, 54.0, 6.0, 0.0, 11.0, 0.0, 16.0, 0.0, 0.0, 121.0, 109.0, 156.0, 58.0, 19.0, 27.0, 82.0, 51.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 84.0, 133.0, 0.0, 0.0, 0.0, 0.0, 61.0, 168.0, 0.0, 0.0, 71.0, 91.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 163.0, 0.0, 0.0, 0.0, 0.0, 50.0, 86.0, 50.0, 7.0, 22.0, 25.0, 39.0, 16.0, 0.0, 0.0, 47.0, 131.0, 26.0, 54.0, 0.0, 57.0, 0.0, 0.0, 15.0, 28.0, 27.0, 28.0, 0.0, 0.0, 28.0, 11.0, 183.0, 0.0, 117.0, 72.0, 73.0, 53.0, 0.0, 8.0, 121.0, 153.0, 29.0, 0.0, 167.0, 11.0, 34.0, 92.0, 118.0, 121.0, 64.0, 72.0, 63.0, 74.0, 0.0, 1.0, 49.0, 14.0, 19.0, 0.0, 0.0, 0.0, 21.0, 12.0, 12.0, 15.0, 17.0, 0.0, 0.0, 34.0, 0.0, 4.0, 0.0, 8.0, 51.0, 45.0, 2.0, 3.0, 19.0, 23.0, 148.0, 27.0, 27.0, 36.0, 7.0, 2.0, 37.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6797672585984021, "mean_inference_ms": 1.7735201190456849, "mean_action_processing_ms": 0.28623566455005645, "mean_env_wait_ms": 0.2437234359223286, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01582956314086914, "StateBufferConnector_ms": 0.0051811933517456055, "ViewRequirementAgentConnector_ms": 0.1490340232849121}, "num_episodes": 18, "episode_return_max": 277.5999999999998, "episode_return_min": -441.19999999999965, "episode_return_mean": 94.76299999999968, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 367.133957528157, "num_env_steps_trained_throughput_per_sec": 367.133957528157, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 10889.084, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10889.032, "sample_time_ms": 1675.455, "learn_time_ms": 9196.459, "learn_throughput": 434.95, "synch_weights_time_ms": 13.68}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "04dec_00002", "date": "2024-08-13_16-36-57", "timestamp": 1723581417, "time_this_iter_s": 10.955286979675293, "time_total_s": 849.5704944133759, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04528b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 849.5704944133759, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 48.55, "ram_util_percent": 81.28125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1948815043325778, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 3.685578753456237, "policy_loss": -0.003392211607750998, "vf_loss": 3.688561551533048, "vf_explained_var": -0.0032708318460555304, "kl": 0.00862618126241264, "entropy": 0.7705450402681159, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.689389466514033, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 7.439027876071829, "policy_loss": 0.0002322035847187397, "vf_loss": 7.438409995528125, "vf_explained_var": -0.04247715138884448, "kl": 0.007223526180055587, "entropy": 0.7961282453209004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 280.5999999999998, "episode_reward_min": -441.19999999999965, "episode_reward_mean": 95.52199999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -359.7999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.39999999999984, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": 10.825999999999947, "predator_policy": 36.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.80000000000002, 35.600000000000236, 12.599999999999964, 183.5999999999999, 104.6999999999998, 119.29999999999964, 171.09999999999985, 272.2000000000005, 136.99999999999974, 187.4999999999997, 133.79999999999976, 141.9999999999999, 167.79999999999998, 174.3999999999998, 81.10000000000008, 180.8999999999988, 151.69999999999962, 152.49999999999886, -33.599999999999994, -35.79999999999993, 85.69999999999993, 6.800000000000124, 139.6999999999991, 162.29999999999956, 113.79999999999927, 7.700000000000033, 138.99999999999915, 40.0000000000003, -4.9000000000000075, 138.99999999999923, 43.300000000000175, 237.99999999999915, 40.0000000000003, 182.7999999999992, -122.70000000000059, 277.5999999999998, 40.0000000000003, -56.79999999999979, 198.69999999999993, 118.49999999999973, 30.800000000000033, 105.69999999999865, -108.40000000000003, 63.9000000000001, 166.30000000000004, 183.0999999999992, 147.49999999999923, 172.09999999999977, 157.89999999999958, 164.1999999999993, -441.19999999999965, -62.599999999999746, 163.89999999999998, 167.09999999999926, -32.19999999999998, 98.99999999999983, 6.499999999999991, 27.70000000000008, 109.20000000000005, 194.00000000000003, 16.799999999999926, 38.90000000000028, 175.29999999999922, 100.99999999999898, 40.0000000000003, 126.69999999999945, 116.49999999999936, 122.09999999999927, 228.4999999999994, 145.39999999999915, 206.69999999999902, 69.40000000000012, 154.49999999999915, 236.7999999999995, -275.5, 190.59999999999943, 135.0999999999992, 168.39999999999964, 152.99999999999994, -2.6999999999997017, 40.0000000000003, 152.19999999999987, 163.09999999999985, 11.099999999999893, 211.89999999999893, 124.0, 82.7, 39.60000000000017, -376.6999999999997, 24.70000000000018, 195.99999999999903, 181.29999999999924, 146.59999999999985, 111.5999999999997, 140.0999999999994, -111.80000000000014, 230.99999999999977, 154.49999999999926, 178.59999999999906, 280.5999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.50000000000002, -67.30000000000001, 17.899999999999988, 13.699999999999967, 13.09999999999997, -263.5, -15.100000000000367, 148.7, 4.700000000000022, 20.000000000000014, 41.300000000000026, 20.000000000000014, 64.4, -124.30000000000001, 140.59999999999982, 131.5999999999996, 86.59999999999988, -91.6000000000002, 41.90000000000002, 122.5999999999998, 148.0999999999998, -103.30000000000021, 111.19999999999987, -137.20000000000002, 82.10000000000002, -100.30000000000001, 50.90000000000003, 57.50000000000005, 20.000000000000014, 1.0999999999999979, 131.59999999999988, 38.3000000000002, 7.399999999999965, 128.3, 132.4999999999996, 20.000000000000014, -118.90000000000003, -144.70000000000002, -359.7999999999999, 109.99999999999979, 3.1999999999999615, 36.49999999999999, -93.70000000000002, -32.49999999999975, 20.000000000000014, 118.69999999999969, 9.499999999999964, 147.79999999999998, 20.000000000000014, 93.79999999999973, 83.60000000000002, -292.90000000000003, 20.000000000000014, 118.99999999999974, 20.000000000000014, 20.000000000000014, 116.29999999999954, -350.20000000000005, 118.99999999999983, 20.000000000000014, 11.599999999999964, -130.3, 129.7999999999999, 108.19999999999979, 20.000000000000014, 20.000000000000014, 7.399999999999965, 169.39999999999984, -327.70000000000005, 20.000000000000014, 144.19999999999987, 133.39999999999986, 20.000000000000014, 20.000000000000014, 29.900000000000183, -222.70000000000002, 124.39999999999992, 17.29999999999999, 51.50000000000001, 20.000000000000014, -44.19999999999989, 20.000000000000014, 20.000000000000014, 85.69999999999942, -118.00000000000003, -168.40000000000003, 20.000000000000014, -36.10000000000014, 2.299999999999997, 107.0, 20.000000000000014, 163.09999999999988, 84.49999999999994, 20.000000000000014, 123.49999999999969, -6.399999999999949, 20.000000000000014, 137.90000000000003, 105.2, 20.000000000000014, -323.79999999999984, -300.4, 20.000000000000014, -271.6, 145.09999999999988, -107.20000000000002, 139.09999999999985, 20.000000000000014, 20.000000000000014, -326.20000000000005, 7.399999999999965, 62.6, 151.4, -322.9, -118.3000000000001, 20.000000000000014, 168.50000000000003, -298.3, -90.40000000000003, 148.39999999999998, -140.20000000000007, 20.000000000000014, 17.899999999999988, 20.000000000000014, 96.4999999999994, 15.80000000000001, 47.90000000000019, 34.10000000000013, 20.000000000000014, 20.000000000000014, 32.300000000000225, 61.40000000000007, 90.49999999999986, -0.9999999999999846, 85.09999999999997, 20.000000000000014, 67.40000000000003, 127.09999999999957, 20.000000000000014, 121.39999999999976, 94.69999999999945, 103.99999999999963, 26.300000000000114, -52.89999999999999, 20.000000000000014, 129.4999999999999, 138.79999999999973, 56.00000000000003, -220.00000000000009, -230.50000000000014, 112.69999999999985, 14.900000000000007, 106.09999999999988, 20.000000000000014, 136.09999999999977, -9.700000000000262, 151.99999999999994, -76.00000000000009, -9.399999999999855, -7.299999999999891, 20.000000000000014, 20.000000000000014, 77.9, -42.70000000000002, 139.6999999999997, -103.6000000000003, -204.1, 63.20000000000015, 151.39999999999975, 60.50000000000019, -52.30000000000002, 62.30000000000006, -1.300000000000113, 20.000000000000014, 20.000000000000014, -9.400000000000029, -330.1, -310.6000000000001, 20.000000000000014, -67.30000000000004, 78.49999999999943, 114.49999999999986, 20.000000000000014, 161.2999999999999, 15.200000000000077, 70.40000000000003, 70.70000000000002, 20.900000000000027, 20.000000000000014, 73.09999999999997, -285.4, -15.399999999999991, 142.9999999999999, 41.00000000000006, 20.000000000000014, 126.49999999999986, 117.19999999999987, 61.400000000000155, 128.89999999999992, 133.6999999999998], "policy_predator_policy_reward": [0.0, 79.0, 0.0, 4.0, 121.0, 142.0, 28.0, 22.0, 25.0, 55.0, 36.0, 22.0, 127.0, 104.0, 0.0, 0.0, 63.0, 79.0, 14.0, 9.0, 89.0, 0.0, 85.0, 83.0, 111.0, 75.0, 44.0, 22.0, 54.0, 6.0, 0.0, 11.0, 0.0, 16.0, 0.0, 0.0, 121.0, 109.0, 156.0, 58.0, 19.0, 27.0, 82.0, 51.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 84.0, 133.0, 0.0, 0.0, 0.0, 0.0, 61.0, 168.0, 0.0, 0.0, 71.0, 91.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 163.0, 0.0, 0.0, 0.0, 0.0, 50.0, 86.0, 50.0, 7.0, 22.0, 25.0, 39.0, 16.0, 0.0, 0.0, 47.0, 131.0, 26.0, 54.0, 0.0, 57.0, 0.0, 0.0, 15.0, 28.0, 27.0, 28.0, 0.0, 0.0, 28.0, 11.0, 183.0, 0.0, 117.0, 72.0, 73.0, 53.0, 0.0, 8.0, 121.0, 153.0, 29.0, 0.0, 167.0, 11.0, 34.0, 92.0, 118.0, 121.0, 64.0, 72.0, 63.0, 74.0, 0.0, 1.0, 49.0, 14.0, 19.0, 0.0, 0.0, 0.0, 21.0, 12.0, 12.0, 15.0, 17.0, 0.0, 0.0, 34.0, 0.0, 4.0, 0.0, 8.0, 51.0, 45.0, 2.0, 3.0, 19.0, 23.0, 148.0, 27.0, 27.0, 36.0, 7.0, 2.0, 37.0, 5.0, 73.0, 4.0, 14.0, 0.0, 0.0, 0.0, 57.0, 60.0, 54.0, 73.0, 121.0, 31.0, 0.0, 0.0, 63.0, 51.0, 32.0, 32.0, 5.0, 24.0, 193.0, 71.0, 50.0, 22.0, 0.0, 3.0, 0.0, 0.0, 43.0, 18.0, 0.0, 20.0, 21.0, 26.0, 36.0, 153.0, 33.0, 14.0, 0.0, 8.0, 0.0, 0.0, 4.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6803358180332717, "mean_inference_ms": 1.7752635094448468, "mean_action_processing_ms": 0.2863226126179472, "mean_env_wait_ms": 0.24387551081424075, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01676332950592041, "StateBufferConnector_ms": 0.00629878044128418, "ViewRequirementAgentConnector_ms": 0.15179038047790527}, "num_episodes": 22, "episode_return_max": 280.5999999999998, "episode_return_min": -441.19999999999965, "episode_return_mean": 95.52199999999974, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.4595997560281, "num_env_steps_trained_throughput_per_sec": 361.4595997560281, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 10880.321, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10880.268, "sample_time_ms": 1626.743, "learn_time_ms": 9232.891, "learn_throughput": 433.234, "synch_weights_time_ms": 16.067}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "04dec_00002", "date": "2024-08-13_16-37-08", "timestamp": 1723581428, "time_this_iter_s": 11.173413038253784, "time_total_s": 860.7439074516296, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04a73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 860.7439074516296, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 48.5, "ram_util_percent": 82.61875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0912362387965595, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 5.304485667697967, "policy_loss": -0.003603898311679365, "vf_loss": 5.307623141278666, "vf_explained_var": -0.0006138731247533566, "kl": 0.009827503013965457, "entropy": 0.7067972310951778, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 27.701191283723034, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 7.737107832974227, "policy_loss": 0.003930315339233155, "vf_loss": 7.73271026182427, "vf_explained_var": -0.2525025297409643, "kl": 0.008751119601677876, "entropy": 0.807362015947463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 280.5999999999998, "episode_reward_min": -492.9999999999998, "episode_reward_mean": 71.30699999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.39999999999984, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -4.436500000000044, "predator_policy": 40.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [162.29999999999956, 113.79999999999927, 7.700000000000033, 138.99999999999915, 40.0000000000003, -4.9000000000000075, 138.99999999999923, 43.300000000000175, 237.99999999999915, 40.0000000000003, 182.7999999999992, -122.70000000000059, 277.5999999999998, 40.0000000000003, -56.79999999999979, 198.69999999999993, 118.49999999999973, 30.800000000000033, 105.69999999999865, -108.40000000000003, 63.9000000000001, 166.30000000000004, 183.0999999999992, 147.49999999999923, 172.09999999999977, 157.89999999999958, 164.1999999999993, -441.19999999999965, -62.599999999999746, 163.89999999999998, 167.09999999999926, -32.19999999999998, 98.99999999999983, 6.499999999999991, 27.70000000000008, 109.20000000000005, 194.00000000000003, 16.799999999999926, 38.90000000000028, 175.29999999999922, 100.99999999999898, 40.0000000000003, 126.69999999999945, 116.49999999999936, 122.09999999999927, 228.4999999999994, 145.39999999999915, 206.69999999999902, 69.40000000000012, 154.49999999999915, 236.7999999999995, -275.5, 190.59999999999943, 135.0999999999992, 168.39999999999964, 152.99999999999994, -2.6999999999997017, 40.0000000000003, 152.19999999999987, 163.09999999999985, 11.099999999999893, 211.89999999999893, 124.0, 82.7, 39.60000000000017, -376.6999999999997, 24.70000000000018, 195.99999999999903, 181.29999999999924, 146.59999999999985, 111.5999999999997, 140.0999999999994, -111.80000000000014, 230.99999999999977, 154.49999999999926, 178.59999999999906, 280.5999999999998, -116.60000000000034, 16.90000000000005, 116.89999999999944, -17.69999999999996, -492.9999999999998, 40.0000000000003, 177.09999999999954, 40.0000000000003, -160.10000000000056, 20.59999999999998, 67.00000000000004, 193.89999999999915, -96.20000000000019, -76.2, 60.999999999999794, -293.20000000000005, 98.49999999999966, 141.09999999999908, 177.89999999999972, 25.40000000000017, 40.0000000000003, 75.60000000000001, 92.39999999999975], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999964, 147.79999999999998, 20.000000000000014, 93.79999999999973, 83.60000000000002, -292.90000000000003, 20.000000000000014, 118.99999999999974, 20.000000000000014, 20.000000000000014, 116.29999999999954, -350.20000000000005, 118.99999999999983, 20.000000000000014, 11.599999999999964, -130.3, 129.7999999999999, 108.19999999999979, 20.000000000000014, 20.000000000000014, 7.399999999999965, 169.39999999999984, -327.70000000000005, 20.000000000000014, 144.19999999999987, 133.39999999999986, 20.000000000000014, 20.000000000000014, 29.900000000000183, -222.70000000000002, 124.39999999999992, 17.29999999999999, 51.50000000000001, 20.000000000000014, -44.19999999999989, 20.000000000000014, 20.000000000000014, 85.69999999999942, -118.00000000000003, -168.40000000000003, 20.000000000000014, -36.10000000000014, 2.299999999999997, 107.0, 20.000000000000014, 163.09999999999988, 84.49999999999994, 20.000000000000014, 123.49999999999969, -6.399999999999949, 20.000000000000014, 137.90000000000003, 105.2, 20.000000000000014, -323.79999999999984, -300.4, 20.000000000000014, -271.6, 145.09999999999988, -107.20000000000002, 139.09999999999985, 20.000000000000014, 20.000000000000014, -326.20000000000005, 7.399999999999965, 62.6, 151.4, -322.9, -118.3000000000001, 20.000000000000014, 168.50000000000003, -298.3, -90.40000000000003, 148.39999999999998, -140.20000000000007, 20.000000000000014, 17.899999999999988, 20.000000000000014, 96.4999999999994, 15.80000000000001, 47.90000000000019, 34.10000000000013, 20.000000000000014, 20.000000000000014, 32.300000000000225, 61.40000000000007, 90.49999999999986, -0.9999999999999846, 85.09999999999997, 20.000000000000014, 67.40000000000003, 127.09999999999957, 20.000000000000014, 121.39999999999976, 94.69999999999945, 103.99999999999963, 26.300000000000114, -52.89999999999999, 20.000000000000014, 129.4999999999999, 138.79999999999973, 56.00000000000003, -220.00000000000009, -230.50000000000014, 112.69999999999985, 14.900000000000007, 106.09999999999988, 20.000000000000014, 136.09999999999977, -9.700000000000262, 151.99999999999994, -76.00000000000009, -9.399999999999855, -7.299999999999891, 20.000000000000014, 20.000000000000014, 77.9, -42.70000000000002, 139.6999999999997, -103.6000000000003, -204.1, 63.20000000000015, 151.39999999999975, 60.50000000000019, -52.30000000000002, 62.30000000000006, -1.300000000000113, 20.000000000000014, 20.000000000000014, -9.400000000000029, -330.1, -310.6000000000001, 20.000000000000014, -67.30000000000004, 78.49999999999943, 114.49999999999986, 20.000000000000014, 161.2999999999999, 15.200000000000077, 70.40000000000003, 70.70000000000002, 20.900000000000027, 20.000000000000014, 73.09999999999997, -285.4, -15.399999999999991, 142.9999999999999, 41.00000000000006, 20.000000000000014, 126.49999999999986, 117.19999999999987, 61.400000000000155, 128.89999999999992, 133.6999999999998, 20.000000000000014, -295.5999999999999, -43.29999999999982, -95.80000000000015, 7.399999999999967, 93.49999999999989, 17.000000000000092, -201.7000000000001, -332.1999999999998, -386.8, 20.000000000000014, 20.000000000000014, -2.499999999999973, 92.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -369.0999999999999, -6.099999999999985, -112.30000000000004, 20.000000000000014, 47.00000000000009, 130.69999999999987, 63.20000000000018, -278.20000000000005, 20.000000000000014, -230.2000000000001, 20.000000000000014, 95.29999999999984, -238.30000000000007, -400.0, -284.20000000000005, 20.000000000000014, 78.49999999999996, 20.000000000000014, 118.09999999999968, 154.09999999999985, -92.20000000000027, -331.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, -342.7, 131.29999999999984, 20.000000000000014, 64.40000000000009], "policy_predator_policy_reward": [5.0, 0.0, 0.0, 0.0, 84.0, 133.0, 0.0, 0.0, 0.0, 0.0, 61.0, 168.0, 0.0, 0.0, 71.0, 91.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 163.0, 0.0, 0.0, 0.0, 0.0, 50.0, 86.0, 50.0, 7.0, 22.0, 25.0, 39.0, 16.0, 0.0, 0.0, 47.0, 131.0, 26.0, 54.0, 0.0, 57.0, 0.0, 0.0, 15.0, 28.0, 27.0, 28.0, 0.0, 0.0, 28.0, 11.0, 183.0, 0.0, 117.0, 72.0, 73.0, 53.0, 0.0, 8.0, 121.0, 153.0, 29.0, 0.0, 167.0, 11.0, 34.0, 92.0, 118.0, 121.0, 64.0, 72.0, 63.0, 74.0, 0.0, 1.0, 49.0, 14.0, 19.0, 0.0, 0.0, 0.0, 21.0, 12.0, 12.0, 15.0, 17.0, 0.0, 0.0, 34.0, 0.0, 4.0, 0.0, 8.0, 51.0, 45.0, 2.0, 3.0, 19.0, 23.0, 148.0, 27.0, 27.0, 36.0, 7.0, 2.0, 37.0, 5.0, 73.0, 4.0, 14.0, 0.0, 0.0, 0.0, 57.0, 60.0, 54.0, 73.0, 121.0, 31.0, 0.0, 0.0, 63.0, 51.0, 32.0, 32.0, 5.0, 24.0, 193.0, 71.0, 50.0, 22.0, 0.0, 3.0, 0.0, 0.0, 43.0, 18.0, 0.0, 20.0, 21.0, 26.0, 36.0, 153.0, 33.0, 14.0, 0.0, 8.0, 0.0, 0.0, 4.0, 14.0, 126.0, 33.0, 47.0, 109.0, 10.0, 6.0, 86.0, 81.0, 198.0, 28.0, 0.0, 0.0, 45.0, 42.0, 0.0, 0.0, 182.0, 7.0, 80.0, 59.0, 0.0, 0.0, 0.0, 0.0, 100.0, 62.0, 87.0, 47.0, 72.0, 132.0, 193.0, 198.0, 0.0, 0.0, 3.0, 0.0, 70.0, 46.0, 168.0, 169.0, 0.0, 0.0, 140.0, 147.0, 8.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.682708296032557, "mean_inference_ms": 1.7831541829862605, "mean_action_processing_ms": 0.287377656336636, "mean_env_wait_ms": 0.24451747962069267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016979455947875977, "StateBufferConnector_ms": 0.007600903511047363, "ViewRequirementAgentConnector_ms": 0.16304826736450195}, "num_episodes": 23, "episode_return_max": 280.5999999999998, "episode_return_min": -492.9999999999998, "episode_return_mean": 71.30699999999973, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.9007869151672, "num_env_steps_trained_throughput_per_sec": 321.9007869151672, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 10869.235, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10869.18, "sample_time_ms": 1627.821, "learn_time_ms": 9220.848, "learn_throughput": 433.8, "synch_weights_time_ms": 16.02}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "04dec_00002", "date": "2024-08-13_16-37-20", "timestamp": 1723581440, "time_this_iter_s": 12.476655006408691, "time_total_s": 873.2205624580383, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04b9820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 873.2205624580383, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 48.92777777777778, "ram_util_percent": 85.50555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.023991710278723, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 4.956139015520691, "policy_loss": -0.0041916972891028435, "vf_loss": 4.959656100929099, "vf_explained_var": 0.002705421775737137, "kl": 0.014214123234990014, "entropy": 0.7351103452462998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.232397528962483, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 8.37776158221815, "policy_loss": -0.0016175165497722527, "vf_loss": 8.378984830240723, "vf_explained_var": -0.07094230528861757, "kl": 0.007383902014022045, "entropy": 0.7424168176121182, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 280.5999999999998, "episode_reward_min": -492.9999999999998, "episode_reward_mean": 64.14199999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.89999999999992, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -11.914000000000044, "predator_policy": 43.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [105.69999999999865, -108.40000000000003, 63.9000000000001, 166.30000000000004, 183.0999999999992, 147.49999999999923, 172.09999999999977, 157.89999999999958, 164.1999999999993, -441.19999999999965, -62.599999999999746, 163.89999999999998, 167.09999999999926, -32.19999999999998, 98.99999999999983, 6.499999999999991, 27.70000000000008, 109.20000000000005, 194.00000000000003, 16.799999999999926, 38.90000000000028, 175.29999999999922, 100.99999999999898, 40.0000000000003, 126.69999999999945, 116.49999999999936, 122.09999999999927, 228.4999999999994, 145.39999999999915, 206.69999999999902, 69.40000000000012, 154.49999999999915, 236.7999999999995, -275.5, 190.59999999999943, 135.0999999999992, 168.39999999999964, 152.99999999999994, -2.6999999999997017, 40.0000000000003, 152.19999999999987, 163.09999999999985, 11.099999999999893, 211.89999999999893, 124.0, 82.7, 39.60000000000017, -376.6999999999997, 24.70000000000018, 195.99999999999903, 181.29999999999924, 146.59999999999985, 111.5999999999997, 140.0999999999994, -111.80000000000014, 230.99999999999977, 154.49999999999926, 178.59999999999906, 280.5999999999998, -116.60000000000034, 16.90000000000005, 116.89999999999944, -17.69999999999996, -492.9999999999998, 40.0000000000003, 177.09999999999954, 40.0000000000003, -160.10000000000056, 20.59999999999998, 67.00000000000004, 193.89999999999915, -96.20000000000019, -76.2, 60.999999999999794, -293.20000000000005, 98.49999999999966, 141.09999999999908, 177.89999999999972, 25.40000000000017, 40.0000000000003, 75.60000000000001, 92.39999999999975, -22.899999999999856, 63.200000000000244, -11.399999999999766, 22.90000000000004, -14.999999999999886, 45.99999999999966, 135.2999999999994, -336.8, 79.59999999999991, 210.09999999999906, 273.0999999999997, 105.39999999999966, -81.7000000000001, -3.59999999999995, 170.99999999999926, -29.099999999999973, 224.49999999999932, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 85.69999999999942, -118.00000000000003, -168.40000000000003, 20.000000000000014, -36.10000000000014, 2.299999999999997, 107.0, 20.000000000000014, 163.09999999999988, 84.49999999999994, 20.000000000000014, 123.49999999999969, -6.399999999999949, 20.000000000000014, 137.90000000000003, 105.2, 20.000000000000014, -323.79999999999984, -300.4, 20.000000000000014, -271.6, 145.09999999999988, -107.20000000000002, 139.09999999999985, 20.000000000000014, 20.000000000000014, -326.20000000000005, 7.399999999999965, 62.6, 151.4, -322.9, -118.3000000000001, 20.000000000000014, 168.50000000000003, -298.3, -90.40000000000003, 148.39999999999998, -140.20000000000007, 20.000000000000014, 17.899999999999988, 20.000000000000014, 96.4999999999994, 15.80000000000001, 47.90000000000019, 34.10000000000013, 20.000000000000014, 20.000000000000014, 32.300000000000225, 61.40000000000007, 90.49999999999986, -0.9999999999999846, 85.09999999999997, 20.000000000000014, 67.40000000000003, 127.09999999999957, 20.000000000000014, 121.39999999999976, 94.69999999999945, 103.99999999999963, 26.300000000000114, -52.89999999999999, 20.000000000000014, 129.4999999999999, 138.79999999999973, 56.00000000000003, -220.00000000000009, -230.50000000000014, 112.69999999999985, 14.900000000000007, 106.09999999999988, 20.000000000000014, 136.09999999999977, -9.700000000000262, 151.99999999999994, -76.00000000000009, -9.399999999999855, -7.299999999999891, 20.000000000000014, 20.000000000000014, 77.9, -42.70000000000002, 139.6999999999997, -103.6000000000003, -204.1, 63.20000000000015, 151.39999999999975, 60.50000000000019, -52.30000000000002, 62.30000000000006, -1.300000000000113, 20.000000000000014, 20.000000000000014, -9.400000000000029, -330.1, -310.6000000000001, 20.000000000000014, -67.30000000000004, 78.49999999999943, 114.49999999999986, 20.000000000000014, 161.2999999999999, 15.200000000000077, 70.40000000000003, 70.70000000000002, 20.900000000000027, 20.000000000000014, 73.09999999999997, -285.4, -15.399999999999991, 142.9999999999999, 41.00000000000006, 20.000000000000014, 126.49999999999986, 117.19999999999987, 61.400000000000155, 128.89999999999992, 133.6999999999998, 20.000000000000014, -295.5999999999999, -43.29999999999982, -95.80000000000015, 7.399999999999967, 93.49999999999989, 17.000000000000092, -201.7000000000001, -332.1999999999998, -386.8, 20.000000000000014, 20.000000000000014, -2.499999999999973, 92.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -369.0999999999999, -6.099999999999985, -112.30000000000004, 20.000000000000014, 47.00000000000009, 130.69999999999987, 63.20000000000018, -278.20000000000005, 20.000000000000014, -230.2000000000001, 20.000000000000014, 95.29999999999984, -238.30000000000007, -400.0, -284.20000000000005, 20.000000000000014, 78.49999999999996, 20.000000000000014, 118.09999999999968, 154.09999999999985, -92.20000000000027, -331.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, -342.7, 131.29999999999984, 20.000000000000014, 64.40000000000009, -151.90000000000015, 20.000000000000014, 33.80000000000016, 7.399999999999986, -126.4, 20.000000000000014, 173.89999999999992, -385.0, -128.20000000000005, -29.79999999999994, -27.700000000000042, 13.699999999999964, 101.2999999999999, 20.000000000000014, -347.5, -235.3, 114.79999999999983, -278.1999999999998, 132.7999999999997, 68.29999999999986, 136.09999999999982, 136.99999999999983, -126.10000000000011, 132.49999999999974, -109.60000000000005, -153.10000000000002, 132.49999999999986, -300.0999999999999, 74.29999999999977, 58.70000000000008, -5.1999999999999265, -244.90000000000006, 101.89999999999975, 122.59999999999972, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 47.0, 131.0, 26.0, 54.0, 0.0, 57.0, 0.0, 0.0, 15.0, 28.0, 27.0, 28.0, 0.0, 0.0, 28.0, 11.0, 183.0, 0.0, 117.0, 72.0, 73.0, 53.0, 0.0, 8.0, 121.0, 153.0, 29.0, 0.0, 167.0, 11.0, 34.0, 92.0, 118.0, 121.0, 64.0, 72.0, 63.0, 74.0, 0.0, 1.0, 49.0, 14.0, 19.0, 0.0, 0.0, 0.0, 21.0, 12.0, 12.0, 15.0, 17.0, 0.0, 0.0, 34.0, 0.0, 4.0, 0.0, 8.0, 51.0, 45.0, 2.0, 3.0, 19.0, 23.0, 148.0, 27.0, 27.0, 36.0, 7.0, 2.0, 37.0, 5.0, 73.0, 4.0, 14.0, 0.0, 0.0, 0.0, 57.0, 60.0, 54.0, 73.0, 121.0, 31.0, 0.0, 0.0, 63.0, 51.0, 32.0, 32.0, 5.0, 24.0, 193.0, 71.0, 50.0, 22.0, 0.0, 3.0, 0.0, 0.0, 43.0, 18.0, 0.0, 20.0, 21.0, 26.0, 36.0, 153.0, 33.0, 14.0, 0.0, 8.0, 0.0, 0.0, 4.0, 14.0, 126.0, 33.0, 47.0, 109.0, 10.0, 6.0, 86.0, 81.0, 198.0, 28.0, 0.0, 0.0, 45.0, 42.0, 0.0, 0.0, 182.0, 7.0, 80.0, 59.0, 0.0, 0.0, 0.0, 0.0, 100.0, 62.0, 87.0, 47.0, 72.0, 132.0, 193.0, 198.0, 0.0, 0.0, 3.0, 0.0, 70.0, 46.0, 168.0, 169.0, 0.0, 0.0, 140.0, 147.0, 8.0, 0.0, 84.0, 25.0, 14.0, 8.0, 0.0, 95.0, 194.0, 40.0, 55.0, 88.0, 60.0, 0.0, 0.0, 14.0, 186.0, 60.0, 118.0, 125.0, 9.0, 0.0, 0.0, 0.0, 50.0, 49.0, 74.0, 107.0, 164.0, 0.0, 0.0, 38.0, 98.0, 123.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6834020654931205, "mean_inference_ms": 1.7881712811617467, "mean_action_processing_ms": 0.2873496252306913, "mean_env_wait_ms": 0.24513528009996563, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012817621231079102, "StateBufferConnector_ms": 0.005952119827270508, "ViewRequirementAgentConnector_ms": 0.14342308044433594}, "num_episodes": 18, "episode_return_max": 280.5999999999998, "episode_return_min": -492.9999999999998, "episode_return_mean": 64.14199999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.96826910942775, "num_env_steps_trained_throughput_per_sec": 363.96826910942775, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 10881.646, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10881.591, "sample_time_ms": 1601.23, "learn_time_ms": 9260.005, "learn_throughput": 431.965, "synch_weights_time_ms": 15.841}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "04dec_00002", "date": "2024-08-13_16-37-31", "timestamp": 1723581451, "time_this_iter_s": 11.049484968185425, "time_total_s": 884.2700474262238, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04bbca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 884.2700474262238, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 41.94666666666667, "ram_util_percent": 86.09333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.009680129019987, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 5.298741343034007, "policy_loss": -0.004738886144613384, "vf_loss": 5.302962345420999, "vf_explained_var": 0.0027696662794345272, "kl": 0.010912034986748049, "entropy": 0.7218580926536883, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.11336513723015, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 0.00010000000000000003, "total_loss": 7.179572186142049, "policy_loss": 0.0003169271777132674, "vf_loss": 7.179142443591325, "vf_explained_var": -0.1608537820281175, "kl": 0.002112771163623254, "entropy": 0.8066183957473311, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 290.89999999999975, "episode_reward_min": -492.9999999999998, "episode_reward_mean": 67.33799999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.89999999999992, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -13.42600000000005, "predator_policy": 47.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [194.00000000000003, 16.799999999999926, 38.90000000000028, 175.29999999999922, 100.99999999999898, 40.0000000000003, 126.69999999999945, 116.49999999999936, 122.09999999999927, 228.4999999999994, 145.39999999999915, 206.69999999999902, 69.40000000000012, 154.49999999999915, 236.7999999999995, -275.5, 190.59999999999943, 135.0999999999992, 168.39999999999964, 152.99999999999994, -2.6999999999997017, 40.0000000000003, 152.19999999999987, 163.09999999999985, 11.099999999999893, 211.89999999999893, 124.0, 82.7, 39.60000000000017, -376.6999999999997, 24.70000000000018, 195.99999999999903, 181.29999999999924, 146.59999999999985, 111.5999999999997, 140.0999999999994, -111.80000000000014, 230.99999999999977, 154.49999999999926, 178.59999999999906, 280.5999999999998, -116.60000000000034, 16.90000000000005, 116.89999999999944, -17.69999999999996, -492.9999999999998, 40.0000000000003, 177.09999999999954, 40.0000000000003, -160.10000000000056, 20.59999999999998, 67.00000000000004, 193.89999999999915, -96.20000000000019, -76.2, 60.999999999999794, -293.20000000000005, 98.49999999999966, 141.09999999999908, 177.89999999999972, 25.40000000000017, 40.0000000000003, 75.60000000000001, 92.39999999999975, -22.899999999999856, 63.200000000000244, -11.399999999999766, 22.90000000000004, -14.999999999999886, 45.99999999999966, 135.2999999999994, -336.8, 79.59999999999991, 210.09999999999906, 273.0999999999997, 105.39999999999966, -81.7000000000001, -3.59999999999995, 170.99999999999926, -29.099999999999973, 224.49999999999932, 40.0000000000003, 89.19999999999987, -314.2999999999999, 31.100000000000286, 171.7999999999993, 158.79999999999933, 33.90000000000026, 90.69999999999993, 135.69999999999973, 274.7999999999998, -224.70000000000002, 265.7999999999995, 18.60000000000023, 40.0000000000003, -9.49999999999985, -62.399999999999835, 143.69999999999925, 275.1999999999998, 290.89999999999975], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-90.40000000000003, 148.39999999999998, -140.20000000000007, 20.000000000000014, 17.899999999999988, 20.000000000000014, 96.4999999999994, 15.80000000000001, 47.90000000000019, 34.10000000000013, 20.000000000000014, 20.000000000000014, 32.300000000000225, 61.40000000000007, 90.49999999999986, -0.9999999999999846, 85.09999999999997, 20.000000000000014, 67.40000000000003, 127.09999999999957, 20.000000000000014, 121.39999999999976, 94.69999999999945, 103.99999999999963, 26.300000000000114, -52.89999999999999, 20.000000000000014, 129.4999999999999, 138.79999999999973, 56.00000000000003, -220.00000000000009, -230.50000000000014, 112.69999999999985, 14.900000000000007, 106.09999999999988, 20.000000000000014, 136.09999999999977, -9.700000000000262, 151.99999999999994, -76.00000000000009, -9.399999999999855, -7.299999999999891, 20.000000000000014, 20.000000000000014, 77.9, -42.70000000000002, 139.6999999999997, -103.6000000000003, -204.1, 63.20000000000015, 151.39999999999975, 60.50000000000019, -52.30000000000002, 62.30000000000006, -1.300000000000113, 20.000000000000014, 20.000000000000014, -9.400000000000029, -330.1, -310.6000000000001, 20.000000000000014, -67.30000000000004, 78.49999999999943, 114.49999999999986, 20.000000000000014, 161.2999999999999, 15.200000000000077, 70.40000000000003, 70.70000000000002, 20.900000000000027, 20.000000000000014, 73.09999999999997, -285.4, -15.399999999999991, 142.9999999999999, 41.00000000000006, 20.000000000000014, 126.49999999999986, 117.19999999999987, 61.400000000000155, 128.89999999999992, 133.6999999999998, 20.000000000000014, -295.5999999999999, -43.29999999999982, -95.80000000000015, 7.399999999999967, 93.49999999999989, 17.000000000000092, -201.7000000000001, -332.1999999999998, -386.8, 20.000000000000014, 20.000000000000014, -2.499999999999973, 92.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -369.0999999999999, -6.099999999999985, -112.30000000000004, 20.000000000000014, 47.00000000000009, 130.69999999999987, 63.20000000000018, -278.20000000000005, 20.000000000000014, -230.2000000000001, 20.000000000000014, 95.29999999999984, -238.30000000000007, -400.0, -284.20000000000005, 20.000000000000014, 78.49999999999996, 20.000000000000014, 118.09999999999968, 154.09999999999985, -92.20000000000027, -331.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, -342.7, 131.29999999999984, 20.000000000000014, 64.40000000000009, -151.90000000000015, 20.000000000000014, 33.80000000000016, 7.399999999999986, -126.4, 20.000000000000014, 173.89999999999992, -385.0, -128.20000000000005, -29.79999999999994, -27.700000000000042, 13.699999999999964, 101.2999999999999, 20.000000000000014, -347.5, -235.3, 114.79999999999983, -278.1999999999998, 132.7999999999997, 68.29999999999986, 136.09999999999982, 136.99999999999983, -126.10000000000011, 132.49999999999974, -109.60000000000005, -153.10000000000002, 132.49999999999986, -300.0999999999999, 74.29999999999977, 58.70000000000008, -5.1999999999999265, -244.90000000000006, 101.89999999999975, 122.59999999999972, 20.000000000000014, 20.000000000000014, 127.0999999999998, -268.9, -345.1, -314.19999999999993, -112.90000000000002, 20.000000000000014, 153.19999999999985, 11.599999999999971, 20.000000000000014, 138.7999999999999, -220.3, 3.1999999999999615, -223.29999999999998, 136.99999999999986, 164.8999999999998, -218.20000000000044, 132.79999999999993, 118.99999999999989, -227.8, -301.9, 131.8999999999999, 122.89999999999975, -267.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, -294.4, 17.899999999999988, 20.000000000000014, -258.4000000000001, 20.000000000000014, 115.69999999999979, 119.89999999999999, 134.29999999999993, 156.79999999999976, 109.09999999999995], "policy_predator_policy_reward": [64.0, 72.0, 63.0, 74.0, 0.0, 1.0, 49.0, 14.0, 19.0, 0.0, 0.0, 0.0, 21.0, 12.0, 12.0, 15.0, 17.0, 0.0, 0.0, 34.0, 0.0, 4.0, 0.0, 8.0, 51.0, 45.0, 2.0, 3.0, 19.0, 23.0, 148.0, 27.0, 27.0, 36.0, 7.0, 2.0, 37.0, 5.0, 73.0, 4.0, 14.0, 0.0, 0.0, 0.0, 57.0, 60.0, 54.0, 73.0, 121.0, 31.0, 0.0, 0.0, 63.0, 51.0, 32.0, 32.0, 5.0, 24.0, 193.0, 71.0, 50.0, 22.0, 0.0, 3.0, 0.0, 0.0, 43.0, 18.0, 0.0, 20.0, 21.0, 26.0, 36.0, 153.0, 33.0, 14.0, 0.0, 8.0, 0.0, 0.0, 4.0, 14.0, 126.0, 33.0, 47.0, 109.0, 10.0, 6.0, 86.0, 81.0, 198.0, 28.0, 0.0, 0.0, 45.0, 42.0, 0.0, 0.0, 182.0, 7.0, 80.0, 59.0, 0.0, 0.0, 0.0, 0.0, 100.0, 62.0, 87.0, 47.0, 72.0, 132.0, 193.0, 198.0, 0.0, 0.0, 3.0, 0.0, 70.0, 46.0, 168.0, 169.0, 0.0, 0.0, 140.0, 147.0, 8.0, 0.0, 84.0, 25.0, 14.0, 8.0, 0.0, 95.0, 194.0, 40.0, 55.0, 88.0, 60.0, 0.0, 0.0, 14.0, 186.0, 60.0, 118.0, 125.0, 9.0, 0.0, 0.0, 0.0, 50.0, 49.0, 74.0, 107.0, 164.0, 0.0, 0.0, 38.0, 98.0, 123.0, 0.0, 0.0, 0.0, 0.0, 97.0, 134.0, 162.0, 183.0, 86.0, 38.0, 2.0, 5.0, 0.0, 0.0, 136.0, 115.0, 92.0, 85.0, 97.0, 92.0, 18.0, 5.0, 168.0, 137.0, 0.0, 11.0, 121.0, 145.0, 0.0, 0.0, 118.0, 149.0, 97.0, 79.0, 0.0, 8.0, 0.0, 21.0, 4.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6848606641117924, "mean_inference_ms": 1.7949057881164956, "mean_action_processing_ms": 0.28784765915687915, "mean_env_wait_ms": 0.24581042141632362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011867523193359375, "StateBufferConnector_ms": 0.005807161331176758, "ViewRequirementAgentConnector_ms": 0.1349853277206421}, "num_episodes": 18, "episode_return_max": 290.89999999999975, "episode_return_min": -492.9999999999998, "episode_return_mean": 67.33799999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 230.0693206380549, "num_env_steps_trained_throughput_per_sec": 230.0693206380549, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 11579.739, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11579.682, "sample_time_ms": 1637.882, "learn_time_ms": 9919.662, "learn_throughput": 403.24, "synch_weights_time_ms": 17.435}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "04dec_00002", "date": "2024-08-13_16-37-49", "timestamp": 1723581469, "time_this_iter_s": 17.498711109161377, "time_total_s": 901.7687585353851, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04ccaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 901.7687585353851, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 77.684, "ram_util_percent": 85.72399999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.134074869483867, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 6.446598865620043, "policy_loss": -0.003256378664817444, "vf_loss": 6.449489587955374, "vf_explained_var": 0.0025540472338439297, "kl": 0.007704563963418777, "entropy": 0.7286158157088769, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.34303880488431, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 0.00010000000000000003, "total_loss": 7.938763157274357, "policy_loss": -0.004558138825768043, "vf_loss": 7.9428435257502965, "vf_explained_var": -0.26284810298334355, "kl": 0.01789610995219942, "entropy": 0.7495045777981875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 290.89999999999975, "episode_reward_min": -492.9999999999998, "episode_reward_mean": 45.46899999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -34.445500000000045, "predator_policy": 57.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [152.19999999999987, 163.09999999999985, 11.099999999999893, 211.89999999999893, 124.0, 82.7, 39.60000000000017, -376.6999999999997, 24.70000000000018, 195.99999999999903, 181.29999999999924, 146.59999999999985, 111.5999999999997, 140.0999999999994, -111.80000000000014, 230.99999999999977, 154.49999999999926, 178.59999999999906, 280.5999999999998, -116.60000000000034, 16.90000000000005, 116.89999999999944, -17.69999999999996, -492.9999999999998, 40.0000000000003, 177.09999999999954, 40.0000000000003, -160.10000000000056, 20.59999999999998, 67.00000000000004, 193.89999999999915, -96.20000000000019, -76.2, 60.999999999999794, -293.20000000000005, 98.49999999999966, 141.09999999999908, 177.89999999999972, 25.40000000000017, 40.0000000000003, 75.60000000000001, 92.39999999999975, -22.899999999999856, 63.200000000000244, -11.399999999999766, 22.90000000000004, -14.999999999999886, 45.99999999999966, 135.2999999999994, -336.8, 79.59999999999991, 210.09999999999906, 273.0999999999997, 105.39999999999966, -81.7000000000001, -3.59999999999995, 170.99999999999926, -29.099999999999973, 224.49999999999932, 40.0000000000003, 89.19999999999987, -314.2999999999999, 31.100000000000286, 171.7999999999993, 158.79999999999933, 33.90000000000026, 90.69999999999993, 135.69999999999973, 274.7999999999998, -224.70000000000002, 265.7999999999995, 18.60000000000023, 40.0000000000003, -9.49999999999985, -62.399999999999835, 143.69999999999925, 275.1999999999998, 290.89999999999975, 33.400000000000205, -153.40000000000057, -7.299999999999837, -9.799999999999946, 119.39999999999885, 129.7, -18.899999999999892, -121.59999999999992, -10.199999999999726, 89.1999999999997, -41.59999999999978, 61.1000000000001, -82.10000000000008, -331.90000000000003, 175.89999999999918, 274.49999999999994, 215.49999999999923, 56.49999999999978, -6.89999999999965, -202.90000000000003, -9.199999999999939, 35.199999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [77.9, -42.70000000000002, 139.6999999999997, -103.6000000000003, -204.1, 63.20000000000015, 151.39999999999975, 60.50000000000019, -52.30000000000002, 62.30000000000006, -1.300000000000113, 20.000000000000014, 20.000000000000014, -9.400000000000029, -330.1, -310.6000000000001, 20.000000000000014, -67.30000000000004, 78.49999999999943, 114.49999999999986, 20.000000000000014, 161.2999999999999, 15.200000000000077, 70.40000000000003, 70.70000000000002, 20.900000000000027, 20.000000000000014, 73.09999999999997, -285.4, -15.399999999999991, 142.9999999999999, 41.00000000000006, 20.000000000000014, 126.49999999999986, 117.19999999999987, 61.400000000000155, 128.89999999999992, 133.6999999999998, 20.000000000000014, -295.5999999999999, -43.29999999999982, -95.80000000000015, 7.399999999999967, 93.49999999999989, 17.000000000000092, -201.7000000000001, -332.1999999999998, -386.8, 20.000000000000014, 20.000000000000014, -2.499999999999973, 92.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -369.0999999999999, -6.099999999999985, -112.30000000000004, 20.000000000000014, 47.00000000000009, 130.69999999999987, 63.20000000000018, -278.20000000000005, 20.000000000000014, -230.2000000000001, 20.000000000000014, 95.29999999999984, -238.30000000000007, -400.0, -284.20000000000005, 20.000000000000014, 78.49999999999996, 20.000000000000014, 118.09999999999968, 154.09999999999985, -92.20000000000027, -331.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, -342.7, 131.29999999999984, 20.000000000000014, 64.40000000000009, -151.90000000000015, 20.000000000000014, 33.80000000000016, 7.399999999999986, -126.4, 20.000000000000014, 173.89999999999992, -385.0, -128.20000000000005, -29.79999999999994, -27.700000000000042, 13.699999999999964, 101.2999999999999, 20.000000000000014, -347.5, -235.3, 114.79999999999983, -278.1999999999998, 132.7999999999997, 68.29999999999986, 136.09999999999982, 136.99999999999983, -126.10000000000011, 132.49999999999974, -109.60000000000005, -153.10000000000002, 132.49999999999986, -300.0999999999999, 74.29999999999977, 58.70000000000008, -5.1999999999999265, -244.90000000000006, 101.89999999999975, 122.59999999999972, 20.000000000000014, 20.000000000000014, 127.0999999999998, -268.9, -345.1, -314.19999999999993, -112.90000000000002, 20.000000000000014, 153.19999999999985, 11.599999999999971, 20.000000000000014, 138.7999999999999, -220.3, 3.1999999999999615, -223.29999999999998, 136.99999999999986, 164.8999999999998, -218.20000000000044, 132.79999999999993, 118.99999999999989, -227.8, -301.9, 131.8999999999999, 122.89999999999975, -267.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, -294.4, 17.899999999999988, 20.000000000000014, -258.4000000000001, 20.000000000000014, 115.69999999999979, 119.89999999999999, 134.29999999999993, 156.79999999999976, 109.09999999999995, 20.000000000000014, 7.399999999999965, 20.000000000000014, -357.4, -11.499999999999833, -161.79999999999993, -80.80000000000013, 20.000000000000014, 91.3999999999995, 20.000000000000014, -281.8, 117.5, 48.499999999999964, -249.40000000000018, -231.4, -167.20000000000002, -101.20000000000036, 20.000000000000014, -155.5, 130.69999999999985, 20.000000000000014, -325.6, 137.59999999999997, -200.50000000000014, -0.9999999999999846, -321.1000000000001, -309.70000000000005, -362.2, 155.89999999999986, 20.000000000000014, 121.69999999999993, 114.79999999999998, 195.49999999999997, 20.000000000000014, -106.00000000000006, 78.49999999999946, -28.299999999999798, -37.599999999999824, -228.99999999999997, -232.90000000000003, 6.500000000000039, -231.69999999999996, 5.299999999999978, -12.099999999999817], "policy_predator_policy_reward": [57.0, 60.0, 54.0, 73.0, 121.0, 31.0, 0.0, 0.0, 63.0, 51.0, 32.0, 32.0, 5.0, 24.0, 193.0, 71.0, 50.0, 22.0, 0.0, 3.0, 0.0, 0.0, 43.0, 18.0, 0.0, 20.0, 21.0, 26.0, 36.0, 153.0, 33.0, 14.0, 0.0, 8.0, 0.0, 0.0, 4.0, 14.0, 126.0, 33.0, 47.0, 109.0, 10.0, 6.0, 86.0, 81.0, 198.0, 28.0, 0.0, 0.0, 45.0, 42.0, 0.0, 0.0, 182.0, 7.0, 80.0, 59.0, 0.0, 0.0, 0.0, 0.0, 100.0, 62.0, 87.0, 47.0, 72.0, 132.0, 193.0, 198.0, 0.0, 0.0, 3.0, 0.0, 70.0, 46.0, 168.0, 169.0, 0.0, 0.0, 140.0, 147.0, 8.0, 0.0, 84.0, 25.0, 14.0, 8.0, 0.0, 95.0, 194.0, 40.0, 55.0, 88.0, 60.0, 0.0, 0.0, 14.0, 186.0, 60.0, 118.0, 125.0, 9.0, 0.0, 0.0, 0.0, 50.0, 49.0, 74.0, 107.0, 164.0, 0.0, 0.0, 38.0, 98.0, 123.0, 0.0, 0.0, 0.0, 0.0, 97.0, 134.0, 162.0, 183.0, 86.0, 38.0, 2.0, 5.0, 0.0, 0.0, 136.0, 115.0, 92.0, 85.0, 97.0, 92.0, 18.0, 5.0, 168.0, 137.0, 0.0, 11.0, 121.0, 145.0, 0.0, 0.0, 118.0, 149.0, 97.0, 79.0, 0.0, 8.0, 0.0, 21.0, 4.0, 21.0, 6.0, 0.0, 0.0, 184.0, 70.0, 96.0, 3.0, 48.0, 8.0, 0.0, 140.0, 154.0, 108.0, 74.0, 146.0, 131.0, 0.0, 71.0, 0.0, 114.0, 138.0, 126.0, 104.0, 20.0, 131.0, 109.0, 178.0, 162.0, 0.0, 0.0, 12.0, 26.0, 0.0, 0.0, 84.0, 0.0, 16.0, 43.0, 109.0, 150.0, 137.0, 79.0, 22.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6881412474145614, "mean_inference_ms": 1.808129114253539, "mean_action_processing_ms": 0.2888395701819924, "mean_env_wait_ms": 0.24679870404642035, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005990028381347656, "StateBufferConnector_ms": 0.005722999572753906, "ViewRequirementAgentConnector_ms": 0.15386569499969482}, "num_episodes": 22, "episode_return_max": 290.89999999999975, "episode_return_min": -492.9999999999998, "episode_return_mean": 45.46899999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 238.0806392314038, "num_env_steps_trained_throughput_per_sec": 238.0806392314038, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 12233.452, "restore_workers_time_ms": 0.018, "training_step_time_ms": 12233.39, "sample_time_ms": 1784.347, "learn_time_ms": 10426.932, "learn_throughput": 383.622, "synch_weights_time_ms": 17.311}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "04dec_00002", "date": "2024-08-13_16-38-06", "timestamp": 1723581486, "time_this_iter_s": 16.94764995574951, "time_total_s": 918.7164084911346, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04b9700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 918.7164084911346, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 78.0625, "ram_util_percent": 85.575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1918377109542095, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 4.164065007557944, "policy_loss": -0.004040851013330871, "vf_loss": 4.167746054810822, "vf_explained_var": 0.008427475306092115, "kl": 0.007581224142389833, "entropy": 0.647475789085267, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.592262685015086, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": -0.0029911812229781714, "vf_loss": 6.823450272171586, "vf_explained_var": 0.10656714480389994, "kl": Infinity, "entropy": 0.7762734316328846, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 330.20000000000005, "episode_reward_min": -492.9999999999998, "episode_reward_mean": 46.31499999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -36.22750000000005, "predator_policy": 59.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [280.5999999999998, -116.60000000000034, 16.90000000000005, 116.89999999999944, -17.69999999999996, -492.9999999999998, 40.0000000000003, 177.09999999999954, 40.0000000000003, -160.10000000000056, 20.59999999999998, 67.00000000000004, 193.89999999999915, -96.20000000000019, -76.2, 60.999999999999794, -293.20000000000005, 98.49999999999966, 141.09999999999908, 177.89999999999972, 25.40000000000017, 40.0000000000003, 75.60000000000001, 92.39999999999975, -22.899999999999856, 63.200000000000244, -11.399999999999766, 22.90000000000004, -14.999999999999886, 45.99999999999966, 135.2999999999994, -336.8, 79.59999999999991, 210.09999999999906, 273.0999999999997, 105.39999999999966, -81.7000000000001, -3.59999999999995, 170.99999999999926, -29.099999999999973, 224.49999999999932, 40.0000000000003, 89.19999999999987, -314.2999999999999, 31.100000000000286, 171.7999999999993, 158.79999999999933, 33.90000000000026, 90.69999999999993, 135.69999999999973, 274.7999999999998, -224.70000000000002, 265.7999999999995, 18.60000000000023, 40.0000000000003, -9.49999999999985, -62.399999999999835, 143.69999999999925, 275.1999999999998, 290.89999999999975, 33.400000000000205, -153.40000000000057, -7.299999999999837, -9.799999999999946, 119.39999999999885, 129.7, -18.899999999999892, -121.59999999999992, -10.199999999999726, 89.1999999999997, -41.59999999999978, 61.1000000000001, -82.10000000000008, -331.90000000000003, 175.89999999999918, 274.49999999999994, 215.49999999999923, 56.49999999999978, -6.89999999999965, -202.90000000000003, -9.199999999999939, 35.199999999999996, 40.0000000000003, 214.59999999999923, 63.30000000000025, 187.39999999999992, 206.4999999999992, 330.20000000000005, 83.39999999999975, 205.99999999999932, -19.399999999999714, 131.39999999999955, 140.19999999999973, 33.400000000000205, -114.30000000000018, 112.89999999999975, 112.7999999999999, 53.90000000000001, -160.60000000000002, 123.39999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [128.89999999999992, 133.6999999999998, 20.000000000000014, -295.5999999999999, -43.29999999999982, -95.80000000000015, 7.399999999999967, 93.49999999999989, 17.000000000000092, -201.7000000000001, -332.1999999999998, -386.8, 20.000000000000014, 20.000000000000014, -2.499999999999973, 92.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -369.0999999999999, -6.099999999999985, -112.30000000000004, 20.000000000000014, 47.00000000000009, 130.69999999999987, 63.20000000000018, -278.20000000000005, 20.000000000000014, -230.2000000000001, 20.000000000000014, 95.29999999999984, -238.30000000000007, -400.0, -284.20000000000005, 20.000000000000014, 78.49999999999996, 20.000000000000014, 118.09999999999968, 154.09999999999985, -92.20000000000027, -331.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, -342.7, 131.29999999999984, 20.000000000000014, 64.40000000000009, -151.90000000000015, 20.000000000000014, 33.80000000000016, 7.399999999999986, -126.4, 20.000000000000014, 173.89999999999992, -385.0, -128.20000000000005, -29.79999999999994, -27.700000000000042, 13.699999999999964, 101.2999999999999, 20.000000000000014, -347.5, -235.3, 114.79999999999983, -278.1999999999998, 132.7999999999997, 68.29999999999986, 136.09999999999982, 136.99999999999983, -126.10000000000011, 132.49999999999974, -109.60000000000005, -153.10000000000002, 132.49999999999986, -300.0999999999999, 74.29999999999977, 58.70000000000008, -5.1999999999999265, -244.90000000000006, 101.89999999999975, 122.59999999999972, 20.000000000000014, 20.000000000000014, 127.0999999999998, -268.9, -345.1, -314.19999999999993, -112.90000000000002, 20.000000000000014, 153.19999999999985, 11.599999999999971, 20.000000000000014, 138.7999999999999, -220.3, 3.1999999999999615, -223.29999999999998, 136.99999999999986, 164.8999999999998, -218.20000000000044, 132.79999999999993, 118.99999999999989, -227.8, -301.9, 131.8999999999999, 122.89999999999975, -267.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, -294.4, 17.899999999999988, 20.000000000000014, -258.4000000000001, 20.000000000000014, 115.69999999999979, 119.89999999999999, 134.29999999999993, 156.79999999999976, 109.09999999999995, 20.000000000000014, 7.399999999999965, 20.000000000000014, -357.4, -11.499999999999833, -161.79999999999993, -80.80000000000013, 20.000000000000014, 91.3999999999995, 20.000000000000014, -281.8, 117.5, 48.499999999999964, -249.40000000000018, -231.4, -167.20000000000002, -101.20000000000036, 20.000000000000014, -155.5, 130.69999999999985, 20.000000000000014, -325.6, 137.59999999999997, -200.50000000000014, -0.9999999999999846, -321.1000000000001, -309.70000000000005, -362.2, 155.89999999999986, 20.000000000000014, 121.69999999999993, 114.79999999999998, 195.49999999999997, 20.000000000000014, -106.00000000000006, 78.49999999999946, -28.299999999999798, -37.599999999999824, -228.99999999999997, -232.90000000000003, 6.500000000000039, -231.69999999999996, 5.299999999999978, -12.099999999999817, 20.000000000000014, 20.000000000000014, 194.59999999999997, 20.000000000000014, -147.7, 20.000000000000014, -114.70000000000002, 181.1, 20.000000000000014, 186.49999999999994, 145.69999999999996, 159.5, 9.499999999999972, 2.899999999999955, 179.0, 20.000000000000014, 20.000000000000014, -93.40000000000053, 100.39999999999999, 20.000000000000014, -120.40000000000023, 185.59999999999994, 13.699999999999966, 13.699999999999964, 20.000000000000014, -295.29999999999995, 20.000000000000014, 71.89999999999998, 171.7999999999999, -337.0, -258.70000000000005, 146.59999999999997, -253.00000000000003, -205.6, 187.39999999999998, -334.0], "policy_predator_policy_reward": [4.0, 14.0, 126.0, 33.0, 47.0, 109.0, 10.0, 6.0, 86.0, 81.0, 198.0, 28.0, 0.0, 0.0, 45.0, 42.0, 0.0, 0.0, 182.0, 7.0, 80.0, 59.0, 0.0, 0.0, 0.0, 0.0, 100.0, 62.0, 87.0, 47.0, 72.0, 132.0, 193.0, 198.0, 0.0, 0.0, 3.0, 0.0, 70.0, 46.0, 168.0, 169.0, 0.0, 0.0, 140.0, 147.0, 8.0, 0.0, 84.0, 25.0, 14.0, 8.0, 0.0, 95.0, 194.0, 40.0, 55.0, 88.0, 60.0, 0.0, 0.0, 14.0, 186.0, 60.0, 118.0, 125.0, 9.0, 0.0, 0.0, 0.0, 50.0, 49.0, 74.0, 107.0, 164.0, 0.0, 0.0, 38.0, 98.0, 123.0, 0.0, 0.0, 0.0, 0.0, 97.0, 134.0, 162.0, 183.0, 86.0, 38.0, 2.0, 5.0, 0.0, 0.0, 136.0, 115.0, 92.0, 85.0, 97.0, 92.0, 18.0, 5.0, 168.0, 137.0, 0.0, 11.0, 121.0, 145.0, 0.0, 0.0, 118.0, 149.0, 97.0, 79.0, 0.0, 8.0, 0.0, 21.0, 4.0, 21.0, 6.0, 0.0, 0.0, 184.0, 70.0, 96.0, 3.0, 48.0, 8.0, 0.0, 140.0, 154.0, 108.0, 74.0, 146.0, 131.0, 0.0, 71.0, 0.0, 114.0, 138.0, 126.0, 104.0, 20.0, 131.0, 109.0, 178.0, 162.0, 0.0, 0.0, 12.0, 26.0, 0.0, 0.0, 84.0, 0.0, 16.0, 43.0, 109.0, 150.0, 137.0, 79.0, 22.0, 20.0, 0.0, 0.0, 0.0, 0.0, 111.0, 80.0, 69.0, 52.0, 0.0, 0.0, 0.0, 25.0, 38.0, 33.0, 7.0, 0.0, 0.0, 54.0, 11.0, 0.0, 9.0, 66.0, 0.0, 6.0, 126.0, 35.0, 15.0, 6.0, 146.0, 132.0, 14.0, 152.0, 158.0, 140.0, 99.0, 171.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6916785874200005, "mean_inference_ms": 1.8240489063659562, "mean_action_processing_ms": 0.29028193605657193, "mean_env_wait_ms": 0.24846447665394358, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0068863630294799805, "StateBufferConnector_ms": 0.00471186637878418, "ViewRequirementAgentConnector_ms": 0.17325735092163086}, "num_episodes": 18, "episode_return_max": 330.20000000000005, "episode_return_min": -492.9999999999998, "episode_return_mean": 46.31499999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 194.85058925604176, "num_env_steps_trained_throughput_per_sec": 194.85058925604176, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 13217.864, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13217.805, "sample_time_ms": 1886.255, "learn_time_ms": 11308.866, "learn_throughput": 353.705, "synch_weights_time_ms": 17.492}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "04dec_00002", "date": "2024-08-13_16-38-27", "timestamp": 1723581507, "time_this_iter_s": 20.69361710548401, "time_total_s": 939.4100255966187, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 939.4100255966187, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 91.56206896551723, "ram_util_percent": 85.33448275862068}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2773645030600684, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 3.464553684532327, "policy_loss": -0.0036259647926916837, "vf_loss": 3.467796670696723, "vf_explained_var": 0.02238030682795893, "kl": 0.008069531064049148, "entropy": 0.6811911379849469, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 28.753828368300482, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": 0.0022173687320439115, "vf_loss": 6.44845428365879, "vf_explained_var": 0.30796705534849217, "kl": Infinity, "entropy": 0.8375602881429056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 364.1, "episode_reward_min": -336.8, "episode_reward_mean": 71.25299999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -385.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -16.193500000000043, "predator_policy": 51.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [92.39999999999975, -22.899999999999856, 63.200000000000244, -11.399999999999766, 22.90000000000004, -14.999999999999886, 45.99999999999966, 135.2999999999994, -336.8, 79.59999999999991, 210.09999999999906, 273.0999999999997, 105.39999999999966, -81.7000000000001, -3.59999999999995, 170.99999999999926, -29.099999999999973, 224.49999999999932, 40.0000000000003, 89.19999999999987, -314.2999999999999, 31.100000000000286, 171.7999999999993, 158.79999999999933, 33.90000000000026, 90.69999999999993, 135.69999999999973, 274.7999999999998, -224.70000000000002, 265.7999999999995, 18.60000000000023, 40.0000000000003, -9.49999999999985, -62.399999999999835, 143.69999999999925, 275.1999999999998, 290.89999999999975, 33.400000000000205, -153.40000000000057, -7.299999999999837, -9.799999999999946, 119.39999999999885, 129.7, -18.899999999999892, -121.59999999999992, -10.199999999999726, 89.1999999999997, -41.59999999999978, 61.1000000000001, -82.10000000000008, -331.90000000000003, 175.89999999999918, 274.49999999999994, 215.49999999999923, 56.49999999999978, -6.89999999999965, -202.90000000000003, -9.199999999999939, 35.199999999999996, 40.0000000000003, 214.59999999999923, 63.30000000000025, 187.39999999999992, 206.4999999999992, 330.20000000000005, 83.39999999999975, 205.99999999999932, -19.399999999999714, 131.39999999999955, 140.19999999999973, 33.400000000000205, -114.30000000000018, 112.89999999999975, 112.7999999999999, 53.90000000000001, -160.60000000000002, 123.39999999999999, 40.0000000000003, 241.69999999999987, 125.09999999999974, 33.400000000000205, 210.09999999999926, 81.90000000000009, 39.800000000000296, -47.09999999999984, 39.100000000000115, 102.80000000000003, 137.19999999999996, 179.19999999999936, 217.89999999999998, 300.50000000000097, 51.600000000000136, 155.69999999999956, 192.7999999999994, 54.900000000000105, 99.90000000000009, 364.1, 139.3, 24.500000000000277, 28.90000000000017], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 64.40000000000009, -151.90000000000015, 20.000000000000014, 33.80000000000016, 7.399999999999986, -126.4, 20.000000000000014, 173.89999999999992, -385.0, -128.20000000000005, -29.79999999999994, -27.700000000000042, 13.699999999999964, 101.2999999999999, 20.000000000000014, -347.5, -235.3, 114.79999999999983, -278.1999999999998, 132.7999999999997, 68.29999999999986, 136.09999999999982, 136.99999999999983, -126.10000000000011, 132.49999999999974, -109.60000000000005, -153.10000000000002, 132.49999999999986, -300.0999999999999, 74.29999999999977, 58.70000000000008, -5.1999999999999265, -244.90000000000006, 101.89999999999975, 122.59999999999972, 20.000000000000014, 20.000000000000014, 127.0999999999998, -268.9, -345.1, -314.19999999999993, -112.90000000000002, 20.000000000000014, 153.19999999999985, 11.599999999999971, 20.000000000000014, 138.7999999999999, -220.3, 3.1999999999999615, -223.29999999999998, 136.99999999999986, 164.8999999999998, -218.20000000000044, 132.79999999999993, 118.99999999999989, -227.8, -301.9, 131.8999999999999, 122.89999999999975, -267.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, -294.4, 17.899999999999988, 20.000000000000014, -258.4000000000001, 20.000000000000014, 115.69999999999979, 119.89999999999999, 134.29999999999993, 156.79999999999976, 109.09999999999995, 20.000000000000014, 7.399999999999965, 20.000000000000014, -357.4, -11.499999999999833, -161.79999999999993, -80.80000000000013, 20.000000000000014, 91.3999999999995, 20.000000000000014, -281.8, 117.5, 48.499999999999964, -249.40000000000018, -231.4, -167.20000000000002, -101.20000000000036, 20.000000000000014, -155.5, 130.69999999999985, 20.000000000000014, -325.6, 137.59999999999997, -200.50000000000014, -0.9999999999999846, -321.1000000000001, -309.70000000000005, -362.2, 155.89999999999986, 20.000000000000014, 121.69999999999993, 114.79999999999998, 195.49999999999997, 20.000000000000014, -106.00000000000006, 78.49999999999946, -28.299999999999798, -37.599999999999824, -228.99999999999997, -232.90000000000003, 6.500000000000039, -231.69999999999996, 5.299999999999978, -12.099999999999817, 20.000000000000014, 20.000000000000014, 194.59999999999997, 20.000000000000014, -147.7, 20.000000000000014, -114.70000000000002, 181.1, 20.000000000000014, 186.49999999999994, 145.69999999999996, 159.5, 9.499999999999972, 2.899999999999955, 179.0, 20.000000000000014, 20.000000000000014, -93.40000000000053, 100.39999999999999, 20.000000000000014, -120.40000000000023, 185.59999999999994, 13.699999999999966, 13.699999999999964, 20.000000000000014, -295.29999999999995, 20.000000000000014, 71.89999999999998, 171.7999999999999, -337.0, -258.70000000000005, 146.59999999999997, -253.00000000000003, -205.6, 187.39999999999998, -334.0, 20.000000000000014, 20.000000000000014, 195.5, 6.199999999999783, -3.099999999999958, 81.2, 20.000000000000014, 7.399999999999965, 190.09999999999997, 20.000000000000014, -3.100000000000037, 20.000000000000014, 20.000000000000014, 18.799999999999976, -180.10000000000008, 20.000000000000014, 10.099999999999987, 20.000000000000014, -136.9, 55.70000000000001, -121.29999999999998, 135.49999999999997, 144.19999999999996, 20.000000000000014, 103.1, 69.80000000000001, 151.39999999999978, 106.1, -75.4, 20.000000000000014, 20.000000000000014, 106.70000000000002, 164.0, 15.799999999999963, -33.10000000000001, 20.000000000000014, -4.6, 15.500000000000028, 196.39999999999998, 154.7, -100.3000000000001, 122.6, 20.000000000000014, -11.500000000000044, -121.90000000000006, 15.799999999999963], "policy_predator_policy_reward": [8.0, 0.0, 84.0, 25.0, 14.0, 8.0, 0.0, 95.0, 194.0, 40.0, 55.0, 88.0, 60.0, 0.0, 0.0, 14.0, 186.0, 60.0, 118.0, 125.0, 9.0, 0.0, 0.0, 0.0, 50.0, 49.0, 74.0, 107.0, 164.0, 0.0, 0.0, 38.0, 98.0, 123.0, 0.0, 0.0, 0.0, 0.0, 97.0, 134.0, 162.0, 183.0, 86.0, 38.0, 2.0, 5.0, 0.0, 0.0, 136.0, 115.0, 92.0, 85.0, 97.0, 92.0, 18.0, 5.0, 168.0, 137.0, 0.0, 11.0, 121.0, 145.0, 0.0, 0.0, 118.0, 149.0, 97.0, 79.0, 0.0, 8.0, 0.0, 21.0, 4.0, 21.0, 6.0, 0.0, 0.0, 184.0, 70.0, 96.0, 3.0, 48.0, 8.0, 0.0, 140.0, 154.0, 108.0, 74.0, 146.0, 131.0, 0.0, 71.0, 0.0, 114.0, 138.0, 126.0, 104.0, 20.0, 131.0, 109.0, 178.0, 162.0, 0.0, 0.0, 12.0, 26.0, 0.0, 0.0, 84.0, 0.0, 16.0, 43.0, 109.0, 150.0, 137.0, 79.0, 22.0, 20.0, 0.0, 0.0, 0.0, 0.0, 111.0, 80.0, 69.0, 52.0, 0.0, 0.0, 0.0, 25.0, 38.0, 33.0, 7.0, 0.0, 0.0, 54.0, 11.0, 0.0, 9.0, 66.0, 0.0, 6.0, 126.0, 35.0, 15.0, 6.0, 146.0, 132.0, 14.0, 152.0, 158.0, 140.0, 99.0, 171.0, 0.0, 0.0, 0.0, 40.0, 0.0, 47.0, 0.0, 6.0, 0.0, 0.0, 65.0, 0.0, 0.0, 1.0, 32.0, 81.0, 1.0, 8.0, 73.0, 111.0, 0.0, 123.0, 15.0, 0.0, 38.0, 7.0, 20.0, 23.0, 62.0, 45.0, 29.0, 0.0, 8.0, 5.0, 24.0, 44.0, 76.0, 13.0, 4.0, 9.0, 70.0, 47.0, 14.0, 2.0, 77.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6968611704928236, "mean_inference_ms": 1.8454294802442082, "mean_action_processing_ms": 0.29205208695832235, "mean_env_wait_ms": 0.2506519667164548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006246209144592285, "StateBufferConnector_ms": 0.006711840629577637, "ViewRequirementAgentConnector_ms": 0.190313458442688}, "num_episodes": 23, "episode_return_max": 364.1, "episode_return_min": -336.8, "episode_return_mean": 71.25299999999989, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.9002899154694, "num_env_steps_trained_throughput_per_sec": 215.9002899154694, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 14034.273, "restore_workers_time_ms": 0.021, "training_step_time_ms": 14034.211, "sample_time_ms": 2047.327, "learn_time_ms": 11963.062, "learn_throughput": 334.363, "synch_weights_time_ms": 18.689}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "04dec_00002", "date": "2024-08-13_16-38-46", "timestamp": 1723581526, "time_this_iter_s": 18.619688987731934, "time_total_s": 958.0297145843506, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04bbb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 958.0297145843506, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 83.97407407407408, "ram_util_percent": 84.96296296296298}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2143665171489513, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 0.00010000000000000003, "total_loss": 4.848596737624476, "policy_loss": -0.022252796762241, "vf_loss": 4.867465490512747, "vf_explained_var": 0.04369459098609036, "kl": 0.07130162276125494, "entropy": 0.7421302515362936, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.58014774060754, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": -0.0037395354099177495, "vf_loss": 7.696853702030484, "vf_explained_var": -0.2752049586129567, "kl": Infinity, "entropy": 0.7965793758473069, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 364.1, "episode_reward_min": -331.90000000000003, "episode_reward_mean": 67.30899999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -362.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": -17.510500000000036, "predator_policy": 51.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 89.19999999999987, -314.2999999999999, 31.100000000000286, 171.7999999999993, 158.79999999999933, 33.90000000000026, 90.69999999999993, 135.69999999999973, 274.7999999999998, -224.70000000000002, 265.7999999999995, 18.60000000000023, 40.0000000000003, -9.49999999999985, -62.399999999999835, 143.69999999999925, 275.1999999999998, 290.89999999999975, 33.400000000000205, -153.40000000000057, -7.299999999999837, -9.799999999999946, 119.39999999999885, 129.7, -18.899999999999892, -121.59999999999992, -10.199999999999726, 89.1999999999997, -41.59999999999978, 61.1000000000001, -82.10000000000008, -331.90000000000003, 175.89999999999918, 274.49999999999994, 215.49999999999923, 56.49999999999978, -6.89999999999965, -202.90000000000003, -9.199999999999939, 35.199999999999996, 40.0000000000003, 214.59999999999923, 63.30000000000025, 187.39999999999992, 206.4999999999992, 330.20000000000005, 83.39999999999975, 205.99999999999932, -19.399999999999714, 131.39999999999955, 140.19999999999973, 33.400000000000205, -114.30000000000018, 112.89999999999975, 112.7999999999999, 53.90000000000001, -160.60000000000002, 123.39999999999999, 40.0000000000003, 241.69999999999987, 125.09999999999974, 33.400000000000205, 210.09999999999926, 81.90000000000009, 39.800000000000296, -47.09999999999984, 39.100000000000115, 102.80000000000003, 137.19999999999996, 179.19999999999936, 217.89999999999998, 300.50000000000097, 51.600000000000136, 155.69999999999956, 192.7999999999994, 54.900000000000105, 99.90000000000009, 364.1, 139.3, 24.500000000000277, 28.90000000000017, 134.3999999999988, 40.0000000000003, -35.7999999999998, 35.700000000000145, 203.99999999999983, -51.89999999999994, 40.0000000000003, -120.90000000000006, 45.400000000000176, 113.39999999999978, 79.39999999999988, 207.99999999999994, -77.60000000000034, 11.399999999999936, 1.0000000000001705, 140.89999999999944, -109.90000000000012, -128.90000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 127.0999999999998, -268.9, -345.1, -314.19999999999993, -112.90000000000002, 20.000000000000014, 153.19999999999985, 11.599999999999971, 20.000000000000014, 138.7999999999999, -220.3, 3.1999999999999615, -223.29999999999998, 136.99999999999986, 164.8999999999998, -218.20000000000044, 132.79999999999993, 118.99999999999989, -227.8, -301.9, 131.8999999999999, 122.89999999999975, -267.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, -294.4, 17.899999999999988, 20.000000000000014, -258.4000000000001, 20.000000000000014, 115.69999999999979, 119.89999999999999, 134.29999999999993, 156.79999999999976, 109.09999999999995, 20.000000000000014, 7.399999999999965, 20.000000000000014, -357.4, -11.499999999999833, -161.79999999999993, -80.80000000000013, 20.000000000000014, 91.3999999999995, 20.000000000000014, -281.8, 117.5, 48.499999999999964, -249.40000000000018, -231.4, -167.20000000000002, -101.20000000000036, 20.000000000000014, -155.5, 130.69999999999985, 20.000000000000014, -325.6, 137.59999999999997, -200.50000000000014, -0.9999999999999846, -321.1000000000001, -309.70000000000005, -362.2, 155.89999999999986, 20.000000000000014, 121.69999999999993, 114.79999999999998, 195.49999999999997, 20.000000000000014, -106.00000000000006, 78.49999999999946, -28.299999999999798, -37.599999999999824, -228.99999999999997, -232.90000000000003, 6.500000000000039, -231.69999999999996, 5.299999999999978, -12.099999999999817, 20.000000000000014, 20.000000000000014, 194.59999999999997, 20.000000000000014, -147.7, 20.000000000000014, -114.70000000000002, 181.1, 20.000000000000014, 186.49999999999994, 145.69999999999996, 159.5, 9.499999999999972, 2.899999999999955, 179.0, 20.000000000000014, 20.000000000000014, -93.40000000000053, 100.39999999999999, 20.000000000000014, -120.40000000000023, 185.59999999999994, 13.699999999999966, 13.699999999999964, 20.000000000000014, -295.29999999999995, 20.000000000000014, 71.89999999999998, 171.7999999999999, -337.0, -258.70000000000005, 146.59999999999997, -253.00000000000003, -205.6, 187.39999999999998, -334.0, 20.000000000000014, 20.000000000000014, 195.5, 6.199999999999783, -3.099999999999958, 81.2, 20.000000000000014, 7.399999999999965, 190.09999999999997, 20.000000000000014, -3.100000000000037, 20.000000000000014, 20.000000000000014, 18.799999999999976, -180.10000000000008, 20.000000000000014, 10.099999999999987, 20.000000000000014, -136.9, 55.70000000000001, -121.29999999999998, 135.49999999999997, 144.19999999999996, 20.000000000000014, 103.1, 69.80000000000001, 151.39999999999978, 106.1, -75.4, 20.000000000000014, 20.000000000000014, 106.70000000000002, 164.0, 15.799999999999963, -33.10000000000001, 20.000000000000014, -4.6, 15.500000000000028, 196.39999999999998, 154.7, -100.3000000000001, 122.6, 20.000000000000014, -11.500000000000044, -121.90000000000006, 15.799999999999963, 106.39999999999941, 11.000000000000085, 20.000000000000014, 20.000000000000014, 38.90000000000014, -210.70000000000002, -73.30000000000001, 20.000000000000014, 113.30000000000001, 28.700000000000074, -29.50000000000003, -153.40000000000003, 20.000000000000014, 20.000000000000014, -338.20000000000005, -57.69999999999998, -46.59999999999998, 20.000000000000014, 46.40000000000001, 20.000000000000014, 177.7999999999999, -243.40000000000003, -14.19999999999996, 180.20000000000002, -42.09999999999997, -149.5, -2.8000000000000296, -53.79999999999996, -119.80000000000003, 15.799999999999963, -37.0, 92.8999999999995, -237.3999999999999, -95.49999999999999, -101.20000000000003, -171.70000000000007], "policy_predator_policy_reward": [0.0, 0.0, 97.0, 134.0, 162.0, 183.0, 86.0, 38.0, 2.0, 5.0, 0.0, 0.0, 136.0, 115.0, 92.0, 85.0, 97.0, 92.0, 18.0, 5.0, 168.0, 137.0, 0.0, 11.0, 121.0, 145.0, 0.0, 0.0, 118.0, 149.0, 97.0, 79.0, 0.0, 8.0, 0.0, 21.0, 4.0, 21.0, 6.0, 0.0, 0.0, 184.0, 70.0, 96.0, 3.0, 48.0, 8.0, 0.0, 140.0, 154.0, 108.0, 74.0, 146.0, 131.0, 0.0, 71.0, 0.0, 114.0, 138.0, 126.0, 104.0, 20.0, 131.0, 109.0, 178.0, 162.0, 0.0, 0.0, 12.0, 26.0, 0.0, 0.0, 84.0, 0.0, 16.0, 43.0, 109.0, 150.0, 137.0, 79.0, 22.0, 20.0, 0.0, 0.0, 0.0, 0.0, 111.0, 80.0, 69.0, 52.0, 0.0, 0.0, 0.0, 25.0, 38.0, 33.0, 7.0, 0.0, 0.0, 54.0, 11.0, 0.0, 9.0, 66.0, 0.0, 6.0, 126.0, 35.0, 15.0, 6.0, 146.0, 132.0, 14.0, 152.0, 158.0, 140.0, 99.0, 171.0, 0.0, 0.0, 0.0, 40.0, 0.0, 47.0, 0.0, 6.0, 0.0, 0.0, 65.0, 0.0, 0.0, 1.0, 32.0, 81.0, 1.0, 8.0, 73.0, 111.0, 0.0, 123.0, 15.0, 0.0, 38.0, 7.0, 20.0, 23.0, 62.0, 45.0, 29.0, 0.0, 8.0, 5.0, 24.0, 44.0, 76.0, 13.0, 4.0, 9.0, 70.0, 47.0, 14.0, 2.0, 77.0, 58.0, 8.0, 9.0, 0.0, 0.0, 0.0, 136.0, 2.0, 87.0, 23.0, 39.0, 111.0, 20.0, 0.0, 0.0, 162.0, 113.0, 34.0, 38.0, 47.0, 0.0, 0.0, 145.0, 0.0, 42.0, 1.0, 113.0, 39.0, 29.0, 0.0, 105.0, 0.0, 85.0, 51.0, 172.0, 0.0, 144.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7012175727885053, "mean_inference_ms": 1.8631131255989561, "mean_action_processing_ms": 0.2935499516072565, "mean_env_wait_ms": 0.2525292129450048, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0061838626861572266, "StateBufferConnector_ms": 0.0067424774169921875, "ViewRequirementAgentConnector_ms": 0.1961878538131714}, "num_episodes": 18, "episode_return_max": 364.1, "episode_return_min": -331.90000000000003, "episode_return_mean": 67.30899999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 262.42088683822516, "num_env_steps_trained_throughput_per_sec": 262.42088683822516, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 14493.48, "restore_workers_time_ms": 0.022, "training_step_time_ms": 14493.417, "sample_time_ms": 2099.025, "learn_time_ms": 12370.671, "learn_throughput": 323.345, "synch_weights_time_ms": 18.974}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "04dec_00002", "date": "2024-08-13_16-39-01", "timestamp": 1723581541, "time_this_iter_s": 15.304817914962769, "time_total_s": 973.3345324993134, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c45e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 973.3345324993134, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 82.43181818181819, "ram_util_percent": 85.1909090909091}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4092082777666668, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 0.00010000000000000003, "total_loss": 4.362256019203751, "policy_loss": -0.003967097755422983, "vf_loss": 4.365278512460214, "vf_explained_var": 0.04635263511112758, "kl": 0.013268544069856588, "entropy": 0.7820783700261797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.72527689321962, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 0.00010000000000000003, "total_loss": 7.566215272429128, "policy_loss": 0.0007242320933275753, "vf_loss": 7.563863579684464, "vf_explained_var": -0.18038361624435142, "kl": 0.018062410092816977, "entropy": 0.7042335657215623, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 369.4000000000002, "episode_reward_min": -331.90000000000003, "episode_reward_mean": 74.56099999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -362.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": -9.254500000000034, "predator_policy": 46.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.799999999999946, 119.39999999999885, 129.7, -18.899999999999892, -121.59999999999992, -10.199999999999726, 89.1999999999997, -41.59999999999978, 61.1000000000001, -82.10000000000008, -331.90000000000003, 175.89999999999918, 274.49999999999994, 215.49999999999923, 56.49999999999978, -6.89999999999965, -202.90000000000003, -9.199999999999939, 35.199999999999996, 40.0000000000003, 214.59999999999923, 63.30000000000025, 187.39999999999992, 206.4999999999992, 330.20000000000005, 83.39999999999975, 205.99999999999932, -19.399999999999714, 131.39999999999955, 140.19999999999973, 33.400000000000205, -114.30000000000018, 112.89999999999975, 112.7999999999999, 53.90000000000001, -160.60000000000002, 123.39999999999999, 40.0000000000003, 241.69999999999987, 125.09999999999974, 33.400000000000205, 210.09999999999926, 81.90000000000009, 39.800000000000296, -47.09999999999984, 39.100000000000115, 102.80000000000003, 137.19999999999996, 179.19999999999936, 217.89999999999998, 300.50000000000097, 51.600000000000136, 155.69999999999956, 192.7999999999994, 54.900000000000105, 99.90000000000009, 364.1, 139.3, 24.500000000000277, 28.90000000000017, 134.3999999999988, 40.0000000000003, -35.7999999999998, 35.700000000000145, 203.99999999999983, -51.89999999999994, 40.0000000000003, -120.90000000000006, 45.400000000000176, 113.39999999999978, 79.39999999999988, 207.99999999999994, -77.60000000000034, 11.399999999999936, 1.0000000000001705, 140.89999999999944, -109.90000000000012, -128.90000000000012, 82.7, 369.4000000000002, -88.1, -127.6000000000002, -86.10000000000002, 40.0000000000003, 149.19999999999996, 30.000000000000057, 288.69999999999993, 299.0, 40.0000000000003, 298.3000000000018, 185.79999999999913, 249.69999999999908, -50.29999999999994, -17.09999999999996, -13.899999999999908, 131.49999999999983, 182.09999999999917, 37.29999999999933, 6.599999999999998, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-80.80000000000013, 20.000000000000014, 91.3999999999995, 20.000000000000014, -281.8, 117.5, 48.499999999999964, -249.40000000000018, -231.4, -167.20000000000002, -101.20000000000036, 20.000000000000014, -155.5, 130.69999999999985, 20.000000000000014, -325.6, 137.59999999999997, -200.50000000000014, -0.9999999999999846, -321.1000000000001, -309.70000000000005, -362.2, 155.89999999999986, 20.000000000000014, 121.69999999999993, 114.79999999999998, 195.49999999999997, 20.000000000000014, -106.00000000000006, 78.49999999999946, -28.299999999999798, -37.599999999999824, -228.99999999999997, -232.90000000000003, 6.500000000000039, -231.69999999999996, 5.299999999999978, -12.099999999999817, 20.000000000000014, 20.000000000000014, 194.59999999999997, 20.000000000000014, -147.7, 20.000000000000014, -114.70000000000002, 181.1, 20.000000000000014, 186.49999999999994, 145.69999999999996, 159.5, 9.499999999999972, 2.899999999999955, 179.0, 20.000000000000014, 20.000000000000014, -93.40000000000053, 100.39999999999999, 20.000000000000014, -120.40000000000023, 185.59999999999994, 13.699999999999966, 13.699999999999964, 20.000000000000014, -295.29999999999995, 20.000000000000014, 71.89999999999998, 171.7999999999999, -337.0, -258.70000000000005, 146.59999999999997, -253.00000000000003, -205.6, 187.39999999999998, -334.0, 20.000000000000014, 20.000000000000014, 195.5, 6.199999999999783, -3.099999999999958, 81.2, 20.000000000000014, 7.399999999999965, 190.09999999999997, 20.000000000000014, -3.100000000000037, 20.000000000000014, 20.000000000000014, 18.799999999999976, -180.10000000000008, 20.000000000000014, 10.099999999999987, 20.000000000000014, -136.9, 55.70000000000001, -121.29999999999998, 135.49999999999997, 144.19999999999996, 20.000000000000014, 103.1, 69.80000000000001, 151.39999999999978, 106.1, -75.4, 20.000000000000014, 20.000000000000014, 106.70000000000002, 164.0, 15.799999999999963, -33.10000000000001, 20.000000000000014, -4.6, 15.500000000000028, 196.39999999999998, 154.7, -100.3000000000001, 122.6, 20.000000000000014, -11.500000000000044, -121.90000000000006, 15.799999999999963, 106.39999999999941, 11.000000000000085, 20.000000000000014, 20.000000000000014, 38.90000000000014, -210.70000000000002, -73.30000000000001, 20.000000000000014, 113.30000000000001, 28.700000000000074, -29.50000000000003, -153.40000000000003, 20.000000000000014, 20.000000000000014, -338.20000000000005, -57.69999999999998, -46.59999999999998, 20.000000000000014, 46.40000000000001, 20.000000000000014, 177.7999999999999, -243.40000000000003, -14.19999999999996, 180.20000000000002, -42.09999999999997, -149.5, -2.8000000000000296, -53.79999999999996, -119.80000000000003, 15.799999999999963, -37.0, 92.8999999999995, -237.3999999999999, -95.49999999999999, -101.20000000000003, -171.70000000000007, 57.20000000000001, -71.49999999999994, 187.39999999999995, 181.99999999999991, -131.80000000000018, -217.30000000000007, -88.30000000000018, -358.29999999999984, -246.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -346.9, 187.1, -30.999999999999993, 20.000000000000014, 164.89999999999986, 120.79999999999991, 190.09999999999997, 92.89999999999995, 20.000000000000014, 20.000000000000014, 154.0999999999998, 144.19999999999968, 20.000000000000014, 165.79999999999984, 179.2999999999999, 70.39999999999975, -39.69999999999998, -226.6000000000002, -9.400000000000006, -141.70000000000002, -85.60000000000022, 13.699999999999964, 45.20000000000002, -30.699999999999868, 157.09999999999985, 20.000000000000014, 70.09999999999975, -131.8, 17.899999999999988, -52.300000000000026, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [3.0, 48.0, 8.0, 0.0, 140.0, 154.0, 108.0, 74.0, 146.0, 131.0, 0.0, 71.0, 0.0, 114.0, 138.0, 126.0, 104.0, 20.0, 131.0, 109.0, 178.0, 162.0, 0.0, 0.0, 12.0, 26.0, 0.0, 0.0, 84.0, 0.0, 16.0, 43.0, 109.0, 150.0, 137.0, 79.0, 22.0, 20.0, 0.0, 0.0, 0.0, 0.0, 111.0, 80.0, 69.0, 52.0, 0.0, 0.0, 0.0, 25.0, 38.0, 33.0, 7.0, 0.0, 0.0, 54.0, 11.0, 0.0, 9.0, 66.0, 0.0, 6.0, 126.0, 35.0, 15.0, 6.0, 146.0, 132.0, 14.0, 152.0, 158.0, 140.0, 99.0, 171.0, 0.0, 0.0, 0.0, 40.0, 0.0, 47.0, 0.0, 6.0, 0.0, 0.0, 65.0, 0.0, 0.0, 1.0, 32.0, 81.0, 1.0, 8.0, 73.0, 111.0, 0.0, 123.0, 15.0, 0.0, 38.0, 7.0, 20.0, 23.0, 62.0, 45.0, 29.0, 0.0, 8.0, 5.0, 24.0, 44.0, 76.0, 13.0, 4.0, 9.0, 70.0, 47.0, 14.0, 2.0, 77.0, 58.0, 8.0, 9.0, 0.0, 0.0, 0.0, 136.0, 2.0, 87.0, 23.0, 39.0, 111.0, 20.0, 0.0, 0.0, 162.0, 113.0, 34.0, 38.0, 47.0, 0.0, 0.0, 145.0, 0.0, 42.0, 1.0, 113.0, 39.0, 29.0, 0.0, 105.0, 0.0, 85.0, 51.0, 172.0, 0.0, 144.0, 20.0, 77.0, 0.0, 0.0, 112.0, 149.0, 183.0, 136.0, 133.0, 7.0, 0.0, 0.0, 172.0, 137.0, 24.0, 17.0, 3.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.0, 118.0, 62.0, 72.0, 58.0, 0.0, 34.0, 83.0, 5.0, 0.0, 99.0, 0.0, 25.0, 16.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7066819735846708, "mean_inference_ms": 1.884658725165926, "mean_action_processing_ms": 0.2952361084904981, "mean_env_wait_ms": 0.2546071163543649, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006354212760925293, "StateBufferConnector_ms": 0.007100820541381836, "ViewRequirementAgentConnector_ms": 0.2129075527191162}, "num_episodes": 22, "episode_return_max": 369.4000000000002, "episode_return_min": -331.90000000000003, "episode_return_mean": 74.56099999999994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 245.72176914818291, "num_env_steps_trained_throughput_per_sec": 245.72176914818291, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 15014.17, "restore_workers_time_ms": 0.021, "training_step_time_ms": 15014.109, "sample_time_ms": 2164.742, "learn_time_ms": 12825.307, "learn_throughput": 311.883, "synch_weights_time_ms": 19.239}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "04dec_00002", "date": "2024-08-13_16-39-18", "timestamp": 1723581558, "time_this_iter_s": 16.339718103408813, "time_total_s": 989.6742506027222, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3587ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 989.6742506027222, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 84.76521739130435, "ram_util_percent": 85.9217391304348}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.278948541119616, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 0.00010000000000000003, "total_loss": 6.808538705583603, "policy_loss": -0.0016264608435372196, "vf_loss": 6.809698719196219, "vf_explained_var": 0.018903729272267175, "kl": 0.006551986371144379, "entropy": 0.7138754958828921, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.191991012941592, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 0.00010000000000000003, "total_loss": 7.032649049052486, "policy_loss": 0.0007635517883553076, "vf_loss": 7.0316290671232515, "vf_explained_var": -0.3963184162422463, "kl": 0.0028459479217397567, "entropy": 0.8230350361614631, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 369.4000000000002, "episode_reward_min": -306.79999999999995, "episode_reward_mean": 72.07999999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -375.40000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": -11.08000000000003, "predator_policy": 47.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.199999999999996, 40.0000000000003, 214.59999999999923, 63.30000000000025, 187.39999999999992, 206.4999999999992, 330.20000000000005, 83.39999999999975, 205.99999999999932, -19.399999999999714, 131.39999999999955, 140.19999999999973, 33.400000000000205, -114.30000000000018, 112.89999999999975, 112.7999999999999, 53.90000000000001, -160.60000000000002, 123.39999999999999, 40.0000000000003, 241.69999999999987, 125.09999999999974, 33.400000000000205, 210.09999999999926, 81.90000000000009, 39.800000000000296, -47.09999999999984, 39.100000000000115, 102.80000000000003, 137.19999999999996, 179.19999999999936, 217.89999999999998, 300.50000000000097, 51.600000000000136, 155.69999999999956, 192.7999999999994, 54.900000000000105, 99.90000000000009, 364.1, 139.3, 24.500000000000277, 28.90000000000017, 134.3999999999988, 40.0000000000003, -35.7999999999998, 35.700000000000145, 203.99999999999983, -51.89999999999994, 40.0000000000003, -120.90000000000006, 45.400000000000176, 113.39999999999978, 79.39999999999988, 207.99999999999994, -77.60000000000034, 11.399999999999936, 1.0000000000001705, 140.89999999999944, -109.90000000000012, -128.90000000000012, 82.7, 369.4000000000002, -88.1, -127.6000000000002, -86.10000000000002, 40.0000000000003, 149.19999999999996, 30.000000000000057, 288.69999999999993, 299.0, 40.0000000000003, 298.3000000000018, 185.79999999999913, 249.69999999999908, -50.29999999999994, -17.09999999999996, -13.899999999999908, 131.49999999999983, 182.09999999999917, 37.29999999999933, 6.599999999999998, 40.0000000000003, 40.0000000000003, 119.4999999999998, 64.60000000000008, 210.09999999999923, -21.599999999999902, -9.199999999999996, 208.29999999999933, -25.599999999999945, -145.5999999999999, 50.09999999999985, -46.59999999999976, -14.699999999999967, -306.79999999999995, 139.99999999999997, -142.20000000000002, -7.40000000000002, 168.59999999999954, -242.90000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999978, -12.099999999999817, 20.000000000000014, 20.000000000000014, 194.59999999999997, 20.000000000000014, -147.7, 20.000000000000014, -114.70000000000002, 181.1, 20.000000000000014, 186.49999999999994, 145.69999999999996, 159.5, 9.499999999999972, 2.899999999999955, 179.0, 20.000000000000014, 20.000000000000014, -93.40000000000053, 100.39999999999999, 20.000000000000014, -120.40000000000023, 185.59999999999994, 13.699999999999966, 13.699999999999964, 20.000000000000014, -295.29999999999995, 20.000000000000014, 71.89999999999998, 171.7999999999999, -337.0, -258.70000000000005, 146.59999999999997, -253.00000000000003, -205.6, 187.39999999999998, -334.0, 20.000000000000014, 20.000000000000014, 195.5, 6.199999999999783, -3.099999999999958, 81.2, 20.000000000000014, 7.399999999999965, 190.09999999999997, 20.000000000000014, -3.100000000000037, 20.000000000000014, 20.000000000000014, 18.799999999999976, -180.10000000000008, 20.000000000000014, 10.099999999999987, 20.000000000000014, -136.9, 55.70000000000001, -121.29999999999998, 135.49999999999997, 144.19999999999996, 20.000000000000014, 103.1, 69.80000000000001, 151.39999999999978, 106.1, -75.4, 20.000000000000014, 20.000000000000014, 106.70000000000002, 164.0, 15.799999999999963, -33.10000000000001, 20.000000000000014, -4.6, 15.500000000000028, 196.39999999999998, 154.7, -100.3000000000001, 122.6, 20.000000000000014, -11.500000000000044, -121.90000000000006, 15.799999999999963, 106.39999999999941, 11.000000000000085, 20.000000000000014, 20.000000000000014, 38.90000000000014, -210.70000000000002, -73.30000000000001, 20.000000000000014, 113.30000000000001, 28.700000000000074, -29.50000000000003, -153.40000000000003, 20.000000000000014, 20.000000000000014, -338.20000000000005, -57.69999999999998, -46.59999999999998, 20.000000000000014, 46.40000000000001, 20.000000000000014, 177.7999999999999, -243.40000000000003, -14.19999999999996, 180.20000000000002, -42.09999999999997, -149.5, -2.8000000000000296, -53.79999999999996, -119.80000000000003, 15.799999999999963, -37.0, 92.8999999999995, -237.3999999999999, -95.49999999999999, -101.20000000000003, -171.70000000000007, 57.20000000000001, -71.49999999999994, 187.39999999999995, 181.99999999999991, -131.80000000000018, -217.30000000000007, -88.30000000000018, -358.29999999999984, -246.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -346.9, 187.1, -30.999999999999993, 20.000000000000014, 164.89999999999986, 120.79999999999991, 190.09999999999997, 92.89999999999995, 20.000000000000014, 20.000000000000014, 154.0999999999998, 144.19999999999968, 20.000000000000014, 165.79999999999984, 179.2999999999999, 70.39999999999975, -39.69999999999998, -226.6000000000002, -9.400000000000006, -141.70000000000002, -85.60000000000022, 13.699999999999964, 45.20000000000002, -30.699999999999868, 157.09999999999985, 20.000000000000014, 70.09999999999975, -131.8, 17.899999999999988, -52.300000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -136.6, 112.10000000000001, -78.4, 20.000000000000014, 20.000000000000014, 190.09999999999997, 11.599999999999964, -89.20000000000005, 20.000000000000014, -344.19999999999993, 20.000000000000014, 188.3, 20.000000000000014, -118.60000000000005, -352.29999999999995, -103.30000000000003, 13.699999999999966, -142.6, -310.90000000000003, 5.299999999999965, -13.000000000000021, -168.70000000000002, -255.40000000000003, -237.40000000000012, 196.39999999999998, -177.40000000000003, -259.90000000000003, -61.30000000000009, -375.40000000000003, 20.000000000000014, 125.6, 20.000000000000014, -272.7999999999997, -225.10000000000002], "policy_predator_policy_reward": [22.0, 20.0, 0.0, 0.0, 0.0, 0.0, 111.0, 80.0, 69.0, 52.0, 0.0, 0.0, 0.0, 25.0, 38.0, 33.0, 7.0, 0.0, 0.0, 54.0, 11.0, 0.0, 9.0, 66.0, 0.0, 6.0, 126.0, 35.0, 15.0, 6.0, 146.0, 132.0, 14.0, 152.0, 158.0, 140.0, 99.0, 171.0, 0.0, 0.0, 0.0, 40.0, 0.0, 47.0, 0.0, 6.0, 0.0, 0.0, 65.0, 0.0, 0.0, 1.0, 32.0, 81.0, 1.0, 8.0, 73.0, 111.0, 0.0, 123.0, 15.0, 0.0, 38.0, 7.0, 20.0, 23.0, 62.0, 45.0, 29.0, 0.0, 8.0, 5.0, 24.0, 44.0, 76.0, 13.0, 4.0, 9.0, 70.0, 47.0, 14.0, 2.0, 77.0, 58.0, 8.0, 9.0, 0.0, 0.0, 0.0, 136.0, 2.0, 87.0, 23.0, 39.0, 111.0, 20.0, 0.0, 0.0, 162.0, 113.0, 34.0, 38.0, 47.0, 0.0, 0.0, 145.0, 0.0, 42.0, 1.0, 113.0, 39.0, 29.0, 0.0, 105.0, 0.0, 85.0, 51.0, 172.0, 0.0, 144.0, 20.0, 77.0, 0.0, 0.0, 112.0, 149.0, 183.0, 136.0, 133.0, 7.0, 0.0, 0.0, 172.0, 137.0, 24.0, 17.0, 3.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.0, 118.0, 62.0, 72.0, 58.0, 0.0, 34.0, 83.0, 5.0, 0.0, 99.0, 0.0, 25.0, 16.0, 0.0, 0.0, 0.0, 0.0, 36.0, 108.0, 35.0, 88.0, 0.0, 0.0, 4.0, 52.0, 171.0, 144.0, 0.0, 0.0, 13.0, 60.0, 179.0, 131.0, 89.0, 90.0, 157.0, 102.0, 6.0, 161.0, 11.0, 175.0, 0.0, 121.0, 7.0, 172.0, 180.0, 168.0, 23.0, 0.0, 122.0, 133.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7105363741346573, "mean_inference_ms": 1.9009551632075659, "mean_action_processing_ms": 0.2966343113733484, "mean_env_wait_ms": 0.25646395517484044, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006616711616516113, "StateBufferConnector_ms": 0.007096767425537109, "ViewRequirementAgentConnector_ms": 0.2267289161682129}, "num_episodes": 18, "episode_return_max": 369.4000000000002, "episode_return_min": -306.79999999999995, "episode_return_mean": 72.07999999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.65154752547227, "num_env_steps_trained_throughput_per_sec": 247.65154752547227, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 15539.823, "restore_workers_time_ms": 0.022, "training_step_time_ms": 15539.758, "sample_time_ms": 2216.705, "learn_time_ms": 13297.584, "learn_throughput": 300.807, "synch_weights_time_ms": 19.317}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "04dec_00002", "date": "2024-08-13_16-39-34", "timestamp": 1723581574, "time_this_iter_s": 16.204982042312622, "time_total_s": 1005.8792326450348, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04bb1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1005.8792326450348, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 82.5086956521739, "ram_util_percent": 85.36086956521739}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6361500199430834, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 0.00010000000000000003, "total_loss": 6.85273906061889, "policy_loss": -0.002272619682403587, "vf_loss": 6.854513888132004, "vf_explained_var": 0.0008299873934851752, "kl": 0.006992200532268995, "entropy": 0.6494269225647841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.807355194842373, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 0.00010000000000000003, "total_loss": 7.763841064644869, "policy_loss": 0.00033694356679916384, "vf_loss": 7.763139350073678, "vf_explained_var": -0.2707624741332241, "kl": 0.008096924748963072, "entropy": 0.72997731427667, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 369.4000000000002, "episode_reward_min": -306.79999999999995, "episode_reward_mean": 47.57599999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -35.91700000000002, "predator_policy": 59.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.09999999999926, 81.90000000000009, 39.800000000000296, -47.09999999999984, 39.100000000000115, 102.80000000000003, 137.19999999999996, 179.19999999999936, 217.89999999999998, 300.50000000000097, 51.600000000000136, 155.69999999999956, 192.7999999999994, 54.900000000000105, 99.90000000000009, 364.1, 139.3, 24.500000000000277, 28.90000000000017, 134.3999999999988, 40.0000000000003, -35.7999999999998, 35.700000000000145, 203.99999999999983, -51.89999999999994, 40.0000000000003, -120.90000000000006, 45.400000000000176, 113.39999999999978, 79.39999999999988, 207.99999999999994, -77.60000000000034, 11.399999999999936, 1.0000000000001705, 140.89999999999944, -109.90000000000012, -128.90000000000012, 82.7, 369.4000000000002, -88.1, -127.6000000000002, -86.10000000000002, 40.0000000000003, 149.19999999999996, 30.000000000000057, 288.69999999999993, 299.0, 40.0000000000003, 298.3000000000018, 185.79999999999913, 249.69999999999908, -50.29999999999994, -17.09999999999996, -13.899999999999908, 131.49999999999983, 182.09999999999917, 37.29999999999933, 6.599999999999998, 40.0000000000003, 40.0000000000003, 119.4999999999998, 64.60000000000008, 210.09999999999923, -21.599999999999902, -9.199999999999996, 208.29999999999933, -25.599999999999945, -145.5999999999999, 50.09999999999985, -46.59999999999976, -14.699999999999967, -306.79999999999995, 139.99999999999997, -142.20000000000002, -7.40000000000002, 168.59999999999954, -242.90000000000015, -125.40000000000006, -54.6, 219.09999999999926, -16.299999999999983, -10.000000000000224, -90.20000000000005, 126.49999999999994, -183.80000000000038, -179.40000000000006, -9.200000000000323, 242.59999999999994, -292.5000000000001, 63.50000000000025, 49.70000000000012, 40.0000000000003, 104.29999999999998, 10.400000000000041, 144.10000000000002, 215.49999999999923, 59.30000000000019, -191.2000000000001, -202.20000000000005, -150.10000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [190.09999999999997, 20.000000000000014, -3.100000000000037, 20.000000000000014, 20.000000000000014, 18.799999999999976, -180.10000000000008, 20.000000000000014, 10.099999999999987, 20.000000000000014, -136.9, 55.70000000000001, -121.29999999999998, 135.49999999999997, 144.19999999999996, 20.000000000000014, 103.1, 69.80000000000001, 151.39999999999978, 106.1, -75.4, 20.000000000000014, 20.000000000000014, 106.70000000000002, 164.0, 15.799999999999963, -33.10000000000001, 20.000000000000014, -4.6, 15.500000000000028, 196.39999999999998, 154.7, -100.3000000000001, 122.6, 20.000000000000014, -11.500000000000044, -121.90000000000006, 15.799999999999963, 106.39999999999941, 11.000000000000085, 20.000000000000014, 20.000000000000014, 38.90000000000014, -210.70000000000002, -73.30000000000001, 20.000000000000014, 113.30000000000001, 28.700000000000074, -29.50000000000003, -153.40000000000003, 20.000000000000014, 20.000000000000014, -338.20000000000005, -57.69999999999998, -46.59999999999998, 20.000000000000014, 46.40000000000001, 20.000000000000014, 177.7999999999999, -243.40000000000003, -14.19999999999996, 180.20000000000002, -42.09999999999997, -149.5, -2.8000000000000296, -53.79999999999996, -119.80000000000003, 15.799999999999963, -37.0, 92.8999999999995, -237.3999999999999, -95.49999999999999, -101.20000000000003, -171.70000000000007, 57.20000000000001, -71.49999999999994, 187.39999999999995, 181.99999999999991, -131.80000000000018, -217.30000000000007, -88.30000000000018, -358.29999999999984, -246.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -346.9, 187.1, -30.999999999999993, 20.000000000000014, 164.89999999999986, 120.79999999999991, 190.09999999999997, 92.89999999999995, 20.000000000000014, 20.000000000000014, 154.0999999999998, 144.19999999999968, 20.000000000000014, 165.79999999999984, 179.2999999999999, 70.39999999999975, -39.69999999999998, -226.6000000000002, -9.400000000000006, -141.70000000000002, -85.60000000000022, 13.699999999999964, 45.20000000000002, -30.699999999999868, 157.09999999999985, 20.000000000000014, 70.09999999999975, -131.8, 17.899999999999988, -52.300000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -136.6, 112.10000000000001, -78.4, 20.000000000000014, 20.000000000000014, 190.09999999999997, 11.599999999999964, -89.20000000000005, 20.000000000000014, -344.19999999999993, 20.000000000000014, 188.3, 20.000000000000014, -118.60000000000005, -352.29999999999995, -103.30000000000003, 13.699999999999966, -142.6, -310.90000000000003, 5.299999999999965, -13.000000000000021, -168.70000000000002, -255.40000000000003, -237.40000000000012, 196.39999999999998, -177.40000000000003, -259.90000000000003, -61.30000000000009, -375.40000000000003, 20.000000000000014, 125.6, 20.000000000000014, -272.7999999999997, -225.10000000000002, -76.0, -303.4, -386.79999999999995, -35.800000000000004, 199.1, 20.000000000000014, 7.399999999999965, -345.70000000000005, -81.39999999999982, -58.600000000000016, 20.000000000000014, -257.2, 171.5, -264.9999999999999, -338.5, -127.30000000000038, -58.30000000000004, -285.1, -34.299999999999805, -106.9, 177.49999999999991, -1.9000000000000057, -289.30000000000007, -371.19999999999993, 39.50000000000006, 20.000000000000014, -195.4, 16.099999999999994, 20.000000000000014, 20.000000000000014, 196.39999999999998, -261.1, 20.000000000000014, -241.6, -266.5, 152.6, 20.000000000000014, 195.49999999999997, -39.70000000000002, 20.000000000000014, -142.0, -332.19999999999993, -289.5999999999999, -235.60000000000002, -315.70000000000005, -210.4], "policy_predator_policy_reward": [0.0, 0.0, 65.0, 0.0, 0.0, 1.0, 32.0, 81.0, 1.0, 8.0, 73.0, 111.0, 0.0, 123.0, 15.0, 0.0, 38.0, 7.0, 20.0, 23.0, 62.0, 45.0, 29.0, 0.0, 8.0, 5.0, 24.0, 44.0, 76.0, 13.0, 4.0, 9.0, 70.0, 47.0, 14.0, 2.0, 77.0, 58.0, 8.0, 9.0, 0.0, 0.0, 0.0, 136.0, 2.0, 87.0, 23.0, 39.0, 111.0, 20.0, 0.0, 0.0, 162.0, 113.0, 34.0, 38.0, 47.0, 0.0, 0.0, 145.0, 0.0, 42.0, 1.0, 113.0, 39.0, 29.0, 0.0, 105.0, 0.0, 85.0, 51.0, 172.0, 0.0, 144.0, 20.0, 77.0, 0.0, 0.0, 112.0, 149.0, 183.0, 136.0, 133.0, 7.0, 0.0, 0.0, 172.0, 137.0, 24.0, 17.0, 3.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.0, 118.0, 62.0, 72.0, 58.0, 0.0, 34.0, 83.0, 5.0, 0.0, 99.0, 0.0, 25.0, 16.0, 0.0, 0.0, 0.0, 0.0, 36.0, 108.0, 35.0, 88.0, 0.0, 0.0, 4.0, 52.0, 171.0, 144.0, 0.0, 0.0, 13.0, 60.0, 179.0, 131.0, 89.0, 90.0, 157.0, 102.0, 6.0, 161.0, 11.0, 175.0, 0.0, 121.0, 7.0, 172.0, 180.0, 168.0, 23.0, 0.0, 122.0, 133.0, 155.0, 99.0, 189.0, 179.0, 0.0, 0.0, 142.0, 180.0, 25.0, 105.0, 147.0, 0.0, 85.0, 135.0, 104.0, 178.0, 164.0, 0.0, 25.0, 107.0, 0.0, 67.0, 181.0, 187.0, 0.0, 4.0, 83.0, 146.0, 0.0, 0.0, 143.0, 26.0, 131.0, 101.0, 136.0, 122.0, 0.0, 0.0, 0.0, 79.0, 163.0, 120.0, 130.0, 193.0, 193.0, 183.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7146744872906234, "mean_inference_ms": 1.9183881293415934, "mean_action_processing_ms": 0.29818120678629056, "mean_env_wait_ms": 0.25817600628626214, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052487850189208984, "StateBufferConnector_ms": 0.0070574283599853516, "ViewRequirementAgentConnector_ms": 0.21141600608825684}, "num_episodes": 23, "episode_return_max": 369.4000000000002, "episode_return_min": -306.79999999999995, "episode_return_mean": 47.57599999999994, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 264.07750950521984, "num_env_steps_trained_throughput_per_sec": 264.07750950521984, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 15947.906, "restore_workers_time_ms": 0.022, "training_step_time_ms": 15947.84, "sample_time_ms": 2295.778, "learn_time_ms": 13629.623, "learn_throughput": 293.478, "synch_weights_time_ms": 17.307}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "04dec_00002", "date": "2024-08-13_16-39-49", "timestamp": 1723581589, "time_this_iter_s": 15.172988891601562, "time_total_s": 1021.0522215366364, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1021.0522215366364, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 79.75238095238095, "ram_util_percent": 83.67619047619048}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.329605495440897, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 0.00010000000000000003, "total_loss": 6.9618490140904825, "policy_loss": -0.0028026078041721745, "vf_loss": 6.964229241628495, "vf_explained_var": -0.0013107308004268264, "kl": 0.005933204951366419, "entropy": 0.6333355819422101, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.562654440648974, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": -6.777087532023273e-06, "vf_loss": 7.143464353349474, "vf_explained_var": -0.5749118222130669, "kl": Infinity, "entropy": 0.7159735573031915, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 369.4000000000002, "episode_reward_min": -306.79999999999995, "episode_reward_mean": 28.31199999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -55.51900000000003, "predator_policy": 69.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.90000000000017, 134.3999999999988, 40.0000000000003, -35.7999999999998, 35.700000000000145, 203.99999999999983, -51.89999999999994, 40.0000000000003, -120.90000000000006, 45.400000000000176, 113.39999999999978, 79.39999999999988, 207.99999999999994, -77.60000000000034, 11.399999999999936, 1.0000000000001705, 140.89999999999944, -109.90000000000012, -128.90000000000012, 82.7, 369.4000000000002, -88.1, -127.6000000000002, -86.10000000000002, 40.0000000000003, 149.19999999999996, 30.000000000000057, 288.69999999999993, 299.0, 40.0000000000003, 298.3000000000018, 185.79999999999913, 249.69999999999908, -50.29999999999994, -17.09999999999996, -13.899999999999908, 131.49999999999983, 182.09999999999917, 37.29999999999933, 6.599999999999998, 40.0000000000003, 40.0000000000003, 119.4999999999998, 64.60000000000008, 210.09999999999923, -21.599999999999902, -9.199999999999996, 208.29999999999933, -25.599999999999945, -145.5999999999999, 50.09999999999985, -46.59999999999976, -14.699999999999967, -306.79999999999995, 139.99999999999997, -142.20000000000002, -7.40000000000002, 168.59999999999954, -242.90000000000015, -125.40000000000006, -54.6, 219.09999999999926, -16.299999999999983, -10.000000000000224, -90.20000000000005, 126.49999999999994, -183.80000000000038, -179.40000000000006, -9.200000000000323, 242.59999999999994, -292.5000000000001, 63.50000000000025, 49.70000000000012, 40.0000000000003, 104.29999999999998, 10.400000000000041, 144.10000000000002, 215.49999999999923, 59.30000000000019, -191.2000000000001, -202.20000000000005, -150.10000000000002, 31.900000000000077, 50.100000000000044, 179.69999999999945, 160.29999999999967, 94.79999999999939, -62.499999999999986, -135.4, -1.8000000000000522, 6.199999999999939, -30.300000000000033, 30.80000000000028, -63.10000000000042, 203.7999999999993, 40.0000000000003, -50.99999999999978, -192.3, 213.79999999999993, -57.199999999999825], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-121.90000000000006, 15.799999999999963, 106.39999999999941, 11.000000000000085, 20.000000000000014, 20.000000000000014, 38.90000000000014, -210.70000000000002, -73.30000000000001, 20.000000000000014, 113.30000000000001, 28.700000000000074, -29.50000000000003, -153.40000000000003, 20.000000000000014, 20.000000000000014, -338.20000000000005, -57.69999999999998, -46.59999999999998, 20.000000000000014, 46.40000000000001, 20.000000000000014, 177.7999999999999, -243.40000000000003, -14.19999999999996, 180.20000000000002, -42.09999999999997, -149.5, -2.8000000000000296, -53.79999999999996, -119.80000000000003, 15.799999999999963, -37.0, 92.8999999999995, -237.3999999999999, -95.49999999999999, -101.20000000000003, -171.70000000000007, 57.20000000000001, -71.49999999999994, 187.39999999999995, 181.99999999999991, -131.80000000000018, -217.30000000000007, -88.30000000000018, -358.29999999999984, -246.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -346.9, 187.1, -30.999999999999993, 20.000000000000014, 164.89999999999986, 120.79999999999991, 190.09999999999997, 92.89999999999995, 20.000000000000014, 20.000000000000014, 154.0999999999998, 144.19999999999968, 20.000000000000014, 165.79999999999984, 179.2999999999999, 70.39999999999975, -39.69999999999998, -226.6000000000002, -9.400000000000006, -141.70000000000002, -85.60000000000022, 13.699999999999964, 45.20000000000002, -30.699999999999868, 157.09999999999985, 20.000000000000014, 70.09999999999975, -131.8, 17.899999999999988, -52.300000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -136.6, 112.10000000000001, -78.4, 20.000000000000014, 20.000000000000014, 190.09999999999997, 11.599999999999964, -89.20000000000005, 20.000000000000014, -344.19999999999993, 20.000000000000014, 188.3, 20.000000000000014, -118.60000000000005, -352.29999999999995, -103.30000000000003, 13.699999999999966, -142.6, -310.90000000000003, 5.299999999999965, -13.000000000000021, -168.70000000000002, -255.40000000000003, -237.40000000000012, 196.39999999999998, -177.40000000000003, -259.90000000000003, -61.30000000000009, -375.40000000000003, 20.000000000000014, 125.6, 20.000000000000014, -272.7999999999997, -225.10000000000002, -76.0, -303.4, -386.79999999999995, -35.800000000000004, 199.1, 20.000000000000014, 7.399999999999965, -345.70000000000005, -81.39999999999982, -58.600000000000016, 20.000000000000014, -257.2, 171.5, -264.9999999999999, -338.5, -127.30000000000038, -58.30000000000004, -285.1, -34.299999999999805, -106.9, 177.49999999999991, -1.9000000000000057, -289.30000000000007, -371.19999999999993, 39.50000000000006, 20.000000000000014, -195.4, 16.099999999999994, 20.000000000000014, 20.000000000000014, 196.39999999999998, -261.1, 20.000000000000014, -241.6, -266.5, 152.6, 20.000000000000014, 195.49999999999997, -39.70000000000002, 20.000000000000014, -142.0, -332.19999999999993, -289.5999999999999, -235.60000000000002, -315.70000000000005, -210.4, -44.50000000000004, -31.599999999999994, 20.000000000000014, -214.9, 163.1, -9.40000000000005, -125.80000000000021, 106.1, -45.099999999999966, 53.89999999999995, -256.9, -64.6, -345.4, -138.99999999999997, -101.8000000000001, 20.000000000000014, 20.000000000000014, -200.8, -4.3000000000000265, -367.0, -5.2000000000000455, 20.000000000000014, -333.10000000000014, 20.000000000000014, 183.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -373.0, -276.7, -235.6, 113.89999999999995, -60.099999999999994, 20.000000000000014, -212.20000000000005], "policy_predator_policy_reward": [77.0, 58.0, 8.0, 9.0, 0.0, 0.0, 0.0, 136.0, 2.0, 87.0, 23.0, 39.0, 111.0, 20.0, 0.0, 0.0, 162.0, 113.0, 34.0, 38.0, 47.0, 0.0, 0.0, 145.0, 0.0, 42.0, 1.0, 113.0, 39.0, 29.0, 0.0, 105.0, 0.0, 85.0, 51.0, 172.0, 0.0, 144.0, 20.0, 77.0, 0.0, 0.0, 112.0, 149.0, 183.0, 136.0, 133.0, 7.0, 0.0, 0.0, 172.0, 137.0, 24.0, 17.0, 3.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.0, 118.0, 62.0, 72.0, 58.0, 0.0, 34.0, 83.0, 5.0, 0.0, 99.0, 0.0, 25.0, 16.0, 0.0, 0.0, 0.0, 0.0, 36.0, 108.0, 35.0, 88.0, 0.0, 0.0, 4.0, 52.0, 171.0, 144.0, 0.0, 0.0, 13.0, 60.0, 179.0, 131.0, 89.0, 90.0, 157.0, 102.0, 6.0, 161.0, 11.0, 175.0, 0.0, 121.0, 7.0, 172.0, 180.0, 168.0, 23.0, 0.0, 122.0, 133.0, 155.0, 99.0, 189.0, 179.0, 0.0, 0.0, 142.0, 180.0, 25.0, 105.0, 147.0, 0.0, 85.0, 135.0, 104.0, 178.0, 164.0, 0.0, 25.0, 107.0, 0.0, 67.0, 181.0, 187.0, 0.0, 4.0, 83.0, 146.0, 0.0, 0.0, 143.0, 26.0, 131.0, 101.0, 136.0, 122.0, 0.0, 0.0, 0.0, 79.0, 163.0, 120.0, 130.0, 193.0, 193.0, 183.0, 19.0, 89.0, 117.0, 128.0, 14.0, 12.0, 95.0, 85.0, 55.0, 31.0, 75.0, 184.0, 173.0, 176.0, 37.0, 43.0, 96.0, 91.0, 161.0, 180.0, 4.0, 12.0, 87.0, 163.0, 0.0, 0.0, 0.0, 0.0, 139.0, 163.0, 184.0, 136.0, 99.0, 61.0, 0.0, 135.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7166651354770401, "mean_inference_ms": 1.9280144172198725, "mean_action_processing_ms": 0.2984824502471094, "mean_env_wait_ms": 0.2591343323867216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0051000118255615234, "StateBufferConnector_ms": 0.003907203674316406, "ViewRequirementAgentConnector_ms": 0.19785237312316895}, "num_episodes": 18, "episode_return_max": 369.4000000000002, "episode_return_min": -306.79999999999995, "episode_return_mean": 28.31199999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 255.99759377261714, "num_env_steps_trained_throughput_per_sec": 255.99759377261714, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 16267.802, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16267.737, "sample_time_ms": 2249.195, "learn_time_ms": 13996.655, "learn_throughput": 285.783, "synch_weights_time_ms": 17.16}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "04dec_00002", "date": "2024-08-13_16-40-05", "timestamp": 1723581605, "time_this_iter_s": 15.701331853866577, "time_total_s": 1036.753553390503, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04ccdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1036.753553390503, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 85.52173913043477, "ram_util_percent": 84.01739130434783}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2050674589301544, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 0.00010000000000000003, "total_loss": 7.052907488333485, "policy_loss": -0.001653649120359982, "vf_loss": 7.054176304580043, "vf_explained_var": -0.0012548319561771614, "kl": 0.0054056263697179465, "entropy": 0.5761656441701153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.54845845973681, "cur_kl_coeff": 0.0675762176513672, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": -0.002984841086867231, "vf_loss": 7.321355095363798, "vf_explained_var": -0.08682176108082766, "kl": Infinity, "entropy": 0.6993121041507318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 369.4000000000002, "episode_reward_min": -338.2999999999996, "episode_reward_mean": 28.392999999999926, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -59.79850000000002, "predator_policy": 73.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-128.90000000000012, 82.7, 369.4000000000002, -88.1, -127.6000000000002, -86.10000000000002, 40.0000000000003, 149.19999999999996, 30.000000000000057, 288.69999999999993, 299.0, 40.0000000000003, 298.3000000000018, 185.79999999999913, 249.69999999999908, -50.29999999999994, -17.09999999999996, -13.899999999999908, 131.49999999999983, 182.09999999999917, 37.29999999999933, 6.599999999999998, 40.0000000000003, 40.0000000000003, 119.4999999999998, 64.60000000000008, 210.09999999999923, -21.599999999999902, -9.199999999999996, 208.29999999999933, -25.599999999999945, -145.5999999999999, 50.09999999999985, -46.59999999999976, -14.699999999999967, -306.79999999999995, 139.99999999999997, -142.20000000000002, -7.40000000000002, 168.59999999999954, -242.90000000000015, -125.40000000000006, -54.6, 219.09999999999926, -16.299999999999983, -10.000000000000224, -90.20000000000005, 126.49999999999994, -183.80000000000038, -179.40000000000006, -9.200000000000323, 242.59999999999994, -292.5000000000001, 63.50000000000025, 49.70000000000012, 40.0000000000003, 104.29999999999998, 10.400000000000041, 144.10000000000002, 215.49999999999923, 59.30000000000019, -191.2000000000001, -202.20000000000005, -150.10000000000002, 31.900000000000077, 50.100000000000044, 179.69999999999945, 160.29999999999967, 94.79999999999939, -62.499999999999986, -135.4, -1.8000000000000522, 6.199999999999939, -30.300000000000033, 30.80000000000028, -63.10000000000042, 203.7999999999993, 40.0000000000003, -50.99999999999978, -192.3, 213.79999999999993, -57.199999999999825, 40.0000000000003, 212.6, 40.0000000000003, -192.79999999999998, -60.89999999999981, 213.69999999999925, 5.899999999999947, -338.2999999999996, 131.0999999999999, 173.59999999999997, 61.599999999999106, 106.29999999999995, 14.90000000000003, 46.199999999999974, 21.70000000000003, 56.50000000000002, 95.19999999999987, 67.20000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-101.20000000000003, -171.70000000000007, 57.20000000000001, -71.49999999999994, 187.39999999999995, 181.99999999999991, -131.80000000000018, -217.30000000000007, -88.30000000000018, -358.29999999999984, -246.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -346.9, 187.1, -30.999999999999993, 20.000000000000014, 164.89999999999986, 120.79999999999991, 190.09999999999997, 92.89999999999995, 20.000000000000014, 20.000000000000014, 154.0999999999998, 144.19999999999968, 20.000000000000014, 165.79999999999984, 179.2999999999999, 70.39999999999975, -39.69999999999998, -226.6000000000002, -9.400000000000006, -141.70000000000002, -85.60000000000022, 13.699999999999964, 45.20000000000002, -30.699999999999868, 157.09999999999985, 20.000000000000014, 70.09999999999975, -131.8, 17.899999999999988, -52.300000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -136.6, 112.10000000000001, -78.4, 20.000000000000014, 20.000000000000014, 190.09999999999997, 11.599999999999964, -89.20000000000005, 20.000000000000014, -344.19999999999993, 20.000000000000014, 188.3, 20.000000000000014, -118.60000000000005, -352.29999999999995, -103.30000000000003, 13.699999999999966, -142.6, -310.90000000000003, 5.299999999999965, -13.000000000000021, -168.70000000000002, -255.40000000000003, -237.40000000000012, 196.39999999999998, -177.40000000000003, -259.90000000000003, -61.30000000000009, -375.40000000000003, 20.000000000000014, 125.6, 20.000000000000014, -272.7999999999997, -225.10000000000002, -76.0, -303.4, -386.79999999999995, -35.800000000000004, 199.1, 20.000000000000014, 7.399999999999965, -345.70000000000005, -81.39999999999982, -58.600000000000016, 20.000000000000014, -257.2, 171.5, -264.9999999999999, -338.5, -127.30000000000038, -58.30000000000004, -285.1, -34.299999999999805, -106.9, 177.49999999999991, -1.9000000000000057, -289.30000000000007, -371.19999999999993, 39.50000000000006, 20.000000000000014, -195.4, 16.099999999999994, 20.000000000000014, 20.000000000000014, 196.39999999999998, -261.1, 20.000000000000014, -241.6, -266.5, 152.6, 20.000000000000014, 195.49999999999997, -39.70000000000002, 20.000000000000014, -142.0, -332.19999999999993, -289.5999999999999, -235.60000000000002, -315.70000000000005, -210.4, -44.50000000000004, -31.599999999999994, 20.000000000000014, -214.9, 163.1, -9.40000000000005, -125.80000000000021, 106.1, -45.099999999999966, 53.89999999999995, -256.9, -64.6, -345.4, -138.99999999999997, -101.8000000000001, 20.000000000000014, 20.000000000000014, -200.8, -4.3000000000000265, -367.0, -5.2000000000000455, 20.000000000000014, -333.10000000000014, 20.000000000000014, 183.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -373.0, -276.7, -235.6, 113.89999999999995, -60.099999999999994, 20.000000000000014, -212.20000000000005, 20.000000000000014, 20.000000000000014, -8.200000000000031, 102.80000000000001, 20.000000000000014, 20.000000000000014, -227.5000000000003, -97.30000000000001, -241.90000000000003, 20.000000000000014, 193.7, 20.000000000000014, -146.2, 1.0999999999999865, -265.9000000000001, -330.40000000000003, 161.29999999999987, -359.20000000000005, -20.5, 16.1, -12.40000000000019, 20.000000000000014, 149.29999999999987, -250.00000000000003, -159.10000000000002, 20.000000000000014, -19.60000000000001, -113.20000000000005, 41.3, -328.60000000000014, 20.000000000000014, -59.500000000000014, 20.000000000000014, -62.80000000000007, -98.79999999999998, 20.000000000000014], "policy_predator_policy_reward": [0.0, 144.0, 20.0, 77.0, 0.0, 0.0, 112.0, 149.0, 183.0, 136.0, 133.0, 7.0, 0.0, 0.0, 172.0, 137.0, 24.0, 17.0, 3.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.0, 118.0, 62.0, 72.0, 58.0, 0.0, 34.0, 83.0, 5.0, 0.0, 99.0, 0.0, 25.0, 16.0, 0.0, 0.0, 0.0, 0.0, 36.0, 108.0, 35.0, 88.0, 0.0, 0.0, 4.0, 52.0, 171.0, 144.0, 0.0, 0.0, 13.0, 60.0, 179.0, 131.0, 89.0, 90.0, 157.0, 102.0, 6.0, 161.0, 11.0, 175.0, 0.0, 121.0, 7.0, 172.0, 180.0, 168.0, 23.0, 0.0, 122.0, 133.0, 155.0, 99.0, 189.0, 179.0, 0.0, 0.0, 142.0, 180.0, 25.0, 105.0, 147.0, 0.0, 85.0, 135.0, 104.0, 178.0, 164.0, 0.0, 25.0, 107.0, 0.0, 67.0, 181.0, 187.0, 0.0, 4.0, 83.0, 146.0, 0.0, 0.0, 143.0, 26.0, 131.0, 101.0, 136.0, 122.0, 0.0, 0.0, 0.0, 79.0, 163.0, 120.0, 130.0, 193.0, 193.0, 183.0, 19.0, 89.0, 117.0, 128.0, 14.0, 12.0, 95.0, 85.0, 55.0, 31.0, 75.0, 184.0, 173.0, 176.0, 37.0, 43.0, 96.0, 91.0, 161.0, 180.0, 4.0, 12.0, 87.0, 163.0, 0.0, 0.0, 0.0, 0.0, 139.0, 163.0, 184.0, 136.0, 99.0, 61.0, 0.0, 135.0, 0.0, 0.0, 34.0, 84.0, 0.0, 0.0, 0.0, 132.0, 49.0, 112.0, 0.0, 0.0, 66.0, 85.0, 195.0, 63.0, 156.0, 173.0, 90.0, 88.0, 54.0, 0.0, 81.0, 126.0, 83.0, 71.0, 80.0, 99.0, 166.0, 143.0, 55.0, 41.0, 79.0, 59.0, 58.0, 88.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.719512634638862, "mean_inference_ms": 1.9386379776259293, "mean_action_processing_ms": 0.29922621618248973, "mean_env_wait_ms": 0.26012975847784015, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00930774211883545, "StateBufferConnector_ms": 0.0038182735443115234, "ViewRequirementAgentConnector_ms": 0.1933426856994629}, "num_episodes": 18, "episode_return_max": 369.4000000000002, "episode_return_min": -338.2999999999996, "episode_return_mean": 28.392999999999926, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 258.17082760758376, "num_env_steps_trained_throughput_per_sec": 258.17082760758376, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 16718.167, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16718.098, "sample_time_ms": 2339.85, "learn_time_ms": 14355.812, "learn_throughput": 278.633, "synch_weights_time_ms": 17.733}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "04dec_00002", "date": "2024-08-13_16-40-21", "timestamp": 1723581621, "time_this_iter_s": 15.569687128067017, "time_total_s": 1052.32324051857, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0441550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1052.32324051857, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 84.41818181818182, "ram_util_percent": 82.38636363636364}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1810616605338595, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 0.00010000000000000003, "total_loss": 5.396819302896974, "policy_loss": -0.0010924965140739918, "vf_loss": 5.397630573202062, "vf_explained_var": -0.0020148471865073713, "kl": 0.003950174201925912, "entropy": 0.6054543952147166, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.34545573462885, "cur_kl_coeff": 0.10136432647705075, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": -6.288159121241835e-05, "vf_loss": 8.183992925018229, "vf_explained_var": 0.24740811277318883, "kl": Infinity, "entropy": 0.6958978336008769, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 393.70000000000005, "episode_reward_min": -338.2999999999996, "episode_reward_mean": 23.22999999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -63.775000000000006, "predator_policy": 75.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, 119.4999999999998, 64.60000000000008, 210.09999999999923, -21.599999999999902, -9.199999999999996, 208.29999999999933, -25.599999999999945, -145.5999999999999, 50.09999999999985, -46.59999999999976, -14.699999999999967, -306.79999999999995, 139.99999999999997, -142.20000000000002, -7.40000000000002, 168.59999999999954, -242.90000000000015, -125.40000000000006, -54.6, 219.09999999999926, -16.299999999999983, -10.000000000000224, -90.20000000000005, 126.49999999999994, -183.80000000000038, -179.40000000000006, -9.200000000000323, 242.59999999999994, -292.5000000000001, 63.50000000000025, 49.70000000000012, 40.0000000000003, 104.29999999999998, 10.400000000000041, 144.10000000000002, 215.49999999999923, 59.30000000000019, -191.2000000000001, -202.20000000000005, -150.10000000000002, 31.900000000000077, 50.100000000000044, 179.69999999999945, 160.29999999999967, 94.79999999999939, -62.499999999999986, -135.4, -1.8000000000000522, 6.199999999999939, -30.300000000000033, 30.80000000000028, -63.10000000000042, 203.7999999999993, 40.0000000000003, -50.99999999999978, -192.3, 213.79999999999993, -57.199999999999825, 40.0000000000003, 212.6, 40.0000000000003, -192.79999999999998, -60.89999999999981, 213.69999999999925, 5.899999999999947, -338.2999999999996, 131.0999999999999, 173.59999999999997, 61.599999999999106, 106.29999999999995, 14.90000000000003, 46.199999999999974, 21.70000000000003, 56.50000000000002, 95.19999999999987, 67.20000000000013, -28.99999999999975, 7.500000000000194, 199.39999999999995, 145.19999999999962, 14.10000000000002, 185.79999999999927, 4.399999999999908, -82.89999999999999, 174.49999999999935, -64.30000000000001, -27.599999999999774, -26.20000000000001, 128.99999999999983, 393.70000000000005, 170.6999999999994, -7.899999999999796, 40.0000000000003, 185.3999999999993, 127.49999999999952, -160.80000000000024, 82.90000000000009, -99.40000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -136.6, 112.10000000000001, -78.4, 20.000000000000014, 20.000000000000014, 190.09999999999997, 11.599999999999964, -89.20000000000005, 20.000000000000014, -344.19999999999993, 20.000000000000014, 188.3, 20.000000000000014, -118.60000000000005, -352.29999999999995, -103.30000000000003, 13.699999999999966, -142.6, -310.90000000000003, 5.299999999999965, -13.000000000000021, -168.70000000000002, -255.40000000000003, -237.40000000000012, 196.39999999999998, -177.40000000000003, -259.90000000000003, -61.30000000000009, -375.40000000000003, 20.000000000000014, 125.6, 20.000000000000014, -272.7999999999997, -225.10000000000002, -76.0, -303.4, -386.79999999999995, -35.800000000000004, 199.1, 20.000000000000014, 7.399999999999965, -345.70000000000005, -81.39999999999982, -58.600000000000016, 20.000000000000014, -257.2, 171.5, -264.9999999999999, -338.5, -127.30000000000038, -58.30000000000004, -285.1, -34.299999999999805, -106.9, 177.49999999999991, -1.9000000000000057, -289.30000000000007, -371.19999999999993, 39.50000000000006, 20.000000000000014, -195.4, 16.099999999999994, 20.000000000000014, 20.000000000000014, 196.39999999999998, -261.1, 20.000000000000014, -241.6, -266.5, 152.6, 20.000000000000014, 195.49999999999997, -39.70000000000002, 20.000000000000014, -142.0, -332.19999999999993, -289.5999999999999, -235.60000000000002, -315.70000000000005, -210.4, -44.50000000000004, -31.599999999999994, 20.000000000000014, -214.9, 163.1, -9.40000000000005, -125.80000000000021, 106.1, -45.099999999999966, 53.89999999999995, -256.9, -64.6, -345.4, -138.99999999999997, -101.8000000000001, 20.000000000000014, 20.000000000000014, -200.8, -4.3000000000000265, -367.0, -5.2000000000000455, 20.000000000000014, -333.10000000000014, 20.000000000000014, 183.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -373.0, -276.7, -235.6, 113.89999999999995, -60.099999999999994, 20.000000000000014, -212.20000000000005, 20.000000000000014, 20.000000000000014, -8.200000000000031, 102.80000000000001, 20.000000000000014, 20.000000000000014, -227.5000000000003, -97.30000000000001, -241.90000000000003, 20.000000000000014, 193.7, 20.000000000000014, -146.2, 1.0999999999999865, -265.9000000000001, -330.40000000000003, 161.29999999999987, -359.20000000000005, -20.5, 16.1, -12.40000000000019, 20.000000000000014, 149.29999999999987, -250.00000000000003, -159.10000000000002, 20.000000000000014, -19.60000000000001, -113.20000000000005, 41.3, -328.60000000000014, 20.000000000000014, -59.500000000000014, 20.000000000000014, -62.80000000000007, -98.79999999999998, 20.000000000000014, -292.0, 20.000000000000014, 20.000000000000014, -44.500000000000014, -169.89999999999998, 185.29999999999995, 20.000000000000014, 84.2, -36.39999999999995, -35.50000000000003, 20.000000000000014, 165.79999999999993, -97.60000000000005, 20.000000000000014, 20.000000000000007, -301.90000000000003, 147.49999999999994, 20.000000000000014, -148.3, -181.00000000000003, -17.800000000000026, -38.80000000000004, -42.099999999999845, -108.10000000000005, 181.99999999999994, -288.9999999999997, 194.59999999999997, 199.1, 178.39999999999986, -78.69999999999996, -26.200000000000024, -36.700000000000045, 20.000000000000014, 20.000000000000014, 15.799999999999953, 167.59999999999994, 97.09999999999997, -34.600000000000044, -160.90000000000023, -274.9, -147.99999999999983, 26.89999999999997, -95.49999999999991, -82.90000000000005], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 36.0, 108.0, 35.0, 88.0, 0.0, 0.0, 4.0, 52.0, 171.0, 144.0, 0.0, 0.0, 13.0, 60.0, 179.0, 131.0, 89.0, 90.0, 157.0, 102.0, 6.0, 161.0, 11.0, 175.0, 0.0, 121.0, 7.0, 172.0, 180.0, 168.0, 23.0, 0.0, 122.0, 133.0, 155.0, 99.0, 189.0, 179.0, 0.0, 0.0, 142.0, 180.0, 25.0, 105.0, 147.0, 0.0, 85.0, 135.0, 104.0, 178.0, 164.0, 0.0, 25.0, 107.0, 0.0, 67.0, 181.0, 187.0, 0.0, 4.0, 83.0, 146.0, 0.0, 0.0, 143.0, 26.0, 131.0, 101.0, 136.0, 122.0, 0.0, 0.0, 0.0, 79.0, 163.0, 120.0, 130.0, 193.0, 193.0, 183.0, 19.0, 89.0, 117.0, 128.0, 14.0, 12.0, 95.0, 85.0, 55.0, 31.0, 75.0, 184.0, 173.0, 176.0, 37.0, 43.0, 96.0, 91.0, 161.0, 180.0, 4.0, 12.0, 87.0, 163.0, 0.0, 0.0, 0.0, 0.0, 139.0, 163.0, 184.0, 136.0, 99.0, 61.0, 0.0, 135.0, 0.0, 0.0, 34.0, 84.0, 0.0, 0.0, 0.0, 132.0, 49.0, 112.0, 0.0, 0.0, 66.0, 85.0, 195.0, 63.0, 156.0, 173.0, 90.0, 88.0, 54.0, 0.0, 81.0, 126.0, 83.0, 71.0, 80.0, 99.0, 166.0, 143.0, 55.0, 41.0, 79.0, 59.0, 58.0, 88.0, 134.0, 109.0, 0.0, 32.0, 90.0, 94.0, 28.0, 13.0, 86.0, 0.0, 0.0, 0.0, 41.0, 41.0, 14.0, 185.0, 0.0, 7.0, 115.0, 150.0, 0.0, 29.0, 71.0, 53.0, 114.0, 122.0, 0.0, 0.0, 29.0, 42.0, 32.0, 23.0, 0.0, 0.0, 0.0, 2.0, 41.0, 24.0, 170.0, 105.0, 110.0, 94.0, 3.0, 76.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7242443744839226, "mean_inference_ms": 1.9544318509793661, "mean_action_processing_ms": 0.3005506994470468, "mean_env_wait_ms": 0.2617135551421127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009291410446166992, "StateBufferConnector_ms": 0.003603339195251465, "ViewRequirementAgentConnector_ms": 0.1927562952041626}, "num_episodes": 22, "episode_return_max": 393.70000000000005, "episode_return_min": -338.2999999999996, "episode_return_mean": 23.22999999999992, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 258.41513023673014, "num_env_steps_trained_throughput_per_sec": 258.41513023673014, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 16527.457, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16527.389, "sample_time_ms": 2462.991, "learn_time_ms": 14042.577, "learn_throughput": 284.848, "synch_weights_time_ms": 17.032}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "04dec_00002", "date": "2024-08-13_16-40-36", "timestamp": 1723581636, "time_this_iter_s": 15.545546054840088, "time_total_s": 1067.86878657341, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3587ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1067.86878657341, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 77.69090909090909, "ram_util_percent": 84.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2984174672021438, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 0.00010000000000000003, "total_loss": 5.75553516458582, "policy_loss": -0.001903952751801443, "vf_loss": 5.75730098492254, "vf_explained_var": -0.0004377345874826744, "kl": 0.003880032243990971, "entropy": 0.6111624984514146, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 30.716973241422544, "cur_kl_coeff": 0.15204648971557616, "cur_lr": 0.00010000000000000003, "total_loss": 6.647845753664693, "policy_loss": -0.0028736846461749226, "vf_loss": 6.649426297283677, "vf_explained_var": -0.01690650084031322, "kl": 0.008505103031035681, "entropy": 0.750274842945987, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 393.70000000000005, "episode_reward_min": -338.2999999999996, "episode_reward_mean": 35.4179999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -53.776000000000025, "predator_policy": 71.485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-242.90000000000015, -125.40000000000006, -54.6, 219.09999999999926, -16.299999999999983, -10.000000000000224, -90.20000000000005, 126.49999999999994, -183.80000000000038, -179.40000000000006, -9.200000000000323, 242.59999999999994, -292.5000000000001, 63.50000000000025, 49.70000000000012, 40.0000000000003, 104.29999999999998, 10.400000000000041, 144.10000000000002, 215.49999999999923, 59.30000000000019, -191.2000000000001, -202.20000000000005, -150.10000000000002, 31.900000000000077, 50.100000000000044, 179.69999999999945, 160.29999999999967, 94.79999999999939, -62.499999999999986, -135.4, -1.8000000000000522, 6.199999999999939, -30.300000000000033, 30.80000000000028, -63.10000000000042, 203.7999999999993, 40.0000000000003, -50.99999999999978, -192.3, 213.79999999999993, -57.199999999999825, 40.0000000000003, 212.6, 40.0000000000003, -192.79999999999998, -60.89999999999981, 213.69999999999925, 5.899999999999947, -338.2999999999996, 131.0999999999999, 173.59999999999997, 61.599999999999106, 106.29999999999995, 14.90000000000003, 46.199999999999974, 21.70000000000003, 56.50000000000002, 95.19999999999987, 67.20000000000013, -28.99999999999975, 7.500000000000194, 199.39999999999995, 145.19999999999962, 14.10000000000002, 185.79999999999927, 4.399999999999908, -82.89999999999999, 174.49999999999935, -64.30000000000001, -27.599999999999774, -26.20000000000001, 128.99999999999983, 393.70000000000005, 170.6999999999994, -7.899999999999796, 40.0000000000003, 185.3999999999993, 127.49999999999952, -160.80000000000024, 82.90000000000009, -99.40000000000018, 169.59999999999945, -3.900000000000027, 9.300000000000086, 40.0000000000003, 37.40000000000017, -45.19999999999988, 13.599999999999998, 55.30000000000008, 123.89999999999978, 129.59999999999945, 145.8999999999996, 79.2999999999999, 179.79999999999998, 56.000000000000156, 192.09999999999923, 27.90000000000011, 178.39999999999918, 151.29999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-272.7999999999997, -225.10000000000002, -76.0, -303.4, -386.79999999999995, -35.800000000000004, 199.1, 20.000000000000014, 7.399999999999965, -345.70000000000005, -81.39999999999982, -58.600000000000016, 20.000000000000014, -257.2, 171.5, -264.9999999999999, -338.5, -127.30000000000038, -58.30000000000004, -285.1, -34.299999999999805, -106.9, 177.49999999999991, -1.9000000000000057, -289.30000000000007, -371.19999999999993, 39.50000000000006, 20.000000000000014, -195.4, 16.099999999999994, 20.000000000000014, 20.000000000000014, 196.39999999999998, -261.1, 20.000000000000014, -241.6, -266.5, 152.6, 20.000000000000014, 195.49999999999997, -39.70000000000002, 20.000000000000014, -142.0, -332.19999999999993, -289.5999999999999, -235.60000000000002, -315.70000000000005, -210.4, -44.50000000000004, -31.599999999999994, 20.000000000000014, -214.9, 163.1, -9.40000000000005, -125.80000000000021, 106.1, -45.099999999999966, 53.89999999999995, -256.9, -64.6, -345.4, -138.99999999999997, -101.8000000000001, 20.000000000000014, 20.000000000000014, -200.8, -4.3000000000000265, -367.0, -5.2000000000000455, 20.000000000000014, -333.10000000000014, 20.000000000000014, 183.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -373.0, -276.7, -235.6, 113.89999999999995, -60.099999999999994, 20.000000000000014, -212.20000000000005, 20.000000000000014, 20.000000000000014, -8.200000000000031, 102.80000000000001, 20.000000000000014, 20.000000000000014, -227.5000000000003, -97.30000000000001, -241.90000000000003, 20.000000000000014, 193.7, 20.000000000000014, -146.2, 1.0999999999999865, -265.9000000000001, -330.40000000000003, 161.29999999999987, -359.20000000000005, -20.5, 16.1, -12.40000000000019, 20.000000000000014, 149.29999999999987, -250.00000000000003, -159.10000000000002, 20.000000000000014, -19.60000000000001, -113.20000000000005, 41.3, -328.60000000000014, 20.000000000000014, -59.500000000000014, 20.000000000000014, -62.80000000000007, -98.79999999999998, 20.000000000000014, -292.0, 20.000000000000014, 20.000000000000014, -44.500000000000014, -169.89999999999998, 185.29999999999995, 20.000000000000014, 84.2, -36.39999999999995, -35.50000000000003, 20.000000000000014, 165.79999999999993, -97.60000000000005, 20.000000000000014, 20.000000000000007, -301.90000000000003, 147.49999999999994, 20.000000000000014, -148.3, -181.00000000000003, -17.800000000000026, -38.80000000000004, -42.099999999999845, -108.10000000000005, 181.99999999999994, -288.9999999999997, 194.59999999999997, 199.1, 178.39999999999986, -78.69999999999996, -26.200000000000024, -36.700000000000045, 20.000000000000014, 20.000000000000014, 15.799999999999953, 167.59999999999994, 97.09999999999997, -34.600000000000044, -160.90000000000023, -274.9, -147.99999999999983, 26.89999999999997, -95.49999999999991, -82.90000000000005, 149.59999999999997, 20.000000000000014, 20.000000000000014, -184.90000000000023, -186.70000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -181.6, 20.000000000000014, -99.1, -150.1000000000002, 5.299999999999965, -15.699999999999761, -145.90000000000023, 12.200000000000003, 149.29999999999993, -150.40000000000015, 7.399999999999965, 57.19999999999999, -69.10000000000002, 154.99999999999994, 20.000000000000014, -99.70000000000002, 24.80000000000001, 50.0, -46.0, 20.000000000000014, 172.0999999999999, 20.000000000000014, 20.000000000000014, -3.099999999999958, 17.899999999999988, 159.49999999999986, -99.70000000000002, 110.0], "policy_predator_policy_reward": [122.0, 133.0, 155.0, 99.0, 189.0, 179.0, 0.0, 0.0, 142.0, 180.0, 25.0, 105.0, 147.0, 0.0, 85.0, 135.0, 104.0, 178.0, 164.0, 0.0, 25.0, 107.0, 0.0, 67.0, 181.0, 187.0, 0.0, 4.0, 83.0, 146.0, 0.0, 0.0, 143.0, 26.0, 131.0, 101.0, 136.0, 122.0, 0.0, 0.0, 0.0, 79.0, 163.0, 120.0, 130.0, 193.0, 193.0, 183.0, 19.0, 89.0, 117.0, 128.0, 14.0, 12.0, 95.0, 85.0, 55.0, 31.0, 75.0, 184.0, 173.0, 176.0, 37.0, 43.0, 96.0, 91.0, 161.0, 180.0, 4.0, 12.0, 87.0, 163.0, 0.0, 0.0, 0.0, 0.0, 139.0, 163.0, 184.0, 136.0, 99.0, 61.0, 0.0, 135.0, 0.0, 0.0, 34.0, 84.0, 0.0, 0.0, 0.0, 132.0, 49.0, 112.0, 0.0, 0.0, 66.0, 85.0, 195.0, 63.0, 156.0, 173.0, 90.0, 88.0, 54.0, 0.0, 81.0, 126.0, 83.0, 71.0, 80.0, 99.0, 166.0, 143.0, 55.0, 41.0, 79.0, 59.0, 58.0, 88.0, 134.0, 109.0, 0.0, 32.0, 90.0, 94.0, 28.0, 13.0, 86.0, 0.0, 0.0, 0.0, 41.0, 41.0, 14.0, 185.0, 0.0, 7.0, 115.0, 150.0, 0.0, 29.0, 71.0, 53.0, 114.0, 122.0, 0.0, 0.0, 29.0, 42.0, 32.0, 23.0, 0.0, 0.0, 0.0, 2.0, 41.0, 24.0, 170.0, 105.0, 110.0, 94.0, 3.0, 76.0, 0.0, 0.0, 73.0, 88.0, 58.0, 118.0, 0.0, 0.0, 80.0, 119.0, 129.0, 75.0, 17.0, 7.0, 99.0, 90.0, 75.0, 50.0, 24.0, 41.0, 0.0, 60.0, 92.0, 67.0, 36.0, 69.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 1.0, 69.0, 72.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.730020026097832, "mean_inference_ms": 1.9721780398406157, "mean_action_processing_ms": 0.3023013851509344, "mean_env_wait_ms": 0.2635420377826826, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009859204292297363, "StateBufferConnector_ms": 0.0035550594329833984, "ViewRequirementAgentConnector_ms": 0.21585440635681152}, "num_episodes": 18, "episode_return_max": 393.70000000000005, "episode_return_min": -338.2999999999996, "episode_return_mean": 35.4179999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 248.94704855980785, "num_env_steps_trained_throughput_per_sec": 248.94704855980785, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 16454.12, "restore_workers_time_ms": 0.02, "training_step_time_ms": 16454.056, "sample_time_ms": 2559.48, "learn_time_ms": 13871.346, "learn_throughput": 288.364, "synch_weights_time_ms": 18.164}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "04dec_00002", "date": "2024-08-13_16-40-53", "timestamp": 1723581653, "time_this_iter_s": 16.532124996185303, "time_total_s": 1084.4009115695953, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044aca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1084.4009115695953, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 79.51304347826088, "ram_util_percent": 85.12608695652175}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2432734958078495, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 0.00010000000000000003, "total_loss": 5.0407872589807665, "policy_loss": -0.002475778360865892, "vf_loss": 5.043159460390687, "vf_explained_var": 0.00015743100453936864, "kl": 0.005819450646215296, "entropy": 0.5867200486559085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.747495190334067, "cur_kl_coeff": 0.15204648971557616, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": 0.003348272307357066, "vf_loss": 7.22625736685657, "vf_explained_var": 0.3099448536123548, "kl": Infinity, "entropy": 0.713133181812902, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 393.70000000000005, "episode_reward_min": -338.2999999999996, "episode_reward_mean": 64.14399999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -26.84800000000002, "predator_policy": 58.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-150.10000000000002, 31.900000000000077, 50.100000000000044, 179.69999999999945, 160.29999999999967, 94.79999999999939, -62.499999999999986, -135.4, -1.8000000000000522, 6.199999999999939, -30.300000000000033, 30.80000000000028, -63.10000000000042, 203.7999999999993, 40.0000000000003, -50.99999999999978, -192.3, 213.79999999999993, -57.199999999999825, 40.0000000000003, 212.6, 40.0000000000003, -192.79999999999998, -60.89999999999981, 213.69999999999925, 5.899999999999947, -338.2999999999996, 131.0999999999999, 173.59999999999997, 61.599999999999106, 106.29999999999995, 14.90000000000003, 46.199999999999974, 21.70000000000003, 56.50000000000002, 95.19999999999987, 67.20000000000013, -28.99999999999975, 7.500000000000194, 199.39999999999995, 145.19999999999962, 14.10000000000002, 185.79999999999927, 4.399999999999908, -82.89999999999999, 174.49999999999935, -64.30000000000001, -27.599999999999774, -26.20000000000001, 128.99999999999983, 393.70000000000005, 170.6999999999994, -7.899999999999796, 40.0000000000003, 185.3999999999993, 127.49999999999952, -160.80000000000024, 82.90000000000009, -99.40000000000018, 169.59999999999945, -3.900000000000027, 9.300000000000086, 40.0000000000003, 37.40000000000017, -45.19999999999988, 13.599999999999998, 55.30000000000008, 123.89999999999978, 129.59999999999945, 145.8999999999996, 79.2999999999999, 179.79999999999998, 56.000000000000156, 192.09999999999923, 27.90000000000011, 178.39999999999918, 151.29999999999993, -61.399999999999814, 270.8999999999999, 86.40000000000009, 310.4999999999998, 98.49999999999984, 117.0, 35.300000000000104, 25.900000000000013, 267.0999999999999, 28.000000000000107, 318.10000000000025, 207.39999999999918, 165.79999999999924, 28.50000000000025, 35.60000000000029, 22.90000000000002, 3.2000000000000086, 74.10000000000007, 198.39999999999927, 23.00000000000025, 124.3999999999997, 187.49999999999932, -17.199999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-315.70000000000005, -210.4, -44.50000000000004, -31.599999999999994, 20.000000000000014, -214.9, 163.1, -9.40000000000005, -125.80000000000021, 106.1, -45.099999999999966, 53.89999999999995, -256.9, -64.6, -345.4, -138.99999999999997, -101.8000000000001, 20.000000000000014, 20.000000000000014, -200.8, -4.3000000000000265, -367.0, -5.2000000000000455, 20.000000000000014, -333.10000000000014, 20.000000000000014, 183.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -373.0, -276.7, -235.6, 113.89999999999995, -60.099999999999994, 20.000000000000014, -212.20000000000005, 20.000000000000014, 20.000000000000014, -8.200000000000031, 102.80000000000001, 20.000000000000014, 20.000000000000014, -227.5000000000003, -97.30000000000001, -241.90000000000003, 20.000000000000014, 193.7, 20.000000000000014, -146.2, 1.0999999999999865, -265.9000000000001, -330.40000000000003, 161.29999999999987, -359.20000000000005, -20.5, 16.1, -12.40000000000019, 20.000000000000014, 149.29999999999987, -250.00000000000003, -159.10000000000002, 20.000000000000014, -19.60000000000001, -113.20000000000005, 41.3, -328.60000000000014, 20.000000000000014, -59.500000000000014, 20.000000000000014, -62.80000000000007, -98.79999999999998, 20.000000000000014, -292.0, 20.000000000000014, 20.000000000000014, -44.500000000000014, -169.89999999999998, 185.29999999999995, 20.000000000000014, 84.2, -36.39999999999995, -35.50000000000003, 20.000000000000014, 165.79999999999993, -97.60000000000005, 20.000000000000014, 20.000000000000007, -301.90000000000003, 147.49999999999994, 20.000000000000014, -148.3, -181.00000000000003, -17.800000000000026, -38.80000000000004, -42.099999999999845, -108.10000000000005, 181.99999999999994, -288.9999999999997, 194.59999999999997, 199.1, 178.39999999999986, -78.69999999999996, -26.200000000000024, -36.700000000000045, 20.000000000000014, 20.000000000000014, 15.799999999999953, 167.59999999999994, 97.09999999999997, -34.600000000000044, -160.90000000000023, -274.9, -147.99999999999983, 26.89999999999997, -95.49999999999991, -82.90000000000005, 149.59999999999997, 20.000000000000014, 20.000000000000014, -184.90000000000023, -186.70000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -181.6, 20.000000000000014, -99.1, -150.1000000000002, 5.299999999999965, -15.699999999999761, -145.90000000000023, 12.200000000000003, 149.29999999999993, -150.40000000000015, 7.399999999999965, 57.19999999999999, -69.10000000000002, 154.99999999999994, 20.000000000000014, -99.70000000000002, 24.80000000000001, 50.0, -46.0, 20.000000000000014, 172.0999999999999, 20.000000000000014, 20.000000000000014, -3.099999999999958, 17.899999999999988, 159.49999999999986, -99.70000000000002, 110.0, -241.0, 11.599999999999964, 167.3, -6.399999999999999, -40.599999999999966, 20.000000000000014, 162.49999999999994, 136.99999999999986, 30.80000000000001, 13.699999999999964, 104.6, -163.59999999999994, 20.000000000000014, -78.69999999999982, -25.600000000000023, -101.49999999999997, 38.3, 162.79999999999998, 17.899999999999988, 1.0999999999999865, 159.49999999999994, 158.59999999999982, 187.39999999999992, 20.000000000000014, -26.199999999999754, 163.9999999999998, 20.000000000000014, -44.500000000000036, 11.599999999999946, 20.000000000000014, 9.499999999999964, 7.399999999999965, -152.8, 20.000000000000014, 37.4, -241.30000000000007, 20.000000000000014, 178.39999999999998, 20.000000000000014, -199.0, 20.000000000000014, 49.400000000000006, 177.49999999999994, -1.0000000000000369, -89.20000000000024, 20.000000000000014], "policy_predator_policy_reward": [193.0, 183.0, 19.0, 89.0, 117.0, 128.0, 14.0, 12.0, 95.0, 85.0, 55.0, 31.0, 75.0, 184.0, 173.0, 176.0, 37.0, 43.0, 96.0, 91.0, 161.0, 180.0, 4.0, 12.0, 87.0, 163.0, 0.0, 0.0, 0.0, 0.0, 139.0, 163.0, 184.0, 136.0, 99.0, 61.0, 0.0, 135.0, 0.0, 0.0, 34.0, 84.0, 0.0, 0.0, 0.0, 132.0, 49.0, 112.0, 0.0, 0.0, 66.0, 85.0, 195.0, 63.0, 156.0, 173.0, 90.0, 88.0, 54.0, 0.0, 81.0, 126.0, 83.0, 71.0, 80.0, 99.0, 166.0, 143.0, 55.0, 41.0, 79.0, 59.0, 58.0, 88.0, 134.0, 109.0, 0.0, 32.0, 90.0, 94.0, 28.0, 13.0, 86.0, 0.0, 0.0, 0.0, 41.0, 41.0, 14.0, 185.0, 0.0, 7.0, 115.0, 150.0, 0.0, 29.0, 71.0, 53.0, 114.0, 122.0, 0.0, 0.0, 29.0, 42.0, 32.0, 23.0, 0.0, 0.0, 0.0, 2.0, 41.0, 24.0, 170.0, 105.0, 110.0, 94.0, 3.0, 76.0, 0.0, 0.0, 73.0, 88.0, 58.0, 118.0, 0.0, 0.0, 80.0, 119.0, 129.0, 75.0, 17.0, 7.0, 99.0, 90.0, 75.0, 50.0, 24.0, 41.0, 0.0, 60.0, 92.0, 67.0, 36.0, 69.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 1.0, 69.0, 72.0, 19.0, 149.0, 45.0, 65.0, 61.0, 46.0, 5.0, 6.0, 3.0, 51.0, 76.0, 100.0, 44.0, 50.0, 68.0, 85.0, 18.0, 48.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 24.0, 29.0, 0.0, 4.0, 6.0, 0.0, 54.0, 82.0, 116.0, 162.0, 0.0, 0.0, 99.0, 103.0, 13.0, 42.0, 9.0, 2.0, 52.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7381907507158633, "mean_inference_ms": 1.9971489154247433, "mean_action_processing_ms": 0.3051173719554867, "mean_env_wait_ms": 0.26646281554330925, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009787917137145996, "StateBufferConnector_ms": 0.0036399364471435547, "ViewRequirementAgentConnector_ms": 0.22040915489196777}, "num_episodes": 23, "episode_return_max": 393.70000000000005, "episode_return_min": -338.2999999999996, "episode_return_mean": 64.14399999999989, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 259.4778649377645, "num_env_steps_trained_throughput_per_sec": 259.4778649377645, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 15943.335, "restore_workers_time_ms": 0.027, "training_step_time_ms": 15942.641, "sample_time_ms": 2598.647, "learn_time_ms": 13321.743, "learn_throughput": 300.261, "synch_weights_time_ms": 17.907}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "04dec_00002", "date": "2024-08-13_16-41-08", "timestamp": 1723581668, "time_this_iter_s": 15.513521909713745, "time_total_s": 1099.914433479309, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b064b310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1099.914433479309, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 76.82608695652173, "ram_util_percent": 84.7391304347826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4457433914854414, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 0.00010000000000000003, "total_loss": 3.9318227996271125, "policy_loss": -0.002248039704417347, "vf_loss": 3.93396413250575, "vf_explained_var": 0.0006301002212302395, "kl": 0.005995561142967954, "entropy": 0.5637203950415213, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.723728083996544, "cur_kl_coeff": 0.22806973457336432, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": -0.0010853341455379175, "vf_loss": 6.770823573813868, "vf_explained_var": 0.45647185274532864, "kl": Infinity, "entropy": 0.7125709917810228, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 393.70000000000005, "episode_reward_min": -338.2999999999996, "episode_reward_mean": 89.26799999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -359.20000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -2.566000000000022, "predator_policy": 47.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-57.199999999999825, 40.0000000000003, 212.6, 40.0000000000003, -192.79999999999998, -60.89999999999981, 213.69999999999925, 5.899999999999947, -338.2999999999996, 131.0999999999999, 173.59999999999997, 61.599999999999106, 106.29999999999995, 14.90000000000003, 46.199999999999974, 21.70000000000003, 56.50000000000002, 95.19999999999987, 67.20000000000013, -28.99999999999975, 7.500000000000194, 199.39999999999995, 145.19999999999962, 14.10000000000002, 185.79999999999927, 4.399999999999908, -82.89999999999999, 174.49999999999935, -64.30000000000001, -27.599999999999774, -26.20000000000001, 128.99999999999983, 393.70000000000005, 170.6999999999994, -7.899999999999796, 40.0000000000003, 185.3999999999993, 127.49999999999952, -160.80000000000024, 82.90000000000009, -99.40000000000018, 169.59999999999945, -3.900000000000027, 9.300000000000086, 40.0000000000003, 37.40000000000017, -45.19999999999988, 13.599999999999998, 55.30000000000008, 123.89999999999978, 129.59999999999945, 145.8999999999996, 79.2999999999999, 179.79999999999998, 56.000000000000156, 192.09999999999923, 27.90000000000011, 178.39999999999918, 151.29999999999993, -61.399999999999814, 270.8999999999999, 86.40000000000009, 310.4999999999998, 98.49999999999984, 117.0, 35.300000000000104, 25.900000000000013, 267.0999999999999, 28.000000000000107, 318.10000000000025, 207.39999999999918, 165.79999999999924, 28.50000000000025, 35.60000000000029, 22.90000000000002, 3.2000000000000086, 74.10000000000007, 198.39999999999927, 23.00000000000025, 124.3999999999997, 187.49999999999932, -17.199999999999918, 151.59999999999903, 59.29999999999999, 115.99999999999967, 215.89999999999964, 177.69999999999902, 136.19999999999936, 149.29999999999964, 240.6999999999996, 248.89999999999955, 203.19999999999987, 174.89999999999924, 143.49999999999932, 118.29999999999959, 87.20000000000002, 138.1999999999995, 159.99999999999937, 130.6999999999995, 185.69999999999936], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -212.20000000000005, 20.000000000000014, 20.000000000000014, -8.200000000000031, 102.80000000000001, 20.000000000000014, 20.000000000000014, -227.5000000000003, -97.30000000000001, -241.90000000000003, 20.000000000000014, 193.7, 20.000000000000014, -146.2, 1.0999999999999865, -265.9000000000001, -330.40000000000003, 161.29999999999987, -359.20000000000005, -20.5, 16.1, -12.40000000000019, 20.000000000000014, 149.29999999999987, -250.00000000000003, -159.10000000000002, 20.000000000000014, -19.60000000000001, -113.20000000000005, 41.3, -328.60000000000014, 20.000000000000014, -59.500000000000014, 20.000000000000014, -62.80000000000007, -98.79999999999998, 20.000000000000014, -292.0, 20.000000000000014, 20.000000000000014, -44.500000000000014, -169.89999999999998, 185.29999999999995, 20.000000000000014, 84.2, -36.39999999999995, -35.50000000000003, 20.000000000000014, 165.79999999999993, -97.60000000000005, 20.000000000000014, 20.000000000000007, -301.90000000000003, 147.49999999999994, 20.000000000000014, -148.3, -181.00000000000003, -17.800000000000026, -38.80000000000004, -42.099999999999845, -108.10000000000005, 181.99999999999994, -288.9999999999997, 194.59999999999997, 199.1, 178.39999999999986, -78.69999999999996, -26.200000000000024, -36.700000000000045, 20.000000000000014, 20.000000000000014, 15.799999999999953, 167.59999999999994, 97.09999999999997, -34.600000000000044, -160.90000000000023, -274.9, -147.99999999999983, 26.89999999999997, -95.49999999999991, -82.90000000000005, 149.59999999999997, 20.000000000000014, 20.000000000000014, -184.90000000000023, -186.70000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -181.6, 20.000000000000014, -99.1, -150.1000000000002, 5.299999999999965, -15.699999999999761, -145.90000000000023, 12.200000000000003, 149.29999999999993, -150.40000000000015, 7.399999999999965, 57.19999999999999, -69.10000000000002, 154.99999999999994, 20.000000000000014, -99.70000000000002, 24.80000000000001, 50.0, -46.0, 20.000000000000014, 172.0999999999999, 20.000000000000014, 20.000000000000014, -3.099999999999958, 17.899999999999988, 159.49999999999986, -99.70000000000002, 110.0, -241.0, 11.599999999999964, 167.3, -6.399999999999999, -40.599999999999966, 20.000000000000014, 162.49999999999994, 136.99999999999986, 30.80000000000001, 13.699999999999964, 104.6, -163.59999999999994, 20.000000000000014, -78.69999999999982, -25.600000000000023, -101.49999999999997, 38.3, 162.79999999999998, 17.899999999999988, 1.0999999999999865, 159.49999999999994, 158.59999999999982, 187.39999999999992, 20.000000000000014, -26.199999999999754, 163.9999999999998, 20.000000000000014, -44.500000000000036, 11.599999999999946, 20.000000000000014, 9.499999999999964, 7.399999999999965, -152.8, 20.000000000000014, 37.4, -241.30000000000007, 20.000000000000014, 178.39999999999998, 20.000000000000014, -199.0, 20.000000000000014, 49.400000000000006, 177.49999999999994, -1.0000000000000369, -89.20000000000024, 20.000000000000014, 20.000000000000014, 131.5999999999997, 12.2, -106.89999999999992, 20.000000000000014, 10.999999999999998, 79.10000000000002, 111.79999999999995, 20.000000000000014, 157.69999999999976, 51.2, 20.000000000000014, 7.999999999999954, 65.30000000000001, 97.39999999999989, 113.29999999999998, 141.49999999999974, 58.39999999999998, 98.89999999999995, -12.699999999999996, 20.000000000000014, 140.89999999999992, 20.000000000000014, 123.49999999999989, 98.29999999999995, 20.000000000000014, 14.599999999999998, -99.40000000000003, 5.299999999999965, 110.89999999999992, 20.000000000000014, 118.99999999999994, 80.90000000000002, -47.19999999999999, 166.39999999999998, 5.29999999999995], "policy_predator_policy_reward": [0.0, 135.0, 0.0, 0.0, 34.0, 84.0, 0.0, 0.0, 0.0, 132.0, 49.0, 112.0, 0.0, 0.0, 66.0, 85.0, 195.0, 63.0, 156.0, 173.0, 90.0, 88.0, 54.0, 0.0, 81.0, 126.0, 83.0, 71.0, 80.0, 99.0, 166.0, 143.0, 55.0, 41.0, 79.0, 59.0, 58.0, 88.0, 134.0, 109.0, 0.0, 32.0, 90.0, 94.0, 28.0, 13.0, 86.0, 0.0, 0.0, 0.0, 41.0, 41.0, 14.0, 185.0, 0.0, 7.0, 115.0, 150.0, 0.0, 29.0, 71.0, 53.0, 114.0, 122.0, 0.0, 0.0, 29.0, 42.0, 32.0, 23.0, 0.0, 0.0, 0.0, 2.0, 41.0, 24.0, 170.0, 105.0, 110.0, 94.0, 3.0, 76.0, 0.0, 0.0, 73.0, 88.0, 58.0, 118.0, 0.0, 0.0, 80.0, 119.0, 129.0, 75.0, 17.0, 7.0, 99.0, 90.0, 75.0, 50.0, 24.0, 41.0, 0.0, 60.0, 92.0, 67.0, 36.0, 69.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 1.0, 69.0, 72.0, 19.0, 149.0, 45.0, 65.0, 61.0, 46.0, 5.0, 6.0, 3.0, 51.0, 76.0, 100.0, 44.0, 50.0, 68.0, 85.0, 18.0, 48.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 24.0, 29.0, 0.0, 4.0, 6.0, 0.0, 54.0, 82.0, 116.0, 162.0, 0.0, 0.0, 99.0, 103.0, 13.0, 42.0, 9.0, 2.0, 52.0, 0.0, 0.0, 0.0, 122.0, 32.0, 34.0, 51.0, 25.0, 0.0, 0.0, 0.0, 22.0, 43.0, 36.0, 40.0, 18.0, 12.0, 34.0, 15.0, 57.0, 60.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 109.0, 63.0, 0.0, 22.0, 1.0, 20.0, 54.0, 43.0, 6.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7460972978225549, "mean_inference_ms": 2.0203035414619563, "mean_action_processing_ms": 0.3078949088228334, "mean_env_wait_ms": 0.26921019116897094, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009690523147583008, "StateBufferConnector_ms": 0.0035997629165649414, "ViewRequirementAgentConnector_ms": 0.23578011989593506}, "num_episodes": 18, "episode_return_max": 393.70000000000005, "episode_return_min": -338.2999999999996, "episode_return_mean": 89.26799999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 239.96582937449165, "num_env_steps_trained_throughput_per_sec": 239.96582937449165, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 15757.532, "restore_workers_time_ms": 0.025, "training_step_time_ms": 15756.84, "sample_time_ms": 2653.241, "learn_time_ms": 13081.727, "learn_throughput": 305.77, "synch_weights_time_ms": 17.441}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "04dec_00002", "date": "2024-08-13_16-41-25", "timestamp": 1723581685, "time_this_iter_s": 16.69670581817627, "time_total_s": 1116.6111392974854, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c4820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1116.6111392974854, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 76.32173913043476, "ram_util_percent": 85.15217391304348}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5201325503527803, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 0.00010000000000000003, "total_loss": 4.76023951169675, "policy_loss": -0.002675860384774823, "vf_loss": 4.762837424101653, "vf_explained_var": -0.001880071686689185, "kl": 0.004378933246655606, "entropy": 0.5863061773713935, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.95563260736289, "cur_kl_coeff": 0.3421046018600463, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": -0.00017687635996413453, "vf_loss": 7.305831935670641, "vf_explained_var": 0.35339802932486963, "kl": Infinity, "entropy": 0.681435984310019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 393.70000000000005, "episode_reward_min": -160.80000000000024, "episode_reward_mean": 110.90099999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -301.90000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": 18.840499999999974, "predator_policy": 36.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [145.19999999999962, 14.10000000000002, 185.79999999999927, 4.399999999999908, -82.89999999999999, 174.49999999999935, -64.30000000000001, -27.599999999999774, -26.20000000000001, 128.99999999999983, 393.70000000000005, 170.6999999999994, -7.899999999999796, 40.0000000000003, 185.3999999999993, 127.49999999999952, -160.80000000000024, 82.90000000000009, -99.40000000000018, 169.59999999999945, -3.900000000000027, 9.300000000000086, 40.0000000000003, 37.40000000000017, -45.19999999999988, 13.599999999999998, 55.30000000000008, 123.89999999999978, 129.59999999999945, 145.8999999999996, 79.2999999999999, 179.79999999999998, 56.000000000000156, 192.09999999999923, 27.90000000000011, 178.39999999999918, 151.29999999999993, -61.399999999999814, 270.8999999999999, 86.40000000000009, 310.4999999999998, 98.49999999999984, 117.0, 35.300000000000104, 25.900000000000013, 267.0999999999999, 28.000000000000107, 318.10000000000025, 207.39999999999918, 165.79999999999924, 28.50000000000025, 35.60000000000029, 22.90000000000002, 3.2000000000000086, 74.10000000000007, 198.39999999999927, 23.00000000000025, 124.3999999999997, 187.49999999999932, -17.199999999999918, 151.59999999999903, 59.29999999999999, 115.99999999999967, 215.89999999999964, 177.69999999999902, 136.19999999999936, 149.29999999999964, 240.6999999999996, 248.89999999999955, 203.19999999999987, 174.89999999999924, 143.49999999999932, 118.29999999999959, 87.20000000000002, 138.1999999999995, 159.99999999999937, 130.6999999999995, 185.69999999999936, 143.4999999999993, 33.80000000000002, 161.49999999999912, 120.19999999999959, 177.99999999999997, 30.100000000000147, 280.7999999999997, 160.3999999999999, 190.2999999999993, 40.0000000000003, 138.4999999999992, 267.7999999999999, 36.70000000000025, 37.80000000000027, 174.19999999999933, 114.09999999999968, 151.79999999999936, 160.09999999999997, 171.19999999999953, 234.2999999999998, 24.30000000000019, 129.09999999999928], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 84.2, -36.39999999999995, -35.50000000000003, 20.000000000000014, 165.79999999999993, -97.60000000000005, 20.000000000000014, 20.000000000000007, -301.90000000000003, 147.49999999999994, 20.000000000000014, -148.3, -181.00000000000003, -17.800000000000026, -38.80000000000004, -42.099999999999845, -108.10000000000005, 181.99999999999994, -288.9999999999997, 194.59999999999997, 199.1, 178.39999999999986, -78.69999999999996, -26.200000000000024, -36.700000000000045, 20.000000000000014, 20.000000000000014, 15.799999999999953, 167.59999999999994, 97.09999999999997, -34.600000000000044, -160.90000000000023, -274.9, -147.99999999999983, 26.89999999999997, -95.49999999999991, -82.90000000000005, 149.59999999999997, 20.000000000000014, 20.000000000000014, -184.90000000000023, -186.70000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -181.6, 20.000000000000014, -99.1, -150.1000000000002, 5.299999999999965, -15.699999999999761, -145.90000000000023, 12.200000000000003, 149.29999999999993, -150.40000000000015, 7.399999999999965, 57.19999999999999, -69.10000000000002, 154.99999999999994, 20.000000000000014, -99.70000000000002, 24.80000000000001, 50.0, -46.0, 20.000000000000014, 172.0999999999999, 20.000000000000014, 20.000000000000014, -3.099999999999958, 17.899999999999988, 159.49999999999986, -99.70000000000002, 110.0, -241.0, 11.599999999999964, 167.3, -6.399999999999999, -40.599999999999966, 20.000000000000014, 162.49999999999994, 136.99999999999986, 30.80000000000001, 13.699999999999964, 104.6, -163.59999999999994, 20.000000000000014, -78.69999999999982, -25.600000000000023, -101.49999999999997, 38.3, 162.79999999999998, 17.899999999999988, 1.0999999999999865, 159.49999999999994, 158.59999999999982, 187.39999999999992, 20.000000000000014, -26.199999999999754, 163.9999999999998, 20.000000000000014, -44.500000000000036, 11.599999999999946, 20.000000000000014, 9.499999999999964, 7.399999999999965, -152.8, 20.000000000000014, 37.4, -241.30000000000007, 20.000000000000014, 178.39999999999998, 20.000000000000014, -199.0, 20.000000000000014, 49.400000000000006, 177.49999999999994, -1.0000000000000369, -89.20000000000024, 20.000000000000014, 20.000000000000014, 131.5999999999997, 12.2, -106.89999999999992, 20.000000000000014, 10.999999999999998, 79.10000000000002, 111.79999999999995, 20.000000000000014, 157.69999999999976, 51.2, 20.000000000000014, 7.999999999999954, 65.30000000000001, 97.39999999999989, 113.29999999999998, 141.49999999999974, 58.39999999999998, 98.89999999999995, -12.699999999999996, 20.000000000000014, 140.89999999999992, 20.000000000000014, 123.49999999999989, 98.29999999999995, 20.000000000000014, 14.599999999999998, -99.40000000000003, 5.299999999999965, 110.89999999999992, 20.000000000000014, 118.99999999999994, 80.90000000000002, -47.19999999999999, 166.39999999999998, 5.29999999999995, 20.000000000000014, 123.49999999999989, -166.6000000000001, 34.400000000000006, 20.000000000000014, 141.4999999999998, 57.200000000000024, 20.000000000000014, 56.300000000000004, -46.29999999999999, 1.099999999999983, 20.000000000000014, 135.19999999999976, 119.6, 3.4999999999999893, 23.900000000000006, 168.49999999999997, 15.799999999999978, 20.000000000000014, 20.000000000000014, 126.19999999999978, 5.299999999999965, 26.29999999999999, 153.49999999999983, 20.000000000000014, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999997, 139.39999999999995, 10.09999999999998, 20.000000000000014, 108.79999999999993, 20.000000000000014, -45.399999999999956, 75.50000000000003, 162.1999999999999, -79.00000000000003, 9.200000000000001, 154.09999999999982, -15.700000000000026, 20.000000000000014, 20.000000000000014, 109.09999999999981], "policy_predator_policy_reward": [28.0, 13.0, 86.0, 0.0, 0.0, 0.0, 41.0, 41.0, 14.0, 185.0, 0.0, 7.0, 115.0, 150.0, 0.0, 29.0, 71.0, 53.0, 114.0, 122.0, 0.0, 0.0, 29.0, 42.0, 32.0, 23.0, 0.0, 0.0, 0.0, 2.0, 41.0, 24.0, 170.0, 105.0, 110.0, 94.0, 3.0, 76.0, 0.0, 0.0, 73.0, 88.0, 58.0, 118.0, 0.0, 0.0, 80.0, 119.0, 129.0, 75.0, 17.0, 7.0, 99.0, 90.0, 75.0, 50.0, 24.0, 41.0, 0.0, 60.0, 92.0, 67.0, 36.0, 69.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 1.0, 69.0, 72.0, 19.0, 149.0, 45.0, 65.0, 61.0, 46.0, 5.0, 6.0, 3.0, 51.0, 76.0, 100.0, 44.0, 50.0, 68.0, 85.0, 18.0, 48.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 24.0, 29.0, 0.0, 4.0, 6.0, 0.0, 54.0, 82.0, 116.0, 162.0, 0.0, 0.0, 99.0, 103.0, 13.0, 42.0, 9.0, 2.0, 52.0, 0.0, 0.0, 0.0, 122.0, 32.0, 34.0, 51.0, 25.0, 0.0, 0.0, 0.0, 22.0, 43.0, 36.0, 40.0, 18.0, 12.0, 34.0, 15.0, 57.0, 60.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 109.0, 63.0, 0.0, 22.0, 1.0, 20.0, 54.0, 43.0, 6.0, 8.0, 0.0, 0.0, 125.0, 41.0, 0.0, 0.0, 40.0, 3.0, 102.0, 66.0, 9.0, 0.0, 18.0, 8.0, 60.0, 73.0, 2.0, 4.0, 0.0, 0.0, 7.0, 0.0, 53.0, 35.0, 3.0, 0.0, 0.0, 2.0, 15.0, 4.0, 43.0, 41.0, 6.0, 17.0, 74.0, 56.0, 45.0, 43.0, 62.0, 9.0, 13.0, 7.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7559788892083462, "mean_inference_ms": 2.049216919906874, "mean_action_processing_ms": 0.3116496357178809, "mean_env_wait_ms": 0.27248838323526053, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00540006160736084, "StateBufferConnector_ms": 0.003537416458129883, "ViewRequirementAgentConnector_ms": 0.24213290214538574}, "num_episodes": 22, "episode_return_max": 393.70000000000005, "episode_return_min": -160.80000000000024, "episode_return_mean": 110.90099999999977, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.4910727252035, "num_env_steps_trained_throughput_per_sec": 210.4910727252035, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 16133.581, "restore_workers_time_ms": 0.025, "training_step_time_ms": 16132.889, "sample_time_ms": 2749.599, "learn_time_ms": 13359.408, "learn_throughput": 299.414, "synch_weights_time_ms": 19.599}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "04dec_00002", "date": "2024-08-13_16-41-44", "timestamp": 1723581704, "time_this_iter_s": 19.02000379562378, "time_total_s": 1135.6311430931091, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06678b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1135.6311430931091, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 81.27037037037037, "ram_util_percent": 84.88888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5404105504274999, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 0.00010000000000000003, "total_loss": 4.146448577774896, "policy_loss": -0.003929792991814711, "vf_loss": 4.150315388548311, "vf_explained_var": 0.004047831246461818, "kl": 0.00707593158334245, "entropy": 0.5666255499477739, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 29.995462357083326, "cur_kl_coeff": 0.5131569027900696, "cur_lr": 0.00010000000000000003, "total_loss": 7.163794441071768, "policy_loss": 0.003178574653987886, "vf_loss": 7.155878072567087, "vf_explained_var": 0.17320843354734794, "kl": 0.009232654750528806, "entropy": 0.6854061996810651, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 318.10000000000025, "episode_reward_min": -217.30000000000004, "episode_reward_mean": 112.55099999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -258.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 187.39999999999992, "predator_policy": 162.0}, "policy_reward_mean": {"prey_policy": 21.270499999999974, "predator_policy": 35.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-99.40000000000018, 169.59999999999945, -3.900000000000027, 9.300000000000086, 40.0000000000003, 37.40000000000017, -45.19999999999988, 13.599999999999998, 55.30000000000008, 123.89999999999978, 129.59999999999945, 145.8999999999996, 79.2999999999999, 179.79999999999998, 56.000000000000156, 192.09999999999923, 27.90000000000011, 178.39999999999918, 151.29999999999993, -61.399999999999814, 270.8999999999999, 86.40000000000009, 310.4999999999998, 98.49999999999984, 117.0, 35.300000000000104, 25.900000000000013, 267.0999999999999, 28.000000000000107, 318.10000000000025, 207.39999999999918, 165.79999999999924, 28.50000000000025, 35.60000000000029, 22.90000000000002, 3.2000000000000086, 74.10000000000007, 198.39999999999927, 23.00000000000025, 124.3999999999997, 187.49999999999932, -17.199999999999918, 151.59999999999903, 59.29999999999999, 115.99999999999967, 215.89999999999964, 177.69999999999902, 136.19999999999936, 149.29999999999964, 240.6999999999996, 248.89999999999955, 203.19999999999987, 174.89999999999924, 143.49999999999932, 118.29999999999959, 87.20000000000002, 138.1999999999995, 159.99999999999937, 130.6999999999995, 185.69999999999936, 143.4999999999993, 33.80000000000002, 161.49999999999912, 120.19999999999959, 177.99999999999997, 30.100000000000147, 280.7999999999997, 160.3999999999999, 190.2999999999993, 40.0000000000003, 138.4999999999992, 267.7999999999999, 36.70000000000025, 37.80000000000027, 174.19999999999933, 114.09999999999968, 151.79999999999936, 160.09999999999997, 171.19999999999953, 234.2999999999998, 24.30000000000019, 129.09999999999928, 38.50000000000028, 35.600000000000236, 135.2999999999991, 5.199999999999977, 110.59999999999972, -217.30000000000004, -15.399999999999663, 36.70000000000025, 139.3999999999992, 181.59999999999926, 183.09999999999974, 98.69999999999995, 160.19999999999953, 80.69999999999992, 143.4999999999999, 26.800000000000093, 116.99999999999952, 188.29999999999924], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-95.49999999999991, -82.90000000000005, 149.59999999999997, 20.000000000000014, 20.000000000000014, -184.90000000000023, -186.70000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -181.6, 20.000000000000014, -99.1, -150.1000000000002, 5.299999999999965, -15.699999999999761, -145.90000000000023, 12.200000000000003, 149.29999999999993, -150.40000000000015, 7.399999999999965, 57.19999999999999, -69.10000000000002, 154.99999999999994, 20.000000000000014, -99.70000000000002, 24.80000000000001, 50.0, -46.0, 20.000000000000014, 172.0999999999999, 20.000000000000014, 20.000000000000014, -3.099999999999958, 17.899999999999988, 159.49999999999986, -99.70000000000002, 110.0, -241.0, 11.599999999999964, 167.3, -6.399999999999999, -40.599999999999966, 20.000000000000014, 162.49999999999994, 136.99999999999986, 30.80000000000001, 13.699999999999964, 104.6, -163.59999999999994, 20.000000000000014, -78.69999999999982, -25.600000000000023, -101.49999999999997, 38.3, 162.79999999999998, 17.899999999999988, 1.0999999999999865, 159.49999999999994, 158.59999999999982, 187.39999999999992, 20.000000000000014, -26.199999999999754, 163.9999999999998, 20.000000000000014, -44.500000000000036, 11.599999999999946, 20.000000000000014, 9.499999999999964, 7.399999999999965, -152.8, 20.000000000000014, 37.4, -241.30000000000007, 20.000000000000014, 178.39999999999998, 20.000000000000014, -199.0, 20.000000000000014, 49.400000000000006, 177.49999999999994, -1.0000000000000369, -89.20000000000024, 20.000000000000014, 20.000000000000014, 131.5999999999997, 12.2, -106.89999999999992, 20.000000000000014, 10.999999999999998, 79.10000000000002, 111.79999999999995, 20.000000000000014, 157.69999999999976, 51.2, 20.000000000000014, 7.999999999999954, 65.30000000000001, 97.39999999999989, 113.29999999999998, 141.49999999999974, 58.39999999999998, 98.89999999999995, -12.699999999999996, 20.000000000000014, 140.89999999999992, 20.000000000000014, 123.49999999999989, 98.29999999999995, 20.000000000000014, 14.599999999999998, -99.40000000000003, 5.299999999999965, 110.89999999999992, 20.000000000000014, 118.99999999999994, 80.90000000000002, -47.19999999999999, 166.39999999999998, 5.29999999999995, 20.000000000000014, 123.49999999999989, -166.6000000000001, 34.400000000000006, 20.000000000000014, 141.4999999999998, 57.200000000000024, 20.000000000000014, 56.300000000000004, -46.29999999999999, 1.099999999999983, 20.000000000000014, 135.19999999999976, 119.6, 3.4999999999999893, 23.900000000000006, 168.49999999999997, 15.799999999999978, 20.000000000000014, 20.000000000000014, 126.19999999999978, 5.299999999999965, 26.29999999999999, 153.49999999999983, 20.000000000000014, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999997, 139.39999999999995, 10.09999999999998, 20.000000000000014, 108.79999999999993, 20.000000000000014, -45.399999999999956, 75.50000000000003, 162.1999999999999, -79.00000000000003, 9.200000000000001, 154.09999999999982, -15.700000000000026, 20.000000000000014, 20.000000000000014, 109.09999999999981, 20.000000000000014, 9.499999999999979, 11.599999999999964, 20.000000000000014, 115.3999999999998, 17.900000000000013, -28.000000000000007, -161.8, 20.000000000000014, 35.6, -247.9, -192.39999999999992, -210.4000000000001, 20.000000000000014, 20.000000000000014, 13.699999999999964, 112.3999999999998, 20.000000000000014, 13.699999999999964, 155.89999999999995, 115.39999999999992, -10.300000000000008, -19.89999999999977, 65.60000000000002, 149.59999999999994, -51.399999999999885, -136.30000000000004, 20.000000000000014, -258.4, 146.89999999999984, -5.199999999999934, 20.000000000000014, 22.1, 17.900000000000006, 20.000000000000014, 167.29999999999993], "policy_predator_policy_reward": [3.0, 76.0, 0.0, 0.0, 73.0, 88.0, 58.0, 118.0, 0.0, 0.0, 80.0, 119.0, 129.0, 75.0, 17.0, 7.0, 99.0, 90.0, 75.0, 50.0, 24.0, 41.0, 0.0, 60.0, 92.0, 67.0, 36.0, 69.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 1.0, 69.0, 72.0, 19.0, 149.0, 45.0, 65.0, 61.0, 46.0, 5.0, 6.0, 3.0, 51.0, 76.0, 100.0, 44.0, 50.0, 68.0, 85.0, 18.0, 48.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 24.0, 29.0, 0.0, 4.0, 6.0, 0.0, 54.0, 82.0, 116.0, 162.0, 0.0, 0.0, 99.0, 103.0, 13.0, 42.0, 9.0, 2.0, 52.0, 0.0, 0.0, 0.0, 122.0, 32.0, 34.0, 51.0, 25.0, 0.0, 0.0, 0.0, 22.0, 43.0, 36.0, 40.0, 18.0, 12.0, 34.0, 15.0, 57.0, 60.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 109.0, 63.0, 0.0, 22.0, 1.0, 20.0, 54.0, 43.0, 6.0, 8.0, 0.0, 0.0, 125.0, 41.0, 0.0, 0.0, 40.0, 3.0, 102.0, 66.0, 9.0, 0.0, 18.0, 8.0, 60.0, 73.0, 2.0, 4.0, 0.0, 0.0, 7.0, 0.0, 53.0, 35.0, 3.0, 0.0, 0.0, 2.0, 15.0, 4.0, 43.0, 41.0, 6.0, 17.0, 74.0, 56.0, 45.0, 43.0, 62.0, 9.0, 13.0, 7.0, 0.0, 0.0, 5.0, 4.0, 0.0, 4.0, 1.0, 1.0, 102.0, 93.0, 17.0, 38.0, 74.0, 149.0, 100.0, 75.0, 0.0, 3.0, 0.0, 7.0, 4.0, 8.0, 33.0, 45.0, 16.0, 37.0, 37.0, 25.0, 103.0, 94.0, 127.0, 128.0, 0.0, 12.0, 30.0, 47.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7631194982114828, "mean_inference_ms": 2.0721199333026, "mean_action_processing_ms": 0.31461469621502824, "mean_env_wait_ms": 0.2751512795242922, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00579988956451416, "StateBufferConnector_ms": 0.003498554229736328, "ViewRequirementAgentConnector_ms": 0.23962366580963135}, "num_episodes": 18, "episode_return_max": 318.10000000000025, "episode_return_min": -217.30000000000004, "episode_return_mean": 112.55099999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.6136340885955, "num_env_steps_trained_throughput_per_sec": 253.6136340885955, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 16082.926, "restore_workers_time_ms": 0.025, "training_step_time_ms": 16082.234, "sample_time_ms": 2749.87, "learn_time_ms": 13308.442, "learn_throughput": 300.561, "synch_weights_time_ms": 19.697}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "04dec_00002", "date": "2024-08-13_16-42-00", "timestamp": 1723581720, "time_this_iter_s": 15.79678225517273, "time_total_s": 1151.4279253482819, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c4a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1151.4279253482819, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 81.76363636363637, "ram_util_percent": 84.67727272727274}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5109790345584904, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 0.00010000000000000003, "total_loss": 5.84347411185976, "policy_loss": -0.00108352135953114, "vf_loss": 5.84453107944872, "vf_explained_var": -0.0016373479807818378, "kl": 0.0029839279117513844, "entropy": 0.5609032393605621, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.069507029510678, "cur_kl_coeff": 0.5131569027900696, "cur_lr": 0.00010000000000000003, "total_loss": 7.637600988811917, "policy_loss": -0.0005566101223131809, "vf_loss": 7.635729924963895, "vf_explained_var": -0.10957487077309341, "kl": 0.004730861669793495, "entropy": 0.6629548193916442, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 318.10000000000025, "episode_reward_min": -217.30000000000004, "episode_reward_mean": 112.14599999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -352.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 187.39999999999992, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 18.562999999999974, "predator_policy": 37.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [98.49999999999984, 117.0, 35.300000000000104, 25.900000000000013, 267.0999999999999, 28.000000000000107, 318.10000000000025, 207.39999999999918, 165.79999999999924, 28.50000000000025, 35.60000000000029, 22.90000000000002, 3.2000000000000086, 74.10000000000007, 198.39999999999927, 23.00000000000025, 124.3999999999997, 187.49999999999932, -17.199999999999918, 151.59999999999903, 59.29999999999999, 115.99999999999967, 215.89999999999964, 177.69999999999902, 136.19999999999936, 149.29999999999964, 240.6999999999996, 248.89999999999955, 203.19999999999987, 174.89999999999924, 143.49999999999932, 118.29999999999959, 87.20000000000002, 138.1999999999995, 159.99999999999937, 130.6999999999995, 185.69999999999936, 143.4999999999993, 33.80000000000002, 161.49999999999912, 120.19999999999959, 177.99999999999997, 30.100000000000147, 280.7999999999997, 160.3999999999999, 190.2999999999993, 40.0000000000003, 138.4999999999992, 267.7999999999999, 36.70000000000025, 37.80000000000027, 174.19999999999933, 114.09999999999968, 151.79999999999936, 160.09999999999997, 171.19999999999953, 234.2999999999998, 24.30000000000019, 129.09999999999928, 38.50000000000028, 35.600000000000236, 135.2999999999991, 5.199999999999977, 110.59999999999972, -217.30000000000004, -15.399999999999663, 36.70000000000025, 139.3999999999992, 181.59999999999926, 183.09999999999974, 98.69999999999995, 160.19999999999953, 80.69999999999992, 143.4999999999999, 26.800000000000093, 116.99999999999952, 188.29999999999924, 88.9, 154.49999999999937, -32.999999999999766, 104.50000000000003, 31.10000000000017, 35.80000000000005, 37.800000000000296, 29.700000000000124, 52.5, 30.100000000000147, 150.49999999999935, 157.4999999999994, 28.20000000000022, 144.2999999999994, 40.0000000000003, 65.70000000000005, 163.0999999999994, 163.6999999999994, 255.69999999999953, -184.80000000000004, 210.29999999999953, 204.8999999999998, 75.79999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [30.80000000000001, 13.699999999999964, 104.6, -163.59999999999994, 20.000000000000014, -78.69999999999982, -25.600000000000023, -101.49999999999997, 38.3, 162.79999999999998, 17.899999999999988, 1.0999999999999865, 159.49999999999994, 158.59999999999982, 187.39999999999992, 20.000000000000014, -26.199999999999754, 163.9999999999998, 20.000000000000014, -44.500000000000036, 11.599999999999946, 20.000000000000014, 9.499999999999964, 7.399999999999965, -152.8, 20.000000000000014, 37.4, -241.30000000000007, 20.000000000000014, 178.39999999999998, 20.000000000000014, -199.0, 20.000000000000014, 49.400000000000006, 177.49999999999994, -1.0000000000000369, -89.20000000000024, 20.000000000000014, 20.000000000000014, 131.5999999999997, 12.2, -106.89999999999992, 20.000000000000014, 10.999999999999998, 79.10000000000002, 111.79999999999995, 20.000000000000014, 157.69999999999976, 51.2, 20.000000000000014, 7.999999999999954, 65.30000000000001, 97.39999999999989, 113.29999999999998, 141.49999999999974, 58.39999999999998, 98.89999999999995, -12.699999999999996, 20.000000000000014, 140.89999999999992, 20.000000000000014, 123.49999999999989, 98.29999999999995, 20.000000000000014, 14.599999999999998, -99.40000000000003, 5.299999999999965, 110.89999999999992, 20.000000000000014, 118.99999999999994, 80.90000000000002, -47.19999999999999, 166.39999999999998, 5.29999999999995, 20.000000000000014, 123.49999999999989, -166.6000000000001, 34.400000000000006, 20.000000000000014, 141.4999999999998, 57.200000000000024, 20.000000000000014, 56.300000000000004, -46.29999999999999, 1.099999999999983, 20.000000000000014, 135.19999999999976, 119.6, 3.4999999999999893, 23.900000000000006, 168.49999999999997, 15.799999999999978, 20.000000000000014, 20.000000000000014, 126.19999999999978, 5.299999999999965, 26.29999999999999, 153.49999999999983, 20.000000000000014, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999997, 139.39999999999995, 10.09999999999998, 20.000000000000014, 108.79999999999993, 20.000000000000014, -45.399999999999956, 75.50000000000003, 162.1999999999999, -79.00000000000003, 9.200000000000001, 154.09999999999982, -15.700000000000026, 20.000000000000014, 20.000000000000014, 109.09999999999981, 20.000000000000014, 9.499999999999979, 11.599999999999964, 20.000000000000014, 115.3999999999998, 17.900000000000013, -28.000000000000007, -161.8, 20.000000000000014, 35.6, -247.9, -192.39999999999992, -210.4000000000001, 20.000000000000014, 20.000000000000014, 13.699999999999964, 112.3999999999998, 20.000000000000014, 13.699999999999964, 155.89999999999995, 115.39999999999992, -10.300000000000008, -19.89999999999977, 65.60000000000002, 149.59999999999994, -51.399999999999885, -136.30000000000004, 20.000000000000014, -258.4, 146.89999999999984, -5.199999999999934, 20.000000000000014, 22.1, 17.900000000000006, 20.000000000000014, 167.29999999999993, -246.70000000000002, 17.60000000000002, 17.899999999999988, 128.5999999999999, 20.000000000000014, -352.0, 57.80000000000001, -88.30000000000013, 7.399999999999968, -232.3, -164.8, 11.599999999999964, 15.799999999999946, 20.000000000000014, -9.700000000000031, 7.399999999999965, -54.400000000000034, -63.10000000000004, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 72.5, 111.5, 20.000000000000014, 20.000000000000014, -17.800000000000026, -47.19999999999978, 141.4999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.30000000000004, 3.1999999999999615, 134.89999999999998, 133.69999999999993, 4.9999999999999645, 112.69999999999982, 118.99999999999994, -203.8, -322.0, 127.69999999999996, 56.6000000000001, -12.699999999999989, 104.59999999999994, -274.6, -10.600000000000014], "policy_predator_policy_reward": [3.0, 51.0, 76.0, 100.0, 44.0, 50.0, 68.0, 85.0, 18.0, 48.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 24.0, 29.0, 0.0, 4.0, 6.0, 0.0, 54.0, 82.0, 116.0, 162.0, 0.0, 0.0, 99.0, 103.0, 13.0, 42.0, 9.0, 2.0, 52.0, 0.0, 0.0, 0.0, 122.0, 32.0, 34.0, 51.0, 25.0, 0.0, 0.0, 0.0, 22.0, 43.0, 36.0, 40.0, 18.0, 12.0, 34.0, 15.0, 57.0, 60.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 109.0, 63.0, 0.0, 22.0, 1.0, 20.0, 54.0, 43.0, 6.0, 8.0, 0.0, 0.0, 125.0, 41.0, 0.0, 0.0, 40.0, 3.0, 102.0, 66.0, 9.0, 0.0, 18.0, 8.0, 60.0, 73.0, 2.0, 4.0, 0.0, 0.0, 7.0, 0.0, 53.0, 35.0, 3.0, 0.0, 0.0, 2.0, 15.0, 4.0, 43.0, 41.0, 6.0, 17.0, 74.0, 56.0, 45.0, 43.0, 62.0, 9.0, 13.0, 7.0, 0.0, 0.0, 5.0, 4.0, 0.0, 4.0, 1.0, 1.0, 102.0, 93.0, 17.0, 38.0, 74.0, 149.0, 100.0, 75.0, 0.0, 3.0, 0.0, 7.0, 4.0, 8.0, 33.0, 45.0, 16.0, 37.0, 37.0, 25.0, 103.0, 94.0, 127.0, 128.0, 0.0, 12.0, 30.0, 47.0, 1.0, 0.0, 162.0, 156.0, 0.0, 8.0, 116.0, 183.0, 50.0, 85.0, 146.0, 110.0, 71.0, 118.0, 2.0, 0.0, 17.0, 15.0, 84.0, 86.0, 0.0, 9.0, 29.0, 29.0, 17.0, 9.0, 16.0, 10.0, 27.0, 23.0, 0.0, 0.0, 77.0, 108.0, 25.0, 0.0, 20.0, 5.0, 5.0, 19.0, 173.0, 168.0, 9.0, 17.0, 60.0, 53.0, 181.0, 180.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7697415056498552, "mean_inference_ms": 2.092998763819918, "mean_action_processing_ms": 0.3177136266520486, "mean_env_wait_ms": 0.277562863275896, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0060808658599853516, "StateBufferConnector_ms": 0.0035649538040161133, "ViewRequirementAgentConnector_ms": 0.1799558401107788}, "num_episodes": 23, "episode_return_max": 318.10000000000025, "episode_return_min": -217.30000000000004, "episode_return_mean": 112.14599999999975, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 254.15645819803467, "num_env_steps_trained_throughput_per_sec": 254.15645819803467, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 16041.586, "restore_workers_time_ms": 0.024, "training_step_time_ms": 16040.892, "sample_time_ms": 2744.89, "learn_time_ms": 13272.098, "learn_throughput": 301.384, "synch_weights_time_ms": 19.917}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "04dec_00002", "date": "2024-08-13_16-42-16", "timestamp": 1723581736, "time_this_iter_s": 15.81259799003601, "time_total_s": 1167.2405233383179, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c43a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1167.2405233383179, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 77.1086956521739, "ram_util_percent": 85.74782608695652}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.431690783026042, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 0.00010000000000000003, "total_loss": 4.304035817630707, "policy_loss": -0.0016942764463632432, "vf_loss": 4.305708050475549, "vf_explained_var": -0.0011006205800979856, "kl": 0.004955369112629745, "entropy": 0.5391375919183096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 30.873452638759815, "cur_kl_coeff": 0.2565784513950348, "cur_lr": 0.00010000000000000003, "total_loss": 6.747158830884903, "policy_loss": 0.0023334892104483313, "vf_loss": 6.742756744415041, "vf_explained_var": 0.21466080429692747, "kl": 0.008062245085217272, "entropy": 0.6716288523383872, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 319.20000000000005, "episode_reward_min": -217.30000000000004, "episode_reward_mean": 115.04799999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -352.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.49999999999997, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 20.668999999999972, "predator_policy": 36.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.199999999999918, 151.59999999999903, 59.29999999999999, 115.99999999999967, 215.89999999999964, 177.69999999999902, 136.19999999999936, 149.29999999999964, 240.6999999999996, 248.89999999999955, 203.19999999999987, 174.89999999999924, 143.49999999999932, 118.29999999999959, 87.20000000000002, 138.1999999999995, 159.99999999999937, 130.6999999999995, 185.69999999999936, 143.4999999999993, 33.80000000000002, 161.49999999999912, 120.19999999999959, 177.99999999999997, 30.100000000000147, 280.7999999999997, 160.3999999999999, 190.2999999999993, 40.0000000000003, 138.4999999999992, 267.7999999999999, 36.70000000000025, 37.80000000000027, 174.19999999999933, 114.09999999999968, 151.79999999999936, 160.09999999999997, 171.19999999999953, 234.2999999999998, 24.30000000000019, 129.09999999999928, 38.50000000000028, 35.600000000000236, 135.2999999999991, 5.199999999999977, 110.59999999999972, -217.30000000000004, -15.399999999999663, 36.70000000000025, 139.3999999999992, 181.59999999999926, 183.09999999999974, 98.69999999999995, 160.19999999999953, 80.69999999999992, 143.4999999999999, 26.800000000000093, 116.99999999999952, 188.29999999999924, 88.9, 154.49999999999937, -32.999999999999766, 104.50000000000003, 31.10000000000017, 35.80000000000005, 37.800000000000296, 29.700000000000124, 52.5, 30.100000000000147, 150.49999999999935, 157.4999999999994, 28.20000000000022, 144.2999999999994, 40.0000000000003, 65.70000000000005, 163.0999999999994, 163.6999999999994, 255.69999999999953, -184.80000000000004, 210.29999999999953, 204.8999999999998, 75.79999999999998, 319.20000000000005, 115.59999999999968, 318.29999999999995, 127.59999999999977, 40.0000000000003, 179.79999999999987, -49.29999999999961, 201.59999999999994, 40.0000000000003, 123.89999999999954, 134.49999999999937, 191.0999999999992, 151.09999999999937, -9.899999999999848, 35.5, 36.700000000000294, 148.39999999999944, 146.7999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-89.20000000000024, 20.000000000000014, 20.000000000000014, 131.5999999999997, 12.2, -106.89999999999992, 20.000000000000014, 10.999999999999998, 79.10000000000002, 111.79999999999995, 20.000000000000014, 157.69999999999976, 51.2, 20.000000000000014, 7.999999999999954, 65.30000000000001, 97.39999999999989, 113.29999999999998, 141.49999999999974, 58.39999999999998, 98.89999999999995, -12.699999999999996, 20.000000000000014, 140.89999999999992, 20.000000000000014, 123.49999999999989, 98.29999999999995, 20.000000000000014, 14.599999999999998, -99.40000000000003, 5.299999999999965, 110.89999999999992, 20.000000000000014, 118.99999999999994, 80.90000000000002, -47.19999999999999, 166.39999999999998, 5.29999999999995, 20.000000000000014, 123.49999999999989, -166.6000000000001, 34.400000000000006, 20.000000000000014, 141.4999999999998, 57.200000000000024, 20.000000000000014, 56.300000000000004, -46.29999999999999, 1.099999999999983, 20.000000000000014, 135.19999999999976, 119.6, 3.4999999999999893, 23.900000000000006, 168.49999999999997, 15.799999999999978, 20.000000000000014, 20.000000000000014, 126.19999999999978, 5.299999999999965, 26.29999999999999, 153.49999999999983, 20.000000000000014, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999997, 139.39999999999995, 10.09999999999998, 20.000000000000014, 108.79999999999993, 20.000000000000014, -45.399999999999956, 75.50000000000003, 162.1999999999999, -79.00000000000003, 9.200000000000001, 154.09999999999982, -15.700000000000026, 20.000000000000014, 20.000000000000014, 109.09999999999981, 20.000000000000014, 9.499999999999979, 11.599999999999964, 20.000000000000014, 115.3999999999998, 17.900000000000013, -28.000000000000007, -161.8, 20.000000000000014, 35.6, -247.9, -192.39999999999992, -210.4000000000001, 20.000000000000014, 20.000000000000014, 13.699999999999964, 112.3999999999998, 20.000000000000014, 13.699999999999964, 155.89999999999995, 115.39999999999992, -10.300000000000008, -19.89999999999977, 65.60000000000002, 149.59999999999994, -51.399999999999885, -136.30000000000004, 20.000000000000014, -258.4, 146.89999999999984, -5.199999999999934, 20.000000000000014, 22.1, 17.900000000000006, 20.000000000000014, 167.29999999999993, -246.70000000000002, 17.60000000000002, 17.899999999999988, 128.5999999999999, 20.000000000000014, -352.0, 57.80000000000001, -88.30000000000013, 7.399999999999968, -232.3, -164.8, 11.599999999999964, 15.799999999999946, 20.000000000000014, -9.700000000000031, 7.399999999999965, -54.400000000000034, -63.10000000000004, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 72.5, 111.5, 20.000000000000014, 20.000000000000014, -17.800000000000026, -47.19999999999978, 141.4999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.30000000000004, 3.1999999999999615, 134.89999999999998, 133.69999999999993, 4.9999999999999645, 112.69999999999982, 118.99999999999994, -203.8, -322.0, 127.69999999999996, 56.6000000000001, -12.699999999999989, 104.59999999999994, -274.6, -10.600000000000014, 157.09999999999985, 157.0999999999999, 29.600000000000026, 20.000000000000014, 163.7, 131.6, 13.699999999999964, 62.900000000000006, 20.000000000000014, 20.000000000000014, -37.60000000000004, 97.39999999999996, -195.1000000000005, -5.200000000000067, -82.9, 156.49999999999994, 20.000000000000014, 20.000000000000014, 56.900000000000034, 20.000000000000014, 114.49999999999989, 20.000000000000014, 166.09999999999988, 20.000000000000014, 103.39999999999989, 13.699999999999974, -328.9, 20.000000000000014, -121.60000000000002, -31.9, 20.000000000000014, 13.699999999999946, 15.799999999999946, 74.60000000000002, 111.7999999999999, 20.000000000000014], "policy_predator_policy_reward": [52.0, 0.0, 0.0, 0.0, 122.0, 32.0, 34.0, 51.0, 25.0, 0.0, 0.0, 0.0, 22.0, 43.0, 36.0, 40.0, 18.0, 12.0, 34.0, 15.0, 57.0, 60.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 109.0, 63.0, 0.0, 22.0, 1.0, 20.0, 54.0, 43.0, 6.0, 8.0, 0.0, 0.0, 125.0, 41.0, 0.0, 0.0, 40.0, 3.0, 102.0, 66.0, 9.0, 0.0, 18.0, 8.0, 60.0, 73.0, 2.0, 4.0, 0.0, 0.0, 7.0, 0.0, 53.0, 35.0, 3.0, 0.0, 0.0, 2.0, 15.0, 4.0, 43.0, 41.0, 6.0, 17.0, 74.0, 56.0, 45.0, 43.0, 62.0, 9.0, 13.0, 7.0, 0.0, 0.0, 5.0, 4.0, 0.0, 4.0, 1.0, 1.0, 102.0, 93.0, 17.0, 38.0, 74.0, 149.0, 100.0, 75.0, 0.0, 3.0, 0.0, 7.0, 4.0, 8.0, 33.0, 45.0, 16.0, 37.0, 37.0, 25.0, 103.0, 94.0, 127.0, 128.0, 0.0, 12.0, 30.0, 47.0, 1.0, 0.0, 162.0, 156.0, 0.0, 8.0, 116.0, 183.0, 50.0, 85.0, 146.0, 110.0, 71.0, 118.0, 2.0, 0.0, 17.0, 15.0, 84.0, 86.0, 0.0, 9.0, 29.0, 29.0, 17.0, 9.0, 16.0, 10.0, 27.0, 23.0, 0.0, 0.0, 77.0, 108.0, 25.0, 0.0, 20.0, 5.0, 5.0, 19.0, 173.0, 168.0, 9.0, 17.0, 60.0, 53.0, 181.0, 180.0, 5.0, 0.0, 44.0, 22.0, 23.0, 0.0, 32.0, 19.0, 0.0, 0.0, 53.0, 67.0, 96.0, 55.0, 90.0, 38.0, 0.0, 0.0, 21.0, 26.0, 0.0, 0.0, 5.0, 0.0, 22.0, 12.0, 143.0, 156.0, 104.0, 85.0, 0.0, 3.0, 28.0, 30.0, 11.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7738375385812559, "mean_inference_ms": 2.1078953196976586, "mean_action_processing_ms": 0.3190797790149913, "mean_env_wait_ms": 0.27904755337768966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069550275802612305, "StateBufferConnector_ms": 0.008283376693725586, "ViewRequirementAgentConnector_ms": 0.20414626598358154}, "num_episodes": 18, "episode_return_max": 319.20000000000005, "episode_return_min": -217.30000000000004, "episode_return_mean": 115.04799999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 259.9576465231085, "num_env_steps_trained_throughput_per_sec": 259.9576465231085, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 16065.591, "restore_workers_time_ms": 0.024, "training_step_time_ms": 16064.897, "sample_time_ms": 2781.975, "learn_time_ms": 13259.252, "learn_throughput": 301.676, "synch_weights_time_ms": 19.632}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "04dec_00002", "date": "2024-08-13_16-42-32", "timestamp": 1723581752, "time_this_iter_s": 15.437252044677734, "time_total_s": 1182.6777753829956, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044ab80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1182.6777753829956, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 77.17727272727274, "ram_util_percent": 86.31818181818181}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3115024693428523, "cur_kl_coeff": 0.002224731445312499, "cur_lr": 0.00010000000000000003, "total_loss": 5.191761504531537, "policy_loss": -0.0018798146860072853, "vf_loss": 5.193629801841009, "vf_explained_var": 0.0004197746988326784, "kl": 0.005178895008239737, "entropy": 0.5396521743643221, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 34.77877784781355, "cur_kl_coeff": 0.2565784513950348, "cur_lr": 0.00010000000000000003, "total_loss": 6.617373008072061, "policy_loss": -0.0008880984397831732, "vf_loss": 6.61495884007247, "vf_explained_var": 0.3791928787395437, "kl": 0.0128703276104326, "entropy": 0.6578675885049123, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 319.20000000000005, "episode_reward_min": -217.30000000000004, "episode_reward_mean": 109.82799999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -352.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.49999999999997, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 16.033999999999974, "predator_policy": 38.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [185.69999999999936, 143.4999999999993, 33.80000000000002, 161.49999999999912, 120.19999999999959, 177.99999999999997, 30.100000000000147, 280.7999999999997, 160.3999999999999, 190.2999999999993, 40.0000000000003, 138.4999999999992, 267.7999999999999, 36.70000000000025, 37.80000000000027, 174.19999999999933, 114.09999999999968, 151.79999999999936, 160.09999999999997, 171.19999999999953, 234.2999999999998, 24.30000000000019, 129.09999999999928, 38.50000000000028, 35.600000000000236, 135.2999999999991, 5.199999999999977, 110.59999999999972, -217.30000000000004, -15.399999999999663, 36.70000000000025, 139.3999999999992, 181.59999999999926, 183.09999999999974, 98.69999999999995, 160.19999999999953, 80.69999999999992, 143.4999999999999, 26.800000000000093, 116.99999999999952, 188.29999999999924, 88.9, 154.49999999999937, -32.999999999999766, 104.50000000000003, 31.10000000000017, 35.80000000000005, 37.800000000000296, 29.700000000000124, 52.5, 30.100000000000147, 150.49999999999935, 157.4999999999994, 28.20000000000022, 144.2999999999994, 40.0000000000003, 65.70000000000005, 163.0999999999994, 163.6999999999994, 255.69999999999953, -184.80000000000004, 210.29999999999953, 204.8999999999998, 75.79999999999998, 319.20000000000005, 115.59999999999968, 318.29999999999995, 127.59999999999977, 40.0000000000003, 179.79999999999987, -49.29999999999961, 201.59999999999994, 40.0000000000003, 123.89999999999954, 134.49999999999937, 191.0999999999992, 151.09999999999937, -9.899999999999848, 35.5, 36.700000000000294, 148.39999999999944, 146.7999999999993, 89.79999999999988, 171.4999999999992, 150.4999999999995, 34.30000000000012, 169.09999999999926, 104.99999999999972, 94.69999999999987, 115.19999999999928, 34.20000000000018, 91.99999999999989, 132.99999999999926, 207.2, 186.99999999999986, 114.99999999999952, 51.200000000000145, 131.89999999999932, 40.0000000000003, 190.7999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [166.39999999999998, 5.29999999999995, 20.000000000000014, 123.49999999999989, -166.6000000000001, 34.400000000000006, 20.000000000000014, 141.4999999999998, 57.200000000000024, 20.000000000000014, 56.300000000000004, -46.29999999999999, 1.099999999999983, 20.000000000000014, 135.19999999999976, 119.6, 3.4999999999999893, 23.900000000000006, 168.49999999999997, 15.799999999999978, 20.000000000000014, 20.000000000000014, 126.19999999999978, 5.299999999999965, 26.29999999999999, 153.49999999999983, 20.000000000000014, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999997, 139.39999999999995, 10.09999999999998, 20.000000000000014, 108.79999999999993, 20.000000000000014, -45.399999999999956, 75.50000000000003, 162.1999999999999, -79.00000000000003, 9.200000000000001, 154.09999999999982, -15.700000000000026, 20.000000000000014, 20.000000000000014, 109.09999999999981, 20.000000000000014, 9.499999999999979, 11.599999999999964, 20.000000000000014, 115.3999999999998, 17.900000000000013, -28.000000000000007, -161.8, 20.000000000000014, 35.6, -247.9, -192.39999999999992, -210.4000000000001, 20.000000000000014, 20.000000000000014, 13.699999999999964, 112.3999999999998, 20.000000000000014, 13.699999999999964, 155.89999999999995, 115.39999999999992, -10.300000000000008, -19.89999999999977, 65.60000000000002, 149.59999999999994, -51.399999999999885, -136.30000000000004, 20.000000000000014, -258.4, 146.89999999999984, -5.199999999999934, 20.000000000000014, 22.1, 17.900000000000006, 20.000000000000014, 167.29999999999993, -246.70000000000002, 17.60000000000002, 17.899999999999988, 128.5999999999999, 20.000000000000014, -352.0, 57.80000000000001, -88.30000000000013, 7.399999999999968, -232.3, -164.8, 11.599999999999964, 15.799999999999946, 20.000000000000014, -9.700000000000031, 7.399999999999965, -54.400000000000034, -63.10000000000004, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 72.5, 111.5, 20.000000000000014, 20.000000000000014, -17.800000000000026, -47.19999999999978, 141.4999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.30000000000004, 3.1999999999999615, 134.89999999999998, 133.69999999999993, 4.9999999999999645, 112.69999999999982, 118.99999999999994, -203.8, -322.0, 127.69999999999996, 56.6000000000001, -12.699999999999989, 104.59999999999994, -274.6, -10.600000000000014, 157.09999999999985, 157.0999999999999, 29.600000000000026, 20.000000000000014, 163.7, 131.6, 13.699999999999964, 62.900000000000006, 20.000000000000014, 20.000000000000014, -37.60000000000004, 97.39999999999996, -195.1000000000005, -5.200000000000067, -82.9, 156.49999999999994, 20.000000000000014, 20.000000000000014, 56.900000000000034, 20.000000000000014, 114.49999999999989, 20.000000000000014, 166.09999999999988, 20.000000000000014, 103.39999999999989, 13.699999999999974, -328.9, 20.000000000000014, -121.60000000000002, -31.9, 20.000000000000014, 13.699999999999946, 15.799999999999946, 74.60000000000002, 111.7999999999999, 20.000000000000014, 17.899999999999988, -69.10000000000005, 147.4999999999999, 20.000000000000014, 20.000000000000014, 102.5, -108.7, 20.000000000000014, 121.09999999999994, 20.000000000000014, 20.000000000000014, 17.000000000000007, 55.70000000000003, -109.00000000000003, 71.29999999999993, -3.0999999999999686, -8.800000000000038, 20.000000000000014, 20.000000000000014, -18.999999999999993, 100.99999999999991, 20.000000000000014, -1.8999999999999986, 73.10000000000002, 126.19999999999997, -5.200000000000006, -24.99999999999998, 20.000000000000014, -82.29999999999998, -11.500000000000048, 127.99999999999977, -24.09999999999993, 20.000000000000014, 20.000000000000014, -59.80000000000001, 74.60000000000001], "policy_predator_policy_reward": [6.0, 8.0, 0.0, 0.0, 125.0, 41.0, 0.0, 0.0, 40.0, 3.0, 102.0, 66.0, 9.0, 0.0, 18.0, 8.0, 60.0, 73.0, 2.0, 4.0, 0.0, 0.0, 7.0, 0.0, 53.0, 35.0, 3.0, 0.0, 0.0, 2.0, 15.0, 4.0, 43.0, 41.0, 6.0, 17.0, 74.0, 56.0, 45.0, 43.0, 62.0, 9.0, 13.0, 7.0, 0.0, 0.0, 5.0, 4.0, 0.0, 4.0, 1.0, 1.0, 102.0, 93.0, 17.0, 38.0, 74.0, 149.0, 100.0, 75.0, 0.0, 3.0, 0.0, 7.0, 4.0, 8.0, 33.0, 45.0, 16.0, 37.0, 37.0, 25.0, 103.0, 94.0, 127.0, 128.0, 0.0, 12.0, 30.0, 47.0, 1.0, 0.0, 162.0, 156.0, 0.0, 8.0, 116.0, 183.0, 50.0, 85.0, 146.0, 110.0, 71.0, 118.0, 2.0, 0.0, 17.0, 15.0, 84.0, 86.0, 0.0, 9.0, 29.0, 29.0, 17.0, 9.0, 16.0, 10.0, 27.0, 23.0, 0.0, 0.0, 77.0, 108.0, 25.0, 0.0, 20.0, 5.0, 5.0, 19.0, 173.0, 168.0, 9.0, 17.0, 60.0, 53.0, 181.0, 180.0, 5.0, 0.0, 44.0, 22.0, 23.0, 0.0, 32.0, 19.0, 0.0, 0.0, 53.0, 67.0, 96.0, 55.0, 90.0, 38.0, 0.0, 0.0, 21.0, 26.0, 0.0, 0.0, 5.0, 0.0, 22.0, 12.0, 143.0, 156.0, 104.0, 85.0, 0.0, 3.0, 28.0, 30.0, 11.0, 4.0, 77.0, 64.0, 4.0, 0.0, 14.0, 14.0, 66.0, 57.0, 15.0, 13.0, 56.0, 12.0, 75.0, 73.0, 11.0, 36.0, 12.0, 11.0, 37.0, 54.0, 0.0, 12.0, 74.0, 62.0, 20.0, 46.0, 55.0, 65.0, 81.0, 64.0, 20.0, 8.0, 0.0, 0.0, 107.0, 69.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7771581842320211, "mean_inference_ms": 2.1202594411050506, "mean_action_processing_ms": 0.3204055379786353, "mean_env_wait_ms": 0.2802721093167764, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0075147151947021484, "StateBufferConnector_ms": 0.00832831859588623, "ViewRequirementAgentConnector_ms": 0.18916213512420654}, "num_episodes": 18, "episode_return_max": 319.20000000000005, "episode_return_min": -217.30000000000004, "episode_return_mean": 109.82799999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 230.7971015988034, "num_env_steps_trained_throughput_per_sec": 230.7971015988034, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 16236.2, "restore_workers_time_ms": 0.024, "training_step_time_ms": 16235.508, "sample_time_ms": 2828.908, "learn_time_ms": 13382.761, "learn_throughput": 298.892, "synch_weights_time_ms": 19.826}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "04dec_00002", "date": "2024-08-13_16-42-49", "timestamp": 1723581769, "time_this_iter_s": 17.444687843322754, "time_total_s": 1200.1224632263184, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04413a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1200.1224632263184, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 80.616, "ram_util_percent": 86.18400000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3026033032508124, "cur_kl_coeff": 0.002224731445312499, "cur_lr": 0.00010000000000000003, "total_loss": 4.977546287465978, "policy_loss": -0.002361822143201987, "vf_loss": 4.979895948859119, "vf_explained_var": -0.000107370482550727, "kl": 0.0054648280513073825, "entropy": 0.5280045484897321, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.451219551336195, "cur_kl_coeff": 0.2565784513950348, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": 0.0020512477679562476, "vf_loss": 6.9512143654798075, "vf_explained_var": 0.4462202353767617, "kl": Infinity, "entropy": 0.6333528059500235, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 319.20000000000005, "episode_reward_min": -217.30000000000004, "episode_reward_mean": 99.0249999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -352.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.29999999999993, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 10.932499999999981, "predator_policy": 38.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [129.09999999999928, 38.50000000000028, 35.600000000000236, 135.2999999999991, 5.199999999999977, 110.59999999999972, -217.30000000000004, -15.399999999999663, 36.70000000000025, 139.3999999999992, 181.59999999999926, 183.09999999999974, 98.69999999999995, 160.19999999999953, 80.69999999999992, 143.4999999999999, 26.800000000000093, 116.99999999999952, 188.29999999999924, 88.9, 154.49999999999937, -32.999999999999766, 104.50000000000003, 31.10000000000017, 35.80000000000005, 37.800000000000296, 29.700000000000124, 52.5, 30.100000000000147, 150.49999999999935, 157.4999999999994, 28.20000000000022, 144.2999999999994, 40.0000000000003, 65.70000000000005, 163.0999999999994, 163.6999999999994, 255.69999999999953, -184.80000000000004, 210.29999999999953, 204.8999999999998, 75.79999999999998, 319.20000000000005, 115.59999999999968, 318.29999999999995, 127.59999999999977, 40.0000000000003, 179.79999999999987, -49.29999999999961, 201.59999999999994, 40.0000000000003, 123.89999999999954, 134.49999999999937, 191.0999999999992, 151.09999999999937, -9.899999999999848, 35.5, 36.700000000000294, 148.39999999999944, 146.7999999999993, 89.79999999999988, 171.4999999999992, 150.4999999999995, 34.30000000000012, 169.09999999999926, 104.99999999999972, 94.69999999999987, 115.19999999999928, 34.20000000000018, 91.99999999999989, 132.99999999999926, 207.2, 186.99999999999986, 114.99999999999952, 51.200000000000145, 131.89999999999932, 40.0000000000003, 190.7999999999999, 141.7999999999994, 129.09999999999926, 43.600000000000094, 147.89999999999964, 34.50000000000022, 38.9000000000003, 40.0000000000003, 91.4999999999993, 36.70000000000025, 182.1999999999991, -0.500000000000032, 36.10000000000026, 81.09999999999997, 40.0000000000003, 135.99999999999952, 160.09999999999968, 40.0000000000003, 155.99999999999952, -3.3999999999999755, 88.1999999999995, 176.09999999999917, 158.89999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 109.09999999999981, 20.000000000000014, 9.499999999999979, 11.599999999999964, 20.000000000000014, 115.3999999999998, 17.900000000000013, -28.000000000000007, -161.8, 20.000000000000014, 35.6, -247.9, -192.39999999999992, -210.4000000000001, 20.000000000000014, 20.000000000000014, 13.699999999999964, 112.3999999999998, 20.000000000000014, 13.699999999999964, 155.89999999999995, 115.39999999999992, -10.300000000000008, -19.89999999999977, 65.60000000000002, 149.59999999999994, -51.399999999999885, -136.30000000000004, 20.000000000000014, -258.4, 146.89999999999984, -5.199999999999934, 20.000000000000014, 22.1, 17.900000000000006, 20.000000000000014, 167.29999999999993, -246.70000000000002, 17.60000000000002, 17.899999999999988, 128.5999999999999, 20.000000000000014, -352.0, 57.80000000000001, -88.30000000000013, 7.399999999999968, -232.3, -164.8, 11.599999999999964, 15.799999999999946, 20.000000000000014, -9.700000000000031, 7.399999999999965, -54.400000000000034, -63.10000000000004, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 72.5, 111.5, 20.000000000000014, 20.000000000000014, -17.800000000000026, -47.19999999999978, 141.4999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.30000000000004, 3.1999999999999615, 134.89999999999998, 133.69999999999993, 4.9999999999999645, 112.69999999999982, 118.99999999999994, -203.8, -322.0, 127.69999999999996, 56.6000000000001, -12.699999999999989, 104.59999999999994, -274.6, -10.600000000000014, 157.09999999999985, 157.0999999999999, 29.600000000000026, 20.000000000000014, 163.7, 131.6, 13.699999999999964, 62.900000000000006, 20.000000000000014, 20.000000000000014, -37.60000000000004, 97.39999999999996, -195.1000000000005, -5.200000000000067, -82.9, 156.49999999999994, 20.000000000000014, 20.000000000000014, 56.900000000000034, 20.000000000000014, 114.49999999999989, 20.000000000000014, 166.09999999999988, 20.000000000000014, 103.39999999999989, 13.699999999999974, -328.9, 20.000000000000014, -121.60000000000002, -31.9, 20.000000000000014, 13.699999999999946, 15.799999999999946, 74.60000000000002, 111.7999999999999, 20.000000000000014, 17.899999999999988, -69.10000000000005, 147.4999999999999, 20.000000000000014, 20.000000000000014, 102.5, -108.7, 20.000000000000014, 121.09999999999994, 20.000000000000014, 20.000000000000014, 17.000000000000007, 55.70000000000003, -109.00000000000003, 71.29999999999993, -3.0999999999999686, -8.800000000000038, 20.000000000000014, 20.000000000000014, -18.999999999999993, 100.99999999999991, 20.000000000000014, -1.8999999999999986, 73.10000000000002, 126.19999999999997, -5.200000000000006, -24.99999999999998, 20.000000000000014, -82.29999999999998, -11.500000000000048, 127.99999999999977, -24.09999999999993, 20.000000000000014, 20.000000000000014, -59.80000000000001, 74.60000000000001, 20.000000000000014, 63.799999999999955, 1.099999999999975, 118.9999999999998, 1.0999999999999865, -110.50000000000003, -42.999999999999986, 122.89999999999996, 20.000000000000014, 9.499999999999964, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, -3.100000000000051, 77.59999999999977, 13.699999999999964, 20.000000000000014, 97.39999999999985, 84.79999999999976, -5.200000000000026, -70.29999999999978, 20.000000000000014, -40.90000000000003, -2.499999999999993, -51.39999999999977, 20.000000000000014, 20.000000000000014, -17.79999999999974, 69.80000000000001, 74.0, 49.1000000000001, 20.000000000000014, 20.000000000000014, -30.39999999999975, 154.39999999999992, -17.199999999999996, -125.20000000000005, 95.59999999999971, -51.39999999999986, 20.000000000000014, 148.09999999999988, -24.70000000000004, 68.60000000000002], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 4.0, 0.0, 4.0, 1.0, 1.0, 102.0, 93.0, 17.0, 38.0, 74.0, 149.0, 100.0, 75.0, 0.0, 3.0, 0.0, 7.0, 4.0, 8.0, 33.0, 45.0, 16.0, 37.0, 37.0, 25.0, 103.0, 94.0, 127.0, 128.0, 0.0, 12.0, 30.0, 47.0, 1.0, 0.0, 162.0, 156.0, 0.0, 8.0, 116.0, 183.0, 50.0, 85.0, 146.0, 110.0, 71.0, 118.0, 2.0, 0.0, 17.0, 15.0, 84.0, 86.0, 0.0, 9.0, 29.0, 29.0, 17.0, 9.0, 16.0, 10.0, 27.0, 23.0, 0.0, 0.0, 77.0, 108.0, 25.0, 0.0, 20.0, 5.0, 5.0, 19.0, 173.0, 168.0, 9.0, 17.0, 60.0, 53.0, 181.0, 180.0, 5.0, 0.0, 44.0, 22.0, 23.0, 0.0, 32.0, 19.0, 0.0, 0.0, 53.0, 67.0, 96.0, 55.0, 90.0, 38.0, 0.0, 0.0, 21.0, 26.0, 0.0, 0.0, 5.0, 0.0, 22.0, 12.0, 143.0, 156.0, 104.0, 85.0, 0.0, 3.0, 28.0, 30.0, 11.0, 4.0, 77.0, 64.0, 4.0, 0.0, 14.0, 14.0, 66.0, 57.0, 15.0, 13.0, 56.0, 12.0, 75.0, 73.0, 11.0, 36.0, 12.0, 11.0, 37.0, 54.0, 0.0, 12.0, 74.0, 62.0, 20.0, 46.0, 55.0, 65.0, 81.0, 64.0, 20.0, 8.0, 0.0, 0.0, 107.0, 69.0, 31.0, 27.0, 0.0, 9.0, 60.0, 93.0, 42.0, 26.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 8.0, 0.0, 3.0, 0.0, 0.0, 35.0, 40.0, 28.0, 29.0, 89.0, 46.0, 0.0, 0.0, 49.0, 35.0, 21.0, 16.0, 0.0, 0.0, 25.0, 7.0, 78.0, 61.0, 10.0, 34.0, 8.0, 0.0, 73.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7801462830439161, "mean_inference_ms": 2.132863059306128, "mean_action_processing_ms": 0.32139700156770573, "mean_env_wait_ms": 0.2814877416847337, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014556884765625, "StateBufferConnector_ms": 0.008426547050476074, "ViewRequirementAgentConnector_ms": 0.19064712524414062}, "num_episodes": 22, "episode_return_max": 319.20000000000005, "episode_return_min": -217.30000000000004, "episode_return_mean": 99.0249999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.2817241333102, "num_env_steps_trained_throughput_per_sec": 268.2817241333102, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 16177.809, "restore_workers_time_ms": 0.024, "training_step_time_ms": 16177.119, "sample_time_ms": 2816.258, "learn_time_ms": 13336.541, "learn_throughput": 299.928, "synch_weights_time_ms": 20.278}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "04dec_00002", "date": "2024-08-13_16-43-04", "timestamp": 1723581784, "time_this_iter_s": 14.987866878509521, "time_total_s": 1215.1103301048279, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06e2790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1215.1103301048279, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 75.73333333333333, "ram_util_percent": 86.29523809523809}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2213001159133103, "cur_kl_coeff": 0.002224731445312499, "cur_lr": 0.00010000000000000003, "total_loss": 5.006770793218461, "policy_loss": -0.003870548089847915, "vf_loss": 5.010627898085055, "vf_explained_var": 0.0005078515047749515, "kl": 0.006046269239948979, "entropy": 0.5021932271895585, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.50628119552577, "cur_kl_coeff": 0.3848676770925522, "cur_lr": 0.00010000000000000003, "total_loss": 7.148764739717756, "policy_loss": -0.0002387560135315335, "vf_loss": 7.147041315250296, "vf_explained_var": 0.046254009670681426, "kl": 0.005098351697422164, "entropy": 0.655331566661754, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 319.20000000000005, "episode_reward_min": -184.80000000000004, "episode_reward_mean": 104.38999999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -352.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.09999999999994, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 11.959999999999978, "predator_policy": 40.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [188.29999999999924, 88.9, 154.49999999999937, -32.999999999999766, 104.50000000000003, 31.10000000000017, 35.80000000000005, 37.800000000000296, 29.700000000000124, 52.5, 30.100000000000147, 150.49999999999935, 157.4999999999994, 28.20000000000022, 144.2999999999994, 40.0000000000003, 65.70000000000005, 163.0999999999994, 163.6999999999994, 255.69999999999953, -184.80000000000004, 210.29999999999953, 204.8999999999998, 75.79999999999998, 319.20000000000005, 115.59999999999968, 318.29999999999995, 127.59999999999977, 40.0000000000003, 179.79999999999987, -49.29999999999961, 201.59999999999994, 40.0000000000003, 123.89999999999954, 134.49999999999937, 191.0999999999992, 151.09999999999937, -9.899999999999848, 35.5, 36.700000000000294, 148.39999999999944, 146.7999999999993, 89.79999999999988, 171.4999999999992, 150.4999999999995, 34.30000000000012, 169.09999999999926, 104.99999999999972, 94.69999999999987, 115.19999999999928, 34.20000000000018, 91.99999999999989, 132.99999999999926, 207.2, 186.99999999999986, 114.99999999999952, 51.200000000000145, 131.89999999999932, 40.0000000000003, 190.7999999999999, 141.7999999999994, 129.09999999999926, 43.600000000000094, 147.89999999999964, 34.50000000000022, 38.9000000000003, 40.0000000000003, 91.4999999999993, 36.70000000000025, 182.1999999999991, -0.500000000000032, 36.10000000000026, 81.09999999999997, 40.0000000000003, 135.99999999999952, 160.09999999999968, 40.0000000000003, 155.99999999999952, -3.3999999999999755, 88.1999999999995, 176.09999999999917, 158.89999999999992, 68.7000000000002, 46.800000000000026, 40.0000000000003, 130.79999999999953, 226.09999999999962, 67.50000000000006, 314.90000000000015, 131.1999999999997, 128.39999999999952, 241.19999999999973, -3.0999999999999974, 279.5999999999999, -25.199999999999946, 21.299999999999994, 144.89999999999938, 21.90000000000004, -50.89999999999975, 141.6999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 167.29999999999993, -246.70000000000002, 17.60000000000002, 17.899999999999988, 128.5999999999999, 20.000000000000014, -352.0, 57.80000000000001, -88.30000000000013, 7.399999999999968, -232.3, -164.8, 11.599999999999964, 15.799999999999946, 20.000000000000014, -9.700000000000031, 7.399999999999965, -54.400000000000034, -63.10000000000004, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 72.5, 111.5, 20.000000000000014, 20.000000000000014, -17.800000000000026, -47.19999999999978, 141.4999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.30000000000004, 3.1999999999999615, 134.89999999999998, 133.69999999999993, 4.9999999999999645, 112.69999999999982, 118.99999999999994, -203.8, -322.0, 127.69999999999996, 56.6000000000001, -12.699999999999989, 104.59999999999994, -274.6, -10.600000000000014, 157.09999999999985, 157.0999999999999, 29.600000000000026, 20.000000000000014, 163.7, 131.6, 13.699999999999964, 62.900000000000006, 20.000000000000014, 20.000000000000014, -37.60000000000004, 97.39999999999996, -195.1000000000005, -5.200000000000067, -82.9, 156.49999999999994, 20.000000000000014, 20.000000000000014, 56.900000000000034, 20.000000000000014, 114.49999999999989, 20.000000000000014, 166.09999999999988, 20.000000000000014, 103.39999999999989, 13.699999999999974, -328.9, 20.000000000000014, -121.60000000000002, -31.9, 20.000000000000014, 13.699999999999946, 15.799999999999946, 74.60000000000002, 111.7999999999999, 20.000000000000014, 17.899999999999988, -69.10000000000005, 147.4999999999999, 20.000000000000014, 20.000000000000014, 102.5, -108.7, 20.000000000000014, 121.09999999999994, 20.000000000000014, 20.000000000000014, 17.000000000000007, 55.70000000000003, -109.00000000000003, 71.29999999999993, -3.0999999999999686, -8.800000000000038, 20.000000000000014, 20.000000000000014, -18.999999999999993, 100.99999999999991, 20.000000000000014, -1.8999999999999986, 73.10000000000002, 126.19999999999997, -5.200000000000006, -24.99999999999998, 20.000000000000014, -82.29999999999998, -11.500000000000048, 127.99999999999977, -24.09999999999993, 20.000000000000014, 20.000000000000014, -59.80000000000001, 74.60000000000001, 20.000000000000014, 63.799999999999955, 1.099999999999975, 118.9999999999998, 1.0999999999999865, -110.50000000000003, -42.999999999999986, 122.89999999999996, 20.000000000000014, 9.499999999999964, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, -3.100000000000051, 77.59999999999977, 13.699999999999964, 20.000000000000014, 97.39999999999985, 84.79999999999976, -5.200000000000026, -70.29999999999978, 20.000000000000014, -40.90000000000003, -2.499999999999993, -51.39999999999977, 20.000000000000014, 20.000000000000014, -17.79999999999974, 69.80000000000001, 74.0, 49.1000000000001, 20.000000000000014, 20.000000000000014, -30.39999999999975, 154.39999999999992, -17.199999999999996, -125.20000000000005, 95.59999999999971, -51.39999999999986, 20.000000000000014, 148.09999999999988, -24.70000000000004, 68.60000000000002, 1.0999999999999759, -111.40000000000003, -172.90000000000006, 13.699999999999964, 20.000000000000014, 20.000000000000014, 115.99999999999986, -26.199999999999992, 109.99999999999984, 82.09999999999998, 100.10000000000001, -139.60000000000034, 169.09999999999994, 138.79999999999987, 130.6999999999997, -344.5, -36.69999999999984, 124.09999999999988, 84.19999999999999, 80.00000000000003, -8.80000000000004, -127.30000000000013, 126.19999999999993, 61.400000000000006, -138.7, -158.50000000000023, 20.000000000000014, -15.699999999999747, 113.8999999999999, 20.000000000000014, 20.000000000000014, -18.099999999999977, -146.1999999999999, -72.69999999999989, 20.000000000000014, 121.69999999999979], "policy_predator_policy_reward": [1.0, 0.0, 162.0, 156.0, 0.0, 8.0, 116.0, 183.0, 50.0, 85.0, 146.0, 110.0, 71.0, 118.0, 2.0, 0.0, 17.0, 15.0, 84.0, 86.0, 0.0, 9.0, 29.0, 29.0, 17.0, 9.0, 16.0, 10.0, 27.0, 23.0, 0.0, 0.0, 77.0, 108.0, 25.0, 0.0, 20.0, 5.0, 5.0, 19.0, 173.0, 168.0, 9.0, 17.0, 60.0, 53.0, 181.0, 180.0, 5.0, 0.0, 44.0, 22.0, 23.0, 0.0, 32.0, 19.0, 0.0, 0.0, 53.0, 67.0, 96.0, 55.0, 90.0, 38.0, 0.0, 0.0, 21.0, 26.0, 0.0, 0.0, 5.0, 0.0, 22.0, 12.0, 143.0, 156.0, 104.0, 85.0, 0.0, 3.0, 28.0, 30.0, 11.0, 4.0, 77.0, 64.0, 4.0, 0.0, 14.0, 14.0, 66.0, 57.0, 15.0, 13.0, 56.0, 12.0, 75.0, 73.0, 11.0, 36.0, 12.0, 11.0, 37.0, 54.0, 0.0, 12.0, 74.0, 62.0, 20.0, 46.0, 55.0, 65.0, 81.0, 64.0, 20.0, 8.0, 0.0, 0.0, 107.0, 69.0, 31.0, 27.0, 0.0, 9.0, 60.0, 93.0, 42.0, 26.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 8.0, 0.0, 3.0, 0.0, 0.0, 35.0, 40.0, 28.0, 29.0, 89.0, 46.0, 0.0, 0.0, 49.0, 35.0, 21.0, 16.0, 0.0, 0.0, 25.0, 7.0, 78.0, 61.0, 10.0, 34.0, 8.0, 0.0, 73.0, 42.0, 85.0, 94.0, 110.0, 96.0, 0.0, 0.0, 20.0, 21.0, 30.0, 4.0, 78.0, 29.0, 0.0, 7.0, 166.0, 179.0, 39.0, 2.0, 32.0, 45.0, 56.0, 77.0, 41.0, 51.0, 120.0, 152.0, 17.0, 0.0, 0.0, 11.0, 12.0, 8.0, 106.0, 62.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7823396205341993, "mean_inference_ms": 2.142648655693612, "mean_action_processing_ms": 0.32214098308737005, "mean_env_wait_ms": 0.2824304415139279, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019266605377197266, "StateBufferConnector_ms": 0.008375287055969238, "ViewRequirementAgentConnector_ms": 0.18283987045288086}, "num_episodes": 18, "episode_return_max": 319.20000000000005, "episode_return_min": -184.80000000000004, "episode_return_mean": 104.38999999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 259.87640377262505, "num_env_steps_trained_throughput_per_sec": 259.87640377262505, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 16169.106, "restore_workers_time_ms": 0.025, "training_step_time_ms": 16168.412, "sample_time_ms": 2706.331, "learn_time_ms": 13437.425, "learn_throughput": 297.676, "synch_weights_time_ms": 20.802}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "04dec_00002", "date": "2024-08-13_16-43-20", "timestamp": 1723581800, "time_this_iter_s": 15.475849866867065, "time_total_s": 1230.586179971695, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06e2430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1230.586179971695, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 76.82272727272728, "ram_util_percent": 86.44545454545452}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.100287676929797, "cur_kl_coeff": 0.002224731445312499, "cur_lr": 0.00010000000000000003, "total_loss": 4.9442420434699486, "policy_loss": -0.0014417903294550284, "vf_loss": 4.945674231821898, "vf_explained_var": -0.0008424405383054541, "kl": 0.00431550750135775, "entropy": 0.4322507391215632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 31.074503962261968, "cur_kl_coeff": 0.3848676770925522, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": 0.000858149255956055, "vf_loss": 6.180199867833859, "vf_explained_var": -0.07396166983735625, "kl": Infinity, "entropy": 0.6654044519025812, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 319.20000000000005, "episode_reward_min": -95.5, "episode_reward_mean": 98.66199999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -344.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.09999999999994, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 10.03099999999998, "predator_policy": 39.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [75.79999999999998, 319.20000000000005, 115.59999999999968, 318.29999999999995, 127.59999999999977, 40.0000000000003, 179.79999999999987, -49.29999999999961, 201.59999999999994, 40.0000000000003, 123.89999999999954, 134.49999999999937, 191.0999999999992, 151.09999999999937, -9.899999999999848, 35.5, 36.700000000000294, 148.39999999999944, 146.7999999999993, 89.79999999999988, 171.4999999999992, 150.4999999999995, 34.30000000000012, 169.09999999999926, 104.99999999999972, 94.69999999999987, 115.19999999999928, 34.20000000000018, 91.99999999999989, 132.99999999999926, 207.2, 186.99999999999986, 114.99999999999952, 51.200000000000145, 131.89999999999932, 40.0000000000003, 190.7999999999999, 141.7999999999994, 129.09999999999926, 43.600000000000094, 147.89999999999964, 34.50000000000022, 38.9000000000003, 40.0000000000003, 91.4999999999993, 36.70000000000025, 182.1999999999991, -0.500000000000032, 36.10000000000026, 81.09999999999997, 40.0000000000003, 135.99999999999952, 160.09999999999968, 40.0000000000003, 155.99999999999952, -3.3999999999999755, 88.1999999999995, 176.09999999999917, 158.89999999999992, 68.7000000000002, 46.800000000000026, 40.0000000000003, 130.79999999999953, 226.09999999999962, 67.50000000000006, 314.90000000000015, 131.1999999999997, 128.39999999999952, 241.19999999999973, -3.0999999999999974, 279.5999999999999, -25.199999999999946, 21.299999999999994, 144.89999999999938, 21.90000000000004, -50.89999999999975, 141.6999999999992, 177.79999999999944, 114.59999999999934, 108.1999999999995, -95.5, 40.0000000000003, 51.700000000000195, 178.5999999999992, 10.099999999999952, 95.79999999999956, 29.000000000000284, 40.0000000000003, 21.19999999999991, 93.49999999999966, 76.30000000000001, 70.90000000000015, 13.799999999999914, 249.19999999999948, -44.09999999999956, 115.79999999999939, 105.69999999999918, -54.99999999999981, 156.59999999999994, -7.7000000000000846], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-274.6, -10.600000000000014, 157.09999999999985, 157.0999999999999, 29.600000000000026, 20.000000000000014, 163.7, 131.6, 13.699999999999964, 62.900000000000006, 20.000000000000014, 20.000000000000014, -37.60000000000004, 97.39999999999996, -195.1000000000005, -5.200000000000067, -82.9, 156.49999999999994, 20.000000000000014, 20.000000000000014, 56.900000000000034, 20.000000000000014, 114.49999999999989, 20.000000000000014, 166.09999999999988, 20.000000000000014, 103.39999999999989, 13.699999999999974, -328.9, 20.000000000000014, -121.60000000000002, -31.9, 20.000000000000014, 13.699999999999946, 15.799999999999946, 74.60000000000002, 111.7999999999999, 20.000000000000014, 17.899999999999988, -69.10000000000005, 147.4999999999999, 20.000000000000014, 20.000000000000014, 102.5, -108.7, 20.000000000000014, 121.09999999999994, 20.000000000000014, 20.000000000000014, 17.000000000000007, 55.70000000000003, -109.00000000000003, 71.29999999999993, -3.0999999999999686, -8.800000000000038, 20.000000000000014, 20.000000000000014, -18.999999999999993, 100.99999999999991, 20.000000000000014, -1.8999999999999986, 73.10000000000002, 126.19999999999997, -5.200000000000006, -24.99999999999998, 20.000000000000014, -82.29999999999998, -11.500000000000048, 127.99999999999977, -24.09999999999993, 20.000000000000014, 20.000000000000014, -59.80000000000001, 74.60000000000001, 20.000000000000014, 63.799999999999955, 1.099999999999975, 118.9999999999998, 1.0999999999999865, -110.50000000000003, -42.999999999999986, 122.89999999999996, 20.000000000000014, 9.499999999999964, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, -3.100000000000051, 77.59999999999977, 13.699999999999964, 20.000000000000014, 97.39999999999985, 84.79999999999976, -5.200000000000026, -70.29999999999978, 20.000000000000014, -40.90000000000003, -2.499999999999993, -51.39999999999977, 20.000000000000014, 20.000000000000014, -17.79999999999974, 69.80000000000001, 74.0, 49.1000000000001, 20.000000000000014, 20.000000000000014, -30.39999999999975, 154.39999999999992, -17.199999999999996, -125.20000000000005, 95.59999999999971, -51.39999999999986, 20.000000000000014, 148.09999999999988, -24.70000000000004, 68.60000000000002, 1.0999999999999759, -111.40000000000003, -172.90000000000006, 13.699999999999964, 20.000000000000014, 20.000000000000014, 115.99999999999986, -26.199999999999992, 109.99999999999984, 82.09999999999998, 100.10000000000001, -139.60000000000034, 169.09999999999994, 138.79999999999987, 130.6999999999997, -344.5, -36.69999999999984, 124.09999999999988, 84.19999999999999, 80.00000000000003, -8.80000000000004, -127.30000000000013, 126.19999999999993, 61.400000000000006, -138.7, -158.50000000000023, 20.000000000000014, -15.699999999999747, 113.8999999999999, 20.000000000000014, 20.000000000000014, -18.099999999999977, -146.1999999999999, -72.69999999999989, 20.000000000000014, 121.69999999999979, 20.000000000000014, 153.79999999999998, 35.599999999999966, 20.000000000000014, 114.49999999999977, -85.30000000000007, -177.70000000000002, -101.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -250.29999999999998, 103.69999999999973, 74.90000000000006, 20.000000000000014, -40.89999999999984, 20.000000000000014, 75.79999999999995, 20.000000000000014, -1.0000000000000235, 20.000000000000014, 20.000000000000014, -104.50000000000009, -85.30000000000007, -35.49999999999997, 20.000000000000014, 89.29999999999953, -42.99999999999977, 20.000000000000014, -114.1, 20.000000000000014, -194.20000000000027, 140.89999999999992, 95.29999999999981, -68.19999999999983, -61.8999999999998, 87.79999999999995, 20.000000000000014, 85.69999999999979, 20.000000000000014, 20.000000000000014, -316.0, 114.5, -253.89999999999998, -162.6999999999999, 20.000000000000014], "policy_predator_policy_reward": [181.0, 180.0, 5.0, 0.0, 44.0, 22.0, 23.0, 0.0, 32.0, 19.0, 0.0, 0.0, 53.0, 67.0, 96.0, 55.0, 90.0, 38.0, 0.0, 0.0, 21.0, 26.0, 0.0, 0.0, 5.0, 0.0, 22.0, 12.0, 143.0, 156.0, 104.0, 85.0, 0.0, 3.0, 28.0, 30.0, 11.0, 4.0, 77.0, 64.0, 4.0, 0.0, 14.0, 14.0, 66.0, 57.0, 15.0, 13.0, 56.0, 12.0, 75.0, 73.0, 11.0, 36.0, 12.0, 11.0, 37.0, 54.0, 0.0, 12.0, 74.0, 62.0, 20.0, 46.0, 55.0, 65.0, 81.0, 64.0, 20.0, 8.0, 0.0, 0.0, 107.0, 69.0, 31.0, 27.0, 0.0, 9.0, 60.0, 93.0, 42.0, 26.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 8.0, 0.0, 3.0, 0.0, 0.0, 35.0, 40.0, 28.0, 29.0, 89.0, 46.0, 0.0, 0.0, 49.0, 35.0, 21.0, 16.0, 0.0, 0.0, 25.0, 7.0, 78.0, 61.0, 10.0, 34.0, 8.0, 0.0, 73.0, 42.0, 85.0, 94.0, 110.0, 96.0, 0.0, 0.0, 20.0, 21.0, 30.0, 4.0, 78.0, 29.0, 0.0, 7.0, 166.0, 179.0, 39.0, 2.0, 32.0, 45.0, 56.0, 77.0, 41.0, 51.0, 120.0, 152.0, 17.0, 0.0, 0.0, 11.0, 12.0, 8.0, 106.0, 62.0, 0.0, 0.0, 0.0, 4.0, 47.0, 12.0, 44.0, 35.0, 64.0, 120.0, 0.0, 0.0, 137.0, 145.0, 0.0, 0.0, 28.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 99.0, 112.0, 50.0, 59.0, 30.0, 0.0, 67.0, 98.0, 97.0, 91.0, 5.0, 8.0, 22.0, 64.0, 1.0, 7.0, 0.0, 0.0, 77.0, 164.0, 155.0, 141.0, 52.0, 83.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7851922049787425, "mean_inference_ms": 2.1549862180866564, "mean_action_processing_ms": 0.3230422876525664, "mean_env_wait_ms": 0.2836068917371806, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01805853843688965, "StateBufferConnector_ms": 0.008335232734680176, "ViewRequirementAgentConnector_ms": 0.17920970916748047}, "num_episodes": 23, "episode_return_max": 319.20000000000005, "episode_return_min": -95.5, "episode_return_mean": 98.66199999999982, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 264.43969186623485, "num_env_steps_trained_throughput_per_sec": 264.43969186623485, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 16074.971, "restore_workers_time_ms": 0.025, "training_step_time_ms": 16074.277, "sample_time_ms": 2535.763, "learn_time_ms": 13515.662, "learn_throughput": 295.953, "synch_weights_time_ms": 19.542}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "04dec_00002", "date": "2024-08-13_16-43-35", "timestamp": 1723581815, "time_this_iter_s": 15.20554804801941, "time_total_s": 1245.7917280197144, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04413a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1245.7917280197144, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 76.00952380952383, "ram_util_percent": 86.5095238095238}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1851613858389476, "cur_kl_coeff": 0.0011123657226562494, "cur_lr": 0.00010000000000000003, "total_loss": 4.497418685564919, "policy_loss": -0.0018724476537918524, "vf_loss": 4.499286766783901, "vf_explained_var": -0.0003369216565732603, "kl": 0.003924983127685119, "entropy": 0.4526109785156906, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 30.367004723460585, "cur_kl_coeff": 0.5773015156388281, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": 5.8011763862201144e-05, "vf_loss": 5.794121430412171, "vf_explained_var": -0.39166929674527, "kl": Infinity, "entropy": 0.6444255289892671, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 314.90000000000015, "episode_reward_min": -95.5, "episode_reward_mean": 85.92999999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -344.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.09999999999994, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": 4.32499999999998, "predator_policy": 38.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [146.7999999999993, 89.79999999999988, 171.4999999999992, 150.4999999999995, 34.30000000000012, 169.09999999999926, 104.99999999999972, 94.69999999999987, 115.19999999999928, 34.20000000000018, 91.99999999999989, 132.99999999999926, 207.2, 186.99999999999986, 114.99999999999952, 51.200000000000145, 131.89999999999932, 40.0000000000003, 190.7999999999999, 141.7999999999994, 129.09999999999926, 43.600000000000094, 147.89999999999964, 34.50000000000022, 38.9000000000003, 40.0000000000003, 91.4999999999993, 36.70000000000025, 182.1999999999991, -0.500000000000032, 36.10000000000026, 81.09999999999997, 40.0000000000003, 135.99999999999952, 160.09999999999968, 40.0000000000003, 155.99999999999952, -3.3999999999999755, 88.1999999999995, 176.09999999999917, 158.89999999999992, 68.7000000000002, 46.800000000000026, 40.0000000000003, 130.79999999999953, 226.09999999999962, 67.50000000000006, 314.90000000000015, 131.1999999999997, 128.39999999999952, 241.19999999999973, -3.0999999999999974, 279.5999999999999, -25.199999999999946, 21.299999999999994, 144.89999999999938, 21.90000000000004, -50.89999999999975, 141.6999999999992, 177.79999999999944, 114.59999999999934, 108.1999999999995, -95.5, 40.0000000000003, 51.700000000000195, 178.5999999999992, 10.099999999999952, 95.79999999999956, 29.000000000000284, 40.0000000000003, 21.19999999999991, 93.49999999999966, 76.30000000000001, 70.90000000000015, 13.799999999999914, 249.19999999999948, -44.09999999999956, 115.79999999999939, 105.69999999999918, -54.99999999999981, 156.59999999999994, -7.7000000000000846, 112.29999999999968, 40.0000000000003, 108.19999999999959, 40.0000000000003, 23.000000000000256, 102.5999999999998, -6.199999999999827, 14.999999999999934, 4.100000000000087, 21.200000000000017, 40.0000000000003, 52.30000000000013, 36.70000000000025, 137.3999999999996, 27.90000000000011, 117.3999999999993, 9.400000000000208, 25.400000000000148], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [111.7999999999999, 20.000000000000014, 17.899999999999988, -69.10000000000005, 147.4999999999999, 20.000000000000014, 20.000000000000014, 102.5, -108.7, 20.000000000000014, 121.09999999999994, 20.000000000000014, 20.000000000000014, 17.000000000000007, 55.70000000000003, -109.00000000000003, 71.29999999999993, -3.0999999999999686, -8.800000000000038, 20.000000000000014, 20.000000000000014, -18.999999999999993, 100.99999999999991, 20.000000000000014, -1.8999999999999986, 73.10000000000002, 126.19999999999997, -5.200000000000006, -24.99999999999998, 20.000000000000014, -82.29999999999998, -11.500000000000048, 127.99999999999977, -24.09999999999993, 20.000000000000014, 20.000000000000014, -59.80000000000001, 74.60000000000001, 20.000000000000014, 63.799999999999955, 1.099999999999975, 118.9999999999998, 1.0999999999999865, -110.50000000000003, -42.999999999999986, 122.89999999999996, 20.000000000000014, 9.499999999999964, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, -3.100000000000051, 77.59999999999977, 13.699999999999964, 20.000000000000014, 97.39999999999985, 84.79999999999976, -5.200000000000026, -70.29999999999978, 20.000000000000014, -40.90000000000003, -2.499999999999993, -51.39999999999977, 20.000000000000014, 20.000000000000014, -17.79999999999974, 69.80000000000001, 74.0, 49.1000000000001, 20.000000000000014, 20.000000000000014, -30.39999999999975, 154.39999999999992, -17.199999999999996, -125.20000000000005, 95.59999999999971, -51.39999999999986, 20.000000000000014, 148.09999999999988, -24.70000000000004, 68.60000000000002, 1.0999999999999759, -111.40000000000003, -172.90000000000006, 13.699999999999964, 20.000000000000014, 20.000000000000014, 115.99999999999986, -26.199999999999992, 109.99999999999984, 82.09999999999998, 100.10000000000001, -139.60000000000034, 169.09999999999994, 138.79999999999987, 130.6999999999997, -344.5, -36.69999999999984, 124.09999999999988, 84.19999999999999, 80.00000000000003, -8.80000000000004, -127.30000000000013, 126.19999999999993, 61.400000000000006, -138.7, -158.50000000000023, 20.000000000000014, -15.699999999999747, 113.8999999999999, 20.000000000000014, 20.000000000000014, -18.099999999999977, -146.1999999999999, -72.69999999999989, 20.000000000000014, 121.69999999999979, 20.000000000000014, 153.79999999999998, 35.599999999999966, 20.000000000000014, 114.49999999999977, -85.30000000000007, -177.70000000000002, -101.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -250.29999999999998, 103.69999999999973, 74.90000000000006, 20.000000000000014, -40.89999999999984, 20.000000000000014, 75.79999999999995, 20.000000000000014, -1.0000000000000235, 20.000000000000014, 20.000000000000014, -104.50000000000009, -85.30000000000007, -35.49999999999997, 20.000000000000014, 89.29999999999953, -42.99999999999977, 20.000000000000014, -114.1, 20.000000000000014, -194.20000000000027, 140.89999999999992, 95.29999999999981, -68.19999999999983, -61.8999999999998, 87.79999999999995, 20.000000000000014, 85.69999999999979, 20.000000000000014, 20.000000000000014, -316.0, 114.5, -253.89999999999998, -162.6999999999999, 20.000000000000014, 20.000000000000014, 41.30000000000001, 20.000000000000014, 20.000000000000014, 69.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -43.00000000000004, 1.6999999999999886, -72.09999999999997, -71.2000000000006, -1.0000000000000204, -62.19999999999989, 3.1999999999999615, -101.5, -57.399999999999984, -144.10000000000028, -51.70000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.70000000000002, 13.699999999999964, 20.000000000000014, 46.40000000000004, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 97.39999999999995, 20.000000000000014, -3.099999999999958, -131.50000000000014, 11.90000000000003, -74.50000000000024], "policy_predator_policy_reward": [11.0, 4.0, 77.0, 64.0, 4.0, 0.0, 14.0, 14.0, 66.0, 57.0, 15.0, 13.0, 56.0, 12.0, 75.0, 73.0, 11.0, 36.0, 12.0, 11.0, 37.0, 54.0, 0.0, 12.0, 74.0, 62.0, 20.0, 46.0, 55.0, 65.0, 81.0, 64.0, 20.0, 8.0, 0.0, 0.0, 107.0, 69.0, 31.0, 27.0, 0.0, 9.0, 60.0, 93.0, 42.0, 26.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 8.0, 0.0, 3.0, 0.0, 0.0, 35.0, 40.0, 28.0, 29.0, 89.0, 46.0, 0.0, 0.0, 49.0, 35.0, 21.0, 16.0, 0.0, 0.0, 25.0, 7.0, 78.0, 61.0, 10.0, 34.0, 8.0, 0.0, 73.0, 42.0, 85.0, 94.0, 110.0, 96.0, 0.0, 0.0, 20.0, 21.0, 30.0, 4.0, 78.0, 29.0, 0.0, 7.0, 166.0, 179.0, 39.0, 2.0, 32.0, 45.0, 56.0, 77.0, 41.0, 51.0, 120.0, 152.0, 17.0, 0.0, 0.0, 11.0, 12.0, 8.0, 106.0, 62.0, 0.0, 0.0, 0.0, 4.0, 47.0, 12.0, 44.0, 35.0, 64.0, 120.0, 0.0, 0.0, 137.0, 145.0, 0.0, 0.0, 28.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 99.0, 112.0, 50.0, 59.0, 30.0, 0.0, 67.0, 98.0, 97.0, 91.0, 5.0, 8.0, 22.0, 64.0, 1.0, 7.0, 0.0, 0.0, 77.0, 164.0, 155.0, 141.0, 52.0, 83.0, 10.0, 41.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 30.0, 16.0, 98.0, 75.0, 26.0, 40.0, 32.0, 42.0, 61.0, 102.0, 116.0, 101.0, 0.0, 0.0, 133.0, 149.0, 3.0, 0.0, 38.0, 33.0, 11.0, 0.0, 0.0, 0.0, 72.0, 72.0, 61.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7870370164134036, "mean_inference_ms": 2.163945557273987, "mean_action_processing_ms": 0.3236941393539626, "mean_env_wait_ms": 0.2844367643758904, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017300963401794434, "StateBufferConnector_ms": 0.0036520957946777344, "ViewRequirementAgentConnector_ms": 0.1565227508544922}, "num_episodes": 18, "episode_return_max": 314.90000000000015, "episode_return_min": -95.5, "episode_return_mean": 85.92999999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 245.40015924988353, "num_env_steps_trained_throughput_per_sec": 245.40015924988353, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 16162.891, "restore_workers_time_ms": 0.017, "training_step_time_ms": 16162.83, "sample_time_ms": 2459.642, "learn_time_ms": 13679.052, "learn_throughput": 292.418, "synch_weights_time_ms": 20.706}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "04dec_00002", "date": "2024-08-13_16-43-51", "timestamp": 1723581831, "time_this_iter_s": 16.37272000312805, "time_total_s": 1262.1644480228424, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04cc430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1262.1644480228424, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 79.94166666666666, "ram_util_percent": 86.55416666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1129679250102193, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 0.00010000000000000003, "total_loss": 3.886966523796162, "policy_loss": -0.001296157925512898, "vf_loss": 3.888260704751999, "vf_explained_var": 5.745603924705869e-05, "kl": 0.0035487634313375624, "entropy": 0.4532824960492906, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 27.337085712807518, "cur_kl_coeff": 0.8659522734582427, "cur_lr": 0.00010000000000000003, "total_loss": 6.506973094536514, "policy_loss": 0.001033356801789037, "vf_loss": 6.501913796783124, "vf_explained_var": -0.2878662367977163, "kl": 0.004649147503566091, "entropy": 0.595609789929062, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 314.90000000000015, "episode_reward_min": -95.5, "episode_reward_mean": 77.0239999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.09999999999994, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": -0.7780000000000211, "predator_policy": 39.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [147.89999999999964, 34.50000000000022, 38.9000000000003, 40.0000000000003, 91.4999999999993, 36.70000000000025, 182.1999999999991, -0.500000000000032, 36.10000000000026, 81.09999999999997, 40.0000000000003, 135.99999999999952, 160.09999999999968, 40.0000000000003, 155.99999999999952, -3.3999999999999755, 88.1999999999995, 176.09999999999917, 158.89999999999992, 68.7000000000002, 46.800000000000026, 40.0000000000003, 130.79999999999953, 226.09999999999962, 67.50000000000006, 314.90000000000015, 131.1999999999997, 128.39999999999952, 241.19999999999973, -3.0999999999999974, 279.5999999999999, -25.199999999999946, 21.299999999999994, 144.89999999999938, 21.90000000000004, -50.89999999999975, 141.6999999999992, 177.79999999999944, 114.59999999999934, 108.1999999999995, -95.5, 40.0000000000003, 51.700000000000195, 178.5999999999992, 10.099999999999952, 95.79999999999956, 29.000000000000284, 40.0000000000003, 21.19999999999991, 93.49999999999966, 76.30000000000001, 70.90000000000015, 13.799999999999914, 249.19999999999948, -44.09999999999956, 115.79999999999939, 105.69999999999918, -54.99999999999981, 156.59999999999994, -7.7000000000000846, 112.29999999999968, 40.0000000000003, 108.19999999999959, 40.0000000000003, 23.000000000000256, 102.5999999999998, -6.199999999999827, 14.999999999999934, 4.100000000000087, 21.200000000000017, 40.0000000000003, 52.30000000000013, 36.70000000000025, 137.3999999999996, 27.90000000000011, 117.3999999999993, 9.400000000000208, 25.400000000000148, 57.900000000000325, 102.89999999999954, 70.90000000000008, 36.90000000000008, 36.60000000000002, -7.099999999999985, 21.90000000000012, 40.0000000000003, 56.800000000000146, 162.8999999999993, -42.79999999999978, 159.99999999999972, -15.699999999999825, 232.79999999999941, 161.29999999999927, 40.0000000000003, 136.39999999999918, 61.60000000000032, 83.79999999999984, 37.00000000000027, 145.29999999999896, 103.69999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-42.999999999999986, 122.89999999999996, 20.000000000000014, 9.499999999999964, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, -3.100000000000051, 77.59999999999977, 13.699999999999964, 20.000000000000014, 97.39999999999985, 84.79999999999976, -5.200000000000026, -70.29999999999978, 20.000000000000014, -40.90000000000003, -2.499999999999993, -51.39999999999977, 20.000000000000014, 20.000000000000014, -17.79999999999974, 69.80000000000001, 74.0, 49.1000000000001, 20.000000000000014, 20.000000000000014, -30.39999999999975, 154.39999999999992, -17.199999999999996, -125.20000000000005, 95.59999999999971, -51.39999999999986, 20.000000000000014, 148.09999999999988, -24.70000000000004, 68.60000000000002, 1.0999999999999759, -111.40000000000003, -172.90000000000006, 13.699999999999964, 20.000000000000014, 20.000000000000014, 115.99999999999986, -26.199999999999992, 109.99999999999984, 82.09999999999998, 100.10000000000001, -139.60000000000034, 169.09999999999994, 138.79999999999987, 130.6999999999997, -344.5, -36.69999999999984, 124.09999999999988, 84.19999999999999, 80.00000000000003, -8.80000000000004, -127.30000000000013, 126.19999999999993, 61.400000000000006, -138.7, -158.50000000000023, 20.000000000000014, -15.699999999999747, 113.8999999999999, 20.000000000000014, 20.000000000000014, -18.099999999999977, -146.1999999999999, -72.69999999999989, 20.000000000000014, 121.69999999999979, 20.000000000000014, 153.79999999999998, 35.599999999999966, 20.000000000000014, 114.49999999999977, -85.30000000000007, -177.70000000000002, -101.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -250.29999999999998, 103.69999999999973, 74.90000000000006, 20.000000000000014, -40.89999999999984, 20.000000000000014, 75.79999999999995, 20.000000000000014, -1.0000000000000235, 20.000000000000014, 20.000000000000014, -104.50000000000009, -85.30000000000007, -35.49999999999997, 20.000000000000014, 89.29999999999953, -42.99999999999977, 20.000000000000014, -114.1, 20.000000000000014, -194.20000000000027, 140.89999999999992, 95.29999999999981, -68.19999999999983, -61.8999999999998, 87.79999999999995, 20.000000000000014, 85.69999999999979, 20.000000000000014, 20.000000000000014, -316.0, 114.5, -253.89999999999998, -162.6999999999999, 20.000000000000014, 20.000000000000014, 41.30000000000001, 20.000000000000014, 20.000000000000014, 69.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -43.00000000000004, 1.6999999999999886, -72.09999999999997, -71.2000000000006, -1.0000000000000204, -62.19999999999989, 3.1999999999999615, -101.5, -57.399999999999984, -144.10000000000028, -51.70000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.70000000000002, 13.699999999999964, 20.000000000000014, 46.40000000000004, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 97.39999999999995, 20.000000000000014, -3.099999999999958, -131.50000000000014, 11.90000000000003, -74.50000000000024, -9.399999999999855, 53.300000000000175, 77.9, 20.000000000000014, -5.199999999999962, -55.90000000000006, 13.699999999999964, -242.8, 20.000000000000014, -192.39999999999998, 36.1999999999999, -175.30000000000015, -87.10000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -159.70000000000041, 72.5, 159.4999999999999, -34.59999999999975, 20.000000000000014, -368.8, 77.60000000000004, 73.39999999999995, -346.9, 30.200000000000095, 119.29999999999987, 90.49999999999986, 131.2999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 112.39999999999984, 9.499999999999964, 46.100000000000136, 20.000000000000014, 48.80000000000008, 20.000000000000014, -19.000000000000036, 66.79999999999997, 78.49999999999994, 93.79999999999987, -0.10000000000003656], "policy_predator_policy_reward": [42.0, 26.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 8.0, 0.0, 3.0, 0.0, 0.0, 35.0, 40.0, 28.0, 29.0, 89.0, 46.0, 0.0, 0.0, 49.0, 35.0, 21.0, 16.0, 0.0, 0.0, 25.0, 7.0, 78.0, 61.0, 10.0, 34.0, 8.0, 0.0, 73.0, 42.0, 85.0, 94.0, 110.0, 96.0, 0.0, 0.0, 20.0, 21.0, 30.0, 4.0, 78.0, 29.0, 0.0, 7.0, 166.0, 179.0, 39.0, 2.0, 32.0, 45.0, 56.0, 77.0, 41.0, 51.0, 120.0, 152.0, 17.0, 0.0, 0.0, 11.0, 12.0, 8.0, 106.0, 62.0, 0.0, 0.0, 0.0, 4.0, 47.0, 12.0, 44.0, 35.0, 64.0, 120.0, 0.0, 0.0, 137.0, 145.0, 0.0, 0.0, 28.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 99.0, 112.0, 50.0, 59.0, 30.0, 0.0, 67.0, 98.0, 97.0, 91.0, 5.0, 8.0, 22.0, 64.0, 1.0, 7.0, 0.0, 0.0, 77.0, 164.0, 155.0, 141.0, 52.0, 83.0, 10.0, 41.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 30.0, 16.0, 98.0, 75.0, 26.0, 40.0, 32.0, 42.0, 61.0, 102.0, 116.0, 101.0, 0.0, 0.0, 133.0, 149.0, 3.0, 0.0, 38.0, 33.0, 11.0, 0.0, 0.0, 0.0, 72.0, 72.0, 61.0, 27.0, 14.0, 0.0, 5.0, 0.0, 74.0, 58.0, 132.0, 134.0, 113.0, 96.0, 89.0, 43.0, 51.0, 38.0, 0.0, 0.0, 80.0, 64.0, 14.0, 24.0, 121.0, 185.0, 9.0, 0.0, 117.0, 184.0, 12.0, 11.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 5.0, 1.0, 0.0, 15.0, 18.0, 18.0, 0.0, 0.0, 2.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7890707499269319, "mean_inference_ms": 2.1719470125255396, "mean_action_processing_ms": 0.3240488967692899, "mean_env_wait_ms": 0.2851923131351062, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01413261890411377, "StateBufferConnector_ms": 0.0036704540252685547, "ViewRequirementAgentConnector_ms": 0.15713322162628174}, "num_episodes": 22, "episode_return_max": 314.90000000000015, "episode_return_min": -95.5, "episode_return_mean": 77.0239999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 270.9786754141081, "num_env_steps_trained_throughput_per_sec": 270.9786754141081, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 15972.118, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15972.056, "sample_time_ms": 2318.99, "learn_time_ms": 13629.082, "learn_throughput": 293.49, "synch_weights_time_ms": 20.513}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "04dec_00002", "date": "2024-08-13_16-44-06", "timestamp": 1723581846, "time_this_iter_s": 14.834462881088257, "time_total_s": 1276.9989109039307, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c4040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1276.9989109039307, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 75.40952380952383, "ram_util_percent": 86.35238095238094}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0761042416489943, "cur_kl_coeff": 0.00027809143066406236, "cur_lr": 0.00010000000000000003, "total_loss": 4.18560911120561, "policy_loss": -0.0029599749872451105, "vf_loss": 4.18856766488817, "vf_explained_var": -0.0003209318118120627, "kl": 0.00509678102565556, "entropy": 0.4013093572602701, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.77805746771671, "cur_kl_coeff": 0.43297613672912133, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": 6.522498569061989e-05, "vf_loss": 6.356443775267828, "vf_explained_var": -0.0787839910656056, "kl": Infinity, "entropy": 0.5994293704550102, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 314.90000000000015, "episode_reward_min": -95.5, "episode_reward_mean": 77.25499999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.09999999999994, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": -5.672500000000024, "predator_policy": 44.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [158.89999999999992, 68.7000000000002, 46.800000000000026, 40.0000000000003, 130.79999999999953, 226.09999999999962, 67.50000000000006, 314.90000000000015, 131.1999999999997, 128.39999999999952, 241.19999999999973, -3.0999999999999974, 279.5999999999999, -25.199999999999946, 21.299999999999994, 144.89999999999938, 21.90000000000004, -50.89999999999975, 141.6999999999992, 177.79999999999944, 114.59999999999934, 108.1999999999995, -95.5, 40.0000000000003, 51.700000000000195, 178.5999999999992, 10.099999999999952, 95.79999999999956, 29.000000000000284, 40.0000000000003, 21.19999999999991, 93.49999999999966, 76.30000000000001, 70.90000000000015, 13.799999999999914, 249.19999999999948, -44.09999999999956, 115.79999999999939, 105.69999999999918, -54.99999999999981, 156.59999999999994, -7.7000000000000846, 112.29999999999968, 40.0000000000003, 108.19999999999959, 40.0000000000003, 23.000000000000256, 102.5999999999998, -6.199999999999827, 14.999999999999934, 4.100000000000087, 21.200000000000017, 40.0000000000003, 52.30000000000013, 36.70000000000025, 137.3999999999996, 27.90000000000011, 117.3999999999993, 9.400000000000208, 25.400000000000148, 57.900000000000325, 102.89999999999954, 70.90000000000008, 36.90000000000008, 36.60000000000002, -7.099999999999985, 21.90000000000012, 40.0000000000003, 56.800000000000146, 162.8999999999993, -42.79999999999978, 159.99999999999972, -15.699999999999825, 232.79999999999941, 161.29999999999927, 40.0000000000003, 136.39999999999918, 61.60000000000032, 83.79999999999984, 37.00000000000027, 145.29999999999896, 103.69999999999956, 46.70000000000018, 88.89999999999966, -45.60000000000016, 46.70000000000021, 30.900000000000166, 83.10000000000001, 189.89999999999966, 29.100000000000108, 101.79999999999947, 19.09999999999997, 185.8999999999993, 38.90000000000028, 112.19999999999979, 119.29999999999961, 129.89999999999964, 139.49999999999977, 48.300000000000196, 139.8999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.70000000000004, 68.60000000000002, 1.0999999999999759, -111.40000000000003, -172.90000000000006, 13.699999999999964, 20.000000000000014, 20.000000000000014, 115.99999999999986, -26.199999999999992, 109.99999999999984, 82.09999999999998, 100.10000000000001, -139.60000000000034, 169.09999999999994, 138.79999999999987, 130.6999999999997, -344.5, -36.69999999999984, 124.09999999999988, 84.19999999999999, 80.00000000000003, -8.80000000000004, -127.30000000000013, 126.19999999999993, 61.400000000000006, -138.7, -158.50000000000023, 20.000000000000014, -15.699999999999747, 113.8999999999999, 20.000000000000014, 20.000000000000014, -18.099999999999977, -146.1999999999999, -72.69999999999989, 20.000000000000014, 121.69999999999979, 20.000000000000014, 153.79999999999998, 35.599999999999966, 20.000000000000014, 114.49999999999977, -85.30000000000007, -177.70000000000002, -101.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -250.29999999999998, 103.69999999999973, 74.90000000000006, 20.000000000000014, -40.89999999999984, 20.000000000000014, 75.79999999999995, 20.000000000000014, -1.0000000000000235, 20.000000000000014, 20.000000000000014, -104.50000000000009, -85.30000000000007, -35.49999999999997, 20.000000000000014, 89.29999999999953, -42.99999999999977, 20.000000000000014, -114.1, 20.000000000000014, -194.20000000000027, 140.89999999999992, 95.29999999999981, -68.19999999999983, -61.8999999999998, 87.79999999999995, 20.000000000000014, 85.69999999999979, 20.000000000000014, 20.000000000000014, -316.0, 114.5, -253.89999999999998, -162.6999999999999, 20.000000000000014, 20.000000000000014, 41.30000000000001, 20.000000000000014, 20.000000000000014, 69.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -43.00000000000004, 1.6999999999999886, -72.09999999999997, -71.2000000000006, -1.0000000000000204, -62.19999999999989, 3.1999999999999615, -101.5, -57.399999999999984, -144.10000000000028, -51.70000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.70000000000002, 13.699999999999964, 20.000000000000014, 46.40000000000004, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 97.39999999999995, 20.000000000000014, -3.099999999999958, -131.50000000000014, 11.90000000000003, -74.50000000000024, -9.399999999999855, 53.300000000000175, 77.9, 20.000000000000014, -5.199999999999962, -55.90000000000006, 13.699999999999964, -242.8, 20.000000000000014, -192.39999999999998, 36.1999999999999, -175.30000000000015, -87.10000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -159.70000000000041, 72.5, 159.4999999999999, -34.59999999999975, 20.000000000000014, -368.8, 77.60000000000004, 73.39999999999995, -346.9, 30.200000000000095, 119.29999999999987, 90.49999999999986, 131.2999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 112.39999999999984, 9.499999999999964, 46.100000000000136, 20.000000000000014, 48.80000000000008, 20.000000000000014, -19.000000000000036, 66.79999999999997, 78.49999999999994, 93.79999999999987, -0.10000000000003656, -88.00000000000011, -7.299999999999891, 65.90000000000003, 20.000000000000014, -100.6000000000002, -232.0, 20.000000000000014, -55.30000000000015, -3.099999999999965, 20.000000000000014, -341.79999999999995, 68.90000000000002, 70.10000000000002, 81.79999999999994, -220.90000000000003, 20.000000000000014, 50.60000000000014, 45.200000000000145, -19.89999999999975, 20.000000000000014, 107.89999999999995, 56.000000000000206, 17.899999999999988, 20.000000000000014, -161.20000000000027, 133.3999999999998, 59.30000000000004, 20.000000000000014, 85.39999999999998, 9.499999999999964, 136.09999999999985, -166.6, 13.699999999999962, -54.40000000000015, 31.70000000000001, 75.20000000000003], "policy_predator_policy_reward": [73.0, 42.0, 85.0, 94.0, 110.0, 96.0, 0.0, 0.0, 20.0, 21.0, 30.0, 4.0, 78.0, 29.0, 0.0, 7.0, 166.0, 179.0, 39.0, 2.0, 32.0, 45.0, 56.0, 77.0, 41.0, 51.0, 120.0, 152.0, 17.0, 0.0, 0.0, 11.0, 12.0, 8.0, 106.0, 62.0, 0.0, 0.0, 0.0, 4.0, 47.0, 12.0, 44.0, 35.0, 64.0, 120.0, 0.0, 0.0, 137.0, 145.0, 0.0, 0.0, 28.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 99.0, 112.0, 50.0, 59.0, 30.0, 0.0, 67.0, 98.0, 97.0, 91.0, 5.0, 8.0, 22.0, 64.0, 1.0, 7.0, 0.0, 0.0, 77.0, 164.0, 155.0, 141.0, 52.0, 83.0, 10.0, 41.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 30.0, 16.0, 98.0, 75.0, 26.0, 40.0, 32.0, 42.0, 61.0, 102.0, 116.0, 101.0, 0.0, 0.0, 133.0, 149.0, 3.0, 0.0, 38.0, 33.0, 11.0, 0.0, 0.0, 0.0, 72.0, 72.0, 61.0, 27.0, 14.0, 0.0, 5.0, 0.0, 74.0, 58.0, 132.0, 134.0, 113.0, 96.0, 89.0, 43.0, 51.0, 38.0, 0.0, 0.0, 80.0, 64.0, 14.0, 24.0, 121.0, 185.0, 9.0, 0.0, 117.0, 184.0, 12.0, 11.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 5.0, 1.0, 0.0, 15.0, 18.0, 18.0, 0.0, 0.0, 2.0, 8.0, 81.0, 61.0, 0.0, 3.0, 141.0, 146.0, 60.0, 22.0, 8.0, 6.0, 180.0, 176.0, 15.0, 23.0, 135.0, 95.0, 6.0, 0.0, 0.0, 19.0, 0.0, 22.0, 0.0, 1.0, 66.0, 74.0, 23.0, 17.0, 2.0, 33.0, 57.0, 113.0, 19.0, 70.0, 31.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7901841300017698, "mean_inference_ms": 2.180015416762127, "mean_action_processing_ms": 0.32470063637859553, "mean_env_wait_ms": 0.2858942174422277, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010345816612243652, "StateBufferConnector_ms": 0.003625154495239258, "ViewRequirementAgentConnector_ms": 0.15050363540649414}, "num_episodes": 18, "episode_return_max": 314.90000000000015, "episode_return_min": -95.5, "episode_return_mean": 77.25499999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.10376667035794, "num_env_steps_trained_throughput_per_sec": 244.10376667035794, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 15710.447, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15710.386, "sample_time_ms": 2229.576, "learn_time_ms": 13458.127, "learn_throughput": 297.218, "synch_weights_time_ms": 18.939}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "04dec_00002", "date": "2024-08-13_16-44-23", "timestamp": 1723581863, "time_this_iter_s": 16.450051069259644, "time_total_s": 1293.4489619731903, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0239040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1293.4489619731903, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 81.1, "ram_util_percent": 85.05652173913043}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.088261857841696, "cur_kl_coeff": 0.00027809143066406236, "cur_lr": 0.00010000000000000003, "total_loss": 4.830126481081443, "policy_loss": -0.001455703067652408, "vf_loss": 4.831581112821266, "vf_explained_var": 0.00035885190837597723, "kl": 0.0038083162666730963, "entropy": 0.3772057727846519, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.410551993966735, "cur_kl_coeff": 0.6494642050936819, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": -0.0009365705067350987, "vf_loss": 6.431908542643148, "vf_explained_var": -0.3628073566174381, "kl": Infinity, "entropy": 0.616683448496319, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 253.3999999999997, "episode_reward_min": -316.1999999999997, "episode_reward_mean": 66.1369999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 159.4999999999999, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": -10.841500000000014, "predator_policy": 43.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 51.700000000000195, 178.5999999999992, 10.099999999999952, 95.79999999999956, 29.000000000000284, 40.0000000000003, 21.19999999999991, 93.49999999999966, 76.30000000000001, 70.90000000000015, 13.799999999999914, 249.19999999999948, -44.09999999999956, 115.79999999999939, 105.69999999999918, -54.99999999999981, 156.59999999999994, -7.7000000000000846, 112.29999999999968, 40.0000000000003, 108.19999999999959, 40.0000000000003, 23.000000000000256, 102.5999999999998, -6.199999999999827, 14.999999999999934, 4.100000000000087, 21.200000000000017, 40.0000000000003, 52.30000000000013, 36.70000000000025, 137.3999999999996, 27.90000000000011, 117.3999999999993, 9.400000000000208, 25.400000000000148, 57.900000000000325, 102.89999999999954, 70.90000000000008, 36.90000000000008, 36.60000000000002, -7.099999999999985, 21.90000000000012, 40.0000000000003, 56.800000000000146, 162.8999999999993, -42.79999999999978, 159.99999999999972, -15.699999999999825, 232.79999999999941, 161.29999999999927, 40.0000000000003, 136.39999999999918, 61.60000000000032, 83.79999999999984, 37.00000000000027, 145.29999999999896, 103.69999999999956, 46.70000000000018, 88.89999999999966, -45.60000000000016, 46.70000000000021, 30.900000000000166, 83.10000000000001, 189.89999999999966, 29.100000000000108, 101.79999999999947, 19.09999999999997, 185.8999999999993, 38.90000000000028, 112.19999999999979, 119.29999999999961, 129.89999999999964, 139.49999999999977, 48.300000000000196, 139.8999999999996, 40.0000000000003, 136.4, -68.69999999999976, -10.40000000000014, -316.1999999999997, 103.59999999999997, 77.79999999999998, 150.7999999999994, 76.19999999999982, 39.20000000000019, 26.200000000000433, -119.20000000000032, 102.3999999999996, 88.59999999999934, 253.3999999999997, 18.80000000000001, 73.30000000000015, 21.700000000000006, 16.89999999999993, 25.19999999999998, 123.39999999999968, 207.59999999999937, 210.99999999999932], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -250.29999999999998, 103.69999999999973, 74.90000000000006, 20.000000000000014, -40.89999999999984, 20.000000000000014, 75.79999999999995, 20.000000000000014, -1.0000000000000235, 20.000000000000014, 20.000000000000014, -104.50000000000009, -85.30000000000007, -35.49999999999997, 20.000000000000014, 89.29999999999953, -42.99999999999977, 20.000000000000014, -114.1, 20.000000000000014, -194.20000000000027, 140.89999999999992, 95.29999999999981, -68.19999999999983, -61.8999999999998, 87.79999999999995, 20.000000000000014, 85.69999999999979, 20.000000000000014, 20.000000000000014, -316.0, 114.5, -253.89999999999998, -162.6999999999999, 20.000000000000014, 20.000000000000014, 41.30000000000001, 20.000000000000014, 20.000000000000014, 69.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -43.00000000000004, 1.6999999999999886, -72.09999999999997, -71.2000000000006, -1.0000000000000204, -62.19999999999989, 3.1999999999999615, -101.5, -57.399999999999984, -144.10000000000028, -51.70000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.70000000000002, 13.699999999999964, 20.000000000000014, 46.40000000000004, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 97.39999999999995, 20.000000000000014, -3.099999999999958, -131.50000000000014, 11.90000000000003, -74.50000000000024, -9.399999999999855, 53.300000000000175, 77.9, 20.000000000000014, -5.199999999999962, -55.90000000000006, 13.699999999999964, -242.8, 20.000000000000014, -192.39999999999998, 36.1999999999999, -175.30000000000015, -87.10000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -159.70000000000041, 72.5, 159.4999999999999, -34.59999999999975, 20.000000000000014, -368.8, 77.60000000000004, 73.39999999999995, -346.9, 30.200000000000095, 119.29999999999987, 90.49999999999986, 131.2999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 112.39999999999984, 9.499999999999964, 46.100000000000136, 20.000000000000014, 48.80000000000008, 20.000000000000014, -19.000000000000036, 66.79999999999997, 78.49999999999994, 93.79999999999987, -0.10000000000003656, -88.00000000000011, -7.299999999999891, 65.90000000000003, 20.000000000000014, -100.6000000000002, -232.0, 20.000000000000014, -55.30000000000015, -3.099999999999965, 20.000000000000014, -341.79999999999995, 68.90000000000002, 70.10000000000002, 81.79999999999994, -220.90000000000003, 20.000000000000014, 50.60000000000014, 45.200000000000145, -19.89999999999975, 20.000000000000014, 107.89999999999995, 56.000000000000206, 17.899999999999988, 20.000000000000014, -161.20000000000027, 133.3999999999998, 59.30000000000004, 20.000000000000014, 85.39999999999998, 9.499999999999964, 136.09999999999985, -166.6, 13.699999999999962, -54.40000000000015, 31.70000000000001, 75.20000000000003, 20.000000000000014, 20.000000000000014, 87.5, -87.10000000000048, -318.69999999999993, 20.000000000000014, -93.40000000000003, -57.999999999999986, -294.6999999999998, -284.49999999999983, 59.60000000000004, 20.000000000000014, 20.000000000000014, 57.80000000000015, 3.1999999999999615, 119.59999999999988, -47.80000000000007, 20.000000000000014, 20.000000000000014, -140.79999999999998, 20.000000000000014, -32.799999999999905, -291.1000000000001, 17.899999999999988, 11.599999999999973, 78.80000000000001, 20.000000000000014, 68.60000000000004, 46.099999999999994, 137.29999999999984, -211.00000000000037, 75.80000000000007, -156.40000000000003, 13.699999999999966, 7.399999999999965, 5.299999999999965, 20.000000000000014, -24.099999999999767, -187.0, 3.1999999999999615, -40.000000000000085, 61.40000000000017, 101.6, 65.00000000000014, 54.200000000000195, 156.79999999999993], "policy_predator_policy_reward": [0.0, 0.0, 137.0, 145.0, 0.0, 0.0, 28.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 99.0, 112.0, 50.0, 59.0, 30.0, 0.0, 67.0, 98.0, 97.0, 91.0, 5.0, 8.0, 22.0, 64.0, 1.0, 7.0, 0.0, 0.0, 77.0, 164.0, 155.0, 141.0, 52.0, 83.0, 10.0, 41.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 30.0, 16.0, 98.0, 75.0, 26.0, 40.0, 32.0, 42.0, 61.0, 102.0, 116.0, 101.0, 0.0, 0.0, 133.0, 149.0, 3.0, 0.0, 38.0, 33.0, 11.0, 0.0, 0.0, 0.0, 72.0, 72.0, 61.0, 27.0, 14.0, 0.0, 5.0, 0.0, 74.0, 58.0, 132.0, 134.0, 113.0, 96.0, 89.0, 43.0, 51.0, 38.0, 0.0, 0.0, 80.0, 64.0, 14.0, 24.0, 121.0, 185.0, 9.0, 0.0, 117.0, 184.0, 12.0, 11.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 5.0, 1.0, 0.0, 15.0, 18.0, 18.0, 0.0, 0.0, 2.0, 8.0, 81.0, 61.0, 0.0, 3.0, 141.0, 146.0, 60.0, 22.0, 8.0, 6.0, 180.0, 176.0, 15.0, 23.0, 135.0, 95.0, 6.0, 0.0, 0.0, 19.0, 0.0, 22.0, 0.0, 1.0, 66.0, 74.0, 23.0, 17.0, 2.0, 33.0, 57.0, 113.0, 19.0, 70.0, 31.0, 2.0, 0.0, 0.0, 66.0, 70.0, 151.0, 79.0, 80.0, 61.0, 95.0, 168.0, 15.0, 9.0, 0.0, 0.0, 10.0, 18.0, 50.0, 54.0, 50.0, 110.0, 26.0, 13.0, 85.0, 69.0, 10.0, 2.0, 0.0, 0.0, 30.0, 40.0, 74.0, 80.0, 114.0, 102.0, 9.0, 0.0, 0.0, 21.0, 111.0, 98.0, 42.0, 60.0, 16.0, 25.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7923341769203011, "mean_inference_ms": 2.1882259638235886, "mean_action_processing_ms": 0.3254478930505581, "mean_env_wait_ms": 0.2864874330567183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005374312400817871, "StateBufferConnector_ms": 0.003701329231262207, "ViewRequirementAgentConnector_ms": 0.15760493278503418}, "num_episodes": 23, "episode_return_max": 253.3999999999997, "episode_return_min": -316.1999999999997, "episode_return_mean": 66.1369999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.3261421800106, "num_env_steps_trained_throughput_per_sec": 231.3261421800106, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 15862.406, "restore_workers_time_ms": 0.018, "training_step_time_ms": 15862.342, "sample_time_ms": 2223.585, "learn_time_ms": 13615.304, "learn_throughput": 293.787, "synch_weights_time_ms": 19.45}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": false, "training_iteration": 100, "trial_id": "04dec_00002", "date": "2024-08-13_16-44-40", "timestamp": 1723581880, "time_this_iter_s": 17.38849401473999, "time_total_s": 1310.8374559879303, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0239ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1310.8374559879303, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 80.90416666666668, "ram_util_percent": 85.64166666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2562274272243181, "cur_kl_coeff": 0.00013904571533203118, "cur_lr": 0.00010000000000000003, "total_loss": 3.15336302474693, "policy_loss": -0.002057921741078928, "vf_loss": 3.1554204323304393, "vf_explained_var": -0.001057781838866138, "kl": 0.0037468245715097277, "entropy": 0.4043425261501282, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 189945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 29.699264899637335, "cur_kl_coeff": 0.9741963076405225, "cur_lr": 0.00010000000000000003, "total_loss": Infinity, "policy_loss": 0.001580478552181924, "vf_loss": 6.441867333871347, "vf_explained_var": 0.2530087683882032, "kl": Infinity, "entropy": 0.5744926001817461, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 189945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "env_runners": {"episode_reward_max": 253.3999999999997, "episode_reward_min": -316.1999999999997, "episode_reward_mean": 69.74599999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 159.4999999999999, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": -4.357000000000012, "predator_policy": 39.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.7000000000000846, 112.29999999999968, 40.0000000000003, 108.19999999999959, 40.0000000000003, 23.000000000000256, 102.5999999999998, -6.199999999999827, 14.999999999999934, 4.100000000000087, 21.200000000000017, 40.0000000000003, 52.30000000000013, 36.70000000000025, 137.3999999999996, 27.90000000000011, 117.3999999999993, 9.400000000000208, 25.400000000000148, 57.900000000000325, 102.89999999999954, 70.90000000000008, 36.90000000000008, 36.60000000000002, -7.099999999999985, 21.90000000000012, 40.0000000000003, 56.800000000000146, 162.8999999999993, -42.79999999999978, 159.99999999999972, -15.699999999999825, 232.79999999999941, 161.29999999999927, 40.0000000000003, 136.39999999999918, 61.60000000000032, 83.79999999999984, 37.00000000000027, 145.29999999999896, 103.69999999999956, 46.70000000000018, 88.89999999999966, -45.60000000000016, 46.70000000000021, 30.900000000000166, 83.10000000000001, 189.89999999999966, 29.100000000000108, 101.79999999999947, 19.09999999999997, 185.8999999999993, 38.90000000000028, 112.19999999999979, 119.29999999999961, 129.89999999999964, 139.49999999999977, 48.300000000000196, 139.8999999999996, 40.0000000000003, 136.4, -68.69999999999976, -10.40000000000014, -316.1999999999997, 103.59999999999997, 77.79999999999998, 150.7999999999994, 76.19999999999982, 39.20000000000019, 26.200000000000433, -119.20000000000032, 102.3999999999996, 88.59999999999934, 253.3999999999997, 18.80000000000001, 73.30000000000015, 21.700000000000006, 16.89999999999993, 25.19999999999998, 123.39999999999968, 207.59999999999937, 210.99999999999932, 94.99999999999987, 94.0999999999996, 77.5999999999999, 144.9999999999993, 75.20000000000005, 30.100000000000147, 27.10000000000008, 237.19999999999953, 30.800000000000146, 40.0000000000003, -9.699999999999818, 142.1999999999997, 109.29999999999951, 151.09999999999957, 168.09999999999977, 134.89999999999984, 40.0000000000003, 22.00000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-162.6999999999999, 20.000000000000014, 20.000000000000014, 41.30000000000001, 20.000000000000014, 20.000000000000014, 69.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -43.00000000000004, 1.6999999999999886, -72.09999999999997, -71.2000000000006, -1.0000000000000204, -62.19999999999989, 3.1999999999999615, -101.5, -57.399999999999984, -144.10000000000028, -51.70000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.70000000000002, 13.699999999999964, 20.000000000000014, 46.40000000000004, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 97.39999999999995, 20.000000000000014, -3.099999999999958, -131.50000000000014, 11.90000000000003, -74.50000000000024, -9.399999999999855, 53.300000000000175, 77.9, 20.000000000000014, -5.199999999999962, -55.90000000000006, 13.699999999999964, -242.8, 20.000000000000014, -192.39999999999998, 36.1999999999999, -175.30000000000015, -87.10000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -159.70000000000041, 72.5, 159.4999999999999, -34.59999999999975, 20.000000000000014, -368.8, 77.60000000000004, 73.39999999999995, -346.9, 30.200000000000095, 119.29999999999987, 90.49999999999986, 131.2999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 112.39999999999984, 9.499999999999964, 46.100000000000136, 20.000000000000014, 48.80000000000008, 20.000000000000014, -19.000000000000036, 66.79999999999997, 78.49999999999994, 93.79999999999987, -0.10000000000003656, -88.00000000000011, -7.299999999999891, 65.90000000000003, 20.000000000000014, -100.6000000000002, -232.0, 20.000000000000014, -55.30000000000015, -3.099999999999965, 20.000000000000014, -341.79999999999995, 68.90000000000002, 70.10000000000002, 81.79999999999994, -220.90000000000003, 20.000000000000014, 50.60000000000014, 45.200000000000145, -19.89999999999975, 20.000000000000014, 107.89999999999995, 56.000000000000206, 17.899999999999988, 20.000000000000014, -161.20000000000027, 133.3999999999998, 59.30000000000004, 20.000000000000014, 85.39999999999998, 9.499999999999964, 136.09999999999985, -166.6, 13.699999999999962, -54.40000000000015, 31.70000000000001, 75.20000000000003, 20.000000000000014, 20.000000000000014, 87.5, -87.10000000000048, -318.69999999999993, 20.000000000000014, -93.40000000000003, -57.999999999999986, -294.6999999999998, -284.49999999999983, 59.60000000000004, 20.000000000000014, 20.000000000000014, 57.80000000000015, 3.1999999999999615, 119.59999999999988, -47.80000000000007, 20.000000000000014, 20.000000000000014, -140.79999999999998, 20.000000000000014, -32.799999999999905, -291.1000000000001, 17.899999999999988, 11.599999999999973, 78.80000000000001, 20.000000000000014, 68.60000000000004, 46.099999999999994, 137.29999999999984, -211.00000000000037, 75.80000000000007, -156.40000000000003, 13.699999999999966, 7.399999999999965, 5.299999999999965, 20.000000000000014, -24.099999999999767, -187.0, 3.1999999999999615, -40.000000000000085, 61.40000000000017, 101.6, 65.00000000000014, 54.200000000000195, 156.79999999999993, -16.90000000000004, 17.899999999999988, 78.49999999999993, 11.599999999999973, 56.60000000000013, 20.000000000000014, 131.59999999999982, 7.399999999999972, 13.699999999999964, 6.500000000000041, 1.099999999999983, 20.000000000000014, -40.000000000000036, -67.90000000000032, 97.10000000000007, 97.09999999999988, -6.3999999999999275, -59.79999999999977, 20.000000000000014, 20.000000000000014, -93.99999999999999, -15.699999999999928, 37.100000000000044, 37.10000000000005, 28.10000000000007, 81.19999999999993, 11.599999999999964, 132.49999999999997, 7.999999999999998, 124.09999999999995, 62.900000000000034, 38.00000000000003, 20.000000000000014, 20.000000000000014, 13.699999999999946, -36.699999999999896], "policy_predator_policy_reward": [52.0, 83.0, 10.0, 41.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 30.0, 16.0, 98.0, 75.0, 26.0, 40.0, 32.0, 42.0, 61.0, 102.0, 116.0, 101.0, 0.0, 0.0, 133.0, 149.0, 3.0, 0.0, 38.0, 33.0, 11.0, 0.0, 0.0, 0.0, 72.0, 72.0, 61.0, 27.0, 14.0, 0.0, 5.0, 0.0, 74.0, 58.0, 132.0, 134.0, 113.0, 96.0, 89.0, 43.0, 51.0, 38.0, 0.0, 0.0, 80.0, 64.0, 14.0, 24.0, 121.0, 185.0, 9.0, 0.0, 117.0, 184.0, 12.0, 11.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 5.0, 1.0, 0.0, 15.0, 18.0, 18.0, 0.0, 0.0, 2.0, 8.0, 81.0, 61.0, 0.0, 3.0, 141.0, 146.0, 60.0, 22.0, 8.0, 6.0, 180.0, 176.0, 15.0, 23.0, 135.0, 95.0, 6.0, 0.0, 0.0, 19.0, 0.0, 22.0, 0.0, 1.0, 66.0, 74.0, 23.0, 17.0, 2.0, 33.0, 57.0, 113.0, 19.0, 70.0, 31.0, 2.0, 0.0, 0.0, 66.0, 70.0, 151.0, 79.0, 80.0, 61.0, 95.0, 168.0, 15.0, 9.0, 0.0, 0.0, 10.0, 18.0, 50.0, 54.0, 50.0, 110.0, 26.0, 13.0, 85.0, 69.0, 10.0, 2.0, 0.0, 0.0, 30.0, 40.0, 74.0, 80.0, 114.0, 102.0, 9.0, 0.0, 0.0, 21.0, 111.0, 98.0, 42.0, 60.0, 16.0, 25.0, 0.0, 0.0, 67.0, 27.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 4.0, 51.0, 0.0, 9.0, 85.0, 50.0, 29.0, 14.0, 34.0, 63.0, 0.0, 0.0, 72.0, 28.0, 36.0, 32.0, 0.0, 0.0, 3.0, 4.0, 19.0, 17.0, 13.0, 21.0, 0.0, 0.0, 16.0, 29.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.793209805609792, "mean_inference_ms": 2.1947907629124077, "mean_action_processing_ms": 0.32554707099778546, "mean_env_wait_ms": 0.28706734261185224, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011670947074890137, "StateBufferConnector_ms": 0.006257295608520508, "ViewRequirementAgentConnector_ms": 0.16747915744781494}, "num_episodes": 18, "episode_return_max": 253.3999999999997, "episode_return_min": -316.1999999999997, "episode_return_mean": 69.74599999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 261.9385337769895, "num_env_steps_trained_throughput_per_sec": 261.9385337769895, "timesteps_total": 404000, "num_env_steps_sampled_lifetime": 404000, "num_agent_steps_sampled_lifetime": 1616000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1616000, "timers": {"training_iteration_time_ms": 15815.648, "restore_workers_time_ms": 0.018, "training_step_time_ms": 15815.589, "sample_time_ms": 2234.446, "learn_time_ms": 13558.53, "learn_throughput": 295.017, "synch_weights_time_ms": 19.508}, "counters": {"num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "done": false, "training_iteration": 101, "trial_id": "04dec_00002", "date": "2024-08-13_16-44-56", "timestamp": 1723581896, "time_this_iter_s": 15.345306873321533, "time_total_s": 1326.1827628612518, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0667940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1326.1827628612518, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 76.35909090909091, "ram_util_percent": 86.02727272727272}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1392613663875237, "cur_kl_coeff": 6.952285766601559e-05, "cur_lr": 0.00010000000000000003, "total_loss": 4.255526144416244, "policy_loss": -0.0026295347218081434, "vf_loss": 4.258155376444418, "vf_explained_var": -0.0046123302802837714, "kl": 0.004000003474746208, "entropy": 0.3531858501610933, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 191835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 28.332497725221845, "cur_kl_coeff": 1.4612944614607846, "cur_lr": 0.00010000000000000003, "total_loss": 6.120641197981658, "policy_loss": 0.0006940771781262897, "vf_loss": 6.11700003740018, "vf_explained_var": -0.21189065064702714, "kl": 0.0020167609142230955, "entropy": 0.6170553581109123, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 191835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "env_runners": {"episode_reward_max": 253.3999999999997, "episode_reward_min": -316.1999999999997, "episode_reward_mean": 74.96399999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.69999999999996, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": 0.3769999999999857, "predator_policy": 37.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.400000000000148, 57.900000000000325, 102.89999999999954, 70.90000000000008, 36.90000000000008, 36.60000000000002, -7.099999999999985, 21.90000000000012, 40.0000000000003, 56.800000000000146, 162.8999999999993, -42.79999999999978, 159.99999999999972, -15.699999999999825, 232.79999999999941, 161.29999999999927, 40.0000000000003, 136.39999999999918, 61.60000000000032, 83.79999999999984, 37.00000000000027, 145.29999999999896, 103.69999999999956, 46.70000000000018, 88.89999999999966, -45.60000000000016, 46.70000000000021, 30.900000000000166, 83.10000000000001, 189.89999999999966, 29.100000000000108, 101.79999999999947, 19.09999999999997, 185.8999999999993, 38.90000000000028, 112.19999999999979, 119.29999999999961, 129.89999999999964, 139.49999999999977, 48.300000000000196, 139.8999999999996, 40.0000000000003, 136.4, -68.69999999999976, -10.40000000000014, -316.1999999999997, 103.59999999999997, 77.79999999999998, 150.7999999999994, 76.19999999999982, 39.20000000000019, 26.200000000000433, -119.20000000000032, 102.3999999999996, 88.59999999999934, 253.3999999999997, 18.80000000000001, 73.30000000000015, 21.700000000000006, 16.89999999999993, 25.19999999999998, 123.39999999999968, 207.59999999999937, 210.99999999999932, 94.99999999999987, 94.0999999999996, 77.5999999999999, 144.9999999999993, 75.20000000000005, 30.100000000000147, 27.10000000000008, 237.19999999999953, 30.800000000000146, 40.0000000000003, -9.699999999999818, 142.1999999999997, 109.29999999999951, 151.09999999999957, 168.09999999999977, 134.89999999999984, 40.0000000000003, 22.00000000000006, 40.0000000000003, 2.100000000000018, 219.6999999999997, 177.2999999999994, 10.300000000000066, 40.0000000000003, 128.39999999999947, 46.300000000000246, 29.900000000000325, 194.99999999999974, 165.49999999999935, 125.29999999999932, 111.09999999999953, 35.600000000000236, -53.39999999999985, 28.500000000000114, -22.50000000000002, 116.29999999999957], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.90000000000003, -74.50000000000024, -9.399999999999855, 53.300000000000175, 77.9, 20.000000000000014, -5.199999999999962, -55.90000000000006, 13.699999999999964, -242.8, 20.000000000000014, -192.39999999999998, 36.1999999999999, -175.30000000000015, -87.10000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -159.70000000000041, 72.5, 159.4999999999999, -34.59999999999975, 20.000000000000014, -368.8, 77.60000000000004, 73.39999999999995, -346.9, 30.200000000000095, 119.29999999999987, 90.49999999999986, 131.2999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 112.39999999999984, 9.499999999999964, 46.100000000000136, 20.000000000000014, 48.80000000000008, 20.000000000000014, -19.000000000000036, 66.79999999999997, 78.49999999999994, 93.79999999999987, -0.10000000000003656, -88.00000000000011, -7.299999999999891, 65.90000000000003, 20.000000000000014, -100.6000000000002, -232.0, 20.000000000000014, -55.30000000000015, -3.099999999999965, 20.000000000000014, -341.79999999999995, 68.90000000000002, 70.10000000000002, 81.79999999999994, -220.90000000000003, 20.000000000000014, 50.60000000000014, 45.200000000000145, -19.89999999999975, 20.000000000000014, 107.89999999999995, 56.000000000000206, 17.899999999999988, 20.000000000000014, -161.20000000000027, 133.3999999999998, 59.30000000000004, 20.000000000000014, 85.39999999999998, 9.499999999999964, 136.09999999999985, -166.6, 13.699999999999962, -54.40000000000015, 31.70000000000001, 75.20000000000003, 20.000000000000014, 20.000000000000014, 87.5, -87.10000000000048, -318.69999999999993, 20.000000000000014, -93.40000000000003, -57.999999999999986, -294.6999999999998, -284.49999999999983, 59.60000000000004, 20.000000000000014, 20.000000000000014, 57.80000000000015, 3.1999999999999615, 119.59999999999988, -47.80000000000007, 20.000000000000014, 20.000000000000014, -140.79999999999998, 20.000000000000014, -32.799999999999905, -291.1000000000001, 17.899999999999988, 11.599999999999973, 78.80000000000001, 20.000000000000014, 68.60000000000004, 46.099999999999994, 137.29999999999984, -211.00000000000037, 75.80000000000007, -156.40000000000003, 13.699999999999966, 7.399999999999965, 5.299999999999965, 20.000000000000014, -24.099999999999767, -187.0, 3.1999999999999615, -40.000000000000085, 61.40000000000017, 101.6, 65.00000000000014, 54.200000000000195, 156.79999999999993, -16.90000000000004, 17.899999999999988, 78.49999999999993, 11.599999999999973, 56.60000000000013, 20.000000000000014, 131.59999999999982, 7.399999999999972, 13.699999999999964, 6.500000000000041, 1.099999999999983, 20.000000000000014, -40.000000000000036, -67.90000000000032, 97.10000000000007, 97.09999999999988, -6.3999999999999275, -59.79999999999977, 20.000000000000014, 20.000000000000014, -93.99999999999999, -15.699999999999928, 37.100000000000044, 37.10000000000005, 28.10000000000007, 81.19999999999993, 11.599999999999964, 132.49999999999997, 7.999999999999998, 124.09999999999995, 62.900000000000034, 38.00000000000003, 20.000000000000014, 20.000000000000014, 13.699999999999946, -36.699999999999896, 20.000000000000014, 20.000000000000014, 123.49999999999982, -261.4000000000002, 147.49999999999994, 6.199999999999955, -9.40000000000003, 169.69999999999996, 20.000000000000014, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.39999999999995, 20.000000000000014, -21.700000000000042, 38.000000000000135, -177.10000000000042, 4.100000000000014, 104.89999999999998, 53.300000000000146, 96.19999999999989, 17.899999999999988, 106.39999999999979, 91.0999999999999, 20.000000000000014, 20.000000000000014, 11.599999999999966, 20.000000000000014, -273.4, -40.00000000000004, -41.49999999999995, -122.49999999999989, 20.000000000000014, 3.1999999999999615, 103.09999999999991], "policy_predator_policy_reward": [61.0, 27.0, 14.0, 0.0, 5.0, 0.0, 74.0, 58.0, 132.0, 134.0, 113.0, 96.0, 89.0, 43.0, 51.0, 38.0, 0.0, 0.0, 80.0, 64.0, 14.0, 24.0, 121.0, 185.0, 9.0, 0.0, 117.0, 184.0, 12.0, 11.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 5.0, 1.0, 0.0, 15.0, 18.0, 18.0, 0.0, 0.0, 2.0, 8.0, 81.0, 61.0, 0.0, 3.0, 141.0, 146.0, 60.0, 22.0, 8.0, 6.0, 180.0, 176.0, 15.0, 23.0, 135.0, 95.0, 6.0, 0.0, 0.0, 19.0, 0.0, 22.0, 0.0, 1.0, 66.0, 74.0, 23.0, 17.0, 2.0, 33.0, 57.0, 113.0, 19.0, 70.0, 31.0, 2.0, 0.0, 0.0, 66.0, 70.0, 151.0, 79.0, 80.0, 61.0, 95.0, 168.0, 15.0, 9.0, 0.0, 0.0, 10.0, 18.0, 50.0, 54.0, 50.0, 110.0, 26.0, 13.0, 85.0, 69.0, 10.0, 2.0, 0.0, 0.0, 30.0, 40.0, 74.0, 80.0, 114.0, 102.0, 9.0, 0.0, 0.0, 21.0, 111.0, 98.0, 42.0, 60.0, 16.0, 25.0, 0.0, 0.0, 67.0, 27.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 4.0, 51.0, 0.0, 9.0, 85.0, 50.0, 29.0, 14.0, 34.0, 63.0, 0.0, 0.0, 72.0, 28.0, 36.0, 32.0, 0.0, 0.0, 3.0, 4.0, 19.0, 17.0, 13.0, 21.0, 0.0, 0.0, 16.0, 29.0, 0.0, 0.0, 0.0, 140.0, 39.0, 27.0, 9.0, 8.0, 0.0, 27.0, 0.0, 0.0, 27.0, 29.0, 24.0, 24.0, 70.0, 99.0, 52.0, 34.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 107.0, 93.0, 71.0, 39.0, 34.0, 46.0, 8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7949879344429874, "mean_inference_ms": 2.201631797431939, "mean_action_processing_ms": 0.3260491457583785, "mean_env_wait_ms": 0.28756911803923596, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011976957321166992, "StateBufferConnector_ms": 0.006425738334655762, "ViewRequirementAgentConnector_ms": 0.15904438495635986}, "num_episodes": 18, "episode_return_max": 253.3999999999997, "episode_return_min": -316.1999999999997, "episode_return_mean": 74.96399999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 270.5646351755333, "num_env_steps_trained_throughput_per_sec": 270.5646351755333, "timesteps_total": 408000, "num_env_steps_sampled_lifetime": 408000, "num_agent_steps_sampled_lifetime": 1632000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1632000, "timers": {"training_iteration_time_ms": 15755.326, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15755.268, "sample_time_ms": 2241.085, "learn_time_ms": 13491.123, "learn_throughput": 296.491, "synch_weights_time_ms": 19.789}, "counters": {"num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "done": false, "training_iteration": 102, "trial_id": "04dec_00002", "date": "2024-08-13_16-45-11", "timestamp": 1723581911, "time_this_iter_s": 14.922481775283813, "time_total_s": 1341.1052446365356, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06678b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1341.1052446365356, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 74.30476190476192, "ram_util_percent": 85.65714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1270752153620518, "cur_kl_coeff": 3.4761428833007795e-05, "cur_lr": 0.00010000000000000003, "total_loss": 2.2128971430359696, "policy_loss": -0.002817794099011552, "vf_loss": 2.2157147825710357, "vf_explained_var": -0.0013819052428795547, "kl": 0.004527601771906417, "entropy": 0.4161593173073713, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 193725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 32.524951961999214, "cur_kl_coeff": 0.7306472307303923, "cur_lr": 0.00010000000000000003, "total_loss": 5.4333817628325605, "policy_loss": -0.00012677829976257666, "vf_loss": 5.428613633201236, "vf_explained_var": -0.6747879379640811, "kl": 0.006699442703080797, "entropy": 0.6638502753916241, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 193725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "env_runners": {"episode_reward_max": 253.3999999999997, "episode_reward_min": -316.1999999999997, "episode_reward_mean": 67.23199999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -341.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.69999999999996, "predator_policy": 180.0}, "policy_reward_mean": {"prey_policy": -0.6640000000000071, "predator_policy": 34.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [103.69999999999956, 46.70000000000018, 88.89999999999966, -45.60000000000016, 46.70000000000021, 30.900000000000166, 83.10000000000001, 189.89999999999966, 29.100000000000108, 101.79999999999947, 19.09999999999997, 185.8999999999993, 38.90000000000028, 112.19999999999979, 119.29999999999961, 129.89999999999964, 139.49999999999977, 48.300000000000196, 139.8999999999996, 40.0000000000003, 136.4, -68.69999999999976, -10.40000000000014, -316.1999999999997, 103.59999999999997, 77.79999999999998, 150.7999999999994, 76.19999999999982, 39.20000000000019, 26.200000000000433, -119.20000000000032, 102.3999999999996, 88.59999999999934, 253.3999999999997, 18.80000000000001, 73.30000000000015, 21.700000000000006, 16.89999999999993, 25.19999999999998, 123.39999999999968, 207.59999999999937, 210.99999999999932, 94.99999999999987, 94.0999999999996, 77.5999999999999, 144.9999999999993, 75.20000000000005, 30.100000000000147, 27.10000000000008, 237.19999999999953, 30.800000000000146, 40.0000000000003, -9.699999999999818, 142.1999999999997, 109.29999999999951, 151.09999999999957, 168.09999999999977, 134.89999999999984, 40.0000000000003, 22.00000000000006, 40.0000000000003, 2.100000000000018, 219.6999999999997, 177.2999999999994, 10.300000000000066, 40.0000000000003, 128.39999999999947, 46.300000000000246, 29.900000000000325, 194.99999999999974, 165.49999999999935, 125.29999999999932, 111.09999999999953, 35.600000000000236, -53.39999999999985, 28.500000000000114, -22.50000000000002, 116.29999999999957, 52.49999999999922, 40.0000000000003, -277.4000000000001, 104.79999999999924, 36.70000000000025, 69.70000000000036, -62.299999999999784, 40.0000000000003, 71.30000000000011, 103.89999999999941, 56.30000000000011, 63.70000000000036, 39.9000000000003, 35.00000000000024, 101.79999999999993, 114.99999999999932, 32.30000000000015, -17.299999999999926, 40.0000000000003, 91.29999999999956, 87.69999999999938, 6.700000000000157], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [93.79999999999987, -0.10000000000003656, -88.00000000000011, -7.299999999999891, 65.90000000000003, 20.000000000000014, -100.6000000000002, -232.0, 20.000000000000014, -55.30000000000015, -3.099999999999965, 20.000000000000014, -341.79999999999995, 68.90000000000002, 70.10000000000002, 81.79999999999994, -220.90000000000003, 20.000000000000014, 50.60000000000014, 45.200000000000145, -19.89999999999975, 20.000000000000014, 107.89999999999995, 56.000000000000206, 17.899999999999988, 20.000000000000014, -161.20000000000027, 133.3999999999998, 59.30000000000004, 20.000000000000014, 85.39999999999998, 9.499999999999964, 136.09999999999985, -166.6, 13.699999999999962, -54.40000000000015, 31.70000000000001, 75.20000000000003, 20.000000000000014, 20.000000000000014, 87.5, -87.10000000000048, -318.69999999999993, 20.000000000000014, -93.40000000000003, -57.999999999999986, -294.6999999999998, -284.49999999999983, 59.60000000000004, 20.000000000000014, 20.000000000000014, 57.80000000000015, 3.1999999999999615, 119.59999999999988, -47.80000000000007, 20.000000000000014, 20.000000000000014, -140.79999999999998, 20.000000000000014, -32.799999999999905, -291.1000000000001, 17.899999999999988, 11.599999999999973, 78.80000000000001, 20.000000000000014, 68.60000000000004, 46.099999999999994, 137.29999999999984, -211.00000000000037, 75.80000000000007, -156.40000000000003, 13.699999999999966, 7.399999999999965, 5.299999999999965, 20.000000000000014, -24.099999999999767, -187.0, 3.1999999999999615, -40.000000000000085, 61.40000000000017, 101.6, 65.00000000000014, 54.200000000000195, 156.79999999999993, -16.90000000000004, 17.899999999999988, 78.49999999999993, 11.599999999999973, 56.60000000000013, 20.000000000000014, 131.59999999999982, 7.399999999999972, 13.699999999999964, 6.500000000000041, 1.099999999999983, 20.000000000000014, -40.000000000000036, -67.90000000000032, 97.10000000000007, 97.09999999999988, -6.3999999999999275, -59.79999999999977, 20.000000000000014, 20.000000000000014, -93.99999999999999, -15.699999999999928, 37.100000000000044, 37.10000000000005, 28.10000000000007, 81.19999999999993, 11.599999999999964, 132.49999999999997, 7.999999999999998, 124.09999999999995, 62.900000000000034, 38.00000000000003, 20.000000000000014, 20.000000000000014, 13.699999999999946, -36.699999999999896, 20.000000000000014, 20.000000000000014, 123.49999999999982, -261.4000000000002, 147.49999999999994, 6.199999999999955, -9.40000000000003, 169.69999999999996, 20.000000000000014, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.39999999999995, 20.000000000000014, -21.700000000000042, 38.000000000000135, -177.10000000000042, 4.100000000000014, 104.89999999999998, 53.300000000000146, 96.19999999999989, 17.899999999999988, 106.39999999999979, 91.0999999999999, 20.000000000000014, 20.000000000000014, 11.599999999999966, 20.000000000000014, -273.4, -40.00000000000004, -41.49999999999995, -122.49999999999989, 20.000000000000014, 3.1999999999999615, 103.09999999999991, -38.49999999999998, -3.9999999999999574, 20.000000000000014, 20.000000000000014, -261.7000000000001, -312.70000000000005, 84.79999999999983, 20.000000000000014, 20.000000000000014, 13.699999999999967, 20.000000000000014, 49.70000000000022, -286.29999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999977, 52.40000000000016, 83.89999999999984, 20.000000000000014, 135.79999999999993, -197.50000000000023, 20.000000000000014, 31.70000000000009, 17.899999999999977, 20.000000000000014, 20.000000000000014, 7.999999999999965, 5.299999999999985, 33.5, 2.899999999999929, 58.100000000000115, 34.100000000000016, -212.79999999999998, 20.000000000000014, -217.3000000000001, 20.000000000000014, 20.000000000000014, 71.30000000000001, 20.000000000000014, 67.70000000000005, 20.000000000000014, -3.099999999999965, -5.1999999999999265], "policy_predator_policy_reward": [2.0, 8.0, 81.0, 61.0, 0.0, 3.0, 141.0, 146.0, 60.0, 22.0, 8.0, 6.0, 180.0, 176.0, 15.0, 23.0, 135.0, 95.0, 6.0, 0.0, 0.0, 19.0, 0.0, 22.0, 0.0, 1.0, 66.0, 74.0, 23.0, 17.0, 2.0, 33.0, 57.0, 113.0, 19.0, 70.0, 31.0, 2.0, 0.0, 0.0, 66.0, 70.0, 151.0, 79.0, 80.0, 61.0, 95.0, 168.0, 15.0, 9.0, 0.0, 0.0, 10.0, 18.0, 50.0, 54.0, 50.0, 110.0, 26.0, 13.0, 85.0, 69.0, 10.0, 2.0, 0.0, 0.0, 30.0, 40.0, 74.0, 80.0, 114.0, 102.0, 9.0, 0.0, 0.0, 21.0, 111.0, 98.0, 42.0, 60.0, 16.0, 25.0, 0.0, 0.0, 67.0, 27.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 4.0, 51.0, 0.0, 9.0, 85.0, 50.0, 29.0, 14.0, 34.0, 63.0, 0.0, 0.0, 72.0, 28.0, 36.0, 32.0, 0.0, 0.0, 3.0, 4.0, 19.0, 17.0, 13.0, 21.0, 0.0, 0.0, 16.0, 29.0, 0.0, 0.0, 0.0, 140.0, 39.0, 27.0, 9.0, 8.0, 0.0, 27.0, 0.0, 0.0, 27.0, 29.0, 24.0, 24.0, 70.0, 99.0, 52.0, 34.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 107.0, 93.0, 71.0, 39.0, 34.0, 46.0, 8.0, 2.0, 67.0, 28.0, 0.0, 0.0, 143.0, 154.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 98.0, 106.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 113.0, 6.0, 6.0, 1.0, 1.0, 0.0, 7.0, 56.0, 7.0, 0.0, 54.0, 129.0, 82.0, 100.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7979537961369837, "mean_inference_ms": 2.2124990841215317, "mean_action_processing_ms": 0.3270311796458926, "mean_env_wait_ms": 0.2884747481133727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01244819164276123, "StateBufferConnector_ms": 0.008347749710083008, "ViewRequirementAgentConnector_ms": 0.1660149097442627}, "num_episodes": 22, "episode_return_max": 253.3999999999997, "episode_return_min": -316.1999999999997, "episode_return_mean": 67.23199999999989, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 246.81768609478513, "num_env_steps_trained_throughput_per_sec": 246.81768609478513, "timesteps_total": 412000, "num_env_steps_sampled_lifetime": 412000, "num_agent_steps_sampled_lifetime": 1648000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1648000, "timers": {"training_iteration_time_ms": 15642.832, "restore_workers_time_ms": 0.018, "training_step_time_ms": 15642.772, "sample_time_ms": 2294.141, "learn_time_ms": 13325.201, "learn_throughput": 300.183, "synch_weights_time_ms": 19.965}, "counters": {"num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "done": false, "training_iteration": 103, "trial_id": "04dec_00002", "date": "2024-08-13_16-45-27", "timestamp": 1723581927, "time_this_iter_s": 16.278203010559082, "time_total_s": 1357.3834476470947, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0452c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1357.3834476470947, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 75.72608695652175, "ram_util_percent": 86.11304347826086}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1504876334279304, "cur_kl_coeff": 1.7380714416503897e-05, "cur_lr": 0.00010000000000000003, "total_loss": 3.673429845880579, "policy_loss": -0.0037727673501071948, "vf_loss": 3.6772025803409556, "vf_explained_var": -7.703963410917414e-05, "kl": 0.004967004802777601, "entropy": 0.44223120518462367, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 195615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.549786828750026, "cur_kl_coeff": 0.7306472307303923, "cur_lr": 0.00010000000000000003, "total_loss": 4.985828404577951, "policy_loss": -1.1804340673344477e-05, "vf_loss": 4.984162718656832, "vf_explained_var": -0.4075592623185859, "kl": 0.002295890166217377, "entropy": 0.5810824968512096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 195615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "env_runners": {"episode_reward_max": 253.3999999999997, "episode_reward_min": -316.1999999999997, "episode_reward_mean": 57.963999999999906, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -324.9999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.69999999999996, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": -5.428000000000004, "predator_policy": 34.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [139.8999999999996, 40.0000000000003, 136.4, -68.69999999999976, -10.40000000000014, -316.1999999999997, 103.59999999999997, 77.79999999999998, 150.7999999999994, 76.19999999999982, 39.20000000000019, 26.200000000000433, -119.20000000000032, 102.3999999999996, 88.59999999999934, 253.3999999999997, 18.80000000000001, 73.30000000000015, 21.700000000000006, 16.89999999999993, 25.19999999999998, 123.39999999999968, 207.59999999999937, 210.99999999999932, 94.99999999999987, 94.0999999999996, 77.5999999999999, 144.9999999999993, 75.20000000000005, 30.100000000000147, 27.10000000000008, 237.19999999999953, 30.800000000000146, 40.0000000000003, -9.699999999999818, 142.1999999999997, 109.29999999999951, 151.09999999999957, 168.09999999999977, 134.89999999999984, 40.0000000000003, 22.00000000000006, 40.0000000000003, 2.100000000000018, 219.6999999999997, 177.2999999999994, 10.300000000000066, 40.0000000000003, 128.39999999999947, 46.300000000000246, 29.900000000000325, 194.99999999999974, 165.49999999999935, 125.29999999999932, 111.09999999999953, 35.600000000000236, -53.39999999999985, 28.500000000000114, -22.50000000000002, 116.29999999999957, 52.49999999999922, 40.0000000000003, -277.4000000000001, 104.79999999999924, 36.70000000000025, 69.70000000000036, -62.299999999999784, 40.0000000000003, 71.30000000000011, 103.89999999999941, 56.30000000000011, 63.70000000000036, 39.9000000000003, 35.00000000000024, 101.79999999999993, 114.99999999999932, 32.30000000000015, -17.299999999999926, 40.0000000000003, 91.29999999999956, 87.69999999999938, 6.700000000000157, 101.19999999999956, -46.59999999999979, 1.5999999999999939, -25.79999999999996, 133.8999999999998, 73.69999999999997, -96.00000000000017, -66.70000000000005, 87.3999999999998, 145.29999999999927, 40.0000000000003, 104.99999999999949, -52.19999999999984, -45.49999999999987, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.70000000000001, 75.20000000000003, 20.000000000000014, 20.000000000000014, 87.5, -87.10000000000048, -318.69999999999993, 20.000000000000014, -93.40000000000003, -57.999999999999986, -294.6999999999998, -284.49999999999983, 59.60000000000004, 20.000000000000014, 20.000000000000014, 57.80000000000015, 3.1999999999999615, 119.59999999999988, -47.80000000000007, 20.000000000000014, 20.000000000000014, -140.79999999999998, 20.000000000000014, -32.799999999999905, -291.1000000000001, 17.899999999999988, 11.599999999999973, 78.80000000000001, 20.000000000000014, 68.60000000000004, 46.099999999999994, 137.29999999999984, -211.00000000000037, 75.80000000000007, -156.40000000000003, 13.699999999999966, 7.399999999999965, 5.299999999999965, 20.000000000000014, -24.099999999999767, -187.0, 3.1999999999999615, -40.000000000000085, 61.40000000000017, 101.6, 65.00000000000014, 54.200000000000195, 156.79999999999993, -16.90000000000004, 17.899999999999988, 78.49999999999993, 11.599999999999973, 56.60000000000013, 20.000000000000014, 131.59999999999982, 7.399999999999972, 13.699999999999964, 6.500000000000041, 1.099999999999983, 20.000000000000014, -40.000000000000036, -67.90000000000032, 97.10000000000007, 97.09999999999988, -6.3999999999999275, -59.79999999999977, 20.000000000000014, 20.000000000000014, -93.99999999999999, -15.699999999999928, 37.100000000000044, 37.10000000000005, 28.10000000000007, 81.19999999999993, 11.599999999999964, 132.49999999999997, 7.999999999999998, 124.09999999999995, 62.900000000000034, 38.00000000000003, 20.000000000000014, 20.000000000000014, 13.699999999999946, -36.699999999999896, 20.000000000000014, 20.000000000000014, 123.49999999999982, -261.4000000000002, 147.49999999999994, 6.199999999999955, -9.40000000000003, 169.69999999999996, 20.000000000000014, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.39999999999995, 20.000000000000014, -21.700000000000042, 38.000000000000135, -177.10000000000042, 4.100000000000014, 104.89999999999998, 53.300000000000146, 96.19999999999989, 17.899999999999988, 106.39999999999979, 91.0999999999999, 20.000000000000014, 20.000000000000014, 11.599999999999966, 20.000000000000014, -273.4, -40.00000000000004, -41.49999999999995, -122.49999999999989, 20.000000000000014, 3.1999999999999615, 103.09999999999991, -38.49999999999998, -3.9999999999999574, 20.000000000000014, 20.000000000000014, -261.7000000000001, -312.70000000000005, 84.79999999999983, 20.000000000000014, 20.000000000000014, 13.699999999999967, 20.000000000000014, 49.70000000000022, -286.29999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999977, 52.40000000000016, 83.89999999999984, 20.000000000000014, 135.79999999999993, -197.50000000000023, 20.000000000000014, 31.70000000000009, 17.899999999999977, 20.000000000000014, 20.000000000000014, 7.999999999999965, 5.299999999999985, 33.5, 2.899999999999929, 58.100000000000115, 34.100000000000016, -212.79999999999998, 20.000000000000014, -217.3000000000001, 20.000000000000014, 20.000000000000014, 71.30000000000001, 20.000000000000014, 67.70000000000005, 20.000000000000014, -3.099999999999965, -5.1999999999999265, 38.300000000000125, 53.900000000000055, 20.000000000000014, -301.6, -147.39999999999998, 20.000000000000014, -224.80000000000015, 20.000000000000014, -90.40000000000006, 38.300000000000026, 61.40000000000017, 5.299999999999965, -324.9999999999999, 20.000000000000014, -289.6, -24.099999999999746, 11.599999999999964, 60.80000000000012, 20.000000000000014, 125.29999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.99999999999986, -296.20000000000005, 20.000000000000014, -323.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.200000000000166, 20.000000000000014], "policy_predator_policy_reward": [31.0, 2.0, 0.0, 0.0, 66.0, 70.0, 151.0, 79.0, 80.0, 61.0, 95.0, 168.0, 15.0, 9.0, 0.0, 0.0, 10.0, 18.0, 50.0, 54.0, 50.0, 110.0, 26.0, 13.0, 85.0, 69.0, 10.0, 2.0, 0.0, 0.0, 30.0, 40.0, 74.0, 80.0, 114.0, 102.0, 9.0, 0.0, 0.0, 21.0, 111.0, 98.0, 42.0, 60.0, 16.0, 25.0, 0.0, 0.0, 67.0, 27.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 4.0, 51.0, 0.0, 9.0, 85.0, 50.0, 29.0, 14.0, 34.0, 63.0, 0.0, 0.0, 72.0, 28.0, 36.0, 32.0, 0.0, 0.0, 3.0, 4.0, 19.0, 17.0, 13.0, 21.0, 0.0, 0.0, 16.0, 29.0, 0.0, 0.0, 0.0, 140.0, 39.0, 27.0, 9.0, 8.0, 0.0, 27.0, 0.0, 0.0, 27.0, 29.0, 24.0, 24.0, 70.0, 99.0, 52.0, 34.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 107.0, 93.0, 71.0, 39.0, 34.0, 46.0, 8.0, 2.0, 67.0, 28.0, 0.0, 0.0, 143.0, 154.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 98.0, 106.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 113.0, 6.0, 6.0, 1.0, 1.0, 0.0, 7.0, 56.0, 7.0, 0.0, 54.0, 129.0, 82.0, 100.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 2.0, 7.0, 155.0, 80.0, 21.0, 108.0, 99.0, 80.0, 94.0, 92.0, 7.0, 0.0, 91.0, 118.0, 152.0, 95.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 152.0, 72.0, 153.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8007572269764041, "mean_inference_ms": 2.2234381419152545, "mean_action_processing_ms": 0.328201518758149, "mean_env_wait_ms": 0.2897240171884999, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012148618698120117, "StateBufferConnector_ms": 0.00842750072479248, "ViewRequirementAgentConnector_ms": 0.17394137382507324}, "num_episodes": 18, "episode_return_max": 253.3999999999997, "episode_return_min": -316.1999999999997, "episode_return_mean": 57.963999999999906, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 228.1750181723687, "num_env_steps_trained_throughput_per_sec": 228.1750181723687, "timesteps_total": 416000, "num_env_steps_sampled_lifetime": 416000, "num_agent_steps_sampled_lifetime": 1664000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1664000, "timers": {"training_iteration_time_ms": 15904.902, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15904.843, "sample_time_ms": 2356.862, "learn_time_ms": 13524.13, "learn_throughput": 295.768, "synch_weights_time_ms": 19.93}, "counters": {"num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "done": false, "training_iteration": 104, "trial_id": "04dec_00002", "date": "2024-08-13_16-45-45", "timestamp": 1723581945, "time_this_iter_s": 17.61870813369751, "time_total_s": 1375.0021557807922, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b045b4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1375.0021557807922, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 78.432, "ram_util_percent": 86.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.24532992051392, "cur_kl_coeff": 8.690357208251949e-06, "cur_lr": 0.00010000000000000003, "total_loss": 5.0152394510450815, "policy_loss": -0.0026812233922697565, "vf_loss": 5.017920672956598, "vf_explained_var": -0.0011656540411489982, "kl": 0.004832667963815945, "entropy": 0.45357322123630966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 197505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.386784607329696, "cur_kl_coeff": 0.36532361536519614, "cur_lr": 0.00010000000000000003, "total_loss": 5.459560689472017, "policy_loss": 0.0006432674697073048, "vf_loss": 5.45811289328116, "vf_explained_var": -0.3119173726076802, "kl": 0.0022022445186872987, "entropy": 0.6445397959499762, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 197505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "env_runners": {"episode_reward_max": 237.19999999999953, "episode_reward_min": -299.0999999999999, "episode_reward_mean": 47.60099999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.69999999999996, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": -10.949499999999999, "predator_policy": 34.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.99999999999932, 94.99999999999987, 94.0999999999996, 77.5999999999999, 144.9999999999993, 75.20000000000005, 30.100000000000147, 27.10000000000008, 237.19999999999953, 30.800000000000146, 40.0000000000003, -9.699999999999818, 142.1999999999997, 109.29999999999951, 151.09999999999957, 168.09999999999977, 134.89999999999984, 40.0000000000003, 22.00000000000006, 40.0000000000003, 2.100000000000018, 219.6999999999997, 177.2999999999994, 10.300000000000066, 40.0000000000003, 128.39999999999947, 46.300000000000246, 29.900000000000325, 194.99999999999974, 165.49999999999935, 125.29999999999932, 111.09999999999953, 35.600000000000236, -53.39999999999985, 28.500000000000114, -22.50000000000002, 116.29999999999957, 52.49999999999922, 40.0000000000003, -277.4000000000001, 104.79999999999924, 36.70000000000025, 69.70000000000036, -62.299999999999784, 40.0000000000003, 71.30000000000011, 103.89999999999941, 56.30000000000011, 63.70000000000036, 39.9000000000003, 35.00000000000024, 101.79999999999993, 114.99999999999932, 32.30000000000015, -17.299999999999926, 40.0000000000003, 91.29999999999956, 87.69999999999938, 6.700000000000157, 101.19999999999956, -46.59999999999979, 1.5999999999999939, -25.79999999999996, 133.8999999999998, 73.69999999999997, -96.00000000000017, -66.70000000000005, 87.3999999999998, 145.29999999999927, 40.0000000000003, 104.99999999999949, -52.19999999999984, -45.49999999999987, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000026, 12.700000000000113, -129.3000000000007, -37.799999999999855, 33.400000000000205, 122.19999999999943, 81.39999999999922, -299.0999999999999, 40.0000000000003, 40.0000000000003, 117.99999999999935, 48.10000000000029, 38.9000000000003, -24.59999999999974, 130.49999999999966, -123.30000000000044, 44.50000000000037, -37.099999999999866, 38.90000000000028, 82.89999999999966, -22.499999999999922, 38.90000000000028, -35.39999999999986, 9.300000000000205], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [54.200000000000195, 156.79999999999993, -16.90000000000004, 17.899999999999988, 78.49999999999993, 11.599999999999973, 56.60000000000013, 20.000000000000014, 131.59999999999982, 7.399999999999972, 13.699999999999964, 6.500000000000041, 1.099999999999983, 20.000000000000014, -40.000000000000036, -67.90000000000032, 97.10000000000007, 97.09999999999988, -6.3999999999999275, -59.79999999999977, 20.000000000000014, 20.000000000000014, -93.99999999999999, -15.699999999999928, 37.100000000000044, 37.10000000000005, 28.10000000000007, 81.19999999999993, 11.599999999999964, 132.49999999999997, 7.999999999999998, 124.09999999999995, 62.900000000000034, 38.00000000000003, 20.000000000000014, 20.000000000000014, 13.699999999999946, -36.699999999999896, 20.000000000000014, 20.000000000000014, 123.49999999999982, -261.4000000000002, 147.49999999999994, 6.199999999999955, -9.40000000000003, 169.69999999999996, 20.000000000000014, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.39999999999995, 20.000000000000014, -21.700000000000042, 38.000000000000135, -177.10000000000042, 4.100000000000014, 104.89999999999998, 53.300000000000146, 96.19999999999989, 17.899999999999988, 106.39999999999979, 91.0999999999999, 20.000000000000014, 20.000000000000014, 11.599999999999966, 20.000000000000014, -273.4, -40.00000000000004, -41.49999999999995, -122.49999999999989, 20.000000000000014, 3.1999999999999615, 103.09999999999991, -38.49999999999998, -3.9999999999999574, 20.000000000000014, 20.000000000000014, -261.7000000000001, -312.70000000000005, 84.79999999999983, 20.000000000000014, 20.000000000000014, 13.699999999999967, 20.000000000000014, 49.70000000000022, -286.29999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999977, 52.40000000000016, 83.89999999999984, 20.000000000000014, 135.79999999999993, -197.50000000000023, 20.000000000000014, 31.70000000000009, 17.899999999999977, 20.000000000000014, 20.000000000000014, 7.999999999999965, 5.299999999999985, 33.5, 2.899999999999929, 58.100000000000115, 34.100000000000016, -212.79999999999998, 20.000000000000014, -217.3000000000001, 20.000000000000014, 20.000000000000014, 71.30000000000001, 20.000000000000014, 67.70000000000005, 20.000000000000014, -3.099999999999965, -5.1999999999999265, 38.300000000000125, 53.900000000000055, 20.000000000000014, -301.6, -147.39999999999998, 20.000000000000014, -224.80000000000015, 20.000000000000014, -90.40000000000006, 38.300000000000026, 61.40000000000017, 5.299999999999965, -324.9999999999999, 20.000000000000014, -289.6, -24.099999999999746, 11.599999999999964, 60.80000000000012, 20.000000000000014, 125.29999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.99999999999986, -296.20000000000005, 20.000000000000014, -323.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.200000000000166, 20.000000000000014, -130.9, -51.400000000000006, -3.0999999999999615, -290.1999999999997, 20.000000000000014, -287.8, 7.399999999999968, 20.000000000000014, 99.19999999999986, 20.000000000000014, 35.30000000000009, -28.900000000000013, -273.40000000000003, -354.6999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999626, 95.9, 20.000000000000014, 28.100000000000108, 17.899999999999977, 20.000000000000014, -379.0, 7.399999999999965, 86.59999999999991, 29.900000000000112, 20.000000000000014, -301.3, 24.50000000000008, 20.000000000000014, 20.000000000000014, -201.09999999999997, 20.000000000000014, 17.899999999999988, 56.900000000000155, 20.000000000000014, 81.20000000000003, -354.70000000000005, 17.899999999999988, 20.000000000000014, -261.4000000000001, 20.000000000000014, 17.899999999999988, -70.60000000000004], "policy_predator_policy_reward": [0.0, 0.0, 67.0, 27.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 4.0, 51.0, 0.0, 9.0, 85.0, 50.0, 29.0, 14.0, 34.0, 63.0, 0.0, 0.0, 72.0, 28.0, 36.0, 32.0, 0.0, 0.0, 3.0, 4.0, 19.0, 17.0, 13.0, 21.0, 0.0, 0.0, 16.0, 29.0, 0.0, 0.0, 0.0, 140.0, 39.0, 27.0, 9.0, 8.0, 0.0, 27.0, 0.0, 0.0, 27.0, 29.0, 24.0, 24.0, 70.0, 99.0, 52.0, 34.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 107.0, 93.0, 71.0, 39.0, 34.0, 46.0, 8.0, 2.0, 67.0, 28.0, 0.0, 0.0, 143.0, 154.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 98.0, 106.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 113.0, 6.0, 6.0, 1.0, 1.0, 0.0, 7.0, 56.0, 7.0, 0.0, 54.0, 129.0, 82.0, 100.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 2.0, 7.0, 155.0, 80.0, 21.0, 108.0, 99.0, 80.0, 94.0, 92.0, 7.0, 0.0, 91.0, 118.0, 152.0, 95.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 152.0, 72.0, 153.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 115.0, 80.0, 161.0, 3.0, 136.0, 94.0, 0.0, 6.0, 0.0, 3.0, 60.0, 15.0, 166.0, 163.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 0.0, 1.0, 164.0, 183.0, 8.0, 6.0, 9.0, 149.0, 0.0, 0.0, 50.0, 94.0, 1.0, 0.0, 0.0, 6.0, 162.0, 89.0, 0.0, 1.0, 130.0, 76.0, 26.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8043436599412422, "mean_inference_ms": 2.237843483309428, "mean_action_processing_ms": 0.32970930496921064, "mean_env_wait_ms": 0.29149889271687424, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01201486587524414, "StateBufferConnector_ms": 0.00835120677947998, "ViewRequirementAgentConnector_ms": 0.1648193597793579}, "num_episodes": 23, "episode_return_max": 237.19999999999953, "episode_return_min": -299.0999999999999, "episode_return_mean": 47.60099999999994, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 263.11885948562644, "num_env_steps_trained_throughput_per_sec": 263.11885948562644, "timesteps_total": 420000, "num_env_steps_sampled_lifetime": 420000, "num_agent_steps_sampled_lifetime": 1680000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1680000, "timers": {"training_iteration_time_ms": 15885.934, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15885.878, "sample_time_ms": 2373.423, "learn_time_ms": 13489.719, "learn_throughput": 296.522, "synch_weights_time_ms": 18.729}, "counters": {"num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "done": false, "training_iteration": 105, "trial_id": "04dec_00002", "date": "2024-08-13_16-46-00", "timestamp": 1723581960, "time_this_iter_s": 15.259353160858154, "time_total_s": 1390.2615089416504, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06678b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1390.2615089416504, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 76.13809523809522, "ram_util_percent": 86.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.246949482847143, "cur_kl_coeff": 4.345178604125974e-06, "cur_lr": 0.00010000000000000003, "total_loss": 3.3715958734038014, "policy_loss": -0.0029372199339959674, "vf_loss": 3.3745330785948133, "vf_explained_var": -0.0004860645879513372, "kl": 0.0046662362820738745, "entropy": 0.42003457098410873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 199395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.057000618731534, "cur_kl_coeff": 0.18266180768259807, "cur_lr": 0.00010000000000000003, "total_loss": 4.6254403056291045, "policy_loss": -0.0009978356016011386, "vf_loss": 4.625586850428707, "vf_explained_var": -0.38282636076054244, "kl": 0.004660466184821725, "entropy": 0.5655068524773159, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 199395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "env_runners": {"episode_reward_max": 219.6999999999997, "episode_reward_min": -299.0999999999999, "episode_reward_mean": 31.420999999999967, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 169.69999999999996, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": -22.2145, "predator_policy": 37.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.00000000000006, 40.0000000000003, 2.100000000000018, 219.6999999999997, 177.2999999999994, 10.300000000000066, 40.0000000000003, 128.39999999999947, 46.300000000000246, 29.900000000000325, 194.99999999999974, 165.49999999999935, 125.29999999999932, 111.09999999999953, 35.600000000000236, -53.39999999999985, 28.500000000000114, -22.50000000000002, 116.29999999999957, 52.49999999999922, 40.0000000000003, -277.4000000000001, 104.79999999999924, 36.70000000000025, 69.70000000000036, -62.299999999999784, 40.0000000000003, 71.30000000000011, 103.89999999999941, 56.30000000000011, 63.70000000000036, 39.9000000000003, 35.00000000000024, 101.79999999999993, 114.99999999999932, 32.30000000000015, -17.299999999999926, 40.0000000000003, 91.29999999999956, 87.69999999999938, 6.700000000000157, 101.19999999999956, -46.59999999999979, 1.5999999999999939, -25.79999999999996, 133.8999999999998, 73.69999999999997, -96.00000000000017, -66.70000000000005, 87.3999999999998, 145.29999999999927, 40.0000000000003, 104.99999999999949, -52.19999999999984, -45.49999999999987, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000026, 12.700000000000113, -129.3000000000007, -37.799999999999855, 33.400000000000205, 122.19999999999943, 81.39999999999922, -299.0999999999999, 40.0000000000003, 40.0000000000003, 117.99999999999935, 48.10000000000029, 38.9000000000003, -24.59999999999974, 130.49999999999966, -123.30000000000044, 44.50000000000037, -37.099999999999866, 38.90000000000028, 82.89999999999966, -22.499999999999922, 38.90000000000028, -35.39999999999986, 9.300000000000205, 122.39999999999966, 12.400000000000054, -87.30000000000062, 40.0000000000003, -146.10000000000025, 112.09999999999955, 73.30000000000003, 11.2000000000002, -31.599999999999838, 63.400000000000354, 111.59999999999958, 76.9000000000002, -27.099999999999955, 40.0000000000003, 36.70000000000025, 10.299999999999967, 27.900000000000112, -265.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999946, -36.699999999999896, 20.000000000000014, 20.000000000000014, 123.49999999999982, -261.4000000000002, 147.49999999999994, 6.199999999999955, -9.40000000000003, 169.69999999999996, 20.000000000000014, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.39999999999995, 20.000000000000014, -21.700000000000042, 38.000000000000135, -177.10000000000042, 4.100000000000014, 104.89999999999998, 53.300000000000146, 96.19999999999989, 17.899999999999988, 106.39999999999979, 91.0999999999999, 20.000000000000014, 20.000000000000014, 11.599999999999966, 20.000000000000014, -273.4, -40.00000000000004, -41.49999999999995, -122.49999999999989, 20.000000000000014, 3.1999999999999615, 103.09999999999991, -38.49999999999998, -3.9999999999999574, 20.000000000000014, 20.000000000000014, -261.7000000000001, -312.70000000000005, 84.79999999999983, 20.000000000000014, 20.000000000000014, 13.699999999999967, 20.000000000000014, 49.70000000000022, -286.29999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999977, 52.40000000000016, 83.89999999999984, 20.000000000000014, 135.79999999999993, -197.50000000000023, 20.000000000000014, 31.70000000000009, 17.899999999999977, 20.000000000000014, 20.000000000000014, 7.999999999999965, 5.299999999999985, 33.5, 2.899999999999929, 58.100000000000115, 34.100000000000016, -212.79999999999998, 20.000000000000014, -217.3000000000001, 20.000000000000014, 20.000000000000014, 71.30000000000001, 20.000000000000014, 67.70000000000005, 20.000000000000014, -3.099999999999965, -5.1999999999999265, 38.300000000000125, 53.900000000000055, 20.000000000000014, -301.6, -147.39999999999998, 20.000000000000014, -224.80000000000015, 20.000000000000014, -90.40000000000006, 38.300000000000026, 61.40000000000017, 5.299999999999965, -324.9999999999999, 20.000000000000014, -289.6, -24.099999999999746, 11.599999999999964, 60.80000000000012, 20.000000000000014, 125.29999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.99999999999986, -296.20000000000005, 20.000000000000014, -323.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.200000000000166, 20.000000000000014, -130.9, -51.400000000000006, -3.0999999999999615, -290.1999999999997, 20.000000000000014, -287.8, 7.399999999999968, 20.000000000000014, 99.19999999999986, 20.000000000000014, 35.30000000000009, -28.900000000000013, -273.40000000000003, -354.6999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999626, 95.9, 20.000000000000014, 28.100000000000108, 17.899999999999977, 20.000000000000014, -379.0, 7.399999999999965, 86.59999999999991, 29.900000000000112, 20.000000000000014, -301.3, 24.50000000000008, 20.000000000000014, 20.000000000000014, -201.09999999999997, 20.000000000000014, 17.899999999999988, 56.900000000000155, 20.000000000000014, 81.20000000000003, -354.70000000000005, 17.899999999999988, 20.000000000000014, -261.4000000000001, 20.000000000000014, 17.899999999999988, -70.60000000000004, 20.000000000000014, 82.39999999999999, -142.90000000000006, 5.299999999999965, -265.3, 32.00000000000013, 20.000000000000014, 20.000000000000014, -193.30000000000013, -164.80000000000055, 20.000000000000014, 79.09999999999997, 20.000000000000014, 53.30000000000015, 20.000000000000014, -233.80000000000004, -38.20000000000001, -147.4, 43.40000000000007, 20.000000000000014, 75.80000000000001, 15.799999999999962, 20.000000000000014, 56.90000000000019, -108.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -36.6999999999998, -3.099999999999965, 20.000000000000014, -250.0, -297.1], "policy_predator_policy_reward": [16.0, 29.0, 0.0, 0.0, 0.0, 140.0, 39.0, 27.0, 9.0, 8.0, 0.0, 27.0, 0.0, 0.0, 27.0, 29.0, 24.0, 24.0, 70.0, 99.0, 52.0, 34.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 107.0, 93.0, 71.0, 39.0, 34.0, 46.0, 8.0, 2.0, 67.0, 28.0, 0.0, 0.0, 143.0, 154.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 98.0, 106.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 113.0, 6.0, 6.0, 1.0, 1.0, 0.0, 7.0, 56.0, 7.0, 0.0, 54.0, 129.0, 82.0, 100.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 2.0, 7.0, 155.0, 80.0, 21.0, 108.0, 99.0, 80.0, 94.0, 92.0, 7.0, 0.0, 91.0, 118.0, 152.0, 95.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 152.0, 72.0, 153.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 115.0, 80.0, 161.0, 3.0, 136.0, 94.0, 0.0, 6.0, 0.0, 3.0, 60.0, 15.0, 166.0, 163.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 0.0, 1.0, 164.0, 183.0, 8.0, 6.0, 9.0, 149.0, 0.0, 0.0, 50.0, 94.0, 1.0, 0.0, 0.0, 6.0, 162.0, 89.0, 0.0, 1.0, 130.0, 76.0, 26.0, 36.0, 16.0, 4.0, 64.0, 86.0, 112.0, 34.0, 0.0, 0.0, 120.0, 92.0, 0.0, 13.0, 0.0, 0.0, 127.0, 98.0, 110.0, 44.0, 0.0, 0.0, 11.0, 9.0, 0.0, 0.0, 58.0, 3.0, 0.0, 0.0, 3.0, 0.0, 27.0, 0.0, 11.0, 0.0, 154.0, 128.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8069190078224594, "mean_inference_ms": 2.2487416188786624, "mean_action_processing_ms": 0.34019329925382935, "mean_env_wait_ms": 0.2928742465115358, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006075739860534668, "StateBufferConnector_ms": 0.006144046783447266, "ViewRequirementAgentConnector_ms": 0.16309213638305664}, "num_episodes": 18, "episode_return_max": 219.6999999999997, "episode_return_min": -299.0999999999999, "episode_return_mean": 31.420999999999967, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 225.5697778626785, "num_env_steps_trained_throughput_per_sec": 225.5697778626785, "timesteps_total": 424000, "num_env_steps_sampled_lifetime": 424000, "num_agent_steps_sampled_lifetime": 1696000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1696000, "timers": {"training_iteration_time_ms": 16146.588, "restore_workers_time_ms": 0.015, "training_step_time_ms": 16146.534, "sample_time_ms": 2615.412, "learn_time_ms": 13507.371, "learn_throughput": 296.135, "synch_weights_time_ms": 19.628}, "counters": {"num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "done": false, "training_iteration": 106, "trial_id": "04dec_00002", "date": "2024-08-13_16-46-18", "timestamp": 1723581978, "time_this_iter_s": 17.8035409450531, "time_total_s": 1408.0650498867035, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06e23a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1408.0650498867035, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 77.976, "ram_util_percent": 85.78}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2165945439584671, "cur_kl_coeff": 2.172589302062987e-06, "cur_lr": 0.00010000000000000003, "total_loss": 3.1189152199124535, "policy_loss": -0.0017545907152077508, "vf_loss": 3.1206698128786035, "vf_explained_var": -0.00010642365173057274, "kl": 0.004575941513411679, "entropy": 0.46419141861812147, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 201285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.07235584181768, "cur_kl_coeff": 0.09133090384129904, "cur_lr": 0.00010000000000000003, "total_loss": 4.0868345774040025, "policy_loss": -0.0007464096827245263, "vf_loss": 4.087144263080819, "vf_explained_var": -0.19342179862910477, "kl": 0.004781862053697494, "entropy": 0.5269646944665404, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 201285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "env_runners": {"episode_reward_max": 158.79999999999944, "episode_reward_min": -337.20000000000016, "episode_reward_mean": 21.77299999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 138.79999999999993, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": -29.09349999999999, "predator_policy": 39.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [104.79999999999924, 36.70000000000025, 69.70000000000036, -62.299999999999784, 40.0000000000003, 71.30000000000011, 103.89999999999941, 56.30000000000011, 63.70000000000036, 39.9000000000003, 35.00000000000024, 101.79999999999993, 114.99999999999932, 32.30000000000015, -17.299999999999926, 40.0000000000003, 91.29999999999956, 87.69999999999938, 6.700000000000157, 101.19999999999956, -46.59999999999979, 1.5999999999999939, -25.79999999999996, 133.8999999999998, 73.69999999999997, -96.00000000000017, -66.70000000000005, 87.3999999999998, 145.29999999999927, 40.0000000000003, 104.99999999999949, -52.19999999999984, -45.49999999999987, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000026, 12.700000000000113, -129.3000000000007, -37.799999999999855, 33.400000000000205, 122.19999999999943, 81.39999999999922, -299.0999999999999, 40.0000000000003, 40.0000000000003, 117.99999999999935, 48.10000000000029, 38.9000000000003, -24.59999999999974, 130.49999999999966, -123.30000000000044, 44.50000000000037, -37.099999999999866, 38.90000000000028, 82.89999999999966, -22.499999999999922, 38.90000000000028, -35.39999999999986, 9.300000000000205, 122.39999999999966, 12.400000000000054, -87.30000000000062, 40.0000000000003, -146.10000000000025, 112.09999999999955, 73.30000000000003, 11.2000000000002, -31.599999999999838, 63.400000000000354, 111.59999999999958, 76.9000000000002, -27.099999999999955, 40.0000000000003, 36.70000000000025, 10.299999999999967, 27.900000000000112, -265.1, 28.60000000000033, 40.0000000000003, -92.70000000000041, -65.39999999999972, -14.99999999999953, 24.60000000000005, 54.700000000000365, 122.79999999999912, 69.70000000000024, 12.500000000000023, -3.7000000000000046, -90.50000000000061, 158.79999999999944, 40.0000000000003, -1.0999999999998864, 40.0000000000003, 118.79999999999936, 52.90000000000028, 9.899999999999984, 35.600000000000236, 64.40000000000008, -337.20000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [84.79999999999983, 20.000000000000014, 20.000000000000014, 13.699999999999967, 20.000000000000014, 49.70000000000022, -286.29999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999977, 52.40000000000016, 83.89999999999984, 20.000000000000014, 135.79999999999993, -197.50000000000023, 20.000000000000014, 31.70000000000009, 17.899999999999977, 20.000000000000014, 20.000000000000014, 7.999999999999965, 5.299999999999985, 33.5, 2.899999999999929, 58.100000000000115, 34.100000000000016, -212.79999999999998, 20.000000000000014, -217.3000000000001, 20.000000000000014, 20.000000000000014, 71.30000000000001, 20.000000000000014, 67.70000000000005, 20.000000000000014, -3.099999999999965, -5.1999999999999265, 38.300000000000125, 53.900000000000055, 20.000000000000014, -301.6, -147.39999999999998, 20.000000000000014, -224.80000000000015, 20.000000000000014, -90.40000000000006, 38.300000000000026, 61.40000000000017, 5.299999999999965, -324.9999999999999, 20.000000000000014, -289.6, -24.099999999999746, 11.599999999999964, 60.80000000000012, 20.000000000000014, 125.29999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.99999999999986, -296.20000000000005, 20.000000000000014, -323.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.200000000000166, 20.000000000000014, -130.9, -51.400000000000006, -3.0999999999999615, -290.1999999999997, 20.000000000000014, -287.8, 7.399999999999968, 20.000000000000014, 99.19999999999986, 20.000000000000014, 35.30000000000009, -28.900000000000013, -273.40000000000003, -354.6999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999626, 95.9, 20.000000000000014, 28.100000000000108, 17.899999999999977, 20.000000000000014, -379.0, 7.399999999999965, 86.59999999999991, 29.900000000000112, 20.000000000000014, -301.3, 24.50000000000008, 20.000000000000014, 20.000000000000014, -201.09999999999997, 20.000000000000014, 17.899999999999988, 56.900000000000155, 20.000000000000014, 81.20000000000003, -354.70000000000005, 17.899999999999988, 20.000000000000014, -261.4000000000001, 20.000000000000014, 17.899999999999988, -70.60000000000004, 20.000000000000014, 82.39999999999999, -142.90000000000006, 5.299999999999965, -265.3, 32.00000000000013, 20.000000000000014, 20.000000000000014, -193.30000000000013, -164.80000000000055, 20.000000000000014, 79.09999999999997, 20.000000000000014, 53.30000000000015, 20.000000000000014, -233.80000000000004, -38.20000000000001, -147.4, 43.40000000000007, 20.000000000000014, 75.80000000000001, 15.799999999999962, 20.000000000000014, 56.90000000000019, -108.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -36.6999999999998, -3.099999999999965, 20.000000000000014, -250.0, -297.1, -69.39999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.70000000000005, -311.1999999999998, 15.799999999999963, -36.69999999999976, -28.29999999999975, 20.000000000000014, -9.399999999999855, 20.000000000000014, 31.700000000000053, 112.69999999999965, 1.0999999999999865, 20.000000000000014, 49.70000000000022, 20.000000000000014, -32.49999999999975, 20.000000000000014, -351.6999999999998, -326.5, 20.000000000000014, 138.79999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -126.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999783, 112.39999999999978, 14.599999999999964, 35.300000000000075, 15.799999999999963, -283.90000000000003, 11.599999999999964, 20.000000000000014, 13.400000000000059, 20.000000000000014, -335.5, -267.70000000000016], "policy_predator_policy_reward": [0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 98.0, 106.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 113.0, 6.0, 6.0, 1.0, 1.0, 0.0, 7.0, 56.0, 7.0, 0.0, 54.0, 129.0, 82.0, 100.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 2.0, 7.0, 155.0, 80.0, 21.0, 108.0, 99.0, 80.0, 94.0, 92.0, 7.0, 0.0, 91.0, 118.0, 152.0, 95.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 152.0, 72.0, 153.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 115.0, 80.0, 161.0, 3.0, 136.0, 94.0, 0.0, 6.0, 0.0, 3.0, 60.0, 15.0, 166.0, 163.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 0.0, 1.0, 164.0, 183.0, 8.0, 6.0, 9.0, 149.0, 0.0, 0.0, 50.0, 94.0, 1.0, 0.0, 0.0, 6.0, 162.0, 89.0, 0.0, 1.0, 130.0, 76.0, 26.0, 36.0, 16.0, 4.0, 64.0, 86.0, 112.0, 34.0, 0.0, 0.0, 120.0, 92.0, 0.0, 13.0, 0.0, 0.0, 127.0, 98.0, 110.0, 44.0, 0.0, 0.0, 11.0, 9.0, 0.0, 0.0, 58.0, 3.0, 0.0, 0.0, 3.0, 0.0, 27.0, 0.0, 11.0, 0.0, 154.0, 128.0, 17.0, 61.0, 0.0, 0.0, 167.0, 51.0, 130.0, 100.0, 27.0, 23.0, 0.0, 14.0, 0.0, 3.0, 0.0, 9.0, 0.0, 0.0, 8.0, 17.0, 153.0, 175.0, 154.0, 62.0, 0.0, 0.0, 0.0, 0.0, 72.0, 33.0, 0.0, 0.0, 9.0, 11.0, 3.0, 0.0, 131.0, 147.0, 0.0, 4.0, 0.0, 31.0, 185.0, 81.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8097525336835565, "mean_inference_ms": 2.259296024786575, "mean_action_processing_ms": 0.35239860847852567, "mean_env_wait_ms": 0.29439549069546755, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0060842037200927734, "StateBufferConnector_ms": 0.006338953971862793, "ViewRequirementAgentConnector_ms": 0.16588056087493896}, "num_episodes": 22, "episode_return_max": 158.79999999999944, "episode_return_min": -337.20000000000016, "episode_return_mean": 21.77299999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 267.9562687328001, "num_env_steps_trained_throughput_per_sec": 267.9562687328001, "timesteps_total": 428000, "num_env_steps_sampled_lifetime": 428000, "num_agent_steps_sampled_lifetime": 1712000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1712000, "timers": {"training_iteration_time_ms": 16009.379, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16009.323, "sample_time_ms": 2618.652, "learn_time_ms": 13368.432, "learn_throughput": 299.212, "synch_weights_time_ms": 18.238}, "counters": {"num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "done": false, "training_iteration": 107, "trial_id": "04dec_00002", "date": "2024-08-13_16-46-33", "timestamp": 1723581993, "time_this_iter_s": 14.975625038146973, "time_total_s": 1423.0406749248505, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06e2f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1423.0406749248505, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 75.15454545454544, "ram_util_percent": 86.36363636363636}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1582249736344372, "cur_kl_coeff": 1.0862946510314936e-06, "cur_lr": 0.00010000000000000003, "total_loss": 3.878207102654472, "policy_loss": -0.001374881738358271, "vf_loss": 3.879581980856638, "vf_explained_var": -0.0001300935392026548, "kl": 0.004229889373368964, "entropy": 0.44407820220662175, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 203175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.249738780294777, "cur_kl_coeff": 0.04566545192064952, "cur_lr": 0.00010000000000000003, "total_loss": 5.27371667352303, "policy_loss": -0.00119753727989971, "vf_loss": 5.274687395272432, "vf_explained_var": -0.1819422719970582, "kl": 0.004967106523144825, "entropy": 0.5975665366208112, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 203175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "env_runners": {"episode_reward_max": 158.79999999999944, "episode_reward_min": -343.4, "episode_reward_mean": 15.023999999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 138.79999999999993, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": -34.87299999999999, "predator_policy": 42.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.700000000000157, 101.19999999999956, -46.59999999999979, 1.5999999999999939, -25.79999999999996, 133.8999999999998, 73.69999999999997, -96.00000000000017, -66.70000000000005, 87.3999999999998, 145.29999999999927, 40.0000000000003, 104.99999999999949, -52.19999999999984, -45.49999999999987, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000026, 12.700000000000113, -129.3000000000007, -37.799999999999855, 33.400000000000205, 122.19999999999943, 81.39999999999922, -299.0999999999999, 40.0000000000003, 40.0000000000003, 117.99999999999935, 48.10000000000029, 38.9000000000003, -24.59999999999974, 130.49999999999966, -123.30000000000044, 44.50000000000037, -37.099999999999866, 38.90000000000028, 82.89999999999966, -22.499999999999922, 38.90000000000028, -35.39999999999986, 9.300000000000205, 122.39999999999966, 12.400000000000054, -87.30000000000062, 40.0000000000003, -146.10000000000025, 112.09999999999955, 73.30000000000003, 11.2000000000002, -31.599999999999838, 63.400000000000354, 111.59999999999958, 76.9000000000002, -27.099999999999955, 40.0000000000003, 36.70000000000025, 10.299999999999967, 27.900000000000112, -265.1, 28.60000000000033, 40.0000000000003, -92.70000000000041, -65.39999999999972, -14.99999999999953, 24.60000000000005, 54.700000000000365, 122.79999999999912, 69.70000000000024, 12.500000000000023, -3.7000000000000046, -90.50000000000061, 158.79999999999944, 40.0000000000003, -1.0999999999998864, 40.0000000000003, 118.79999999999936, 52.90000000000028, 9.899999999999984, 35.600000000000236, 64.40000000000008, -337.20000000000016, -25.59999999999983, -343.4, 50.80000000000048, 106.79999999999953, 27.200000000000216, 20.200000000000095, -58.89999999999976, -49.39999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000013, -6.300000000000038, 78.49999999999997, 83.29999999999959, 127.2999999999993, 117.6999999999995, 20.500000000000057], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.099999999999965, -5.1999999999999265, 38.300000000000125, 53.900000000000055, 20.000000000000014, -301.6, -147.39999999999998, 20.000000000000014, -224.80000000000015, 20.000000000000014, -90.40000000000006, 38.300000000000026, 61.40000000000017, 5.299999999999965, -324.9999999999999, 20.000000000000014, -289.6, -24.099999999999746, 11.599999999999964, 60.80000000000012, 20.000000000000014, 125.29999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.99999999999986, -296.20000000000005, 20.000000000000014, -323.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.200000000000166, 20.000000000000014, -130.9, -51.400000000000006, -3.0999999999999615, -290.1999999999997, 20.000000000000014, -287.8, 7.399999999999968, 20.000000000000014, 99.19999999999986, 20.000000000000014, 35.30000000000009, -28.900000000000013, -273.40000000000003, -354.6999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999626, 95.9, 20.000000000000014, 28.100000000000108, 17.899999999999977, 20.000000000000014, -379.0, 7.399999999999965, 86.59999999999991, 29.900000000000112, 20.000000000000014, -301.3, 24.50000000000008, 20.000000000000014, 20.000000000000014, -201.09999999999997, 20.000000000000014, 17.899999999999988, 56.900000000000155, 20.000000000000014, 81.20000000000003, -354.70000000000005, 17.899999999999988, 20.000000000000014, -261.4000000000001, 20.000000000000014, 17.899999999999988, -70.60000000000004, 20.000000000000014, 82.39999999999999, -142.90000000000006, 5.299999999999965, -265.3, 32.00000000000013, 20.000000000000014, 20.000000000000014, -193.30000000000013, -164.80000000000055, 20.000000000000014, 79.09999999999997, 20.000000000000014, 53.30000000000015, 20.000000000000014, -233.80000000000004, -38.20000000000001, -147.4, 43.40000000000007, 20.000000000000014, 75.80000000000001, 15.799999999999962, 20.000000000000014, 56.90000000000019, -108.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -36.6999999999998, -3.099999999999965, 20.000000000000014, -250.0, -297.1, -69.39999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.70000000000005, -311.1999999999998, 15.799999999999963, -36.69999999999976, -28.29999999999975, 20.000000000000014, -9.399999999999855, 20.000000000000014, 31.700000000000053, 112.69999999999965, 1.0999999999999865, 20.000000000000014, 49.70000000000022, 20.000000000000014, -32.49999999999975, 20.000000000000014, -351.6999999999998, -326.5, 20.000000000000014, 138.79999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -126.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999783, 112.39999999999978, 14.599999999999964, 35.300000000000075, 15.799999999999963, -283.90000000000003, 11.599999999999964, 20.000000000000014, 13.400000000000059, 20.000000000000014, -335.5, -267.70000000000016, 20.000000000000014, -118.60000000000056, -232.00000000000023, -333.39999999999986, 30.800000000000196, 20.000000000000014, 86.59999999999992, 3.199999999999967, 85.69999999999999, -203.50000000000006, -3.1000000000000294, 5.299999999999965, 20.000000000000014, -199.89999999999998, 1.4000000000000654, -260.80000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.20000000000016, -264.69999999999993, 13.399999999999984, 17.899999999999984, 47.60000000000006, 68.90000000000006, -34.5999999999999, 16.099999999999945, 99.19999999999993, 94.69999999999993, 20.000000000000014, -253.00000000000003, 78.49999999999994], "policy_predator_policy_reward": [15.0, 0.0, 2.0, 7.0, 155.0, 80.0, 21.0, 108.0, 99.0, 80.0, 94.0, 92.0, 7.0, 0.0, 91.0, 118.0, 152.0, 95.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 152.0, 72.0, 153.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 115.0, 80.0, 161.0, 3.0, 136.0, 94.0, 0.0, 6.0, 0.0, 3.0, 60.0, 15.0, 166.0, 163.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 0.0, 1.0, 164.0, 183.0, 8.0, 6.0, 9.0, 149.0, 0.0, 0.0, 50.0, 94.0, 1.0, 0.0, 0.0, 6.0, 162.0, 89.0, 0.0, 1.0, 130.0, 76.0, 26.0, 36.0, 16.0, 4.0, 64.0, 86.0, 112.0, 34.0, 0.0, 0.0, 120.0, 92.0, 0.0, 13.0, 0.0, 0.0, 127.0, 98.0, 110.0, 44.0, 0.0, 0.0, 11.0, 9.0, 0.0, 0.0, 58.0, 3.0, 0.0, 0.0, 3.0, 0.0, 27.0, 0.0, 11.0, 0.0, 154.0, 128.0, 17.0, 61.0, 0.0, 0.0, 167.0, 51.0, 130.0, 100.0, 27.0, 23.0, 0.0, 14.0, 0.0, 3.0, 0.0, 9.0, 0.0, 0.0, 8.0, 17.0, 153.0, 175.0, 154.0, 62.0, 0.0, 0.0, 0.0, 0.0, 72.0, 33.0, 0.0, 0.0, 9.0, 11.0, 3.0, 0.0, 131.0, 147.0, 0.0, 4.0, 0.0, 31.0, 185.0, 81.0, 13.0, 60.0, 181.0, 41.0, 0.0, 0.0, 11.0, 6.0, 118.0, 27.0, 14.0, 4.0, 121.0, 0.0, 111.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 117.0, 128.0, 0.0, 13.0, 0.0, 49.0, 7.0, 5.0, 3.0, 0.0, 130.0, 65.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8110114228925502, "mean_inference_ms": 2.268590752216453, "mean_action_processing_ms": 0.36236943376677927, "mean_env_wait_ms": 0.29543137228648164, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0057985782623291016, "StateBufferConnector_ms": 0.004351615905761719, "ViewRequirementAgentConnector_ms": 0.1559000015258789}, "num_episodes": 18, "episode_return_max": 158.79999999999944, "episode_return_min": -343.4, "episode_return_mean": 15.023999999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.55801336757696, "num_env_steps_trained_throughput_per_sec": 247.55801336757696, "timesteps_total": 432000, "num_env_steps_sampled_lifetime": 432000, "num_agent_steps_sampled_lifetime": 1728000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1728000, "timers": {"training_iteration_time_ms": 16149.03, "restore_workers_time_ms": 0.015, "training_step_time_ms": 16148.974, "sample_time_ms": 2614.761, "learn_time_ms": 13511.779, "learn_throughput": 296.038, "synch_weights_time_ms": 18.128}, "counters": {"num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "done": false, "training_iteration": 108, "trial_id": "04dec_00002", "date": "2024-08-13_16-46-49", "timestamp": 1723582009, "time_this_iter_s": 16.19967007637024, "time_total_s": 1439.2403450012207, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1439.2403450012207, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 77.8826086956522, "ram_util_percent": 85.5391304347826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.165185419813035, "cur_kl_coeff": 5.431473255157468e-07, "cur_lr": 0.00010000000000000003, "total_loss": 4.491684071222941, "policy_loss": -0.0015257022599812853, "vf_loss": 4.493209772639805, "vf_explained_var": 0.0006970890930720738, "kl": 0.004763674577578147, "entropy": 0.43847312889401874, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 205065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.99861605847008, "cur_kl_coeff": 0.02283272596032476, "cur_lr": 0.00010000000000000003, "total_loss": 4.750796040277632, "policy_loss": -0.0003541559566098152, "vf_loss": 4.751033659839125, "vf_explained_var": -0.2504035313924154, "kl": 0.005103231538413989, "entropy": 0.576711800111034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 205065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "env_runners": {"episode_reward_max": 158.79999999999944, "episode_reward_min": -360.99999999999994, "episode_reward_mean": 5.761000000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.49999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 138.79999999999993, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -43.6945, "predator_policy": 46.575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.20000000000026, 12.700000000000113, -129.3000000000007, -37.799999999999855, 33.400000000000205, 122.19999999999943, 81.39999999999922, -299.0999999999999, 40.0000000000003, 40.0000000000003, 117.99999999999935, 48.10000000000029, 38.9000000000003, -24.59999999999974, 130.49999999999966, -123.30000000000044, 44.50000000000037, -37.099999999999866, 38.90000000000028, 82.89999999999966, -22.499999999999922, 38.90000000000028, -35.39999999999986, 9.300000000000205, 122.39999999999966, 12.400000000000054, -87.30000000000062, 40.0000000000003, -146.10000000000025, 112.09999999999955, 73.30000000000003, 11.2000000000002, -31.599999999999838, 63.400000000000354, 111.59999999999958, 76.9000000000002, -27.099999999999955, 40.0000000000003, 36.70000000000025, 10.299999999999967, 27.900000000000112, -265.1, 28.60000000000033, 40.0000000000003, -92.70000000000041, -65.39999999999972, -14.99999999999953, 24.60000000000005, 54.700000000000365, 122.79999999999912, 69.70000000000024, 12.500000000000023, -3.7000000000000046, -90.50000000000061, 158.79999999999944, 40.0000000000003, -1.0999999999998864, 40.0000000000003, 118.79999999999936, 52.90000000000028, 9.899999999999984, 35.600000000000236, 64.40000000000008, -337.20000000000016, -25.59999999999983, -343.4, 50.80000000000048, 106.79999999999953, 27.200000000000216, 20.200000000000095, -58.89999999999976, -49.39999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000013, -6.300000000000038, 78.49999999999997, 83.29999999999959, 127.2999999999993, 117.6999999999995, 20.500000000000057, 37.500000000000156, -26.800000000000026, -360.99999999999994, -303.5000000000001, -1.8000000000000425, 97.59999999999974, 41.00000000000015, -85.70000000000059, 30.100000000000147, 4.700000000000007, 87.69999999999999, 37.80000000000027, 57.80000000000025, 40.0000000000003, 40.80000000000032, 36.70000000000025, 79.59999999999997, -256.80000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [42.200000000000166, 20.000000000000014, -130.9, -51.400000000000006, -3.0999999999999615, -290.1999999999997, 20.000000000000014, -287.8, 7.399999999999968, 20.000000000000014, 99.19999999999986, 20.000000000000014, 35.30000000000009, -28.900000000000013, -273.40000000000003, -354.6999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999626, 95.9, 20.000000000000014, 28.100000000000108, 17.899999999999977, 20.000000000000014, -379.0, 7.399999999999965, 86.59999999999991, 29.900000000000112, 20.000000000000014, -301.3, 24.50000000000008, 20.000000000000014, 20.000000000000014, -201.09999999999997, 20.000000000000014, 17.899999999999988, 56.900000000000155, 20.000000000000014, 81.20000000000003, -354.70000000000005, 17.899999999999988, 20.000000000000014, -261.4000000000001, 20.000000000000014, 17.899999999999988, -70.60000000000004, 20.000000000000014, 82.39999999999999, -142.90000000000006, 5.299999999999965, -265.3, 32.00000000000013, 20.000000000000014, 20.000000000000014, -193.30000000000013, -164.80000000000055, 20.000000000000014, 79.09999999999997, 20.000000000000014, 53.30000000000015, 20.000000000000014, -233.80000000000004, -38.20000000000001, -147.4, 43.40000000000007, 20.000000000000014, 75.80000000000001, 15.799999999999962, 20.000000000000014, 56.90000000000019, -108.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -36.6999999999998, -3.099999999999965, 20.000000000000014, -250.0, -297.1, -69.39999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.70000000000005, -311.1999999999998, 15.799999999999963, -36.69999999999976, -28.29999999999975, 20.000000000000014, -9.399999999999855, 20.000000000000014, 31.700000000000053, 112.69999999999965, 1.0999999999999865, 20.000000000000014, 49.70000000000022, 20.000000000000014, -32.49999999999975, 20.000000000000014, -351.6999999999998, -326.5, 20.000000000000014, 138.79999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -126.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999783, 112.39999999999978, 14.599999999999964, 35.300000000000075, 15.799999999999963, -283.90000000000003, 11.599999999999964, 20.000000000000014, 13.400000000000059, 20.000000000000014, -335.5, -267.70000000000016, 20.000000000000014, -118.60000000000056, -232.00000000000023, -333.39999999999986, 30.800000000000196, 20.000000000000014, 86.59999999999992, 3.199999999999967, 85.69999999999999, -203.50000000000006, -3.1000000000000294, 5.299999999999965, 20.000000000000014, -199.89999999999998, 1.4000000000000654, -260.80000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.20000000000016, -264.69999999999993, 13.399999999999984, 17.899999999999984, 47.60000000000006, 68.90000000000006, -34.5999999999999, 16.099999999999945, 99.19999999999993, 94.69999999999993, 20.000000000000014, -253.00000000000003, 78.49999999999994, 9.499999999999952, 20.000000000000014, -149.20000000000022, 7.399999999999965, -383.20000000000005, -359.79999999999995, -286.00000000000006, -329.5, -209.80000000000007, 20.000000000000014, 68.60000000000005, 20.000000000000014, 20.000000000000014, -166.0, -189.10000000000016, -118.60000000000059, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -313.30000000000007, 20.000000000000014, 67.70000000000002, 15.799999999999962, 20.000000000000014, 38.899999999999984, 17.899999999999988, 20.000000000000014, 20.000000000000014, -191.19999999999996, 20.000000000000014, 13.699999999999967, 20.000000000000014, 127.09999999999982, -389.49999999999994, -294.70000000000005, -231.1], "policy_predator_policy_reward": [4.0, 0.0, 115.0, 80.0, 161.0, 3.0, 136.0, 94.0, 0.0, 6.0, 0.0, 3.0, 60.0, 15.0, 166.0, 163.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 0.0, 1.0, 164.0, 183.0, 8.0, 6.0, 9.0, 149.0, 0.0, 0.0, 50.0, 94.0, 1.0, 0.0, 0.0, 6.0, 162.0, 89.0, 0.0, 1.0, 130.0, 76.0, 26.0, 36.0, 16.0, 4.0, 64.0, 86.0, 112.0, 34.0, 0.0, 0.0, 120.0, 92.0, 0.0, 13.0, 0.0, 0.0, 127.0, 98.0, 110.0, 44.0, 0.0, 0.0, 11.0, 9.0, 0.0, 0.0, 58.0, 3.0, 0.0, 0.0, 3.0, 0.0, 27.0, 0.0, 11.0, 0.0, 154.0, 128.0, 17.0, 61.0, 0.0, 0.0, 167.0, 51.0, 130.0, 100.0, 27.0, 23.0, 0.0, 14.0, 0.0, 3.0, 0.0, 9.0, 0.0, 0.0, 8.0, 17.0, 153.0, 175.0, 154.0, 62.0, 0.0, 0.0, 0.0, 0.0, 72.0, 33.0, 0.0, 0.0, 9.0, 11.0, 3.0, 0.0, 131.0, 147.0, 0.0, 4.0, 0.0, 31.0, 185.0, 81.0, 13.0, 60.0, 181.0, 41.0, 0.0, 0.0, 11.0, 6.0, 118.0, 27.0, 14.0, 4.0, 121.0, 0.0, 111.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 117.0, 128.0, 0.0, 13.0, 0.0, 49.0, 7.0, 5.0, 3.0, 0.0, 130.0, 65.0, 8.0, 0.0, 97.0, 18.0, 200.0, 182.0, 145.0, 167.0, 98.0, 90.0, 0.0, 9.0, 90.0, 97.0, 128.0, 94.0, 0.0, 9.0, 138.0, 160.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 112.0, 100.0, 3.0, 0.0, 192.0, 150.0, 98.0, 171.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8121922295053678, "mean_inference_ms": 2.2749607628071926, "mean_action_processing_ms": 0.37179711982973557, "mean_env_wait_ms": 0.2960108902567072, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006037354469299316, "StateBufferConnector_ms": 0.004303097724914551, "ViewRequirementAgentConnector_ms": 0.163132905960083}, "num_episodes": 18, "episode_return_max": 158.79999999999944, "episode_return_min": -360.99999999999994, "episode_return_mean": 5.761000000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 261.902791621148, "num_env_steps_trained_throughput_per_sec": 261.902791621148, "timesteps_total": 436000, "num_env_steps_sampled_lifetime": 436000, "num_agent_steps_sampled_lifetime": 1744000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1744000, "timers": {"training_iteration_time_ms": 16037.667, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16037.61, "sample_time_ms": 2637.223, "learn_time_ms": 13377.89, "learn_throughput": 299.001, "synch_weights_time_ms": 17.829}, "counters": {"num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "done": false, "training_iteration": 109, "trial_id": "04dec_00002", "date": "2024-08-13_16-47-04", "timestamp": 1723582024, "time_this_iter_s": 15.313004970550537, "time_total_s": 1454.5533499717712, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0239ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1454.5533499717712, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 75.40952380952382, "ram_util_percent": 85.60476190476192}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1683349455475176, "cur_kl_coeff": 2.715736627578734e-07, "cur_lr": 0.00010000000000000003, "total_loss": 3.511531818228424, "policy_loss": -0.002103465657543253, "vf_loss": 3.5136352796403187, "vf_explained_var": 0.0008657311320935607, "kl": 0.005233624734875208, "entropy": 0.44713900112916555, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 206955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.771014011789251, "cur_kl_coeff": 0.02283272596032476, "cur_lr": 0.00010000000000000003, "total_loss": 4.391910562818013, "policy_loss": -0.00032318308986427764, "vf_loss": 4.392169303868814, "vf_explained_var": -0.14548364631713384, "kl": 0.002821665353432167, "entropy": 0.6067389938251051, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 206955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "env_runners": {"episode_reward_max": 182.1999999999994, "episode_reward_min": -360.99999999999994, "episode_reward_mean": 13.096000000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.49999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -38.527000000000015, "predator_policy": 45.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.300000000000205, 122.39999999999966, 12.400000000000054, -87.30000000000062, 40.0000000000003, -146.10000000000025, 112.09999999999955, 73.30000000000003, 11.2000000000002, -31.599999999999838, 63.400000000000354, 111.59999999999958, 76.9000000000002, -27.099999999999955, 40.0000000000003, 36.70000000000025, 10.299999999999967, 27.900000000000112, -265.1, 28.60000000000033, 40.0000000000003, -92.70000000000041, -65.39999999999972, -14.99999999999953, 24.60000000000005, 54.700000000000365, 122.79999999999912, 69.70000000000024, 12.500000000000023, -3.7000000000000046, -90.50000000000061, 158.79999999999944, 40.0000000000003, -1.0999999999998864, 40.0000000000003, 118.79999999999936, 52.90000000000028, 9.899999999999984, 35.600000000000236, 64.40000000000008, -337.20000000000016, -25.59999999999983, -343.4, 50.80000000000048, 106.79999999999953, 27.200000000000216, 20.200000000000095, -58.89999999999976, -49.39999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000013, -6.300000000000038, 78.49999999999997, 83.29999999999959, 127.2999999999993, 117.6999999999995, 20.500000000000057, 37.500000000000156, -26.800000000000026, -360.99999999999994, -303.5000000000001, -1.8000000000000425, 97.59999999999974, 41.00000000000015, -85.70000000000059, 30.100000000000147, 4.700000000000007, 87.69999999999999, 37.80000000000027, 57.80000000000025, 40.0000000000003, 40.80000000000032, 36.70000000000025, 79.59999999999997, -256.80000000000007, 40.0000000000003, 148.89999999999918, 66.70000000000014, 182.1999999999994, 94.89999999999972, 30.100000000000147, -151.79999999999995, 84.4999999999999, 40.0000000000003, -5.999999999999895, -65.1999999999999, 40.0000000000003, -9.09999999999972, 150.29999999999984, 85.10000000000007, -68.20000000000074, 129.89999999999986, 23.500000000000092, 35.70000000000024, 21.299999999999994, 23.799999999999997, 38.90000000000028, 25.50000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, -70.60000000000004, 20.000000000000014, 82.39999999999999, -142.90000000000006, 5.299999999999965, -265.3, 32.00000000000013, 20.000000000000014, 20.000000000000014, -193.30000000000013, -164.80000000000055, 20.000000000000014, 79.09999999999997, 20.000000000000014, 53.30000000000015, 20.000000000000014, -233.80000000000004, -38.20000000000001, -147.4, 43.40000000000007, 20.000000000000014, 75.80000000000001, 15.799999999999962, 20.000000000000014, 56.90000000000019, -108.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -36.6999999999998, -3.099999999999965, 20.000000000000014, -250.0, -297.1, -69.39999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.70000000000005, -311.1999999999998, 15.799999999999963, -36.69999999999976, -28.29999999999975, 20.000000000000014, -9.399999999999855, 20.000000000000014, 31.700000000000053, 112.69999999999965, 1.0999999999999865, 20.000000000000014, 49.70000000000022, 20.000000000000014, -32.49999999999975, 20.000000000000014, -351.6999999999998, -326.5, 20.000000000000014, 138.79999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -126.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999783, 112.39999999999978, 14.599999999999964, 35.300000000000075, 15.799999999999963, -283.90000000000003, 11.599999999999964, 20.000000000000014, 13.400000000000059, 20.000000000000014, -335.5, -267.70000000000016, 20.000000000000014, -118.60000000000056, -232.00000000000023, -333.39999999999986, 30.800000000000196, 20.000000000000014, 86.59999999999992, 3.199999999999967, 85.69999999999999, -203.50000000000006, -3.1000000000000294, 5.299999999999965, 20.000000000000014, -199.89999999999998, 1.4000000000000654, -260.80000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.20000000000016, -264.69999999999993, 13.399999999999984, 17.899999999999984, 47.60000000000006, 68.90000000000006, -34.5999999999999, 16.099999999999945, 99.19999999999993, 94.69999999999993, 20.000000000000014, -253.00000000000003, 78.49999999999994, 9.499999999999952, 20.000000000000014, -149.20000000000022, 7.399999999999965, -383.20000000000005, -359.79999999999995, -286.00000000000006, -329.5, -209.80000000000007, 20.000000000000014, 68.60000000000005, 20.000000000000014, 20.000000000000014, -166.0, -189.10000000000016, -118.60000000000059, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -313.30000000000007, 20.000000000000014, 67.70000000000002, 15.799999999999962, 20.000000000000014, 38.899999999999984, 17.899999999999988, 20.000000000000014, 20.000000000000014, -191.19999999999996, 20.000000000000014, 13.699999999999967, 20.000000000000014, 127.09999999999982, -389.49999999999994, -294.70000000000005, -231.1, 20.000000000000014, 20.000000000000014, 138.79999999999976, 1.0999999999999865, 16.99999999999997, 19.700000000000017, 162.2, 20.000000000000014, 74.9, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -190.30000000000004, -269.5, 20.000000000000014, 45.50000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.0, 20.000000000000014, -212.2, 20.000000000000014, 20.000000000000014, -5.800000000000026, -91.30000000000084, -133.60000000000002, 116.89999999999988, 58.10000000000002, 20.000000000000014, -281.2000000000001, -64.0000000000006, -280.0, 134.8999999999999, -74.50000000000071, 20.000000000000014, 20.000000000000014, -7.299999999999901, -15.699999999999754, 20.000000000000014, 64.10000000000011, -334.29999999999995, 20.000000000000014, 17.899999999999988, -8.499999999999897, 20.000000000000014], "policy_predator_policy_reward": [26.0, 36.0, 16.0, 4.0, 64.0, 86.0, 112.0, 34.0, 0.0, 0.0, 120.0, 92.0, 0.0, 13.0, 0.0, 0.0, 127.0, 98.0, 110.0, 44.0, 0.0, 0.0, 11.0, 9.0, 0.0, 0.0, 58.0, 3.0, 0.0, 0.0, 3.0, 0.0, 27.0, 0.0, 11.0, 0.0, 154.0, 128.0, 17.0, 61.0, 0.0, 0.0, 167.0, 51.0, 130.0, 100.0, 27.0, 23.0, 0.0, 14.0, 0.0, 3.0, 0.0, 9.0, 0.0, 0.0, 8.0, 17.0, 153.0, 175.0, 154.0, 62.0, 0.0, 0.0, 0.0, 0.0, 72.0, 33.0, 0.0, 0.0, 9.0, 11.0, 3.0, 0.0, 131.0, 147.0, 0.0, 4.0, 0.0, 31.0, 185.0, 81.0, 13.0, 60.0, 181.0, 41.0, 0.0, 0.0, 11.0, 6.0, 118.0, 27.0, 14.0, 4.0, 121.0, 0.0, 111.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 117.0, 128.0, 0.0, 13.0, 0.0, 49.0, 7.0, 5.0, 3.0, 0.0, 130.0, 65.0, 8.0, 0.0, 97.0, 18.0, 200.0, 182.0, 145.0, 167.0, 98.0, 90.0, 0.0, 9.0, 90.0, 97.0, 128.0, 94.0, 0.0, 9.0, 138.0, 160.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 112.0, 100.0, 3.0, 0.0, 192.0, 150.0, 98.0, 171.0, 0.0, 0.0, 0.0, 9.0, 18.0, 12.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 170.0, 138.0, 8.0, 11.0, 0.0, 0.0, 113.0, 0.0, 1.0, 126.0, 0.0, 0.0, 35.0, 53.0, 85.0, 82.0, 3.0, 4.0, 145.0, 132.0, 159.0, 116.0, 48.0, 30.0, 11.0, 12.0, 0.0, 17.0, 131.0, 163.0, 1.0, 0.0, 14.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8138762908934138, "mean_inference_ms": 2.2825435766380098, "mean_action_processing_ms": 0.3837041298220133, "mean_env_wait_ms": 0.2966711991939259, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008685111999511719, "StateBufferConnector_ms": 0.005094170570373535, "ViewRequirementAgentConnector_ms": 0.19784724712371826}, "num_episodes": 23, "episode_return_max": 182.1999999999994, "episode_return_min": -360.99999999999994, "episode_return_mean": 13.096000000000005, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 260.5187699361763, "num_env_steps_trained_throughput_per_sec": 260.5187699361763, "timesteps_total": 440000, "num_env_steps_sampled_lifetime": 440000, "num_agent_steps_sampled_lifetime": 1760000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1760000, "timers": {"training_iteration_time_ms": 15843.904, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15843.848, "sample_time_ms": 2648.036, "learn_time_ms": 13173.712, "learn_throughput": 303.635, "synch_weights_time_ms": 17.57}, "counters": {"num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "done": false, "training_iteration": 110, "trial_id": "04dec_00002", "date": "2024-08-13_16-47-20", "timestamp": 1723582040, "time_this_iter_s": 15.419047117233276, "time_total_s": 1469.9723970890045, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0728700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1469.9723970890045, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 74.19545454545455, "ram_util_percent": 86.03181818181817}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9999308629877983, "cur_kl_coeff": 2.715736627578734e-07, "cur_lr": 0.00010000000000000003, "total_loss": 2.186348716733317, "policy_loss": -0.001555343984044773, "vf_loss": 2.1879040653112702, "vf_explained_var": 0.0002087555865131358, "kl": 0.005036176468585997, "entropy": 0.383007038349197, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 208845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.09606845495562, "cur_kl_coeff": 0.01141636298016238, "cur_lr": 0.00010000000000000003, "total_loss": 4.316773843765259, "policy_loss": -0.0010782688788369928, "vf_loss": 4.317798424145532, "vf_explained_var": -0.10225016235043763, "kl": 0.004703018547140955, "entropy": 0.5770416198584137, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 208845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "env_runners": {"episode_reward_max": 182.1999999999994, "episode_reward_min": -360.99999999999994, "episode_reward_mean": 17.791000000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.49999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -36.89950000000002, "predator_policy": 45.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-265.1, 28.60000000000033, 40.0000000000003, -92.70000000000041, -65.39999999999972, -14.99999999999953, 24.60000000000005, 54.700000000000365, 122.79999999999912, 69.70000000000024, 12.500000000000023, -3.7000000000000046, -90.50000000000061, 158.79999999999944, 40.0000000000003, -1.0999999999998864, 40.0000000000003, 118.79999999999936, 52.90000000000028, 9.899999999999984, 35.600000000000236, 64.40000000000008, -337.20000000000016, -25.59999999999983, -343.4, 50.80000000000048, 106.79999999999953, 27.200000000000216, 20.200000000000095, -58.89999999999976, -49.39999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000013, -6.300000000000038, 78.49999999999997, 83.29999999999959, 127.2999999999993, 117.6999999999995, 20.500000000000057, 37.500000000000156, -26.800000000000026, -360.99999999999994, -303.5000000000001, -1.8000000000000425, 97.59999999999974, 41.00000000000015, -85.70000000000059, 30.100000000000147, 4.700000000000007, 87.69999999999999, 37.80000000000027, 57.80000000000025, 40.0000000000003, 40.80000000000032, 36.70000000000025, 79.59999999999997, -256.80000000000007, 40.0000000000003, 148.89999999999918, 66.70000000000014, 182.1999999999994, 94.89999999999972, 30.100000000000147, -151.79999999999995, 84.4999999999999, 40.0000000000003, -5.999999999999895, -65.1999999999999, 40.0000000000003, -9.09999999999972, 150.29999999999984, 85.10000000000007, -68.20000000000074, 129.89999999999986, 23.500000000000092, 35.70000000000024, 21.299999999999994, 23.799999999999997, 38.90000000000028, 25.50000000000005, -11.499999999999755, 48.50000000000032, 10.000000000000002, 153.89999999999944, 45.70000000000013, 59.80000000000035, 40.0000000000003, 106.29999999999964, 40.0000000000003, -67.29999999999995, 134.09999999999943, 8.199999999999966, 120.59999999999948, 23.500000000000036, 118.59999999999991, 40.0000000000003, 40.0000000000003, 14.500000000000037], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-250.0, -297.1, -69.39999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -330.70000000000005, -311.1999999999998, 15.799999999999963, -36.69999999999976, -28.29999999999975, 20.000000000000014, -9.399999999999855, 20.000000000000014, 31.700000000000053, 112.69999999999965, 1.0999999999999865, 20.000000000000014, 49.70000000000022, 20.000000000000014, -32.49999999999975, 20.000000000000014, -351.6999999999998, -326.5, 20.000000000000014, 138.79999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -126.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999783, 112.39999999999978, 14.599999999999964, 35.300000000000075, 15.799999999999963, -283.90000000000003, 11.599999999999964, 20.000000000000014, 13.400000000000059, 20.000000000000014, -335.5, -267.70000000000016, 20.000000000000014, -118.60000000000056, -232.00000000000023, -333.39999999999986, 30.800000000000196, 20.000000000000014, 86.59999999999992, 3.199999999999967, 85.69999999999999, -203.50000000000006, -3.1000000000000294, 5.299999999999965, 20.000000000000014, -199.89999999999998, 1.4000000000000654, -260.80000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.20000000000016, -264.69999999999993, 13.399999999999984, 17.899999999999984, 47.60000000000006, 68.90000000000006, -34.5999999999999, 16.099999999999945, 99.19999999999993, 94.69999999999993, 20.000000000000014, -253.00000000000003, 78.49999999999994, 9.499999999999952, 20.000000000000014, -149.20000000000022, 7.399999999999965, -383.20000000000005, -359.79999999999995, -286.00000000000006, -329.5, -209.80000000000007, 20.000000000000014, 68.60000000000005, 20.000000000000014, 20.000000000000014, -166.0, -189.10000000000016, -118.60000000000059, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -313.30000000000007, 20.000000000000014, 67.70000000000002, 15.799999999999962, 20.000000000000014, 38.899999999999984, 17.899999999999988, 20.000000000000014, 20.000000000000014, -191.19999999999996, 20.000000000000014, 13.699999999999967, 20.000000000000014, 127.09999999999982, -389.49999999999994, -294.70000000000005, -231.1, 20.000000000000014, 20.000000000000014, 138.79999999999976, 1.0999999999999865, 16.99999999999997, 19.700000000000017, 162.2, 20.000000000000014, 74.9, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -190.30000000000004, -269.5, 20.000000000000014, 45.50000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.0, 20.000000000000014, -212.2, 20.000000000000014, 20.000000000000014, -5.800000000000026, -91.30000000000084, -133.60000000000002, 116.89999999999988, 58.10000000000002, 20.000000000000014, -281.2000000000001, -64.0000000000006, -280.0, 134.8999999999999, -74.50000000000071, 20.000000000000014, 20.000000000000014, -7.299999999999901, -15.699999999999754, 20.000000000000014, 64.10000000000011, -334.29999999999995, 20.000000000000014, 17.899999999999988, -8.499999999999897, 20.000000000000014, -102.40000000000056, 17.899999999999988, 18.500000000000014, 20.000000000000014, -247.0, 20.000000000000014, 118.09999999999985, 33.79999999999998, 7.69999999999996, 20.000000000000014, 20.000000000000014, 39.80000000000011, 20.000000000000014, 20.000000000000014, 7.399999999999965, 92.89999999999992, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -272.5, 20.000000000000014, 103.0999999999999, -238.60000000000022, 93.79999999999995, 79.7, 17.89999999999998, -11.499999999999826, 20.000000000000014, 155.29999999999987, -336.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -268.3000000000002, 84.80000000000001], "policy_predator_policy_reward": [154.0, 128.0, 17.0, 61.0, 0.0, 0.0, 167.0, 51.0, 130.0, 100.0, 27.0, 23.0, 0.0, 14.0, 0.0, 3.0, 0.0, 9.0, 0.0, 0.0, 8.0, 17.0, 153.0, 175.0, 154.0, 62.0, 0.0, 0.0, 0.0, 0.0, 72.0, 33.0, 0.0, 0.0, 9.0, 11.0, 3.0, 0.0, 131.0, 147.0, 0.0, 4.0, 0.0, 31.0, 185.0, 81.0, 13.0, 60.0, 181.0, 41.0, 0.0, 0.0, 11.0, 6.0, 118.0, 27.0, 14.0, 4.0, 121.0, 0.0, 111.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 117.0, 128.0, 0.0, 13.0, 0.0, 49.0, 7.0, 5.0, 3.0, 0.0, 130.0, 65.0, 8.0, 0.0, 97.0, 18.0, 200.0, 182.0, 145.0, 167.0, 98.0, 90.0, 0.0, 9.0, 90.0, 97.0, 128.0, 94.0, 0.0, 9.0, 138.0, 160.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 112.0, 100.0, 3.0, 0.0, 192.0, 150.0, 98.0, 171.0, 0.0, 0.0, 0.0, 9.0, 18.0, 12.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 170.0, 138.0, 8.0, 11.0, 0.0, 0.0, 113.0, 0.0, 1.0, 126.0, 0.0, 0.0, 35.0, 53.0, 85.0, 82.0, 3.0, 4.0, 145.0, 132.0, 159.0, 116.0, 48.0, 30.0, 11.0, 12.0, 0.0, 17.0, 131.0, 163.0, 1.0, 0.0, 14.0, 0.0, 9.0, 64.0, 2.0, 8.0, 115.0, 122.0, 2.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 65.0, 137.0, 0.0, 11.0, 23.0, 130.0, 15.0, 8.0, 0.0, 15.0, 164.0, 136.0, 0.0, 0.0, 0.0, 0.0, 79.0, 119.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8150629165696622, "mean_inference_ms": 2.2882002557704233, "mean_action_processing_ms": 0.38415185705912597, "mean_env_wait_ms": 0.2971453508653254, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008361339569091797, "StateBufferConnector_ms": 0.004967212677001953, "ViewRequirementAgentConnector_ms": 0.18741798400878906}, "num_episodes": 18, "episode_return_max": 182.1999999999994, "episode_return_min": -360.99999999999994, "episode_return_mean": 17.791000000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.31532424596975, "num_env_steps_trained_throughput_per_sec": 269.31532424596975, "timesteps_total": 444000, "num_env_steps_sampled_lifetime": 444000, "num_agent_steps_sampled_lifetime": 1776000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1776000, "timers": {"training_iteration_time_ms": 15802.077, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15802.02, "sample_time_ms": 2625.837, "learn_time_ms": 13154.421, "learn_throughput": 304.08, "synch_weights_time_ms": 17.191}, "counters": {"num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "done": false, "training_iteration": 111, "trial_id": "04dec_00002", "date": "2024-08-13_16-47-35", "timestamp": 1723582055, "time_this_iter_s": 14.898289918899536, "time_total_s": 1484.870687007904, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c4430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1484.870687007904, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 73.09523809523807, "ram_util_percent": 85.82380952380952}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1280354610905445, "cur_kl_coeff": 2.715736627578734e-07, "cur_lr": 0.00010000000000000003, "total_loss": 2.976600259006339, "policy_loss": -0.001977275691128203, "vf_loss": 2.978577534294633, "vf_explained_var": 0.0028098139497968887, "kl": 0.004237900671462616, "entropy": 0.36442618267561394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 210735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.08244161776134, "cur_kl_coeff": 0.00570818149008119, "cur_lr": 0.00010000000000000003, "total_loss": 3.783552057654769, "policy_loss": -0.0005422850739378384, "vf_loss": 3.7840726436130585, "vf_explained_var": -0.15611754444541123, "kl": 0.003802734848617655, "entropy": 0.6149195859987269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 210735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "env_runners": {"episode_reward_max": 182.1999999999994, "episode_reward_min": -360.99999999999994, "episode_reward_mean": 28.55, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.49999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -26.365000000000023, "predator_policy": 40.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-337.20000000000016, -25.59999999999983, -343.4, 50.80000000000048, 106.79999999999953, 27.200000000000216, 20.200000000000095, -58.89999999999976, -49.39999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.20000000000013, -6.300000000000038, 78.49999999999997, 83.29999999999959, 127.2999999999993, 117.6999999999995, 20.500000000000057, 37.500000000000156, -26.800000000000026, -360.99999999999994, -303.5000000000001, -1.8000000000000425, 97.59999999999974, 41.00000000000015, -85.70000000000059, 30.100000000000147, 4.700000000000007, 87.69999999999999, 37.80000000000027, 57.80000000000025, 40.0000000000003, 40.80000000000032, 36.70000000000025, 79.59999999999997, -256.80000000000007, 40.0000000000003, 148.89999999999918, 66.70000000000014, 182.1999999999994, 94.89999999999972, 30.100000000000147, -151.79999999999995, 84.4999999999999, 40.0000000000003, -5.999999999999895, -65.1999999999999, 40.0000000000003, -9.09999999999972, 150.29999999999984, 85.10000000000007, -68.20000000000074, 129.89999999999986, 23.500000000000092, 35.70000000000024, 21.299999999999994, 23.799999999999997, 38.90000000000028, 25.50000000000005, -11.499999999999755, 48.50000000000032, 10.000000000000002, 153.89999999999944, 45.70000000000013, 59.80000000000035, 40.0000000000003, 106.29999999999964, 40.0000000000003, -67.29999999999995, 134.09999999999943, 8.199999999999966, 120.59999999999948, 23.500000000000036, 118.59999999999991, 40.0000000000003, 40.0000000000003, 14.500000000000037, 31.100000000000165, 30.100000000000147, 152.99999999999926, 40.0000000000003, 47.700000000000244, 173.19999999999928, 40.0000000000003, 34.89999999999999, 6.5999999999999215, 154.69999999999928, 26.900000000000148, 40.0000000000003, 40.0000000000003, 22.30000000000029, 169.0999999999992, 75.89999999999986, 60.60000000000026, 35.600000000000236, 84.99999999999969, 105.69999999999986, 15.600000000000183, 27.700000000000124], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-335.5, -267.70000000000016, 20.000000000000014, -118.60000000000056, -232.00000000000023, -333.39999999999986, 30.800000000000196, 20.000000000000014, 86.59999999999992, 3.199999999999967, 85.69999999999999, -203.50000000000006, -3.1000000000000294, 5.299999999999965, 20.000000000000014, -199.89999999999998, 1.4000000000000654, -260.80000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.20000000000016, -264.69999999999993, 13.399999999999984, 17.899999999999984, 47.60000000000006, 68.90000000000006, -34.5999999999999, 16.099999999999945, 99.19999999999993, 94.69999999999993, 20.000000000000014, -253.00000000000003, 78.49999999999994, 9.499999999999952, 20.000000000000014, -149.20000000000022, 7.399999999999965, -383.20000000000005, -359.79999999999995, -286.00000000000006, -329.5, -209.80000000000007, 20.000000000000014, 68.60000000000005, 20.000000000000014, 20.000000000000014, -166.0, -189.10000000000016, -118.60000000000059, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -313.30000000000007, 20.000000000000014, 67.70000000000002, 15.799999999999962, 20.000000000000014, 38.899999999999984, 17.899999999999988, 20.000000000000014, 20.000000000000014, -191.19999999999996, 20.000000000000014, 13.699999999999967, 20.000000000000014, 127.09999999999982, -389.49999999999994, -294.70000000000005, -231.1, 20.000000000000014, 20.000000000000014, 138.79999999999976, 1.0999999999999865, 16.99999999999997, 19.700000000000017, 162.2, 20.000000000000014, 74.9, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -190.30000000000004, -269.5, 20.000000000000014, 45.50000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.0, 20.000000000000014, -212.2, 20.000000000000014, 20.000000000000014, -5.800000000000026, -91.30000000000084, -133.60000000000002, 116.89999999999988, 58.10000000000002, 20.000000000000014, -281.2000000000001, -64.0000000000006, -280.0, 134.8999999999999, -74.50000000000071, 20.000000000000014, 20.000000000000014, -7.299999999999901, -15.699999999999754, 20.000000000000014, 64.10000000000011, -334.29999999999995, 20.000000000000014, 17.899999999999988, -8.499999999999897, 20.000000000000014, -102.40000000000056, 17.899999999999988, 18.500000000000014, 20.000000000000014, -247.0, 20.000000000000014, 118.09999999999985, 33.79999999999998, 7.69999999999996, 20.000000000000014, 20.000000000000014, 39.80000000000011, 20.000000000000014, 20.000000000000014, 7.399999999999965, 92.89999999999992, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -272.5, 20.000000000000014, 103.0999999999999, -238.60000000000022, 93.79999999999995, 79.7, 17.89999999999998, -11.499999999999826, 20.000000000000014, 155.29999999999987, -336.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -268.3000000000002, 84.80000000000001, 1.099999999999983, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 121.99999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999934, 35.90000000000012, 20.000000000000014, 153.1999999999999, 20.000000000000014, 20.000000000000014, -31.299999999999898, 3.1999999999999633, 20.000000000000014, -255.4000000000001, 152.29999999999978, -13.599999999999783, 20.000000000000014, -174.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.70000000000005, 5.299999999999965, 156.7999999999998, 20.000000000000014, 41.900000000000084, 56.00000000000017, -9.399999999999876, 11.599999999999973, 20.000000000000014, 65.00000000000011, 20.000000000000014, 85.70000000000003, 20.000000000000014, -2.799999999999883, 1.400000000000101, -7.299999999999919, 20.000000000000014], "policy_predator_policy_reward": [185.0, 81.0, 13.0, 60.0, 181.0, 41.0, 0.0, 0.0, 11.0, 6.0, 118.0, 27.0, 14.0, 4.0, 121.0, 0.0, 111.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 117.0, 128.0, 0.0, 13.0, 0.0, 49.0, 7.0, 5.0, 3.0, 0.0, 130.0, 65.0, 8.0, 0.0, 97.0, 18.0, 200.0, 182.0, 145.0, 167.0, 98.0, 90.0, 0.0, 9.0, 90.0, 97.0, 128.0, 94.0, 0.0, 9.0, 138.0, 160.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 112.0, 100.0, 3.0, 0.0, 192.0, 150.0, 98.0, 171.0, 0.0, 0.0, 0.0, 9.0, 18.0, 12.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 170.0, 138.0, 8.0, 11.0, 0.0, 0.0, 113.0, 0.0, 1.0, 126.0, 0.0, 0.0, 35.0, 53.0, 85.0, 82.0, 3.0, 4.0, 145.0, 132.0, 159.0, 116.0, 48.0, 30.0, 11.0, 12.0, 0.0, 17.0, 131.0, 163.0, 1.0, 0.0, 14.0, 0.0, 9.0, 64.0, 2.0, 8.0, 115.0, 122.0, 2.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 65.0, 137.0, 0.0, 11.0, 23.0, 130.0, 15.0, 8.0, 0.0, 15.0, 164.0, 136.0, 0.0, 0.0, 0.0, 0.0, 79.0, 119.0, 9.0, 1.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 0.0, 39.0, 24.0, 135.0, 107.0, 0.0, 16.0, 62.0, 119.0, 0.0, 0.0, 0.0, 0.0, 114.0, 129.0, 7.0, 0.0, 0.0, 14.0, 11.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 3.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.816310789124236, "mean_inference_ms": 2.2949991831961287, "mean_action_processing_ms": 0.38407726895794125, "mean_env_wait_ms": 0.2977110881222253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008376240730285645, "StateBufferConnector_ms": 0.008054614067077637, "ViewRequirementAgentConnector_ms": 0.20083510875701904}, "num_episodes": 22, "episode_return_max": 182.1999999999994, "episode_return_min": -360.99999999999994, "episode_return_mean": 28.55, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 258.5979752641898, "num_env_steps_trained_throughput_per_sec": 258.5979752641898, "timesteps_total": 448000, "num_env_steps_sampled_lifetime": 448000, "num_agent_steps_sampled_lifetime": 1792000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1792000, "timers": {"training_iteration_time_ms": 15870.489, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15870.432, "sample_time_ms": 2593.996, "learn_time_ms": 13254.846, "learn_throughput": 301.776, "synch_weights_time_ms": 16.839}, "counters": {"num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "done": false, "training_iteration": 112, "trial_id": "04dec_00002", "date": "2024-08-13_16-47-50", "timestamp": 1723582070, "time_this_iter_s": 15.535606622695923, "time_total_s": 1500.4062936306, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0239ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1500.4062936306, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 78.10909090909091, "ram_util_percent": 85.92272727272726}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.129478010937335, "cur_kl_coeff": 1.357868313789367e-07, "cur_lr": 0.00010000000000000003, "total_loss": 2.3447796475319636, "policy_loss": -0.001614574419467577, "vf_loss": 2.346394220735661, "vf_explained_var": 0.0018385674587633244, "kl": 0.0033142927778470103, "entropy": 0.36805531265874386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 212625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.046912755663433, "cur_kl_coeff": 0.002854090745040595, "cur_lr": 0.00010000000000000003, "total_loss": 3.966168671184116, "policy_loss": -0.00276931607775469, "vf_loss": 3.968912377054729, "vf_explained_var": -0.15506283240343527, "kl": 0.008974767943404212, "entropy": 0.6017081848843387, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 212625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "env_runners": {"episode_reward_max": 214.5999999999991, "episode_reward_min": -360.99999999999994, "episode_reward_mean": 34.47999999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.49999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -22.420000000000012, "predator_policy": 39.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.500000000000057, 37.500000000000156, -26.800000000000026, -360.99999999999994, -303.5000000000001, -1.8000000000000425, 97.59999999999974, 41.00000000000015, -85.70000000000059, 30.100000000000147, 4.700000000000007, 87.69999999999999, 37.80000000000027, 57.80000000000025, 40.0000000000003, 40.80000000000032, 36.70000000000025, 79.59999999999997, -256.80000000000007, 40.0000000000003, 148.89999999999918, 66.70000000000014, 182.1999999999994, 94.89999999999972, 30.100000000000147, -151.79999999999995, 84.4999999999999, 40.0000000000003, -5.999999999999895, -65.1999999999999, 40.0000000000003, -9.09999999999972, 150.29999999999984, 85.10000000000007, -68.20000000000074, 129.89999999999986, 23.500000000000092, 35.70000000000024, 21.299999999999994, 23.799999999999997, 38.90000000000028, 25.50000000000005, -11.499999999999755, 48.50000000000032, 10.000000000000002, 153.89999999999944, 45.70000000000013, 59.80000000000035, 40.0000000000003, 106.29999999999964, 40.0000000000003, -67.29999999999995, 134.09999999999943, 8.199999999999966, 120.59999999999948, 23.500000000000036, 118.59999999999991, 40.0000000000003, 40.0000000000003, 14.500000000000037, 31.100000000000165, 30.100000000000147, 152.99999999999926, 40.0000000000003, 47.700000000000244, 173.19999999999928, 40.0000000000003, 34.89999999999999, 6.5999999999999215, 154.69999999999928, 26.900000000000148, 40.0000000000003, 40.0000000000003, 22.30000000000029, 169.0999999999992, 75.89999999999986, 60.60000000000026, 35.600000000000236, 84.99999999999969, 105.69999999999986, 15.600000000000183, 27.700000000000124, -5.9999999999998845, 214.5999999999991, 91.29999999999977, 32.30000000000018, 11.099999999999989, -47.29999999999987, -19.20000000000002, 40.0000000000003, 29.00000000000013, 134.89999999999958, 22.400000000000013, 181.29999999999913, -83.90000000000009, -95.40000000000055, 41.10000000000026, 3.400000000000216, -27.19999999999979, 47.80000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-253.00000000000003, 78.49999999999994, 9.499999999999952, 20.000000000000014, -149.20000000000022, 7.399999999999965, -383.20000000000005, -359.79999999999995, -286.00000000000006, -329.5, -209.80000000000007, 20.000000000000014, 68.60000000000005, 20.000000000000014, 20.000000000000014, -166.0, -189.10000000000016, -118.60000000000059, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -313.30000000000007, 20.000000000000014, 67.70000000000002, 15.799999999999962, 20.000000000000014, 38.899999999999984, 17.899999999999988, 20.000000000000014, 20.000000000000014, -191.19999999999996, 20.000000000000014, 13.699999999999967, 20.000000000000014, 127.09999999999982, -389.49999999999994, -294.70000000000005, -231.1, 20.000000000000014, 20.000000000000014, 138.79999999999976, 1.0999999999999865, 16.99999999999997, 19.700000000000017, 162.2, 20.000000000000014, 74.9, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -190.30000000000004, -269.5, 20.000000000000014, 45.50000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.0, 20.000000000000014, -212.2, 20.000000000000014, 20.000000000000014, -5.800000000000026, -91.30000000000084, -133.60000000000002, 116.89999999999988, 58.10000000000002, 20.000000000000014, -281.2000000000001, -64.0000000000006, -280.0, 134.8999999999999, -74.50000000000071, 20.000000000000014, 20.000000000000014, -7.299999999999901, -15.699999999999754, 20.000000000000014, 64.10000000000011, -334.29999999999995, 20.000000000000014, 17.899999999999988, -8.499999999999897, 20.000000000000014, -102.40000000000056, 17.899999999999988, 18.500000000000014, 20.000000000000014, -247.0, 20.000000000000014, 118.09999999999985, 33.79999999999998, 7.69999999999996, 20.000000000000014, 20.000000000000014, 39.80000000000011, 20.000000000000014, 20.000000000000014, 7.399999999999965, 92.89999999999992, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -272.5, 20.000000000000014, 103.0999999999999, -238.60000000000022, 93.79999999999995, 79.7, 17.89999999999998, -11.499999999999826, 20.000000000000014, 155.29999999999987, -336.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -268.3000000000002, 84.80000000000001, 1.099999999999983, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 121.99999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999934, 35.90000000000012, 20.000000000000014, 153.1999999999999, 20.000000000000014, 20.000000000000014, -31.299999999999898, 3.1999999999999633, 20.000000000000014, -255.4000000000001, 152.29999999999978, -13.599999999999783, 20.000000000000014, -174.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.70000000000005, 5.299999999999965, 156.7999999999998, 20.000000000000014, 41.900000000000084, 56.00000000000017, -9.399999999999876, 11.599999999999973, 20.000000000000014, 65.00000000000011, 20.000000000000014, 85.70000000000003, 20.000000000000014, -2.799999999999883, 1.400000000000101, -7.299999999999919, 20.000000000000014, -45.09999999999981, -13.8999999999998, 92.89999999999989, 121.69999999999987, 20.000000000000014, 71.3000000000001, 5.299999999999965, 20.000000000000014, -36.69999999999978, 15.799999999999963, 20.000000000000014, -193.3, -329.19999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999917, 49.400000000000055, 75.5, -7.299999999999912, 13.699999999999964, 20.000000000000014, 161.2999999999998, -280.3, 43.400000000000134, 20.000000000000014, -300.3999999999995, 20.000000000000014, 13.099999999999966, -17.79999999999974, 3.1999999999999615, -347.19999999999993, 20.000000000000014, 20.000000000000014, 24.799999999999997], "policy_predator_policy_reward": [130.0, 65.0, 8.0, 0.0, 97.0, 18.0, 200.0, 182.0, 145.0, 167.0, 98.0, 90.0, 0.0, 9.0, 90.0, 97.0, 128.0, 94.0, 0.0, 9.0, 138.0, 160.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 112.0, 100.0, 3.0, 0.0, 192.0, 150.0, 98.0, 171.0, 0.0, 0.0, 0.0, 9.0, 18.0, 12.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 170.0, 138.0, 8.0, 11.0, 0.0, 0.0, 113.0, 0.0, 1.0, 126.0, 0.0, 0.0, 35.0, 53.0, 85.0, 82.0, 3.0, 4.0, 145.0, 132.0, 159.0, 116.0, 48.0, 30.0, 11.0, 12.0, 0.0, 17.0, 131.0, 163.0, 1.0, 0.0, 14.0, 0.0, 9.0, 64.0, 2.0, 8.0, 115.0, 122.0, 2.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 65.0, 137.0, 0.0, 11.0, 23.0, 130.0, 15.0, 8.0, 0.0, 15.0, 164.0, 136.0, 0.0, 0.0, 0.0, 0.0, 79.0, 119.0, 9.0, 1.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 0.0, 39.0, 24.0, 135.0, 107.0, 0.0, 16.0, 62.0, 119.0, 0.0, 0.0, 0.0, 0.0, 114.0, 129.0, 7.0, 0.0, 0.0, 14.0, 11.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 3.0, 12.0, 47.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 11.0, 21.0, 110.0, 16.0, 147.0, 143.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 3.0, 13.0, 0.0, 0.0, 46.0, 107.0, 50.0, 135.0, 3.0, 5.0, 6.0, 12.0, 171.0, 129.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8173250568180805, "mean_inference_ms": 2.300325424825847, "mean_action_processing_ms": 0.38396668251839217, "mean_env_wait_ms": 0.29813030307979893, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012016057968139648, "StateBufferConnector_ms": 0.008060336112976074, "ViewRequirementAgentConnector_ms": 0.20686113834381104}, "num_episodes": 18, "episode_return_max": 214.5999999999991, "episode_return_min": -360.99999999999994, "episode_return_mean": 34.47999999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 270.5239397704754, "num_env_steps_trained_throughput_per_sec": 270.5239397704754, "timesteps_total": 452000, "num_env_steps_sampled_lifetime": 452000, "num_agent_steps_sampled_lifetime": 1808000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1808000, "timers": {"training_iteration_time_ms": 15728.471, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15728.415, "sample_time_ms": 2496.958, "learn_time_ms": 13209.778, "learn_throughput": 302.806, "synch_weights_time_ms": 16.737}, "counters": {"num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "done": false, "training_iteration": 113, "trial_id": "04dec_00002", "date": "2024-08-13_16-48-05", "timestamp": 1723582085, "time_this_iter_s": 14.833279848098755, "time_total_s": 1515.2395734786987, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04418b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1515.2395734786987, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 74.9952380952381, "ram_util_percent": 86.4047619047619}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2081388359268506, "cur_kl_coeff": 6.789341568946835e-08, "cur_lr": 0.00010000000000000003, "total_loss": 4.3071084142361995, "policy_loss": -0.00235458948555841, "vf_loss": 4.309463007740243, "vf_explained_var": 0.0003400657858167376, "kl": 0.004653741502345999, "entropy": 0.3762445782542859, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 214515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.473593348485451, "cur_kl_coeff": 0.002854090745040595, "cur_lr": 0.00010000000000000003, "total_loss": 3.556035161081445, "policy_loss": -0.0010334395526331805, "vf_loss": 3.557051128685159, "vf_explained_var": -0.20652509814216977, "kl": 0.006117506035504694, "entropy": 0.5919704114003156, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 214515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "env_runners": {"episode_reward_max": 214.5999999999991, "episode_reward_min": -266.4, "episode_reward_mean": 38.323, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -377.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.2999999999998, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -18.983500000000003, "predator_policy": 38.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [94.89999999999972, 30.100000000000147, -151.79999999999995, 84.4999999999999, 40.0000000000003, -5.999999999999895, -65.1999999999999, 40.0000000000003, -9.09999999999972, 150.29999999999984, 85.10000000000007, -68.20000000000074, 129.89999999999986, 23.500000000000092, 35.70000000000024, 21.299999999999994, 23.799999999999997, 38.90000000000028, 25.50000000000005, -11.499999999999755, 48.50000000000032, 10.000000000000002, 153.89999999999944, 45.70000000000013, 59.80000000000035, 40.0000000000003, 106.29999999999964, 40.0000000000003, -67.29999999999995, 134.09999999999943, 8.199999999999966, 120.59999999999948, 23.500000000000036, 118.59999999999991, 40.0000000000003, 40.0000000000003, 14.500000000000037, 31.100000000000165, 30.100000000000147, 152.99999999999926, 40.0000000000003, 47.700000000000244, 173.19999999999928, 40.0000000000003, 34.89999999999999, 6.5999999999999215, 154.69999999999928, 26.900000000000148, 40.0000000000003, 40.0000000000003, 22.30000000000029, 169.0999999999992, 75.89999999999986, 60.60000000000026, 35.600000000000236, 84.99999999999969, 105.69999999999986, 15.600000000000183, 27.700000000000124, -5.9999999999998845, 214.5999999999991, 91.29999999999977, 32.30000000000018, 11.099999999999989, -47.29999999999987, -19.20000000000002, 40.0000000000003, 29.00000000000013, 134.89999999999958, 22.400000000000013, 181.29999999999913, -83.90000000000009, -95.40000000000055, 41.10000000000026, 3.400000000000216, -27.19999999999979, 47.80000000000028, 40.0000000000003, 40.0000000000003, -266.4, 49.6000000000001, 24.600000000000055, 94.49999999999935, -12.899999999999842, 9.699999999999939, 72.09999999999997, 40.0000000000003, 35.600000000000236, 75.99999999999987, 1.1000000000000458, 150.29999999999941, 95.4999999999998, -50.59999999999983, 38.10000000000027, 40.9000000000003, 38.90000000000028, -128.4000000000005, 20.199999999999974, -50.499999999999794, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [74.9, 20.000000000000014, 1.0999999999999865, 20.000000000000014, -190.30000000000004, -269.5, 20.000000000000014, 45.50000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, -139.0, 20.000000000000014, -212.2, 20.000000000000014, 20.000000000000014, -5.800000000000026, -91.30000000000084, -133.60000000000002, 116.89999999999988, 58.10000000000002, 20.000000000000014, -281.2000000000001, -64.0000000000006, -280.0, 134.8999999999999, -74.50000000000071, 20.000000000000014, 20.000000000000014, -7.299999999999901, -15.699999999999754, 20.000000000000014, 64.10000000000011, -334.29999999999995, 20.000000000000014, 17.899999999999988, -8.499999999999897, 20.000000000000014, -102.40000000000056, 17.899999999999988, 18.500000000000014, 20.000000000000014, -247.0, 20.000000000000014, 118.09999999999985, 33.79999999999998, 7.69999999999996, 20.000000000000014, 20.000000000000014, 39.80000000000011, 20.000000000000014, 20.000000000000014, 7.399999999999965, 92.89999999999992, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -272.5, 20.000000000000014, 103.0999999999999, -238.60000000000022, 93.79999999999995, 79.7, 17.89999999999998, -11.499999999999826, 20.000000000000014, 155.29999999999987, -336.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -268.3000000000002, 84.80000000000001, 1.099999999999983, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 121.99999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999934, 35.90000000000012, 20.000000000000014, 153.1999999999999, 20.000000000000014, 20.000000000000014, -31.299999999999898, 3.1999999999999633, 20.000000000000014, -255.4000000000001, 152.29999999999978, -13.599999999999783, 20.000000000000014, -174.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.70000000000005, 5.299999999999965, 156.7999999999998, 20.000000000000014, 41.900000000000084, 56.00000000000017, -9.399999999999876, 11.599999999999973, 20.000000000000014, 65.00000000000011, 20.000000000000014, 85.70000000000003, 20.000000000000014, -2.799999999999883, 1.400000000000101, -7.299999999999919, 20.000000000000014, -45.09999999999981, -13.8999999999998, 92.89999999999989, 121.69999999999987, 20.000000000000014, 71.3000000000001, 5.299999999999965, 20.000000000000014, -36.69999999999978, 15.799999999999963, 20.000000000000014, -193.3, -329.19999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999917, 49.400000000000055, 75.5, -7.299999999999912, 13.699999999999964, 20.000000000000014, 161.2999999999998, -280.3, 43.400000000000134, 20.000000000000014, -300.3999999999995, 20.000000000000014, 13.099999999999966, -17.79999999999974, 3.1999999999999615, -347.19999999999993, 20.000000000000014, 20.000000000000014, 24.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -377.4999999999999, -277.9, -229.30000000000004, 53.900000000000055, 20.000000000000014, -9.399999999999862, -80.50000000000003, 20.000000000000014, 20.000000000000014, -361.9, 20.000000000000014, -319.3, 46.100000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 56.00000000000017, -255.7, -5.199999999999944, 20.000000000000014, 119.29999999999998, 54.499999999999964, 20.000000000000014, -349.5999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999794, 20.90000000000003, 20.000000000000014, 17.899999999999988, 20.000000000000014, -325.3, 17.899999999999988, 20.000000000000014, -17.79999999999974, 20.000000000000014, -341.5, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 2.0, 7.0, 170.0, 138.0, 8.0, 11.0, 0.0, 0.0, 113.0, 0.0, 1.0, 126.0, 0.0, 0.0, 35.0, 53.0, 85.0, 82.0, 3.0, 4.0, 145.0, 132.0, 159.0, 116.0, 48.0, 30.0, 11.0, 12.0, 0.0, 17.0, 131.0, 163.0, 1.0, 0.0, 14.0, 0.0, 9.0, 64.0, 2.0, 8.0, 115.0, 122.0, 2.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 65.0, 137.0, 0.0, 11.0, 23.0, 130.0, 15.0, 8.0, 0.0, 15.0, 164.0, 136.0, 0.0, 0.0, 0.0, 0.0, 79.0, 119.0, 9.0, 1.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 0.0, 39.0, 24.0, 135.0, 107.0, 0.0, 16.0, 62.0, 119.0, 0.0, 0.0, 0.0, 0.0, 114.0, 129.0, 7.0, 0.0, 0.0, 14.0, 11.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 3.0, 12.0, 47.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 11.0, 21.0, 110.0, 16.0, 147.0, 143.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 3.0, 13.0, 0.0, 0.0, 46.0, 107.0, 50.0, 135.0, 3.0, 5.0, 6.0, 12.0, 171.0, 129.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 195.0, 194.0, 103.0, 122.0, 0.0, 14.0, 70.0, 85.0, 150.0, 179.0, 144.0, 165.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 109.0, 153.0, 0.0, 11.0, 14.0, 7.0, 136.0, 143.0, 8.0, 9.0, 0.0, 0.0, 0.0, 1.0, 6.0, 173.0, 10.0, 8.0, 154.0, 117.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.819860738374739, "mean_inference_ms": 2.3077860290550123, "mean_action_processing_ms": 0.38462295658980816, "mean_env_wait_ms": 0.2988471360394092, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01479649543762207, "StateBufferConnector_ms": 0.009103894233703613, "ViewRequirementAgentConnector_ms": 0.2055734395980835}, "num_episodes": 23, "episode_return_max": 214.5999999999991, "episode_return_min": -266.4, "episode_return_mean": 38.323, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 243.68325703629432, "num_env_steps_trained_throughput_per_sec": 243.68325703629432, "timesteps_total": 456000, "num_env_steps_sampled_lifetime": 456000, "num_agent_steps_sampled_lifetime": 1824000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1824000, "timers": {"training_iteration_time_ms": 15616.906, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15616.85, "sample_time_ms": 2513.435, "learn_time_ms": 13079.386, "learn_throughput": 305.825, "synch_weights_time_ms": 18.415}, "counters": {"num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "done": false, "training_iteration": 114, "trial_id": "04dec_00002", "date": "2024-08-13_16-48-22", "timestamp": 1723582102, "time_this_iter_s": 16.57952904701233, "time_total_s": 1531.819102525711, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06e2670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1531.819102525711, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 79.78333333333335, "ram_util_percent": 86.1875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3045842438699706, "cur_kl_coeff": 3.3946707844734175e-08, "cur_lr": 0.00010000000000000003, "total_loss": 3.356765713515105, "policy_loss": -0.001586509572598275, "vf_loss": 3.358352227185769, "vf_explained_var": -4.881361804941974e-05, "kl": 0.00447525781874792, "entropy": 0.4024896839150676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 216405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.258905785881653, "cur_kl_coeff": 0.002854090745040595, "cur_lr": 0.00010000000000000003, "total_loss": 4.50343955042501, "policy_loss": -8.61676094472093e-05, "vf_loss": 4.503501159047324, "vf_explained_var": -0.06676129165780607, "kl": 0.008604425298457886, "entropy": 0.597930278128417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 216405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "env_runners": {"episode_reward_max": 221.39999999999947, "episode_reward_min": -266.4, "episode_reward_mean": 45.17199999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -377.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.2999999999998, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -14.913999999999996, "predator_policy": 37.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.50000000000005, -11.499999999999755, 48.50000000000032, 10.000000000000002, 153.89999999999944, 45.70000000000013, 59.80000000000035, 40.0000000000003, 106.29999999999964, 40.0000000000003, -67.29999999999995, 134.09999999999943, 8.199999999999966, 120.59999999999948, 23.500000000000036, 118.59999999999991, 40.0000000000003, 40.0000000000003, 14.500000000000037, 31.100000000000165, 30.100000000000147, 152.99999999999926, 40.0000000000003, 47.700000000000244, 173.19999999999928, 40.0000000000003, 34.89999999999999, 6.5999999999999215, 154.69999999999928, 26.900000000000148, 40.0000000000003, 40.0000000000003, 22.30000000000029, 169.0999999999992, 75.89999999999986, 60.60000000000026, 35.600000000000236, 84.99999999999969, 105.69999999999986, 15.600000000000183, 27.700000000000124, -5.9999999999998845, 214.5999999999991, 91.29999999999977, 32.30000000000018, 11.099999999999989, -47.29999999999987, -19.20000000000002, 40.0000000000003, 29.00000000000013, 134.89999999999958, 22.400000000000013, 181.29999999999913, -83.90000000000009, -95.40000000000055, 41.10000000000026, 3.400000000000216, -27.19999999999979, 47.80000000000028, 40.0000000000003, 40.0000000000003, -266.4, 49.6000000000001, 24.600000000000055, 94.49999999999935, -12.899999999999842, 9.699999999999939, 72.09999999999997, 40.0000000000003, 35.600000000000236, 75.99999999999987, 1.1000000000000458, 150.29999999999941, 95.4999999999998, -50.59999999999983, 38.10000000000027, 40.9000000000003, 38.90000000000028, -128.4000000000005, 20.199999999999974, -50.499999999999794, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 96.39999999999962, 20.500000000000263, 221.39999999999947, 82.49999999999964, -41.5999999999998, -42.59999999999988, 40.0000000000003, 126.89999999999961, 40.0000000000003, 112.89999999999941, 25.80000000000014, 51.70000000000048, 18.50000000000029, 96.89999999999978, 213.2999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.499999999999897, 20.000000000000014, -102.40000000000056, 17.899999999999988, 18.500000000000014, 20.000000000000014, -247.0, 20.000000000000014, 118.09999999999985, 33.79999999999998, 7.69999999999996, 20.000000000000014, 20.000000000000014, 39.80000000000011, 20.000000000000014, 20.000000000000014, 7.399999999999965, 92.89999999999992, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -272.5, 20.000000000000014, 103.0999999999999, -238.60000000000022, 93.79999999999995, 79.7, 17.89999999999998, -11.499999999999826, 20.000000000000014, 155.29999999999987, -336.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -268.3000000000002, 84.80000000000001, 1.099999999999983, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 121.99999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999934, 35.90000000000012, 20.000000000000014, 153.1999999999999, 20.000000000000014, 20.000000000000014, -31.299999999999898, 3.1999999999999633, 20.000000000000014, -255.4000000000001, 152.29999999999978, -13.599999999999783, 20.000000000000014, -174.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.70000000000005, 5.299999999999965, 156.7999999999998, 20.000000000000014, 41.900000000000084, 56.00000000000017, -9.399999999999876, 11.599999999999973, 20.000000000000014, 65.00000000000011, 20.000000000000014, 85.70000000000003, 20.000000000000014, -2.799999999999883, 1.400000000000101, -7.299999999999919, 20.000000000000014, -45.09999999999981, -13.8999999999998, 92.89999999999989, 121.69999999999987, 20.000000000000014, 71.3000000000001, 5.299999999999965, 20.000000000000014, -36.69999999999978, 15.799999999999963, 20.000000000000014, -193.3, -329.19999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999917, 49.400000000000055, 75.5, -7.299999999999912, 13.699999999999964, 20.000000000000014, 161.2999999999998, -280.3, 43.400000000000134, 20.000000000000014, -300.3999999999995, 20.000000000000014, 13.099999999999966, -17.79999999999974, 3.1999999999999615, -347.19999999999993, 20.000000000000014, 20.000000000000014, 24.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -377.4999999999999, -277.9, -229.30000000000004, 53.900000000000055, 20.000000000000014, -9.399999999999862, -80.50000000000003, 20.000000000000014, 20.000000000000014, -361.9, 20.000000000000014, -319.3, 46.100000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 56.00000000000017, -255.7, -5.199999999999944, 20.000000000000014, 119.29999999999998, 54.499999999999964, 20.000000000000014, -349.5999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999794, 20.90000000000003, 20.000000000000014, 17.899999999999988, 20.000000000000014, -325.3, 17.899999999999988, 20.000000000000014, -17.79999999999974, 20.000000000000014, -341.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 65.90000000000009, 24.500000000000053, 7.399999999999965, -220.90000000000003, 113.6, 78.80000000000004, 3.199999999999965, 71.29999999999987, 20.000000000000014, -337.6, 20.000000000000014, -262.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, -314.20000000000005, 20.000000000000014, 20.000000000000014, -4.299999999999798, 20.000000000000014, -272.5, -265.9000000000001, 111.79999999999977, 69.80000000000004, 120.4999999999999], "policy_predator_policy_reward": [14.0, 0.0, 9.0, 64.0, 2.0, 8.0, 115.0, 122.0, 2.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 65.0, 137.0, 0.0, 11.0, 23.0, 130.0, 15.0, 8.0, 0.0, 15.0, 164.0, 136.0, 0.0, 0.0, 0.0, 0.0, 79.0, 119.0, 9.0, 1.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 0.0, 39.0, 24.0, 135.0, 107.0, 0.0, 16.0, 62.0, 119.0, 0.0, 0.0, 0.0, 0.0, 114.0, 129.0, 7.0, 0.0, 0.0, 14.0, 11.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 3.0, 12.0, 47.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 11.0, 21.0, 110.0, 16.0, 147.0, 143.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 3.0, 13.0, 0.0, 0.0, 46.0, 107.0, 50.0, 135.0, 3.0, 5.0, 6.0, 12.0, 171.0, 129.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 195.0, 194.0, 103.0, 122.0, 0.0, 14.0, 70.0, 85.0, 150.0, 179.0, 144.0, 165.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 109.0, 153.0, 0.0, 11.0, 14.0, 7.0, 136.0, 143.0, 8.0, 9.0, 0.0, 0.0, 0.0, 1.0, 6.0, 173.0, 10.0, 8.0, 154.0, 117.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 111.0, 123.0, 15.0, 14.0, 6.0, 2.0, 175.0, 101.0, 138.0, 62.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 158.0, 162.0, 20.0, 16.0, 134.0, 137.0, 119.0, 132.0, 23.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.821164910921833, "mean_inference_ms": 2.3159526313738787, "mean_action_processing_ms": 0.38451823328415585, "mean_env_wait_ms": 0.2995745022679588, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012729525566101074, "StateBufferConnector_ms": 0.008311748504638672, "ViewRequirementAgentConnector_ms": 0.1664210557937622}, "num_episodes": 18, "episode_return_max": 221.39999999999947, "episode_return_min": -266.4, "episode_return_mean": 45.17199999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 256.21649934515744, "num_env_steps_trained_throughput_per_sec": 256.21649934515744, "timesteps_total": 460000, "num_env_steps_sampled_lifetime": 460000, "num_agent_steps_sampled_lifetime": 1840000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1840000, "timers": {"training_iteration_time_ms": 15657.86, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15657.804, "sample_time_ms": 2573.456, "learn_time_ms": 13057.871, "learn_throughput": 306.329, "synch_weights_time_ms": 19.635}, "counters": {"num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "done": false, "training_iteration": 115, "trial_id": "04dec_00002", "date": "2024-08-13_16-48-38", "timestamp": 1723582118, "time_this_iter_s": 15.671805143356323, "time_total_s": 1547.4909076690674, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0631430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1547.4909076690674, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 76.56818181818181, "ram_util_percent": 85.95000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2374398242938456, "cur_kl_coeff": 1.6973353922367087e-08, "cur_lr": 0.00010000000000000003, "total_loss": 2.242077926983909, "policy_loss": -0.00204703573657387, "vf_loss": 2.2441249667336702, "vf_explained_var": 0.00027769753541895953, "kl": 0.003816174267225105, "entropy": 0.3603078411685096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 218295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.447913297206636, "cur_kl_coeff": 0.002854090745040595, "cur_lr": 0.00010000000000000003, "total_loss": 4.126792541256657, "policy_loss": -0.00046130127344950637, "vf_loss": 4.127236583119347, "vf_explained_var": -0.1602628680764052, "kl": 0.006048441199376152, "entropy": 0.5789510334137256, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 218295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "env_runners": {"episode_reward_max": 221.39999999999947, "episode_reward_min": -412.6, "episode_reward_mean": 41.994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.2999999999998, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -16.42299999999999, "predator_policy": 37.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 47.700000000000244, 173.19999999999928, 40.0000000000003, 34.89999999999999, 6.5999999999999215, 154.69999999999928, 26.900000000000148, 40.0000000000003, 40.0000000000003, 22.30000000000029, 169.0999999999992, 75.89999999999986, 60.60000000000026, 35.600000000000236, 84.99999999999969, 105.69999999999986, 15.600000000000183, 27.700000000000124, -5.9999999999998845, 214.5999999999991, 91.29999999999977, 32.30000000000018, 11.099999999999989, -47.29999999999987, -19.20000000000002, 40.0000000000003, 29.00000000000013, 134.89999999999958, 22.400000000000013, 181.29999999999913, -83.90000000000009, -95.40000000000055, 41.10000000000026, 3.400000000000216, -27.19999999999979, 47.80000000000028, 40.0000000000003, 40.0000000000003, -266.4, 49.6000000000001, 24.600000000000055, 94.49999999999935, -12.899999999999842, 9.699999999999939, 72.09999999999997, 40.0000000000003, 35.600000000000236, 75.99999999999987, 1.1000000000000458, 150.29999999999941, 95.4999999999998, -50.59999999999983, 38.10000000000027, 40.9000000000003, 38.90000000000028, -128.4000000000005, 20.199999999999974, -50.499999999999794, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 96.39999999999962, 20.500000000000263, 221.39999999999947, 82.49999999999964, -41.5999999999998, -42.59999999999988, 40.0000000000003, 126.89999999999961, 40.0000000000003, 112.89999999999941, 25.80000000000014, 51.70000000000048, 18.50000000000029, 96.89999999999978, 213.2999999999997, 32.30000000000018, 38.90000000000028, 49.20000000000027, 149.2999999999993, 85.89999999999988, 37.10000000000026, 40.0000000000003, 32.30000000000018, 166.89999999999924, 89.59999999999997, 1.0000000000001716, 12.099999999999959, 127.9999999999994, 8.90000000000004, 40.0000000000003, -412.6, 40.0000000000003, 40.0000000000003, 27.500000000000032, 34.40000000000022, 32.30000000000019, 173.6999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -5.199999999999934, 35.90000000000012, 20.000000000000014, 153.1999999999999, 20.000000000000014, 20.000000000000014, -31.299999999999898, 3.1999999999999633, 20.000000000000014, -255.4000000000001, 152.29999999999978, -13.599999999999783, 20.000000000000014, -174.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.70000000000005, 5.299999999999965, 156.7999999999998, 20.000000000000014, 41.900000000000084, 56.00000000000017, -9.399999999999876, 11.599999999999973, 20.000000000000014, 65.00000000000011, 20.000000000000014, 85.70000000000003, 20.000000000000014, -2.799999999999883, 1.400000000000101, -7.299999999999919, 20.000000000000014, -45.09999999999981, -13.8999999999998, 92.89999999999989, 121.69999999999987, 20.000000000000014, 71.3000000000001, 5.299999999999965, 20.000000000000014, -36.69999999999978, 15.799999999999963, 20.000000000000014, -193.3, -329.19999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999917, 49.400000000000055, 75.5, -7.299999999999912, 13.699999999999964, 20.000000000000014, 161.2999999999998, -280.3, 43.400000000000134, 20.000000000000014, -300.3999999999995, 20.000000000000014, 13.099999999999966, -17.79999999999974, 3.1999999999999615, -347.19999999999993, 20.000000000000014, 20.000000000000014, 24.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -377.4999999999999, -277.9, -229.30000000000004, 53.900000000000055, 20.000000000000014, -9.399999999999862, -80.50000000000003, 20.000000000000014, 20.000000000000014, -361.9, 20.000000000000014, -319.3, 46.100000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 56.00000000000017, -255.7, -5.199999999999944, 20.000000000000014, 119.29999999999998, 54.499999999999964, 20.000000000000014, -349.5999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999794, 20.90000000000003, 20.000000000000014, 17.899999999999988, 20.000000000000014, -325.3, 17.899999999999988, 20.000000000000014, -17.79999999999974, 20.000000000000014, -341.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 65.90000000000009, 24.500000000000053, 7.399999999999965, -220.90000000000003, 113.6, 78.80000000000004, 3.199999999999965, 71.29999999999987, 20.000000000000014, -337.6, 20.000000000000014, -262.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, -314.20000000000005, 20.000000000000014, 20.000000000000014, -4.299999999999798, 20.000000000000014, -272.5, -265.9000000000001, 111.79999999999977, 69.80000000000004, 120.4999999999999, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 24.20000000000001, 20.000000000000014, 122.2999999999999, 20.000000000000014, 20.000000000000014, 65.90000000000008, 0.499999999999967, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 146.89999999999986, 5.299999999999978, 44.300000000000054, 20.000000000000014, -88.0000000000008, 5.299999999999967, -344.20000000000005, 118.99999999999984, -0.9999999999999952, -135.10000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, -385.6, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.70000000000005, -284.20000000000005, 7.399999999999965, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 118.09999999999977, 53.600000000000115], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 0.0, 39.0, 24.0, 135.0, 107.0, 0.0, 16.0, 62.0, 119.0, 0.0, 0.0, 0.0, 0.0, 114.0, 129.0, 7.0, 0.0, 0.0, 14.0, 11.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 3.0, 12.0, 47.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 11.0, 21.0, 110.0, 16.0, 147.0, 143.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 3.0, 13.0, 0.0, 0.0, 46.0, 107.0, 50.0, 135.0, 3.0, 5.0, 6.0, 12.0, 171.0, 129.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 195.0, 194.0, 103.0, 122.0, 0.0, 14.0, 70.0, 85.0, 150.0, 179.0, 144.0, 165.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 109.0, 153.0, 0.0, 11.0, 14.0, 7.0, 136.0, 143.0, 8.0, 9.0, 0.0, 0.0, 0.0, 1.0, 6.0, 173.0, 10.0, 8.0, 154.0, 117.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 111.0, 123.0, 15.0, 14.0, 6.0, 2.0, 175.0, 101.0, 138.0, 62.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 158.0, 162.0, 20.0, 16.0, 134.0, 137.0, 119.0, 132.0, 23.0, 0.0, 0.0, 7.0, 1.0, 0.0, 4.0, 1.0, 7.0, 0.0, 0.0, 0.0, 12.0, 13.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 34.0, 16.0, 53.0, 178.0, 173.0, 0.0, 10.0, 80.0, 44.0, 0.0, 0.0, 198.0, 172.0, 0.0, 0.0, 0.0, 0.0, 146.0, 98.0, 1.0, 6.0, 0.0, 7.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8236679868581689, "mean_inference_ms": 2.324372222740323, "mean_action_processing_ms": 0.3853152716595106, "mean_env_wait_ms": 0.3005369226337299, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013723611831665039, "StateBufferConnector_ms": 0.009676218032836914, "ViewRequirementAgentConnector_ms": 0.1774601936340332}, "num_episodes": 22, "episode_return_max": 221.39999999999947, "episode_return_min": -412.6, "episode_return_mean": 41.994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 194.79730577790608, "num_env_steps_trained_throughput_per_sec": 194.79730577790608, "timesteps_total": 464000, "num_env_steps_sampled_lifetime": 464000, "num_agent_steps_sampled_lifetime": 1856000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1856000, "timers": {"training_iteration_time_ms": 15937.99, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15937.934, "sample_time_ms": 2350.783, "learn_time_ms": 13560.159, "learn_throughput": 294.982, "synch_weights_time_ms": 20.24}, "counters": {"num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "done": false, "training_iteration": 116, "trial_id": "04dec_00002", "date": "2024-08-13_16-48-58", "timestamp": 1723582138, "time_this_iter_s": 20.6414692401886, "time_total_s": 1568.132376909256, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06310d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1568.132376909256, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 90.49310344827587, "ram_util_percent": 83.31379310344828}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0814512546455104, "cur_kl_coeff": 8.486676961183544e-09, "cur_lr": 0.00010000000000000003, "total_loss": 4.126297960457978, "policy_loss": -0.0011663683108670056, "vf_loss": 4.127464339720509, "vf_explained_var": 0.0004818273284447887, "kl": 0.00322575827135596, "entropy": 0.3264948686279317, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 220185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.637090023595189, "cur_kl_coeff": 0.002854090745040595, "cur_lr": 0.00010000000000000003, "total_loss": 4.837622275554314, "policy_loss": -0.00024393492319162876, "vf_loss": 4.837851900019974, "vf_explained_var": -0.13900436377399183, "kl": 0.005015090854794209, "entropy": 0.6307518381290335, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 220185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "env_runners": {"episode_reward_max": 221.39999999999947, "episode_reward_min": -412.6, "episode_reward_mean": 39.72599999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.89999999999995, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -24.622, "predator_policy": 44.485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.700000000000124, -5.9999999999998845, 214.5999999999991, 91.29999999999977, 32.30000000000018, 11.099999999999989, -47.29999999999987, -19.20000000000002, 40.0000000000003, 29.00000000000013, 134.89999999999958, 22.400000000000013, 181.29999999999913, -83.90000000000009, -95.40000000000055, 41.10000000000026, 3.400000000000216, -27.19999999999979, 47.80000000000028, 40.0000000000003, 40.0000000000003, -266.4, 49.6000000000001, 24.600000000000055, 94.49999999999935, -12.899999999999842, 9.699999999999939, 72.09999999999997, 40.0000000000003, 35.600000000000236, 75.99999999999987, 1.1000000000000458, 150.29999999999941, 95.4999999999998, -50.59999999999983, 38.10000000000027, 40.9000000000003, 38.90000000000028, -128.4000000000005, 20.199999999999974, -50.499999999999794, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 96.39999999999962, 20.500000000000263, 221.39999999999947, 82.49999999999964, -41.5999999999998, -42.59999999999988, 40.0000000000003, 126.89999999999961, 40.0000000000003, 112.89999999999941, 25.80000000000014, 51.70000000000048, 18.50000000000029, 96.89999999999978, 213.2999999999997, 32.30000000000018, 38.90000000000028, 49.20000000000027, 149.2999999999993, 85.89999999999988, 37.10000000000026, 40.0000000000003, 32.30000000000018, 166.89999999999924, 89.59999999999997, 1.0000000000001716, 12.099999999999959, 127.9999999999994, 8.90000000000004, 40.0000000000003, -412.6, 40.0000000000003, 40.0000000000003, 27.500000000000032, 34.40000000000022, 32.30000000000019, 173.6999999999991, -25.199999999999832, 45.700000000000024, 9.200000000000017, 193.89999999999927, 41.10000000000011, -14.999999999999773, 0.10000000000024267, 152.39999999999938, 138.59999999999988, -12.199999999999841, 98.29999999999991, 22.99999999999997, 25.70000000000007, -37.599999999999774, 90.59999999999992, 40.0000000000003, 21.7, 156.6999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-7.299999999999919, 20.000000000000014, -45.09999999999981, -13.8999999999998, 92.89999999999989, 121.69999999999987, 20.000000000000014, 71.3000000000001, 5.299999999999965, 20.000000000000014, -36.69999999999978, 15.799999999999963, 20.000000000000014, -193.3, -329.19999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999917, 49.400000000000055, 75.5, -7.299999999999912, 13.699999999999964, 20.000000000000014, 161.2999999999998, -280.3, 43.400000000000134, 20.000000000000014, -300.3999999999995, 20.000000000000014, 13.099999999999966, -17.79999999999974, 3.1999999999999615, -347.19999999999993, 20.000000000000014, 20.000000000000014, 24.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -377.4999999999999, -277.9, -229.30000000000004, 53.900000000000055, 20.000000000000014, -9.399999999999862, -80.50000000000003, 20.000000000000014, 20.000000000000014, -361.9, 20.000000000000014, -319.3, 46.100000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 56.00000000000017, -255.7, -5.199999999999944, 20.000000000000014, 119.29999999999998, 54.499999999999964, 20.000000000000014, -349.5999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999794, 20.90000000000003, 20.000000000000014, 17.899999999999988, 20.000000000000014, -325.3, 17.899999999999988, 20.000000000000014, -17.79999999999974, 20.000000000000014, -341.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 65.90000000000009, 24.500000000000053, 7.399999999999965, -220.90000000000003, 113.6, 78.80000000000004, 3.199999999999965, 71.29999999999987, 20.000000000000014, -337.6, 20.000000000000014, -262.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, -314.20000000000005, 20.000000000000014, 20.000000000000014, -4.299999999999798, 20.000000000000014, -272.5, -265.9000000000001, 111.79999999999977, 69.80000000000004, 120.4999999999999, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 24.20000000000001, 20.000000000000014, 122.2999999999999, 20.000000000000014, 20.000000000000014, 65.90000000000008, 0.499999999999967, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 146.89999999999986, 5.299999999999978, 44.300000000000054, 20.000000000000014, -88.0000000000008, 5.299999999999967, -344.20000000000005, 118.99999999999984, -0.9999999999999952, -135.10000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, -385.6, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.70000000000005, -284.20000000000005, 7.399999999999965, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 118.09999999999977, 53.600000000000115, 20.000000000000014, -146.20000000000002, 113.59999999999994, -373.9, -36.69999999999976, 17.899999999999984, 173.89999999999995, 20.000000000000014, -226.9, 20.000000000000014, -376.0, 20.000000000000014, 3.1999999999999633, -24.099999999999753, 118.39999999999995, 20.000000000000014, -318.4000000000001, 139.99999999999994, 3.1999999999999615, -225.4000000000001, 17.899999999999988, 79.40000000000005, -289.0, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, -361.6, 28.100000000000097, 48.50000000000008, 20.000000000000014, 20.000000000000014, 9.499999999999964, 3.1999999999999633, 20.000000000000014, 124.69999999999979], "policy_predator_policy_reward": [3.0, 12.0, 47.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 11.0, 21.0, 110.0, 16.0, 147.0, 143.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 3.0, 13.0, 0.0, 0.0, 46.0, 107.0, 50.0, 135.0, 3.0, 5.0, 6.0, 12.0, 171.0, 129.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 195.0, 194.0, 103.0, 122.0, 0.0, 14.0, 70.0, 85.0, 150.0, 179.0, 144.0, 165.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 109.0, 153.0, 0.0, 11.0, 14.0, 7.0, 136.0, 143.0, 8.0, 9.0, 0.0, 0.0, 0.0, 1.0, 6.0, 173.0, 10.0, 8.0, 154.0, 117.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 111.0, 123.0, 15.0, 14.0, 6.0, 2.0, 175.0, 101.0, 138.0, 62.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 158.0, 162.0, 20.0, 16.0, 134.0, 137.0, 119.0, 132.0, 23.0, 0.0, 0.0, 7.0, 1.0, 0.0, 4.0, 1.0, 7.0, 0.0, 0.0, 0.0, 12.0, 13.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 34.0, 16.0, 53.0, 178.0, 173.0, 0.0, 10.0, 80.0, 44.0, 0.0, 0.0, 198.0, 172.0, 0.0, 0.0, 0.0, 0.0, 146.0, 98.0, 1.0, 6.0, 0.0, 7.0, 0.0, 2.0, 0.0, 101.0, 165.0, 141.0, 0.0, 28.0, 0.0, 0.0, 137.0, 111.0, 151.0, 190.0, 21.0, 0.0, 14.0, 0.0, 139.0, 178.0, 132.0, 78.0, 1.0, 0.0, 157.0, 135.0, 13.0, 0.0, 121.0, 183.0, 14.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8260666821193843, "mean_inference_ms": 2.3355599983366075, "mean_action_processing_ms": 0.385899740389908, "mean_env_wait_ms": 0.30154122455005267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013698458671569824, "StateBufferConnector_ms": 0.0061380863189697266, "ViewRequirementAgentConnector_ms": 0.18250465393066406}, "num_episodes": 18, "episode_return_max": 221.39999999999947, "episode_return_min": -412.6, "episode_return_mean": 39.72599999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 274.5223051041903, "num_env_steps_trained_throughput_per_sec": 274.5223051041903, "timesteps_total": 468000, "num_env_steps_sampled_lifetime": 468000, "num_agent_steps_sampled_lifetime": 1872000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1872000, "timers": {"training_iteration_time_ms": 15902.285, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15902.23, "sample_time_ms": 2406.991, "learn_time_ms": 13468.292, "learn_throughput": 296.994, "synch_weights_time_ms": 20.176}, "counters": {"num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "done": false, "training_iteration": 117, "trial_id": "04dec_00002", "date": "2024-08-13_16-49-13", "timestamp": 1723582153, "time_this_iter_s": 14.62216305732727, "time_total_s": 1582.7545399665833, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04ccaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1582.7545399665833, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 76.73500000000001, "ram_util_percent": 83.59500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.223750513539743, "cur_kl_coeff": 4.243338480591772e-09, "cur_lr": 0.00010000000000000003, "total_loss": 3.9031709329161064, "policy_loss": -0.0012695886409057984, "vf_loss": 3.9044405239599724, "vf_explained_var": 0.0001316846047759687, "kl": 0.0028065209357490462, "entropy": 0.35551098928880437, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 222075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.332866616160782, "cur_kl_coeff": 0.002854090745040595, "cur_lr": 0.00010000000000000003, "total_loss": 4.3973394832913835, "policy_loss": 0.0006200333364879486, "vf_loss": 4.396675034679433, "vf_explained_var": -0.11166977611168352, "kl": 0.015563546524556151, "entropy": 0.5484783346533144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 222075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "env_runners": {"episode_reward_max": 221.39999999999947, "episode_reward_min": -412.6, "episode_reward_mean": 44.01399999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.89999999999995, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -26.923000000000012, "predator_policy": 48.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.80000000000028, 40.0000000000003, 40.0000000000003, -266.4, 49.6000000000001, 24.600000000000055, 94.49999999999935, -12.899999999999842, 9.699999999999939, 72.09999999999997, 40.0000000000003, 35.600000000000236, 75.99999999999987, 1.1000000000000458, 150.29999999999941, 95.4999999999998, -50.59999999999983, 38.10000000000027, 40.9000000000003, 38.90000000000028, -128.4000000000005, 20.199999999999974, -50.499999999999794, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 96.39999999999962, 20.500000000000263, 221.39999999999947, 82.49999999999964, -41.5999999999998, -42.59999999999988, 40.0000000000003, 126.89999999999961, 40.0000000000003, 112.89999999999941, 25.80000000000014, 51.70000000000048, 18.50000000000029, 96.89999999999978, 213.2999999999997, 32.30000000000018, 38.90000000000028, 49.20000000000027, 149.2999999999993, 85.89999999999988, 37.10000000000026, 40.0000000000003, 32.30000000000018, 166.89999999999924, 89.59999999999997, 1.0000000000001716, 12.099999999999959, 127.9999999999994, 8.90000000000004, 40.0000000000003, -412.6, 40.0000000000003, 40.0000000000003, 27.500000000000032, 34.40000000000022, 32.30000000000019, 173.6999999999991, -25.199999999999832, 45.700000000000024, 9.200000000000017, 193.89999999999927, 41.10000000000011, -14.999999999999773, 0.10000000000024267, 152.39999999999938, 138.59999999999988, -12.199999999999841, 98.29999999999991, 22.99999999999997, 25.70000000000007, -37.599999999999774, 90.59999999999992, 40.0000000000003, 21.7, 156.6999999999992, -7.200000000000019, 55.30000000000007, 9.19999999999997, 13.699999999999962, 177.6999999999992, 40.0000000000003, 71.30000000000001, -71.40000000000046, 109.29999999999954, -23.59999999999976, 192.99999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 126.29999999999951, 94.79999999999964, -23.699999999999662, 94.19999999999966], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 24.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -377.4999999999999, -277.9, -229.30000000000004, 53.900000000000055, 20.000000000000014, -9.399999999999862, -80.50000000000003, 20.000000000000014, 20.000000000000014, -361.9, 20.000000000000014, -319.3, 46.100000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 56.00000000000017, -255.7, -5.199999999999944, 20.000000000000014, 119.29999999999998, 54.499999999999964, 20.000000000000014, -349.5999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999794, 20.90000000000003, 20.000000000000014, 17.899999999999988, 20.000000000000014, -325.3, 17.899999999999988, 20.000000000000014, -17.79999999999974, 20.000000000000014, -341.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 65.90000000000009, 24.500000000000053, 7.399999999999965, -220.90000000000003, 113.6, 78.80000000000004, 3.199999999999965, 71.29999999999987, 20.000000000000014, -337.6, 20.000000000000014, -262.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, -314.20000000000005, 20.000000000000014, 20.000000000000014, -4.299999999999798, 20.000000000000014, -272.5, -265.9000000000001, 111.79999999999977, 69.80000000000004, 120.4999999999999, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 24.20000000000001, 20.000000000000014, 122.2999999999999, 20.000000000000014, 20.000000000000014, 65.90000000000008, 0.499999999999967, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 146.89999999999986, 5.299999999999978, 44.300000000000054, 20.000000000000014, -88.0000000000008, 5.299999999999967, -344.20000000000005, 118.99999999999984, -0.9999999999999952, -135.10000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, -385.6, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.70000000000005, -284.20000000000005, 7.399999999999965, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 118.09999999999977, 53.600000000000115, 20.000000000000014, -146.20000000000002, 113.59999999999994, -373.9, -36.69999999999976, 17.899999999999984, 173.89999999999995, 20.000000000000014, -226.9, 20.000000000000014, -376.0, 20.000000000000014, 3.1999999999999633, -24.099999999999753, 118.39999999999995, 20.000000000000014, -318.4000000000001, 139.99999999999994, 3.1999999999999615, -225.4000000000001, 17.899999999999988, 79.40000000000005, -289.0, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, -361.6, 28.100000000000097, 48.50000000000008, 20.000000000000014, 20.000000000000014, 9.499999999999964, 3.1999999999999633, 20.000000000000014, 124.69999999999979, 15.799999999999963, -361.0, -108.69999999999999, 20.000000000000014, 20.000000000000014, -356.79999999999995, -49.299999999999834, 20.000000000000014, 20.000000000000014, 157.69999999999987, 20.000000000000014, 20.000000000000014, 92.89999999999992, -364.6, 20.000000000000014, -351.4, 89.29999999999984, 20.000000000000014, -351.4, -5.1999999999999265, 20.000000000000014, 172.99999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -157.90000000000046, 141.19999999999987, 90.19999999999985, -9.399999999999855, 20.000000000000014, -120.70000000000059, 20.000000000000014, 3.20000000000005], "policy_predator_policy_reward": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 195.0, 194.0, 103.0, 122.0, 0.0, 14.0, 70.0, 85.0, 150.0, 179.0, 144.0, 165.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 109.0, 153.0, 0.0, 11.0, 14.0, 7.0, 136.0, 143.0, 8.0, 9.0, 0.0, 0.0, 0.0, 1.0, 6.0, 173.0, 10.0, 8.0, 154.0, 117.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 111.0, 123.0, 15.0, 14.0, 6.0, 2.0, 175.0, 101.0, 138.0, 62.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 158.0, 162.0, 20.0, 16.0, 134.0, 137.0, 119.0, 132.0, 23.0, 0.0, 0.0, 7.0, 1.0, 0.0, 4.0, 1.0, 7.0, 0.0, 0.0, 0.0, 12.0, 13.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 34.0, 16.0, 53.0, 178.0, 173.0, 0.0, 10.0, 80.0, 44.0, 0.0, 0.0, 198.0, 172.0, 0.0, 0.0, 0.0, 0.0, 146.0, 98.0, 1.0, 6.0, 0.0, 7.0, 0.0, 2.0, 0.0, 101.0, 165.0, 141.0, 0.0, 28.0, 0.0, 0.0, 137.0, 111.0, 151.0, 190.0, 21.0, 0.0, 14.0, 0.0, 139.0, 178.0, 132.0, 78.0, 1.0, 0.0, 157.0, 135.0, 13.0, 0.0, 121.0, 183.0, 14.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 4.0, 183.0, 155.0, 61.0, 83.0, 174.0, 172.0, 32.0, 11.0, 0.0, 0.0, 0.0, 0.0, 171.0, 172.0, 181.0, 79.0, 0.0, 0.0, 193.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 89.0, 54.0, 14.0, 0.0, 10.0, 67.0, 33.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8284304696347979, "mean_inference_ms": 2.344566579498042, "mean_action_processing_ms": 0.38652673743922333, "mean_env_wait_ms": 0.3024464145443766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009970545768737793, "StateBufferConnector_ms": 0.006082773208618164, "ViewRequirementAgentConnector_ms": 0.17033064365386963}, "num_episodes": 18, "episode_return_max": 221.39999999999947, "episode_return_min": -412.6, "episode_return_mean": 44.01399999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.3934397926755, "num_env_steps_trained_throughput_per_sec": 317.3934397926755, "timesteps_total": 472000, "num_env_steps_sampled_lifetime": 472000, "num_agent_steps_sampled_lifetime": 1888000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1888000, "timers": {"training_iteration_time_ms": 15546.767, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15546.714, "sample_time_ms": 2375.816, "learn_time_ms": 13144.21, "learn_throughput": 304.316, "synch_weights_time_ms": 20.166}, "counters": {"num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "done": false, "training_iteration": 118, "trial_id": "04dec_00002", "date": "2024-08-13_16-49-26", "timestamp": 1723582166, "time_this_iter_s": 12.644263982772827, "time_total_s": 1595.398803949356, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1595.398803949356, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 67.03888888888889, "ram_util_percent": 83.7888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1925634642993963, "cur_kl_coeff": 2.121669240295886e-09, "cur_lr": 0.00010000000000000003, "total_loss": 3.751895453690221, "policy_loss": -0.0007768076829730518, "vf_loss": 3.752672263175722, "vf_explained_var": 0.00017519621621994746, "kl": 0.0036296675237237996, "entropy": 0.36640847888257766, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 223965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.049974618639265, "cur_kl_coeff": 0.002854090745040595, "cur_lr": 0.00010000000000000003, "total_loss": 3.882657405812904, "policy_loss": -6.556834079443462e-05, "vf_loss": 3.882701499247677, "vf_explained_var": -0.03898860941488276, "kl": 0.007524251132756704, "entropy": 0.5679640734479541, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 223965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "env_runners": {"episode_reward_max": 249.19999999999908, "episode_reward_min": -412.6, "episode_reward_mean": 53.01899999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -20.24050000000002, "predator_policy": 46.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 96.39999999999962, 20.500000000000263, 221.39999999999947, 82.49999999999964, -41.5999999999998, -42.59999999999988, 40.0000000000003, 126.89999999999961, 40.0000000000003, 112.89999999999941, 25.80000000000014, 51.70000000000048, 18.50000000000029, 96.89999999999978, 213.2999999999997, 32.30000000000018, 38.90000000000028, 49.20000000000027, 149.2999999999993, 85.89999999999988, 37.10000000000026, 40.0000000000003, 32.30000000000018, 166.89999999999924, 89.59999999999997, 1.0000000000001716, 12.099999999999959, 127.9999999999994, 8.90000000000004, 40.0000000000003, -412.6, 40.0000000000003, 40.0000000000003, 27.500000000000032, 34.40000000000022, 32.30000000000019, 173.6999999999991, -25.199999999999832, 45.700000000000024, 9.200000000000017, 193.89999999999927, 41.10000000000011, -14.999999999999773, 0.10000000000024267, 152.39999999999938, 138.59999999999988, -12.199999999999841, 98.29999999999991, 22.99999999999997, 25.70000000000007, -37.599999999999774, 90.59999999999992, 40.0000000000003, 21.7, 156.6999999999992, -7.200000000000019, 55.30000000000007, 9.19999999999997, 13.699999999999962, 177.6999999999992, 40.0000000000003, 71.30000000000001, -71.40000000000046, 109.29999999999954, -23.59999999999976, 192.99999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 126.29999999999951, 94.79999999999964, -23.699999999999662, 94.19999999999966, -56.09999999999976, 60.9000000000002, 90.1999999999993, 37.80000000000027, 175.39999999999927, 80.09999999999948, 107.49999999999956, 40.0000000000003, -215.90000000000006, -114.70000000000107, 249.19999999999908, 212.2999999999993, 8.000000000000044, -4.000000000000064, 28.600000000000133, 219.99999999999926, 84.49999999999963, 38.90000000000028, 40.0000000000003, 1.4999999999999787, 142.39999999999924, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 65.90000000000009, 24.500000000000053, 7.399999999999965, -220.90000000000003, 113.6, 78.80000000000004, 3.199999999999965, 71.29999999999987, 20.000000000000014, -337.6, 20.000000000000014, -262.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999995, -314.20000000000005, 20.000000000000014, 20.000000000000014, -4.299999999999798, 20.000000000000014, -272.5, -265.9000000000001, 111.79999999999977, 69.80000000000004, 120.4999999999999, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 24.20000000000001, 20.000000000000014, 122.2999999999999, 20.000000000000014, 20.000000000000014, 65.90000000000008, 0.499999999999967, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 146.89999999999986, 5.299999999999978, 44.300000000000054, 20.000000000000014, -88.0000000000008, 5.299999999999967, -344.20000000000005, 118.99999999999984, -0.9999999999999952, -135.10000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, -385.6, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.70000000000005, -284.20000000000005, 7.399999999999965, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 118.09999999999977, 53.600000000000115, 20.000000000000014, -146.20000000000002, 113.59999999999994, -373.9, -36.69999999999976, 17.899999999999984, 173.89999999999995, 20.000000000000014, -226.9, 20.000000000000014, -376.0, 20.000000000000014, 3.1999999999999633, -24.099999999999753, 118.39999999999995, 20.000000000000014, -318.4000000000001, 139.99999999999994, 3.1999999999999615, -225.4000000000001, 17.899999999999988, 79.40000000000005, -289.0, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, -361.6, 28.100000000000097, 48.50000000000008, 20.000000000000014, 20.000000000000014, 9.499999999999964, 3.1999999999999633, 20.000000000000014, 124.69999999999979, 15.799999999999963, -361.0, -108.69999999999999, 20.000000000000014, 20.000000000000014, -356.79999999999995, -49.299999999999834, 20.000000000000014, 20.000000000000014, 157.69999999999987, 20.000000000000014, 20.000000000000014, 92.89999999999992, -364.6, 20.000000000000014, -351.4, 89.29999999999984, 20.000000000000014, -351.4, -5.1999999999999265, 20.000000000000014, 172.99999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -157.90000000000046, 141.19999999999987, 90.19999999999985, -9.399999999999855, 20.000000000000014, -120.70000000000059, 20.000000000000014, 3.20000000000005, 20.000000000000014, -336.0999999999999, 20.000000000000014, -12.10000000000003, 72.20000000000002, -1.0000000000000204, 20.000000000000014, 15.799999999999963, 20.000000000000014, 145.3999999999999, 66.80000000000001, 5.299999999999965, 83.89999999999998, -33.39999999999981, 20.000000000000014, 20.000000000000014, -309.1, -263.8, -254.50000000000028, -74.20000000000084, 200.0, 45.20000000000023, 5.299999999999965, 200.0, -313.9, 26.90000000000008, -395.8, 15.799999999999963, 11.299999999999974, 5.299999999999965, 200.0, 20.000000000000014, 11.599999999999964, -45.09999999999995, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -266.20000000000005, 13.699999999999964, 5.299999999999965, 127.09999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 111.0, 123.0, 15.0, 14.0, 6.0, 2.0, 175.0, 101.0, 138.0, 62.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 158.0, 162.0, 20.0, 16.0, 134.0, 137.0, 119.0, 132.0, 23.0, 0.0, 0.0, 7.0, 1.0, 0.0, 4.0, 1.0, 7.0, 0.0, 0.0, 0.0, 12.0, 13.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 34.0, 16.0, 53.0, 178.0, 173.0, 0.0, 10.0, 80.0, 44.0, 0.0, 0.0, 198.0, 172.0, 0.0, 0.0, 0.0, 0.0, 146.0, 98.0, 1.0, 6.0, 0.0, 7.0, 0.0, 2.0, 0.0, 101.0, 165.0, 141.0, 0.0, 28.0, 0.0, 0.0, 137.0, 111.0, 151.0, 190.0, 21.0, 0.0, 14.0, 0.0, 139.0, 178.0, 132.0, 78.0, 1.0, 0.0, 157.0, 135.0, 13.0, 0.0, 121.0, 183.0, 14.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 4.0, 183.0, 155.0, 61.0, 83.0, 174.0, 172.0, 32.0, 11.0, 0.0, 0.0, 0.0, 0.0, 171.0, 172.0, 181.0, 79.0, 0.0, 0.0, 193.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 89.0, 54.0, 14.0, 0.0, 10.0, 67.0, 33.0, 38.0, 89.0, 171.0, 30.0, 23.0, 10.0, 9.0, 2.0, 0.0, 4.0, 6.0, 5.0, 3.0, 37.0, 20.0, 0.0, 0.0, 177.0, 180.0, 79.0, 135.0, 3.0, 1.0, 0.0, 7.0, 159.0, 136.0, 178.0, 198.0, 5.0, 7.0, 0.0, 0.0, 60.0, 58.0, 1.0, 0.0, 0.0, 0.0, 101.0, 153.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8306544047437063, "mean_inference_ms": 2.3538986658057808, "mean_action_processing_ms": 0.387049082255904, "mean_env_wait_ms": 0.30329508145841216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009212493896484375, "StateBufferConnector_ms": 0.005795717239379883, "ViewRequirementAgentConnector_ms": 0.18558061122894287}, "num_episodes": 23, "episode_return_max": 249.19999999999908, "episode_return_min": -412.6, "episode_return_mean": 53.01899999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.12771974363324, "num_env_steps_trained_throughput_per_sec": 304.12771974363324, "timesteps_total": 476000, "num_env_steps_sampled_lifetime": 476000, "num_agent_steps_sampled_lifetime": 1904000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1904000, "timers": {"training_iteration_time_ms": 15334.72, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15334.667, "sample_time_ms": 2355.745, "learn_time_ms": 12952.237, "learn_throughput": 308.827, "synch_weights_time_ms": 19.824}, "counters": {"num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "done": false, "training_iteration": 119, "trial_id": "04dec_00002", "date": "2024-08-13_16-49-39", "timestamp": 1723582179, "time_this_iter_s": 13.203108072280884, "time_total_s": 1608.601912021637, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0728a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1608.601912021637, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 67.21052631578948, "ram_util_percent": 83.74736842105264}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2762002583849368, "cur_kl_coeff": 1.060834620147943e-09, "cur_lr": 0.00010000000000000003, "total_loss": 3.7873983709900467, "policy_loss": -0.001361925519815592, "vf_loss": 3.788760292088544, "vf_explained_var": 0.0001307999330853659, "kl": 0.003403645085124659, "entropy": 0.35293241764502553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 225855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.151070936016305, "cur_kl_coeff": 0.002854090745040595, "cur_lr": 0.00010000000000000003, "total_loss": 3.497234782655403, "policy_loss": 0.00024792053490364676, "vf_loss": 3.4969733923831314, "vf_explained_var": -0.039892321793490615, "kl": 0.004722645714585608, "entropy": 0.4534477219852821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 225855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "env_runners": {"episode_reward_max": 249.19999999999908, "episode_reward_min": -412.6, "episode_reward_mean": 46.786999999999914, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -25.736500000000024, "predator_policy": 49.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [149.2999999999993, 85.89999999999988, 37.10000000000026, 40.0000000000003, 32.30000000000018, 166.89999999999924, 89.59999999999997, 1.0000000000001716, 12.099999999999959, 127.9999999999994, 8.90000000000004, 40.0000000000003, -412.6, 40.0000000000003, 40.0000000000003, 27.500000000000032, 34.40000000000022, 32.30000000000019, 173.6999999999991, -25.199999999999832, 45.700000000000024, 9.200000000000017, 193.89999999999927, 41.10000000000011, -14.999999999999773, 0.10000000000024267, 152.39999999999938, 138.59999999999988, -12.199999999999841, 98.29999999999991, 22.99999999999997, 25.70000000000007, -37.599999999999774, 90.59999999999992, 40.0000000000003, 21.7, 156.6999999999992, -7.200000000000019, 55.30000000000007, 9.19999999999997, 13.699999999999962, 177.6999999999992, 40.0000000000003, 71.30000000000001, -71.40000000000046, 109.29999999999954, -23.59999999999976, 192.99999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 126.29999999999951, 94.79999999999964, -23.699999999999662, 94.19999999999966, -56.09999999999976, 60.9000000000002, 90.1999999999993, 37.80000000000027, 175.39999999999927, 80.09999999999948, 107.49999999999956, 40.0000000000003, -215.90000000000006, -114.70000000000107, 249.19999999999908, 212.2999999999993, 8.000000000000044, -4.000000000000064, 28.600000000000133, 219.99999999999926, 84.49999999999963, 38.90000000000028, 40.0000000000003, 1.4999999999999787, 142.39999999999924, 40.0000000000003, 40.0000000000003, 77.9999999999998, 140.79999999999907, 58.40000000000026, 60.799999999999464, -190.70000000000024, 40.0000000000003, 185.99999999999943, 40.0000000000003, 117.6999999999995, -5.200000000000005, 40.0000000000003, 40.0000000000003, 92.19999999999938, -13.499999999999945, -50.5999999999998, 40.0000000000003, -9.400000000000007, 40.0000000000003, 50.80000000000028, 35.600000000000236, -64.39999999999984, -6.699999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [122.2999999999999, 20.000000000000014, 20.000000000000014, 65.90000000000008, 0.499999999999967, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 146.89999999999986, 5.299999999999978, 44.300000000000054, 20.000000000000014, -88.0000000000008, 5.299999999999967, -344.20000000000005, 118.99999999999984, -0.9999999999999952, -135.10000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, -385.6, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.70000000000005, -284.20000000000005, 7.399999999999965, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 118.09999999999977, 53.600000000000115, 20.000000000000014, -146.20000000000002, 113.59999999999994, -373.9, -36.69999999999976, 17.899999999999984, 173.89999999999995, 20.000000000000014, -226.9, 20.000000000000014, -376.0, 20.000000000000014, 3.1999999999999633, -24.099999999999753, 118.39999999999995, 20.000000000000014, -318.4000000000001, 139.99999999999994, 3.1999999999999615, -225.4000000000001, 17.899999999999988, 79.40000000000005, -289.0, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, -361.6, 28.100000000000097, 48.50000000000008, 20.000000000000014, 20.000000000000014, 9.499999999999964, 3.1999999999999633, 20.000000000000014, 124.69999999999979, 15.799999999999963, -361.0, -108.69999999999999, 20.000000000000014, 20.000000000000014, -356.79999999999995, -49.299999999999834, 20.000000000000014, 20.000000000000014, 157.69999999999987, 20.000000000000014, 20.000000000000014, 92.89999999999992, -364.6, 20.000000000000014, -351.4, 89.29999999999984, 20.000000000000014, -351.4, -5.1999999999999265, 20.000000000000014, 172.99999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -157.90000000000046, 141.19999999999987, 90.19999999999985, -9.399999999999855, 20.000000000000014, -120.70000000000059, 20.000000000000014, 3.20000000000005, 20.000000000000014, -336.0999999999999, 20.000000000000014, -12.10000000000003, 72.20000000000002, -1.0000000000000204, 20.000000000000014, 15.799999999999963, 20.000000000000014, 145.3999999999999, 66.80000000000001, 5.299999999999965, 83.89999999999998, -33.39999999999981, 20.000000000000014, 20.000000000000014, -309.1, -263.8, -254.50000000000028, -74.20000000000084, 200.0, 45.20000000000023, 5.299999999999965, 200.0, -313.9, 26.90000000000008, -395.8, 15.799999999999963, 11.299999999999974, 5.299999999999965, 200.0, 20.000000000000014, 11.599999999999964, -45.09999999999995, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -266.20000000000005, 13.699999999999964, 5.299999999999965, 127.09999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.000000000000014, 20.000000000000014, 120.7999999999997, -262.9000000000001, 53.30000000000023, 20.000000000000014, -35.2, -200.5000000000002, -290.20000000000005, 20.000000000000014, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 85.70000000000003, 20.000000000000014, -302.1999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.1999999999999, 20.000000000000014, 9.499999999999964, -208.00000000000037, 20.000000000000014, -268.6000000000001, 20.000000000000014, 20.000000000000014, -321.3999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.80000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999964, -17.79999999999974, -292.59999999999997, 11.599999999999964, -214.30000000000013], "policy_predator_policy_reward": [7.0, 0.0, 0.0, 0.0, 12.0, 13.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 34.0, 16.0, 53.0, 178.0, 173.0, 0.0, 10.0, 80.0, 44.0, 0.0, 0.0, 198.0, 172.0, 0.0, 0.0, 0.0, 0.0, 146.0, 98.0, 1.0, 6.0, 0.0, 7.0, 0.0, 2.0, 0.0, 101.0, 165.0, 141.0, 0.0, 28.0, 0.0, 0.0, 137.0, 111.0, 151.0, 190.0, 21.0, 0.0, 14.0, 0.0, 139.0, 178.0, 132.0, 78.0, 1.0, 0.0, 157.0, 135.0, 13.0, 0.0, 121.0, 183.0, 14.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 4.0, 183.0, 155.0, 61.0, 83.0, 174.0, 172.0, 32.0, 11.0, 0.0, 0.0, 0.0, 0.0, 171.0, 172.0, 181.0, 79.0, 0.0, 0.0, 193.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 89.0, 54.0, 14.0, 0.0, 10.0, 67.0, 33.0, 38.0, 89.0, 171.0, 30.0, 23.0, 10.0, 9.0, 2.0, 0.0, 4.0, 6.0, 5.0, 3.0, 37.0, 20.0, 0.0, 0.0, 177.0, 180.0, 79.0, 135.0, 3.0, 1.0, 0.0, 7.0, 159.0, 136.0, 178.0, 198.0, 5.0, 7.0, 0.0, 0.0, 60.0, 58.0, 1.0, 0.0, 0.0, 0.0, 101.0, 153.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 50.0, 42.0, 0.0, 0.0, 143.0, 125.0, 58.0, 18.0, 133.0, 167.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 12.0, 150.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 81.0, 110.0, 88.0, 0.0, 0.0, 160.0, 132.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 125.0, 121.0, 86.0, 110.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8320300407908721, "mean_inference_ms": 2.3578618000353724, "mean_action_processing_ms": 0.38705242176183546, "mean_env_wait_ms": 0.3037150949195292, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01108241081237793, "StateBufferConnector_ms": 0.005771517753601074, "ViewRequirementAgentConnector_ms": 0.18788933753967285}, "num_episodes": 22, "episode_return_max": 249.19999999999908, "episode_return_min": -412.6, "episode_return_mean": 46.786999999999914, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 313.4909935236364, "num_env_steps_trained_throughput_per_sec": 313.4909935236364, "timesteps_total": 480000, "num_env_steps_sampled_lifetime": 480000, "num_agent_steps_sampled_lifetime": 1920000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1920000, "timers": {"training_iteration_time_ms": 15075.276, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15075.224, "sample_time_ms": 2316.605, "learn_time_ms": 12732.218, "learn_throughput": 314.164, "synch_weights_time_ms": 19.418}, "counters": {"num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "done": false, "training_iteration": 120, "trial_id": "04dec_00002", "date": "2024-08-13_16-49-52", "timestamp": 1723582192, "time_this_iter_s": 12.813006162643433, "time_total_s": 1621.4149181842804, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b02bc430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1621.4149181842804, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 68.25000000000001, "ram_util_percent": 83.79444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1532340713160694, "cur_kl_coeff": 5.304173100739715e-10, "cur_lr": 0.00010000000000000003, "total_loss": 2.2019236306664807, "policy_loss": -0.0013654630291201765, "vf_loss": 2.203289092533172, "vf_explained_var": 0.000702880961554391, "kl": 0.0035394120628228195, "entropy": 0.3440682514003976, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 227745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.328895453241452, "cur_kl_coeff": 0.0014270453725202974, "cur_lr": 0.00010000000000000003, "total_loss": 2.8702051347525663, "policy_loss": -0.0031602093487948417, "vf_loss": 2.8733542302928905, "vf_explained_var": -0.029525690230112228, "kl": 0.007785307337180841, "entropy": 0.40193701563058076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 227745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "env_runners": {"episode_reward_max": 249.19999999999908, "episode_reward_min": -215.90000000000006, "episode_reward_mean": 54.67499999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -21.18250000000002, "predator_policy": 48.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [173.6999999999991, -25.199999999999832, 45.700000000000024, 9.200000000000017, 193.89999999999927, 41.10000000000011, -14.999999999999773, 0.10000000000024267, 152.39999999999938, 138.59999999999988, -12.199999999999841, 98.29999999999991, 22.99999999999997, 25.70000000000007, -37.599999999999774, 90.59999999999992, 40.0000000000003, 21.7, 156.6999999999992, -7.200000000000019, 55.30000000000007, 9.19999999999997, 13.699999999999962, 177.6999999999992, 40.0000000000003, 71.30000000000001, -71.40000000000046, 109.29999999999954, -23.59999999999976, 192.99999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 126.29999999999951, 94.79999999999964, -23.699999999999662, 94.19999999999966, -56.09999999999976, 60.9000000000002, 90.1999999999993, 37.80000000000027, 175.39999999999927, 80.09999999999948, 107.49999999999956, 40.0000000000003, -215.90000000000006, -114.70000000000107, 249.19999999999908, 212.2999999999993, 8.000000000000044, -4.000000000000064, 28.600000000000133, 219.99999999999926, 84.49999999999963, 38.90000000000028, 40.0000000000003, 1.4999999999999787, 142.39999999999924, 40.0000000000003, 40.0000000000003, 77.9999999999998, 140.79999999999907, 58.40000000000026, 60.799999999999464, -190.70000000000024, 40.0000000000003, 185.99999999999943, 40.0000000000003, 117.6999999999995, -5.200000000000005, 40.0000000000003, 40.0000000000003, 92.19999999999938, -13.499999999999945, -50.5999999999998, 40.0000000000003, -9.400000000000007, 40.0000000000003, 50.80000000000028, 35.600000000000236, -64.39999999999984, -6.699999999999974, -74.7000000000003, 99.09999999999943, 40.0000000000003, -12.799999999999594, 211.1999999999993, 205.99999999999932, 51.900000000000134, 219.99999999999926, 31.200000000000177, 40.0000000000003, -1.1999999999999669, 219.99999999999926, 168.2999999999995, 2.2999999999999963, 24.600000000000065, 35.600000000000236, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [118.09999999999977, 53.600000000000115, 20.000000000000014, -146.20000000000002, 113.59999999999994, -373.9, -36.69999999999976, 17.899999999999984, 173.89999999999995, 20.000000000000014, -226.9, 20.000000000000014, -376.0, 20.000000000000014, 3.1999999999999633, -24.099999999999753, 118.39999999999995, 20.000000000000014, -318.4000000000001, 139.99999999999994, 3.1999999999999615, -225.4000000000001, 17.899999999999988, 79.40000000000005, -289.0, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, -361.6, 28.100000000000097, 48.50000000000008, 20.000000000000014, 20.000000000000014, 9.499999999999964, 3.1999999999999633, 20.000000000000014, 124.69999999999979, 15.799999999999963, -361.0, -108.69999999999999, 20.000000000000014, 20.000000000000014, -356.79999999999995, -49.299999999999834, 20.000000000000014, 20.000000000000014, 157.69999999999987, 20.000000000000014, 20.000000000000014, 92.89999999999992, -364.6, 20.000000000000014, -351.4, 89.29999999999984, 20.000000000000014, -351.4, -5.1999999999999265, 20.000000000000014, 172.99999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -157.90000000000046, 141.19999999999987, 90.19999999999985, -9.399999999999855, 20.000000000000014, -120.70000000000059, 20.000000000000014, 3.20000000000005, 20.000000000000014, -336.0999999999999, 20.000000000000014, -12.10000000000003, 72.20000000000002, -1.0000000000000204, 20.000000000000014, 15.799999999999963, 20.000000000000014, 145.3999999999999, 66.80000000000001, 5.299999999999965, 83.89999999999998, -33.39999999999981, 20.000000000000014, 20.000000000000014, -309.1, -263.8, -254.50000000000028, -74.20000000000084, 200.0, 45.20000000000023, 5.299999999999965, 200.0, -313.9, 26.90000000000008, -395.8, 15.799999999999963, 11.299999999999974, 5.299999999999965, 200.0, 20.000000000000014, 11.599999999999964, -45.09999999999995, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -266.20000000000005, 13.699999999999964, 5.299999999999965, 127.09999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.000000000000014, 20.000000000000014, 120.7999999999997, -262.9000000000001, 53.30000000000023, 20.000000000000014, -35.2, -200.5000000000002, -290.20000000000005, 20.000000000000014, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 85.70000000000003, 20.000000000000014, -302.1999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.1999999999999, 20.000000000000014, 9.499999999999964, -208.00000000000037, 20.000000000000014, -268.6000000000001, 20.000000000000014, 20.000000000000014, -321.3999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.80000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999964, -17.79999999999974, -292.59999999999997, 11.599999999999964, -214.30000000000013, -13.599999999999811, -336.1, 85.69999999999987, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.80000000000085, 200.0, 3.1999999999999615, 179.0, 20.000000000000014, 20.000000000000014, -150.1, 200.0, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -221.20000000000016, 200.0, 20.000000000000014, 5.299999999999978, 128.0, -369.69999999999993, 20.000000000000014, -9.39999999999988, 20.000000000000014, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 2.0, 0.0, 101.0, 165.0, 141.0, 0.0, 28.0, 0.0, 0.0, 137.0, 111.0, 151.0, 190.0, 21.0, 0.0, 14.0, 0.0, 139.0, 178.0, 132.0, 78.0, 1.0, 0.0, 157.0, 135.0, 13.0, 0.0, 121.0, 183.0, 14.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 4.0, 183.0, 155.0, 61.0, 83.0, 174.0, 172.0, 32.0, 11.0, 0.0, 0.0, 0.0, 0.0, 171.0, 172.0, 181.0, 79.0, 0.0, 0.0, 193.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 89.0, 54.0, 14.0, 0.0, 10.0, 67.0, 33.0, 38.0, 89.0, 171.0, 30.0, 23.0, 10.0, 9.0, 2.0, 0.0, 4.0, 6.0, 5.0, 3.0, 37.0, 20.0, 0.0, 0.0, 177.0, 180.0, 79.0, 135.0, 3.0, 1.0, 0.0, 7.0, 159.0, 136.0, 178.0, 198.0, 5.0, 7.0, 0.0, 0.0, 60.0, 58.0, 1.0, 0.0, 0.0, 0.0, 101.0, 153.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 50.0, 42.0, 0.0, 0.0, 143.0, 125.0, 58.0, 18.0, 133.0, 167.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 12.0, 150.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 81.0, 110.0, 88.0, 0.0, 0.0, 160.0, 132.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 125.0, 121.0, 86.0, 110.0, 175.0, 100.0, 6.0, 0.0, 0.0, 0.0, 0.0, 48.0, 0.0, 8.0, 0.0, 7.0, 84.0, 98.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 97.0, 103.0, 0.0, 0.0, 6.0, 29.0, 170.0, 182.0, 14.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8325797406213072, "mean_inference_ms": 2.363101983014475, "mean_action_processing_ms": 0.386775160208892, "mean_env_wait_ms": 0.3039199829236526, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012632608413696289, "StateBufferConnector_ms": 0.004132628440856934, "ViewRequirementAgentConnector_ms": 0.1740645170211792}, "num_episodes": 18, "episode_return_max": 249.19999999999908, "episode_return_min": -215.90000000000006, "episode_return_mean": 54.67499999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.9604531888575, "num_env_steps_trained_throughput_per_sec": 316.9604531888575, "timesteps_total": 484000, "num_env_steps_sampled_lifetime": 484000, "num_agent_steps_sampled_lifetime": 1936000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1936000, "timers": {"training_iteration_time_ms": 14852.015, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14851.963, "sample_time_ms": 2291.886, "learn_time_ms": 12533.995, "learn_throughput": 319.132, "synch_weights_time_ms": 19.308}, "counters": {"num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "done": false, "training_iteration": 121, "trial_id": "04dec_00002", "date": "2024-08-13_16-50-05", "timestamp": 1723582205, "time_this_iter_s": 12.666030168533325, "time_total_s": 1634.0809483528137, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b02bcdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1634.0809483528137, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 65.54444444444444, "ram_util_percent": 83.59444444444443}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1518537326543419, "cur_kl_coeff": 2.6520865503698574e-10, "cur_lr": 0.00010000000000000003, "total_loss": 3.1722908207979152, "policy_loss": -0.0008915014175708017, "vf_loss": 3.173182323243883, "vf_explained_var": 0.0004341820245066648, "kl": 0.002366054278581356, "entropy": 0.2942026279590748, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 229635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.27929201051987, "cur_kl_coeff": 0.0014270453725202974, "cur_lr": 0.00010000000000000003, "total_loss": 4.225979631918448, "policy_loss": -0.0007889360581184664, "vf_loss": 4.226761185933674, "vf_explained_var": -0.03746747582677811, "kl": 0.005169518639289251, "entropy": 0.5363097268910635, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 229635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "env_runners": {"episode_reward_max": 249.19999999999908, "episode_reward_min": -262.70000000000005, "episode_reward_mean": 50.231999999999886, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -19.264000000000024, "predator_policy": 44.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [156.6999999999992, -7.200000000000019, 55.30000000000007, 9.19999999999997, 13.699999999999962, 177.6999999999992, 40.0000000000003, 71.30000000000001, -71.40000000000046, 109.29999999999954, -23.59999999999976, 192.99999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 126.29999999999951, 94.79999999999964, -23.699999999999662, 94.19999999999966, -56.09999999999976, 60.9000000000002, 90.1999999999993, 37.80000000000027, 175.39999999999927, 80.09999999999948, 107.49999999999956, 40.0000000000003, -215.90000000000006, -114.70000000000107, 249.19999999999908, 212.2999999999993, 8.000000000000044, -4.000000000000064, 28.600000000000133, 219.99999999999926, 84.49999999999963, 38.90000000000028, 40.0000000000003, 1.4999999999999787, 142.39999999999924, 40.0000000000003, 40.0000000000003, 77.9999999999998, 140.79999999999907, 58.40000000000026, 60.799999999999464, -190.70000000000024, 40.0000000000003, 185.99999999999943, 40.0000000000003, 117.6999999999995, -5.200000000000005, 40.0000000000003, 40.0000000000003, 92.19999999999938, -13.499999999999945, -50.5999999999998, 40.0000000000003, -9.400000000000007, 40.0000000000003, 50.80000000000028, 35.600000000000236, -64.39999999999984, -6.699999999999974, -74.7000000000003, 99.09999999999943, 40.0000000000003, -12.799999999999594, 211.1999999999993, 205.99999999999932, 51.900000000000134, 219.99999999999926, 31.200000000000177, 40.0000000000003, -1.1999999999999669, 219.99999999999926, 168.2999999999995, 2.2999999999999963, 24.600000000000065, 35.600000000000236, 40.0000000000003, 40.0000000000003, 97.1999999999997, 32.30000000000018, 40.0000000000003, 40.0000000000003, -262.70000000000005, 145.3999999999993, -7.500000000000044, 120.99999999999918, 23.500000000000032, -164.30000000000004, 40.0000000000003, 85.69999999999987, 74.19999999999999, 191.5999999999994, 32.30000000000019, -48.999999999999844, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 124.69999999999979, 15.799999999999963, -361.0, -108.69999999999999, 20.000000000000014, 20.000000000000014, -356.79999999999995, -49.299999999999834, 20.000000000000014, 20.000000000000014, 157.69999999999987, 20.000000000000014, 20.000000000000014, 92.89999999999992, -364.6, 20.000000000000014, -351.4, 89.29999999999984, 20.000000000000014, -351.4, -5.1999999999999265, 20.000000000000014, 172.99999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -157.90000000000046, 141.19999999999987, 90.19999999999985, -9.399999999999855, 20.000000000000014, -120.70000000000059, 20.000000000000014, 3.20000000000005, 20.000000000000014, -336.0999999999999, 20.000000000000014, -12.10000000000003, 72.20000000000002, -1.0000000000000204, 20.000000000000014, 15.799999999999963, 20.000000000000014, 145.3999999999999, 66.80000000000001, 5.299999999999965, 83.89999999999998, -33.39999999999981, 20.000000000000014, 20.000000000000014, -309.1, -263.8, -254.50000000000028, -74.20000000000084, 200.0, 45.20000000000023, 5.299999999999965, 200.0, -313.9, 26.90000000000008, -395.8, 15.799999999999963, 11.299999999999974, 5.299999999999965, 200.0, 20.000000000000014, 11.599999999999964, -45.09999999999995, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -266.20000000000005, 13.699999999999964, 5.299999999999965, 127.09999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.000000000000014, 20.000000000000014, 120.7999999999997, -262.9000000000001, 53.30000000000023, 20.000000000000014, -35.2, -200.5000000000002, -290.20000000000005, 20.000000000000014, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 85.70000000000003, 20.000000000000014, -302.1999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.1999999999999, 20.000000000000014, 9.499999999999964, -208.00000000000037, 20.000000000000014, -268.6000000000001, 20.000000000000014, 20.000000000000014, -321.3999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.80000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999964, -17.79999999999974, -292.59999999999997, 11.599999999999964, -214.30000000000013, -13.599999999999811, -336.1, 85.69999999999987, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.80000000000085, 200.0, 3.1999999999999615, 179.0, 20.000000000000014, 20.000000000000014, -150.1, 200.0, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -221.20000000000016, 200.0, 20.000000000000014, 5.299999999999978, 128.0, -369.69999999999993, 20.000000000000014, -9.39999999999988, 20.000000000000014, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.49999999999966, -298.30000000000007, 20.000000000000014, 5.299999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -324.1, -178.60000000000002, 121.39999999999984, 20.000000000000014, 20.000000000000014, -236.5000000000001, 100.99999999999974, 20.000000000000014, 20.000000000000014, -11.499999999999822, -225.7000000000002, -223.60000000000008, 20.000000000000014, 20.000000000000014, -83.50000000000063, 51.20000000000009, 45.20000000000007, 20.000000000000014, 164.0, 11.599999999999964, 20.000000000000014, 5.299999999999969, -344.79999999999984, 75.79999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [8.0, 4.0, 183.0, 155.0, 61.0, 83.0, 174.0, 172.0, 32.0, 11.0, 0.0, 0.0, 0.0, 0.0, 171.0, 172.0, 181.0, 79.0, 0.0, 0.0, 193.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 89.0, 54.0, 14.0, 0.0, 10.0, 67.0, 33.0, 38.0, 89.0, 171.0, 30.0, 23.0, 10.0, 9.0, 2.0, 0.0, 4.0, 6.0, 5.0, 3.0, 37.0, 20.0, 0.0, 0.0, 177.0, 180.0, 79.0, 135.0, 3.0, 1.0, 0.0, 7.0, 159.0, 136.0, 178.0, 198.0, 5.0, 7.0, 0.0, 0.0, 60.0, 58.0, 1.0, 0.0, 0.0, 0.0, 101.0, 153.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 50.0, 42.0, 0.0, 0.0, 143.0, 125.0, 58.0, 18.0, 133.0, 167.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 12.0, 150.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 81.0, 110.0, 88.0, 0.0, 0.0, 160.0, 132.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 125.0, 121.0, 86.0, 110.0, 175.0, 100.0, 6.0, 0.0, 0.0, 0.0, 0.0, 48.0, 0.0, 8.0, 0.0, 7.0, 84.0, 98.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 97.0, 103.0, 0.0, 0.0, 6.0, 29.0, 170.0, 182.0, 14.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 143.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 112.0, 0.0, 4.0, 85.0, 124.0, 0.0, 0.0, 6.0, 9.0, 137.0, 148.0, 0.0, 0.0, 59.0, 59.0, 9.0, 0.0, 4.0, 12.0, 2.0, 5.0, 174.0, 46.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8324968268339191, "mean_inference_ms": 2.3643675878510337, "mean_action_processing_ms": 0.3863000424382506, "mean_env_wait_ms": 0.3038306925727995, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012139439582824707, "StateBufferConnector_ms": 0.004100322723388672, "ViewRequirementAgentConnector_ms": 0.15353143215179443}, "num_episodes": 18, "episode_return_max": 249.19999999999908, "episode_return_min": -262.70000000000005, "episode_return_mean": 50.231999999999886, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.8243070435163, "num_env_steps_trained_throughput_per_sec": 294.8243070435163, "timesteps_total": 488000, "num_env_steps_sampled_lifetime": 488000, "num_agent_steps_sampled_lifetime": 1952000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1952000, "timers": {"training_iteration_time_ms": 14661.953, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14661.901, "sample_time_ms": 2238.986, "learn_time_ms": 12397.169, "learn_throughput": 322.654, "synch_weights_time_ms": 19.191}, "counters": {"num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "done": false, "training_iteration": 122, "trial_id": "04dec_00002", "date": "2024-08-13_16-50-18", "timestamp": 1723582218, "time_this_iter_s": 13.653055906295776, "time_total_s": 1647.7340042591095, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0728940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1647.7340042591095, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 75.00500000000001, "ram_util_percent": 83.695}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.14538331465431, "cur_kl_coeff": 1.3260432751849287e-10, "cur_lr": 0.00010000000000000003, "total_loss": 3.40080482101945, "policy_loss": -0.0008599994491007199, "vf_loss": 3.4016648283711186, "vf_explained_var": 0.0009766842322374777, "kl": 0.002124373047458417, "entropy": 0.2790282256467633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 231525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.25746102601132, "cur_kl_coeff": 0.0014270453725202974, "cur_lr": 0.00010000000000000003, "total_loss": 4.677059845192723, "policy_loss": -0.0014115020819993878, "vf_loss": 4.678456393246928, "vf_explained_var": -0.07076269706721028, "kl": 0.010479382986539684, "entropy": 0.5025994192828577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 231525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "env_runners": {"episode_reward_max": 300.9999999999998, "episode_reward_min": -262.70000000000005, "episode_reward_mean": 53.744999999999884, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -12.632500000000023, "predator_policy": 39.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [175.39999999999927, 80.09999999999948, 107.49999999999956, 40.0000000000003, -215.90000000000006, -114.70000000000107, 249.19999999999908, 212.2999999999993, 8.000000000000044, -4.000000000000064, 28.600000000000133, 219.99999999999926, 84.49999999999963, 38.90000000000028, 40.0000000000003, 1.4999999999999787, 142.39999999999924, 40.0000000000003, 40.0000000000003, 77.9999999999998, 140.79999999999907, 58.40000000000026, 60.799999999999464, -190.70000000000024, 40.0000000000003, 185.99999999999943, 40.0000000000003, 117.6999999999995, -5.200000000000005, 40.0000000000003, 40.0000000000003, 92.19999999999938, -13.499999999999945, -50.5999999999998, 40.0000000000003, -9.400000000000007, 40.0000000000003, 50.80000000000028, 35.600000000000236, -64.39999999999984, -6.699999999999974, -74.7000000000003, 99.09999999999943, 40.0000000000003, -12.799999999999594, 211.1999999999993, 205.99999999999932, 51.900000000000134, 219.99999999999926, 31.200000000000177, 40.0000000000003, -1.1999999999999669, 219.99999999999926, 168.2999999999995, 2.2999999999999963, 24.600000000000065, 35.600000000000236, 40.0000000000003, 40.0000000000003, 97.1999999999997, 32.30000000000018, 40.0000000000003, 40.0000000000003, -262.70000000000005, 145.3999999999993, -7.500000000000044, 120.99999999999918, 23.500000000000032, -164.30000000000004, 40.0000000000003, 85.69999999999987, 74.19999999999999, 191.5999999999994, 32.30000000000019, -48.999999999999844, 40.0000000000003, 40.0000000000003, 40.0000000000003, 134.4999999999995, 3.6000000000002164, -55.39999999999974, -51.99999999999975, 199.99999999999935, -22.00000000000005, 271.19999999999953, 40.0000000000003, 55.5000000000002, -27.19999999999986, 300.9999999999998, 132.79999999999944, 23.000000000000036, -11.40000000000007, -57.0999999999998, 122.89999999999934, 91.19999999999973, 205.99999999999932, -2.600000000000019, 40.0000000000003, 145.6999999999991, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 145.3999999999999, 66.80000000000001, 5.299999999999965, 83.89999999999998, -33.39999999999981, 20.000000000000014, 20.000000000000014, -309.1, -263.8, -254.50000000000028, -74.20000000000084, 200.0, 45.20000000000023, 5.299999999999965, 200.0, -313.9, 26.90000000000008, -395.8, 15.799999999999963, 11.299999999999974, 5.299999999999965, 200.0, 20.000000000000014, 11.599999999999964, -45.09999999999995, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -266.20000000000005, 13.699999999999964, 5.299999999999965, 127.09999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.000000000000014, 20.000000000000014, 120.7999999999997, -262.9000000000001, 53.30000000000023, 20.000000000000014, -35.2, -200.5000000000002, -290.20000000000005, 20.000000000000014, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 85.70000000000003, 20.000000000000014, -302.1999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.1999999999999, 20.000000000000014, 9.499999999999964, -208.00000000000037, 20.000000000000014, -268.6000000000001, 20.000000000000014, 20.000000000000014, -321.3999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.80000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999964, -17.79999999999974, -292.59999999999997, 11.599999999999964, -214.30000000000013, -13.599999999999811, -336.1, 85.69999999999987, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.80000000000085, 200.0, 3.1999999999999615, 179.0, 20.000000000000014, 20.000000000000014, -150.1, 200.0, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -221.20000000000016, 200.0, 20.000000000000014, 5.299999999999978, 128.0, -369.69999999999993, 20.000000000000014, -9.39999999999988, 20.000000000000014, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.49999999999966, -298.30000000000007, 20.000000000000014, 5.299999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -324.1, -178.60000000000002, 121.39999999999984, 20.000000000000014, 20.000000000000014, -236.5000000000001, 100.99999999999974, 20.000000000000014, 20.000000000000014, -11.499999999999822, -225.7000000000002, -223.60000000000008, 20.000000000000014, 20.000000000000014, -83.50000000000063, 51.20000000000009, 45.20000000000007, 20.000000000000014, 164.0, 11.599999999999964, 20.000000000000014, 5.299999999999969, -344.79999999999984, 75.79999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999989, -9.399999999999855, -0.9999999999999846, -76.60000000000073, -191.8, -180.99999999999997, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -295.0, 87.19999999999987, 173.0, 20.000000000000014, 20.000000000000014, 54.20000000000015, -15.699999999999747, 74.90000000000003, -258.1, 200.0, 100.9999999999998, 105.79999999999986, 20.000000000000014, -36.99999999999977, 20.000000000000014, 20.000000000000014, -150.40000000000003, -284.5, 10.399999999999968, 74.89999999999998, 20.000000000000014, 57.20000000000009, 20.000000000000014, 179.0, 20.000000000000014, -237.40000000000015, 15.799999999999963, 20.000000000000014, 20.000000000000014, 145.99999999999972, -49.29999999999977, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [4.0, 6.0, 5.0, 3.0, 37.0, 20.0, 0.0, 0.0, 177.0, 180.0, 79.0, 135.0, 3.0, 1.0, 0.0, 7.0, 159.0, 136.0, 178.0, 198.0, 5.0, 7.0, 0.0, 0.0, 60.0, 58.0, 1.0, 0.0, 0.0, 0.0, 101.0, 153.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 50.0, 42.0, 0.0, 0.0, 143.0, 125.0, 58.0, 18.0, 133.0, 167.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 12.0, 150.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 81.0, 110.0, 88.0, 0.0, 0.0, 160.0, 132.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 125.0, 121.0, 86.0, 110.0, 175.0, 100.0, 6.0, 0.0, 0.0, 0.0, 0.0, 48.0, 0.0, 8.0, 0.0, 7.0, 84.0, 98.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 97.0, 103.0, 0.0, 0.0, 6.0, 29.0, 170.0, 182.0, 14.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 143.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 112.0, 0.0, 4.0, 85.0, 124.0, 0.0, 0.0, 6.0, 9.0, 137.0, 148.0, 0.0, 0.0, 59.0, 59.0, 9.0, 0.0, 4.0, 12.0, 2.0, 5.0, 174.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 124.0, 89.0, 109.0, 0.0, 10.0, 0.0, 103.0, 150.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 149.0, 7.0, 0.0, 0.0, 2.0, 5.0, 20.0, 20.0, 49.0, 70.0, 94.0, 123.0, 15.0, 13.0, 11.0, 3.0, 6.0, 1.0, 108.0, 111.0, 0.0, 0.0, 17.0, 32.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8328102474798607, "mean_inference_ms": 2.3652044791221036, "mean_action_processing_ms": 0.38613925487592027, "mean_env_wait_ms": 0.30367492896615855, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011662006378173828, "StateBufferConnector_ms": 0.004343986511230469, "ViewRequirementAgentConnector_ms": 0.14587998390197754}, "num_episodes": 23, "episode_return_max": 300.9999999999998, "episode_return_min": -262.70000000000005, "episode_return_mean": 53.744999999999884, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.4363241370147, "num_env_steps_trained_throughput_per_sec": 291.4363241370147, "timesteps_total": 492000, "num_env_steps_sampled_lifetime": 492000, "num_agent_steps_sampled_lifetime": 1968000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1968000, "timers": {"training_iteration_time_ms": 14555.853, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14555.803, "sample_time_ms": 2216.705, "learn_time_ms": 12314.134, "learn_throughput": 324.83, "synch_weights_time_ms": 18.722}, "counters": {"num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "done": false, "training_iteration": 123, "trial_id": "04dec_00002", "date": "2024-08-13_16-50-32", "timestamp": 1723582232, "time_this_iter_s": 13.762572765350342, "time_total_s": 1661.4965770244598, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c4ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1661.4965770244598, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 71.87368421052632, "ram_util_percent": 83.65263157894738}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0548801287693321, "cur_kl_coeff": 6.630216375924643e-11, "cur_lr": 0.00010000000000000003, "total_loss": 5.198528424772636, "policy_loss": -0.0012527914877941526, "vf_loss": 5.199781207685118, "vf_explained_var": 0.00023359053980105769, "kl": 0.0027553662982558067, "entropy": 0.27588297447199545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 233415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.097521748492326, "cur_kl_coeff": 0.0014270453725202974, "cur_lr": 0.00010000000000000003, "total_loss": 5.006843178486698, "policy_loss": -0.0006926840939928615, "vf_loss": 5.007521809471978, "vf_explained_var": -0.056469822497594926, "kl": 0.009844786570508291, "entropy": 0.504232642322621, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 233415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "env_runners": {"episode_reward_max": 300.9999999999998, "episode_reward_min": -283.60000000000014, "episode_reward_mean": 48.61299999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -376.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": -18.728500000000018, "predator_policy": 43.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 77.9999999999998, 140.79999999999907, 58.40000000000026, 60.799999999999464, -190.70000000000024, 40.0000000000003, 185.99999999999943, 40.0000000000003, 117.6999999999995, -5.200000000000005, 40.0000000000003, 40.0000000000003, 92.19999999999938, -13.499999999999945, -50.5999999999998, 40.0000000000003, -9.400000000000007, 40.0000000000003, 50.80000000000028, 35.600000000000236, -64.39999999999984, -6.699999999999974, -74.7000000000003, 99.09999999999943, 40.0000000000003, -12.799999999999594, 211.1999999999993, 205.99999999999932, 51.900000000000134, 219.99999999999926, 31.200000000000177, 40.0000000000003, -1.1999999999999669, 219.99999999999926, 168.2999999999995, 2.2999999999999963, 24.600000000000065, 35.600000000000236, 40.0000000000003, 40.0000000000003, 97.1999999999997, 32.30000000000018, 40.0000000000003, 40.0000000000003, -262.70000000000005, 145.3999999999993, -7.500000000000044, 120.99999999999918, 23.500000000000032, -164.30000000000004, 40.0000000000003, 85.69999999999987, 74.19999999999999, 191.5999999999994, 32.30000000000019, -48.999999999999844, 40.0000000000003, 40.0000000000003, 40.0000000000003, 134.4999999999995, 3.6000000000002164, -55.39999999999974, -51.99999999999975, 199.99999999999935, -22.00000000000005, 271.19999999999953, 40.0000000000003, 55.5000000000002, -27.19999999999986, 300.9999999999998, 132.79999999999944, 23.000000000000036, -11.40000000000007, -57.0999999999998, 122.89999999999934, 91.19999999999973, 205.99999999999932, -2.600000000000019, 40.0000000000003, 145.6999999999991, 40.0000000000003, 38.90000000000028, 39.40000000000005, -283.60000000000014, 136.19999999999987, -23.299999999999763, 8.299999999999976, 32.30000000000018, 40.0000000000003, 74.20000000000003, 219.99999999999926, 1.9999999999999494, 40.0000000000003, 28.300000000000153, -13.600000000000062, 183.99999999999918, 40.0000000000003, -4.400000000000029, 61.9000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -34.000000000000014, 20.000000000000014, 120.7999999999997, -262.9000000000001, 53.30000000000023, 20.000000000000014, -35.2, -200.5000000000002, -290.20000000000005, 20.000000000000014, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 85.70000000000003, 20.000000000000014, -302.1999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.1999999999999, 20.000000000000014, 9.499999999999964, -208.00000000000037, 20.000000000000014, -268.6000000000001, 20.000000000000014, 20.000000000000014, -321.3999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.80000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999964, -17.79999999999974, -292.59999999999997, 11.599999999999964, -214.30000000000013, -13.599999999999811, -336.1, 85.69999999999987, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.80000000000085, 200.0, 3.1999999999999615, 179.0, 20.000000000000014, 20.000000000000014, -150.1, 200.0, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -221.20000000000016, 200.0, 20.000000000000014, 5.299999999999978, 128.0, -369.69999999999993, 20.000000000000014, -9.39999999999988, 20.000000000000014, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.49999999999966, -298.30000000000007, 20.000000000000014, 5.299999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -324.1, -178.60000000000002, 121.39999999999984, 20.000000000000014, 20.000000000000014, -236.5000000000001, 100.99999999999974, 20.000000000000014, 20.000000000000014, -11.499999999999822, -225.7000000000002, -223.60000000000008, 20.000000000000014, 20.000000000000014, -83.50000000000063, 51.20000000000009, 45.20000000000007, 20.000000000000014, 164.0, 11.599999999999964, 20.000000000000014, 5.299999999999969, -344.79999999999984, 75.79999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999989, -9.399999999999855, -0.9999999999999846, -76.60000000000073, -191.8, -180.99999999999997, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -295.0, 87.19999999999987, 173.0, 20.000000000000014, 20.000000000000014, 54.20000000000015, -15.699999999999747, 74.90000000000003, -258.1, 200.0, 100.9999999999998, 105.79999999999986, 20.000000000000014, -36.99999999999977, 20.000000000000014, 20.000000000000014, -150.40000000000003, -284.5, 10.399999999999968, 74.89999999999998, 20.000000000000014, 57.20000000000009, 20.000000000000014, 179.0, 20.000000000000014, -237.40000000000015, 15.799999999999963, 20.000000000000014, 20.000000000000014, 145.99999999999972, -49.29999999999977, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -355.9, 71.3000000000001, -362.20000000000005, -285.4000000000001, 116.0, -212.8000000000002, -283.29999999999984, 20.000000000000014, 20.000000000000014, -174.70000000000036, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000015, 20.000000000000014, 200.0, 20.000000000000014, -376.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.500000000000114, -176.19999999999996, -223.60000000000022, 20.000000000000014, 108.1999999999999, 75.79999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000018, 91.0999999999998, -206.2000000000003], "policy_predator_policy_reward": [0.0, 0.0, 50.0, 42.0, 0.0, 0.0, 143.0, 125.0, 58.0, 18.0, 133.0, 167.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 12.0, 150.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 81.0, 110.0, 88.0, 0.0, 0.0, 160.0, 132.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 125.0, 121.0, 86.0, 110.0, 175.0, 100.0, 6.0, 0.0, 0.0, 0.0, 0.0, 48.0, 0.0, 8.0, 0.0, 7.0, 84.0, 98.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 97.0, 103.0, 0.0, 0.0, 6.0, 29.0, 170.0, 182.0, 14.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 143.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 112.0, 0.0, 4.0, 85.0, 124.0, 0.0, 0.0, 6.0, 9.0, 137.0, 148.0, 0.0, 0.0, 59.0, 59.0, 9.0, 0.0, 4.0, 12.0, 2.0, 5.0, 174.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 124.0, 89.0, 109.0, 0.0, 10.0, 0.0, 103.0, 150.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 149.0, 7.0, 0.0, 0.0, 2.0, 5.0, 20.0, 20.0, 49.0, 70.0, 94.0, 123.0, 15.0, 13.0, 11.0, 3.0, 6.0, 1.0, 108.0, 111.0, 0.0, 0.0, 17.0, 32.0, 0.0, 0.0, 0.0, 1.0, 152.0, 172.0, 177.0, 187.0, 126.0, 107.0, 94.0, 146.0, 91.0, 72.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 187.0, 0.0, 0.0, 90.0, 57.0, 92.0, 98.0, 0.0, 0.0, 0.0, 0.0, 128.0, 97.0, 74.0, 103.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8318612849268959, "mean_inference_ms": 2.3658650242366503, "mean_action_processing_ms": 0.38501616040600467, "mean_env_wait_ms": 0.3035206319280077, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009297609329223633, "StateBufferConnector_ms": 0.0036443471908569336, "ViewRequirementAgentConnector_ms": 0.12114822864532471}, "num_episodes": 18, "episode_return_max": 300.9999999999998, "episode_return_min": -283.60000000000014, "episode_return_mean": 48.61299999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.7472396766713, "num_env_steps_trained_throughput_per_sec": 305.7472396766713, "timesteps_total": 496000, "num_env_steps_sampled_lifetime": 496000, "num_agent_steps_sampled_lifetime": 1984000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1984000, "timers": {"training_iteration_time_ms": 14222.648, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14222.598, "sample_time_ms": 2083.917, "learn_time_ms": 12117.187, "learn_throughput": 330.11, "synch_weights_time_ms": 16.285}, "counters": {"num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "done": false, "training_iteration": 124, "trial_id": "04dec_00002", "date": "2024-08-13_16-50-45", "timestamp": 1723582245, "time_this_iter_s": 13.129808187484741, "time_total_s": 1674.6263852119446, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1674.6263852119446, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 65.4157894736842, "ram_util_percent": 83.3}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.13389297317339, "cur_kl_coeff": 3.315108187962322e-11, "cur_lr": 0.00010000000000000003, "total_loss": 2.5208757872303957, "policy_loss": -0.001042224845119688, "vf_loss": 2.5219180129192496, "vf_explained_var": 0.000758296566665488, "kl": 0.002708513530473957, "entropy": 0.2982446466409971, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 235305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.421757979966976, "cur_kl_coeff": 0.0014270453725202974, "cur_lr": 0.00010000000000000003, "total_loss": 2.6004557711737495, "policy_loss": -0.0018235286076863607, "vf_loss": 2.602268216029677, "vf_explained_var": -0.1031624386865626, "kl": 0.007763620535550496, "entropy": 0.46194556680305926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 235305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "env_runners": {"episode_reward_max": 300.9999999999998, "episode_reward_min": -283.60000000000014, "episode_reward_mean": 52.55599999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -376.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": -14.872000000000021, "predator_policy": 41.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.699999999999974, -74.7000000000003, 99.09999999999943, 40.0000000000003, -12.799999999999594, 211.1999999999993, 205.99999999999932, 51.900000000000134, 219.99999999999926, 31.200000000000177, 40.0000000000003, -1.1999999999999669, 219.99999999999926, 168.2999999999995, 2.2999999999999963, 24.600000000000065, 35.600000000000236, 40.0000000000003, 40.0000000000003, 97.1999999999997, 32.30000000000018, 40.0000000000003, 40.0000000000003, -262.70000000000005, 145.3999999999993, -7.500000000000044, 120.99999999999918, 23.500000000000032, -164.30000000000004, 40.0000000000003, 85.69999999999987, 74.19999999999999, 191.5999999999994, 32.30000000000019, -48.999999999999844, 40.0000000000003, 40.0000000000003, 40.0000000000003, 134.4999999999995, 3.6000000000002164, -55.39999999999974, -51.99999999999975, 199.99999999999935, -22.00000000000005, 271.19999999999953, 40.0000000000003, 55.5000000000002, -27.19999999999986, 300.9999999999998, 132.79999999999944, 23.000000000000036, -11.40000000000007, -57.0999999999998, 122.89999999999934, 91.19999999999973, 205.99999999999932, -2.600000000000019, 40.0000000000003, 145.6999999999991, 40.0000000000003, 38.90000000000028, 39.40000000000005, -283.60000000000014, 136.19999999999987, -23.299999999999763, 8.299999999999976, 32.30000000000018, 40.0000000000003, 74.20000000000003, 219.99999999999926, 1.9999999999999494, 40.0000000000003, 28.300000000000153, -13.600000000000062, 183.99999999999918, 40.0000000000003, -4.400000000000029, 61.9000000000002, -1.1000000000000485, 36.70000000000025, 36.70000000000025, 35.600000000000236, -23.69999999999977, 34.50000000000022, 143.49999999999977, 200.29999999999964, 33.400000000000205, 65.90000000000009, 134.49999999999935, 40.0000000000003, -23.800000000000004, -5.399999999999861, 100.29999999999953, 40.0000000000003, 27.50000000000012, 37.80000000000027, -39.399999999999764, 212.9999999999993, 38.90000000000028, 35.600000000000236], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, -214.30000000000013, -13.599999999999811, -336.1, 85.69999999999987, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.80000000000085, 200.0, 3.1999999999999615, 179.0, 20.000000000000014, 20.000000000000014, -150.1, 200.0, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -221.20000000000016, 200.0, 20.000000000000014, 5.299999999999978, 128.0, -369.69999999999993, 20.000000000000014, -9.39999999999988, 20.000000000000014, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.49999999999966, -298.30000000000007, 20.000000000000014, 5.299999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -324.1, -178.60000000000002, 121.39999999999984, 20.000000000000014, 20.000000000000014, -236.5000000000001, 100.99999999999974, 20.000000000000014, 20.000000000000014, -11.499999999999822, -225.7000000000002, -223.60000000000008, 20.000000000000014, 20.000000000000014, -83.50000000000063, 51.20000000000009, 45.20000000000007, 20.000000000000014, 164.0, 11.599999999999964, 20.000000000000014, 5.299999999999969, -344.79999999999984, 75.79999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999989, -9.399999999999855, -0.9999999999999846, -76.60000000000073, -191.8, -180.99999999999997, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -295.0, 87.19999999999987, 173.0, 20.000000000000014, 20.000000000000014, 54.20000000000015, -15.699999999999747, 74.90000000000003, -258.1, 200.0, 100.9999999999998, 105.79999999999986, 20.000000000000014, -36.99999999999977, 20.000000000000014, 20.000000000000014, -150.40000000000003, -284.5, 10.399999999999968, 74.89999999999998, 20.000000000000014, 57.20000000000009, 20.000000000000014, 179.0, 20.000000000000014, -237.40000000000015, 15.799999999999963, 20.000000000000014, 20.000000000000014, 145.99999999999972, -49.29999999999977, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -355.9, 71.3000000000001, -362.20000000000005, -285.4000000000001, 116.0, -212.8000000000002, -283.29999999999984, 20.000000000000014, 20.000000000000014, -174.70000000000036, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000015, 20.000000000000014, 200.0, 20.000000000000014, -376.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.500000000000114, -176.19999999999996, -223.60000000000022, 20.000000000000014, 108.1999999999999, 75.79999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000018, 91.0999999999998, -206.2000000000003, -270.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 13.699999999999964, 20.000000000000014, 11.599999999999966, -319.8999999999999, -14.799999999999807, 9.499999999999964, 20.000000000000014, 20.000000000000014, 123.50000000000006, -54.7, 118.99999999999983, 20.000000000000014, 7.399999999999965, -101.50000000000051, 79.40000000000002, 20.000000000000014, 105.49999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, -326.8, 20.000000000000014, -285.40000000000003, 80.30000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999847, 20.000000000000014, 15.799999999999963, -258.40000000000015, 20.000000000000014, 185.0, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999968], "policy_predator_policy_reward": [86.0, 110.0, 175.0, 100.0, 6.0, 0.0, 0.0, 0.0, 0.0, 48.0, 0.0, 8.0, 0.0, 7.0, 84.0, 98.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 97.0, 103.0, 0.0, 0.0, 6.0, 29.0, 170.0, 182.0, 14.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 143.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 112.0, 0.0, 4.0, 85.0, 124.0, 0.0, 0.0, 6.0, 9.0, 137.0, 148.0, 0.0, 0.0, 59.0, 59.0, 9.0, 0.0, 4.0, 12.0, 2.0, 5.0, 174.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 124.0, 89.0, 109.0, 0.0, 10.0, 0.0, 103.0, 150.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 149.0, 7.0, 0.0, 0.0, 2.0, 5.0, 20.0, 20.0, 49.0, 70.0, 94.0, 123.0, 15.0, 13.0, 11.0, 3.0, 6.0, 1.0, 108.0, 111.0, 0.0, 0.0, 17.0, 32.0, 0.0, 0.0, 0.0, 1.0, 152.0, 172.0, 177.0, 187.0, 126.0, 107.0, 94.0, 146.0, 91.0, 72.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 187.0, 0.0, 0.0, 90.0, 57.0, 92.0, 98.0, 0.0, 0.0, 0.0, 0.0, 128.0, 97.0, 74.0, 103.0, 110.0, 139.0, 3.0, 0.0, 0.0, 3.0, 4.0, 0.0, 171.0, 140.0, 5.0, 0.0, 0.0, 0.0, 54.0, 82.0, 0.0, 6.0, 62.0, 26.0, 0.0, 9.0, 0.0, 0.0, 119.0, 164.0, 106.0, 154.0, 0.0, 0.0, 0.0, 0.0, 11.0, 8.0, 0.0, 2.0, 74.0, 125.0, 5.0, 3.0, 1.0, 0.0, 0.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8314027258489611, "mean_inference_ms": 2.365720701219683, "mean_action_processing_ms": 0.3843040949869075, "mean_env_wait_ms": 0.303325707953278, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006486296653747559, "StateBufferConnector_ms": 0.004571676254272461, "ViewRequirementAgentConnector_ms": 0.11636602878570557}, "num_episodes": 22, "episode_return_max": 300.9999999999998, "episode_return_min": -283.60000000000014, "episode_return_mean": 52.55599999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 312.5916294192988, "num_env_steps_trained_throughput_per_sec": 312.5916294192988, "timesteps_total": 500000, "num_env_steps_sampled_lifetime": 500000, "num_agent_steps_sampled_lifetime": 2000000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2000000, "timers": {"training_iteration_time_ms": 13941.093, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13941.044, "sample_time_ms": 1975.377, "learn_time_ms": 11946.758, "learn_throughput": 334.819, "synch_weights_time_ms": 15.141}, "counters": {"num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "done": false, "training_iteration": 125, "trial_id": "04dec_00002", "date": "2024-08-13_16-50-58", "timestamp": 1723582258, "time_this_iter_s": 12.843063116073608, "time_total_s": 1687.4694483280182, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b061a040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1687.4694483280182, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 67.67222222222223, "ram_util_percent": 83.47777777777779}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0773916111500175, "cur_kl_coeff": 1.657554093981161e-11, "cur_lr": 0.00010000000000000003, "total_loss": 1.7735953281796168, "policy_loss": -0.0007728616339918325, "vf_loss": 1.7743681916484126, "vf_explained_var": 0.00036582234044554374, "kl": 0.003031109855545902, "entropy": 0.31823109050907156, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 237195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.274304816560456, "cur_kl_coeff": 0.0014270453725202974, "cur_lr": 0.00010000000000000003, "total_loss": 2.690651928684699, "policy_loss": -0.000961074776696189, "vf_loss": 2.691605903358056, "vf_explained_var": 0.007863497607922428, "kl": 0.0049730310685821705, "entropy": 0.4123064283813749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 237195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "env_runners": {"episode_reward_max": 300.9999999999998, "episode_reward_min": -283.60000000000014, "episode_reward_mean": 53.24399999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": -11.39800000000002, "predator_policy": 38.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 97.1999999999997, 32.30000000000018, 40.0000000000003, 40.0000000000003, -262.70000000000005, 145.3999999999993, -7.500000000000044, 120.99999999999918, 23.500000000000032, -164.30000000000004, 40.0000000000003, 85.69999999999987, 74.19999999999999, 191.5999999999994, 32.30000000000019, -48.999999999999844, 40.0000000000003, 40.0000000000003, 40.0000000000003, 134.4999999999995, 3.6000000000002164, -55.39999999999974, -51.99999999999975, 199.99999999999935, -22.00000000000005, 271.19999999999953, 40.0000000000003, 55.5000000000002, -27.19999999999986, 300.9999999999998, 132.79999999999944, 23.000000000000036, -11.40000000000007, -57.0999999999998, 122.89999999999934, 91.19999999999973, 205.99999999999932, -2.600000000000019, 40.0000000000003, 145.6999999999991, 40.0000000000003, 38.90000000000028, 39.40000000000005, -283.60000000000014, 136.19999999999987, -23.299999999999763, 8.299999999999976, 32.30000000000018, 40.0000000000003, 74.20000000000003, 219.99999999999926, 1.9999999999999494, 40.0000000000003, 28.300000000000153, -13.600000000000062, 183.99999999999918, 40.0000000000003, -4.400000000000029, 61.9000000000002, -1.1000000000000485, 36.70000000000025, 36.70000000000025, 35.600000000000236, -23.69999999999977, 34.50000000000022, 143.49999999999977, 200.29999999999964, 33.400000000000205, 65.90000000000009, 134.49999999999935, 40.0000000000003, -23.800000000000004, -5.399999999999861, 100.29999999999953, 40.0000000000003, 27.50000000000012, 37.80000000000027, -39.399999999999764, 212.9999999999993, 38.90000000000028, 35.600000000000236, 36.10000000000024, 215.59999999999928, 181.2, 30.100000000000144, 40.0000000000003, 30.100000000000147, 31.200000000000166, 153.39999999999932, 40.0000000000003, 219.99999999999926, 40.0000000000003, 43.60000000000035, -17.399999999999963, 28.800000000000125, 111.69999999999935, 101.39999999999979, 40.0000000000003, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 132.49999999999966, -298.30000000000007, 20.000000000000014, 5.299999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -324.1, -178.60000000000002, 121.39999999999984, 20.000000000000014, 20.000000000000014, -236.5000000000001, 100.99999999999974, 20.000000000000014, 20.000000000000014, -11.499999999999822, -225.7000000000002, -223.60000000000008, 20.000000000000014, 20.000000000000014, -83.50000000000063, 51.20000000000009, 45.20000000000007, 20.000000000000014, 164.0, 11.599999999999964, 20.000000000000014, 5.299999999999969, -344.79999999999984, 75.79999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999989, -9.399999999999855, -0.9999999999999846, -76.60000000000073, -191.8, -180.99999999999997, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -295.0, 87.19999999999987, 173.0, 20.000000000000014, 20.000000000000014, 54.20000000000015, -15.699999999999747, 74.90000000000003, -258.1, 200.0, 100.9999999999998, 105.79999999999986, 20.000000000000014, -36.99999999999977, 20.000000000000014, 20.000000000000014, -150.40000000000003, -284.5, 10.399999999999968, 74.89999999999998, 20.000000000000014, 57.20000000000009, 20.000000000000014, 179.0, 20.000000000000014, -237.40000000000015, 15.799999999999963, 20.000000000000014, 20.000000000000014, 145.99999999999972, -49.29999999999977, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -355.9, 71.3000000000001, -362.20000000000005, -285.4000000000001, 116.0, -212.8000000000002, -283.29999999999984, 20.000000000000014, 20.000000000000014, -174.70000000000036, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000015, 20.000000000000014, 200.0, 20.000000000000014, -376.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.500000000000114, -176.19999999999996, -223.60000000000022, 20.000000000000014, 108.1999999999999, 75.79999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000018, 91.0999999999998, -206.2000000000003, -270.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 13.699999999999964, 20.000000000000014, 11.599999999999966, -319.8999999999999, -14.799999999999807, 9.499999999999964, 20.000000000000014, 20.000000000000014, 123.50000000000006, -54.7, 118.99999999999983, 20.000000000000014, 7.399999999999965, -101.50000000000051, 79.40000000000002, 20.000000000000014, 105.49999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, -326.8, 20.000000000000014, -285.40000000000003, 80.30000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999847, 20.000000000000014, 15.799999999999963, -258.40000000000015, 20.000000000000014, 185.0, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999968, 20.000000000000014, -10.899999999999835, 200.0, 11.599999999999964, -383.2, 187.4, 9.499999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 105.79999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, -150.40000000000023, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.29999999999978, 7.399999999999965, -22.6000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963], "policy_predator_policy_reward": [0.0, 0.0, 120.0, 143.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 112.0, 0.0, 4.0, 85.0, 124.0, 0.0, 0.0, 6.0, 9.0, 137.0, 148.0, 0.0, 0.0, 59.0, 59.0, 9.0, 0.0, 4.0, 12.0, 2.0, 5.0, 174.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 124.0, 89.0, 109.0, 0.0, 10.0, 0.0, 103.0, 150.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 149.0, 7.0, 0.0, 0.0, 2.0, 5.0, 20.0, 20.0, 49.0, 70.0, 94.0, 123.0, 15.0, 13.0, 11.0, 3.0, 6.0, 1.0, 108.0, 111.0, 0.0, 0.0, 17.0, 32.0, 0.0, 0.0, 0.0, 1.0, 152.0, 172.0, 177.0, 187.0, 126.0, 107.0, 94.0, 146.0, 91.0, 72.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 187.0, 0.0, 0.0, 90.0, 57.0, 92.0, 98.0, 0.0, 0.0, 0.0, 0.0, 128.0, 97.0, 74.0, 103.0, 110.0, 139.0, 3.0, 0.0, 0.0, 3.0, 4.0, 0.0, 171.0, 140.0, 5.0, 0.0, 0.0, 0.0, 54.0, 82.0, 0.0, 6.0, 62.0, 26.0, 0.0, 9.0, 0.0, 0.0, 119.0, 164.0, 106.0, 154.0, 0.0, 0.0, 0.0, 0.0, 11.0, 8.0, 0.0, 2.0, 74.0, 125.0, 5.0, 3.0, 1.0, 0.0, 0.0, 4.0, 11.0, 16.0, 4.0, 0.0, 186.0, 191.0, 5.0, 4.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 100.0, 2.0, 12.0, 6.0, 0.0, 47.0, 57.0, 0.0, 0.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8310350209780063, "mean_inference_ms": 2.3656338190587083, "mean_action_processing_ms": 0.3837488698539437, "mean_env_wait_ms": 0.30322587035632476, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004171013832092285, "StateBufferConnector_ms": 0.004659414291381836, "ViewRequirementAgentConnector_ms": 0.12024962902069092}, "num_episodes": 18, "episode_return_max": 300.9999999999998, "episode_return_min": -283.60000000000014, "episode_return_mean": 53.24399999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.6276858492316, "num_env_steps_trained_throughput_per_sec": 307.6276858492316, "timesteps_total": 504000, "num_env_steps_sampled_lifetime": 504000, "num_agent_steps_sampled_lifetime": 2016000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2016000, "timers": {"training_iteration_time_ms": 13187.949, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13187.901, "sample_time_ms": 1912.105, "learn_time_ms": 11257.812, "learn_throughput": 355.309, "synch_weights_time_ms": 14.126}, "counters": {"num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "done": false, "training_iteration": 126, "trial_id": "04dec_00002", "date": "2024-08-13_16-51-11", "timestamp": 1723582271, "time_this_iter_s": 13.056154012680054, "time_total_s": 1700.5256023406982, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b061a4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1700.5256023406982, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 64.07777777777777, "ram_util_percent": 83.28888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7531141893199039, "cur_kl_coeff": 8.287770469905804e-12, "cur_lr": 0.00010000000000000003, "total_loss": 0.768596850296177, "policy_loss": -0.000551629791322051, "vf_loss": 0.7691484796937811, "vf_explained_var": 0.0004852259600604022, "kl": 0.0038483895650830483, "entropy": 0.2708634347669662, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 239085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.533634809116839, "cur_kl_coeff": 0.0007135226862601487, "cur_lr": 0.00010000000000000003, "total_loss": 3.2540233166760237, "policy_loss": -0.0013721303904685315, "vf_loss": 3.255391508435446, "vf_explained_var": 0.2846517340846793, "kl": 0.005524304616359042, "entropy": 0.3866284839375309, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 239085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "env_runners": {"episode_reward_max": 300.9999999999998, "episode_reward_min": -283.60000000000014, "episode_reward_mean": 67.48299999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": -2.648500000000014, "predator_policy": 36.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, 134.4999999999995, 3.6000000000002164, -55.39999999999974, -51.99999999999975, 199.99999999999935, -22.00000000000005, 271.19999999999953, 40.0000000000003, 55.5000000000002, -27.19999999999986, 300.9999999999998, 132.79999999999944, 23.000000000000036, -11.40000000000007, -57.0999999999998, 122.89999999999934, 91.19999999999973, 205.99999999999932, -2.600000000000019, 40.0000000000003, 145.6999999999991, 40.0000000000003, 38.90000000000028, 39.40000000000005, -283.60000000000014, 136.19999999999987, -23.299999999999763, 8.299999999999976, 32.30000000000018, 40.0000000000003, 74.20000000000003, 219.99999999999926, 1.9999999999999494, 40.0000000000003, 28.300000000000153, -13.600000000000062, 183.99999999999918, 40.0000000000003, -4.400000000000029, 61.9000000000002, -1.1000000000000485, 36.70000000000025, 36.70000000000025, 35.600000000000236, -23.69999999999977, 34.50000000000022, 143.49999999999977, 200.29999999999964, 33.400000000000205, 65.90000000000009, 134.49999999999935, 40.0000000000003, -23.800000000000004, -5.399999999999861, 100.29999999999953, 40.0000000000003, 27.50000000000012, 37.80000000000027, -39.399999999999764, 212.9999999999993, 38.90000000000028, 35.600000000000236, 36.10000000000024, 215.59999999999928, 181.2, 30.100000000000144, 40.0000000000003, 30.100000000000147, 31.200000000000166, 153.39999999999932, 40.0000000000003, 219.99999999999926, 40.0000000000003, 43.60000000000035, -17.399999999999963, 28.800000000000125, 111.69999999999935, 101.39999999999979, 40.0000000000003, 37.80000000000027, 153.99999999999983, 197.49999999999937, 220.49999999999994, 32.800000000000196, 192.0999999999994, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 20.899999999999988, 35.600000000000236, 219.99999999999926, -1.9000000000000443, 219.99999999999926, -47.39999999999975, 177.49999999999943, 157.99999999999952, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999989, -9.399999999999855, -0.9999999999999846, -76.60000000000073, -191.8, -180.99999999999997, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -295.0, 87.19999999999987, 173.0, 20.000000000000014, 20.000000000000014, 54.20000000000015, -15.699999999999747, 74.90000000000003, -258.1, 200.0, 100.9999999999998, 105.79999999999986, 20.000000000000014, -36.99999999999977, 20.000000000000014, 20.000000000000014, -150.40000000000003, -284.5, 10.399999999999968, 74.89999999999998, 20.000000000000014, 57.20000000000009, 20.000000000000014, 179.0, 20.000000000000014, -237.40000000000015, 15.799999999999963, 20.000000000000014, 20.000000000000014, 145.99999999999972, -49.29999999999977, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -355.9, 71.3000000000001, -362.20000000000005, -285.4000000000001, 116.0, -212.8000000000002, -283.29999999999984, 20.000000000000014, 20.000000000000014, -174.70000000000036, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000015, 20.000000000000014, 200.0, 20.000000000000014, -376.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.500000000000114, -176.19999999999996, -223.60000000000022, 20.000000000000014, 108.1999999999999, 75.79999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000018, 91.0999999999998, -206.2000000000003, -270.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 13.699999999999964, 20.000000000000014, 11.599999999999966, -319.8999999999999, -14.799999999999807, 9.499999999999964, 20.000000000000014, 20.000000000000014, 123.50000000000006, -54.7, 118.99999999999983, 20.000000000000014, 7.399999999999965, -101.50000000000051, 79.40000000000002, 20.000000000000014, 105.49999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, -326.8, 20.000000000000014, -285.40000000000003, 80.30000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999847, 20.000000000000014, 15.799999999999963, -258.40000000000015, 20.000000000000014, 185.0, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999968, 20.000000000000014, -10.899999999999835, 200.0, 11.599999999999964, -383.2, 187.4, 9.499999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 105.79999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, -150.40000000000023, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.29999999999978, 7.399999999999965, -22.6000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -360.0999999999998, 172.0999999999999, 177.5, 20.000000000000014, -40.60000000000025, 154.10000000000005, 20.000000000000014, 3.7999999999999656, 172.1, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.899999999999743, 15.799999999999963, 20.000000000000014, 11.599999999999964, 20.000000000000014, 200.0, 27.20000000000013, -339.10000000000014, 20.000000000000014, 200.0, -316.89999999999986, 9.499999999999964, 20.000000000000014, 156.49999999999997, 20.000000000000014, 133.99999999999997, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 124.0, 89.0, 109.0, 0.0, 10.0, 0.0, 103.0, 150.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 149.0, 7.0, 0.0, 0.0, 2.0, 5.0, 20.0, 20.0, 49.0, 70.0, 94.0, 123.0, 15.0, 13.0, 11.0, 3.0, 6.0, 1.0, 108.0, 111.0, 0.0, 0.0, 17.0, 32.0, 0.0, 0.0, 0.0, 1.0, 152.0, 172.0, 177.0, 187.0, 126.0, 107.0, 94.0, 146.0, 91.0, 72.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 187.0, 0.0, 0.0, 90.0, 57.0, 92.0, 98.0, 0.0, 0.0, 0.0, 0.0, 128.0, 97.0, 74.0, 103.0, 110.0, 139.0, 3.0, 0.0, 0.0, 3.0, 4.0, 0.0, 171.0, 140.0, 5.0, 0.0, 0.0, 0.0, 54.0, 82.0, 0.0, 6.0, 62.0, 26.0, 0.0, 9.0, 0.0, 0.0, 119.0, 164.0, 106.0, 154.0, 0.0, 0.0, 0.0, 0.0, 11.0, 8.0, 0.0, 2.0, 74.0, 125.0, 5.0, 3.0, 1.0, 0.0, 0.0, 4.0, 11.0, 16.0, 4.0, 0.0, 186.0, 191.0, 5.0, 4.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 100.0, 2.0, 12.0, 6.0, 0.0, 47.0, 57.0, 0.0, 0.0, 0.0, 2.0, 163.0, 179.0, 0.0, 0.0, 64.0, 43.0, 9.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 9.0, 0.0, 4.0, 0.0, 0.0, 141.0, 169.0, 0.0, 0.0, 97.0, 163.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8306679026727346, "mean_inference_ms": 2.365920239398138, "mean_action_processing_ms": 0.3833097470704949, "mean_env_wait_ms": 0.30319799439757034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004306435585021973, "StateBufferConnector_ms": 0.0047380924224853516, "ViewRequirementAgentConnector_ms": 0.11568427085876465}, "num_episodes": 18, "episode_return_max": 300.9999999999998, "episode_return_min": -283.60000000000014, "episode_return_mean": 67.48299999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.03802323074973, "num_env_steps_trained_throughput_per_sec": 301.03802323074973, "timesteps_total": 508000, "num_env_steps_sampled_lifetime": 508000, "num_agent_steps_sampled_lifetime": 2032000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2032000, "timers": {"training_iteration_time_ms": 13059.609, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13059.56, "sample_time_ms": 1820.465, "learn_time_ms": 11220.731, "learn_throughput": 356.483, "synch_weights_time_ms": 14.611}, "counters": {"num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "done": false, "training_iteration": 127, "trial_id": "04dec_00002", "date": "2024-08-13_16-51-25", "timestamp": 1723582285, "time_this_iter_s": 13.325383186340332, "time_total_s": 1713.8509855270386, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b061af70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1713.8509855270386, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 63.96842105263157, "ram_util_percent": 83.65789473684211}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.805755598744545, "cur_kl_coeff": 4.143885234952902e-12, "cur_lr": 0.00010000000000000003, "total_loss": 1.0265261945428041, "policy_loss": -0.0018949347358472922, "vf_loss": 1.0284211293335945, "vf_explained_var": 0.0007393814899303295, "kl": 0.0037745391445008574, "entropy": 0.25390540225007546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 240975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.825776491830588, "cur_kl_coeff": 0.0007135226862601487, "cur_lr": 0.00010000000000000003, "total_loss": 2.1365921053306134, "policy_loss": -0.008435146311771065, "vf_loss": 2.1450086794517658, "vf_explained_var": 0.09653011765429582, "kl": 0.026030429890726545, "entropy": 0.3597327345105075, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 240975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "env_runners": {"episode_reward_max": 311.6, "episode_reward_min": -283.60000000000014, "episode_reward_mean": 72.648, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 4.09399999999999, "predator_policy": 32.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 38.90000000000028, 39.40000000000005, -283.60000000000014, 136.19999999999987, -23.299999999999763, 8.299999999999976, 32.30000000000018, 40.0000000000003, 74.20000000000003, 219.99999999999926, 1.9999999999999494, 40.0000000000003, 28.300000000000153, -13.600000000000062, 183.99999999999918, 40.0000000000003, -4.400000000000029, 61.9000000000002, -1.1000000000000485, 36.70000000000025, 36.70000000000025, 35.600000000000236, -23.69999999999977, 34.50000000000022, 143.49999999999977, 200.29999999999964, 33.400000000000205, 65.90000000000009, 134.49999999999935, 40.0000000000003, -23.800000000000004, -5.399999999999861, 100.29999999999953, 40.0000000000003, 27.50000000000012, 37.80000000000027, -39.399999999999764, 212.9999999999993, 38.90000000000028, 35.600000000000236, 36.10000000000024, 215.59999999999928, 181.2, 30.100000000000144, 40.0000000000003, 30.100000000000147, 31.200000000000166, 153.39999999999932, 40.0000000000003, 219.99999999999926, 40.0000000000003, 43.60000000000035, -17.399999999999963, 28.800000000000125, 111.69999999999935, 101.39999999999979, 40.0000000000003, 37.80000000000027, 153.99999999999983, 197.49999999999937, 220.49999999999994, 32.800000000000196, 192.0999999999994, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 20.899999999999988, 35.600000000000236, 219.99999999999926, -1.9000000000000443, 219.99999999999926, -47.39999999999975, 177.49999999999943, 157.99999999999952, 40.0000000000003, 49.00000000000045, 23.500000000000032, 32.30000000000018, 219.99999999999926, 40.0000000000003, 35.600000000000236, 197.99999999999937, 189.6, 38.90000000000028, 40.0000000000003, 198.69999999999936, 311.6, 40.0000000000003, 162.19999999999993, 40.0000000000003, 31.200000000000166, 133.0999999999997, 40.0000000000003, 40.0000000000003, 34.50000000000022, 162.39999999999918, 37.80000000000027, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -355.9, 71.3000000000001, -362.20000000000005, -285.4000000000001, 116.0, -212.8000000000002, -283.29999999999984, 20.000000000000014, 20.000000000000014, -174.70000000000036, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 54.20000000000015, 20.000000000000014, 200.0, 20.000000000000014, -376.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.500000000000114, -176.19999999999996, -223.60000000000022, 20.000000000000014, 108.1999999999999, 75.79999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000018, 91.0999999999998, -206.2000000000003, -270.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 13.699999999999964, 20.000000000000014, 11.599999999999966, -319.8999999999999, -14.799999999999807, 9.499999999999964, 20.000000000000014, 20.000000000000014, 123.50000000000006, -54.7, 118.99999999999983, 20.000000000000014, 7.399999999999965, -101.50000000000051, 79.40000000000002, 20.000000000000014, 105.49999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, -326.8, 20.000000000000014, -285.40000000000003, 80.30000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999847, 20.000000000000014, 15.799999999999963, -258.40000000000015, 20.000000000000014, 185.0, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999968, 20.000000000000014, -10.899999999999835, 200.0, 11.599999999999964, -383.2, 187.4, 9.499999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 105.79999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, -150.40000000000023, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.29999999999978, 7.399999999999965, -22.6000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -360.0999999999998, 172.0999999999999, 177.5, 20.000000000000014, -40.60000000000025, 154.10000000000005, 20.000000000000014, 3.7999999999999656, 172.1, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.899999999999743, 15.799999999999963, 20.000000000000014, 11.599999999999964, 20.000000000000014, 200.0, 27.20000000000013, -339.10000000000014, 20.000000000000014, 200.0, -316.89999999999986, 9.499999999999964, 20.000000000000014, 156.49999999999997, 20.000000000000014, 133.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, -11.499999999999819, 5.299999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 167.0, 20.000000000000014, -368.5, 199.1, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 170.0, 116.0, 167.6, 20.000000000000014, 20.000000000000014, 171.79999999999998, -106.60000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 16.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 142.39999999999978, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 1.0, 152.0, 172.0, 177.0, 187.0, 126.0, 107.0, 94.0, 146.0, 91.0, 72.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 171.0, 187.0, 0.0, 0.0, 90.0, 57.0, 92.0, 98.0, 0.0, 0.0, 0.0, 0.0, 128.0, 97.0, 74.0, 103.0, 110.0, 139.0, 3.0, 0.0, 0.0, 3.0, 4.0, 0.0, 171.0, 140.0, 5.0, 0.0, 0.0, 0.0, 54.0, 82.0, 0.0, 6.0, 62.0, 26.0, 0.0, 9.0, 0.0, 0.0, 119.0, 164.0, 106.0, 154.0, 0.0, 0.0, 0.0, 0.0, 11.0, 8.0, 0.0, 2.0, 74.0, 125.0, 5.0, 3.0, 1.0, 0.0, 0.0, 4.0, 11.0, 16.0, 4.0, 0.0, 186.0, 191.0, 5.0, 4.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 100.0, 2.0, 12.0, 6.0, 0.0, 47.0, 57.0, 0.0, 0.0, 0.0, 2.0, 163.0, 179.0, 0.0, 0.0, 64.0, 43.0, 9.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 9.0, 0.0, 4.0, 0.0, 0.0, 141.0, 169.0, 0.0, 0.0, 97.0, 163.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 174.0, 185.0, 1.0, 0.0, 0.0, 0.0, 4.0, 11.0, 28.0, 0.0, 0.0, 0.0, 55.0, 42.0, 0.0, 0.0, 0.0, 8.0, 41.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8300180065800604, "mean_inference_ms": 2.365987132173564, "mean_action_processing_ms": 0.3827182792440434, "mean_env_wait_ms": 0.30310463918132247, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004410743713378906, "StateBufferConnector_ms": 0.006163120269775391, "ViewRequirementAgentConnector_ms": 0.11678695678710938}, "num_episodes": 23, "episode_return_max": 311.6, "episode_return_min": -283.60000000000014, "episode_return_mean": 72.648, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.83127624025275, "num_env_steps_trained_throughput_per_sec": 305.83127624025275, "timesteps_total": 512000, "num_env_steps_sampled_lifetime": 512000, "num_agent_steps_sampled_lifetime": 2048000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2048000, "timers": {"training_iteration_time_ms": 13107.254, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13107.206, "sample_time_ms": 1807.534, "learn_time_ms": 11281.528, "learn_throughput": 354.562, "synch_weights_time_ms": 14.353}, "counters": {"num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "done": false, "training_iteration": 128, "trial_id": "04dec_00002", "date": "2024-08-13_16-51-38", "timestamp": 1723582298, "time_this_iter_s": 13.168025016784668, "time_total_s": 1727.0190105438232, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0631e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1727.0190105438232, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 66.99473684210525, "ram_util_percent": 83.63157894736842}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.780122858400225, "cur_kl_coeff": 2.071942617476451e-12, "cur_lr": 0.00010000000000000003, "total_loss": 1.2923211879200405, "policy_loss": -0.0016307377708563336, "vf_loss": 1.2939519246576956, "vf_explained_var": 0.0026229767572312126, "kl": 0.003167151874370132, "entropy": 0.2084756829908916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 242865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.535548683906358, "cur_kl_coeff": 0.0010702840293902221, "cur_lr": 0.00010000000000000003, "total_loss": 3.2212645674508718, "policy_loss": 0.0009162160733014975, "vf_loss": 3.220341478895258, "vf_explained_var": 0.24549587501419914, "kl": 0.0064130271450363865, "entropy": 0.36022813039481955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 242865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "env_runners": {"episode_reward_max": 311.6, "episode_reward_min": -47.39999999999975, "episode_reward_mean": 89.55899999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 22.974499999999992, "predator_policy": 21.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.600000000000236, -23.69999999999977, 34.50000000000022, 143.49999999999977, 200.29999999999964, 33.400000000000205, 65.90000000000009, 134.49999999999935, 40.0000000000003, -23.800000000000004, -5.399999999999861, 100.29999999999953, 40.0000000000003, 27.50000000000012, 37.80000000000027, -39.399999999999764, 212.9999999999993, 38.90000000000028, 35.600000000000236, 36.10000000000024, 215.59999999999928, 181.2, 30.100000000000144, 40.0000000000003, 30.100000000000147, 31.200000000000166, 153.39999999999932, 40.0000000000003, 219.99999999999926, 40.0000000000003, 43.60000000000035, -17.399999999999963, 28.800000000000125, 111.69999999999935, 101.39999999999979, 40.0000000000003, 37.80000000000027, 153.99999999999983, 197.49999999999937, 220.49999999999994, 32.800000000000196, 192.0999999999994, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 20.899999999999988, 35.600000000000236, 219.99999999999926, -1.9000000000000443, 219.99999999999926, -47.39999999999975, 177.49999999999943, 157.99999999999952, 40.0000000000003, 49.00000000000045, 23.500000000000032, 32.30000000000018, 219.99999999999926, 40.0000000000003, 35.600000000000236, 197.99999999999937, 189.6, 38.90000000000028, 40.0000000000003, 198.69999999999936, 311.6, 40.0000000000003, 162.19999999999993, 40.0000000000003, 31.200000000000166, 133.0999999999997, 40.0000000000003, 40.0000000000003, 34.50000000000022, 162.39999999999918, 37.80000000000027, 37.80000000000027, 33.400000000000205, 44.50000000000036, 40.0000000000003, 40.0000000000003, 118.39999999999976, 177.09999999999948, 40.0000000000003, 40.0000000000003, 30.700000000000163, 40.0000000000003, 40.0000000000003, 212.79999999999922, 219.99999999999926, 77.99999999999957, 219.99999999999926, 24.900000000000063, 168.99999999999952, 232.1, 40.0000000000003, 205.99999999999932, 171.09999999999948, 205.99999999999932], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 11.599999999999966, -319.8999999999999, -14.799999999999807, 9.499999999999964, 20.000000000000014, 20.000000000000014, 123.50000000000006, -54.7, 118.99999999999983, 20.000000000000014, 7.399999999999965, -101.50000000000051, 79.40000000000002, 20.000000000000014, 105.49999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, -326.8, 20.000000000000014, -285.40000000000003, 80.30000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999847, 20.000000000000014, 15.799999999999963, -258.40000000000015, 20.000000000000014, 185.0, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999968, 20.000000000000014, -10.899999999999835, 200.0, 11.599999999999964, -383.2, 187.4, 9.499999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 105.79999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, -150.40000000000023, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.29999999999978, 7.399999999999965, -22.6000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -360.0999999999998, 172.0999999999999, 177.5, 20.000000000000014, -40.60000000000025, 154.10000000000005, 20.000000000000014, 3.7999999999999656, 172.1, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.899999999999743, 15.799999999999963, 20.000000000000014, 11.599999999999964, 20.000000000000014, 200.0, 27.20000000000013, -339.10000000000014, 20.000000000000014, 200.0, -316.89999999999986, 9.499999999999964, 20.000000000000014, 156.49999999999997, 20.000000000000014, 133.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, -11.499999999999819, 5.299999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 167.0, 20.000000000000014, -368.5, 199.1, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 170.0, 116.0, 167.6, 20.000000000000014, 20.000000000000014, 171.79999999999998, -106.60000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 16.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 142.39999999999978, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.400000000000006, -61.90000000000071, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999898, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 200.0, 20.000000000000014, 20.000000000000014, -175.0, 20.000000000000014, 200.0, -12.099999999999817, 20.000000000000014, 119.0, 20.000000000000014, -118.9, 182.0, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 127.1, 20.000000000000014, 20.000000000000014, 179.0], "policy_predator_policy_reward": [4.0, 0.0, 171.0, 140.0, 5.0, 0.0, 0.0, 0.0, 54.0, 82.0, 0.0, 6.0, 62.0, 26.0, 0.0, 9.0, 0.0, 0.0, 119.0, 164.0, 106.0, 154.0, 0.0, 0.0, 0.0, 0.0, 11.0, 8.0, 0.0, 2.0, 74.0, 125.0, 5.0, 3.0, 1.0, 0.0, 0.0, 4.0, 11.0, 16.0, 4.0, 0.0, 186.0, 191.0, 5.0, 4.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 100.0, 2.0, 12.0, 6.0, 0.0, 47.0, 57.0, 0.0, 0.0, 0.0, 2.0, 163.0, 179.0, 0.0, 0.0, 64.0, 43.0, 9.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 9.0, 0.0, 4.0, 0.0, 0.0, 141.0, 169.0, 0.0, 0.0, 97.0, 163.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 174.0, 185.0, 1.0, 0.0, 0.0, 0.0, 4.0, 11.0, 28.0, 0.0, 0.0, 0.0, 55.0, 42.0, 0.0, 0.0, 0.0, 8.0, 41.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 18.0, 10.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 113.0, 120.0, 0.0, 0.0, 0.0, 17.0, 11.0, 19.0, 100.0, 69.0, 0.0, 0.0, 7.0, 0.0, 17.0, 7.0, 6.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8303314284707622, "mean_inference_ms": 2.3657852881329022, "mean_action_processing_ms": 0.38249604920227376, "mean_env_wait_ms": 0.3031953739587408, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02100348472595215, "StateBufferConnector_ms": 0.006553053855895996, "ViewRequirementAgentConnector_ms": 0.11498427391052246}, "num_episodes": 22, "episode_return_max": 311.6, "episode_return_min": -47.39999999999975, "episode_return_mean": 89.55899999999995, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 302.6256081678172, "num_env_steps_trained_throughput_per_sec": 302.6256081678172, "timesteps_total": 516000, "num_env_steps_sampled_lifetime": 516000, "num_agent_steps_sampled_lifetime": 2064000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2064000, "timers": {"training_iteration_time_ms": 13113.782, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13113.735, "sample_time_ms": 1855.442, "learn_time_ms": 11240.952, "learn_throughput": 355.842, "synch_weights_time_ms": 14.554}, "counters": {"num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "done": false, "training_iteration": 129, "trial_id": "04dec_00002", "date": "2024-08-13_16-51-51", "timestamp": 1723582311, "time_this_iter_s": 13.26719880104065, "time_total_s": 1740.286209344864, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06311f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1740.286209344864, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 67.03684210526316, "ram_util_percent": 83.80000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9217216654311097, "cur_kl_coeff": 1.0359713087382255e-12, "cur_lr": 0.00010000000000000003, "total_loss": 1.4046448467269776, "policy_loss": -0.0015660132377571057, "vf_loss": 1.406210854507628, "vf_explained_var": 0.002046467135192225, "kl": 0.004940397943942073, "entropy": 0.2104815541121064, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 244755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.256584015267865, "cur_kl_coeff": 0.0010702840293902221, "cur_lr": 0.00010000000000000003, "total_loss": 3.8487951687404087, "policy_loss": -0.0025190043021375364, "vf_loss": 3.8513063628837547, "vf_explained_var": 0.17803954992975507, "kl": 0.007285909234693914, "entropy": 0.26727008605917923, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 244755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "env_runners": {"episode_reward_max": 383.3, "episode_reward_min": -57.899999999999764, "episode_reward_mean": 96.54299999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 28.761499999999998, "predator_policy": 19.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.600000000000236, 36.10000000000024, 215.59999999999928, 181.2, 30.100000000000144, 40.0000000000003, 30.100000000000147, 31.200000000000166, 153.39999999999932, 40.0000000000003, 219.99999999999926, 40.0000000000003, 43.60000000000035, -17.399999999999963, 28.800000000000125, 111.69999999999935, 101.39999999999979, 40.0000000000003, 37.80000000000027, 153.99999999999983, 197.49999999999937, 220.49999999999994, 32.800000000000196, 192.0999999999994, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 20.899999999999988, 35.600000000000236, 219.99999999999926, -1.9000000000000443, 219.99999999999926, -47.39999999999975, 177.49999999999943, 157.99999999999952, 40.0000000000003, 49.00000000000045, 23.500000000000032, 32.30000000000018, 219.99999999999926, 40.0000000000003, 35.600000000000236, 197.99999999999937, 189.6, 38.90000000000028, 40.0000000000003, 198.69999999999936, 311.6, 40.0000000000003, 162.19999999999993, 40.0000000000003, 31.200000000000166, 133.0999999999997, 40.0000000000003, 40.0000000000003, 34.50000000000022, 162.39999999999918, 37.80000000000027, 37.80000000000027, 33.400000000000205, 44.50000000000036, 40.0000000000003, 40.0000000000003, 118.39999999999976, 177.09999999999948, 40.0000000000003, 40.0000000000003, 30.700000000000163, 40.0000000000003, 40.0000000000003, 212.79999999999922, 219.99999999999926, 77.99999999999957, 219.99999999999926, 24.900000000000063, 168.99999999999952, 232.1, 40.0000000000003, 205.99999999999932, 171.09999999999948, 205.99999999999932, 31.300000000000164, 40.0000000000003, 207.99999999999932, 239.9, 241.1, 40.0000000000003, 22.1, 383.3, 117.99999999999979, 36.800000000000246, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 203.29999999999933, -57.899999999999764, 40.0000000000003, 50.90000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 11.599999999999968, 20.000000000000014, -10.899999999999835, 200.0, 11.599999999999964, -383.2, 187.4, 9.499999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 105.79999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, -150.40000000000023, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.29999999999978, 7.399999999999965, -22.6000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -360.0999999999998, 172.0999999999999, 177.5, 20.000000000000014, -40.60000000000025, 154.10000000000005, 20.000000000000014, 3.7999999999999656, 172.1, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.899999999999743, 15.799999999999963, 20.000000000000014, 11.599999999999964, 20.000000000000014, 200.0, 27.20000000000013, -339.10000000000014, 20.000000000000014, 200.0, -316.89999999999986, 9.499999999999964, 20.000000000000014, 156.49999999999997, 20.000000000000014, 133.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, -11.499999999999819, 5.299999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 167.0, 20.000000000000014, -368.5, 199.1, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 170.0, 116.0, 167.6, 20.000000000000014, 20.000000000000014, 171.79999999999998, -106.60000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 16.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 142.39999999999978, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.400000000000006, -61.90000000000071, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999898, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 200.0, 20.000000000000014, 20.000000000000014, -175.0, 20.000000000000014, 200.0, -12.099999999999817, 20.000000000000014, 119.0, 20.000000000000014, -118.9, 182.0, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 127.1, 20.000000000000014, 20.000000000000014, 179.0, 17.899999999999988, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 56.0, 119.9, -217.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, -391.0, 199.1, 200.0, 176.3, -79.0, 20.000000000000014, 20.000000000000014, -8.199999999999905, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 14.299999999999969, -160.60000000000025, 13.699999999999966, 20.000000000000014, 20.000000000000014, 11.599999999999964, 35.30000000000026], "policy_predator_policy_reward": [0.0, 4.0, 11.0, 16.0, 4.0, 0.0, 186.0, 191.0, 5.0, 4.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 100.0, 2.0, 12.0, 6.0, 0.0, 47.0, 57.0, 0.0, 0.0, 0.0, 2.0, 163.0, 179.0, 0.0, 0.0, 64.0, 43.0, 9.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 9.0, 0.0, 4.0, 0.0, 0.0, 141.0, 169.0, 0.0, 0.0, 97.0, 163.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 174.0, 185.0, 1.0, 0.0, 0.0, 0.0, 4.0, 11.0, 28.0, 0.0, 0.0, 0.0, 55.0, 42.0, 0.0, 0.0, 0.0, 8.0, 41.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 18.0, 10.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 113.0, 120.0, 0.0, 0.0, 0.0, 17.0, 11.0, 19.0, 100.0, 69.0, 0.0, 0.0, 7.0, 0.0, 17.0, 7.0, 6.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 6.0, 44.0, 20.0, 126.0, 133.0, 0.0, 0.0, 197.0, 17.0, 0.0, 7.0, 84.0, 93.0, 16.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 89.0, 0.0, 0.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8310890474068928, "mean_inference_ms": 2.370974388338236, "mean_action_processing_ms": 0.3824548364536007, "mean_env_wait_ms": 0.3035720925209937, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021296143531799316, "StateBufferConnector_ms": 0.011055469512939453, "ViewRequirementAgentConnector_ms": 0.15735971927642822}, "num_episodes": 18, "episode_return_max": 383.3, "episode_return_min": -57.899999999999764, "episode_return_mean": 96.54299999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 299.6809119042168, "num_env_steps_trained_throughput_per_sec": 299.6809119042168, "timesteps_total": 520000, "num_env_steps_sampled_lifetime": 520000, "num_agent_steps_sampled_lifetime": 2080000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2080000, "timers": {"training_iteration_time_ms": 13172.582, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13172.47, "sample_time_ms": 1947.68, "learn_time_ms": 11206.722, "learn_throughput": 356.929, "synch_weights_time_ms": 15.137}, "counters": {"num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "done": false, "training_iteration": 130, "trial_id": "04dec_00002", "date": "2024-08-13_16-52-05", "timestamp": 1723582325, "time_this_iter_s": 13.44465184211731, "time_total_s": 1753.7308611869812, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b044a8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1753.7308611869812, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 66.7, "ram_util_percent": 83.53157894736843}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1566313515501048, "cur_kl_coeff": 5.179856543691128e-13, "cur_lr": 0.00010000000000000003, "total_loss": 0.9348762607605999, "policy_loss": -0.0017941378586723534, "vf_loss": 0.9366703991852109, "vf_explained_var": 0.008666785494991081, "kl": 0.0036234391074538744, "entropy": 0.1653392450085708, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 246645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.383461510756659, "cur_kl_coeff": 0.0010702840293902221, "cur_lr": 0.00010000000000000003, "total_loss": 3.725281377948781, "policy_loss": -0.01125521234313036, "vf_loss": 3.7364765726069296, "vf_explained_var": 0.3001730339867728, "kl": 0.056081069521033824, "entropy": 0.3462480896995181, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 246645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -57.899999999999764, "episode_reward_mean": 108.40499999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 35.95250000000001, "predator_policy": 18.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 153.99999999999983, 197.49999999999937, 220.49999999999994, 32.800000000000196, 192.0999999999994, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 20.899999999999988, 35.600000000000236, 219.99999999999926, -1.9000000000000443, 219.99999999999926, -47.39999999999975, 177.49999999999943, 157.99999999999952, 40.0000000000003, 49.00000000000045, 23.500000000000032, 32.30000000000018, 219.99999999999926, 40.0000000000003, 35.600000000000236, 197.99999999999937, 189.6, 38.90000000000028, 40.0000000000003, 198.69999999999936, 311.6, 40.0000000000003, 162.19999999999993, 40.0000000000003, 31.200000000000166, 133.0999999999997, 40.0000000000003, 40.0000000000003, 34.50000000000022, 162.39999999999918, 37.80000000000027, 37.80000000000027, 33.400000000000205, 44.50000000000036, 40.0000000000003, 40.0000000000003, 118.39999999999976, 177.09999999999948, 40.0000000000003, 40.0000000000003, 30.700000000000163, 40.0000000000003, 40.0000000000003, 212.79999999999922, 219.99999999999926, 77.99999999999957, 219.99999999999926, 24.900000000000063, 168.99999999999952, 232.1, 40.0000000000003, 205.99999999999932, 171.09999999999948, 205.99999999999932, 31.300000000000164, 40.0000000000003, 207.99999999999932, 239.9, 241.1, 40.0000000000003, 22.1, 383.3, 117.99999999999979, 36.800000000000246, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 203.29999999999933, -57.899999999999764, 40.0000000000003, 50.90000000000048, 18.399999999999963, 212.79999999999927, 39.800000000000296, -8.799999999999637, 213.69999999999928, 40.0000000000003, 400.0, 40.0000000000003, 40.0000000000003, 240.0, 206.1999999999993, -24.19999999999999, 207.89999999999932, 219.99999999999926, 394.0, 37.80000000000027, 215.99999999999926, 54.00000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 15.799999999999963, -360.0999999999998, 172.0999999999999, 177.5, 20.000000000000014, -40.60000000000025, 154.10000000000005, 20.000000000000014, 3.7999999999999656, 172.1, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.899999999999743, 15.799999999999963, 20.000000000000014, 11.599999999999964, 20.000000000000014, 200.0, 27.20000000000013, -339.10000000000014, 20.000000000000014, 200.0, -316.89999999999986, 9.499999999999964, 20.000000000000014, 156.49999999999997, 20.000000000000014, 133.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, -11.499999999999819, 5.299999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 167.0, 20.000000000000014, -368.5, 199.1, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 170.0, 116.0, 167.6, 20.000000000000014, 20.000000000000014, 171.79999999999998, -106.60000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 16.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 142.39999999999978, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.400000000000006, -61.90000000000071, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999898, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 200.0, 20.000000000000014, 20.000000000000014, -175.0, 20.000000000000014, 200.0, -12.099999999999817, 20.000000000000014, 119.0, 20.000000000000014, -118.9, 182.0, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 127.1, 20.000000000000014, 20.000000000000014, 179.0, 17.899999999999988, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 56.0, 119.9, -217.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, -391.0, 199.1, 200.0, 176.3, -79.0, 20.000000000000014, 20.000000000000014, -8.199999999999905, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 14.299999999999969, -160.60000000000025, 13.699999999999966, 20.000000000000014, 20.000000000000014, 11.599999999999964, 35.30000000000026, -34.59999999999978, 20.000000000000014, 20.000000000000014, 192.8, 15.799999999999963, 20.000000000000014, -21.69999999999976, -24.099999999999746, 193.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.0, 80.0, 180.2, 20.000000000000014, -100.0, -86.19999999999999, 17.899999999999988, 185.0, 200.0, 20.000000000000014, 191.0, 200.0, 20.000000000000014, 15.799999999999962, 20.000000000000014, 194.0, 20.000000000000014, -112.0], "policy_predator_policy_reward": [0.0, 2.0, 163.0, 179.0, 0.0, 0.0, 64.0, 43.0, 9.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 9.0, 0.0, 4.0, 0.0, 0.0, 141.0, 169.0, 0.0, 0.0, 97.0, 163.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 174.0, 185.0, 1.0, 0.0, 0.0, 0.0, 4.0, 11.0, 28.0, 0.0, 0.0, 0.0, 55.0, 42.0, 0.0, 0.0, 0.0, 8.0, 41.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 18.0, 10.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 113.0, 120.0, 0.0, 0.0, 0.0, 17.0, 11.0, 19.0, 100.0, 69.0, 0.0, 0.0, 7.0, 0.0, 17.0, 7.0, 6.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 6.0, 44.0, 20.0, 126.0, 133.0, 0.0, 0.0, 197.0, 17.0, 0.0, 7.0, 84.0, 93.0, 16.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 89.0, 0.0, 0.0, 4.0, 0.0, 19.0, 14.0, 0.0, 0.0, 2.0, 2.0, 23.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 25.0, 0.0, 6.0, 84.0, 78.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 98.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8321554008815282, "mean_inference_ms": 2.3750800383474937, "mean_action_processing_ms": 0.38258927098530776, "mean_env_wait_ms": 0.3040074737189136, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02108168601989746, "StateBufferConnector_ms": 0.010997653007507324, "ViewRequirementAgentConnector_ms": 0.16442334651947021}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -57.899999999999764, "episode_return_mean": 108.40499999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 302.4101582837326, "num_env_steps_trained_throughput_per_sec": 302.4101582837326, "timesteps_total": 524000, "num_env_steps_sampled_lifetime": 524000, "num_agent_steps_sampled_lifetime": 2096000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2096000, "timers": {"training_iteration_time_ms": 13233.302, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13233.189, "sample_time_ms": 1992.637, "learn_time_ms": 11222.228, "learn_throughput": 356.435, "synch_weights_time_ms": 15.278}, "counters": {"num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "done": false, "training_iteration": 131, "trial_id": "04dec_00002", "date": "2024-08-13_16-52-18", "timestamp": 1723582338, "time_this_iter_s": 13.292763948440552, "time_total_s": 1767.0236251354218, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b02bcd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1767.0236251354218, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 68.4, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.502035385612694, "cur_kl_coeff": 2.589928271845564e-13, "cur_lr": 0.00010000000000000003, "total_loss": 0.33028883880408355, "policy_loss": -0.0018704903245504413, "vf_loss": 0.33215932969797574, "vf_explained_var": 0.005304307754708346, "kl": 0.0032108311913008453, "entropy": 0.1907891087825336, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 248535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.66315559716452, "cur_kl_coeff": 0.0016054260440853335, "cur_lr": 0.00010000000000000003, "total_loss": 2.2584358232992665, "policy_loss": -0.0014120970786150012, "vf_loss": 2.2598352345209274, "vf_explained_var": 0.4810507856348835, "kl": 0.007900798923457207, "entropy": 0.5031930909112647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 248535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -134.3000000000005, "episode_reward_mean": 105.11699999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 37.968500000000006, "predator_policy": 14.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 35.600000000000236, 197.99999999999937, 189.6, 38.90000000000028, 40.0000000000003, 198.69999999999936, 311.6, 40.0000000000003, 162.19999999999993, 40.0000000000003, 31.200000000000166, 133.0999999999997, 40.0000000000003, 40.0000000000003, 34.50000000000022, 162.39999999999918, 37.80000000000027, 37.80000000000027, 33.400000000000205, 44.50000000000036, 40.0000000000003, 40.0000000000003, 118.39999999999976, 177.09999999999948, 40.0000000000003, 40.0000000000003, 30.700000000000163, 40.0000000000003, 40.0000000000003, 212.79999999999922, 219.99999999999926, 77.99999999999957, 219.99999999999926, 24.900000000000063, 168.99999999999952, 232.1, 40.0000000000003, 205.99999999999932, 171.09999999999948, 205.99999999999932, 31.300000000000164, 40.0000000000003, 207.99999999999932, 239.9, 241.1, 40.0000000000003, 22.1, 383.3, 117.99999999999979, 36.800000000000246, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 203.29999999999933, -57.899999999999764, 40.0000000000003, 50.90000000000048, 18.399999999999963, 212.79999999999927, 39.800000000000296, -8.799999999999637, 213.69999999999928, 40.0000000000003, 400.0, 40.0000000000003, 40.0000000000003, 240.0, 206.1999999999993, -24.19999999999999, 207.89999999999932, 219.99999999999926, 394.0, 37.80000000000027, 215.99999999999926, 54.00000000000013, 124.5999999999998, 39.9000000000003, 40.0000000000003, 40.0000000000003, 211.9999999999993, -35.89999999999967, 40.0000000000003, 191.9999999999994, 40.0000000000003, 61.600000000000485, 79.59999999999937, 210.9999999999993, 37.80000000000027, 215.99999999999926, 212.2999999999993, 28.300000000000125, 219.99999999999926, 40.0000000000003, 38.50000000000028, 40.0000000000003, -134.3000000000005, 40.0000000000003, 193.99999999999937], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 167.0, 20.000000000000014, -368.5, 199.1, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 170.0, 116.0, 167.6, 20.000000000000014, 20.000000000000014, 171.79999999999998, -106.60000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 16.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 142.39999999999978, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.400000000000006, -61.90000000000071, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999898, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 200.0, 20.000000000000014, 20.000000000000014, -175.0, 20.000000000000014, 200.0, -12.099999999999817, 20.000000000000014, 119.0, 20.000000000000014, -118.9, 182.0, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 127.1, 20.000000000000014, 20.000000000000014, 179.0, 17.899999999999988, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 56.0, 119.9, -217.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, -391.0, 199.1, 200.0, 176.3, -79.0, 20.000000000000014, 20.000000000000014, -8.199999999999905, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 14.299999999999969, -160.60000000000025, 13.699999999999966, 20.000000000000014, 20.000000000000014, 11.599999999999964, 35.30000000000026, -34.59999999999978, 20.000000000000014, 20.000000000000014, 192.8, 15.799999999999963, 20.000000000000014, -21.69999999999976, -24.099999999999746, 193.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.0, 80.0, 180.2, 20.000000000000014, -100.0, -86.19999999999999, 17.899999999999988, 185.0, 200.0, 20.000000000000014, 191.0, 200.0, 20.000000000000014, 15.799999999999962, 20.000000000000014, 194.0, 20.000000000000014, -112.0, -2.799999999999993, 85.4, 13.699999999999964, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 190.1, 17.899999999999988, 13.699999999999966, -118.60000000000048, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 26.300000000000114, 35.30000000000024, 57.800000000000225, 21.80000000000004, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 5.299999999999965, 20.000000000000014, -15.699999999999761, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -328.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0], "policy_predator_policy_reward": [0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 174.0, 185.0, 1.0, 0.0, 0.0, 0.0, 4.0, 11.0, 28.0, 0.0, 0.0, 0.0, 55.0, 42.0, 0.0, 0.0, 0.0, 8.0, 41.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 18.0, 10.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 113.0, 120.0, 0.0, 0.0, 0.0, 17.0, 11.0, 19.0, 100.0, 69.0, 0.0, 0.0, 7.0, 0.0, 17.0, 7.0, 6.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 6.0, 44.0, 20.0, 126.0, 133.0, 0.0, 0.0, 197.0, 17.0, 0.0, 7.0, 84.0, 93.0, 16.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 89.0, 0.0, 0.0, 4.0, 0.0, 19.0, 14.0, 0.0, 0.0, 2.0, 2.0, 23.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 25.0, 0.0, 6.0, 84.0, 78.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 98.0, 48.0, 28.0, 14.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 60.0, 9.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 7.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 171.0, 0.0, 0.0, 12.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8341655602819196, "mean_inference_ms": 2.3795784241408824, "mean_action_processing_ms": 0.383120474862155, "mean_env_wait_ms": 0.3045237846266794, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021094799041748047, "StateBufferConnector_ms": 0.011030197143554688, "ViewRequirementAgentConnector_ms": 0.16688752174377441}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -134.3000000000005, "episode_return_mean": 105.11699999999995, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.4842660790334, "num_env_steps_trained_throughput_per_sec": 311.4842660790334, "timesteps_total": 528000, "num_env_steps_sampled_lifetime": 528000, "num_agent_steps_sampled_lifetime": 2112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2112000, "timers": {"training_iteration_time_ms": 13160.735, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13160.623, "sample_time_ms": 1998.779, "learn_time_ms": 11143.389, "learn_throughput": 358.957, "synch_weights_time_ms": 15.636}, "counters": {"num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "done": false, "training_iteration": 132, "trial_id": "04dec_00002", "date": "2024-08-13_16-52-31", "timestamp": 1723582351, "time_this_iter_s": 12.918219804763794, "time_total_s": 1779.9418449401855, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06b71f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1779.9418449401855, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 68.2421052631579, "ram_util_percent": 83.20526315789475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6020148366886787, "cur_kl_coeff": 1.294964135922782e-13, "cur_lr": 0.00010000000000000003, "total_loss": 1.2231158384255, "policy_loss": -0.0012389398007481187, "vf_loss": 1.2243547774496533, "vf_explained_var": 0.002000355058246189, "kl": 0.002350592973493266, "entropy": 0.1254586428758644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 250425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.90037735434121, "cur_kl_coeff": 0.0016054260440853335, "cur_lr": 0.00010000000000000003, "total_loss": 3.364577312696548, "policy_loss": -0.012577864449968926, "vf_loss": 3.377113259217096, "vf_explained_var": 0.0879023550048707, "kl": 0.026114605109582776, "entropy": 0.3764707089731933, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 250425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -150.00000000000048, "episode_reward_mean": 103.91399999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 37.27700000000001, "predator_policy": 14.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 33.400000000000205, 44.50000000000036, 40.0000000000003, 40.0000000000003, 118.39999999999976, 177.09999999999948, 40.0000000000003, 40.0000000000003, 30.700000000000163, 40.0000000000003, 40.0000000000003, 212.79999999999922, 219.99999999999926, 77.99999999999957, 219.99999999999926, 24.900000000000063, 168.99999999999952, 232.1, 40.0000000000003, 205.99999999999932, 171.09999999999948, 205.99999999999932, 31.300000000000164, 40.0000000000003, 207.99999999999932, 239.9, 241.1, 40.0000000000003, 22.1, 383.3, 117.99999999999979, 36.800000000000246, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 203.29999999999933, -57.899999999999764, 40.0000000000003, 50.90000000000048, 18.399999999999963, 212.79999999999927, 39.800000000000296, -8.799999999999637, 213.69999999999928, 40.0000000000003, 400.0, 40.0000000000003, 40.0000000000003, 240.0, 206.1999999999993, -24.19999999999999, 207.89999999999932, 219.99999999999926, 394.0, 37.80000000000027, 215.99999999999926, 54.00000000000013, 124.5999999999998, 39.9000000000003, 40.0000000000003, 40.0000000000003, 211.9999999999993, -35.89999999999967, 40.0000000000003, 191.9999999999994, 40.0000000000003, 61.600000000000485, 79.59999999999937, 210.9999999999993, 37.80000000000027, 215.99999999999926, 212.2999999999993, 28.300000000000125, 219.99999999999926, 40.0000000000003, 38.50000000000028, 40.0000000000003, -134.3000000000005, 40.0000000000003, 193.99999999999937, 40.0000000000003, 219.99999999999926, 59.800000000000466, 342.1, 36.70000000000025, -18.0, 201.99999999999935, 40.0000000000003, 221.59999999999926, 81.69999999999996, -150.00000000000048, 40.0000000000003, 40.0000000000003, 201.99999999999935, 35.600000000000236, 40.90000000000031, 190.9999999999994, 27.900000000000116], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.400000000000006, -61.90000000000071, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999898, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 200.0, 20.000000000000014, 20.000000000000014, -175.0, 20.000000000000014, 200.0, -12.099999999999817, 20.000000000000014, 119.0, 20.000000000000014, -118.9, 182.0, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 127.1, 20.000000000000014, 20.000000000000014, 179.0, 17.899999999999988, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 56.0, 119.9, -217.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, -391.0, 199.1, 200.0, 176.3, -79.0, 20.000000000000014, 20.000000000000014, -8.199999999999905, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 14.299999999999969, -160.60000000000025, 13.699999999999966, 20.000000000000014, 20.000000000000014, 11.599999999999964, 35.30000000000026, -34.59999999999978, 20.000000000000014, 20.000000000000014, 192.8, 15.799999999999963, 20.000000000000014, -21.69999999999976, -24.099999999999746, 193.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.0, 80.0, 180.2, 20.000000000000014, -100.0, -86.19999999999999, 17.899999999999988, 185.0, 200.0, 20.000000000000014, 191.0, 200.0, 20.000000000000014, 15.799999999999962, 20.000000000000014, 194.0, 20.000000000000014, -112.0, -2.799999999999993, 85.4, 13.699999999999964, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 190.1, 17.899999999999988, 13.699999999999966, -118.60000000000048, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 26.300000000000114, 35.30000000000024, 57.800000000000225, 21.80000000000004, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 5.299999999999965, 20.000000000000014, -15.699999999999761, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -328.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.00000000000017, 30.800000000000203, 128.0, 190.1, 20.000000000000014, 13.699999999999964, 173.0, -400.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 23.600000000000065, -106.0, 13.699999999999964, -355.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 11.599999999999971, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 155.0, 20.000000000000014, -3.099999999999972], "policy_predator_policy_reward": [0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 18.0, 10.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 113.0, 120.0, 0.0, 0.0, 0.0, 17.0, 11.0, 19.0, 100.0, 69.0, 0.0, 0.0, 7.0, 0.0, 17.0, 7.0, 6.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 6.0, 44.0, 20.0, 126.0, 133.0, 0.0, 0.0, 197.0, 17.0, 0.0, 7.0, 84.0, 93.0, 16.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 89.0, 0.0, 0.0, 4.0, 0.0, 19.0, 14.0, 0.0, 0.0, 2.0, 2.0, 23.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 25.0, 0.0, 6.0, 84.0, 78.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 98.0, 48.0, 28.0, 14.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 60.0, 9.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 7.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 171.0, 0.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 22.0, 0.0, 3.0, 191.0, 18.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 76.0, 98.0, 5.0, 180.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 2.0, 2.0, 0.0, 0.0, 1.0, 15.0, 0.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8349386589241925, "mean_inference_ms": 2.384053280952402, "mean_action_processing_ms": 0.38271131677457026, "mean_env_wait_ms": 0.3049557170133406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021069645881652832, "StateBufferConnector_ms": 0.00957643985748291, "ViewRequirementAgentConnector_ms": 0.16602075099945068}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -150.00000000000048, "episode_return_mean": 103.91399999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 313.7516218021525, "num_env_steps_trained_throughput_per_sec": 313.7516218021525, "timesteps_total": 532000, "num_env_steps_sampled_lifetime": 532000, "num_agent_steps_sampled_lifetime": 2128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2128000, "timers": {"training_iteration_time_ms": 13063.117, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13063.002, "sample_time_ms": 1993.201, "learn_time_ms": 11049.73, "learn_throughput": 362.0, "synch_weights_time_ms": 17.304}, "counters": {"num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "done": false, "training_iteration": 133, "trial_id": "04dec_00002", "date": "2024-08-13_16-52-44", "timestamp": 1723582364, "time_this_iter_s": 12.794128179550171, "time_total_s": 1792.7359731197357, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06b7dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1792.7359731197357, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 66.75, "ram_util_percent": 83.20555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6121342569865562, "cur_kl_coeff": 6.47482067961391e-14, "cur_lr": 0.00010000000000000003, "total_loss": 0.49408860656792525, "policy_loss": -0.000361000735155016, "vf_loss": 0.49444960785103304, "vf_explained_var": 0.014053020023164295, "kl": 0.0028693328818298544, "entropy": 0.13831802359412587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 252315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.713802075512195, "cur_kl_coeff": 0.0024081390661280016, "cur_lr": 0.00010000000000000003, "total_loss": 2.82939029162523, "policy_loss": -0.0006337741934374053, "vf_loss": 2.8299839844148624, "vf_explained_var": 0.35774541418388406, "kl": 0.016644325593434133, "entropy": 0.42556055461761183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 252315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -150.00000000000048, "episode_reward_mean": 100.42399999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 36.90200000000001, "predator_policy": 13.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.99999999999932, 31.300000000000164, 40.0000000000003, 207.99999999999932, 239.9, 241.1, 40.0000000000003, 22.1, 383.3, 117.99999999999979, 36.800000000000246, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 203.29999999999933, -57.899999999999764, 40.0000000000003, 50.90000000000048, 18.399999999999963, 212.79999999999927, 39.800000000000296, -8.799999999999637, 213.69999999999928, 40.0000000000003, 400.0, 40.0000000000003, 40.0000000000003, 240.0, 206.1999999999993, -24.19999999999999, 207.89999999999932, 219.99999999999926, 394.0, 37.80000000000027, 215.99999999999926, 54.00000000000013, 124.5999999999998, 39.9000000000003, 40.0000000000003, 40.0000000000003, 211.9999999999993, -35.89999999999967, 40.0000000000003, 191.9999999999994, 40.0000000000003, 61.600000000000485, 79.59999999999937, 210.9999999999993, 37.80000000000027, 215.99999999999926, 212.2999999999993, 28.300000000000125, 219.99999999999926, 40.0000000000003, 38.50000000000028, 40.0000000000003, -134.3000000000005, 40.0000000000003, 193.99999999999937, 40.0000000000003, 219.99999999999926, 59.800000000000466, 342.1, 36.70000000000025, -18.0, 201.99999999999935, 40.0000000000003, 221.59999999999926, 81.69999999999996, -150.00000000000048, 40.0000000000003, 40.0000000000003, 201.99999999999935, 35.600000000000236, 40.90000000000031, 190.9999999999994, 27.900000000000116, 54.40000000000052, 400.0, -88.90000000000028, 205.99999999999932, 40.0000000000003, 40.0000000000003, 26.00000000000012, 40.0000000000003, 33.400000000000205, 33.400000000000205, 209.99999999999932, 40.0000000000003, 40.0000000000003, 36.70000000000025, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 338.0, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 179.0, 17.899999999999988, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 56.0, 119.9, -217.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, -391.0, 199.1, 200.0, 176.3, -79.0, 20.000000000000014, 20.000000000000014, -8.199999999999905, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 14.299999999999969, -160.60000000000025, 13.699999999999966, 20.000000000000014, 20.000000000000014, 11.599999999999964, 35.30000000000026, -34.59999999999978, 20.000000000000014, 20.000000000000014, 192.8, 15.799999999999963, 20.000000000000014, -21.69999999999976, -24.099999999999746, 193.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.0, 80.0, 180.2, 20.000000000000014, -100.0, -86.19999999999999, 17.899999999999988, 185.0, 200.0, 20.000000000000014, 191.0, 200.0, 20.000000000000014, 15.799999999999962, 20.000000000000014, 194.0, 20.000000000000014, -112.0, -2.799999999999993, 85.4, 13.699999999999964, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 190.1, 17.899999999999988, 13.699999999999966, -118.60000000000048, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 26.300000000000114, 35.30000000000024, 57.800000000000225, 21.80000000000004, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 5.299999999999965, 20.000000000000014, -15.699999999999761, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -328.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.00000000000017, 30.800000000000203, 128.0, 190.1, 20.000000000000014, 13.699999999999964, 173.0, -400.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 23.600000000000065, -106.0, 13.699999999999964, -355.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 11.599999999999971, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 155.0, 20.000000000000014, -3.099999999999972, 20.000000000000014, 34.40000000000026, 200.0, 200.0, 20.300000000000022, -236.20000000000027, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 152.0, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [6.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 6.0, 44.0, 20.0, 126.0, 133.0, 0.0, 0.0, 197.0, 17.0, 0.0, 7.0, 84.0, 93.0, 16.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 89.0, 0.0, 0.0, 4.0, 0.0, 19.0, 14.0, 0.0, 0.0, 2.0, 2.0, 23.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 25.0, 0.0, 6.0, 84.0, 78.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 98.0, 48.0, 28.0, 14.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 60.0, 9.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 7.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 171.0, 0.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 22.0, 0.0, 3.0, 191.0, 18.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 76.0, 98.0, 5.0, 180.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 2.0, 2.0, 0.0, 0.0, 1.0, 15.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 122.0, 5.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 96.0, 43.0, 0.0, 0.0, 5.0, 1.0, 6.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8360481903499911, "mean_inference_ms": 2.388404136326487, "mean_action_processing_ms": 0.38271748259564153, "mean_env_wait_ms": 0.30539890272062686, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021170616149902344, "StateBufferConnector_ms": 0.009379386901855469, "ViewRequirementAgentConnector_ms": 0.17719411849975586}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -150.00000000000048, "episode_return_mean": 100.42399999999996, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.3084941274268, "num_env_steps_trained_throughput_per_sec": 310.3084941274268, "timesteps_total": 536000, "num_env_steps_sampled_lifetime": 536000, "num_agent_steps_sampled_lifetime": 2144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2144000, "timers": {"training_iteration_time_ms": 13043.889, "restore_workers_time_ms": 0.021, "training_step_time_ms": 13043.747, "sample_time_ms": 2039.865, "learn_time_ms": 10983.655, "learn_throughput": 364.177, "synch_weights_time_ms": 17.367}, "counters": {"num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "done": false, "training_iteration": 134, "trial_id": "04dec_00002", "date": "2024-08-13_16-52-57", "timestamp": 1723582377, "time_this_iter_s": 12.930591106414795, "time_total_s": 1805.6665642261505, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c44c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1805.6665642261505, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 69.25555555555555, "ram_util_percent": 83.73333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.675243191610253, "cur_kl_coeff": 3.237410339806955e-14, "cur_lr": 0.00010000000000000003, "total_loss": 0.8819768673370755, "policy_loss": -0.0010094513106480162, "vf_loss": 0.8829863170467357, "vf_explained_var": 0.013430006699587303, "kl": 0.0025930282028159583, "entropy": 0.13250581322917862, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 254205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.342834477575998, "cur_kl_coeff": 0.0024081390661280016, "cur_lr": 0.00010000000000000003, "total_loss": 3.8874670789355323, "policy_loss": -0.0028101681010975015, "vf_loss": 3.890254203352348, "vf_explained_var": 0.25227777875920454, "kl": 0.009572590918243985, "entropy": 0.4930360369266026, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 254205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -341.59999999999974, "episode_reward_mean": 95.89999999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 36.470000000000006, "predator_policy": 11.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.90000000000048, 18.399999999999963, 212.79999999999927, 39.800000000000296, -8.799999999999637, 213.69999999999928, 40.0000000000003, 400.0, 40.0000000000003, 40.0000000000003, 240.0, 206.1999999999993, -24.19999999999999, 207.89999999999932, 219.99999999999926, 394.0, 37.80000000000027, 215.99999999999926, 54.00000000000013, 124.5999999999998, 39.9000000000003, 40.0000000000003, 40.0000000000003, 211.9999999999993, -35.89999999999967, 40.0000000000003, 191.9999999999994, 40.0000000000003, 61.600000000000485, 79.59999999999937, 210.9999999999993, 37.80000000000027, 215.99999999999926, 212.2999999999993, 28.300000000000125, 219.99999999999926, 40.0000000000003, 38.50000000000028, 40.0000000000003, -134.3000000000005, 40.0000000000003, 193.99999999999937, 40.0000000000003, 219.99999999999926, 59.800000000000466, 342.1, 36.70000000000025, -18.0, 201.99999999999935, 40.0000000000003, 221.59999999999926, 81.69999999999996, -150.00000000000048, 40.0000000000003, 40.0000000000003, 201.99999999999935, 35.600000000000236, 40.90000000000031, 190.9999999999994, 27.900000000000116, 54.40000000000052, 400.0, -88.90000000000028, 205.99999999999932, 40.0000000000003, 40.0000000000003, 26.00000000000012, 40.0000000000003, 33.400000000000205, 33.400000000000205, 209.99999999999932, 40.0000000000003, 40.0000000000003, 36.70000000000025, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 338.0, 40.0000000000003, -109.60000000000063, 210.9999999999993, 195.49999999999937, 31.80000000000019, -341.59999999999974, 219.99999999999926, 43.60000000000036, 72.50000000000003, 96.99999999999875, 40.0000000000003, 190.0999999999994, 40.0000000000003, 216.09999999999923, 40.0000000000003, 397.3, 34.100000000000215, 36.200000000000244, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 35.30000000000026, -34.59999999999978, 20.000000000000014, 20.000000000000014, 192.8, 15.799999999999963, 20.000000000000014, -21.69999999999976, -24.099999999999746, 193.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.0, 80.0, 180.2, 20.000000000000014, -100.0, -86.19999999999999, 17.899999999999988, 185.0, 200.0, 20.000000000000014, 191.0, 200.0, 20.000000000000014, 15.799999999999962, 20.000000000000014, 194.0, 20.000000000000014, -112.0, -2.799999999999993, 85.4, 13.699999999999964, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 190.1, 17.899999999999988, 13.699999999999966, -118.60000000000048, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 26.300000000000114, 35.30000000000024, 57.800000000000225, 21.80000000000004, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 5.299999999999965, 20.000000000000014, -15.699999999999761, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -328.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.00000000000017, 30.800000000000203, 128.0, 190.1, 20.000000000000014, 13.699999999999964, 173.0, -400.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 23.600000000000065, -106.0, 13.699999999999964, -355.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 11.599999999999971, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 155.0, 20.000000000000014, -3.099999999999972, 20.000000000000014, 34.40000000000026, 200.0, 200.0, 20.300000000000022, -236.20000000000027, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 152.0, 20.000000000000014, 20.000000000000014, -265.60000000000014, 20.000000000000014, 179.0, 20.000000000000014, 167.0, 15.499999999999963, 20.000000000000014, -5.199999999999941, -221.50000000000023, -255.1000000000003, 20.000000000000014, 200.0, 20.000000000000014, 23.60000000000007, 185.0, -242.50000000000028, 65.00000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 170.0, 31.10000000000021, 20.000000000000014, 20.000000000000014, 197.3, 200.0, 7.099999999999966, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [4.0, 0.0, 19.0, 14.0, 0.0, 0.0, 2.0, 2.0, 23.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 25.0, 0.0, 6.0, 84.0, 78.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 98.0, 48.0, 28.0, 14.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 60.0, 9.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 7.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 171.0, 0.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 22.0, 0.0, 3.0, 191.0, 18.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 76.0, 98.0, 5.0, 180.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 2.0, 2.0, 0.0, 0.0, 1.0, 15.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 122.0, 5.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 96.0, 43.0, 0.0, 0.0, 5.0, 1.0, 6.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 136.0, 5.0, 7.0, 11.0, 2.0, 10.0, 7.0, 1.0, 134.0, 0.0, 0.0, 0.0, 0.0, 125.0, 5.0, 0.0, 12.0, 0.0, 0.0, 4.0, 15.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 8.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8362704810856377, "mean_inference_ms": 2.390176644472938, "mean_action_processing_ms": 0.3824257025426072, "mean_env_wait_ms": 0.30549047718010525, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004518985748291016, "StateBufferConnector_ms": 0.009121894836425781, "ViewRequirementAgentConnector_ms": 0.14323389530181885}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -341.59999999999974, "episode_return_mean": 95.89999999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.2780453485605, "num_env_steps_trained_throughput_per_sec": 323.2780453485605, "timesteps_total": 540000, "num_env_steps_sampled_lifetime": 540000, "num_agent_steps_sampled_lifetime": 2160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2160000, "timers": {"training_iteration_time_ms": 13001.59, "restore_workers_time_ms": 0.021, "training_step_time_ms": 13001.447, "sample_time_ms": 2033.099, "learn_time_ms": 10946.971, "learn_throughput": 365.398, "synch_weights_time_ms": 17.581}, "counters": {"num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "done": false, "training_iteration": 135, "trial_id": "04dec_00002", "date": "2024-08-13_16-53-09", "timestamp": 1723582389, "time_this_iter_s": 12.454484939575195, "time_total_s": 1818.1210491657257, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b061a5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1818.1210491657257, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 64.19444444444443, "ram_util_percent": 83.52777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6455247069024062, "cur_kl_coeff": 1.6187051699034774e-14, "cur_lr": 0.00010000000000000003, "total_loss": 0.19844033066478986, "policy_loss": -0.003544878932553782, "vf_loss": 0.2019852087906286, "vf_explained_var": 0.09626476458771518, "kl": 0.007127538995292946, "entropy": 0.15273011197094563, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 256095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.339884578251334, "cur_kl_coeff": 0.0024081390661280016, "cur_lr": 0.00010000000000000003, "total_loss": 4.262644091737333, "policy_loss": 0.0005564639746413503, "vf_loss": 4.262074951520042, "vf_explained_var": 0.46657193643706185, "kl": 0.005262975511690875, "entropy": 0.42855739738575366, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 256095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -341.59999999999974, "episode_reward_mean": 109.73999999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 44.375, "predator_policy": 10.495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.00000000000013, 124.5999999999998, 39.9000000000003, 40.0000000000003, 40.0000000000003, 211.9999999999993, -35.89999999999967, 40.0000000000003, 191.9999999999994, 40.0000000000003, 61.600000000000485, 79.59999999999937, 210.9999999999993, 37.80000000000027, 215.99999999999926, 212.2999999999993, 28.300000000000125, 219.99999999999926, 40.0000000000003, 38.50000000000028, 40.0000000000003, -134.3000000000005, 40.0000000000003, 193.99999999999937, 40.0000000000003, 219.99999999999926, 59.800000000000466, 342.1, 36.70000000000025, -18.0, 201.99999999999935, 40.0000000000003, 221.59999999999926, 81.69999999999996, -150.00000000000048, 40.0000000000003, 40.0000000000003, 201.99999999999935, 35.600000000000236, 40.90000000000031, 190.9999999999994, 27.900000000000116, 54.40000000000052, 400.0, -88.90000000000028, 205.99999999999932, 40.0000000000003, 40.0000000000003, 26.00000000000012, 40.0000000000003, 33.400000000000205, 33.400000000000205, 209.99999999999932, 40.0000000000003, 40.0000000000003, 36.70000000000025, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 338.0, 40.0000000000003, -109.60000000000063, 210.9999999999993, 195.49999999999937, 31.80000000000019, -341.59999999999974, 219.99999999999926, 43.60000000000036, 72.50000000000003, 96.99999999999875, 40.0000000000003, 190.0999999999994, 40.0000000000003, 216.09999999999923, 40.0000000000003, 397.3, 34.100000000000215, 36.200000000000244, 40.0000000000003, 196.89999999999938, 41.80000000000033, 221.79999999999924, 203.99999999999935, 40.0000000000003, 376.0, 207.99999999999932, 384.0, 197.99999999999937, 379.0, 201.99999999999935, 207.5999999999993, 397.0, 42.70000000000034, 352.0, 219.99999999999926, 205.99999999999935, 51.70000000000049], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -112.0, -2.799999999999993, 85.4, 13.699999999999964, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 190.1, 17.899999999999988, 13.699999999999966, -118.60000000000048, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 26.300000000000114, 35.30000000000024, 57.800000000000225, 21.80000000000004, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 5.299999999999965, 20.000000000000014, -15.699999999999761, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -328.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.00000000000017, 30.800000000000203, 128.0, 190.1, 20.000000000000014, 13.699999999999964, 173.0, -400.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 23.600000000000065, -106.0, 13.699999999999964, -355.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 11.599999999999971, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 155.0, 20.000000000000014, -3.099999999999972, 20.000000000000014, 34.40000000000026, 200.0, 200.0, 20.300000000000022, -236.20000000000027, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 152.0, 20.000000000000014, 20.000000000000014, -265.60000000000014, 20.000000000000014, 179.0, 20.000000000000014, 167.0, 15.499999999999963, 20.000000000000014, -5.199999999999941, -221.50000000000023, -255.1000000000003, 20.000000000000014, 200.0, 20.000000000000014, 23.60000000000007, 185.0, -242.50000000000028, 65.00000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 170.0, 31.10000000000021, 20.000000000000014, 20.000000000000014, 197.3, 200.0, 7.099999999999966, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, -24.099999999999746, 21.800000000000043, 20.000000000000014, 21.80000000000004, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 182.0, 176.0, 200.0, 167.0, 20.000000000000014, 182.0, 191.0, 20.000000000000014, 173.0, 185.0, 14.59999999999996, 191.0, 200.0, 20.000000000000014, 22.700000000000053, 161.0, 173.0, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 31.700000000000212, 20.000000000000014], "policy_predator_policy_reward": [98.0, 48.0, 28.0, 14.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 60.0, 9.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 7.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 171.0, 0.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 22.0, 0.0, 3.0, 191.0, 18.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 76.0, 98.0, 5.0, 180.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 2.0, 2.0, 0.0, 0.0, 1.0, 15.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 122.0, 5.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 96.0, 43.0, 0.0, 0.0, 5.0, 1.0, 6.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 136.0, 5.0, 7.0, 11.0, 2.0, 10.0, 7.0, 1.0, 134.0, 0.0, 0.0, 0.0, 0.0, 125.0, 5.0, 0.0, 12.0, 0.0, 0.0, 4.0, 15.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 8.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 3.0, 0.0, 8.0, 11.0, 0.0, 5.0, 1.0, 0.0, 9.0, 5.0, 3.0, 3.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8362981481291776, "mean_inference_ms": 2.3912508487948596, "mean_action_processing_ms": 0.3819933541479341, "mean_env_wait_ms": 0.3054686668940256, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010383367538452148, "StateBufferConnector_ms": 0.003980755805969238, "ViewRequirementAgentConnector_ms": 0.12920773029327393}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -341.59999999999974, "episode_return_mean": 109.73999999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.82215494106595, "num_env_steps_trained_throughput_per_sec": 315.82215494106595, "timesteps_total": 544000, "num_env_steps_sampled_lifetime": 544000, "num_agent_steps_sampled_lifetime": 2176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2176000, "timers": {"training_iteration_time_ms": 12967.852, "restore_workers_time_ms": 0.022, "training_step_time_ms": 12967.709, "sample_time_ms": 2042.66, "learn_time_ms": 10903.835, "learn_throughput": 366.843, "synch_weights_time_ms": 17.46}, "counters": {"num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "done": false, "training_iteration": 136, "trial_id": "04dec_00002", "date": "2024-08-13_16-53-22", "timestamp": 1723582402, "time_this_iter_s": 12.73319673538208, "time_total_s": 1830.8542459011078, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b061a8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1830.8542459011078, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 66.12777777777778, "ram_util_percent": 83.41666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3198713364306266, "cur_kl_coeff": 1.6187051699034774e-14, "cur_lr": 0.00010000000000000003, "total_loss": 0.6464898666849843, "policy_loss": -0.0003259973398473843, "vf_loss": 0.6468158622740438, "vf_explained_var": 0.002118222612552542, "kl": 0.004242791059483165, "entropy": 0.1256598802904288, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 257985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.689576944535371, "cur_kl_coeff": 0.0024081390661280016, "cur_lr": 0.00010000000000000003, "total_loss": 3.265874222220567, "policy_loss": 0.0001338078867072466, "vf_loss": 3.2657312426617535, "vf_explained_var": 0.3499519524750886, "kl": 0.0038114023749770843, "entropy": 0.49957669743154415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 257985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -341.59999999999974, "episode_reward_mean": 120.4309999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 50.79050000000001, "predator_policy": 9.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [193.99999999999937, 40.0000000000003, 219.99999999999926, 59.800000000000466, 342.1, 36.70000000000025, -18.0, 201.99999999999935, 40.0000000000003, 221.59999999999926, 81.69999999999996, -150.00000000000048, 40.0000000000003, 40.0000000000003, 201.99999999999935, 35.600000000000236, 40.90000000000031, 190.9999999999994, 27.900000000000116, 54.40000000000052, 400.0, -88.90000000000028, 205.99999999999932, 40.0000000000003, 40.0000000000003, 26.00000000000012, 40.0000000000003, 33.400000000000205, 33.400000000000205, 209.99999999999932, 40.0000000000003, 40.0000000000003, 36.70000000000025, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 338.0, 40.0000000000003, -109.60000000000063, 210.9999999999993, 195.49999999999937, 31.80000000000019, -341.59999999999974, 219.99999999999926, 43.60000000000036, 72.50000000000003, 96.99999999999875, 40.0000000000003, 190.0999999999994, 40.0000000000003, 216.09999999999923, 40.0000000000003, 397.3, 34.100000000000215, 36.200000000000244, 40.0000000000003, 196.89999999999938, 41.80000000000033, 221.79999999999924, 203.99999999999935, 40.0000000000003, 376.0, 207.99999999999932, 384.0, 197.99999999999937, 379.0, 201.99999999999935, 207.5999999999993, 397.0, 42.70000000000034, 352.0, 219.99999999999926, 205.99999999999935, 51.70000000000049, 32.30000000000019, 40.0000000000003, 191.9999999999994, 37.90000000000027, 38.90000000000028, 49.90000000000046, 204.99999999999932, 219.99999999999926, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 191.9999999999994, 44.50000000000037, 204.49999999999935, 191.9999999999994, 40.0000000000003, 40.0000000000003, 213.9999999999993, 40.0000000000003, 367.0, -163.50000000000057, 400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.00000000000017, 30.800000000000203, 128.0, 190.1, 20.000000000000014, 13.699999999999964, 173.0, -400.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 23.600000000000065, -106.0, 13.699999999999964, -355.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 11.599999999999971, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 155.0, 20.000000000000014, -3.099999999999972, 20.000000000000014, 34.40000000000026, 200.0, 200.0, 20.300000000000022, -236.20000000000027, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 152.0, 20.000000000000014, 20.000000000000014, -265.60000000000014, 20.000000000000014, 179.0, 20.000000000000014, 167.0, 15.499999999999963, 20.000000000000014, -5.199999999999941, -221.50000000000023, -255.1000000000003, 20.000000000000014, 200.0, 20.000000000000014, 23.60000000000007, 185.0, -242.50000000000028, 65.00000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 170.0, 31.10000000000021, 20.000000000000014, 20.000000000000014, 197.3, 200.0, 7.099999999999966, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, -24.099999999999746, 21.800000000000043, 20.000000000000014, 21.80000000000004, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 182.0, 176.0, 200.0, 167.0, 20.000000000000014, 182.0, 191.0, 20.000000000000014, 173.0, 185.0, 14.59999999999996, 191.0, 200.0, 20.000000000000014, 22.700000000000053, 161.0, 173.0, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 31.700000000000212, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 24.500000000000085, 7.399999999999967, 17.899999999999988, 20.000000000000014, 20.000000000000014, 29.90000000000018, -0.9999999999999846, 194.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 24.500000000000085, 20.000000000000014, 171.5, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 185.0, 173.0, -368.5, 20.000000000000014, 200.0, 200.0], "policy_predator_policy_reward": [12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 22.0, 0.0, 3.0, 191.0, 18.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 76.0, 98.0, 5.0, 180.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 2.0, 2.0, 0.0, 0.0, 1.0, 15.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 122.0, 5.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 96.0, 43.0, 0.0, 0.0, 5.0, 1.0, 6.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 136.0, 5.0, 7.0, 11.0, 2.0, 10.0, 7.0, 1.0, 134.0, 0.0, 0.0, 0.0, 0.0, 125.0, 5.0, 0.0, 12.0, 0.0, 0.0, 4.0, 15.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 8.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 3.0, 0.0, 8.0, 11.0, 0.0, 5.0, 1.0, 0.0, 9.0, 5.0, 3.0, 3.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 14.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 9.0, 91.0, 94.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8362114993438218, "mean_inference_ms": 2.3923877859005334, "mean_action_processing_ms": 0.3814059862945653, "mean_env_wait_ms": 0.30538412096998496, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011078238487243652, "StateBufferConnector_ms": 0.0038824081420898438, "ViewRequirementAgentConnector_ms": 0.12707161903381348}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -341.59999999999974, "episode_return_mean": 120.4309999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.97255390299637, "num_env_steps_trained_throughput_per_sec": 318.97255390299637, "timesteps_total": 548000, "num_env_steps_sampled_lifetime": 548000, "num_agent_steps_sampled_lifetime": 2192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2192000, "timers": {"training_iteration_time_ms": 12893.143, "restore_workers_time_ms": 0.021, "training_step_time_ms": 12893.0, "sample_time_ms": 2023.823, "learn_time_ms": 10848.439, "learn_throughput": 368.717, "synch_weights_time_ms": 16.885}, "counters": {"num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "done": false, "training_iteration": 137, "trial_id": "04dec_00002", "date": "2024-08-13_16-53-35", "timestamp": 1723582415, "time_this_iter_s": 12.598881006240845, "time_total_s": 1843.4531269073486, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0631d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1843.4531269073486, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 63.88333333333334, "ram_util_percent": 83.49444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8773967464567808, "cur_kl_coeff": 8.093525849517387e-15, "cur_lr": 0.00010000000000000003, "total_loss": 0.47674925275265223, "policy_loss": -1.8762161206237223e-05, "vf_loss": 0.476768013877331, "vf_explained_var": 0.0017440094518913793, "kl": 0.0027684504987907682, "entropy": 0.16819945302589862, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 259875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.576102245516248, "cur_kl_coeff": 0.0012040695330640008, "cur_lr": 0.00010000000000000003, "total_loss": 3.1845318047457902, "policy_loss": -0.0011533669235490303, "vf_loss": 3.185677915969223, "vf_explained_var": 0.49329618288095667, "kl": 0.006025570782796388, "entropy": 0.537961634804332, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 259875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -341.59999999999974, "episode_reward_mean": 126.63999999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 136.0}, "policy_reward_mean": {"prey_policy": 56.495, "predator_policy": 6.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.99999999999932, 40.0000000000003, 40.0000000000003, 26.00000000000012, 40.0000000000003, 33.400000000000205, 33.400000000000205, 209.99999999999932, 40.0000000000003, 40.0000000000003, 36.70000000000025, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 338.0, 40.0000000000003, -109.60000000000063, 210.9999999999993, 195.49999999999937, 31.80000000000019, -341.59999999999974, 219.99999999999926, 43.60000000000036, 72.50000000000003, 96.99999999999875, 40.0000000000003, 190.0999999999994, 40.0000000000003, 216.09999999999923, 40.0000000000003, 397.3, 34.100000000000215, 36.200000000000244, 40.0000000000003, 196.89999999999938, 41.80000000000033, 221.79999999999924, 203.99999999999935, 40.0000000000003, 376.0, 207.99999999999932, 384.0, 197.99999999999937, 379.0, 201.99999999999935, 207.5999999999993, 397.0, 42.70000000000034, 352.0, 219.99999999999926, 205.99999999999935, 51.70000000000049, 32.30000000000019, 40.0000000000003, 191.9999999999994, 37.90000000000027, 38.90000000000028, 49.90000000000046, 204.99999999999932, 219.99999999999926, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 191.9999999999994, 44.50000000000037, 204.49999999999935, 191.9999999999994, 40.0000000000003, 40.0000000000003, 213.9999999999993, 40.0000000000003, 367.0, -163.50000000000057, 400.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, 188.3999999999994, -27.099999999999547, 199.99999999999935, 205.99999999999932, 207.99999999999932, 398.0, 47.200000000000415, 32.00000000000022, 40.0000000000003, 219.99999999999926, 35.40000000000023, 29.900000000000148, 394.0, 198.99999999999935, 40.0000000000003, 46.3000000000004, 201.19999999999933, 31.800000000000175, 223.59999999999923], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 152.0, 20.000000000000014, 20.000000000000014, -265.60000000000014, 20.000000000000014, 179.0, 20.000000000000014, 167.0, 15.499999999999963, 20.000000000000014, -5.199999999999941, -221.50000000000023, -255.1000000000003, 20.000000000000014, 200.0, 20.000000000000014, 23.60000000000007, 185.0, -242.50000000000028, 65.00000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 170.0, 31.10000000000021, 20.000000000000014, 20.000000000000014, 197.3, 200.0, 7.099999999999966, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, -24.099999999999746, 21.800000000000043, 20.000000000000014, 21.80000000000004, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 182.0, 176.0, 200.0, 167.0, 20.000000000000014, 182.0, 191.0, 20.000000000000014, 173.0, 185.0, 14.59999999999996, 191.0, 200.0, 20.000000000000014, 22.700000000000053, 161.0, 173.0, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 31.700000000000212, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 24.500000000000085, 7.399999999999967, 17.899999999999988, 20.000000000000014, 20.000000000000014, 29.90000000000018, -0.9999999999999846, 194.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 24.500000000000085, 20.000000000000014, 171.5, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 185.0, 173.0, -368.5, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999967, 170.0, -108.10000000000076, 20.000000000000014, 161.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 182.0, 200.0, 197.0, 27.20000000000013, 20.000000000000014, 20.000000000000014, -82.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 10.399999999999967, 20.000000000000014, -0.9999999999999952, 20.900000000000027, 200.0, 191.0, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.300000000000118, 185.0, 0.19999999999998655, 12.499999999999972, 5.299999999999965, 200.0, 23.60000000000007], "policy_predator_policy_reward": [8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 96.0, 43.0, 0.0, 0.0, 5.0, 1.0, 6.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 136.0, 5.0, 7.0, 11.0, 2.0, 10.0, 7.0, 1.0, 134.0, 0.0, 0.0, 0.0, 0.0, 125.0, 5.0, 0.0, 12.0, 0.0, 0.0, 4.0, 15.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 8.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 3.0, 0.0, 8.0, 11.0, 0.0, 5.0, 1.0, 0.0, 9.0, 5.0, 3.0, 3.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 14.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 9.0, 91.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 61.0, 0.0, 9.0, 10.0, 7.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 3.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 14.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8360134365744248, "mean_inference_ms": 2.391268049814605, "mean_action_processing_ms": 0.3809781873136741, "mean_env_wait_ms": 0.3052492886855564, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011681318283081055, "StateBufferConnector_ms": 0.0036019086837768555, "ViewRequirementAgentConnector_ms": 0.12603747844696045}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -341.59999999999974, "episode_return_mean": 126.63999999999989, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 308.5876915763763, "num_env_steps_trained_throughput_per_sec": 308.5876915763763, "timesteps_total": 552000, "num_env_steps_sampled_lifetime": 552000, "num_agent_steps_sampled_lifetime": 2208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2208000, "timers": {"training_iteration_time_ms": 12881.46, "restore_workers_time_ms": 0.021, "training_step_time_ms": 12881.316, "sample_time_ms": 2020.412, "learn_time_ms": 10839.973, "learn_throughput": 369.005, "synch_weights_time_ms": 16.949}, "counters": {"num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "done": false, "training_iteration": 138, "trial_id": "04dec_00002", "date": "2024-08-13_16-53-48", "timestamp": 1723582428, "time_this_iter_s": 13.024017095565796, "time_total_s": 1856.4771440029144, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0441310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1856.4771440029144, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 66.83333333333334, "ram_util_percent": 83.72222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.525487241645654, "cur_kl_coeff": 4.0467629247586935e-15, "cur_lr": 0.00010000000000000003, "total_loss": 0.6770288044025028, "policy_loss": -0.0029900085063966574, "vf_loss": 0.6800188120819195, "vf_explained_var": 0.003658326782246746, "kl": 0.003024771475286636, "entropy": 0.0843280031153607, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 261765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.097653573924902, "cur_kl_coeff": 0.0012040695330640008, "cur_lr": 0.00010000000000000003, "total_loss": 3.114238483817489, "policy_loss": -0.0009222596275211169, "vf_loss": 3.1151544303490373, "vf_explained_var": 0.5658002653765299, "kl": 0.005237270224136761, "entropy": 0.4375414333330891, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 261765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -341.59999999999974, "episode_reward_mean": 135.2269999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 136.0}, "policy_reward_mean": {"prey_policy": 61.158500000000004, "predator_policy": 6.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -109.60000000000063, 210.9999999999993, 195.49999999999937, 31.80000000000019, -341.59999999999974, 219.99999999999926, 43.60000000000036, 72.50000000000003, 96.99999999999875, 40.0000000000003, 190.0999999999994, 40.0000000000003, 216.09999999999923, 40.0000000000003, 397.3, 34.100000000000215, 36.200000000000244, 40.0000000000003, 196.89999999999938, 41.80000000000033, 221.79999999999924, 203.99999999999935, 40.0000000000003, 376.0, 207.99999999999932, 384.0, 197.99999999999937, 379.0, 201.99999999999935, 207.5999999999993, 397.0, 42.70000000000034, 352.0, 219.99999999999926, 205.99999999999935, 51.70000000000049, 32.30000000000019, 40.0000000000003, 191.9999999999994, 37.90000000000027, 38.90000000000028, 49.90000000000046, 204.99999999999932, 219.99999999999926, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 191.9999999999994, 44.50000000000037, 204.49999999999935, 191.9999999999994, 40.0000000000003, 40.0000000000003, 213.9999999999993, 40.0000000000003, 367.0, -163.50000000000057, 400.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, 188.3999999999994, -27.099999999999547, 199.99999999999935, 205.99999999999932, 207.99999999999932, 398.0, 47.200000000000415, 32.00000000000022, 40.0000000000003, 219.99999999999926, 35.40000000000023, 29.900000000000148, 394.0, 198.99999999999935, 40.0000000000003, 46.3000000000004, 201.19999999999933, 31.800000000000175, 223.59999999999923, 43.60000000000035, 42.700000000000344, 197.39999999999935, 40.0000000000003, 194.49999999999937, 37.80000000000027, 375.0, 213.3999999999993, 40.0000000000003, 198.99999999999935, 43.40000000000035, 26.400000000000084, 40.90000000000031, 377.0, 26.900000000000087, 40.0000000000003, 201.99999999999935, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -265.60000000000014, 20.000000000000014, 179.0, 20.000000000000014, 167.0, 15.499999999999963, 20.000000000000014, -5.199999999999941, -221.50000000000023, -255.1000000000003, 20.000000000000014, 200.0, 20.000000000000014, 23.60000000000007, 185.0, -242.50000000000028, 65.00000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 170.0, 31.10000000000021, 20.000000000000014, 20.000000000000014, 197.3, 200.0, 7.099999999999966, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, -24.099999999999746, 21.800000000000043, 20.000000000000014, 21.80000000000004, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 182.0, 176.0, 200.0, 167.0, 20.000000000000014, 182.0, 191.0, 20.000000000000014, 173.0, 185.0, 14.59999999999996, 191.0, 200.0, 20.000000000000014, 22.700000000000053, 161.0, 173.0, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 31.700000000000212, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 24.500000000000085, 7.399999999999967, 17.899999999999988, 20.000000000000014, 20.000000000000014, 29.90000000000018, -0.9999999999999846, 194.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 24.500000000000085, 20.000000000000014, 171.5, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 185.0, 173.0, -368.5, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999967, 170.0, -108.10000000000076, 20.000000000000014, 161.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 182.0, 200.0, 197.0, 27.20000000000013, 20.000000000000014, 20.000000000000014, -82.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 10.399999999999967, 20.000000000000014, -0.9999999999999952, 20.900000000000027, 200.0, 191.0, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.300000000000118, 185.0, 0.19999999999998655, 12.499999999999972, 5.299999999999965, 200.0, 23.60000000000007, 23.600000000000065, 20.000000000000014, 22.700000000000056, 20.000000000000014, 176.0, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999964, 170.0, 15.799999999999963, 20.000000000000014, 200.0, 152.0, 200.0, 7.399999999999967, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.900000000000027, 21.500000000000036, 2.8999999999999684, 9.499999999999964, 20.900000000000027, 20.000000000000014, 185.0, 182.0, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 200.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 136.0, 5.0, 7.0, 11.0, 2.0, 10.0, 7.0, 1.0, 134.0, 0.0, 0.0, 0.0, 0.0, 125.0, 5.0, 0.0, 12.0, 0.0, 0.0, 4.0, 15.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 8.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 3.0, 0.0, 8.0, 11.0, 0.0, 5.0, 1.0, 0.0, 9.0, 5.0, 3.0, 3.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 14.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 9.0, 91.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 61.0, 0.0, 9.0, 10.0, 7.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 3.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 10.0, 5.0, 0.0, 2.0, 11.0, 12.0, 6.0, 0.0, 0.0, 0.0, 6.0, 9.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 4.0, 6.0, 0.0, 10.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8353915168005781, "mean_inference_ms": 2.392760801900419, "mean_action_processing_ms": 0.3803083183221196, "mean_env_wait_ms": 0.3050628110907431, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0119398832321167, "StateBufferConnector_ms": 0.0035353899002075195, "ViewRequirementAgentConnector_ms": 0.1117868423461914}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -341.59999999999974, "episode_return_mean": 135.2269999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 314.7962443417103, "num_env_steps_trained_throughput_per_sec": 314.7962443417103, "timesteps_total": 556000, "num_env_steps_sampled_lifetime": 556000, "num_agent_steps_sampled_lifetime": 2224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2224000, "timers": {"training_iteration_time_ms": 12830.358, "restore_workers_time_ms": 0.022, "training_step_time_ms": 12830.214, "sample_time_ms": 1933.321, "learn_time_ms": 10876.319, "learn_throughput": 367.771, "synch_weights_time_ms": 16.492}, "counters": {"num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "done": false, "training_iteration": 139, "trial_id": "04dec_00002", "date": "2024-08-13_16-54-01", "timestamp": 1723582441, "time_this_iter_s": 12.76357102394104, "time_total_s": 1869.2407150268555, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06fc160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1869.2407150268555, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 64.48333333333333, "ram_util_percent": 83.41111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5431798419939777, "cur_kl_coeff": 2.0233814623793468e-15, "cur_lr": 0.00010000000000000003, "total_loss": 1.3190759770138554, "policy_loss": -0.0032015788648523903, "vf_loss": 1.3222775569983891, "vf_explained_var": 0.002681122381220419, "kl": 0.0118738948162202, "entropy": 0.14767558140650627, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 263655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.185039616246073, "cur_kl_coeff": 0.0012040695330640008, "cur_lr": 0.00010000000000000003, "total_loss": 2.965478484971183, "policy_loss": -0.002264160178441594, "vf_loss": 2.967725519843833, "vf_explained_var": 0.29607818968712335, "kl": 0.014228451194824071, "entropy": 0.5723999736012605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 263655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -163.50000000000057, "episode_reward_mean": 129.45999999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": 55.95500000000001, "predator_policy": 8.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 196.89999999999938, 41.80000000000033, 221.79999999999924, 203.99999999999935, 40.0000000000003, 376.0, 207.99999999999932, 384.0, 197.99999999999937, 379.0, 201.99999999999935, 207.5999999999993, 397.0, 42.70000000000034, 352.0, 219.99999999999926, 205.99999999999935, 51.70000000000049, 32.30000000000019, 40.0000000000003, 191.9999999999994, 37.90000000000027, 38.90000000000028, 49.90000000000046, 204.99999999999932, 219.99999999999926, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 191.9999999999994, 44.50000000000037, 204.49999999999935, 191.9999999999994, 40.0000000000003, 40.0000000000003, 213.9999999999993, 40.0000000000003, 367.0, -163.50000000000057, 400.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, 188.3999999999994, -27.099999999999547, 199.99999999999935, 205.99999999999932, 207.99999999999932, 398.0, 47.200000000000415, 32.00000000000022, 40.0000000000003, 219.99999999999926, 35.40000000000023, 29.900000000000148, 394.0, 198.99999999999935, 40.0000000000003, 46.3000000000004, 201.19999999999933, 31.800000000000175, 223.59999999999923, 43.60000000000035, 42.700000000000344, 197.39999999999935, 40.0000000000003, 194.49999999999937, 37.80000000000027, 375.0, 213.3999999999993, 40.0000000000003, 198.99999999999935, 43.40000000000035, 26.400000000000084, 40.90000000000031, 377.0, 26.900000000000087, 40.0000000000003, 201.99999999999935, 219.99999999999926, -143.10000000000056, -64.99999999999989, 35.50000000000002, 29.200000000000127, 180.99999999999946, 40.0000000000003, 28.80000000000014, 207.99999999999932, 49.00000000000045, 32.30000000000018, 46.10000000000025, 38.90000000000028, 25.70000000000007, 215.99999999999926, 47.200000000000415, 38.90000000000028, -138.20000000000059, 206.99999999999932], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 200.0, -24.099999999999746, 21.800000000000043, 20.000000000000014, 21.80000000000004, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 182.0, 176.0, 200.0, 167.0, 20.000000000000014, 182.0, 191.0, 20.000000000000014, 173.0, 185.0, 14.59999999999996, 191.0, 200.0, 20.000000000000014, 22.700000000000053, 161.0, 173.0, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 31.700000000000212, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 24.500000000000085, 7.399999999999967, 17.899999999999988, 20.000000000000014, 20.000000000000014, 29.90000000000018, -0.9999999999999846, 194.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 24.500000000000085, 20.000000000000014, 171.5, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 185.0, 173.0, -368.5, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999967, 170.0, -108.10000000000076, 20.000000000000014, 161.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 182.0, 200.0, 197.0, 27.20000000000013, 20.000000000000014, 20.000000000000014, -82.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 10.399999999999967, 20.000000000000014, -0.9999999999999952, 20.900000000000027, 200.0, 191.0, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.300000000000118, 185.0, 0.19999999999998655, 12.499999999999972, 5.299999999999965, 200.0, 23.60000000000007, 23.600000000000065, 20.000000000000014, 22.700000000000056, 20.000000000000014, 176.0, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999964, 170.0, 15.799999999999963, 20.000000000000014, 200.0, 152.0, 200.0, 7.399999999999967, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.900000000000027, 21.500000000000036, 2.8999999999999684, 9.499999999999964, 20.900000000000027, 20.000000000000014, 185.0, 182.0, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 200.0, 20.000000000000014, 16.69999999999997, -332.8, -364.0, 20.000000000000014, 179.0, -305.49999999999994, 7.399999999999965, 15.799999999999963, 20.000000000000014, 125.0, 20.000000000000014, 20.000000000000014, 7.399999999999965, 10.399999999999979, 20.000000000000014, 173.0, 20.000000000000014, 29.000000000000163, 5.299999999999965, 20.000000000000014, 4.0999999999999694, -52.0, 17.899999999999988, 20.000000000000014, -7.299999999999891, 20.000000000000014, 194.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.19999999999993, 20.000000000000014, 20.000000000000014, 176.0], "policy_predator_policy_reward": [0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 3.0, 0.0, 8.0, 11.0, 0.0, 5.0, 1.0, 0.0, 9.0, 5.0, 3.0, 3.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 14.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 9.0, 91.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 61.0, 0.0, 9.0, 10.0, 7.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 3.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 10.0, 5.0, 0.0, 2.0, 11.0, 12.0, 6.0, 0.0, 0.0, 0.0, 6.0, 9.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 4.0, 6.0, 0.0, 10.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 168.0, 5.0, 91.0, 188.0, 7.0, 155.0, 6.0, 0.0, 19.0, 17.0, 0.0, 0.0, 0.0, 11.0, 9.0, 6.0, 0.0, 0.0, 0.0, 7.0, 2.0, 92.0, 0.0, 1.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 162.0, 0.0, 3.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8346826463603995, "mean_inference_ms": 2.3922954280709727, "mean_action_processing_ms": 0.3797071348346479, "mean_env_wait_ms": 0.3048197722425607, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012032151222229004, "StateBufferConnector_ms": 0.0035163164138793945, "ViewRequirementAgentConnector_ms": 0.11067676544189453}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -163.50000000000057, "episode_return_mean": 129.45999999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.4869651093096, "num_env_steps_trained_throughput_per_sec": 306.4869651093096, "timesteps_total": 560000, "num_env_steps_sampled_lifetime": 560000, "num_agent_steps_sampled_lifetime": 2240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2240000, "timers": {"training_iteration_time_ms": 12800.717, "restore_workers_time_ms": 0.021, "training_step_time_ms": 12800.638, "sample_time_ms": 1823.613, "learn_time_ms": 10956.988, "learn_throughput": 365.064, "synch_weights_time_ms": 16.216}, "counters": {"num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "done": false, "training_iteration": 140, "trial_id": "04dec_00002", "date": "2024-08-13_16-54-14", "timestamp": 1723582454, "time_this_iter_s": 13.10352897644043, "time_total_s": 1882.344244003296, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06310d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1882.344244003296, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 65.0, "ram_util_percent": 83.56666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9976142462283846, "cur_kl_coeff": 2.0233814623793468e-15, "cur_lr": 0.00010000000000000003, "total_loss": 0.40697265469996385, "policy_loss": -0.0014027768824860533, "vf_loss": 0.4083754321487581, "vf_explained_var": 0.009462975698804098, "kl": 0.003422153154681875, "entropy": 0.19261716190311645, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 265545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.723234789475562, "cur_kl_coeff": 0.0012040695330640008, "cur_lr": 0.00010000000000000003, "total_loss": 1.8979506449724632, "policy_loss": -0.0030628449322345356, "vf_loss": 1.900993874810991, "vf_explained_var": 0.4860850556186898, "kl": 0.01628994627644753, "entropy": 0.6578642030241628, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 265545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -163.50000000000057, "episode_reward_mean": 105.61199999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": 43.721000000000004, "predator_policy": 9.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.90000000000028, 49.90000000000046, 204.99999999999932, 219.99999999999926, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 191.9999999999994, 44.50000000000037, 204.49999999999935, 191.9999999999994, 40.0000000000003, 40.0000000000003, 213.9999999999993, 40.0000000000003, 367.0, -163.50000000000057, 400.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, 188.3999999999994, -27.099999999999547, 199.99999999999935, 205.99999999999932, 207.99999999999932, 398.0, 47.200000000000415, 32.00000000000022, 40.0000000000003, 219.99999999999926, 35.40000000000023, 29.900000000000148, 394.0, 198.99999999999935, 40.0000000000003, 46.3000000000004, 201.19999999999933, 31.800000000000175, 223.59999999999923, 43.60000000000035, 42.700000000000344, 197.39999999999935, 40.0000000000003, 194.49999999999937, 37.80000000000027, 375.0, 213.3999999999993, 40.0000000000003, 198.99999999999935, 43.40000000000035, 26.400000000000084, 40.90000000000031, 377.0, 26.900000000000087, 40.0000000000003, 201.99999999999935, 219.99999999999926, -143.10000000000056, -64.99999999999989, 35.50000000000002, 29.200000000000127, 180.99999999999946, 40.0000000000003, 28.80000000000014, 207.99999999999932, 49.00000000000045, 32.30000000000018, 46.10000000000025, 38.90000000000028, 25.70000000000007, 215.99999999999926, 47.200000000000415, 38.90000000000028, -138.20000000000059, 206.99999999999932, 203.99999999999935, 36.100000000000236, 77.29999999999943, 45.000000000000384, 219.99999999999926, 36.80000000000025, 35.20000000000023, 207.99999999999932, 59.80000000000051, 31.200000000000166, -5.599999999999733, 26.500000000000092, 40.90000000000031, 44.60000000000039, 177.99999999999946, 197.99999999999937, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 34.60000000000022, 36.70000000000025, 38.80000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, 20.000000000000014, 20.000000000000014, 29.90000000000018, -0.9999999999999846, 194.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 24.500000000000085, 20.000000000000014, 171.5, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 185.0, 173.0, -368.5, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999967, 170.0, -108.10000000000076, 20.000000000000014, 161.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 182.0, 200.0, 197.0, 27.20000000000013, 20.000000000000014, 20.000000000000014, -82.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 10.399999999999967, 20.000000000000014, -0.9999999999999952, 20.900000000000027, 200.0, 191.0, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.300000000000118, 185.0, 0.19999999999998655, 12.499999999999972, 5.299999999999965, 200.0, 23.60000000000007, 23.600000000000065, 20.000000000000014, 22.700000000000056, 20.000000000000014, 176.0, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999964, 170.0, 15.799999999999963, 20.000000000000014, 200.0, 152.0, 200.0, 7.399999999999967, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.900000000000027, 21.500000000000036, 2.8999999999999684, 9.499999999999964, 20.900000000000027, 20.000000000000014, 185.0, 182.0, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 200.0, 20.000000000000014, 16.69999999999997, -332.8, -364.0, 20.000000000000014, 179.0, -305.49999999999994, 7.399999999999965, 15.799999999999963, 20.000000000000014, 125.0, 20.000000000000014, 20.000000000000014, 7.399999999999965, 10.399999999999979, 20.000000000000014, 173.0, 20.000000000000014, 29.000000000000163, 5.299999999999965, 20.000000000000014, 4.0999999999999694, -52.0, 17.899999999999988, 20.000000000000014, -7.299999999999891, 20.000000000000014, 194.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.19999999999993, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 176.0, 22.700000000000053, 7.399999999999965, -3.099999999999958, 61.40000000000016, 20.000000000000014, 23.00000000000006, 20.000000000000014, 200.0, 17.899999999999988, 17.899999999999988, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 182.0, 32.60000000000023, 27.200000000000134, 3.1999999999999615, 20.000000000000014, -80.80000000000082, 27.200000000000134, -7.299999999999901, 15.79999999999996, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.600000000000026, 20.000000000000014, 125.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999872, 13.699999999999964, 20.000000000000014, 12.79999999999997, 20.000000000000014], "policy_predator_policy_reward": [1.0, 0.0, 0.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 9.0, 91.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 61.0, 0.0, 9.0, 10.0, 7.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 3.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 10.0, 5.0, 0.0, 2.0, 11.0, 12.0, 6.0, 0.0, 0.0, 0.0, 6.0, 9.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 4.0, 6.0, 0.0, 10.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 168.0, 5.0, 91.0, 188.0, 7.0, 155.0, 6.0, 0.0, 19.0, 17.0, 0.0, 0.0, 0.0, 11.0, 9.0, 6.0, 0.0, 0.0, 0.0, 7.0, 2.0, 92.0, 0.0, 1.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 162.0, 0.0, 3.0, 8.0, 8.0, 0.0, 6.0, 0.0, 11.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 4.0, 4.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 48.0, 12.0, 6.0, 0.0, 0.0, 0.0, 4.0, 9.0, 24.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 10.0, 3.0, 0.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.834381573143397, "mean_inference_ms": 2.3913840608757657, "mean_action_processing_ms": 0.3794148649966945, "mean_env_wait_ms": 0.30442000105204126, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006111502647399902, "StateBufferConnector_ms": 0.004896640777587891, "ViewRequirementAgentConnector_ms": 0.12200284004211426}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -163.50000000000057, "episode_return_mean": 105.61199999999994, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.7058885035986, "num_env_steps_trained_throughput_per_sec": 310.7058885035986, "timesteps_total": 564000, "num_env_steps_sampled_lifetime": 564000, "num_agent_steps_sampled_lifetime": 2256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2256000, "timers": {"training_iteration_time_ms": 12765.401, "restore_workers_time_ms": 0.021, "training_step_time_ms": 12765.322, "sample_time_ms": 1789.632, "learn_time_ms": 10955.369, "learn_throughput": 365.118, "synch_weights_time_ms": 16.442}, "counters": {"num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "done": false, "training_iteration": 141, "trial_id": "04dec_00002", "date": "2024-08-13_16-54-27", "timestamp": 1723582467, "time_this_iter_s": 12.925196886062622, "time_total_s": 1895.2694408893585, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0631f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1895.2694408893585, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 67.13157894736841, "ram_util_percent": 83.45263157894736}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8846370705536433, "cur_kl_coeff": 1.0116907311896734e-15, "cur_lr": 0.00010000000000000003, "total_loss": 0.8031046749895843, "policy_loss": -0.003307516316306733, "vf_loss": 0.8064121917047828, "vf_explained_var": 0.004029290859030668, "kl": 0.007417849187027902, "entropy": 0.26967549799453644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 267435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.210149526154554, "cur_kl_coeff": 0.0012040695330640008, "cur_lr": 0.00010000000000000003, "total_loss": 2.9595739604304074, "policy_loss": -0.007135163790364035, "vf_loss": 2.9666812674709098, "vf_explained_var": 0.37007649777427554, "kl": 0.023133739015004547, "entropy": 0.7223844300186824, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 267435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -143.10000000000056, "episode_reward_mean": 96.99599999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": 37.86800000000001, "predator_policy": 10.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [400.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, 188.3999999999994, -27.099999999999547, 199.99999999999935, 205.99999999999932, 207.99999999999932, 398.0, 47.200000000000415, 32.00000000000022, 40.0000000000003, 219.99999999999926, 35.40000000000023, 29.900000000000148, 394.0, 198.99999999999935, 40.0000000000003, 46.3000000000004, 201.19999999999933, 31.800000000000175, 223.59999999999923, 43.60000000000035, 42.700000000000344, 197.39999999999935, 40.0000000000003, 194.49999999999937, 37.80000000000027, 375.0, 213.3999999999993, 40.0000000000003, 198.99999999999935, 43.40000000000035, 26.400000000000084, 40.90000000000031, 377.0, 26.900000000000087, 40.0000000000003, 201.99999999999935, 219.99999999999926, -143.10000000000056, -64.99999999999989, 35.50000000000002, 29.200000000000127, 180.99999999999946, 40.0000000000003, 28.80000000000014, 207.99999999999932, 49.00000000000045, 32.30000000000018, 46.10000000000025, 38.90000000000028, 25.70000000000007, 215.99999999999926, 47.200000000000415, 38.90000000000028, -138.20000000000059, 206.99999999999932, 203.99999999999935, 36.100000000000236, 77.29999999999943, 45.000000000000384, 219.99999999999926, 36.80000000000025, 35.20000000000023, 207.99999999999932, 59.80000000000051, 31.200000000000166, -5.599999999999733, 26.500000000000092, 40.90000000000031, 44.60000000000039, 177.99999999999946, 197.99999999999937, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 34.60000000000022, 36.70000000000025, 38.80000000000028, -90.90000000000029, -68.90000000000066, 36.00000000000024, 40.0000000000003, 219.99999999999926, 37.80000000000027, 205.99999999999932, 343.3, 185.59999999999943, 37.30000000000026, 40.30000000000031, 40.0000000000003, 49.900000000000475, 211.9999999999993, 40.0000000000003, 40.0000000000003, 107.79999999999988, -133.50000000000063], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999967, 170.0, -108.10000000000076, 20.000000000000014, 161.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 182.0, 200.0, 197.0, 27.20000000000013, 20.000000000000014, 20.000000000000014, -82.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 10.399999999999967, 20.000000000000014, -0.9999999999999952, 20.900000000000027, 200.0, 191.0, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.300000000000118, 185.0, 0.19999999999998655, 12.499999999999972, 5.299999999999965, 200.0, 23.60000000000007, 23.600000000000065, 20.000000000000014, 22.700000000000056, 20.000000000000014, 176.0, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999964, 170.0, 15.799999999999963, 20.000000000000014, 200.0, 152.0, 200.0, 7.399999999999967, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.900000000000027, 21.500000000000036, 2.8999999999999684, 9.499999999999964, 20.900000000000027, 20.000000000000014, 185.0, 182.0, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 200.0, 20.000000000000014, 16.69999999999997, -332.8, -364.0, 20.000000000000014, 179.0, -305.49999999999994, 7.399999999999965, 15.799999999999963, 20.000000000000014, 125.0, 20.000000000000014, 20.000000000000014, 7.399999999999965, 10.399999999999979, 20.000000000000014, 173.0, 20.000000000000014, 29.000000000000163, 5.299999999999965, 20.000000000000014, 4.0999999999999694, -52.0, 17.899999999999988, 20.000000000000014, -7.299999999999891, 20.000000000000014, 194.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.19999999999993, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 176.0, 22.700000000000053, 7.399999999999965, -3.099999999999958, 61.40000000000016, 20.000000000000014, 23.00000000000006, 20.000000000000014, 200.0, 17.899999999999988, 17.899999999999988, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 182.0, 32.60000000000023, 27.200000000000134, 3.1999999999999615, 20.000000000000014, -80.80000000000082, 27.200000000000134, -7.299999999999901, 15.79999999999996, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.600000000000026, 20.000000000000014, 125.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999872, 13.699999999999964, 20.000000000000014, 12.79999999999997, 20.000000000000014, -229.9000000000001, 20.000000000000014, 20.000000000000014, -187.90000000000032, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 167.0, 20.000000000000014, 173.0, 134.3, 151.7, 17.899999999999988, 20.000000000000014, 8.299999999999969, 20.000000000000014, 8.299999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 35.0, -322.2999999999997, 18.799999999999997], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 61.0, 0.0, 9.0, 10.0, 7.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 94.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 3.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 10.0, 5.0, 0.0, 2.0, 11.0, 12.0, 6.0, 0.0, 0.0, 0.0, 6.0, 9.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 4.0, 6.0, 0.0, 10.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 168.0, 5.0, 91.0, 188.0, 7.0, 155.0, 6.0, 0.0, 19.0, 17.0, 0.0, 0.0, 0.0, 11.0, 9.0, 6.0, 0.0, 0.0, 0.0, 7.0, 2.0, 92.0, 0.0, 1.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 162.0, 0.0, 3.0, 8.0, 8.0, 0.0, 6.0, 0.0, 11.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 4.0, 4.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 48.0, 12.0, 6.0, 0.0, 0.0, 0.0, 4.0, 9.0, 24.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 10.0, 3.0, 0.0, 6.0, 0.0, 119.0, 0.0, 99.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 8.0, 23.0, 13.0, 14.0, 2.0, 0.0, 9.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 55.0, 163.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8332114503462026, "mean_inference_ms": 2.391330934573503, "mean_action_processing_ms": 0.37847662750617134, "mean_env_wait_ms": 0.304209080322295, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005473136901855469, "StateBufferConnector_ms": 0.004953980445861816, "ViewRequirementAgentConnector_ms": 0.1306476593017578}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -143.10000000000056, "episode_return_mean": 96.99599999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 309.3051477507166, "num_env_steps_trained_throughput_per_sec": 309.3051477507166, "timesteps_total": 568000, "num_env_steps_sampled_lifetime": 568000, "num_agent_steps_sampled_lifetime": 2272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2272000, "timers": {"training_iteration_time_ms": 12774.449, "restore_workers_time_ms": 0.021, "training_step_time_ms": 12774.37, "sample_time_ms": 1780.341, "learn_time_ms": 10974.038, "learn_throughput": 364.497, "synch_weights_time_ms": 16.025}, "counters": {"num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "done": false, "training_iteration": 142, "trial_id": "04dec_00002", "date": "2024-08-13_16-54-40", "timestamp": 1723582480, "time_this_iter_s": 12.970267295837402, "time_total_s": 1908.239708185196, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0239f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1908.239708185196, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 64.5, "ram_util_percent": 83.22777777777776}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2792955195225735, "cur_kl_coeff": 1.0116907311896734e-15, "cur_lr": 0.00010000000000000003, "total_loss": 0.3551574105860064, "policy_loss": -0.005013648531197634, "vf_loss": 0.3601710586474775, "vf_explained_var": 0.008281093268167405, "kl": 0.009273087398791475, "entropy": 0.2546372056322754, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 269325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.623048271798583, "cur_kl_coeff": 0.0018061042995960004, "cur_lr": 0.00010000000000000003, "total_loss": 1.6933951299657266, "policy_loss": -0.0023391827847315835, "vf_loss": 1.6956925662421676, "vf_explained_var": 0.38219824386021445, "kl": 0.023113935546319204, "entropy": 0.7713562104437086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 269325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "env_runners": {"episode_reward_max": 377.0, "episode_reward_min": -143.10000000000056, "episode_reward_mean": 86.90199999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": 32.93600000000001, "predator_policy": 10.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [223.59999999999923, 43.60000000000035, 42.700000000000344, 197.39999999999935, 40.0000000000003, 194.49999999999937, 37.80000000000027, 375.0, 213.3999999999993, 40.0000000000003, 198.99999999999935, 43.40000000000035, 26.400000000000084, 40.90000000000031, 377.0, 26.900000000000087, 40.0000000000003, 201.99999999999935, 219.99999999999926, -143.10000000000056, -64.99999999999989, 35.50000000000002, 29.200000000000127, 180.99999999999946, 40.0000000000003, 28.80000000000014, 207.99999999999932, 49.00000000000045, 32.30000000000018, 46.10000000000025, 38.90000000000028, 25.70000000000007, 215.99999999999926, 47.200000000000415, 38.90000000000028, -138.20000000000059, 206.99999999999932, 203.99999999999935, 36.100000000000236, 77.29999999999943, 45.000000000000384, 219.99999999999926, 36.80000000000025, 35.20000000000023, 207.99999999999932, 59.80000000000051, 31.200000000000166, -5.599999999999733, 26.500000000000092, 40.90000000000031, 44.60000000000039, 177.99999999999946, 197.99999999999937, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 34.60000000000022, 36.70000000000025, 38.80000000000028, -90.90000000000029, -68.90000000000066, 36.00000000000024, 40.0000000000003, 219.99999999999926, 37.80000000000027, 205.99999999999932, 343.3, 185.59999999999943, 37.30000000000026, 40.30000000000031, 40.0000000000003, 49.900000000000475, 211.9999999999993, 40.0000000000003, 40.0000000000003, 107.79999999999988, -133.50000000000063, 219.99999999999926, 40.0000000000003, 40.0000000000003, 183.59999999999945, 54.7000000000005, 25.500000000000068, 219.99999999999926, 199.69999999999936, 38.00000000000027, 40.0000000000003, 33.400000000000205, 35.70000000000024, 219.99999999999926, 40.0000000000003, 35.90000000000024, -11.699999999999655, 40.0000000000003, 216.69999999999928, 206.19999999999933, 22.300000000000022, 60.70000000000051, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 23.60000000000007, 23.600000000000065, 20.000000000000014, 22.700000000000056, 20.000000000000014, 176.0, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999964, 170.0, 15.799999999999963, 20.000000000000014, 200.0, 152.0, 200.0, 7.399999999999967, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.900000000000027, 21.500000000000036, 2.8999999999999684, 9.499999999999964, 20.900000000000027, 20.000000000000014, 185.0, 182.0, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 200.0, 20.000000000000014, 16.69999999999997, -332.8, -364.0, 20.000000000000014, 179.0, -305.49999999999994, 7.399999999999965, 15.799999999999963, 20.000000000000014, 125.0, 20.000000000000014, 20.000000000000014, 7.399999999999965, 10.399999999999979, 20.000000000000014, 173.0, 20.000000000000014, 29.000000000000163, 5.299999999999965, 20.000000000000014, 4.0999999999999694, -52.0, 17.899999999999988, 20.000000000000014, -7.299999999999891, 20.000000000000014, 194.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.19999999999993, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 176.0, 22.700000000000053, 7.399999999999965, -3.099999999999958, 61.40000000000016, 20.000000000000014, 23.00000000000006, 20.000000000000014, 200.0, 17.899999999999988, 17.899999999999988, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 182.0, 32.60000000000023, 27.200000000000134, 3.1999999999999615, 20.000000000000014, -80.80000000000082, 27.200000000000134, -7.299999999999901, 15.79999999999996, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.600000000000026, 20.000000000000014, 125.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999872, 13.699999999999964, 20.000000000000014, 12.79999999999997, 20.000000000000014, -229.9000000000001, 20.000000000000014, 20.000000000000014, -187.90000000000032, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 167.0, 20.000000000000014, 173.0, 134.3, 151.7, 17.899999999999988, 20.000000000000014, 8.299999999999969, 20.000000000000014, 8.299999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 35.0, -322.2999999999997, 18.799999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 155.0, 31.700000000000216, 20.000000000000014, 20.900000000000027, -9.399999999999855, 200.0, 20.000000000000014, 170.0, 13.699999999999964, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 15.799999999999963, 17.899999999999988, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 8.89999999999997, 20.000000000000014, 20.000000000000014, -78.70000000000071, 20.000000000000014, 20.000000000000014, 200.0, 13.69999999999997, 180.2, 20.000000000000014, -78.70000000000087, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 10.0, 5.0, 0.0, 2.0, 11.0, 12.0, 6.0, 0.0, 0.0, 0.0, 6.0, 9.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 4.0, 6.0, 0.0, 10.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 168.0, 5.0, 91.0, 188.0, 7.0, 155.0, 6.0, 0.0, 19.0, 17.0, 0.0, 0.0, 0.0, 11.0, 9.0, 6.0, 0.0, 0.0, 0.0, 7.0, 2.0, 92.0, 0.0, 1.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 162.0, 0.0, 3.0, 8.0, 8.0, 0.0, 6.0, 0.0, 11.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 4.0, 4.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 48.0, 12.0, 6.0, 0.0, 0.0, 0.0, 4.0, 9.0, 24.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 10.0, 3.0, 0.0, 6.0, 0.0, 119.0, 0.0, 99.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 8.0, 23.0, 13.0, 14.0, 2.0, 0.0, 9.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 55.0, 163.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 10.0, 6.0, 20.0, 20.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 47.0, 0.0, 0.0, 3.0, 0.0, 0.0, 6.0, 47.0, 34.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8325879201091123, "mean_inference_ms": 2.3911235142926746, "mean_action_processing_ms": 0.3778087252109493, "mean_env_wait_ms": 0.30393436191523227, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005243539810180664, "StateBufferConnector_ms": 0.005182385444641113, "ViewRequirementAgentConnector_ms": 0.1643970012664795}, "num_episodes": 22, "episode_return_max": 377.0, "episode_return_min": -143.10000000000056, "episode_return_mean": 86.90199999999993, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 302.15068111076124, "num_env_steps_trained_throughput_per_sec": 302.15068111076124, "timesteps_total": 572000, "num_env_steps_sampled_lifetime": 572000, "num_agent_steps_sampled_lifetime": 2288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2288000, "timers": {"training_iteration_time_ms": 12823.398, "restore_workers_time_ms": 0.021, "training_step_time_ms": 12823.322, "sample_time_ms": 1780.897, "learn_time_ms": 11023.784, "learn_throughput": 362.852, "synch_weights_time_ms": 14.629}, "counters": {"num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "done": false, "training_iteration": 143, "trial_id": "04dec_00002", "date": "2024-08-13_16-54-53", "timestamp": 1723582493, "time_this_iter_s": 13.313255310058594, "time_total_s": 1921.5529634952545, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06b7ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1921.5529634952545, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 66.49473684210525, "ram_util_percent": 83.65789473684212}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7733010793607387, "cur_kl_coeff": 1.0116907311896734e-15, "cur_lr": 0.00010000000000000003, "total_loss": 1.2557775936429463, "policy_loss": -0.00030488872003776055, "vf_loss": 1.2560824823600274, "vf_explained_var": 0.0014448172200924505, "kl": 0.0037958081639476045, "entropy": 0.21693655598573583, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 271215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.721948717203405, "cur_kl_coeff": 0.002709156449394001, "cur_lr": 0.00010000000000000003, "total_loss": 2.9790191505321117, "policy_loss": 0.0003905718151982578, "vf_loss": 2.9786024710488697, "vf_explained_var": 0.0956212442703348, "kl": 0.009637480597928632, "entropy": 0.7279606053595821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 271215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "env_runners": {"episode_reward_max": 343.3, "episode_reward_min": -180.60000000000065, "episode_reward_mean": 75.99899999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -388.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": 25.83949999999999, "predator_policy": 12.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, -143.10000000000056, -64.99999999999989, 35.50000000000002, 29.200000000000127, 180.99999999999946, 40.0000000000003, 28.80000000000014, 207.99999999999932, 49.00000000000045, 32.30000000000018, 46.10000000000025, 38.90000000000028, 25.70000000000007, 215.99999999999926, 47.200000000000415, 38.90000000000028, -138.20000000000059, 206.99999999999932, 203.99999999999935, 36.100000000000236, 77.29999999999943, 45.000000000000384, 219.99999999999926, 36.80000000000025, 35.20000000000023, 207.99999999999932, 59.80000000000051, 31.200000000000166, -5.599999999999733, 26.500000000000092, 40.90000000000031, 44.60000000000039, 177.99999999999946, 197.99999999999937, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 34.60000000000022, 36.70000000000025, 38.80000000000028, -90.90000000000029, -68.90000000000066, 36.00000000000024, 40.0000000000003, 219.99999999999926, 37.80000000000027, 205.99999999999932, 343.3, 185.59999999999943, 37.30000000000026, 40.30000000000031, 40.0000000000003, 49.900000000000475, 211.9999999999993, 40.0000000000003, 40.0000000000003, 107.79999999999988, -133.50000000000063, 219.99999999999926, 40.0000000000003, 40.0000000000003, 183.59999999999945, 54.7000000000005, 25.500000000000068, 219.99999999999926, 199.69999999999936, 38.00000000000027, 40.0000000000003, 33.400000000000205, 35.70000000000024, 219.99999999999926, 40.0000000000003, 35.90000000000024, -11.699999999999655, 40.0000000000003, 216.69999999999928, 206.19999999999933, 22.300000000000022, 60.70000000000051, 40.0000000000003, 40.0000000000003, -7.299999999999677, 203.99999999999935, -180.60000000000065, -18.299999999999542, 219.99999999999926, 206.79999999999933, 204.89999999999932, 40.90000000000031, 191.7999999999994, 40.0000000000003, 34.50000000000022, 59.20000000000049, 32.30000000000019, 40.0000000000003, 96.99999999999997, 36.70000000000025, 31.400000000000173], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 20.000000000000014, 16.69999999999997, -332.8, -364.0, 20.000000000000014, 179.0, -305.49999999999994, 7.399999999999965, 15.799999999999963, 20.000000000000014, 125.0, 20.000000000000014, 20.000000000000014, 7.399999999999965, 10.399999999999979, 20.000000000000014, 173.0, 20.000000000000014, 29.000000000000163, 5.299999999999965, 20.000000000000014, 4.0999999999999694, -52.0, 17.899999999999988, 20.000000000000014, -7.299999999999891, 20.000000000000014, 194.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.19999999999993, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 176.0, 22.700000000000053, 7.399999999999965, -3.099999999999958, 61.40000000000016, 20.000000000000014, 23.00000000000006, 20.000000000000014, 200.0, 17.899999999999988, 17.899999999999988, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 182.0, 32.60000000000023, 27.200000000000134, 3.1999999999999615, 20.000000000000014, -80.80000000000082, 27.200000000000134, -7.299999999999901, 15.79999999999996, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.600000000000026, 20.000000000000014, 125.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999872, 13.699999999999964, 20.000000000000014, 12.79999999999997, 20.000000000000014, -229.9000000000001, 20.000000000000014, 20.000000000000014, -187.90000000000032, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 167.0, 20.000000000000014, 173.0, 134.3, 151.7, 17.899999999999988, 20.000000000000014, 8.299999999999969, 20.000000000000014, 8.299999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 35.0, -322.2999999999997, 18.799999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 155.0, 31.700000000000216, 20.000000000000014, 20.900000000000027, -9.399999999999855, 200.0, 20.000000000000014, 170.0, 13.699999999999964, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 15.799999999999963, 17.899999999999988, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 8.89999999999997, 20.000000000000014, 20.000000000000014, -78.70000000000071, 20.000000000000014, 20.000000000000014, 200.0, 13.69999999999997, 180.2, 20.000000000000014, -78.70000000000087, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, 176.0, 20.000000000000014, 4.999999999999966, -388.6, -91.30000000000081, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -5.200000000000001, 17.899999999999984, 179.0, 20.000000000000014, 20.900000000000027, 155.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 36.200000000000244, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.0, 20.000000000000014, 13.699999999999964, -0.40000000000001346, 15.799999999999963], "policy_predator_policy_reward": [0.0, 0.0, 168.0, 5.0, 91.0, 188.0, 7.0, 155.0, 6.0, 0.0, 19.0, 17.0, 0.0, 0.0, 0.0, 11.0, 9.0, 6.0, 0.0, 0.0, 0.0, 7.0, 2.0, 92.0, 0.0, 1.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 162.0, 0.0, 3.0, 8.0, 8.0, 0.0, 6.0, 0.0, 11.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 4.0, 4.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 48.0, 12.0, 6.0, 0.0, 0.0, 0.0, 4.0, 9.0, 24.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 10.0, 3.0, 0.0, 6.0, 0.0, 119.0, 0.0, 99.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 8.0, 23.0, 13.0, 14.0, 2.0, 0.0, 9.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 55.0, 163.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 10.0, 6.0, 20.0, 20.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 47.0, 0.0, 0.0, 3.0, 0.0, 0.0, 6.0, 47.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 8.0, 5.0, 198.0, 53.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 33.0, 33.0, 3.0, 0.0, 14.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8321251194771766, "mean_inference_ms": 2.390949084661509, "mean_action_processing_ms": 0.3772942152229834, "mean_env_wait_ms": 0.30370512120712356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004927873611450195, "StateBufferConnector_ms": 0.0052651166915893555, "ViewRequirementAgentConnector_ms": 0.17026805877685547}, "num_episodes": 18, "episode_return_max": 343.3, "episode_return_min": -180.60000000000065, "episode_return_mean": 75.99899999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.4414532948977, "num_env_steps_trained_throughput_per_sec": 324.4414532948977, "timesteps_total": 576000, "num_env_steps_sampled_lifetime": 576000, "num_agent_steps_sampled_lifetime": 2304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2304000, "timers": {"training_iteration_time_ms": 12767.243, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12767.194, "sample_time_ms": 1732.671, "learn_time_ms": 11015.433, "learn_throughput": 363.127, "synch_weights_time_ms": 14.97}, "counters": {"num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "done": false, "training_iteration": 144, "trial_id": "04dec_00002", "date": "2024-08-13_16-55-05", "timestamp": 1723582505, "time_this_iter_s": 12.361534833908081, "time_total_s": 1933.9144983291626, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06fc670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1933.9144983291626, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 65.82352941176471, "ram_util_percent": 83.49411764705881}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5126820426217462, "cur_kl_coeff": 5.058453655948367e-16, "cur_lr": 0.00010000000000000003, "total_loss": 2.4961131302137223, "policy_loss": -0.00023174089251490183, "vf_loss": 2.496344870991177, "vf_explained_var": 0.0012380407285438014, "kl": 0.0031902524796286425, "entropy": 0.15216851683047714, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 273105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.390355624502929, "cur_kl_coeff": 0.002709156449394001, "cur_lr": 0.00010000000000000003, "total_loss": 4.154948526463181, "policy_loss": -0.00017179539131503257, "vf_loss": 4.155105674708331, "vf_explained_var": -0.05709136904232086, "kl": 0.0054091818902455005, "entropy": 0.6236877224905781, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 273105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "env_runners": {"episode_reward_max": 343.3, "episode_reward_min": -180.60000000000065, "episode_reward_mean": 78.18999999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 23.749999999999986, "predator_policy": 15.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [206.99999999999932, 203.99999999999935, 36.100000000000236, 77.29999999999943, 45.000000000000384, 219.99999999999926, 36.80000000000025, 35.20000000000023, 207.99999999999932, 59.80000000000051, 31.200000000000166, -5.599999999999733, 26.500000000000092, 40.90000000000031, 44.60000000000039, 177.99999999999946, 197.99999999999937, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 34.60000000000022, 36.70000000000025, 38.80000000000028, -90.90000000000029, -68.90000000000066, 36.00000000000024, 40.0000000000003, 219.99999999999926, 37.80000000000027, 205.99999999999932, 343.3, 185.59999999999943, 37.30000000000026, 40.30000000000031, 40.0000000000003, 49.900000000000475, 211.9999999999993, 40.0000000000003, 40.0000000000003, 107.79999999999988, -133.50000000000063, 219.99999999999926, 40.0000000000003, 40.0000000000003, 183.59999999999945, 54.7000000000005, 25.500000000000068, 219.99999999999926, 199.69999999999936, 38.00000000000027, 40.0000000000003, 33.400000000000205, 35.70000000000024, 219.99999999999926, 40.0000000000003, 35.90000000000024, -11.699999999999655, 40.0000000000003, 216.69999999999928, 206.19999999999933, 22.300000000000022, 60.70000000000051, 40.0000000000003, 40.0000000000003, -7.299999999999677, 203.99999999999935, -180.60000000000065, -18.299999999999542, 219.99999999999926, 206.79999999999933, 204.89999999999932, 40.90000000000031, 191.7999999999994, 40.0000000000003, 34.50000000000022, 59.20000000000049, 32.30000000000019, 40.0000000000003, 96.99999999999997, 36.70000000000025, 31.400000000000173, -75.00000000000003, -146.80000000000058, 17.99999999999999, 214.59999999999928, 40.0000000000003, 219.99999999999926, -47.0, -55.99999999999988, 199.99999999999935, 40.0000000000003, 40.0000000000003, 33.5000000000002, 302.5, 10.199999999999946, 198.29999999999936, 28.10000000000012, 40.0000000000003, 49.00000000000046], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 176.0, 20.000000000000014, 176.0, 22.700000000000053, 7.399999999999965, -3.099999999999958, 61.40000000000016, 20.000000000000014, 23.00000000000006, 20.000000000000014, 200.0, 17.899999999999988, 17.899999999999988, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 182.0, 32.60000000000023, 27.200000000000134, 3.1999999999999615, 20.000000000000014, -80.80000000000082, 27.200000000000134, -7.299999999999901, 15.79999999999996, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.600000000000026, 20.000000000000014, 125.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999872, 13.699999999999964, 20.000000000000014, 12.79999999999997, 20.000000000000014, -229.9000000000001, 20.000000000000014, 20.000000000000014, -187.90000000000032, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 167.0, 20.000000000000014, 173.0, 134.3, 151.7, 17.899999999999988, 20.000000000000014, 8.299999999999969, 20.000000000000014, 8.299999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 35.0, -322.2999999999997, 18.799999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 155.0, 31.700000000000216, 20.000000000000014, 20.900000000000027, -9.399999999999855, 200.0, 20.000000000000014, 170.0, 13.699999999999964, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 15.799999999999963, 17.899999999999988, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 8.89999999999997, 20.000000000000014, 20.000000000000014, -78.70000000000071, 20.000000000000014, 20.000000000000014, 200.0, 13.69999999999997, 180.2, 20.000000000000014, -78.70000000000087, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, 176.0, 20.000000000000014, 4.999999999999966, -388.6, -91.30000000000081, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -5.200000000000001, 17.899999999999984, 179.0, 20.000000000000014, 20.900000000000027, 155.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 36.200000000000244, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.0, 20.000000000000014, 13.699999999999964, -0.40000000000001346, 15.799999999999963, -376.0, 20.000000000000014, 20.000000000000014, -350.8, 20.000000000000014, -400.0, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -286.0, 32.0, 20.000000000000014, -361.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 9.79999999999997, 120.5, 149.0, -89.20000000000084, -55.599999999999994, 173.3, 20.000000000000014, 17.899999999999988, -20.799999999999756, 20.000000000000014, 20.000000000000014, 29.00000000000017, 20.000000000000014], "policy_predator_policy_reward": [3.0, 8.0, 8.0, 0.0, 6.0, 0.0, 11.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 4.0, 4.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 48.0, 12.0, 6.0, 0.0, 0.0, 0.0, 4.0, 9.0, 24.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 10.0, 3.0, 0.0, 6.0, 0.0, 119.0, 0.0, 99.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 8.0, 23.0, 13.0, 14.0, 2.0, 0.0, 9.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 55.0, 163.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 10.0, 6.0, 20.0, 20.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 47.0, 0.0, 0.0, 3.0, 0.0, 0.0, 6.0, 47.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 8.0, 5.0, 198.0, 53.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 33.0, 33.0, 3.0, 0.0, 14.0, 2.0, 89.0, 192.0, 183.0, 1.0, 200.0, 198.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.0, 162.0, 184.0, 101.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 25.0, 8.0, 75.0, 80.0, 5.0, 0.0, 10.0, 21.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8321535058135798, "mean_inference_ms": 2.3915334726776116, "mean_action_processing_ms": 0.3769157673627595, "mean_env_wait_ms": 0.3036074990836356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004575133323669434, "StateBufferConnector_ms": 0.005283951759338379, "ViewRequirementAgentConnector_ms": 0.1719987392425537}, "num_episodes": 18, "episode_return_max": 343.3, "episode_return_min": -180.60000000000065, "episode_return_mean": 78.18999999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.0033215772613, "num_env_steps_trained_throughput_per_sec": 311.0033215772613, "timesteps_total": 580000, "num_env_steps_sampled_lifetime": 580000, "num_agent_steps_sampled_lifetime": 2320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2320000, "timers": {"training_iteration_time_ms": 12816.078, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12816.029, "sample_time_ms": 1790.538, "learn_time_ms": 11006.959, "learn_throughput": 363.406, "synch_weights_time_ms": 14.914}, "counters": {"num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "done": false, "training_iteration": 145, "trial_id": "04dec_00002", "date": "2024-08-13_16-55-18", "timestamp": 1723582518, "time_this_iter_s": 12.920217037200928, "time_total_s": 1946.8347153663635, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0720820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1946.8347153663635, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 64.0, "ram_util_percent": 83.36842105263158}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1669102250110535, "cur_kl_coeff": 2.5292268279741835e-16, "cur_lr": 0.00010000000000000003, "total_loss": 2.8369518780203724, "policy_loss": -0.002100794934347351, "vf_loss": 2.8390526705318027, "vf_explained_var": -0.00011248090279796136, "kl": 0.011653173056873016, "entropy": 0.18883788509580193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 274995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.22588419600454, "cur_kl_coeff": 0.002709156449394001, "cur_lr": 0.00010000000000000003, "total_loss": 3.3904044140583625, "policy_loss": 0.00035756676058684077, "vf_loss": 3.390023802197169, "vf_explained_var": -0.0611287497654163, "kl": 0.008504261980278083, "entropy": 0.7537675373768681, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 274995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "env_runners": {"episode_reward_max": 343.3, "episode_reward_min": -496.0, "episode_reward_mean": 69.21699999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 12.228499999999986, "predator_policy": 22.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.80000000000028, -90.90000000000029, -68.90000000000066, 36.00000000000024, 40.0000000000003, 219.99999999999926, 37.80000000000027, 205.99999999999932, 343.3, 185.59999999999943, 37.30000000000026, 40.30000000000031, 40.0000000000003, 49.900000000000475, 211.9999999999993, 40.0000000000003, 40.0000000000003, 107.79999999999988, -133.50000000000063, 219.99999999999926, 40.0000000000003, 40.0000000000003, 183.59999999999945, 54.7000000000005, 25.500000000000068, 219.99999999999926, 199.69999999999936, 38.00000000000027, 40.0000000000003, 33.400000000000205, 35.70000000000024, 219.99999999999926, 40.0000000000003, 35.90000000000024, -11.699999999999655, 40.0000000000003, 216.69999999999928, 206.19999999999933, 22.300000000000022, 60.70000000000051, 40.0000000000003, 40.0000000000003, -7.299999999999677, 203.99999999999935, -180.60000000000065, -18.299999999999542, 219.99999999999926, 206.79999999999933, 204.89999999999932, 40.90000000000031, 191.7999999999994, 40.0000000000003, 34.50000000000022, 59.20000000000049, 32.30000000000019, 40.0000000000003, 96.99999999999997, 36.70000000000025, 31.400000000000173, -75.00000000000003, -146.80000000000058, 17.99999999999999, 214.59999999999928, 40.0000000000003, 219.99999999999926, -47.0, -55.99999999999988, 199.99999999999935, 40.0000000000003, 40.0000000000003, 33.5000000000002, 302.5, 10.199999999999946, 198.29999999999936, 28.10000000000012, 40.0000000000003, 49.00000000000046, 219.99999999999926, 31.200000000000177, 40.0000000000003, 44.9000000000004, 190.0999999999994, 228.09999999999923, 32.30000000000018, -374.0, 219.99999999999926, 31.20000000000018, 219.99999999999926, -496.0, -88.00000000000065, -50.09999999999977, 202.0, 40.0000000000003, 19.90000000000002, 217.79999999999927, -13.899999999999569, 145.2999999999996, 215.99999999999926, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [12.79999999999997, 20.000000000000014, -229.9000000000001, 20.000000000000014, 20.000000000000014, -187.90000000000032, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 167.0, 20.000000000000014, 173.0, 134.3, 151.7, 17.899999999999988, 20.000000000000014, 8.299999999999969, 20.000000000000014, 8.299999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 35.0, -322.2999999999997, 18.799999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 155.0, 31.700000000000216, 20.000000000000014, 20.900000000000027, -9.399999999999855, 200.0, 20.000000000000014, 170.0, 13.699999999999964, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 15.799999999999963, 17.899999999999988, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 8.89999999999997, 20.000000000000014, 20.000000000000014, -78.70000000000071, 20.000000000000014, 20.000000000000014, 200.0, 13.69999999999997, 180.2, 20.000000000000014, -78.70000000000087, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, 176.0, 20.000000000000014, 4.999999999999966, -388.6, -91.30000000000081, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -5.200000000000001, 17.899999999999984, 179.0, 20.000000000000014, 20.900000000000027, 155.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 36.200000000000244, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.0, 20.000000000000014, 13.699999999999964, -0.40000000000001346, 15.799999999999963, -376.0, 20.000000000000014, 20.000000000000014, -350.8, 20.000000000000014, -400.0, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -286.0, 32.0, 20.000000000000014, -361.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 9.79999999999997, 120.5, 149.0, -89.20000000000084, -55.599999999999994, 173.3, 20.000000000000014, 17.899999999999988, -20.799999999999756, 20.000000000000014, 20.000000000000014, 29.00000000000017, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 31.7000000000002, 20.000000000000014, 136.1, 28.100000000000147, 200.0, 5.299999999999965, 20.000000000000014, -382.0, -379.0, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 200.0, 20.000000000000014, -400.0, -385.0, -400.0, 20.000000000000014, 17.899999999999988, -385.0, -97.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, -97.0, 15.799999999999963, 200.0, -82.90000000000086, 20.000000000000014, 107.3, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [6.0, 0.0, 119.0, 0.0, 99.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 8.0, 23.0, 13.0, 14.0, 2.0, 0.0, 9.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 55.0, 163.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 10.0, 6.0, 20.0, 20.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 47.0, 0.0, 0.0, 3.0, 0.0, 0.0, 6.0, 47.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 8.0, 5.0, 198.0, 53.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 33.0, 33.0, 3.0, 0.0, 14.0, 2.0, 89.0, 192.0, 183.0, 1.0, 200.0, 198.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.0, 162.0, 184.0, 101.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 25.0, 8.0, 75.0, 80.0, 5.0, 0.0, 10.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 8.0, 21.0, 13.0, 0.0, 0.0, 7.0, 0.0, 194.0, 193.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 180.0, 109.0, 92.0, 200.0, 195.0, 122.0, 0.0, 99.0, 0.0, 0.0, 92.0, 7.0, 2.0, 0.0, 0.0, 49.0, 18.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8327294239017423, "mean_inference_ms": 2.39381348233958, "mean_action_processing_ms": 0.3767273737235549, "mean_env_wait_ms": 0.30370146862676195, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006773710250854492, "StateBufferConnector_ms": 0.0036826133728027344, "ViewRequirementAgentConnector_ms": 0.18554651737213135}, "num_episodes": 23, "episode_return_max": 343.3, "episode_return_min": -496.0, "episode_return_mean": 69.21699999999993, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.58011522557325, "num_env_steps_trained_throughput_per_sec": 294.58011522557325, "timesteps_total": 584000, "num_env_steps_sampled_lifetime": 584000, "num_agent_steps_sampled_lifetime": 2336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2336000, "timers": {"training_iteration_time_ms": 12907.406, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12907.359, "sample_time_ms": 1863.34, "learn_time_ms": 11026.017, "learn_throughput": 362.778, "synch_weights_time_ms": 14.445}, "counters": {"num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "done": false, "training_iteration": 146, "trial_id": "04dec_00002", "date": "2024-08-13_16-55-32", "timestamp": 1723582532, "time_this_iter_s": 13.641566038131714, "time_total_s": 1960.4762814044952, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06b7dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1960.4762814044952, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 66.98421052631578, "ram_util_percent": 83.42105263157895}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8327505398206609, "cur_kl_coeff": 2.5292268279741835e-16, "cur_lr": 0.00010000000000000003, "total_loss": 3.576412430389848, "policy_loss": -0.0014295668974420223, "vf_loss": 3.577841993740627, "vf_explained_var": 0.0002549982575512437, "kl": 0.004072020827150255, "entropy": 0.10651232730005941, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 276885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.049923124144632, "cur_kl_coeff": 0.002709156449394001, "cur_lr": 0.00010000000000000003, "total_loss": 3.542549575951995, "policy_loss": -0.0008428484862965961, "vf_loss": 3.543367097869752, "vf_explained_var": -0.018718506230248344, "kl": 0.009349599382800094, "entropy": 0.6349422940028407, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 276885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "env_runners": {"episode_reward_max": 302.5, "episode_reward_min": -496.0, "episode_reward_mean": 58.22299999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -5.573500000000019, "predator_policy": 34.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.59999999999945, 54.7000000000005, 25.500000000000068, 219.99999999999926, 199.69999999999936, 38.00000000000027, 40.0000000000003, 33.400000000000205, 35.70000000000024, 219.99999999999926, 40.0000000000003, 35.90000000000024, -11.699999999999655, 40.0000000000003, 216.69999999999928, 206.19999999999933, 22.300000000000022, 60.70000000000051, 40.0000000000003, 40.0000000000003, -7.299999999999677, 203.99999999999935, -180.60000000000065, -18.299999999999542, 219.99999999999926, 206.79999999999933, 204.89999999999932, 40.90000000000031, 191.7999999999994, 40.0000000000003, 34.50000000000022, 59.20000000000049, 32.30000000000019, 40.0000000000003, 96.99999999999997, 36.70000000000025, 31.400000000000173, -75.00000000000003, -146.80000000000058, 17.99999999999999, 214.59999999999928, 40.0000000000003, 219.99999999999926, -47.0, -55.99999999999988, 199.99999999999935, 40.0000000000003, 40.0000000000003, 33.5000000000002, 302.5, 10.199999999999946, 198.29999999999936, 28.10000000000012, 40.0000000000003, 49.00000000000046, 219.99999999999926, 31.200000000000177, 40.0000000000003, 44.9000000000004, 190.0999999999994, 228.09999999999923, 32.30000000000018, -374.0, 219.99999999999926, 31.20000000000018, 219.99999999999926, -496.0, -88.00000000000065, -50.09999999999977, 202.0, 40.0000000000003, 19.90000000000002, 217.79999999999927, -13.899999999999569, 145.2999999999996, 215.99999999999926, 40.0000000000003, 40.0000000000003, -165.4000000000006, 37.80000000000027, -358.0, 40.0000000000003, 138.0, 40.0000000000003, 3.9999999999999627, 21.800000000000015, 180.8, 34.50000000000022, 40.0000000000003, 26.80000000000009, 40.0000000000003, 122.19999999999882, 37.40000000000027, 189.1, 39.9000000000003, 30.100000000000147, -27.99999999999976, -140.0000000000004, 32.00000000000022, 219.09999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 155.0, 31.700000000000216, 20.000000000000014, 20.900000000000027, -9.399999999999855, 200.0, 20.000000000000014, 170.0, 13.699999999999964, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 15.799999999999963, 17.899999999999988, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 8.89999999999997, 20.000000000000014, 20.000000000000014, -78.70000000000071, 20.000000000000014, 20.000000000000014, 200.0, 13.69999999999997, 180.2, 20.000000000000014, -78.70000000000087, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, 176.0, 20.000000000000014, 4.999999999999966, -388.6, -91.30000000000081, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -5.200000000000001, 17.899999999999984, 179.0, 20.000000000000014, 20.900000000000027, 155.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 36.200000000000244, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.0, 20.000000000000014, 13.699999999999964, -0.40000000000001346, 15.799999999999963, -376.0, 20.000000000000014, 20.000000000000014, -350.8, 20.000000000000014, -400.0, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -286.0, 32.0, 20.000000000000014, -361.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 9.79999999999997, 120.5, 149.0, -89.20000000000084, -55.599999999999994, 173.3, 20.000000000000014, 17.899999999999988, -20.799999999999756, 20.000000000000014, 20.000000000000014, 29.00000000000017, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 31.7000000000002, 20.000000000000014, 136.1, 28.100000000000147, 200.0, 5.299999999999965, 20.000000000000014, -382.0, -379.0, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 200.0, 20.000000000000014, -400.0, -385.0, -400.0, 20.000000000000014, 17.899999999999988, -385.0, -97.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, -97.0, 15.799999999999963, 200.0, -82.90000000000086, 20.000000000000014, 107.3, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999959, -370.0, 15.799999999999963, 20.000000000000014, -358.0, -376.0, 20.000000000000014, 20.000000000000014, 122.0, -370.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 5.299999999999965, 9.499999999999964, -394.0, 183.8, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.29999999999949, 17.899999999999988, 11.599999999999966, 21.800000000000047, 179.0, -382.9, 17.899999999999988, 20.000000000000014, 1.0999999999999794, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, -340.0, -370.0, 29.000000000000163, 199.1, 20.000000000000014], "policy_predator_policy_reward": [17.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 10.0, 6.0, 20.0, 20.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 47.0, 0.0, 0.0, 3.0, 0.0, 0.0, 6.0, 47.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 8.0, 5.0, 198.0, 53.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 33.0, 33.0, 3.0, 0.0, 14.0, 2.0, 89.0, 192.0, 183.0, 1.0, 200.0, 198.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.0, 162.0, 184.0, 101.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 25.0, 8.0, 75.0, 80.0, 5.0, 0.0, 10.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 8.0, 21.0, 13.0, 0.0, 0.0, 7.0, 0.0, 194.0, 193.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 180.0, 109.0, 92.0, 200.0, 195.0, 122.0, 0.0, 99.0, 0.0, 0.0, 92.0, 7.0, 2.0, 0.0, 0.0, 49.0, 18.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 12.0, 0.0, 2.0, 184.0, 192.0, 0.0, 0.0, 186.0, 200.0, 0.0, 0.0, 200.0, 184.0, 7.0, 0.0, 193.0, 198.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 197.0, 196.0, 1.0, 1.0, 9.0, 0.0, 182.0, 125.0, 180.0, 0.0, 183.0, 190.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8335154719736405, "mean_inference_ms": 2.3939350455250503, "mean_action_processing_ms": 0.3767099786153754, "mean_env_wait_ms": 0.3037977075698986, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0067147016525268555, "StateBufferConnector_ms": 0.0038336515426635742, "ViewRequirementAgentConnector_ms": 0.16790294647216797}, "num_episodes": 22, "episode_return_max": 302.5, "episode_return_min": -496.0, "episode_return_mean": 58.22299999999995, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.4133496927033, "num_env_steps_trained_throughput_per_sec": 298.4133496927033, "timesteps_total": 588000, "num_env_steps_sampled_lifetime": 588000, "num_agent_steps_sampled_lifetime": 2352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2352000, "timers": {"training_iteration_time_ms": 12993.812, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12993.754, "sample_time_ms": 1868.304, "learn_time_ms": 11106.061, "learn_throughput": 360.164, "synch_weights_time_ms": 15.852}, "counters": {"num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "done": false, "training_iteration": 147, "trial_id": "04dec_00002", "date": "2024-08-13_16-55-46", "timestamp": 1723582546, "time_this_iter_s": 13.472512006759644, "time_total_s": 1973.9487934112549, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06b7310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1973.9487934112549, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 65.98947368421051, "ram_util_percent": 83.43684210526317}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7414710190797609, "cur_kl_coeff": 1.2646134139870917e-16, "cur_lr": 0.00010000000000000003, "total_loss": 1.795413123678278, "policy_loss": -0.0013503440350254691, "vf_loss": 1.7967634683878964, "vf_explained_var": 0.0042143211793647245, "kl": 0.003226024284444242, "entropy": 0.13467871933465914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 278775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.215380242624611, "cur_kl_coeff": 0.002709156449394001, "cur_lr": 0.00010000000000000003, "total_loss": 3.1042690092293674, "policy_loss": -3.500989276087946e-05, "vf_loss": 3.104294321965919, "vf_explained_var": 0.03854436120658955, "kl": 0.0035839131155192914, "entropy": 0.6906174728163966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 278775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "env_runners": {"episode_reward_max": 302.5, "episode_reward_min": -496.0, "episode_reward_mean": 57.83899999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -8.780500000000016, "predator_policy": 37.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, -7.299999999999677, 203.99999999999935, -180.60000000000065, -18.299999999999542, 219.99999999999926, 206.79999999999933, 204.89999999999932, 40.90000000000031, 191.7999999999994, 40.0000000000003, 34.50000000000022, 59.20000000000049, 32.30000000000019, 40.0000000000003, 96.99999999999997, 36.70000000000025, 31.400000000000173, -75.00000000000003, -146.80000000000058, 17.99999999999999, 214.59999999999928, 40.0000000000003, 219.99999999999926, -47.0, -55.99999999999988, 199.99999999999935, 40.0000000000003, 40.0000000000003, 33.5000000000002, 302.5, 10.199999999999946, 198.29999999999936, 28.10000000000012, 40.0000000000003, 49.00000000000046, 219.99999999999926, 31.200000000000177, 40.0000000000003, 44.9000000000004, 190.0999999999994, 228.09999999999923, 32.30000000000018, -374.0, 219.99999999999926, 31.20000000000018, 219.99999999999926, -496.0, -88.00000000000065, -50.09999999999977, 202.0, 40.0000000000003, 19.90000000000002, 217.79999999999927, -13.899999999999569, 145.2999999999996, 215.99999999999926, 40.0000000000003, 40.0000000000003, -165.4000000000006, 37.80000000000027, -358.0, 40.0000000000003, 138.0, 40.0000000000003, 3.9999999999999627, 21.800000000000015, 180.8, 34.50000000000022, 40.0000000000003, 26.80000000000009, 40.0000000000003, 122.19999999999882, 37.40000000000027, 189.1, 39.9000000000003, 30.100000000000147, -27.99999999999976, -140.0000000000004, 32.00000000000022, 219.09999999999926, 181.19999999999948, 219.99999999999926, 181.49999999999946, 39.9000000000003, 40.0000000000003, 40.0000000000003, -6.999999999999842, 178.0, 40.0000000000003, 39.800000000000296, 40.0000000000003, 40.0000000000003, 176.2999999999995, 233.49999999999952, 2.0000000000000897, 219.99999999999926, -80.7000000000001, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, 176.0, 20.000000000000014, 4.999999999999966, -388.6, -91.30000000000081, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -5.200000000000001, 17.899999999999984, 179.0, 20.000000000000014, 20.900000000000027, 155.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 36.200000000000244, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.0, 20.000000000000014, 13.699999999999964, -0.40000000000001346, 15.799999999999963, -376.0, 20.000000000000014, 20.000000000000014, -350.8, 20.000000000000014, -400.0, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -286.0, 32.0, 20.000000000000014, -361.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 9.79999999999997, 120.5, 149.0, -89.20000000000084, -55.599999999999994, 173.3, 20.000000000000014, 17.899999999999988, -20.799999999999756, 20.000000000000014, 20.000000000000014, 29.00000000000017, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 31.7000000000002, 20.000000000000014, 136.1, 28.100000000000147, 200.0, 5.299999999999965, 20.000000000000014, -382.0, -379.0, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 200.0, 20.000000000000014, -400.0, -385.0, -400.0, 20.000000000000014, 17.899999999999988, -385.0, -97.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, -97.0, 15.799999999999963, 200.0, -82.90000000000086, 20.000000000000014, 107.3, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999959, -370.0, 15.799999999999963, 20.000000000000014, -358.0, -376.0, 20.000000000000014, 20.000000000000014, 122.0, -370.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 5.299999999999965, 9.499999999999964, -394.0, 183.8, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.29999999999949, 17.899999999999988, 11.599999999999966, 21.800000000000047, 179.0, -382.9, 17.899999999999988, 20.000000000000014, 1.0999999999999794, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, -340.0, -370.0, 29.000000000000163, 199.1, 20.000000000000014, 3.1999999999999615, 167.0, 20.000000000000014, 200.0, -53.49999999999983, 200.0, 20.000000000000014, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, -225.70000000000047, 200.0, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 42.500000000000135, 182.0, -169.0, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, -373.0, 20.000000000000014, 15.799999999999963], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 8.0, 5.0, 198.0, 53.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 33.0, 33.0, 3.0, 0.0, 14.0, 2.0, 89.0, 192.0, 183.0, 1.0, 200.0, 198.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.0, 162.0, 184.0, 101.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 25.0, 8.0, 75.0, 80.0, 5.0, 0.0, 10.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 8.0, 21.0, 13.0, 0.0, 0.0, 7.0, 0.0, 194.0, 193.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 180.0, 109.0, 92.0, 200.0, 195.0, 122.0, 0.0, 99.0, 0.0, 0.0, 92.0, 7.0, 2.0, 0.0, 0.0, 49.0, 18.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 12.0, 0.0, 2.0, 184.0, 192.0, 0.0, 0.0, 186.0, 200.0, 0.0, 0.0, 200.0, 184.0, 7.0, 0.0, 193.0, 198.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 197.0, 196.0, 1.0, 1.0, 9.0, 0.0, 182.0, 125.0, 180.0, 0.0, 183.0, 190.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 95.0, 110.0, 96.0, 36.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 6.0, 56.0, 95.0, 0.0, 0.0, 191.0, 96.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8339283656820743, "mean_inference_ms": 2.397366228378134, "mean_action_processing_ms": 0.3765202732920768, "mean_env_wait_ms": 0.3038835118803738, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006709694862365723, "StateBufferConnector_ms": 0.0036089420318603516, "ViewRequirementAgentConnector_ms": 0.14103257656097412}, "num_episodes": 18, "episode_return_max": 302.5, "episode_return_min": -496.0, "episode_return_mean": 57.83899999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.3063533413712, "num_env_steps_trained_throughput_per_sec": 310.3063533413712, "timesteps_total": 592000, "num_env_steps_sampled_lifetime": 592000, "num_agent_steps_sampled_lifetime": 2368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2368000, "timers": {"training_iteration_time_ms": 12986.632, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12986.575, "sample_time_ms": 1874.888, "learn_time_ms": 11091.627, "learn_throughput": 360.632, "synch_weights_time_ms": 16.063}, "counters": {"num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "done": false, "training_iteration": 148, "trial_id": "04dec_00002", "date": "2024-08-13_16-55-59", "timestamp": 1723582559, "time_this_iter_s": 12.963318109512329, "time_total_s": 1986.9121115207672, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0631e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1986.9121115207672, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 65.29444444444445, "ram_util_percent": 83.6277777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9814885518774784, "cur_kl_coeff": 6.323067069935459e-17, "cur_lr": 0.00010000000000000003, "total_loss": 2.2122236533770487, "policy_loss": -4.150867844049735e-05, "vf_loss": 2.212265161799375, "vf_explained_var": -0.00017567157114624346, "kl": 0.0018672309540788891, "entropy": 0.08229143430020601, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 280665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.821800487350535, "cur_kl_coeff": 0.0013545782246970005, "cur_lr": 0.00010000000000000003, "total_loss": 3.3196969766465445, "policy_loss": -0.0003718636150190991, "vf_loss": 3.320061122235798, "vf_explained_var": 0.008187066877960529, "kl": 0.005693710331628248, "entropy": 0.6467106654845848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 280665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "env_runners": {"episode_reward_max": 302.5, "episode_reward_min": -496.0, "episode_reward_mean": 60.74499999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -13.397500000000012, "predator_policy": 43.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.400000000000173, -75.00000000000003, -146.80000000000058, 17.99999999999999, 214.59999999999928, 40.0000000000003, 219.99999999999926, -47.0, -55.99999999999988, 199.99999999999935, 40.0000000000003, 40.0000000000003, 33.5000000000002, 302.5, 10.199999999999946, 198.29999999999936, 28.10000000000012, 40.0000000000003, 49.00000000000046, 219.99999999999926, 31.200000000000177, 40.0000000000003, 44.9000000000004, 190.0999999999994, 228.09999999999923, 32.30000000000018, -374.0, 219.99999999999926, 31.20000000000018, 219.99999999999926, -496.0, -88.00000000000065, -50.09999999999977, 202.0, 40.0000000000003, 19.90000000000002, 217.79999999999927, -13.899999999999569, 145.2999999999996, 215.99999999999926, 40.0000000000003, 40.0000000000003, -165.4000000000006, 37.80000000000027, -358.0, 40.0000000000003, 138.0, 40.0000000000003, 3.9999999999999627, 21.800000000000015, 180.8, 34.50000000000022, 40.0000000000003, 26.80000000000009, 40.0000000000003, 122.19999999999882, 37.40000000000027, 189.1, 39.9000000000003, 30.100000000000147, -27.99999999999976, -140.0000000000004, 32.00000000000022, 219.09999999999926, 181.19999999999948, 219.99999999999926, 181.49999999999946, 39.9000000000003, 40.0000000000003, 40.0000000000003, -6.999999999999842, 178.0, 40.0000000000003, 39.800000000000296, 40.0000000000003, 40.0000000000003, 176.2999999999995, 233.49999999999952, 2.0000000000000897, 219.99999999999926, -80.7000000000001, 37.80000000000027, 40.0000000000003, 35.600000000000236, 17.99999999999999, 161.0, 214.4999999999993, 190.29999999999941, 40.0000000000003, -6.999999999999899, 41.800000000000296, 40.0000000000003, 76.00000000000003, 32.30000000000018, 199.99999999999935, 210.5999999999993, 37.80000000000027, 194.89999999999938, 40.0000000000003, 6.699999999999964], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.40000000000001346, 15.799999999999963, -376.0, 20.000000000000014, 20.000000000000014, -350.8, 20.000000000000014, -400.0, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -286.0, 32.0, 20.000000000000014, -361.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 9.79999999999997, 120.5, 149.0, -89.20000000000084, -55.599999999999994, 173.3, 20.000000000000014, 17.899999999999988, -20.799999999999756, 20.000000000000014, 20.000000000000014, 29.00000000000017, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 31.7000000000002, 20.000000000000014, 136.1, 28.100000000000147, 200.0, 5.299999999999965, 20.000000000000014, -382.0, -379.0, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 200.0, 20.000000000000014, -400.0, -385.0, -400.0, 20.000000000000014, 17.899999999999988, -385.0, -97.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, -97.0, 15.799999999999963, 200.0, -82.90000000000086, 20.000000000000014, 107.3, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999959, -370.0, 15.799999999999963, 20.000000000000014, -358.0, -376.0, 20.000000000000014, 20.000000000000014, 122.0, -370.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 5.299999999999965, 9.499999999999964, -394.0, 183.8, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.29999999999949, 17.899999999999988, 11.599999999999966, 21.800000000000047, 179.0, -382.9, 17.899999999999988, 20.000000000000014, 1.0999999999999794, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, -340.0, -370.0, 29.000000000000163, 199.1, 20.000000000000014, 3.1999999999999615, 167.0, 20.000000000000014, 200.0, -53.49999999999983, 200.0, 20.000000000000014, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, -225.70000000000047, 200.0, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 42.500000000000135, 182.0, -169.0, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, -373.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, -400.0, -373.0, 152.0, 200.0, 9.499999999999964, 5.299999999999965, 167.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, 20.000000000000014, -16.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 170.0, 11.599999999999952, 182.0, 20.000000000000014, 15.799999999999963, 158.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 13.699999999999964, -346.0], "policy_predator_policy_reward": [14.0, 2.0, 89.0, 192.0, 183.0, 1.0, 200.0, 198.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.0, 162.0, 184.0, 101.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 25.0, 8.0, 75.0, 80.0, 5.0, 0.0, 10.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 8.0, 21.0, 13.0, 0.0, 0.0, 7.0, 0.0, 194.0, 193.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 180.0, 109.0, 92.0, 200.0, 195.0, 122.0, 0.0, 99.0, 0.0, 0.0, 92.0, 7.0, 2.0, 0.0, 0.0, 49.0, 18.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 12.0, 0.0, 2.0, 184.0, 192.0, 0.0, 0.0, 186.0, 200.0, 0.0, 0.0, 200.0, 184.0, 7.0, 0.0, 193.0, 198.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 197.0, 196.0, 1.0, 1.0, 9.0, 0.0, 182.0, 125.0, 180.0, 0.0, 183.0, 190.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 95.0, 110.0, 96.0, 36.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 6.0, 56.0, 95.0, 0.0, 0.0, 191.0, 96.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 200.0, 198.0, 198.0, 184.0, 0.0, 5.0, 11.0, 7.0, 0.0, 0.0, 173.0, 200.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 7.0, 0.0, 0.0, 10.0, 8.0, 9.0, 2.0, 0.0, 12.0, 7.0, 0.0, 0.0, 185.0, 154.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8344607080207023, "mean_inference_ms": 2.3990659492290365, "mean_action_processing_ms": 0.3764884108802089, "mean_env_wait_ms": 0.3039958249347445, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0066776275634765625, "StateBufferConnector_ms": 0.0035016536712646484, "ViewRequirementAgentConnector_ms": 0.14385175704956055}, "num_episodes": 18, "episode_return_max": 302.5, "episode_return_min": -496.0, "episode_return_mean": 60.74499999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.8419595014274, "num_env_steps_trained_throughput_per_sec": 317.8419595014274, "timesteps_total": 596000, "num_env_steps_sampled_lifetime": 596000, "num_agent_steps_sampled_lifetime": 2384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2384000, "timers": {"training_iteration_time_ms": 12974.456, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12974.4, "sample_time_ms": 1885.451, "learn_time_ms": 11068.855, "learn_throughput": 361.374, "synch_weights_time_ms": 16.188}, "counters": {"num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "done": false, "training_iteration": 149, "trial_id": "04dec_00002", "date": "2024-08-13_16-56-11", "timestamp": 1723582571, "time_this_iter_s": 12.645354986190796, "time_total_s": 1999.557466506958, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0728550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1999.557466506958, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 64.16111111111111, "ram_util_percent": 83.54444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2390239051567815, "cur_kl_coeff": 3.1615335349677293e-17, "cur_lr": 0.00010000000000000003, "total_loss": 3.4382423206611916, "policy_loss": -0.0004141479407846139, "vf_loss": 3.438656468744631, "vf_explained_var": 0.0018146753941894209, "kl": 0.002253434099050282, "entropy": 0.14144693179420692, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 282555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.194154365463231, "cur_kl_coeff": 0.0013545782246970005, "cur_lr": 0.00010000000000000003, "total_loss": 3.235403753462292, "policy_loss": -0.0005210004596621113, "vf_loss": 3.2359172739679853, "vf_explained_var": -0.008346778248983716, "kl": 0.0055251702881999746, "entropy": 0.6422790118941555, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 282555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "env_runners": {"episode_reward_max": 384.0, "episode_reward_min": -496.0, "episode_reward_mean": 60.91299999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -11.033500000000005, "predator_policy": 41.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [190.0999999999994, 228.09999999999923, 32.30000000000018, -374.0, 219.99999999999926, 31.20000000000018, 219.99999999999926, -496.0, -88.00000000000065, -50.09999999999977, 202.0, 40.0000000000003, 19.90000000000002, 217.79999999999927, -13.899999999999569, 145.2999999999996, 215.99999999999926, 40.0000000000003, 40.0000000000003, -165.4000000000006, 37.80000000000027, -358.0, 40.0000000000003, 138.0, 40.0000000000003, 3.9999999999999627, 21.800000000000015, 180.8, 34.50000000000022, 40.0000000000003, 26.80000000000009, 40.0000000000003, 122.19999999999882, 37.40000000000027, 189.1, 39.9000000000003, 30.100000000000147, -27.99999999999976, -140.0000000000004, 32.00000000000022, 219.09999999999926, 181.19999999999948, 219.99999999999926, 181.49999999999946, 39.9000000000003, 40.0000000000003, 40.0000000000003, -6.999999999999842, 178.0, 40.0000000000003, 39.800000000000296, 40.0000000000003, 40.0000000000003, 176.2999999999995, 233.49999999999952, 2.0000000000000897, 219.99999999999926, -80.7000000000001, 37.80000000000027, 40.0000000000003, 35.600000000000236, 17.99999999999999, 161.0, 214.4999999999993, 190.29999999999941, 40.0000000000003, -6.999999999999899, 41.800000000000296, 40.0000000000003, 76.00000000000003, 32.30000000000018, 199.99999999999935, 210.5999999999993, 37.80000000000027, 194.89999999999938, 40.0000000000003, 6.699999999999964, 40.0000000000003, 176.39999999999947, 3.100000000000061, 40.0000000000003, 167.7999999999995, 40.0000000000003, -137.10000000000088, 4.999999999999957, 40.0000000000003, 29.40000000000016, -15.999999999999746, 40.0000000000003, -15.199999999999982, 40.0000000000003, 384.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, -30.999999999999964, -66.6999999999998, 219.99999999999926, 212.8999999999993, 201.09999999999934], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 136.1, 28.100000000000147, 200.0, 5.299999999999965, 20.000000000000014, -382.0, -379.0, 200.0, 20.000000000000014, 20.000000000000014, 3.199999999999967, 200.0, 20.000000000000014, -400.0, -385.0, -400.0, 20.000000000000014, 17.899999999999988, -385.0, -97.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, -97.0, 15.799999999999963, 200.0, -82.90000000000086, 20.000000000000014, 107.3, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999959, -370.0, 15.799999999999963, 20.000000000000014, -358.0, -376.0, 20.000000000000014, 20.000000000000014, 122.0, -370.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 5.299999999999965, 9.499999999999964, -394.0, 183.8, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.29999999999949, 17.899999999999988, 11.599999999999966, 21.800000000000047, 179.0, -382.9, 17.899999999999988, 20.000000000000014, 1.0999999999999794, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, -340.0, -370.0, 29.000000000000163, 199.1, 20.000000000000014, 3.1999999999999615, 167.0, 20.000000000000014, 200.0, -53.49999999999983, 200.0, 20.000000000000014, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, -225.70000000000047, 200.0, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 42.500000000000135, 182.0, -169.0, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, -373.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, -400.0, -373.0, 152.0, 200.0, 9.499999999999964, 5.299999999999965, 167.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, 20.000000000000014, -16.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 170.0, 11.599999999999952, 182.0, 20.000000000000014, 15.799999999999963, 158.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 13.699999999999964, -346.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 154.4, 20.000000000000014, -61.89999999999984, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -318.0999999999991, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000003, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -173.20000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -247.0, -183.7000000000003, 20.000000000000014, 200.0, 20.000000000000014, 188.0, 20.90000000000003, 181.1, 20.000000000000014], "policy_predator_policy_reward": [21.0, 13.0, 0.0, 0.0, 7.0, 0.0, 194.0, 193.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 180.0, 109.0, 92.0, 200.0, 195.0, 122.0, 0.0, 99.0, 0.0, 0.0, 92.0, 7.0, 2.0, 0.0, 0.0, 49.0, 18.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 12.0, 0.0, 2.0, 184.0, 192.0, 0.0, 0.0, 186.0, 200.0, 0.0, 0.0, 200.0, 184.0, 7.0, 0.0, 193.0, 198.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 197.0, 196.0, 1.0, 1.0, 9.0, 0.0, 182.0, 125.0, 180.0, 0.0, 183.0, 190.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 95.0, 110.0, 96.0, 36.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 6.0, 56.0, 95.0, 0.0, 0.0, 191.0, 96.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 200.0, 198.0, 198.0, 184.0, 0.0, 5.0, 11.0, 7.0, 0.0, 0.0, 173.0, 200.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 7.0, 0.0, 0.0, 10.0, 8.0, 9.0, 2.0, 0.0, 12.0, 7.0, 0.0, 0.0, 185.0, 154.0, 0.0, 0.0, 2.0, 0.0, 11.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 161.0, 200.0, 185.0, 0.0, 0.0, 9.0, 14.0, 118.0, 0.0, 0.0, 0.0, 47.0, 91.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 102.0, 94.0, 0.0, 97.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8350811137697618, "mean_inference_ms": 2.400138405276429, "mean_action_processing_ms": 0.3767201418559011, "mean_env_wait_ms": 0.30393128288251564, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006618618965148926, "StateBufferConnector_ms": 0.003366827964782715, "ViewRequirementAgentConnector_ms": 0.12123560905456543}, "num_episodes": 23, "episode_return_max": 384.0, "episode_return_min": -496.0, "episode_return_mean": 60.91299999999994, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 302.38273154951986, "num_env_steps_trained_throughput_per_sec": 302.38273154951986, "timesteps_total": 600000, "num_env_steps_sampled_lifetime": 600000, "num_agent_steps_sampled_lifetime": 2400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2400000, "timers": {"training_iteration_time_ms": 12992.17, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12992.113, "sample_time_ms": 1896.84, "learn_time_ms": 11074.368, "learn_throughput": 361.194, "synch_weights_time_ms": 16.76}, "counters": {"num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "done": false, "training_iteration": 150, "trial_id": "04dec_00002", "date": "2024-08-13_16-56-25", "timestamp": 1723582585, "time_this_iter_s": 13.27864408493042, "time_total_s": 2012.8361105918884, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0720310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2012.8361105918884, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 69.16842105263159, "ram_util_percent": 83.57368421052632}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.911330519064709, "cur_kl_coeff": 1.5807667674838647e-17, "cur_lr": 0.00010000000000000003, "total_loss": 3.814798737581445, "policy_loss": -0.00038997674676239806, "vf_loss": 3.8151887043443304, "vf_explained_var": 1.824337338644361e-05, "kl": 0.0019873931212000553, "entropy": 0.11149367581875551, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 284445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.846191258949262, "cur_kl_coeff": 0.0013545782246970005, "cur_lr": 0.00010000000000000003, "total_loss": 3.6712442415731923, "policy_loss": -0.0004946251295102888, "vf_loss": 3.6717350610349544, "vf_explained_var": 0.005616858617338554, "kl": 0.0028079533626809354, "entropy": 0.5812842097389634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 284445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "env_runners": {"episode_reward_max": 384.0, "episode_reward_min": -358.0, "episode_reward_mean": 57.92899999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -15.905500000000002, "predator_policy": 44.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -165.4000000000006, 37.80000000000027, -358.0, 40.0000000000003, 138.0, 40.0000000000003, 3.9999999999999627, 21.800000000000015, 180.8, 34.50000000000022, 40.0000000000003, 26.80000000000009, 40.0000000000003, 122.19999999999882, 37.40000000000027, 189.1, 39.9000000000003, 30.100000000000147, -27.99999999999976, -140.0000000000004, 32.00000000000022, 219.09999999999926, 181.19999999999948, 219.99999999999926, 181.49999999999946, 39.9000000000003, 40.0000000000003, 40.0000000000003, -6.999999999999842, 178.0, 40.0000000000003, 39.800000000000296, 40.0000000000003, 40.0000000000003, 176.2999999999995, 233.49999999999952, 2.0000000000000897, 219.99999999999926, -80.7000000000001, 37.80000000000027, 40.0000000000003, 35.600000000000236, 17.99999999999999, 161.0, 214.4999999999993, 190.29999999999941, 40.0000000000003, -6.999999999999899, 41.800000000000296, 40.0000000000003, 76.00000000000003, 32.30000000000018, 199.99999999999935, 210.5999999999993, 37.80000000000027, 194.89999999999938, 40.0000000000003, 6.699999999999964, 40.0000000000003, 176.39999999999947, 3.100000000000061, 40.0000000000003, 167.7999999999995, 40.0000000000003, -137.10000000000088, 4.999999999999957, 40.0000000000003, 29.40000000000016, -15.999999999999746, 40.0000000000003, -15.199999999999982, 40.0000000000003, 384.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, -30.999999999999964, -66.6999999999998, 219.99999999999926, 212.8999999999993, 201.09999999999934, 40.0000000000003, 171.0, 23.70000000000018, 37.60000000000029, -77.00000000000068, -21.59999999999954, 14.999999999999957, 40.0000000000003, -92.00000000000014, 40.0000000000003, -154.7000000000005, 40.0000000000003, 218.89999999999927, -86.00000000000057, 27.900000000000126, 13.899999999999958, 40.0000000000003, 205.5999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 11.599999999999959, -370.0, 15.799999999999963, 20.000000000000014, -358.0, -376.0, 20.000000000000014, 20.000000000000014, 122.0, -370.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 5.299999999999965, 9.499999999999964, -394.0, 183.8, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.29999999999949, 17.899999999999988, 11.599999999999966, 21.800000000000047, 179.0, -382.9, 17.899999999999988, 20.000000000000014, 1.0999999999999794, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, -340.0, -370.0, 29.000000000000163, 199.1, 20.000000000000014, 3.1999999999999615, 167.0, 20.000000000000014, 200.0, -53.49999999999983, 200.0, 20.000000000000014, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, -225.70000000000047, 200.0, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 42.500000000000135, 182.0, -169.0, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, -373.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, -400.0, -373.0, 152.0, 200.0, 9.499999999999964, 5.299999999999965, 167.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, 20.000000000000014, -16.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 170.0, 11.599999999999952, 182.0, 20.000000000000014, 15.799999999999963, 158.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 13.699999999999964, -346.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 154.4, 20.000000000000014, -61.89999999999984, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -318.0999999999991, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000003, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -173.20000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -247.0, -183.7000000000003, 20.000000000000014, 200.0, 20.000000000000014, 188.0, 20.90000000000003, 181.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, -40.0, -49.299999999999905, 11.599999999999946, 20.000000000000014, -400.0, 20.000000000000014, -97.60000000000082, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -271.0, 20.000000000000014, 20.000000000000014, -351.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 200.0, -376.0, 20.000000000000014, -24.09999999999991, 20.000000000000014, -400.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 185.6, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 181.0, 12.0, 0.0, 2.0, 184.0, 192.0, 0.0, 0.0, 186.0, 200.0, 0.0, 0.0, 200.0, 184.0, 7.0, 0.0, 193.0, 198.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 197.0, 196.0, 1.0, 1.0, 9.0, 0.0, 182.0, 125.0, 180.0, 0.0, 183.0, 190.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 95.0, 110.0, 96.0, 36.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 6.0, 56.0, 95.0, 0.0, 0.0, 191.0, 96.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 200.0, 198.0, 198.0, 184.0, 0.0, 5.0, 11.0, 7.0, 0.0, 0.0, 173.0, 200.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 7.0, 0.0, 0.0, 10.0, 8.0, 9.0, 2.0, 0.0, 12.0, 7.0, 0.0, 0.0, 185.0, 154.0, 0.0, 0.0, 2.0, 0.0, 11.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 161.0, 200.0, 185.0, 0.0, 0.0, 9.0, 14.0, 118.0, 0.0, 0.0, 0.0, 47.0, 91.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 102.0, 94.0, 0.0, 97.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 200.0, 171.0, 12.0, 101.0, 4.0, 2.0, 103.0, 200.0, 56.0, 0.0, 195.0, 200.0, 0.0, 0.0, 89.0, 70.0, 0.0, 0.0, 83.0, 94.0, 0.0, 0.0, 1.0, 0.0, 192.0, 78.0, 11.0, 21.0, 196.0, 200.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8343994706739031, "mean_inference_ms": 2.4001293514717035, "mean_action_processing_ms": 0.37602819449811437, "mean_env_wait_ms": 0.30380826566781954, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004476070404052734, "StateBufferConnector_ms": 0.0033435821533203125, "ViewRequirementAgentConnector_ms": 0.11896562576293945}, "num_episodes": 18, "episode_return_max": 384.0, "episode_return_min": -358.0, "episode_return_mean": 57.92899999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.957144506602, "num_env_steps_trained_throughput_per_sec": 315.957144506602, "timesteps_total": 604000, "num_env_steps_sampled_lifetime": 604000, "num_agent_steps_sampled_lifetime": 2416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2416000, "timers": {"training_iteration_time_ms": 12970.774, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12970.716, "sample_time_ms": 1882.221, "learn_time_ms": 11067.864, "learn_throughput": 361.407, "synch_weights_time_ms": 16.317}, "counters": {"num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "done": false, "training_iteration": 151, "trial_id": "04dec_00002", "date": "2024-08-13_16-56-37", "timestamp": 1723582597, "time_this_iter_s": 12.718883037567139, "time_total_s": 2025.5549936294556, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0720dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2025.5549936294556, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 66.93333333333334, "ram_util_percent": 83.40555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5535685440692952, "cur_kl_coeff": 7.903833837419323e-18, "cur_lr": 0.00010000000000000003, "total_loss": 0.8516467305402907, "policy_loss": -0.000728617304512275, "vf_loss": 0.8523753489845645, "vf_explained_var": -6.120223847646561e-05, "kl": 0.0034547009432254337, "entropy": 0.13219366372420044, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 286335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.8584285580765005, "cur_kl_coeff": 0.0006772891123485003, "cur_lr": 0.00010000000000000003, "total_loss": 2.5187105040701607, "policy_loss": -0.0004938948409208072, "vf_loss": 2.5192006619519027, "vf_explained_var": 0.10088097525652123, "kl": 0.005521829993100759, "entropy": 0.5249043157018681, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 286335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -154.7000000000005, "episode_reward_mean": 76.67999999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 5.5550000000000015, "predator_policy": 32.785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.09999999999926, 181.19999999999948, 219.99999999999926, 181.49999999999946, 39.9000000000003, 40.0000000000003, 40.0000000000003, -6.999999999999842, 178.0, 40.0000000000003, 39.800000000000296, 40.0000000000003, 40.0000000000003, 176.2999999999995, 233.49999999999952, 2.0000000000000897, 219.99999999999926, -80.7000000000001, 37.80000000000027, 40.0000000000003, 35.600000000000236, 17.99999999999999, 161.0, 214.4999999999993, 190.29999999999941, 40.0000000000003, -6.999999999999899, 41.800000000000296, 40.0000000000003, 76.00000000000003, 32.30000000000018, 199.99999999999935, 210.5999999999993, 37.80000000000027, 194.89999999999938, 40.0000000000003, 6.699999999999964, 40.0000000000003, 176.39999999999947, 3.100000000000061, 40.0000000000003, 167.7999999999995, 40.0000000000003, -137.10000000000088, 4.999999999999957, 40.0000000000003, 29.40000000000016, -15.999999999999746, 40.0000000000003, -15.199999999999982, 40.0000000000003, 384.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, -30.999999999999964, -66.6999999999998, 219.99999999999926, 212.8999999999993, 201.09999999999934, 40.0000000000003, 171.0, 23.70000000000018, 37.60000000000029, -77.00000000000068, -21.59999999999954, 14.999999999999957, 40.0000000000003, -92.00000000000014, 40.0000000000003, -154.7000000000005, 40.0000000000003, 218.89999999999927, -86.00000000000057, 27.900000000000126, 13.899999999999958, 40.0000000000003, 205.5999999999993, 166.19999999999933, 40.0000000000003, 194.59999999999937, 400.0, 193.2999999999994, 37.80000000000027, -6.000000000000226, 38.90000000000028, 23.500000000000032, 33.400000000000205, 213.9999999999993, 195.89999999999935, 201.99999999999935, 27.90000000000012, 24.70000000000005, 163.89999999999955, -29.999999999999744, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [199.1, 20.000000000000014, 3.1999999999999615, 167.0, 20.000000000000014, 200.0, -53.49999999999983, 200.0, 20.000000000000014, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, -225.70000000000047, 200.0, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 42.500000000000135, 182.0, -169.0, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, -373.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, -400.0, -373.0, 152.0, 200.0, 9.499999999999964, 5.299999999999965, 167.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, 20.000000000000014, -16.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 170.0, 11.599999999999952, 182.0, 20.000000000000014, 15.799999999999963, 158.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 13.699999999999964, -346.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 154.4, 20.000000000000014, -61.89999999999984, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -318.0999999999991, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000003, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -173.20000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -247.0, -183.7000000000003, 20.000000000000014, 200.0, 20.000000000000014, 188.0, 20.90000000000003, 181.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, -40.0, -49.299999999999905, 11.599999999999946, 20.000000000000014, -400.0, 20.000000000000014, -97.60000000000082, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -271.0, 20.000000000000014, 20.000000000000014, -351.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 200.0, -376.0, 20.000000000000014, -24.09999999999991, 20.000000000000014, -400.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 185.6, 20.000000000000014, 120.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, 20.000000000000014, 200.0, 200.0, 170.0, 5.299999999999998, 20.000000000000014, 15.799999999999963, -139.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, -0.9999999999999917, 9.499999999999964, 7.399999999999965, 20.000000000000014, 191.0, 20.000000000000014, 167.9, 20.000000000000014, 20.000000000000014, 173.0, -3.099999999999979, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 155.3, -9.399999999999855, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 95.0, 110.0, 96.0, 36.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 6.0, 56.0, 95.0, 0.0, 0.0, 191.0, 96.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 200.0, 198.0, 198.0, 184.0, 0.0, 5.0, 11.0, 7.0, 0.0, 0.0, 173.0, 200.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 7.0, 0.0, 0.0, 10.0, 8.0, 9.0, 2.0, 0.0, 12.0, 7.0, 0.0, 0.0, 185.0, 154.0, 0.0, 0.0, 2.0, 0.0, 11.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 161.0, 200.0, 185.0, 0.0, 0.0, 9.0, 14.0, 118.0, 0.0, 0.0, 0.0, 47.0, 91.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 102.0, 94.0, 0.0, 97.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 200.0, 171.0, 12.0, 101.0, 4.0, 2.0, 103.0, 200.0, 56.0, 0.0, 195.0, 200.0, 0.0, 0.0, 89.0, 70.0, 0.0, 0.0, 83.0, 94.0, 0.0, 0.0, 1.0, 0.0, 192.0, 78.0, 11.0, 21.0, 196.0, 200.0, 0.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 16.0, 2.0, 0.0, 2.0, 113.0, 0.0, 1.0, 0.0, 5.0, 10.0, 6.0, 0.0, 3.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 11.0, 0.0, 12.0, 7.0, 11.0, 150.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8343127127402604, "mean_inference_ms": 2.400589322361809, "mean_action_processing_ms": 0.37570376860394616, "mean_env_wait_ms": 0.30368163287581706, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004776597023010254, "StateBufferConnector_ms": 0.0032171010971069336, "ViewRequirementAgentConnector_ms": 0.12994515895843506}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -154.7000000000005, "episode_return_mean": 76.67999999999992, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 309.2428506459944, "num_env_steps_trained_throughput_per_sec": 309.2428506459944, "timesteps_total": 608000, "num_env_steps_sampled_lifetime": 608000, "num_agent_steps_sampled_lifetime": 2432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2432000, "timers": {"training_iteration_time_ms": 12971.035, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12970.977, "sample_time_ms": 1926.205, "learn_time_ms": 11023.261, "learn_throughput": 362.869, "synch_weights_time_ms": 17.157}, "counters": {"num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "done": false, "training_iteration": 152, "trial_id": "04dec_00002", "date": "2024-08-13_16-56-50", "timestamp": 1723582610, "time_this_iter_s": 12.978328704833984, "time_total_s": 2038.5333223342896, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b07285e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2038.5333223342896, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 69.27222222222223, "ram_util_percent": 83.69444444444446}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9165420591594681, "cur_kl_coeff": 3.951916918709662e-18, "cur_lr": 0.00010000000000000003, "total_loss": 3.6068214342076943, "policy_loss": -0.0008976163946230102, "vf_loss": 3.607719048179647, "vf_explained_var": 0.0010389908911689878, "kl": 0.0023323245885529522, "entropy": 0.0811472703352886, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 288225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.89057863764662, "cur_kl_coeff": 0.0006772891123485003, "cur_lr": 0.00010000000000000003, "total_loss": 3.491285475473555, "policy_loss": -0.0044094623357215255, "vf_loss": 3.495685557713584, "vf_explained_var": -0.057311065613277375, "kl": 0.013861565897169172, "entropy": 0.5348600669354989, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 288225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -154.7000000000005, "episode_reward_mean": 73.29999999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -1.2249999999999985, "predator_policy": 37.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 40.0000000000003, 35.600000000000236, 17.99999999999999, 161.0, 214.4999999999993, 190.29999999999941, 40.0000000000003, -6.999999999999899, 41.800000000000296, 40.0000000000003, 76.00000000000003, 32.30000000000018, 199.99999999999935, 210.5999999999993, 37.80000000000027, 194.89999999999938, 40.0000000000003, 6.699999999999964, 40.0000000000003, 176.39999999999947, 3.100000000000061, 40.0000000000003, 167.7999999999995, 40.0000000000003, -137.10000000000088, 4.999999999999957, 40.0000000000003, 29.40000000000016, -15.999999999999746, 40.0000000000003, -15.199999999999982, 40.0000000000003, 384.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, -30.999999999999964, -66.6999999999998, 219.99999999999926, 212.8999999999993, 201.09999999999934, 40.0000000000003, 171.0, 23.70000000000018, 37.60000000000029, -77.00000000000068, -21.59999999999954, 14.999999999999957, 40.0000000000003, -92.00000000000014, 40.0000000000003, -154.7000000000005, 40.0000000000003, 218.89999999999927, -86.00000000000057, 27.900000000000126, 13.899999999999958, 40.0000000000003, 205.5999999999993, 166.19999999999933, 40.0000000000003, 194.59999999999937, 400.0, 193.2999999999994, 37.80000000000027, -6.000000000000226, 38.90000000000028, 23.500000000000032, 33.400000000000205, 213.9999999999993, 195.89999999999935, 201.99999999999935, 27.90000000000012, 24.70000000000005, 163.89999999999955, -29.999999999999744, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 40.0000000000003, 150.90000000000003, 29.900000000000176, 32.30000000000019, 40.0000000000003, 34.50000000000022, -1.299999999999958, 25.70000000000007, 185.0, 141.2999999999995, -79.60000000000008, 40.0000000000003, 181.99999999999943, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 172.29999999999953, 188.59999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, -400.0, -373.0, 152.0, 200.0, 9.499999999999964, 5.299999999999965, 167.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, 20.000000000000014, -16.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 170.0, 11.599999999999952, 182.0, 20.000000000000014, 15.799999999999963, 158.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 13.699999999999964, -346.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 154.4, 20.000000000000014, -61.89999999999984, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -318.0999999999991, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000003, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -173.20000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -247.0, -183.7000000000003, 20.000000000000014, 200.0, 20.000000000000014, 188.0, 20.90000000000003, 181.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, -40.0, -49.299999999999905, 11.599999999999946, 20.000000000000014, -400.0, 20.000000000000014, -97.60000000000082, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -271.0, 20.000000000000014, 20.000000000000014, -351.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 200.0, -376.0, 20.000000000000014, -24.09999999999991, 20.000000000000014, -400.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 185.6, 20.000000000000014, 120.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, 20.000000000000014, 200.0, 200.0, 170.0, 5.299999999999998, 20.000000000000014, 15.799999999999963, -139.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, -0.9999999999999917, 9.499999999999964, 7.399999999999965, 20.000000000000014, 191.0, 20.000000000000014, 167.9, 20.000000000000014, 20.000000000000014, 173.0, -3.099999999999979, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 155.3, -9.399999999999855, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 200.0, -339.1, -331.0, -3.099999999999958, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -397.0, 13.699999999999964, 3.1999999999999615, 9.499999999999966, 200.0, -400.0, 20.000000000000014, 83.3, -376.9, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 148.1, 3.1999999999999615, 131.6, 20.000000000000014], "policy_predator_policy_reward": [0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 200.0, 198.0, 198.0, 184.0, 0.0, 5.0, 11.0, 7.0, 0.0, 0.0, 173.0, 200.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 7.0, 0.0, 0.0, 10.0, 8.0, 9.0, 2.0, 0.0, 12.0, 7.0, 0.0, 0.0, 185.0, 154.0, 0.0, 0.0, 2.0, 0.0, 11.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 161.0, 200.0, 185.0, 0.0, 0.0, 9.0, 14.0, 118.0, 0.0, 0.0, 0.0, 47.0, 91.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 102.0, 94.0, 0.0, 97.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 200.0, 171.0, 12.0, 101.0, 4.0, 2.0, 103.0, 200.0, 56.0, 0.0, 195.0, 200.0, 0.0, 0.0, 89.0, 70.0, 0.0, 0.0, 83.0, 94.0, 0.0, 0.0, 1.0, 0.0, 192.0, 78.0, 11.0, 21.0, 196.0, 200.0, 0.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 16.0, 2.0, 0.0, 2.0, 113.0, 0.0, 1.0, 0.0, 5.0, 10.0, 6.0, 0.0, 3.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 11.0, 0.0, 12.0, 7.0, 11.0, 150.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 134.0, 156.0, 176.0, 188.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 200.0, 182.0, 8.0, 5.0, 185.0, 200.0, 38.0, 0.0, 103.0, 189.0, 0.0, 0.0, 0.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 19.0, 18.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.83417478857378, "mean_inference_ms": 2.4008662926078643, "mean_action_processing_ms": 0.3754227345147425, "mean_env_wait_ms": 0.3035576822145918, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043985843658447266, "StateBufferConnector_ms": 0.003241419792175293, "ViewRequirementAgentConnector_ms": 0.13334035873413086}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -154.7000000000005, "episode_return_mean": 73.29999999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.6237372571054, "num_env_steps_trained_throughput_per_sec": 324.6237372571054, "timesteps_total": 612000, "num_env_steps_sampled_lifetime": 612000, "num_agent_steps_sampled_lifetime": 2448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2448000, "timers": {"training_iteration_time_ms": 12879.388, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12879.329, "sample_time_ms": 1914.591, "learn_time_ms": 10943.608, "learn_throughput": 365.51, "synch_weights_time_ms": 16.824}, "counters": {"num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "done": false, "training_iteration": 153, "trial_id": "04dec_00002", "date": "2024-08-13_16-57-03", "timestamp": 1723582623, "time_this_iter_s": 12.369561910629272, "time_total_s": 2050.902884244919, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0728700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2050.902884244919, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 65.63333333333334, "ram_util_percent": 83.36666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6567737113231074, "cur_kl_coeff": 1.975958459354831e-18, "cur_lr": 0.00010000000000000003, "total_loss": 3.072292648169099, "policy_loss": -0.0009415208110733638, "vf_loss": 3.073234171400625, "vf_explained_var": -0.0003333038123196395, "kl": 0.0022819509234051454, "entropy": 0.08772909857046904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 290115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.7529712510250866, "cur_kl_coeff": 0.0006772891123485003, "cur_lr": 0.00010000000000000003, "total_loss": 4.558813641058705, "policy_loss": -8.107133495508047e-05, "vf_loss": 4.558891779657394, "vf_explained_var": 0.005160538387046289, "kl": 0.0043387485706882015, "entropy": 0.4558729849479817, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 290115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -347.7, "episode_reward_mean": 71.90999999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -5.679999999999998, "predator_policy": 41.635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.699999999999964, 40.0000000000003, 176.39999999999947, 3.100000000000061, 40.0000000000003, 167.7999999999995, 40.0000000000003, -137.10000000000088, 4.999999999999957, 40.0000000000003, 29.40000000000016, -15.999999999999746, 40.0000000000003, -15.199999999999982, 40.0000000000003, 384.0, 40.0000000000003, 40.0000000000003, 40.0000000000003, -30.999999999999964, -66.6999999999998, 219.99999999999926, 212.8999999999993, 201.09999999999934, 40.0000000000003, 171.0, 23.70000000000018, 37.60000000000029, -77.00000000000068, -21.59999999999954, 14.999999999999957, 40.0000000000003, -92.00000000000014, 40.0000000000003, -154.7000000000005, 40.0000000000003, 218.89999999999927, -86.00000000000057, 27.900000000000126, 13.899999999999958, 40.0000000000003, 205.5999999999993, 166.19999999999933, 40.0000000000003, 194.59999999999937, 400.0, 193.2999999999994, 37.80000000000027, -6.000000000000226, 38.90000000000028, 23.500000000000032, 33.400000000000205, 213.9999999999993, 195.89999999999935, 201.99999999999935, 27.90000000000012, 24.70000000000005, 163.89999999999955, -29.999999999999744, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 40.0000000000003, 150.90000000000003, 29.900000000000176, 32.30000000000019, 40.0000000000003, 34.50000000000022, -1.299999999999958, 25.70000000000007, 185.0, 141.2999999999995, -79.60000000000008, 40.0000000000003, 181.99999999999943, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 172.29999999999953, 188.59999999999943, 40.0000000000003, 186.09999999999943, 208.99999999999932, 160.49999999999957, 400.0, 37.80000000000027, 36.70000000000025, 219.99999999999926, 205.99999999999932, 199.99999999999935, 9.599999999999962, -173.00000000000063, 37.80000000000027, -347.7, 25.900000000000112, 171.3, 8.99999999999996, 35.600000000000236], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, -346.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 154.4, 20.000000000000014, -61.89999999999984, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -318.0999999999991, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000003, -154.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -173.20000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -247.0, -183.7000000000003, 20.000000000000014, 200.0, 20.000000000000014, 188.0, 20.90000000000003, 181.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, -40.0, -49.299999999999905, 11.599999999999946, 20.000000000000014, -400.0, 20.000000000000014, -97.60000000000082, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -271.0, 20.000000000000014, 20.000000000000014, -351.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 200.0, -376.0, 20.000000000000014, -24.09999999999991, 20.000000000000014, -400.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 185.6, 20.000000000000014, 120.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, 20.000000000000014, 200.0, 200.0, 170.0, 5.299999999999998, 20.000000000000014, 15.799999999999963, -139.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, -0.9999999999999917, 9.499999999999964, 7.399999999999965, 20.000000000000014, 191.0, 20.000000000000014, 167.9, 20.000000000000014, 20.000000000000014, 173.0, -3.099999999999979, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 155.3, -9.399999999999855, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 200.0, -339.1, -331.0, -3.099999999999958, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -397.0, 13.699999999999964, 3.1999999999999615, 9.499999999999966, 200.0, -400.0, 20.000000000000014, 83.3, -376.9, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 148.1, 3.1999999999999615, 131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.0999999999999865, 20.000000000000014, 170.0, 9.499999999999964, 119.0, 200.0, 200.0, 15.799999999999963, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -381.4, -400.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, -351.7, -361.0, -255.10000000000002, 20.000000000000014, 155.3, -367.0, -391.0, 20.000000000000014, 11.599999999999964, 20.000000000000014], "policy_predator_policy_reward": [185.0, 154.0, 0.0, 0.0, 2.0, 0.0, 11.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 161.0, 200.0, 185.0, 0.0, 0.0, 9.0, 14.0, 118.0, 0.0, 0.0, 0.0, 47.0, 91.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 102.0, 94.0, 0.0, 97.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 200.0, 171.0, 12.0, 101.0, 4.0, 2.0, 103.0, 200.0, 56.0, 0.0, 195.0, 200.0, 0.0, 0.0, 89.0, 70.0, 0.0, 0.0, 83.0, 94.0, 0.0, 0.0, 1.0, 0.0, 192.0, 78.0, 11.0, 21.0, 196.0, 200.0, 0.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 16.0, 2.0, 0.0, 2.0, 113.0, 0.0, 1.0, 0.0, 5.0, 10.0, 6.0, 0.0, 3.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 11.0, 0.0, 12.0, 7.0, 11.0, 150.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 134.0, 156.0, 176.0, 188.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 200.0, 182.0, 8.0, 5.0, 185.0, 200.0, 38.0, 0.0, 103.0, 189.0, 0.0, 0.0, 0.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 19.0, 18.0, 19.0, 0.0, 0.0, 0.0, 15.0, 9.0, 10.0, 10.0, 22.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 192.0, 179.0, 7.0, 200.0, 2.0, 0.0, 184.0, 181.0, 131.0, 130.0, 194.0, 189.0, 183.0, 197.0, 0.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8340163196482755, "mean_inference_ms": 2.401206269437342, "mean_action_processing_ms": 0.37511064120212223, "mean_env_wait_ms": 0.3034616488490522, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004765033721923828, "StateBufferConnector_ms": 0.00391232967376709, "ViewRequirementAgentConnector_ms": 0.1419050693511963}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -347.7, "episode_return_mean": 71.90999999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.15068562787343, "num_env_steps_trained_throughput_per_sec": 333.15068562787343, "timesteps_total": 616000, "num_env_steps_sampled_lifetime": 616000, "num_agent_steps_sampled_lifetime": 2464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2464000, "timers": {"training_iteration_time_ms": 12847.158, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12847.099, "sample_time_ms": 1918.318, "learn_time_ms": 10907.646, "learn_throughput": 366.715, "synch_weights_time_ms": 17.033}, "counters": {"num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "done": false, "training_iteration": 154, "trial_id": "04dec_00002", "date": "2024-08-13_16-57-15", "timestamp": 1723582635, "time_this_iter_s": 12.058825016021729, "time_total_s": 2062.9617092609406, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c4ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2062.9617092609406, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 66.7764705882353, "ram_util_percent": 83.57058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.039034062746183, "cur_kl_coeff": 9.879792296774154e-19, "cur_lr": 0.00010000000000000003, "total_loss": 2.4497595004934483, "policy_loss": -0.00036368583447285116, "vf_loss": 2.450123190564453, "vf_explained_var": 0.00040727453257041003, "kl": 0.002623391346473475, "entropy": 0.09323655527932619, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 292005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.390408172430815, "cur_kl_coeff": 0.00033864455617425013, "cur_lr": 0.00010000000000000003, "total_loss": 3.482223969540268, "policy_loss": -0.0008909130254612555, "vf_loss": 3.483113528054858, "vf_explained_var": -0.016664681579700854, "kl": 0.004022127195920734, "entropy": 0.45464195706856947, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 292005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -347.7, "episode_reward_mean": 75.13599999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -7.327000000000003, "predator_policy": 44.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [201.09999999999934, 40.0000000000003, 171.0, 23.70000000000018, 37.60000000000029, -77.00000000000068, -21.59999999999954, 14.999999999999957, 40.0000000000003, -92.00000000000014, 40.0000000000003, -154.7000000000005, 40.0000000000003, 218.89999999999927, -86.00000000000057, 27.900000000000126, 13.899999999999958, 40.0000000000003, 205.5999999999993, 166.19999999999933, 40.0000000000003, 194.59999999999937, 400.0, 193.2999999999994, 37.80000000000027, -6.000000000000226, 38.90000000000028, 23.500000000000032, 33.400000000000205, 213.9999999999993, 195.89999999999935, 201.99999999999935, 27.90000000000012, 24.70000000000005, 163.89999999999955, -29.999999999999744, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 40.0000000000003, 150.90000000000003, 29.900000000000176, 32.30000000000019, 40.0000000000003, 34.50000000000022, -1.299999999999958, 25.70000000000007, 185.0, 141.2999999999995, -79.60000000000008, 40.0000000000003, 181.99999999999943, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 172.29999999999953, 188.59999999999943, 40.0000000000003, 186.09999999999943, 208.99999999999932, 160.49999999999957, 400.0, 37.80000000000027, 36.70000000000025, 219.99999999999926, 205.99999999999932, 199.99999999999935, 9.599999999999962, -173.00000000000063, 37.80000000000027, -347.7, 25.900000000000112, 171.3, 8.99999999999996, 35.600000000000236, 40.0000000000003, 42.00000000000026, -82.50000000000054, 356.0, 24.900000000000052, 19.700000000000014, 199.99999999999935, -168.0000000000006, 33.400000000000205, 40.0000000000003, 219.99999999999926, -219.2999999999999, 37.80000000000027, 38.90000000000028, 33.400000000000205, 173.19999999999948, 12.599999999999973, 371.5, 198.49999999999937, 39.40000000000029, 11.999999999999961, 19.6, 178.79999999999947], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [181.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, -40.0, -49.299999999999905, 11.599999999999946, 20.000000000000014, -400.0, 20.000000000000014, -97.60000000000082, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -271.0, 20.000000000000014, 20.000000000000014, -351.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 200.0, -376.0, 20.000000000000014, -24.09999999999991, 20.000000000000014, -400.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 185.6, 20.000000000000014, 120.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, 20.000000000000014, 200.0, 200.0, 170.0, 5.299999999999998, 20.000000000000014, 15.799999999999963, -139.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, -0.9999999999999917, 9.499999999999964, 7.399999999999965, 20.000000000000014, 191.0, 20.000000000000014, 167.9, 20.000000000000014, 20.000000000000014, 173.0, -3.099999999999979, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 155.3, -9.399999999999855, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 200.0, -339.1, -331.0, -3.099999999999958, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -397.0, 13.699999999999964, 3.1999999999999615, 9.499999999999966, 200.0, -400.0, 20.000000000000014, 83.3, -376.9, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 148.1, 3.1999999999999615, 131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.0999999999999865, 20.000000000000014, 170.0, 9.499999999999964, 119.0, 200.0, 200.0, 15.799999999999963, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -381.4, -400.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, -351.7, -361.0, -255.10000000000002, 20.000000000000014, 155.3, -367.0, -391.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -307.0, 20.000000000000014, 9.499999999999964, -364.0, 170.0, 173.0, 5.299999999999965, 11.599999999999964, 7.399999999999965, 5.299999999999965, 170.0, 20.000000000000014, 20.000000000000014, -382.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -200.49999999999994, -248.8000000000001, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 153.2, -324.4, 20.000000000000014, 164.0, 195.5, 9.499999999999964, 176.0, 7.399999999999965, 20.000000000000014, -385.0, 20.000000000000014, -334.6, 3.1999999999999615, 20.000000000000014, 150.8], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 200.0, 171.0, 12.0, 101.0, 4.0, 2.0, 103.0, 200.0, 56.0, 0.0, 195.0, 200.0, 0.0, 0.0, 89.0, 70.0, 0.0, 0.0, 83.0, 94.0, 0.0, 0.0, 1.0, 0.0, 192.0, 78.0, 11.0, 21.0, 196.0, 200.0, 0.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 16.0, 2.0, 0.0, 2.0, 113.0, 0.0, 1.0, 0.0, 5.0, 10.0, 6.0, 0.0, 3.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 11.0, 0.0, 12.0, 7.0, 11.0, 150.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 134.0, 156.0, 176.0, 188.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 200.0, 182.0, 8.0, 5.0, 185.0, 200.0, 38.0, 0.0, 103.0, 189.0, 0.0, 0.0, 0.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 19.0, 18.0, 19.0, 0.0, 0.0, 0.0, 15.0, 9.0, 10.0, 10.0, 22.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 192.0, 179.0, 7.0, 200.0, 2.0, 0.0, 184.0, 181.0, 131.0, 130.0, 194.0, 189.0, 183.0, 197.0, 0.0, 4.0, 0.0, 0.0, 169.0, 160.0, 193.0, 79.0, 0.0, 13.0, 0.0, 8.0, 7.0, 0.0, 0.0, 10.0, 0.0, 194.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 91.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 164.0, 153.0, 0.0, 12.0, 5.0, 8.0, 6.0, 6.0, 195.0, 182.0, 179.0, 172.0, 0.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8336119391005866, "mean_inference_ms": 2.401365123204287, "mean_action_processing_ms": 0.3746625673492378, "mean_env_wait_ms": 0.30332937045285324, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0053479671478271484, "StateBufferConnector_ms": 0.003979682922363281, "ViewRequirementAgentConnector_ms": 0.14843249320983887}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -347.7, "episode_return_mean": 75.13599999999991, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.7314389055906, "num_env_steps_trained_throughput_per_sec": 325.7314389055906, "timesteps_total": 620000, "num_env_steps_sampled_lifetime": 620000, "num_agent_steps_sampled_lifetime": 2480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2480000, "timers": {"training_iteration_time_ms": 12789.003, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12788.945, "sample_time_ms": 1854.675, "learn_time_ms": 10912.582, "learn_throughput": 366.549, "synch_weights_time_ms": 17.932}, "counters": {"num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "done": false, "training_iteration": 155, "trial_id": "04dec_00002", "date": "2024-08-13_16-57-27", "timestamp": 1723582647, "time_this_iter_s": 12.313961029052734, "time_total_s": 2075.2756702899933, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06b7d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2075.2756702899933, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 66.00588235294117, "ram_util_percent": 83.41176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6574813317842585, "cur_kl_coeff": 4.939896148387077e-19, "cur_lr": 0.00010000000000000003, "total_loss": 2.7957288385068297, "policy_loss": 2.508913782775087e-06, "vf_loss": 2.7957263260922103, "vf_explained_var": 0.0005209990279384391, "kl": 0.0010252458590687427, "entropy": 0.047095408987145496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 293895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.707648632277257, "cur_kl_coeff": 0.00016932227808712507, "cur_lr": 0.00010000000000000003, "total_loss": 2.769172829988772, "policy_loss": -0.005908634598741416, "vf_loss": 2.7750779979443423, "vf_explained_var": -0.0125156942498747, "kl": 0.020427384216759017, "entropy": 0.6025967726474086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 293895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -347.7, "episode_reward_mean": 76.75799999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -4.785999999999997, "predator_policy": 43.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [400.0, 193.2999999999994, 37.80000000000027, -6.000000000000226, 38.90000000000028, 23.500000000000032, 33.400000000000205, 213.9999999999993, 195.89999999999935, 201.99999999999935, 27.90000000000012, 24.70000000000005, 163.89999999999955, -29.999999999999744, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 40.0000000000003, 150.90000000000003, 29.900000000000176, 32.30000000000019, 40.0000000000003, 34.50000000000022, -1.299999999999958, 25.70000000000007, 185.0, 141.2999999999995, -79.60000000000008, 40.0000000000003, 181.99999999999943, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 172.29999999999953, 188.59999999999943, 40.0000000000003, 186.09999999999943, 208.99999999999932, 160.49999999999957, 400.0, 37.80000000000027, 36.70000000000025, 219.99999999999926, 205.99999999999932, 199.99999999999935, 9.599999999999962, -173.00000000000063, 37.80000000000027, -347.7, 25.900000000000112, 171.3, 8.99999999999996, 35.600000000000236, 40.0000000000003, 42.00000000000026, -82.50000000000054, 356.0, 24.900000000000052, 19.700000000000014, 199.99999999999935, -168.0000000000006, 33.400000000000205, 40.0000000000003, 219.99999999999926, -219.2999999999999, 37.80000000000027, 38.90000000000028, 33.400000000000205, 173.19999999999948, 12.599999999999973, 371.5, 198.49999999999937, 39.40000000000029, 11.999999999999961, 19.6, 178.79999999999947, -94.00000000000003, 27.60000000000014, 33.000000000000234, 40.0000000000003, 169.69999999999953, 40.0000000000003, 219.99999999999926, 199.99999999999935, 23.50000000000005, 26.600000000000115, 40.0000000000003, 37.700000000000294, 40.0000000000003, -120.00000000000077, 40.0000000000003, 198.10000000000002, -44.79999999999976, 30.100000000000147, 219.99999999999926, 40.0000000000003, 40.0000000000003, 38.90000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 200.0, 170.0, 5.299999999999998, 20.000000000000014, 15.799999999999963, -139.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, -0.9999999999999917, 9.499999999999964, 7.399999999999965, 20.000000000000014, 191.0, 20.000000000000014, 167.9, 20.000000000000014, 20.000000000000014, 173.0, -3.099999999999979, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 155.3, -9.399999999999855, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 200.0, -339.1, -331.0, -3.099999999999958, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -397.0, 13.699999999999964, 3.1999999999999615, 9.499999999999966, 200.0, -400.0, 20.000000000000014, 83.3, -376.9, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 148.1, 3.1999999999999615, 131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.0999999999999865, 20.000000000000014, 170.0, 9.499999999999964, 119.0, 200.0, 200.0, 15.799999999999963, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -381.4, -400.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, -351.7, -361.0, -255.10000000000002, 20.000000000000014, 155.3, -367.0, -391.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -307.0, 20.000000000000014, 9.499999999999964, -364.0, 170.0, 173.0, 5.299999999999965, 11.599999999999964, 7.399999999999965, 5.299999999999965, 170.0, 20.000000000000014, 20.000000000000014, -382.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -200.49999999999994, -248.8000000000001, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 153.2, -324.4, 20.000000000000014, 164.0, 195.5, 9.499999999999964, 176.0, 7.399999999999965, 20.000000000000014, -385.0, 20.000000000000014, -334.6, 3.1999999999999615, 20.000000000000014, 150.8, 20.000000000000014, -271.0, 11.599999999999964, -343.0, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, 155.9, -5.199999999999937, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 170.0, -11.499999999999847, 20.000000000000014, 7.399999999999979, 3.199999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999744, -385.0, 20.000000000000014, 20.000000000000014, 200.0, -355.9, -368.8, -42.999999999999766, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988], "policy_predator_policy_reward": [0.0, 0.0, 16.0, 2.0, 0.0, 2.0, 113.0, 0.0, 1.0, 0.0, 5.0, 10.0, 6.0, 0.0, 3.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 11.0, 0.0, 12.0, 7.0, 11.0, 150.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 134.0, 156.0, 176.0, 188.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 200.0, 182.0, 8.0, 5.0, 185.0, 200.0, 38.0, 0.0, 103.0, 189.0, 0.0, 0.0, 0.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 19.0, 18.0, 19.0, 0.0, 0.0, 0.0, 15.0, 9.0, 10.0, 10.0, 22.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 192.0, 179.0, 7.0, 200.0, 2.0, 0.0, 184.0, 181.0, 131.0, 130.0, 194.0, 189.0, 183.0, 197.0, 0.0, 4.0, 0.0, 0.0, 169.0, 160.0, 193.0, 79.0, 0.0, 13.0, 0.0, 8.0, 7.0, 0.0, 0.0, 10.0, 0.0, 194.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 91.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 164.0, 153.0, 0.0, 12.0, 5.0, 8.0, 6.0, 6.0, 195.0, 182.0, 179.0, 172.0, 0.0, 8.0, 0.0, 157.0, 178.0, 181.0, 185.0, 183.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 15.0, 0.0, 2.0, 14.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 195.0, 92.0, 0.0, 0.0, 176.0, 178.0, 186.0, 181.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8332322138052624, "mean_inference_ms": 2.399460578419778, "mean_action_processing_ms": 0.3742914695985202, "mean_env_wait_ms": 0.3032139774894708, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005273342132568359, "StateBufferConnector_ms": 0.003956913948059082, "ViewRequirementAgentConnector_ms": 0.1451575756072998}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -347.7, "episode_return_mean": 76.75799999999992, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.84710802673135, "num_env_steps_trained_throughput_per_sec": 326.84710802673135, "timesteps_total": 624000, "num_env_steps_sampled_lifetime": 624000, "num_agent_steps_sampled_lifetime": 2496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2496000, "timers": {"training_iteration_time_ms": 12654.952, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12654.894, "sample_time_ms": 1762.709, "learn_time_ms": 10870.449, "learn_throughput": 367.97, "synch_weights_time_ms": 17.948}, "counters": {"num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "done": false, "training_iteration": 156, "trial_id": "04dec_00002", "date": "2024-08-13_16-57-40", "timestamp": 1723582660, "time_this_iter_s": 12.298153162002563, "time_total_s": 2087.573823451996, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0724c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2087.573823451996, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 66.09444444444445, "ram_util_percent": 83.3111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9971786801343557, "cur_kl_coeff": 2.4699480741935385e-19, "cur_lr": 0.00010000000000000003, "total_loss": 2.111232304825354, "policy_loss": -0.0003700567682879785, "vf_loss": 2.111602358149473, "vf_explained_var": 0.0006906141995122193, "kl": 0.0020204783993062487, "entropy": 0.06631770821179821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 295785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.4891470803864415, "cur_kl_coeff": 0.0002539834171306877, "cur_lr": 0.00010000000000000003, "total_loss": 3.4382815231091133, "policy_loss": -0.0008481717454121699, "vf_loss": 3.439127620187386, "vf_explained_var": 0.024979092708971133, "kl": 0.008155388528017504, "entropy": 0.48997842223240584, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 295785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -347.7, "episode_reward_mean": 73.24699999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -9.041499999999997, "predator_policy": 45.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 150.90000000000003, 29.900000000000176, 32.30000000000019, 40.0000000000003, 34.50000000000022, -1.299999999999958, 25.70000000000007, 185.0, 141.2999999999995, -79.60000000000008, 40.0000000000003, 181.99999999999943, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 172.29999999999953, 188.59999999999943, 40.0000000000003, 186.09999999999943, 208.99999999999932, 160.49999999999957, 400.0, 37.80000000000027, 36.70000000000025, 219.99999999999926, 205.99999999999932, 199.99999999999935, 9.599999999999962, -173.00000000000063, 37.80000000000027, -347.7, 25.900000000000112, 171.3, 8.99999999999996, 35.600000000000236, 40.0000000000003, 42.00000000000026, -82.50000000000054, 356.0, 24.900000000000052, 19.700000000000014, 199.99999999999935, -168.0000000000006, 33.400000000000205, 40.0000000000003, 219.99999999999926, -219.2999999999999, 37.80000000000027, 38.90000000000028, 33.400000000000205, 173.19999999999948, 12.599999999999973, 371.5, 198.49999999999937, 39.40000000000029, 11.999999999999961, 19.6, 178.79999999999947, -94.00000000000003, 27.60000000000014, 33.000000000000234, 40.0000000000003, 169.69999999999953, 40.0000000000003, 219.99999999999926, 199.99999999999935, 23.50000000000005, 26.600000000000115, 40.0000000000003, 37.700000000000294, 40.0000000000003, -120.00000000000077, 40.0000000000003, 198.10000000000002, -44.79999999999976, 30.100000000000147, 219.99999999999926, 40.0000000000003, 40.0000000000003, 38.90000000000028, 87.29999999999991, 40.0000000000003, -94.60000000000036, 40.0000000000003, 40.0000000000003, 196.69999999999936, 40.0000000000003, 199.99999999999935, 40.0000000000003, 211.9999999999993, 167.6, 205.69999999999933, 40.0000000000003, 129.30000000000007, 30.100000000000147, 40.0000000000003, 33.2000000000002, 38.900000000000276], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 200.0, -339.1, -331.0, -3.099999999999958, 20.000000000000014, 5.299999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -397.0, 13.699999999999964, 3.1999999999999615, 9.499999999999966, 200.0, -400.0, 20.000000000000014, 83.3, -376.9, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 148.1, 3.1999999999999615, 131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.0999999999999865, 20.000000000000014, 170.0, 9.499999999999964, 119.0, 200.0, 200.0, 15.799999999999963, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -381.4, -400.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, -351.7, -361.0, -255.10000000000002, 20.000000000000014, 155.3, -367.0, -391.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -307.0, 20.000000000000014, 9.499999999999964, -364.0, 170.0, 173.0, 5.299999999999965, 11.599999999999964, 7.399999999999965, 5.299999999999965, 170.0, 20.000000000000014, 20.000000000000014, -382.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -200.49999999999994, -248.8000000000001, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 153.2, -324.4, 20.000000000000014, 164.0, 195.5, 9.499999999999964, 176.0, 7.399999999999965, 20.000000000000014, -385.0, 20.000000000000014, -334.6, 3.1999999999999615, 20.000000000000014, 150.8, 20.000000000000014, -271.0, 11.599999999999964, -343.0, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, 155.9, -5.199999999999937, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 170.0, -11.499999999999847, 20.000000000000014, 7.399999999999979, 3.199999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999744, -385.0, 20.000000000000014, 20.000000000000014, 200.0, -355.9, -368.8, -42.999999999999766, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 125.60000000000007, -112.30000000000004, 20.000000000000014, 20.000000000000014, -229.0, -34.59999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999967, 170.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 176.6, -385.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 143.3, -400.0, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 134.0, 156.0, 176.0, 188.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 200.0, 182.0, 8.0, 5.0, 185.0, 200.0, 38.0, 0.0, 103.0, 189.0, 0.0, 0.0, 0.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 19.0, 18.0, 19.0, 0.0, 0.0, 0.0, 15.0, 9.0, 10.0, 10.0, 22.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 192.0, 179.0, 7.0, 200.0, 2.0, 0.0, 184.0, 181.0, 131.0, 130.0, 194.0, 189.0, 183.0, 197.0, 0.0, 4.0, 0.0, 0.0, 169.0, 160.0, 193.0, 79.0, 0.0, 13.0, 0.0, 8.0, 7.0, 0.0, 0.0, 10.0, 0.0, 194.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 91.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 164.0, 153.0, 0.0, 12.0, 5.0, 8.0, 6.0, 6.0, 195.0, 182.0, 179.0, 172.0, 0.0, 8.0, 0.0, 157.0, 178.0, 181.0, 185.0, 183.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 15.0, 0.0, 2.0, 14.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 195.0, 92.0, 0.0, 0.0, 176.0, 178.0, 186.0, 181.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 42.0, 32.0, 0.0, 0.0, 20.0, 149.0, 0.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 8.0, 181.0, 195.0, 12.0, 1.0, 0.0, 0.0, 186.0, 200.0, 0.0, 9.0, 0.0, 0.0, 8.0, 2.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8326367210186285, "mean_inference_ms": 2.4006764115408963, "mean_action_processing_ms": 0.37376546948486095, "mean_env_wait_ms": 0.30301178200803547, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005306124687194824, "StateBufferConnector_ms": 0.0054923295974731445, "ViewRequirementAgentConnector_ms": 0.14373481273651123}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -347.7, "episode_return_mean": 73.24699999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 303.4173665820375, "num_env_steps_trained_throughput_per_sec": 303.4173665820375, "timesteps_total": 628000, "num_env_steps_sampled_lifetime": 628000, "num_agent_steps_sampled_lifetime": 2512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2512000, "timers": {"training_iteration_time_ms": 12632.837, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12632.788, "sample_time_ms": 1757.071, "learn_time_ms": 10855.009, "learn_throughput": 368.493, "synch_weights_time_ms": 16.504}, "counters": {"num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "done": false, "training_iteration": 157, "trial_id": "04dec_00002", "date": "2024-08-13_16-57-53", "timestamp": 1723582673, "time_this_iter_s": 13.229607105255127, "time_total_s": 2100.803430557251, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0724e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2100.803430557251, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 74.74444444444445, "ram_util_percent": 83.66666666666669}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.988349366475823, "cur_kl_coeff": 1.2349740370967693e-19, "cur_lr": 0.00010000000000000003, "total_loss": 2.11410149707996, "policy_loss": -0.00154728270603945, "vf_loss": 2.115648776513559, "vf_explained_var": 0.0008764863014221191, "kl": 0.002226279771692623, "entropy": 0.0791984598452925, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 297675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.752713853499246, "cur_kl_coeff": 0.0002539834171306877, "cur_lr": 0.00010000000000000003, "total_loss": 4.080590315092177, "policy_loss": -0.009817191026981665, "vf_loss": 4.090399822860799, "vf_explained_var": 0.041266281579537364, "kl": 0.030263543435045753, "entropy": 0.5273473224627278, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 297675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -347.7, "episode_reward_mean": 84.97599999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -1.5219999999999958, "predator_policy": 44.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [188.59999999999943, 40.0000000000003, 186.09999999999943, 208.99999999999932, 160.49999999999957, 400.0, 37.80000000000027, 36.70000000000025, 219.99999999999926, 205.99999999999932, 199.99999999999935, 9.599999999999962, -173.00000000000063, 37.80000000000027, -347.7, 25.900000000000112, 171.3, 8.99999999999996, 35.600000000000236, 40.0000000000003, 42.00000000000026, -82.50000000000054, 356.0, 24.900000000000052, 19.700000000000014, 199.99999999999935, -168.0000000000006, 33.400000000000205, 40.0000000000003, 219.99999999999926, -219.2999999999999, 37.80000000000027, 38.90000000000028, 33.400000000000205, 173.19999999999948, 12.599999999999973, 371.5, 198.49999999999937, 39.40000000000029, 11.999999999999961, 19.6, 178.79999999999947, -94.00000000000003, 27.60000000000014, 33.000000000000234, 40.0000000000003, 169.69999999999953, 40.0000000000003, 219.99999999999926, 199.99999999999935, 23.50000000000005, 26.600000000000115, 40.0000000000003, 37.700000000000294, 40.0000000000003, -120.00000000000077, 40.0000000000003, 198.10000000000002, -44.79999999999976, 30.100000000000147, 219.99999999999926, 40.0000000000003, 40.0000000000003, 38.90000000000028, 87.29999999999991, 40.0000000000003, -94.60000000000036, 40.0000000000003, 40.0000000000003, 196.69999999999936, 40.0000000000003, 199.99999999999935, 40.0000000000003, 211.9999999999993, 167.6, 205.69999999999933, 40.0000000000003, 129.30000000000007, 30.100000000000147, 40.0000000000003, 33.2000000000002, 38.900000000000276, 38.90000000000028, 197.49999999999937, 214.4999999999993, 195.0, 36.300000000000246, 194.7999999999994, 308.0, 288.1, 205.99999999999932, 176.0, -101.0000000000005, 40.0000000000003, 173.7999999999995, 40.0000000000003, 22.000000000000043, 199.99999999999935, 40.0000000000003, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 1.0999999999999865, 20.000000000000014, 170.0, 9.499999999999964, 119.0, 200.0, 200.0, 15.799999999999963, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -381.4, -400.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, -351.7, -361.0, -255.10000000000002, 20.000000000000014, 155.3, -367.0, -391.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -307.0, 20.000000000000014, 9.499999999999964, -364.0, 170.0, 173.0, 5.299999999999965, 11.599999999999964, 7.399999999999965, 5.299999999999965, 170.0, 20.000000000000014, 20.000000000000014, -382.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -200.49999999999994, -248.8000000000001, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 153.2, -324.4, 20.000000000000014, 164.0, 195.5, 9.499999999999964, 176.0, 7.399999999999965, 20.000000000000014, -385.0, 20.000000000000014, -334.6, 3.1999999999999615, 20.000000000000014, 150.8, 20.000000000000014, -271.0, 11.599999999999964, -343.0, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, 155.9, -5.199999999999937, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 170.0, -11.499999999999847, 20.000000000000014, 7.399999999999979, 3.199999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999744, -385.0, 20.000000000000014, 20.000000000000014, 200.0, -355.9, -368.8, -42.999999999999766, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 125.60000000000007, -112.30000000000004, 20.000000000000014, 20.000000000000014, -229.0, -34.59999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999967, 170.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 176.6, -385.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 143.3, -400.0, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 20.000000000000014, 17.899999999999988, 20.000000000000014, 177.5, 20.000000000000014, 9.499999999999964, 200.0, -388.0, 200.0, 8.299999999999965, 20.000000000000014, 20.000000000000014, 174.8, 200.0, 62.0, 64.10000000000011, 200.0, 179.0, 20.000000000000014, 188.0, -388.0, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -68.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -352.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0], "policy_predator_policy_reward": [18.0, 19.0, 0.0, 0.0, 0.0, 15.0, 9.0, 10.0, 10.0, 22.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 192.0, 179.0, 7.0, 200.0, 2.0, 0.0, 184.0, 181.0, 131.0, 130.0, 194.0, 189.0, 183.0, 197.0, 0.0, 4.0, 0.0, 0.0, 169.0, 160.0, 193.0, 79.0, 0.0, 13.0, 0.0, 8.0, 7.0, 0.0, 0.0, 10.0, 0.0, 194.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 91.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 164.0, 153.0, 0.0, 12.0, 5.0, 8.0, 6.0, 6.0, 195.0, 182.0, 179.0, 172.0, 0.0, 8.0, 0.0, 157.0, 178.0, 181.0, 185.0, 183.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 15.0, 0.0, 2.0, 14.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 195.0, 92.0, 0.0, 0.0, 176.0, 178.0, 186.0, 181.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 42.0, 32.0, 0.0, 0.0, 20.0, 149.0, 0.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 8.0, 181.0, 195.0, 12.0, 1.0, 0.0, 0.0, 186.0, 200.0, 0.0, 9.0, 0.0, 0.0, 8.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 187.0, 196.0, 6.0, 2.0, 0.0, 0.0, 1.0, 45.0, 16.0, 8.0, 7.0, 0.0, 176.0, 200.0, 51.0, 186.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 174.0, 180.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8321386641332488, "mean_inference_ms": 2.40026354352337, "mean_action_processing_ms": 0.37334049019000376, "mean_env_wait_ms": 0.30283966082185343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006122708320617676, "StateBufferConnector_ms": 0.005567669868469238, "ViewRequirementAgentConnector_ms": 0.14905619621276855}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -347.7, "episode_return_mean": 84.97599999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 303.3598812454566, "num_env_steps_trained_throughput_per_sec": 303.3598812454566, "timesteps_total": 632000, "num_env_steps_sampled_lifetime": 632000, "num_agent_steps_sampled_lifetime": 2528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2528000, "timers": {"training_iteration_time_ms": 12662.354, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12662.306, "sample_time_ms": 1764.564, "learn_time_ms": 10876.51, "learn_throughput": 367.765, "synch_weights_time_ms": 17.911}, "counters": {"num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "done": false, "training_iteration": 158, "trial_id": "04dec_00002", "date": "2024-08-13_16-58-06", "timestamp": 1723582686, "time_this_iter_s": 13.250856876373291, "time_total_s": 2114.0542874336243, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06fce50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2114.0542874336243, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 72.03157894736842, "ram_util_percent": 83.62105263157893}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0260154448213086, "cur_kl_coeff": 6.174870185483846e-20, "cur_lr": 0.00010000000000000003, "total_loss": 1.3880132821817246, "policy_loss": -3.736214379646948e-05, "vf_loss": 1.3880506444071967, "vf_explained_var": 4.1634916628479325e-05, "kl": 0.002173278131486397, "entropy": 0.06736163626567869, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 299565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.263145991990333, "cur_kl_coeff": 0.00038097512569603136, "cur_lr": 0.00010000000000000003, "total_loss": 2.5403048130570265, "policy_loss": -0.00013234148999410016, "vf_loss": 2.5404331438440493, "vf_explained_var": 0.03625435680939407, "kl": 0.01052345724495585, "entropy": 0.5889919785910813, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 299565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -219.2999999999999, "episode_reward_mean": 85.16799999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 6.524, "predator_policy": 36.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.600000000000236, 40.0000000000003, 42.00000000000026, -82.50000000000054, 356.0, 24.900000000000052, 19.700000000000014, 199.99999999999935, -168.0000000000006, 33.400000000000205, 40.0000000000003, 219.99999999999926, -219.2999999999999, 37.80000000000027, 38.90000000000028, 33.400000000000205, 173.19999999999948, 12.599999999999973, 371.5, 198.49999999999937, 39.40000000000029, 11.999999999999961, 19.6, 178.79999999999947, -94.00000000000003, 27.60000000000014, 33.000000000000234, 40.0000000000003, 169.69999999999953, 40.0000000000003, 219.99999999999926, 199.99999999999935, 23.50000000000005, 26.600000000000115, 40.0000000000003, 37.700000000000294, 40.0000000000003, -120.00000000000077, 40.0000000000003, 198.10000000000002, -44.79999999999976, 30.100000000000147, 219.99999999999926, 40.0000000000003, 40.0000000000003, 38.90000000000028, 87.29999999999991, 40.0000000000003, -94.60000000000036, 40.0000000000003, 40.0000000000003, 196.69999999999936, 40.0000000000003, 199.99999999999935, 40.0000000000003, 211.9999999999993, 167.6, 205.69999999999933, 40.0000000000003, 129.30000000000007, 30.100000000000147, 40.0000000000003, 33.2000000000002, 38.900000000000276, 38.90000000000028, 197.49999999999937, 214.4999999999993, 195.0, 36.300000000000246, 194.7999999999994, 308.0, 288.1, 205.99999999999932, 176.0, -101.0000000000005, 40.0000000000003, 173.7999999999995, 40.0000000000003, 22.000000000000043, 199.99999999999935, 40.0000000000003, 219.99999999999926, -126.0, -9.499999999999705, 40.0000000000003, 400.0, 200.49999999999935, 219.99999999999926, 208.5999999999993, 203.99999999999932, 38.90000000000028, 40.0000000000003, 40.0000000000003, -20.499999999999588, 40.0000000000003, 40.0000000000003, 40.0000000000003, 34.50000000000022, 32.30000000000018, 213.9999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -307.0, 20.000000000000014, 9.499999999999964, -364.0, 170.0, 173.0, 5.299999999999965, 11.599999999999964, 7.399999999999965, 5.299999999999965, 170.0, 20.000000000000014, 20.000000000000014, -382.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -200.49999999999994, -248.8000000000001, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 153.2, -324.4, 20.000000000000014, 164.0, 195.5, 9.499999999999964, 176.0, 7.399999999999965, 20.000000000000014, -385.0, 20.000000000000014, -334.6, 3.1999999999999615, 20.000000000000014, 150.8, 20.000000000000014, -271.0, 11.599999999999964, -343.0, 20.000000000000014, -355.0, 20.000000000000014, 20.000000000000014, 155.9, -5.199999999999937, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 170.0, -11.499999999999847, 20.000000000000014, 7.399999999999979, 3.199999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999744, -385.0, 20.000000000000014, 20.000000000000014, 200.0, -355.9, -368.8, -42.999999999999766, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 125.60000000000007, -112.30000000000004, 20.000000000000014, 20.000000000000014, -229.0, -34.59999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999967, 170.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 176.6, -385.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 143.3, -400.0, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 20.000000000000014, 17.899999999999988, 20.000000000000014, 177.5, 20.000000000000014, 9.499999999999964, 200.0, -388.0, 200.0, 8.299999999999965, 20.000000000000014, 20.000000000000014, 174.8, 200.0, 62.0, 64.10000000000011, 200.0, 179.0, 20.000000000000014, 188.0, -388.0, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -68.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -352.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -400.0, -85.0, 20.000000000000014, -74.50000000000072, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 200.0, -9.399999999999855, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -95.50000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, 191.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 4.0, 0.0, 0.0, 169.0, 160.0, 193.0, 79.0, 0.0, 13.0, 0.0, 8.0, 7.0, 0.0, 0.0, 10.0, 0.0, 194.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 91.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 164.0, 153.0, 0.0, 12.0, 5.0, 8.0, 6.0, 6.0, 195.0, 182.0, 179.0, 172.0, 0.0, 8.0, 0.0, 157.0, 178.0, 181.0, 185.0, 183.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 15.0, 0.0, 2.0, 14.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 195.0, 92.0, 0.0, 0.0, 176.0, 178.0, 186.0, 181.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 42.0, 32.0, 0.0, 0.0, 20.0, 149.0, 0.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 8.0, 181.0, 195.0, 12.0, 1.0, 0.0, 0.0, 186.0, 200.0, 0.0, 9.0, 0.0, 0.0, 8.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 187.0, 196.0, 6.0, 2.0, 0.0, 0.0, 1.0, 45.0, 16.0, 8.0, 7.0, 0.0, 176.0, 200.0, 51.0, 186.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 174.0, 180.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 200.0, 159.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 14.0, 4.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8316415189432195, "mean_inference_ms": 2.399831293990949, "mean_action_processing_ms": 0.3729430719347981, "mean_env_wait_ms": 0.30265491311274884, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006512045860290527, "StateBufferConnector_ms": 0.005253911018371582, "ViewRequirementAgentConnector_ms": 0.1333017349243164}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -219.2999999999999, "episode_return_mean": 85.16799999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.33546868181537, "num_env_steps_trained_throughput_per_sec": 316.33546868181537, "timesteps_total": 636000, "num_env_steps_sampled_lifetime": 636000, "num_agent_steps_sampled_lifetime": 2544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2544000, "timers": {"training_iteration_time_ms": 12668.347, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12668.299, "sample_time_ms": 1765.638, "learn_time_ms": 10881.626, "learn_throughput": 367.592, "synch_weights_time_ms": 17.735}, "counters": {"num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "done": false, "training_iteration": 159, "trial_id": "04dec_00002", "date": "2024-08-13_16-58-19", "timestamp": 1723582699, "time_this_iter_s": 12.702917098999023, "time_total_s": 2126.7572045326233, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06fcd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2126.7572045326233, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 69.30555555555556, "ram_util_percent": 83.29444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.009538170734726, "cur_kl_coeff": 3.087435092741923e-20, "cur_lr": 0.00010000000000000003, "total_loss": 2.286238602229527, "policy_loss": -0.0029638662404582773, "vf_loss": 2.289202464383746, "vf_explained_var": 0.0017596495529961964, "kl": 0.0032302934143909456, "entropy": 0.07511434194942315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 301455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.5447308401266735, "cur_kl_coeff": 0.00038097512569603136, "cur_lr": 0.00010000000000000003, "total_loss": 3.0147342398053123, "policy_loss": -0.0018492239175078573, "vf_loss": 3.016580746413539, "vf_explained_var": -0.008031687976191283, "kl": 0.007128756134317314, "entropy": 0.5555705879888837, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 301455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -163.50000000000045, "episode_reward_mean": 77.39699999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 7.9084999999999885, "predator_policy": 30.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 169.69999999999953, 40.0000000000003, 219.99999999999926, 199.99999999999935, 23.50000000000005, 26.600000000000115, 40.0000000000003, 37.700000000000294, 40.0000000000003, -120.00000000000077, 40.0000000000003, 198.10000000000002, -44.79999999999976, 30.100000000000147, 219.99999999999926, 40.0000000000003, 40.0000000000003, 38.90000000000028, 87.29999999999991, 40.0000000000003, -94.60000000000036, 40.0000000000003, 40.0000000000003, 196.69999999999936, 40.0000000000003, 199.99999999999935, 40.0000000000003, 211.9999999999993, 167.6, 205.69999999999933, 40.0000000000003, 129.30000000000007, 30.100000000000147, 40.0000000000003, 33.2000000000002, 38.900000000000276, 38.90000000000028, 197.49999999999937, 214.4999999999993, 195.0, 36.300000000000246, 194.7999999999994, 308.0, 288.1, 205.99999999999932, 176.0, -101.0000000000005, 40.0000000000003, 173.7999999999995, 40.0000000000003, 22.000000000000043, 199.99999999999935, 40.0000000000003, 219.99999999999926, -126.0, -9.499999999999705, 40.0000000000003, 400.0, 200.49999999999935, 219.99999999999926, 208.5999999999993, 203.99999999999932, 38.90000000000028, 40.0000000000003, 40.0000000000003, -20.499999999999588, 40.0000000000003, 40.0000000000003, 40.0000000000003, 34.50000000000022, 32.30000000000018, 213.9999999999993, 61.600000000000286, 40.0000000000003, -19.399999999999544, 2.199999999999954, 13.999999999999964, 219.99999999999926, 31.100000000000172, 41.800000000000324, 40.0000000000003, -158.00000000000054, 131.79999999999973, 219.99999999999926, 40.0000000000003, 26.000000000000107, 130.99999999999972, 40.0000000000003, -32.4999999999998, -104.70000000000087, 40.0000000000003, 40.0000000000003, -163.50000000000045, 24.600000000000048, 36.70000000000025, 28.900000000000155, 34.50000000000022, 40.0000000000003, 40.90000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 155.9, -5.199999999999937, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 170.0, -11.499999999999847, 20.000000000000014, 7.399999999999979, 3.199999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999744, -385.0, 20.000000000000014, 20.000000000000014, 200.0, -355.9, -368.8, -42.999999999999766, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 125.60000000000007, -112.30000000000004, 20.000000000000014, 20.000000000000014, -229.0, -34.59999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999967, 170.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 176.6, -385.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 143.3, -400.0, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 20.000000000000014, 17.899999999999988, 20.000000000000014, 177.5, 20.000000000000014, 9.499999999999964, 200.0, -388.0, 200.0, 8.299999999999965, 20.000000000000014, 20.000000000000014, 174.8, 200.0, 62.0, 64.10000000000011, 200.0, 179.0, 20.000000000000014, 188.0, -388.0, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -68.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -352.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -400.0, -85.0, 20.000000000000014, -74.50000000000072, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 200.0, -9.399999999999855, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -95.50000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, 191.0, 20.000000000000014, 41.60000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, -93.40000000000082, 20.000000000000014, -379.0, 3.1999999999999615, 20.000000000000014, -121.0, 20.000000000000014, 200.0, -124.90000000000074, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, -101.80000000000075, 174.8, 20.000000000000014, 20.000000000000014, 9.499999999999964, -379.0, 20.000000000000014, -258.69999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -118.60000000000029, -130.90000000000023, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 13.699999999999966, -88.0, 20.90000000000003, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 15.0, 0.0, 2.0, 14.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 195.0, 92.0, 0.0, 0.0, 176.0, 178.0, 186.0, 181.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 42.0, 32.0, 0.0, 0.0, 20.0, 149.0, 0.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 8.0, 181.0, 195.0, 12.0, 1.0, 0.0, 0.0, 186.0, 200.0, 0.0, 9.0, 0.0, 0.0, 8.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 187.0, 196.0, 6.0, 2.0, 0.0, 0.0, 1.0, 45.0, 16.0, 8.0, 7.0, 0.0, 176.0, 200.0, 51.0, 186.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 174.0, 180.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 200.0, 159.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 14.0, 4.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 0.0, 190.0, 188.0, 14.0, 101.0, 0.0, 0.0, 68.0, 68.0, 0.0, 0.0, 0.0, 0.0, 102.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 193.0, 58.0, 0.0, 0.0, 0.0, 150.0, 187.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 10.0, 4.0, 0.0, 3.0, 96.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8311531859677026, "mean_inference_ms": 2.397777658965664, "mean_action_processing_ms": 0.3724832388145138, "mean_env_wait_ms": 0.3024443755197188, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01775038242340088, "StateBufferConnector_ms": 0.005550503730773926, "ViewRequirementAgentConnector_ms": 0.1430138349533081}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -163.50000000000045, "episode_return_mean": 77.39699999999998, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.0718835081459, "num_env_steps_trained_throughput_per_sec": 316.0718835081459, "timesteps_total": 640000, "num_env_steps_sampled_lifetime": 640000, "num_agent_steps_sampled_lifetime": 2560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2560000, "timers": {"training_iteration_time_ms": 12611.055, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12611.008, "sample_time_ms": 1778.966, "learn_time_ms": 10810.496, "learn_throughput": 370.011, "synch_weights_time_ms": 18.638}, "counters": {"num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "done": false, "training_iteration": 160, "trial_id": "04dec_00002", "date": "2024-08-13_16-58-32", "timestamp": 1723582712, "time_this_iter_s": 12.694519996643066, "time_total_s": 2139.4517245292664, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0728550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2139.4517245292664, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 66.68333333333334, "ram_util_percent": 83.25555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7689101998768155, "cur_kl_coeff": 1.5437175463709616e-20, "cur_lr": 0.00010000000000000003, "total_loss": 2.0156648199394267, "policy_loss": 4.2225017764226156e-05, "vf_loss": 2.0156225943691517, "vf_explained_var": 0.0001229223435517972, "kl": 0.002954971613753538, "entropy": 0.14478804249336164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 303345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.337006713126702, "cur_kl_coeff": 0.00038097512569603136, "cur_lr": 0.00010000000000000003, "total_loss": 3.6909475635599205, "policy_loss": -0.014983433994301965, "vf_loss": 3.705919217180323, "vf_explained_var": 0.023737519821792685, "kl": 0.03091048226005637, "entropy": 0.3694412940945575, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 303345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -257.0, "episode_reward_mean": 80.99199999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 10.675999999999988, "predator_policy": 29.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.90000000000028, 87.29999999999991, 40.0000000000003, -94.60000000000036, 40.0000000000003, 40.0000000000003, 196.69999999999936, 40.0000000000003, 199.99999999999935, 40.0000000000003, 211.9999999999993, 167.6, 205.69999999999933, 40.0000000000003, 129.30000000000007, 30.100000000000147, 40.0000000000003, 33.2000000000002, 38.900000000000276, 38.90000000000028, 197.49999999999937, 214.4999999999993, 195.0, 36.300000000000246, 194.7999999999994, 308.0, 288.1, 205.99999999999932, 176.0, -101.0000000000005, 40.0000000000003, 173.7999999999995, 40.0000000000003, 22.000000000000043, 199.99999999999935, 40.0000000000003, 219.99999999999926, -126.0, -9.499999999999705, 40.0000000000003, 400.0, 200.49999999999935, 219.99999999999926, 208.5999999999993, 203.99999999999932, 38.90000000000028, 40.0000000000003, 40.0000000000003, -20.499999999999588, 40.0000000000003, 40.0000000000003, 40.0000000000003, 34.50000000000022, 32.30000000000018, 213.9999999999993, 61.600000000000286, 40.0000000000003, -19.399999999999544, 2.199999999999954, 13.999999999999964, 219.99999999999926, 31.100000000000172, 41.800000000000324, 40.0000000000003, -158.00000000000054, 131.79999999999973, 219.99999999999926, 40.0000000000003, 26.000000000000107, 130.99999999999972, 40.0000000000003, -32.4999999999998, -104.70000000000087, 40.0000000000003, 40.0000000000003, -163.50000000000045, 24.600000000000048, 36.70000000000025, 28.900000000000155, 34.50000000000022, 40.0000000000003, 40.90000000000031, 20.000000000000014, 219.99999999999926, 30.000000000000146, 40.0000000000003, 218.89999999999927, 219.99999999999926, 203.99999999999935, 40.0000000000003, 40.0000000000003, 109.99999999999929, 166.8999999999995, 219.99999999999926, 196.19999999999936, -257.0, 196.09999999999937, 34.50000000000022, 49.00000000000043, -148.20000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 17.899999999999988, 125.60000000000007, -112.30000000000004, 20.000000000000014, 20.000000000000014, -229.0, -34.59999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999967, 170.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 176.6, -385.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 143.3, -400.0, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 20.000000000000014, 17.899999999999988, 20.000000000000014, 177.5, 20.000000000000014, 9.499999999999964, 200.0, -388.0, 200.0, 8.299999999999965, 20.000000000000014, 20.000000000000014, 174.8, 200.0, 62.0, 64.10000000000011, 200.0, 179.0, 20.000000000000014, 188.0, -388.0, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -68.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -352.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -400.0, -85.0, 20.000000000000014, -74.50000000000072, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 200.0, -9.399999999999855, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -95.50000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, 191.0, 20.000000000000014, 41.60000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, -93.40000000000082, 20.000000000000014, -379.0, 3.1999999999999615, 20.000000000000014, -121.0, 20.000000000000014, 200.0, -124.90000000000074, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, -101.80000000000075, 174.8, 20.000000000000014, 20.000000000000014, 9.499999999999964, -379.0, 20.000000000000014, -258.69999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -118.60000000000029, -130.90000000000023, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 13.699999999999966, -88.0, 20.90000000000003, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, -385.0, 200.0, 20.000000000000014, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 17.899999999999984, 200.0, 200.0, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.0, 146.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 174.2, 20.000000000000014, -94.0, -373.0, 179.6, 9.499999999999966, 9.499999999999973, 20.000000000000014, 20.000000000000014, 29.000000000000174, 15.799999999999962, -349.0], "policy_predator_policy_reward": [0.0, 1.0, 42.0, 32.0, 0.0, 0.0, 20.0, 149.0, 0.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 8.0, 181.0, 195.0, 12.0, 1.0, 0.0, 0.0, 186.0, 200.0, 0.0, 9.0, 0.0, 0.0, 8.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 187.0, 196.0, 6.0, 2.0, 0.0, 0.0, 1.0, 45.0, 16.0, 8.0, 7.0, 0.0, 176.0, 200.0, 51.0, 186.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 174.0, 180.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 200.0, 159.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 14.0, 4.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 0.0, 190.0, 188.0, 14.0, 101.0, 0.0, 0.0, 68.0, 68.0, 0.0, 0.0, 0.0, 0.0, 102.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 193.0, 58.0, 0.0, 0.0, 0.0, 150.0, 187.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 10.0, 4.0, 0.0, 3.0, 96.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 195.0, 0.0, 0.0, 3.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 14.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 191.0, 19.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 183.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8308271965089928, "mean_inference_ms": 2.3996013473480446, "mean_action_processing_ms": 0.37205078040668516, "mean_env_wait_ms": 0.30229786635623335, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018542766571044922, "StateBufferConnector_ms": 0.005614638328552246, "ViewRequirementAgentConnector_ms": 0.15825927257537842}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -257.0, "episode_return_mean": 80.99199999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.5071791231179, "num_env_steps_trained_throughput_per_sec": 316.5071791231179, "timesteps_total": 644000, "num_env_steps_sampled_lifetime": 644000, "num_agent_steps_sampled_lifetime": 2576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2576000, "timers": {"training_iteration_time_ms": 12608.855, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12608.803, "sample_time_ms": 1781.157, "learn_time_ms": 10805.358, "learn_throughput": 370.187, "synch_weights_time_ms": 19.406}, "counters": {"num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "done": false, "training_iteration": 161, "trial_id": "04dec_00002", "date": "2024-08-13_16-58-44", "timestamp": 1723582724, "time_this_iter_s": 12.699501752853394, "time_total_s": 2152.1512262821198, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0728310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2152.1512262821198, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 67.46666666666667, "ram_util_percent": 83.52777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8997777061014579, "cur_kl_coeff": 7.718587731854808e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.6619064819245112, "policy_loss": -0.0002162156254545879, "vf_loss": 0.6621226972254811, "vf_explained_var": 0.003916115546352649, "kl": 0.0022793841293602592, "entropy": 0.12544129854905858, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 305235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.336671177814247, "cur_kl_coeff": 0.0005714626885440471, "cur_lr": 0.00010000000000000003, "total_loss": 2.1349485696623565, "policy_loss": -0.0014938882835426185, "vf_loss": 2.136437080839954, "vf_explained_var": 0.20397153950872876, "kl": 0.009405086256492057, "entropy": 0.5126476424869406, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 305235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -257.0, "episode_reward_mean": 83.5019999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 15.895999999999985, "predator_policy": 25.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.900000000000276, 38.90000000000028, 197.49999999999937, 214.4999999999993, 195.0, 36.300000000000246, 194.7999999999994, 308.0, 288.1, 205.99999999999932, 176.0, -101.0000000000005, 40.0000000000003, 173.7999999999995, 40.0000000000003, 22.000000000000043, 199.99999999999935, 40.0000000000003, 219.99999999999926, -126.0, -9.499999999999705, 40.0000000000003, 400.0, 200.49999999999935, 219.99999999999926, 208.5999999999993, 203.99999999999932, 38.90000000000028, 40.0000000000003, 40.0000000000003, -20.499999999999588, 40.0000000000003, 40.0000000000003, 40.0000000000003, 34.50000000000022, 32.30000000000018, 213.9999999999993, 61.600000000000286, 40.0000000000003, -19.399999999999544, 2.199999999999954, 13.999999999999964, 219.99999999999926, 31.100000000000172, 41.800000000000324, 40.0000000000003, -158.00000000000054, 131.79999999999973, 219.99999999999926, 40.0000000000003, 26.000000000000107, 130.99999999999972, 40.0000000000003, -32.4999999999998, -104.70000000000087, 40.0000000000003, 40.0000000000003, -163.50000000000045, 24.600000000000048, 36.70000000000025, 28.900000000000155, 34.50000000000022, 40.0000000000003, 40.90000000000031, 20.000000000000014, 219.99999999999926, 30.000000000000146, 40.0000000000003, 218.89999999999927, 219.99999999999926, 203.99999999999935, 40.0000000000003, 40.0000000000003, 109.99999999999929, 166.8999999999995, 219.99999999999926, 196.19999999999936, -257.0, 196.09999999999937, 34.50000000000022, 49.00000000000043, -148.20000000000047, 25.200000000000074, 8.30000000000013, 185.99999999999943, 40.0000000000003, 40.0000000000003, 40.0000000000003, 216.39999999999927, 40.0000000000003, 371.2, 40.0000000000003, 40.0000000000003, 219.99999999999926, 17.999999999999954, 213.9999999999993, 37.80000000000027, 40.0000000000003, 143.9999999999997, 16.299999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, 20.000000000000014, 17.899999999999988, 20.000000000000014, 177.5, 20.000000000000014, 9.499999999999964, 200.0, -388.0, 200.0, 8.299999999999965, 20.000000000000014, 20.000000000000014, 174.8, 200.0, 62.0, 64.10000000000011, 200.0, 179.0, 20.000000000000014, 188.0, -388.0, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -68.20000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -352.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -400.0, -85.0, 20.000000000000014, -74.50000000000072, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 200.0, -9.399999999999855, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -95.50000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, 191.0, 20.000000000000014, 41.60000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, -93.40000000000082, 20.000000000000014, -379.0, 3.1999999999999615, 20.000000000000014, -121.0, 20.000000000000014, 200.0, -124.90000000000074, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, -101.80000000000075, 174.8, 20.000000000000014, 20.000000000000014, 9.499999999999964, -379.0, 20.000000000000014, -258.69999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -118.60000000000029, -130.90000000000023, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 13.699999999999966, -88.0, 20.90000000000003, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, -385.0, 200.0, 20.000000000000014, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 17.899999999999984, 200.0, 200.0, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.0, 146.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 174.2, 20.000000000000014, -94.0, -373.0, 179.6, 9.499999999999966, 9.499999999999973, 20.000000000000014, 20.000000000000014, 29.000000000000174, 15.799999999999962, -349.0, 20.000000000000014, -80.80000000000084, 3.1999999999999615, -19.899999999999743, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 162.20000000000002, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -21.999999999999844, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 26.0, 20.000000000000014, 20.000000000000014, -27.699999999999818], "policy_predator_policy_reward": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 187.0, 196.0, 6.0, 2.0, 0.0, 0.0, 1.0, 45.0, 16.0, 8.0, 7.0, 0.0, 176.0, 200.0, 51.0, 186.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 174.0, 180.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 200.0, 159.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 14.0, 4.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 0.0, 190.0, 188.0, 14.0, 101.0, 0.0, 0.0, 68.0, 68.0, 0.0, 0.0, 0.0, 0.0, 102.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 193.0, 58.0, 0.0, 0.0, 0.0, 150.0, 187.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 10.0, 4.0, 0.0, 3.0, 96.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 195.0, 0.0, 0.0, 3.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 14.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 191.0, 19.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 183.0, 2.0, 39.0, 47.0, 19.0, 6.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8305622195450948, "mean_inference_ms": 2.399511465893115, "mean_action_processing_ms": 0.37171461413777507, "mean_env_wait_ms": 0.30220377550536265, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01860034465789795, "StateBufferConnector_ms": 0.003962516784667969, "ViewRequirementAgentConnector_ms": 0.14288532733917236}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -257.0, "episode_return_mean": 83.5019999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.35142922545685, "num_env_steps_trained_throughput_per_sec": 321.35142922545685, "timesteps_total": 648000, "num_env_steps_sampled_lifetime": 648000, "num_agent_steps_sampled_lifetime": 2592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2592000, "timers": {"training_iteration_time_ms": 12560.116, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12560.064, "sample_time_ms": 1743.079, "learn_time_ms": 10795.499, "learn_throughput": 370.525, "synch_weights_time_ms": 18.659}, "counters": {"num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "done": false, "training_iteration": 162, "trial_id": "04dec_00002", "date": "2024-08-13_16-58-57", "timestamp": 1723582737, "time_this_iter_s": 12.506797075271606, "time_total_s": 2164.6580233573914, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0720d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2164.6580233573914, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 66.83888888888889, "ram_util_percent": 83.58333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6819858186853627, "cur_kl_coeff": 3.859293865927404e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.0248227878853127, "policy_loss": 0.001316851140591242, "vf_loss": 1.0235059385892575, "vf_explained_var": -0.0007184382784303534, "kl": 0.0035796087897371166, "entropy": 0.10569874243564391, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 307125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.849856293784878, "cur_kl_coeff": 0.0005714626885440471, "cur_lr": 0.00010000000000000003, "total_loss": 3.412139578975698, "policy_loss": -0.0010985805946229785, "vf_loss": 3.4132335376487206, "vf_explained_var": 0.2353931401141737, "kl": 0.008094863460101088, "entropy": 0.34733095691790655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 307125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -257.0, "episode_reward_mean": 82.64499999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 18.702499999999986, "predator_policy": 22.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, -126.0, -9.499999999999705, 40.0000000000003, 400.0, 200.49999999999935, 219.99999999999926, 208.5999999999993, 203.99999999999932, 38.90000000000028, 40.0000000000003, 40.0000000000003, -20.499999999999588, 40.0000000000003, 40.0000000000003, 40.0000000000003, 34.50000000000022, 32.30000000000018, 213.9999999999993, 61.600000000000286, 40.0000000000003, -19.399999999999544, 2.199999999999954, 13.999999999999964, 219.99999999999926, 31.100000000000172, 41.800000000000324, 40.0000000000003, -158.00000000000054, 131.79999999999973, 219.99999999999926, 40.0000000000003, 26.000000000000107, 130.99999999999972, 40.0000000000003, -32.4999999999998, -104.70000000000087, 40.0000000000003, 40.0000000000003, -163.50000000000045, 24.600000000000048, 36.70000000000025, 28.900000000000155, 34.50000000000022, 40.0000000000003, 40.90000000000031, 20.000000000000014, 219.99999999999926, 30.000000000000146, 40.0000000000003, 218.89999999999927, 219.99999999999926, 203.99999999999935, 40.0000000000003, 40.0000000000003, 109.99999999999929, 166.8999999999995, 219.99999999999926, 196.19999999999936, -257.0, 196.09999999999937, 34.50000000000022, 49.00000000000043, -148.20000000000047, 25.200000000000074, 8.30000000000013, 185.99999999999943, 40.0000000000003, 40.0000000000003, 40.0000000000003, 216.39999999999927, 40.0000000000003, 371.2, 40.0000000000003, 40.0000000000003, 219.99999999999926, 17.999999999999954, 213.9999999999993, 37.80000000000027, 40.0000000000003, 143.9999999999997, 16.299999999999926, 211.2999999999993, 200.89999999999935, 190.4999999999994, 386.0, 34.50000000000022, 219.99999999999926, 40.0000000000003, 211.1999999999993, 143.09999999999968, 207.99999999999932, -25.999999999999822, 40.0000000000003, 44.40000000000036, 40.0000000000003, 29.500000000000142, -3.000000000000032, 38.90000000000028, 213.79999999999927], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, -400.0, -85.0, 20.000000000000014, -74.50000000000072, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 200.0, -9.399999999999855, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 17.899999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -95.50000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, 191.0, 20.000000000000014, 41.60000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, -93.40000000000082, 20.000000000000014, -379.0, 3.1999999999999615, 20.000000000000014, -121.0, 20.000000000000014, 200.0, -124.90000000000074, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, -101.80000000000075, 174.8, 20.000000000000014, 20.000000000000014, 9.499999999999964, -379.0, 20.000000000000014, -258.69999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -118.60000000000029, -130.90000000000023, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 13.699999999999966, -88.0, 20.90000000000003, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, -385.0, 200.0, 20.000000000000014, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 17.899999999999984, 200.0, 200.0, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.0, 146.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 174.2, 20.000000000000014, -94.0, -373.0, 179.6, 9.499999999999966, 9.499999999999973, 20.000000000000014, 20.000000000000014, 29.000000000000174, 15.799999999999962, -349.0, 20.000000000000014, -80.80000000000084, 3.1999999999999615, -19.899999999999743, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 162.20000000000002, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -21.999999999999844, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 26.0, 20.000000000000014, 20.000000000000014, -27.699999999999818, 200.0, -15.699999999999761, 17.899999999999984, 173.0, 164.0, 9.49999999999997, 179.0, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 200.0, 162.8, -57.70000000000034, 182.0, 20.000000000000014, 20.000000000000014, -391.0, 20.000000000000014, 20.000000000000014, 21.500000000000043, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -17.79999999999974, 20.000000000000014, -379.0, 20.000000000000014, 17.899999999999988, 21.80000000000004, 188.0], "policy_predator_policy_reward": [0.0, 0.0, 200.0, 159.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 14.0, 4.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 0.0, 190.0, 188.0, 14.0, 101.0, 0.0, 0.0, 68.0, 68.0, 0.0, 0.0, 0.0, 0.0, 102.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 193.0, 58.0, 0.0, 0.0, 0.0, 150.0, 187.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 10.0, 4.0, 0.0, 3.0, 96.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 195.0, 0.0, 0.0, 3.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 14.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 191.0, 19.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 183.0, 2.0, 39.0, 47.0, 19.0, 6.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 24.0, 15.0, 12.0, 9.0, 1.0, 12.0, 5.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 37.0, 1.0, 0.0, 6.0, 154.0, 191.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 18.0, 3.0, 170.0, 186.0, 0.0, 1.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8302690717263413, "mean_inference_ms": 2.3992715553344293, "mean_action_processing_ms": 0.3713685050766148, "mean_env_wait_ms": 0.3021175989089493, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018570423126220703, "StateBufferConnector_ms": 0.006196379661560059, "ViewRequirementAgentConnector_ms": 0.13533663749694824}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -257.0, "episode_return_mean": 82.64499999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.74592675598217, "num_env_steps_trained_throughput_per_sec": 332.74592675598217, "timesteps_total": 652000, "num_env_steps_sampled_lifetime": 652000, "num_agent_steps_sampled_lifetime": 2608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2608000, "timers": {"training_iteration_time_ms": 12530.039, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12529.965, "sample_time_ms": 1743.378, "learn_time_ms": 10763.851, "learn_throughput": 371.614, "synch_weights_time_ms": 19.382}, "counters": {"num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "done": false, "training_iteration": 163, "trial_id": "04dec_00002", "date": "2024-08-13_16-59-09", "timestamp": 1723582749, "time_this_iter_s": 12.060658931732178, "time_total_s": 2176.7186822891235, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0774af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2176.7186822891235, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 66.79411764705883, "ram_util_percent": 83.5294117647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3111149540653935, "cur_kl_coeff": 1.929646932963702e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.4365742180397902, "policy_loss": -0.00023903815413297958, "vf_loss": 1.4368132543311547, "vf_explained_var": -2.5136067123009416e-05, "kl": 0.0027811969584827577, "entropy": 0.17668563199658244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 309015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.779816936027436, "cur_kl_coeff": 0.0005714626885440471, "cur_lr": 0.00010000000000000003, "total_loss": 3.7322340263891474, "policy_loss": -0.0020226572647631643, "vf_loss": 3.734159146919452, "vf_explained_var": 0.14908444070942187, "kl": 0.17067996880539177, "entropy": 0.5555223484518667, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 309015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "env_runners": {"episode_reward_max": 386.0, "episode_reward_min": -257.0, "episode_reward_mean": 81.59999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 19.384999999999987, "predator_policy": 21.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.999999999999964, 219.99999999999926, 31.100000000000172, 41.800000000000324, 40.0000000000003, -158.00000000000054, 131.79999999999973, 219.99999999999926, 40.0000000000003, 26.000000000000107, 130.99999999999972, 40.0000000000003, -32.4999999999998, -104.70000000000087, 40.0000000000003, 40.0000000000003, -163.50000000000045, 24.600000000000048, 36.70000000000025, 28.900000000000155, 34.50000000000022, 40.0000000000003, 40.90000000000031, 20.000000000000014, 219.99999999999926, 30.000000000000146, 40.0000000000003, 218.89999999999927, 219.99999999999926, 203.99999999999935, 40.0000000000003, 40.0000000000003, 109.99999999999929, 166.8999999999995, 219.99999999999926, 196.19999999999936, -257.0, 196.09999999999937, 34.50000000000022, 49.00000000000043, -148.20000000000047, 25.200000000000074, 8.30000000000013, 185.99999999999943, 40.0000000000003, 40.0000000000003, 40.0000000000003, 216.39999999999927, 40.0000000000003, 371.2, 40.0000000000003, 40.0000000000003, 219.99999999999926, 17.999999999999954, 213.9999999999993, 37.80000000000027, 40.0000000000003, 143.9999999999997, 16.299999999999926, 211.2999999999993, 200.89999999999935, 190.4999999999994, 386.0, 34.50000000000022, 219.99999999999926, 40.0000000000003, 211.1999999999993, 143.09999999999968, 207.99999999999932, -25.999999999999822, 40.0000000000003, 44.40000000000036, 40.0000000000003, 29.500000000000142, -3.000000000000032, 38.90000000000028, 213.79999999999927, 205.99999999999932, 40.0000000000003, 182.89999999999944, 206.49999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 37.80000000000027, 219.99999999999926, 207.99999999999932, 147.9999999999996, -40.000000000000284, 219.99999999999926, 190.5999999999994, -48.999999999999936, 37.80000000000027, -27.09999999999956, -154.8000000000005, -195.80000000000078, 33.400000000000205, 87.99999999999946, 144.3999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -121.0, 20.000000000000014, 200.0, -124.90000000000074, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -379.0, -101.80000000000075, 174.8, 20.000000000000014, 20.000000000000014, 9.499999999999964, -379.0, 20.000000000000014, -258.69999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -118.60000000000029, -130.90000000000023, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 13.699999999999966, -88.0, 20.90000000000003, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, -385.0, 200.0, 20.000000000000014, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 17.899999999999984, 200.0, 200.0, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.0, 146.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 174.2, 20.000000000000014, -94.0, -373.0, 179.6, 9.499999999999966, 9.499999999999973, 20.000000000000014, 20.000000000000014, 29.000000000000174, 15.799999999999962, -349.0, 20.000000000000014, -80.80000000000084, 3.1999999999999615, -19.899999999999743, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 162.20000000000002, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -21.999999999999844, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 26.0, 20.000000000000014, 20.000000000000014, -27.699999999999818, 200.0, -15.699999999999761, 17.899999999999984, 173.0, 164.0, 9.49999999999997, 179.0, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 200.0, 162.8, -57.70000000000034, 182.0, 20.000000000000014, 20.000000000000014, -391.0, 20.000000000000014, 20.000000000000014, 21.500000000000043, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -17.79999999999974, 20.000000000000014, -379.0, 20.000000000000014, 17.899999999999988, 21.80000000000004, 188.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 183.8, -82.90000000000084, 20.000000000000014, 186.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 127.99999999999999, -32.49999999999975, -32.49999999999975, 200.0, 20.000000000000014, 20.000000000000014, 158.6, 20.000000000000014, -208.0, 20.000000000000014, 15.799999999999963, -36.69999999999983, -51.40000000000002, 12.199999999999967, -358.0, -113.5000000000004, -175.3000000000004, 7.399999999999965, 20.000000000000014, -1.0, 20.000000000000014, 20.000000000000014, 124.39999999999998], "policy_predator_policy_reward": [14.0, 101.0, 0.0, 0.0, 68.0, 68.0, 0.0, 0.0, 0.0, 0.0, 102.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 193.0, 58.0, 0.0, 0.0, 0.0, 150.0, 187.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 10.0, 4.0, 0.0, 3.0, 96.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 190.0, 195.0, 0.0, 0.0, 3.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 14.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 191.0, 19.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 183.0, 2.0, 39.0, 47.0, 19.0, 6.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 24.0, 15.0, 12.0, 9.0, 1.0, 12.0, 5.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 37.0, 1.0, 0.0, 6.0, 154.0, 191.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 18.0, 3.0, 170.0, 186.0, 0.0, 1.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 41.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 12.0, 0.0, 135.0, 4.0, 0.0, 2.0, 0.0, 61.0, 5.0, 186.0, 5.0, 88.0, 0.0, 6.0, 39.0, 30.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8303488129616771, "mean_inference_ms": 2.3984386930460557, "mean_action_processing_ms": 0.37125926633926426, "mean_env_wait_ms": 0.3019259255200395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01708376407623291, "StateBufferConnector_ms": 0.006010890007019043, "ViewRequirementAgentConnector_ms": 0.1392453908920288}, "num_episodes": 23, "episode_return_max": 386.0, "episode_return_min": -257.0, "episode_return_mean": 81.59999999999985, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.16374114476673, "num_env_steps_trained_throughput_per_sec": 318.16374114476673, "timesteps_total": 656000, "num_env_steps_sampled_lifetime": 656000, "num_agent_steps_sampled_lifetime": 2624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2624000, "timers": {"training_iteration_time_ms": 12586.595, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12586.517, "sample_time_ms": 1745.131, "learn_time_ms": 10819.214, "learn_throughput": 369.713, "synch_weights_time_ms": 18.759}, "counters": {"num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "done": false, "training_iteration": 164, "trial_id": "04dec_00002", "date": "2024-08-13_16-59-22", "timestamp": 1723582762, "time_this_iter_s": 12.612069129943848, "time_total_s": 2189.3307514190674, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0720f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2189.3307514190674, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 64.94444444444444, "ram_util_percent": 83.24444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1109587827017382, "cur_kl_coeff": 9.64823466481851e-22, "cur_lr": 0.00010000000000000003, "total_loss": 0.302056991734675, "policy_loss": -0.0039727784535556875, "vf_loss": 0.3060297700699675, "vf_explained_var": -8.713385415455651e-05, "kl": 0.005840398153981491, "entropy": 0.08220759010504163, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 310905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.878566218904718, "cur_kl_coeff": 0.000857194032816071, "cur_lr": 0.00010000000000000003, "total_loss": 2.042128245761155, "policy_loss": -0.0006974163000772475, "vf_loss": 2.0428079285949625, "vf_explained_var": 0.5744294812754979, "kl": 0.020685757616250328, "entropy": 0.5349066613212464, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 310905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "env_runners": {"episode_reward_max": 386.0, "episode_reward_min": -257.0, "episode_reward_mean": 97.69199999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 34.300999999999995, "predator_policy": 14.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.90000000000031, 20.000000000000014, 219.99999999999926, 30.000000000000146, 40.0000000000003, 218.89999999999927, 219.99999999999926, 203.99999999999935, 40.0000000000003, 40.0000000000003, 109.99999999999929, 166.8999999999995, 219.99999999999926, 196.19999999999936, -257.0, 196.09999999999937, 34.50000000000022, 49.00000000000043, -148.20000000000047, 25.200000000000074, 8.30000000000013, 185.99999999999943, 40.0000000000003, 40.0000000000003, 40.0000000000003, 216.39999999999927, 40.0000000000003, 371.2, 40.0000000000003, 40.0000000000003, 219.99999999999926, 17.999999999999954, 213.9999999999993, 37.80000000000027, 40.0000000000003, 143.9999999999997, 16.299999999999926, 211.2999999999993, 200.89999999999935, 190.4999999999994, 386.0, 34.50000000000022, 219.99999999999926, 40.0000000000003, 211.1999999999993, 143.09999999999968, 207.99999999999932, -25.999999999999822, 40.0000000000003, 44.40000000000036, 40.0000000000003, 29.500000000000142, -3.000000000000032, 38.90000000000028, 213.79999999999927, 205.99999999999932, 40.0000000000003, 182.89999999999944, 206.49999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 37.80000000000027, 219.99999999999926, 207.99999999999932, 147.9999999999996, -40.000000000000284, 219.99999999999926, 190.5999999999994, -48.999999999999936, 37.80000000000027, -27.09999999999956, -154.8000000000005, -195.80000000000078, 33.400000000000205, 87.99999999999946, 144.3999999999996, 96.69999999999862, 40.0000000000003, 40.0000000000003, 203.69999999999928, 219.99999999999926, 40.0000000000003, 357.5, 23.500000000000032, 19.99999999999997, 40.0000000000003, 40.0000000000003, 40.0000000000003, 187.99999999999943, 197.49999999999937, 40.0000000000003, 208.2999999999993, 199.99999999999935, 21.299999999999994, 33.400000000000205, 40.0000000000003, 40.0000000000003, 200.99999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.900000000000027, 20.000000000000014, -385.0, 200.0, 20.000000000000014, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 17.899999999999984, 200.0, 200.0, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.0, 146.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 174.2, 20.000000000000014, -94.0, -373.0, 179.6, 9.499999999999966, 9.499999999999973, 20.000000000000014, 20.000000000000014, 29.000000000000174, 15.799999999999962, -349.0, 20.000000000000014, -80.80000000000084, 3.1999999999999615, -19.899999999999743, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 162.20000000000002, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -21.999999999999844, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 26.0, 20.000000000000014, 20.000000000000014, -27.699999999999818, 200.0, -15.699999999999761, 17.899999999999984, 173.0, 164.0, 9.49999999999997, 179.0, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 200.0, 162.8, -57.70000000000034, 182.0, 20.000000000000014, 20.000000000000014, -391.0, 20.000000000000014, 20.000000000000014, 21.500000000000043, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -17.79999999999974, 20.000000000000014, -379.0, 20.000000000000014, 17.899999999999988, 21.80000000000004, 188.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 183.8, -82.90000000000084, 20.000000000000014, 186.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 127.99999999999999, -32.49999999999975, -32.49999999999975, 200.0, 20.000000000000014, 20.000000000000014, 158.6, 20.000000000000014, -208.0, 20.000000000000014, 15.799999999999963, -36.69999999999983, -51.40000000000002, 12.199999999999967, -358.0, -113.5000000000004, -175.3000000000004, 7.399999999999965, 20.000000000000014, -1.0, 20.000000000000014, 20.000000000000014, 124.39999999999998, 76.6999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -91.30000000000072, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.6, 176.9, -11.499999999999826, 20.000000000000014, 20.000000000000014, -18.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 177.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 188.3, 20.000000000000014, 170.0, 20.000000000000014, -13.59999999999979, 17.899999999999988, 13.699999999999966, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0], "policy_predator_policy_reward": [0.0, 0.0, 190.0, 195.0, 0.0, 0.0, 3.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 14.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 191.0, 19.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 183.0, 2.0, 39.0, 47.0, 19.0, 6.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 24.0, 15.0, 12.0, 9.0, 1.0, 12.0, 5.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 37.0, 1.0, 0.0, 6.0, 154.0, 191.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 18.0, 3.0, 170.0, 186.0, 0.0, 1.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 41.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 12.0, 0.0, 135.0, 4.0, 0.0, 2.0, 0.0, 61.0, 5.0, 186.0, 5.0, 88.0, 0.0, 6.0, 39.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 15.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 17.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8296027273720596, "mean_inference_ms": 2.3985517077100083, "mean_action_processing_ms": 0.3704949898603701, "mean_env_wait_ms": 0.30175965644565855, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005489945411682129, "StateBufferConnector_ms": 0.005900144577026367, "ViewRequirementAgentConnector_ms": 0.13900601863861084}, "num_episodes": 22, "episode_return_max": 386.0, "episode_return_min": -257.0, "episode_return_mean": 97.69199999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.20080526719505, "num_env_steps_trained_throughput_per_sec": 332.20080526719505, "timesteps_total": 660000, "num_env_steps_sampled_lifetime": 660000, "num_agent_steps_sampled_lifetime": 2640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2640000, "timers": {"training_iteration_time_ms": 12562.681, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12562.602, "sample_time_ms": 1756.78, "learn_time_ms": 10784.946, "learn_throughput": 370.887, "synch_weights_time_ms": 17.598}, "counters": {"num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "done": false, "training_iteration": 165, "trial_id": "04dec_00002", "date": "2024-08-13_16-59-34", "timestamp": 1723582774, "time_this_iter_s": 12.086682081222534, "time_total_s": 2201.41743350029, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0720ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2201.41743350029, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 64.84705882352941, "ram_util_percent": 83.28235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6718150523407435, "cur_kl_coeff": 9.64823466481851e-22, "cur_lr": 0.00010000000000000003, "total_loss": 0.7777579419669651, "policy_loss": -0.0019658626251849074, "vf_loss": 0.7797238045741641, "vf_explained_var": 1.939721208400827e-05, "kl": 0.02373083826930101, "entropy": 0.20911978495420602, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 312795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.5275659910112465, "cur_kl_coeff": 0.0012857910492241058, "cur_lr": 0.00010000000000000003, "total_loss": 3.3628060855562727, "policy_loss": 0.001124988079795407, "vf_loss": 3.3616703735457527, "vf_explained_var": 0.3212954423099599, "kl": 0.008343484350308442, "entropy": 0.4484244988235847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 312795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "env_runners": {"episode_reward_max": 386.0, "episode_reward_min": -195.80000000000078, "episode_reward_mean": 101.77799999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 36.76399999999999, "predator_policy": 14.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-148.20000000000047, 25.200000000000074, 8.30000000000013, 185.99999999999943, 40.0000000000003, 40.0000000000003, 40.0000000000003, 216.39999999999927, 40.0000000000003, 371.2, 40.0000000000003, 40.0000000000003, 219.99999999999926, 17.999999999999954, 213.9999999999993, 37.80000000000027, 40.0000000000003, 143.9999999999997, 16.299999999999926, 211.2999999999993, 200.89999999999935, 190.4999999999994, 386.0, 34.50000000000022, 219.99999999999926, 40.0000000000003, 211.1999999999993, 143.09999999999968, 207.99999999999932, -25.999999999999822, 40.0000000000003, 44.40000000000036, 40.0000000000003, 29.500000000000142, -3.000000000000032, 38.90000000000028, 213.79999999999927, 205.99999999999932, 40.0000000000003, 182.89999999999944, 206.49999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 37.80000000000027, 219.99999999999926, 207.99999999999932, 147.9999999999996, -40.000000000000284, 219.99999999999926, 190.5999999999994, -48.999999999999936, 37.80000000000027, -27.09999999999956, -154.8000000000005, -195.80000000000078, 33.400000000000205, 87.99999999999946, 144.3999999999996, 96.69999999999862, 40.0000000000003, 40.0000000000003, 203.69999999999928, 219.99999999999926, 40.0000000000003, 357.5, 23.500000000000032, 19.99999999999997, 40.0000000000003, 40.0000000000003, 40.0000000000003, 187.99999999999943, 197.49999999999937, 40.0000000000003, 208.2999999999993, 199.99999999999935, 21.299999999999994, 33.400000000000205, 40.0000000000003, 40.0000000000003, 200.99999999999935, 200.19999999999936, 40.0000000000003, 342.7, 40.0000000000003, 213.9999999999993, 40.0000000000003, 40.0000000000003, 40.0000000000003, 183.8999999999994, 172.0, 15.29999999999995, 31.200000000000166, 198.39999999999935, -16.199999999999534, 207.99999999999932, 209.99999999999932, 199.69999999999936, 38.90000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999962, -349.0, 20.000000000000014, -80.80000000000084, 3.1999999999999615, -19.899999999999743, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 162.20000000000002, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -21.999999999999844, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 26.0, 20.000000000000014, 20.000000000000014, -27.699999999999818, 200.0, -15.699999999999761, 17.899999999999984, 173.0, 164.0, 9.49999999999997, 179.0, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 200.0, 162.8, -57.70000000000034, 182.0, 20.000000000000014, 20.000000000000014, -391.0, 20.000000000000014, 20.000000000000014, 21.500000000000043, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -17.79999999999974, 20.000000000000014, -379.0, 20.000000000000014, 17.899999999999988, 21.80000000000004, 188.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 183.8, -82.90000000000084, 20.000000000000014, 186.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 127.99999999999999, -32.49999999999975, -32.49999999999975, 200.0, 20.000000000000014, 20.000000000000014, 158.6, 20.000000000000014, -208.0, 20.000000000000014, 15.799999999999963, -36.69999999999983, -51.40000000000002, 12.199999999999967, -358.0, -113.5000000000004, -175.3000000000004, 7.399999999999965, 20.000000000000014, -1.0, 20.000000000000014, 20.000000000000014, 124.39999999999998, 76.6999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -91.30000000000072, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.6, 176.9, -11.499999999999826, 20.000000000000014, 20.000000000000014, -18.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 177.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 188.3, 20.000000000000014, 170.0, 20.000000000000014, -13.59999999999979, 17.899999999999988, 13.699999999999966, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 173.0, 166.7, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.9, -400.0, 191.0, 5.2999999999999705, -127.00000000000074, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 178.4, 20.000000000000014, -89.20000000000084, 20.000000000000014, 182.0, 20.000000000000014, 185.0, 20.000000000000014, 172.7, 20.000000000000014, 17.899999999999988], "policy_predator_policy_reward": [183.0, 2.0, 39.0, 47.0, 19.0, 6.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 24.0, 15.0, 12.0, 9.0, 1.0, 12.0, 5.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 37.0, 1.0, 0.0, 6.0, 154.0, 191.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 18.0, 3.0, 170.0, 186.0, 0.0, 1.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 41.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 12.0, 0.0, 135.0, 4.0, 0.0, 2.0, 0.0, 61.0, 5.0, 186.0, 5.0, 88.0, 0.0, 6.0, 39.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 15.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 17.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 200.0, 181.0, 70.0, 67.0, 0.0, 8.0, 0.0, 0.0, 52.0, 1.0, 0.0, 6.0, 5.0, 0.0, 5.0, 2.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8293056076748578, "mean_inference_ms": 2.3982707167147184, "mean_action_processing_ms": 0.3701281089335899, "mean_env_wait_ms": 0.30155287524256374, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004741787910461426, "StateBufferConnector_ms": 0.005959868431091309, "ViewRequirementAgentConnector_ms": 0.1192617416381836}, "num_episodes": 18, "episode_return_max": 386.0, "episode_return_min": -195.80000000000078, "episode_return_mean": 101.77799999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.33894482945396, "num_env_steps_trained_throughput_per_sec": 325.33894482945396, "timesteps_total": 664000, "num_env_steps_sampled_lifetime": 664000, "num_agent_steps_sampled_lifetime": 2656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2656000, "timers": {"training_iteration_time_ms": 12568.354, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12568.276, "sample_time_ms": 1767.569, "learn_time_ms": 10776.469, "learn_throughput": 371.179, "synch_weights_time_ms": 20.833}, "counters": {"num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "done": false, "training_iteration": 166, "trial_id": "04dec_00002", "date": "2024-08-13_16-59-46", "timestamp": 1723582786, "time_this_iter_s": 12.347616910934448, "time_total_s": 2213.7650504112244, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04cc430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2213.7650504112244, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 63.51764705882353, "ram_util_percent": 83.46470588235293}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9006833980973593, "cur_kl_coeff": 1.4472351997227768e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.7469212340930151, "policy_loss": -6.101486992544283e-05, "vf_loss": 1.7469822496018081, "vf_explained_var": 0.0010215356236412411, "kl": 0.002977056120379477, "entropy": 0.09720844991465726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 314685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.039824875921169, "cur_kl_coeff": 0.0012857910492241058, "cur_lr": 0.00010000000000000003, "total_loss": 5.058672678029096, "policy_loss": 0.000258911329459537, "vf_loss": 5.058393721479588, "vf_explained_var": 0.2488527183810239, "kl": 0.015586944403502952, "entropy": 0.3472775095511997, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 314685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "env_runners": {"episode_reward_max": 387.4, "episode_reward_min": -195.80000000000078, "episode_reward_mean": 120.88499999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 44.23249999999998, "predator_policy": 16.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.299999999999926, 211.2999999999993, 200.89999999999935, 190.4999999999994, 386.0, 34.50000000000022, 219.99999999999926, 40.0000000000003, 211.1999999999993, 143.09999999999968, 207.99999999999932, -25.999999999999822, 40.0000000000003, 44.40000000000036, 40.0000000000003, 29.500000000000142, -3.000000000000032, 38.90000000000028, 213.79999999999927, 205.99999999999932, 40.0000000000003, 182.89999999999944, 206.49999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 37.80000000000027, 219.99999999999926, 207.99999999999932, 147.9999999999996, -40.000000000000284, 219.99999999999926, 190.5999999999994, -48.999999999999936, 37.80000000000027, -27.09999999999956, -154.8000000000005, -195.80000000000078, 33.400000000000205, 87.99999999999946, 144.3999999999996, 96.69999999999862, 40.0000000000003, 40.0000000000003, 203.69999999999928, 219.99999999999926, 40.0000000000003, 357.5, 23.500000000000032, 19.99999999999997, 40.0000000000003, 40.0000000000003, 40.0000000000003, 187.99999999999943, 197.49999999999937, 40.0000000000003, 208.2999999999993, 199.99999999999935, 21.299999999999994, 33.400000000000205, 40.0000000000003, 40.0000000000003, 200.99999999999935, 200.19999999999936, 40.0000000000003, 342.7, 40.0000000000003, 213.9999999999993, 40.0000000000003, 40.0000000000003, 40.0000000000003, 183.8999999999994, 172.0, 15.29999999999995, 31.200000000000166, 198.39999999999935, -16.199999999999534, 207.99999999999932, 209.99999999999932, 199.69999999999936, 38.90000000000028, 219.99999999999926, 193.99999999999937, 214.9999999999993, 205.99999999999932, 40.0000000000003, 364.2, 376.0, 201.0, 40.0000000000003, 180.39999999999947, -44.00000000000052, 209.9999999999993, 213.9999999999993, 387.4, 352.4, 40.0000000000003, 206.99999999999932, 80.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -27.699999999999818, 200.0, -15.699999999999761, 17.899999999999984, 173.0, 164.0, 9.49999999999997, 179.0, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 200.0, 162.8, -57.70000000000034, 182.0, 20.000000000000014, 20.000000000000014, -391.0, 20.000000000000014, 20.000000000000014, 21.500000000000043, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -17.79999999999974, 20.000000000000014, -379.0, 20.000000000000014, 17.899999999999988, 21.80000000000004, 188.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 183.8, -82.90000000000084, 20.000000000000014, 186.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 127.99999999999999, -32.49999999999975, -32.49999999999975, 200.0, 20.000000000000014, 20.000000000000014, 158.6, 20.000000000000014, -208.0, 20.000000000000014, 15.799999999999963, -36.69999999999983, -51.40000000000002, 12.199999999999967, -358.0, -113.5000000000004, -175.3000000000004, 7.399999999999965, 20.000000000000014, -1.0, 20.000000000000014, 20.000000000000014, 124.39999999999998, 76.6999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -91.30000000000072, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.6, 176.9, -11.499999999999826, 20.000000000000014, 20.000000000000014, -18.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 177.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 188.3, 20.000000000000014, 170.0, 20.000000000000014, -13.59999999999979, 17.899999999999988, 13.699999999999966, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 173.0, 166.7, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.9, -400.0, 191.0, 5.2999999999999705, -127.00000000000074, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 178.4, 20.000000000000014, -89.20000000000084, 20.000000000000014, 182.0, 20.000000000000014, 185.0, 20.000000000000014, 172.7, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 20.000000000000014, 188.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 171.2, 188.0, 182.0, -379.0, 197.0, 20.000000000000014, 20.000000000000014, 200.0, -55.60000000000028, -196.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 191.0, 187.4, 200.0, 167.0, 169.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -139.0, -0.9999999999999846], "policy_predator_policy_reward": [0.0, 24.0, 15.0, 12.0, 9.0, 1.0, 12.0, 5.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 37.0, 1.0, 0.0, 6.0, 154.0, 191.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 18.0, 3.0, 170.0, 186.0, 0.0, 1.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 41.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 12.0, 0.0, 135.0, 4.0, 0.0, 2.0, 0.0, 61.0, 5.0, 186.0, 5.0, 88.0, 0.0, 6.0, 39.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 15.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 17.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 200.0, 181.0, 70.0, 67.0, 0.0, 8.0, 0.0, 0.0, 52.0, 1.0, 0.0, 6.0, 5.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 0.0, 11.0, 2.0, 3.0, 4.0, 0.0, 7.0, 0.0, 0.0, 17.0, 0.0, 0.0, 6.0, 193.0, 190.0, 0.0, 0.0, 36.0, 0.0, 0.0, 132.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 10.0, 102.0, 118.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8294957990384152, "mean_inference_ms": 2.399045973081806, "mean_action_processing_ms": 0.3698552361640167, "mean_env_wait_ms": 0.30144384968490257, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004519104957580566, "StateBufferConnector_ms": 0.006039261817932129, "ViewRequirementAgentConnector_ms": 0.13548898696899414}, "num_episodes": 18, "episode_return_max": 387.4, "episode_return_min": -195.80000000000078, "episode_return_mean": 120.88499999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.0762029969274, "num_env_steps_trained_throughput_per_sec": 324.0762029969274, "timesteps_total": 668000, "num_env_steps_sampled_lifetime": 668000, "num_agent_steps_sampled_lifetime": 2672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2672000, "timers": {"training_iteration_time_ms": 12484.315, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12484.23, "sample_time_ms": 1846.885, "learn_time_ms": 10612.469, "learn_throughput": 376.915, "synch_weights_time_ms": 21.804}, "counters": {"num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "done": false, "training_iteration": 167, "trial_id": "04dec_00002", "date": "2024-08-13_16-59-59", "timestamp": 1723582799, "time_this_iter_s": 12.447067975997925, "time_total_s": 2226.2121183872223, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06fc670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2226.2121183872223, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 62.72222222222222, "ram_util_percent": 83.63333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8478909377698545, "cur_kl_coeff": 7.236175998613884e-22, "cur_lr": 0.00010000000000000003, "total_loss": 1.3972286646959011, "policy_loss": -0.00041392343734740895, "vf_loss": 1.3976425922421551, "vf_explained_var": 0.0002173852352868943, "kl": 0.004948933037615044, "entropy": 0.10358489215886467, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 316575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.414190803318427, "cur_kl_coeff": 0.0012857910492241058, "cur_lr": 0.00010000000000000003, "total_loss": 3.353088676487958, "policy_loss": -0.006808052579354909, "vf_loss": 3.359849724820051, "vf_explained_var": 0.4137584237825303, "kl": 0.036555388197168005, "entropy": 0.44095067722456793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 316575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "env_runners": {"episode_reward_max": 387.4, "episode_reward_min": -195.80000000000078, "episode_reward_mean": 118.07999999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 42.96499999999998, "predator_policy": 16.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [213.79999999999927, 205.99999999999932, 40.0000000000003, 182.89999999999944, 206.49999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 37.80000000000027, 219.99999999999926, 207.99999999999932, 147.9999999999996, -40.000000000000284, 219.99999999999926, 190.5999999999994, -48.999999999999936, 37.80000000000027, -27.09999999999956, -154.8000000000005, -195.80000000000078, 33.400000000000205, 87.99999999999946, 144.3999999999996, 96.69999999999862, 40.0000000000003, 40.0000000000003, 203.69999999999928, 219.99999999999926, 40.0000000000003, 357.5, 23.500000000000032, 19.99999999999997, 40.0000000000003, 40.0000000000003, 40.0000000000003, 187.99999999999943, 197.49999999999937, 40.0000000000003, 208.2999999999993, 199.99999999999935, 21.299999999999994, 33.400000000000205, 40.0000000000003, 40.0000000000003, 200.99999999999935, 200.19999999999936, 40.0000000000003, 342.7, 40.0000000000003, 213.9999999999993, 40.0000000000003, 40.0000000000003, 40.0000000000003, 183.8999999999994, 172.0, 15.29999999999995, 31.200000000000166, 198.39999999999935, -16.199999999999534, 207.99999999999932, 209.99999999999932, 199.69999999999936, 38.90000000000028, 219.99999999999926, 193.99999999999937, 214.9999999999993, 205.99999999999932, 40.0000000000003, 364.2, 376.0, 201.0, 40.0000000000003, 180.39999999999947, -44.00000000000052, 209.9999999999993, 213.9999999999993, 387.4, 352.4, 40.0000000000003, 206.99999999999932, 80.0, 219.99999999999926, 106.99999999999986, 115.99999999999962, 23.70000000000003, 29.000000000000128, -6.1999999999996955, 201.99999999999935, 38.90000000000028, 203.99999999999935, 210.8999999999993, 204.99999999999935, 40.0000000000003, 19.000000000000004, 27.10000000000009, 40.0000000000003, 24.600000000000062, 204.09999999999934, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [21.80000000000004, 188.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 183.8, -82.90000000000084, 20.000000000000014, 186.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 127.99999999999999, -32.49999999999975, -32.49999999999975, 200.0, 20.000000000000014, 20.000000000000014, 158.6, 20.000000000000014, -208.0, 20.000000000000014, 15.799999999999963, -36.69999999999983, -51.40000000000002, 12.199999999999967, -358.0, -113.5000000000004, -175.3000000000004, 7.399999999999965, 20.000000000000014, -1.0, 20.000000000000014, 20.000000000000014, 124.39999999999998, 76.6999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -91.30000000000072, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.6, 176.9, -11.499999999999826, 20.000000000000014, 20.000000000000014, -18.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 177.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 188.3, 20.000000000000014, 170.0, 20.000000000000014, -13.59999999999979, 17.899999999999988, 13.699999999999966, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 173.0, 166.7, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.9, -400.0, 191.0, 5.2999999999999705, -127.00000000000074, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 178.4, 20.000000000000014, -89.20000000000084, 20.000000000000014, 182.0, 20.000000000000014, 185.0, 20.000000000000014, 172.7, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 20.000000000000014, 188.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 171.2, 188.0, 182.0, -379.0, 197.0, 20.000000000000014, 20.000000000000014, 200.0, -55.60000000000028, -196.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 191.0, 187.4, 200.0, 167.0, 169.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -139.0, -0.9999999999999846, 20.000000000000014, 200.0, -211.00000000000037, 200.0, 20.000000000000014, -82.0, -3.099999999999958, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -68.2000000000009, 164.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 173.0, 20.000000000000014, 9.499999999999964, 196.4, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.0, 7.399999999999965, 13.699999999999964, 20.000000000000014, 20.000000000000014, -9.399999999999872, 20.000000000000014, 191.0, 1.0999999999999865, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 41.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 12.0, 0.0, 135.0, 4.0, 0.0, 2.0, 0.0, 61.0, 5.0, 186.0, 5.0, 88.0, 0.0, 6.0, 39.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 15.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 17.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 200.0, 181.0, 70.0, 67.0, 0.0, 8.0, 0.0, 0.0, 52.0, 1.0, 0.0, 6.0, 5.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 0.0, 11.0, 2.0, 3.0, 4.0, 0.0, 7.0, 0.0, 0.0, 17.0, 0.0, 0.0, 6.0, 193.0, 190.0, 0.0, 0.0, 36.0, 0.0, 0.0, 132.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 10.0, 102.0, 118.0, 0.0, 0.0, 110.0, 8.0, 94.0, 84.0, 11.0, 0.0, 10.0, 0.0, 0.0, 42.0, 8.0, 10.0, 0.0, 1.0, 5.0, 6.0, 0.0, 5.0, 11.0, 13.0, 0.0, 0.0, 197.0, 193.0, 6.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8305264469570747, "mean_inference_ms": 2.402004267989306, "mean_action_processing_ms": 0.36982988542723616, "mean_env_wait_ms": 0.3015686710576339, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00444793701171875, "StateBufferConnector_ms": 0.006042957305908203, "ViewRequirementAgentConnector_ms": 0.1398228406906128}, "num_episodes": 18, "episode_return_max": 387.4, "episode_return_min": -195.80000000000078, "episode_return_mean": 118.07999999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.5068517557926, "num_env_steps_trained_throughput_per_sec": 294.5068517557926, "timesteps_total": 672000, "num_env_steps_sampled_lifetime": 672000, "num_agent_steps_sampled_lifetime": 2688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2688000, "timers": {"training_iteration_time_ms": 12523.953, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12523.866, "sample_time_ms": 1996.073, "learn_time_ms": 10504.205, "learn_throughput": 380.8, "synch_weights_time_ms": 20.413}, "counters": {"num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "done": false, "training_iteration": 168, "trial_id": "04dec_00002", "date": "2024-08-13_17-00-13", "timestamp": 1723582813, "time_this_iter_s": 13.714335203170776, "time_total_s": 2239.926453590393, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b08159d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2239.926453590393, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 64.14736842105263, "ram_util_percent": 83.61052631578949}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2612461450593497, "cur_kl_coeff": 3.618087999306942e-22, "cur_lr": 0.00010000000000000003, "total_loss": 0.5276039206477069, "policy_loss": -0.0002751575563615434, "vf_loss": 0.5278790809044112, "vf_explained_var": 0.005114600519654612, "kl": 0.020489473228721418, "entropy": 0.17834931172864146, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 318465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.629729548017815, "cur_kl_coeff": 0.001928686573836159, "cur_lr": 0.00010000000000000003, "total_loss": 3.7436419555119107, "policy_loss": -0.0009961131352822852, "vf_loss": 3.744588780781579, "vf_explained_var": 0.7255016642588156, "kl": 0.025555754385669045, "entropy": 0.47869556322299617, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 318465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "env_runners": {"episode_reward_max": 390.0, "episode_reward_min": -44.00000000000052, "episode_reward_mean": 138.05799999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 53.38399999999998, "predator_policy": 15.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [203.69999999999928, 219.99999999999926, 40.0000000000003, 357.5, 23.500000000000032, 19.99999999999997, 40.0000000000003, 40.0000000000003, 40.0000000000003, 187.99999999999943, 197.49999999999937, 40.0000000000003, 208.2999999999993, 199.99999999999935, 21.299999999999994, 33.400000000000205, 40.0000000000003, 40.0000000000003, 200.99999999999935, 200.19999999999936, 40.0000000000003, 342.7, 40.0000000000003, 213.9999999999993, 40.0000000000003, 40.0000000000003, 40.0000000000003, 183.8999999999994, 172.0, 15.29999999999995, 31.200000000000166, 198.39999999999935, -16.199999999999534, 207.99999999999932, 209.99999999999932, 199.69999999999936, 38.90000000000028, 219.99999999999926, 193.99999999999937, 214.9999999999993, 205.99999999999932, 40.0000000000003, 364.2, 376.0, 201.0, 40.0000000000003, 180.39999999999947, -44.00000000000052, 209.9999999999993, 213.9999999999993, 387.4, 352.4, 40.0000000000003, 206.99999999999932, 80.0, 219.99999999999926, 106.99999999999986, 115.99999999999962, 23.70000000000003, 29.000000000000128, -6.1999999999996955, 201.99999999999935, 38.90000000000028, 203.99999999999935, 210.8999999999993, 204.99999999999935, 40.0000000000003, 19.000000000000004, 27.10000000000009, 40.0000000000003, 24.600000000000062, 204.09999999999934, 40.0000000000003, 195.99999999999937, 40.0000000000003, 23.50000000000004, 40.0000000000003, 209.7999999999993, 390.0, 381.0, -8.29999999999971, 34.50000000000022, 246.09999999999943, 197.49999999999937, 38.90000000000028, 79.1, 149.99999999999963, 203.79999999999933, 195.99999999999937, 193.89999999999938, 213.9999999999993, 195.2999999999994, 98.99999999999997, 370.3, 40.0000000000003, 40.0000000000003, 200.29999999999936, 219.99999999999926, 212.9999999999993, 21.299999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -91.30000000000072, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.6, 176.9, -11.499999999999826, 20.000000000000014, 20.000000000000014, -18.999999999999744, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 177.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 188.3, 20.000000000000014, 170.0, 20.000000000000014, -13.59999999999979, 17.899999999999988, 13.699999999999966, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 173.0, 166.7, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.9, -400.0, 191.0, 5.2999999999999705, -127.00000000000074, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 178.4, 20.000000000000014, -89.20000000000084, 20.000000000000014, 182.0, 20.000000000000014, 185.0, 20.000000000000014, 172.7, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 20.000000000000014, 188.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 171.2, 188.0, 182.0, -379.0, 197.0, 20.000000000000014, 20.000000000000014, 200.0, -55.60000000000028, -196.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 191.0, 187.4, 200.0, 167.0, 169.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -139.0, -0.9999999999999846, 20.000000000000014, 200.0, -211.00000000000037, 200.0, 20.000000000000014, -82.0, -3.099999999999958, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -68.2000000000009, 164.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 173.0, 20.000000000000014, 9.499999999999964, 196.4, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.0, 7.399999999999965, 13.699999999999964, 20.000000000000014, 20.000000000000014, -9.399999999999872, 20.000000000000014, 191.0, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999837, 20.000000000000014, 20.000000000000014, 15.799999999999963, 188.0, 185.0, 200.0, 200.0, 161.0, -129.10000000000068, 15.799999999999962, 20.000000000000014, 9.499999999999964, 46.09999999999997, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 17.899999999999988, 181.1, -400.0, 11.599999999999964, 130.39999999999998, 183.8, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 173.9, 20.000000000000014, 191.0, 20.000000000000014, 164.3, 5.0, 20.000000000000014, 188.3, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.3, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, -15.699999999999754], "policy_predator_policy_reward": [48.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 15.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 17.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 200.0, 181.0, 70.0, 67.0, 0.0, 8.0, 0.0, 0.0, 52.0, 1.0, 0.0, 6.0, 5.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 0.0, 11.0, 2.0, 3.0, 4.0, 0.0, 7.0, 0.0, 0.0, 17.0, 0.0, 0.0, 6.0, 193.0, 190.0, 0.0, 0.0, 36.0, 0.0, 0.0, 132.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 10.0, 102.0, 118.0, 0.0, 0.0, 110.0, 8.0, 94.0, 84.0, 11.0, 0.0, 10.0, 0.0, 0.0, 42.0, 8.0, 10.0, 0.0, 1.0, 5.0, 6.0, 0.0, 5.0, 11.0, 13.0, 0.0, 0.0, 197.0, 193.0, 6.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 6.0, 0.0, 0.0, 5.0, 10.0, 10.0, 62.0, 43.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 200.0, 98.0, 8.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 65.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8333983398760454, "mean_inference_ms": 2.4080687410545063, "mean_action_processing_ms": 0.3705280419028997, "mean_env_wait_ms": 0.3022679421686368, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006889224052429199, "StateBufferConnector_ms": 0.004405498504638672, "ViewRequirementAgentConnector_ms": 0.18689239025115967}, "num_episodes": 27, "episode_return_max": 390.0, "episode_return_min": -44.00000000000052, "episode_return_mean": 138.05799999999982, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 286.0937919571897, "num_env_steps_trained_throughput_per_sec": 286.0937919571897, "timesteps_total": 676000, "num_env_steps_sampled_lifetime": 676000, "num_agent_steps_sampled_lifetime": 2704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2704000, "timers": {"training_iteration_time_ms": 12657.616, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12657.528, "sample_time_ms": 2165.201, "learn_time_ms": 10467.906, "learn_throughput": 382.12, "synch_weights_time_ms": 20.965}, "counters": {"num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "done": false, "training_iteration": 169, "trial_id": "04dec_00002", "date": "2024-08-13_17-00-27", "timestamp": 1723582827, "time_this_iter_s": 14.057731628417969, "time_total_s": 2253.984185218811, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0815c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2253.984185218811, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 65.94500000000001, "ram_util_percent": 83.49499999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9604147009512105, "cur_kl_coeff": 5.427131998960416e-22, "cur_lr": 0.00010000000000000003, "total_loss": 0.3855740456196366, "policy_loss": -0.0018153608485898644, "vf_loss": 0.3873894057502858, "vf_explained_var": -0.00027243643210678506, "kl": 0.06429651907887216, "entropy": 0.390051507610808, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 320355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.450427444492068, "cur_kl_coeff": 0.002893029860754238, "cur_lr": 0.00010000000000000003, "total_loss": 3.5659543853588205, "policy_loss": -0.003546795574578619, "vf_loss": 3.5694044095498545, "vf_explained_var": 0.6428930556332624, "kl": 0.03344859741134099, "entropy": 0.4855503445737576, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 320355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "env_runners": {"episode_reward_max": 390.0, "episode_reward_min": -165.70000000000073, "episode_reward_mean": 141.5109999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 54.79549999999999, "predator_policy": 15.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [200.99999999999935, 200.19999999999936, 40.0000000000003, 342.7, 40.0000000000003, 213.9999999999993, 40.0000000000003, 40.0000000000003, 40.0000000000003, 183.8999999999994, 172.0, 15.29999999999995, 31.200000000000166, 198.39999999999935, -16.199999999999534, 207.99999999999932, 209.99999999999932, 199.69999999999936, 38.90000000000028, 219.99999999999926, 193.99999999999937, 214.9999999999993, 205.99999999999932, 40.0000000000003, 364.2, 376.0, 201.0, 40.0000000000003, 180.39999999999947, -44.00000000000052, 209.9999999999993, 213.9999999999993, 387.4, 352.4, 40.0000000000003, 206.99999999999932, 80.0, 219.99999999999926, 106.99999999999986, 115.99999999999962, 23.70000000000003, 29.000000000000128, -6.1999999999996955, 201.99999999999935, 38.90000000000028, 203.99999999999935, 210.8999999999993, 204.99999999999935, 40.0000000000003, 19.000000000000004, 27.10000000000009, 40.0000000000003, 24.600000000000062, 204.09999999999934, 40.0000000000003, 195.99999999999937, 40.0000000000003, 23.50000000000004, 40.0000000000003, 209.7999999999993, 390.0, 381.0, -8.29999999999971, 34.50000000000022, 246.09999999999943, 197.49999999999937, 38.90000000000028, 79.1, 149.99999999999963, 203.79999999999933, 195.99999999999937, 193.89999999999938, 213.9999999999993, 195.2999999999994, 98.99999999999997, 370.3, 40.0000000000003, 40.0000000000003, 200.29999999999936, 219.99999999999926, 212.9999999999993, 21.299999999999997, 40.0000000000003, 40.90000000000031, 219.99999999999926, 349.4, 199.99999999999935, 196.29999999999936, 40.0000000000003, 219.99999999999926, 201.99999999999935, 40.0000000000003, -165.70000000000073, 182.89999999999944, 34.50000000000022, 27.90000000000011, 219.99999999999926, 190.29999999999941, 40.0000000000003, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 170.0, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 173.0, 166.7, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 149.9, -400.0, 191.0, 5.2999999999999705, -127.00000000000074, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 178.4, 20.000000000000014, -89.20000000000084, 20.000000000000014, 182.0, 20.000000000000014, 185.0, 20.000000000000014, 172.7, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 20.000000000000014, 188.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 171.2, 188.0, 182.0, -379.0, 197.0, 20.000000000000014, 20.000000000000014, 200.0, -55.60000000000028, -196.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 191.0, 187.4, 200.0, 167.0, 169.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -139.0, -0.9999999999999846, 20.000000000000014, 200.0, -211.00000000000037, 200.0, 20.000000000000014, -82.0, -3.099999999999958, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -68.2000000000009, 164.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 173.0, 20.000000000000014, 9.499999999999964, 196.4, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.0, 7.399999999999965, 13.699999999999964, 20.000000000000014, 20.000000000000014, -9.399999999999872, 20.000000000000014, 191.0, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999837, 20.000000000000014, 20.000000000000014, 15.799999999999963, 188.0, 185.0, 200.0, 200.0, 161.0, -129.10000000000068, 15.799999999999962, 20.000000000000014, 9.499999999999964, 46.09999999999997, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 17.899999999999988, 181.1, -400.0, 11.599999999999964, 130.39999999999998, 183.8, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 173.9, 20.000000000000014, 191.0, 20.000000000000014, 164.3, 5.0, 20.000000000000014, 188.3, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.3, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 200.0, 20.000000000000014, 169.4, 170.0, 20.000000000000014, 170.0, 182.9, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -362.19999999999993, 9.499999999999964, 9.499999999999964, 154.4, 9.499999999999968, 20.000000000000014, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 170.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014], "policy_predator_policy_reward": [9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 200.0, 181.0, 70.0, 67.0, 0.0, 8.0, 0.0, 0.0, 52.0, 1.0, 0.0, 6.0, 5.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 0.0, 11.0, 2.0, 3.0, 4.0, 0.0, 7.0, 0.0, 0.0, 17.0, 0.0, 0.0, 6.0, 193.0, 190.0, 0.0, 0.0, 36.0, 0.0, 0.0, 132.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 10.0, 102.0, 118.0, 0.0, 0.0, 110.0, 8.0, 94.0, 84.0, 11.0, 0.0, 10.0, 0.0, 0.0, 42.0, 8.0, 10.0, 0.0, 1.0, 5.0, 6.0, 0.0, 5.0, 11.0, 13.0, 0.0, 0.0, 197.0, 193.0, 6.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 6.0, 0.0, 0.0, 5.0, 10.0, 10.0, 62.0, 43.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 200.0, 98.0, 8.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 65.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 182.0, 0.0, 19.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8357772706395796, "mean_inference_ms": 2.416548933104191, "mean_action_processing_ms": 0.37101808660933416, "mean_env_wait_ms": 0.3027970289448561, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006897568702697754, "StateBufferConnector_ms": 0.0045288801193237305, "ViewRequirementAgentConnector_ms": 0.18639671802520752}, "num_episodes": 18, "episode_return_max": 390.0, "episode_return_min": -165.70000000000073, "episode_return_mean": 141.5109999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.6432026907186, "num_env_steps_trained_throughput_per_sec": 305.6432026907186, "timesteps_total": 680000, "num_env_steps_sampled_lifetime": 680000, "num_agent_steps_sampled_lifetime": 2720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2720000, "timers": {"training_iteration_time_ms": 12700.797, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12700.708, "sample_time_ms": 2238.557, "learn_time_ms": 10438.548, "learn_throughput": 383.195, "synch_weights_time_ms": 20.117}, "counters": {"num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "done": false, "training_iteration": 170, "trial_id": "04dec_00002", "date": "2024-08-13_17-00-40", "timestamp": 1723582840, "time_this_iter_s": 13.209566831588745, "time_total_s": 2267.1937520504, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b08151f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2267.1937520504, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 64.90526315789472, "ram_util_percent": 83.16842105263159}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2436695567632794, "cur_kl_coeff": 8.14069799844062e-22, "cur_lr": 0.00010000000000000003, "total_loss": 0.22547876017670782, "policy_loss": -0.0009128052287946933, "vf_loss": 0.22639156491412515, "vf_explained_var": 0.027956041236403127, "kl": 0.008497146354961885, "entropy": 0.3392040929624012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 322245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.83862524581334, "cur_kl_coeff": 0.004339544791131358, "cur_lr": 0.00010000000000000003, "total_loss": 3.7563958266424753, "policy_loss": 0.0008031259638272108, "vf_loss": 3.7555668290960726, "vf_explained_var": 0.8730878710431397, "kl": 0.005961148547422218, "entropy": 0.4801046539551367, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 322245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "env_runners": {"episode_reward_max": 390.0, "episode_reward_min": -165.70000000000073, "episode_reward_mean": 142.27399999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 57.632, "predator_policy": 13.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.90000000000028, 219.99999999999926, 193.99999999999937, 214.9999999999993, 205.99999999999932, 40.0000000000003, 364.2, 376.0, 201.0, 40.0000000000003, 180.39999999999947, -44.00000000000052, 209.9999999999993, 213.9999999999993, 387.4, 352.4, 40.0000000000003, 206.99999999999932, 80.0, 219.99999999999926, 106.99999999999986, 115.99999999999962, 23.70000000000003, 29.000000000000128, -6.1999999999996955, 201.99999999999935, 38.90000000000028, 203.99999999999935, 210.8999999999993, 204.99999999999935, 40.0000000000003, 19.000000000000004, 27.10000000000009, 40.0000000000003, 24.600000000000062, 204.09999999999934, 40.0000000000003, 195.99999999999937, 40.0000000000003, 23.50000000000004, 40.0000000000003, 209.7999999999993, 390.0, 381.0, -8.29999999999971, 34.50000000000022, 246.09999999999943, 197.49999999999937, 38.90000000000028, 79.1, 149.99999999999963, 203.79999999999933, 195.99999999999937, 193.89999999999938, 213.9999999999993, 195.2999999999994, 98.99999999999997, 370.3, 40.0000000000003, 40.0000000000003, 200.29999999999936, 219.99999999999926, 212.9999999999993, 21.299999999999997, 40.0000000000003, 40.90000000000031, 219.99999999999926, 349.4, 199.99999999999935, 196.29999999999936, 40.0000000000003, 219.99999999999926, 201.99999999999935, 40.0000000000003, -165.70000000000073, 182.89999999999944, 34.50000000000022, 27.90000000000011, 219.99999999999926, 190.29999999999941, 40.0000000000003, 219.99999999999926, 211.9999999999993, 40.0000000000003, 211.9999999999993, 40.0000000000003, 190.2999999999994, 198.99999999999935, 140.9999999999997, 190.19999999999942, 188.5999999999994, 203.49999999999935, 219.99999999999926, 205.99999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 209.1999999999993, 37.80000000000027, 26.90000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 20.000000000000014, 188.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 171.2, 188.0, 182.0, -379.0, 197.0, 20.000000000000014, 20.000000000000014, 200.0, -55.60000000000028, -196.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 191.0, 187.4, 200.0, 167.0, 169.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -139.0, -0.9999999999999846, 20.000000000000014, 200.0, -211.00000000000037, 200.0, 20.000000000000014, -82.0, -3.099999999999958, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -68.2000000000009, 164.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 173.0, 20.000000000000014, 9.499999999999964, 196.4, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.0, 7.399999999999965, 13.699999999999964, 20.000000000000014, 20.000000000000014, -9.399999999999872, 20.000000000000014, 191.0, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999837, 20.000000000000014, 20.000000000000014, 15.799999999999963, 188.0, 185.0, 200.0, 200.0, 161.0, -129.10000000000068, 15.799999999999962, 20.000000000000014, 9.499999999999964, 46.09999999999997, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 17.899999999999988, 181.1, -400.0, 11.599999999999964, 130.39999999999998, 183.8, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 173.9, 20.000000000000014, 191.0, 20.000000000000014, 164.3, 5.0, 20.000000000000014, 188.3, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.3, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 200.0, 20.000000000000014, 169.4, 170.0, 20.000000000000014, 170.0, 182.9, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -362.19999999999993, 9.499999999999964, 9.499999999999964, 154.4, 9.499999999999968, 20.000000000000014, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 170.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.3, 161.0, 20.000000000000014, -27.399999999999764, 142.4, 20.000000000000014, 153.2, 11.599999999999964, 143.0, -11.499999999999833, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 189.2, 20.000000000000014, 15.799999999999963, 20.000000000000014, -0.9999999999999881, 17.899999999999984], "policy_predator_policy_reward": [0.0, 1.0, 0.0, 0.0, 11.0, 2.0, 3.0, 4.0, 0.0, 7.0, 0.0, 0.0, 17.0, 0.0, 0.0, 6.0, 193.0, 190.0, 0.0, 0.0, 36.0, 0.0, 0.0, 132.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 10.0, 102.0, 118.0, 0.0, 0.0, 110.0, 8.0, 94.0, 84.0, 11.0, 0.0, 10.0, 0.0, 0.0, 42.0, 8.0, 10.0, 0.0, 1.0, 5.0, 6.0, 0.0, 5.0, 11.0, 13.0, 0.0, 0.0, 197.0, 193.0, 6.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 6.0, 0.0, 0.0, 5.0, 10.0, 10.0, 62.0, 43.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 200.0, 98.0, 8.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 65.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 182.0, 0.0, 19.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 6.0, 12.0, 23.0, 3.0, 9.0, 8.0, 18.0, 16.0, 0.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8386631475893099, "mean_inference_ms": 2.4243751111616563, "mean_action_processing_ms": 0.3717862894675767, "mean_env_wait_ms": 0.30354462325712317, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006911754608154297, "StateBufferConnector_ms": 0.0044373273849487305, "ViewRequirementAgentConnector_ms": 0.20392441749572754}, "num_episodes": 18, "episode_return_max": 390.0, "episode_return_min": -165.70000000000073, "episode_return_mean": 142.27399999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.96562956848385, "num_env_steps_trained_throughput_per_sec": 306.96562956848385, "timesteps_total": 684000, "num_env_steps_sampled_lifetime": 684000, "num_agent_steps_sampled_lifetime": 2736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2736000, "timers": {"training_iteration_time_ms": 12740.08, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12739.997, "sample_time_ms": 2339.321, "learn_time_ms": 10377.483, "learn_throughput": 385.45, "synch_weights_time_ms": 19.953}, "counters": {"num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "done": false, "training_iteration": 171, "trial_id": "04dec_00002", "date": "2024-08-13_17-00-53", "timestamp": 1723582853, "time_this_iter_s": 13.081949949264526, "time_total_s": 2280.2757019996643, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06fcd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2280.2757019996643, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 66.27777777777777, "ram_util_percent": 83.54444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5434729470541237, "cur_kl_coeff": 8.14069799844062e-22, "cur_lr": 0.00010000000000000003, "total_loss": 0.4666657425975673, "policy_loss": -0.0032074769737110253, "vf_loss": 0.46987321864463705, "vf_explained_var": 0.0045240252106278035, "kl": 0.006627344632437068, "entropy": 0.32323418862762904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 324135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.695014397681705, "cur_kl_coeff": 0.004339544791131358, "cur_lr": 0.00010000000000000003, "total_loss": 4.210905319168454, "policy_loss": -0.00411259580770675, "vf_loss": 4.214933970365575, "vf_explained_var": 0.877132694620304, "kl": 0.01934308107805203, "entropy": 0.4788131875335855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 324135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "env_runners": {"episode_reward_max": 390.0, "episode_reward_min": -165.70000000000073, "episode_reward_mean": 141.93699999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 59.47849999999998, "predator_policy": 11.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, 219.99999999999926, 106.99999999999986, 115.99999999999962, 23.70000000000003, 29.000000000000128, -6.1999999999996955, 201.99999999999935, 38.90000000000028, 203.99999999999935, 210.8999999999993, 204.99999999999935, 40.0000000000003, 19.000000000000004, 27.10000000000009, 40.0000000000003, 24.600000000000062, 204.09999999999934, 40.0000000000003, 195.99999999999937, 40.0000000000003, 23.50000000000004, 40.0000000000003, 209.7999999999993, 390.0, 381.0, -8.29999999999971, 34.50000000000022, 246.09999999999943, 197.49999999999937, 38.90000000000028, 79.1, 149.99999999999963, 203.79999999999933, 195.99999999999937, 193.89999999999938, 213.9999999999993, 195.2999999999994, 98.99999999999997, 370.3, 40.0000000000003, 40.0000000000003, 200.29999999999936, 219.99999999999926, 212.9999999999993, 21.299999999999997, 40.0000000000003, 40.90000000000031, 219.99999999999926, 349.4, 199.99999999999935, 196.29999999999936, 40.0000000000003, 219.99999999999926, 201.99999999999935, 40.0000000000003, -165.70000000000073, 182.89999999999944, 34.50000000000022, 27.90000000000011, 219.99999999999926, 190.29999999999941, 40.0000000000003, 219.99999999999926, 211.9999999999993, 40.0000000000003, 211.9999999999993, 40.0000000000003, 190.2999999999994, 198.99999999999935, 140.9999999999997, 190.19999999999942, 188.5999999999994, 203.49999999999935, 219.99999999999926, 205.99999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 209.1999999999993, 37.80000000000027, 26.90000000000009, 179.69999999999945, 197.69999999999936, 364.0, 219.99999999999926, 40.0000000000003, 187.99999999999943, 40.0000000000003, 199.99999999999935, 355.3, 40.0000000000003, 292.89999999999975, -24.899999999999572, 216.69999999999928, 160.29999999999956, 356.0, 191.29999999999941, 199.99999999999935, 191.5999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-139.0, -0.9999999999999846, 20.000000000000014, 200.0, -211.00000000000037, 200.0, 20.000000000000014, -82.0, -3.099999999999958, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -68.2000000000009, 164.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 173.0, 20.000000000000014, 9.499999999999964, 196.4, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.0, 7.399999999999965, 13.699999999999964, 20.000000000000014, 20.000000000000014, -9.399999999999872, 20.000000000000014, 191.0, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999837, 20.000000000000014, 20.000000000000014, 15.799999999999963, 188.0, 185.0, 200.0, 200.0, 161.0, -129.10000000000068, 15.799999999999962, 20.000000000000014, 9.499999999999964, 46.09999999999997, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 17.899999999999988, 181.1, -400.0, 11.599999999999964, 130.39999999999998, 183.8, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 173.9, 20.000000000000014, 191.0, 20.000000000000014, 164.3, 5.0, 20.000000000000014, 188.3, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.3, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 200.0, 20.000000000000014, 169.4, 170.0, 20.000000000000014, 170.0, 182.9, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -362.19999999999993, 9.499999999999964, 9.499999999999964, 154.4, 9.499999999999968, 20.000000000000014, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 170.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.3, 161.0, 20.000000000000014, -27.399999999999764, 142.4, 20.000000000000014, 153.2, 11.599999999999964, 143.0, -11.499999999999833, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 189.2, 20.000000000000014, 15.799999999999963, 20.000000000000014, -0.9999999999999881, 17.899999999999984, 142.7, 20.000000000000014, 169.7, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 171.2, 169.1, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, -103.90000000000074, 13.699999999999964, 200.0, 167.6, -49.299999999999905, 182.0, 161.0, 20.000000000000014, 158.3, 20.000000000000014, 170.0, 11.599999999999964, 164.0], "policy_predator_policy_reward": [102.0, 118.0, 0.0, 0.0, 110.0, 8.0, 94.0, 84.0, 11.0, 0.0, 10.0, 0.0, 0.0, 42.0, 8.0, 10.0, 0.0, 1.0, 5.0, 6.0, 0.0, 5.0, 11.0, 13.0, 0.0, 0.0, 197.0, 193.0, 6.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 6.0, 0.0, 0.0, 5.0, 10.0, 10.0, 62.0, 43.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 200.0, 98.0, 8.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 65.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 182.0, 0.0, 19.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 6.0, 12.0, 23.0, 3.0, 9.0, 8.0, 18.0, 16.0, 0.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 10.0, 17.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 3.0, 33.0, 9.0, 0.0, 13.0, 0.0, 13.0, 8.0, 2.0, 4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8415682266300272, "mean_inference_ms": 2.432671357822613, "mean_action_processing_ms": 0.3727188503795327, "mean_env_wait_ms": 0.30445384778226703, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00756227970123291, "StateBufferConnector_ms": 0.0044171810150146484, "ViewRequirementAgentConnector_ms": 0.24469506740570068}, "num_episodes": 18, "episode_return_max": 390.0, "episode_return_min": -165.70000000000073, "episode_return_mean": 141.93699999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.43592121279573, "num_env_steps_trained_throughput_per_sec": 310.43592121279573, "timesteps_total": 688000, "num_env_steps_sampled_lifetime": 688000, "num_agent_steps_sampled_lifetime": 2752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2752000, "timers": {"training_iteration_time_ms": 12783.851, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12783.759, "sample_time_ms": 2441.338, "learn_time_ms": 10319.498, "learn_throughput": 387.616, "synch_weights_time_ms": 19.829}, "counters": {"num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "done": false, "training_iteration": 172, "trial_id": "04dec_00002", "date": "2024-08-13_17-01-06", "timestamp": 1723582866, "time_this_iter_s": 12.9360990524292, "time_total_s": 2293.2118010520935, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b02bce50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2293.2118010520935, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 62.53684210526315, "ram_util_percent": 83.10526315789475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7372287716105501, "cur_kl_coeff": 8.14069799844062e-22, "cur_lr": 0.00010000000000000003, "total_loss": 1.1353243958067012, "policy_loss": -0.0021388810095943943, "vf_loss": 1.1374632778937224, "vf_explained_var": 0.00044091987231421095, "kl": 0.045271725129180755, "entropy": 0.3494335223521505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 326025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.23375216195823, "cur_kl_coeff": 0.004339544791131358, "cur_lr": 0.00010000000000000003, "total_loss": 3.554694509380078, "policy_loss": -0.02287804168900327, "vf_loss": 3.577391487706906, "vf_explained_var": 0.5255527443040615, "kl": 0.04172380399595893, "entropy": 0.48794331709859234, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 326025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "env_runners": {"episode_reward_max": 397.3, "episode_reward_min": -165.70000000000073, "episode_reward_mean": 155.60099999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 67.8005, "predator_policy": 10.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [209.7999999999993, 390.0, 381.0, -8.29999999999971, 34.50000000000022, 246.09999999999943, 197.49999999999937, 38.90000000000028, 79.1, 149.99999999999963, 203.79999999999933, 195.99999999999937, 193.89999999999938, 213.9999999999993, 195.2999999999994, 98.99999999999997, 370.3, 40.0000000000003, 40.0000000000003, 200.29999999999936, 219.99999999999926, 212.9999999999993, 21.299999999999997, 40.0000000000003, 40.90000000000031, 219.99999999999926, 349.4, 199.99999999999935, 196.29999999999936, 40.0000000000003, 219.99999999999926, 201.99999999999935, 40.0000000000003, -165.70000000000073, 182.89999999999944, 34.50000000000022, 27.90000000000011, 219.99999999999926, 190.29999999999941, 40.0000000000003, 219.99999999999926, 211.9999999999993, 40.0000000000003, 211.9999999999993, 40.0000000000003, 190.2999999999994, 198.99999999999935, 140.9999999999997, 190.19999999999942, 188.5999999999994, 203.49999999999935, 219.99999999999926, 205.99999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 209.1999999999993, 37.80000000000027, 26.90000000000009, 179.69999999999945, 197.69999999999936, 364.0, 219.99999999999926, 40.0000000000003, 187.99999999999943, 40.0000000000003, 199.99999999999935, 355.3, 40.0000000000003, 292.89999999999975, -24.899999999999572, 216.69999999999928, 160.29999999999956, 356.0, 191.29999999999941, 199.99999999999935, 191.5999999999994, 40.0000000000003, -164.60000000000062, -41.899999999999615, 233.49999999999915, 355.9000000000011, 195.99999999999937, 209.9999999999993, 31.200000000000166, 30.10000000000015, -1.9999999999999587, 181.29999999999944, 397.3, 380.0, 213.09999999999928, 148.99999999999963, 324.3999999999999, 40.0000000000003, 37.80000000000027, 205.99999999999932, 205.99999999999932, 219.99999999999926, 215.59999999999928, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, 188.0, 185.0, 200.0, 200.0, 161.0, -129.10000000000068, 15.799999999999962, 20.000000000000014, 9.499999999999964, 46.09999999999997, 200.0, 177.5, 20.000000000000014, 20.000000000000014, 17.899999999999988, 181.1, -400.0, 11.599999999999964, 130.39999999999998, 183.8, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 173.9, 20.000000000000014, 191.0, 20.000000000000014, 164.3, 5.0, 20.000000000000014, 188.3, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.3, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 200.0, 20.000000000000014, 169.4, 170.0, 20.000000000000014, 170.0, 182.9, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -362.19999999999993, 9.499999999999964, 9.499999999999964, 154.4, 9.499999999999968, 20.000000000000014, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 170.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.3, 161.0, 20.000000000000014, -27.399999999999764, 142.4, 20.000000000000014, 153.2, 11.599999999999964, 143.0, -11.499999999999833, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 189.2, 20.000000000000014, 15.799999999999963, 20.000000000000014, -0.9999999999999881, 17.899999999999984, 142.7, 20.000000000000014, 169.7, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 171.2, 169.1, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, -103.90000000000074, 13.699999999999964, 200.0, 167.6, -49.299999999999905, 182.0, 161.0, 20.000000000000014, 158.3, 20.000000000000014, 170.0, 11.599999999999964, 164.0, 20.000000000000014, 20.000000000000014, -370.59999999999997, 20.000000000000014, -59.80000000000027, -45.09999999999979, 33.50000000000024, 200.0, 200.0, 155.89999999999972, 20.000000000000014, 164.0, 185.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 143.3, 200.0, 197.3, 200.0, 170.0, 1.0999999999999723, 200.0, 20.000000000000014, 68.0, 124.39999999999998, 200.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 179.0, 200.0, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 5.299999999999965], "policy_predator_policy_reward": [6.0, 0.0, 0.0, 5.0, 10.0, 10.0, 62.0, 43.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 200.0, 98.0, 8.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 65.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 182.0, 0.0, 19.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 6.0, 12.0, 23.0, 3.0, 9.0, 8.0, 18.0, 16.0, 0.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 10.0, 17.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 3.0, 33.0, 9.0, 0.0, 13.0, 0.0, 13.0, 8.0, 2.0, 4.0, 12.0, 0.0, 0.0, 0.0, 186.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 9.0, 178.0, 200.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 9.0, 3.0, 27.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8450572509466139, "mean_inference_ms": 2.4412021586866897, "mean_action_processing_ms": 0.3740434423353334, "mean_env_wait_ms": 0.30535381666670114, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00862419605255127, "StateBufferConnector_ms": 0.004520058631896973, "ViewRequirementAgentConnector_ms": 0.2671637535095215}, "num_episodes": 23, "episode_return_max": 397.3, "episode_return_min": -165.70000000000073, "episode_return_mean": 155.60099999999974, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.12827891127375, "num_env_steps_trained_throughput_per_sec": 298.12827891127375, "timesteps_total": 692000, "num_env_steps_sampled_lifetime": 692000, "num_agent_steps_sampled_lifetime": 2768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2768000, "timers": {"training_iteration_time_ms": 12923.437, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12923.362, "sample_time_ms": 2545.711, "learn_time_ms": 10350.422, "learn_throughput": 386.458, "synch_weights_time_ms": 24.125}, "counters": {"num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "done": false, "training_iteration": 173, "trial_id": "04dec_00002", "date": "2024-08-13_17-01-20", "timestamp": 1723582880, "time_this_iter_s": 13.493309020996094, "time_total_s": 2306.7051100730896, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c44c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2306.7051100730896, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 64.39999999999999, "ram_util_percent": 83.32105263157894}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.221541582765403, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.129066095749537, "policy_loss": -0.0020536729514046954, "vf_loss": 1.1311197675252087, "vf_explained_var": 0.0009361140311710418, "kl": 0.009865038286501572, "entropy": 0.39640259801079986, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 327915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.926298333412756, "cur_kl_coeff": 0.006509317186697034, "cur_lr": 0.00010000000000000003, "total_loss": 3.1770862238116995, "policy_loss": -0.002511187005916206, "vf_loss": 3.1791888131035697, "vf_explained_var": 0.6880085096788154, "kl": 0.06277102851701785, "entropy": 0.422997795013839, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 327915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "env_runners": {"episode_reward_max": 397.3, "episode_reward_min": -172.30000000000078, "episode_reward_mean": 139.54699999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 59.2235, "predator_policy": 10.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.299999999999997, 40.0000000000003, 40.90000000000031, 219.99999999999926, 349.4, 199.99999999999935, 196.29999999999936, 40.0000000000003, 219.99999999999926, 201.99999999999935, 40.0000000000003, -165.70000000000073, 182.89999999999944, 34.50000000000022, 27.90000000000011, 219.99999999999926, 190.29999999999941, 40.0000000000003, 219.99999999999926, 211.9999999999993, 40.0000000000003, 211.9999999999993, 40.0000000000003, 190.2999999999994, 198.99999999999935, 140.9999999999997, 190.19999999999942, 188.5999999999994, 203.49999999999935, 219.99999999999926, 205.99999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 209.1999999999993, 37.80000000000027, 26.90000000000009, 179.69999999999945, 197.69999999999936, 364.0, 219.99999999999926, 40.0000000000003, 187.99999999999943, 40.0000000000003, 199.99999999999935, 355.3, 40.0000000000003, 292.89999999999975, -24.899999999999572, 216.69999999999928, 160.29999999999956, 356.0, 191.29999999999941, 199.99999999999935, 191.5999999999994, 40.0000000000003, -164.60000000000062, -41.899999999999615, 233.49999999999915, 355.9000000000011, 195.99999999999937, 209.9999999999993, 31.200000000000166, 30.10000000000015, -1.9999999999999587, 181.29999999999944, 397.3, 380.0, 213.09999999999928, 148.99999999999963, 324.3999999999999, 40.0000000000003, 37.80000000000027, 205.99999999999932, 205.99999999999932, 219.99999999999926, 215.59999999999928, 32.30000000000018, 40.0000000000003, 219.99999999999926, 190.5999999999994, 27.900000000000116, 213.69999999999928, 206.79999999999933, -36.99999999999956, -138.20000000000047, 40.0000000000003, 30.100000000000158, 244.49999999999974, 216.39999999999927, -90.90000000000036, -172.30000000000078, 193.99999999999937, 219.99999999999926, 40.0000000000003, 219.99999999999926, 361.0, 17.50000000000001, 36.70000000000025, 217.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 200.0, 20.000000000000014, 169.4, 170.0, 20.000000000000014, 170.0, 182.9, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -362.19999999999993, 9.499999999999964, 9.499999999999964, 154.4, 9.499999999999968, 20.000000000000014, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 170.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.3, 161.0, 20.000000000000014, -27.399999999999764, 142.4, 20.000000000000014, 153.2, 11.599999999999964, 143.0, -11.499999999999833, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 189.2, 20.000000000000014, 15.799999999999963, 20.000000000000014, -0.9999999999999881, 17.899999999999984, 142.7, 20.000000000000014, 169.7, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 171.2, 169.1, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, -103.90000000000074, 13.699999999999964, 200.0, 167.6, -49.299999999999905, 182.0, 161.0, 20.000000000000014, 158.3, 20.000000000000014, 170.0, 11.599999999999964, 164.0, 20.000000000000014, 20.000000000000014, -370.59999999999997, 20.000000000000014, -59.80000000000027, -45.09999999999979, 33.50000000000024, 200.0, 200.0, 155.89999999999972, 20.000000000000014, 164.0, 185.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 143.3, 200.0, 197.3, 200.0, 170.0, 1.0999999999999723, 200.0, 20.000000000000014, 68.0, 124.39999999999998, 200.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 179.0, 200.0, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 164.0, 11.599999999999966, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 193.7, -5.1999999999999265, 200.0, -127.00000000000045, 20.000000000000014, -288.7, -11.499999999999819, 20.000000000000014, 20.000000000000014, 1.0999999999999635, 20.000000000000014, 18.499999999999986, 200.0, 20.000000000000014, 196.4, -229.9000000000002, 20.000000000000014, -362.19999999999976, -3.099999999999972, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 155.0, 7.399999999999965, 1.0999999999999865, 13.699999999999964, 20.000000000000014, 197.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 182.0, 0.0, 19.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 6.0, 12.0, 23.0, 3.0, 9.0, 8.0, 18.0, 16.0, 0.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 10.0, 17.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 3.0, 33.0, 9.0, 0.0, 13.0, 0.0, 13.0, 8.0, 2.0, 4.0, 12.0, 0.0, 0.0, 0.0, 186.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 9.0, 178.0, 200.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 9.0, 3.0, 27.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 70.0, 0.0, 0.0, 162.0, 0.0, 0.0, 9.0, 0.0, 19.0, 7.0, 0.0, 0.0, 119.0, 0.0, 182.0, 11.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 18.0, 9.0, 0.0, 3.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8472933646385853, "mean_inference_ms": 2.448945627987679, "mean_action_processing_ms": 0.37461762505534785, "mean_env_wait_ms": 0.30633824386798425, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0072667598724365234, "StateBufferConnector_ms": 0.0035049915313720703, "ViewRequirementAgentConnector_ms": 0.23344552516937256}, "num_episodes": 22, "episode_return_max": 397.3, "episode_return_min": -172.30000000000078, "episode_return_mean": 139.54699999999974, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 302.2567535102417, "num_env_steps_trained_throughput_per_sec": 302.2567535102417, "timesteps_total": 696000, "num_env_steps_sampled_lifetime": 696000, "num_agent_steps_sampled_lifetime": 2784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2784000, "timers": {"training_iteration_time_ms": 12989.601, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12989.53, "sample_time_ms": 2636.916, "learn_time_ms": 10324.365, "learn_throughput": 387.433, "synch_weights_time_ms": 25.115}, "counters": {"num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "done": false, "training_iteration": 174, "trial_id": "04dec_00002", "date": "2024-08-13_17-01-33", "timestamp": 1723582893, "time_this_iter_s": 13.343451023101807, "time_total_s": 2320.0485610961914, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0774d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2320.0485610961914, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 64.30526315789473, "ram_util_percent": 83.61052631578949}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.67517971543881, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.5019724142772181, "policy_loss": -0.0012680442584924912, "vf_loss": 0.5032404576778097, "vf_explained_var": 0.03560475114161375, "kl": 0.007032023812781266, "entropy": 0.3633217277429091, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 329805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.622632591655016, "cur_kl_coeff": 0.009763975780045557, "cur_lr": 0.00010000000000000003, "total_loss": 3.068112682791614, "policy_loss": -0.004362481601644682, "vf_loss": 3.0721426333699906, "vf_explained_var": 0.8816884681030556, "kl": 0.0340560901198019, "entropy": 0.38924977808560013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 329805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "env_runners": {"episode_reward_max": 397.3, "episode_reward_min": -172.30000000000078, "episode_reward_mean": 142.86899999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 61.4795, "predator_policy": 9.955}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 211.9999999999993, 40.0000000000003, 211.9999999999993, 40.0000000000003, 190.2999999999994, 198.99999999999935, 140.9999999999997, 190.19999999999942, 188.5999999999994, 203.49999999999935, 219.99999999999926, 205.99999999999932, 40.0000000000003, 40.0000000000003, 40.0000000000003, 209.1999999999993, 37.80000000000027, 26.90000000000009, 179.69999999999945, 197.69999999999936, 364.0, 219.99999999999926, 40.0000000000003, 187.99999999999943, 40.0000000000003, 199.99999999999935, 355.3, 40.0000000000003, 292.89999999999975, -24.899999999999572, 216.69999999999928, 160.29999999999956, 356.0, 191.29999999999941, 199.99999999999935, 191.5999999999994, 40.0000000000003, -164.60000000000062, -41.899999999999615, 233.49999999999915, 355.9000000000011, 195.99999999999937, 209.9999999999993, 31.200000000000166, 30.10000000000015, -1.9999999999999587, 181.29999999999944, 397.3, 380.0, 213.09999999999928, 148.99999999999963, 324.3999999999999, 40.0000000000003, 37.80000000000027, 205.99999999999932, 205.99999999999932, 219.99999999999926, 215.59999999999928, 32.30000000000018, 40.0000000000003, 219.99999999999926, 190.5999999999994, 27.900000000000116, 213.69999999999928, 206.79999999999933, -36.99999999999956, -138.20000000000047, 40.0000000000003, 30.100000000000158, 244.49999999999974, 216.39999999999927, -90.90000000000036, -172.30000000000078, 193.99999999999937, 219.99999999999926, 40.0000000000003, 219.99999999999926, 361.0, 17.50000000000001, 36.70000000000025, 217.99999999999926, 158.29999999999956, 197.49999999999937, 208.99999999999932, 40.0000000000003, 61.90000000000029, 185.59999999999943, 40.0000000000003, 195.69999999999936, 40.0000000000003, 207.99999999999932, 103.89999999999995, 36.70000000000025, 40.0000000000003, 37.80000000000027, 209.9999999999993, 219.99999999999926, 247.59999999999957, 199.99999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.3, 161.0, 20.000000000000014, -27.399999999999764, 142.4, 20.000000000000014, 153.2, 11.599999999999964, 143.0, -11.499999999999833, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 189.2, 20.000000000000014, 15.799999999999963, 20.000000000000014, -0.9999999999999881, 17.899999999999984, 142.7, 20.000000000000014, 169.7, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 171.2, 169.1, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, -103.90000000000074, 13.699999999999964, 200.0, 167.6, -49.299999999999905, 182.0, 161.0, 20.000000000000014, 158.3, 20.000000000000014, 170.0, 11.599999999999964, 164.0, 20.000000000000014, 20.000000000000014, -370.59999999999997, 20.000000000000014, -59.80000000000027, -45.09999999999979, 33.50000000000024, 200.0, 200.0, 155.89999999999972, 20.000000000000014, 164.0, 185.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 143.3, 200.0, 197.3, 200.0, 170.0, 1.0999999999999723, 200.0, 20.000000000000014, 68.0, 124.39999999999998, 200.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 179.0, 200.0, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 164.0, 11.599999999999966, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 193.7, -5.1999999999999265, 200.0, -127.00000000000045, 20.000000000000014, -288.7, -11.499999999999819, 20.000000000000014, 20.000000000000014, 1.0999999999999635, 20.000000000000014, 18.499999999999986, 200.0, 20.000000000000014, 196.4, -229.9000000000002, 20.000000000000014, -362.19999999999976, -3.099999999999972, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 155.0, 7.399999999999965, 1.0999999999999865, 13.699999999999964, 20.000000000000014, 197.0, 20.000000000000014, 176.0, -78.7000000000004, 177.5, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 34.40000000000014, 24.50000000000009, 11.599999999999964, 155.0, 20.000000000000014, 20.000000000000014, 161.0, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 83.89999999999998, 20.000000000000014, 13.699999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 185.0, 20.000000000000014, 200.0, 20.000000000000014, 59.59999999999996, 182.0, 20.000000000000014, 170.0], "policy_predator_policy_reward": [0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 6.0, 12.0, 23.0, 3.0, 9.0, 8.0, 18.0, 16.0, 0.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 10.0, 17.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 3.0, 33.0, 9.0, 0.0, 13.0, 0.0, 13.0, 8.0, 2.0, 4.0, 12.0, 0.0, 0.0, 0.0, 186.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 9.0, 178.0, 200.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 9.0, 3.0, 27.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 70.0, 0.0, 0.0, 162.0, 0.0, 0.0, 9.0, 0.0, 19.0, 7.0, 0.0, 0.0, 119.0, 0.0, 182.0, 11.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 18.0, 9.0, 0.0, 3.0, 0.0, 0.0, 1.0, 24.0, 37.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 19.0, 0.0, 0.0, 5.0, 16.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8494404340554947, "mean_inference_ms": 2.4555142811657227, "mean_action_processing_ms": 0.3753358032593336, "mean_env_wait_ms": 0.30704612435874135, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008612632751464844, "StateBufferConnector_ms": 0.0034177303314208984, "ViewRequirementAgentConnector_ms": 0.25023365020751953}, "num_episodes": 18, "episode_return_max": 397.3, "episode_return_min": -172.30000000000078, "episode_return_mean": 142.86899999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 308.12835326551794, "num_env_steps_trained_throughput_per_sec": 308.12835326551794, "timesteps_total": 700000, "num_env_steps_sampled_lifetime": 700000, "num_agent_steps_sampled_lifetime": 2800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2800000, "timers": {"training_iteration_time_ms": 13083.671, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13083.599, "sample_time_ms": 2750.286, "learn_time_ms": 10304.2, "learn_throughput": 388.191, "synch_weights_time_ms": 25.748}, "counters": {"num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "done": false, "training_iteration": 175, "trial_id": "04dec_00002", "date": "2024-08-13_17-01-46", "timestamp": 1723582906, "time_this_iter_s": 13.022426843643188, "time_total_s": 2333.0709879398346, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b083b940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2333.0709879398346, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 68.89444444444445, "ram_util_percent": 83.62777777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3994709153970082, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.35506774045960615, "policy_loss": 0.0004467503002613152, "vf_loss": 0.35462098866454744, "vf_explained_var": 0.09449744215087286, "kl": 0.008452007693203355, "entropy": 0.3590196464664091, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 331695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.757198662417277, "cur_kl_coeff": 0.014645963670068325, "cur_lr": 0.00010000000000000003, "total_loss": 2.7008308802332195, "policy_loss": -0.0011862376531112998, "vf_loss": 2.701633181206133, "vf_explained_var": 0.9339106898143809, "kl": 0.026214378396278853, "entropy": 0.20683363158078422, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 331695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "env_runners": {"episode_reward_max": 397.3, "episode_reward_min": -172.30000000000078, "episode_reward_mean": 156.03099999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 67.95049999999999, "predator_policy": 10.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.90000000000009, 179.69999999999945, 197.69999999999936, 364.0, 219.99999999999926, 40.0000000000003, 187.99999999999943, 40.0000000000003, 199.99999999999935, 355.3, 40.0000000000003, 292.89999999999975, -24.899999999999572, 216.69999999999928, 160.29999999999956, 356.0, 191.29999999999941, 199.99999999999935, 191.5999999999994, 40.0000000000003, -164.60000000000062, -41.899999999999615, 233.49999999999915, 355.9000000000011, 195.99999999999937, 209.9999999999993, 31.200000000000166, 30.10000000000015, -1.9999999999999587, 181.29999999999944, 397.3, 380.0, 213.09999999999928, 148.99999999999963, 324.3999999999999, 40.0000000000003, 37.80000000000027, 205.99999999999932, 205.99999999999932, 219.99999999999926, 215.59999999999928, 32.30000000000018, 40.0000000000003, 219.99999999999926, 190.5999999999994, 27.900000000000116, 213.69999999999928, 206.79999999999933, -36.99999999999956, -138.20000000000047, 40.0000000000003, 30.100000000000158, 244.49999999999974, 216.39999999999927, -90.90000000000036, -172.30000000000078, 193.99999999999937, 219.99999999999926, 40.0000000000003, 219.99999999999926, 361.0, 17.50000000000001, 36.70000000000025, 217.99999999999926, 158.29999999999956, 197.49999999999937, 208.99999999999932, 40.0000000000003, 61.90000000000029, 185.59999999999943, 40.0000000000003, 195.69999999999936, 40.0000000000003, 207.99999999999932, 103.89999999999995, 36.70000000000025, 40.0000000000003, 37.80000000000027, 209.9999999999993, 219.99999999999926, 247.59999999999957, 199.99999999999935, 302.79999999999984, 201.99999999999935, 274.5999999999999, 201.99999999999935, 382.0, 369.0, 348.6, 208.99999999999932, 217.99999999999926, 193.49999999999937, 22.400000000000013, 219.99999999999926, 137.0999999999997, 194.7999999999994, 380.0, 209.99999999999932, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.9999999999999881, 17.899999999999984, 142.7, 20.000000000000014, 169.7, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 171.2, 169.1, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, -103.90000000000074, 13.699999999999964, 200.0, 167.6, -49.299999999999905, 182.0, 161.0, 20.000000000000014, 158.3, 20.000000000000014, 170.0, 11.599999999999964, 164.0, 20.000000000000014, 20.000000000000014, -370.59999999999997, 20.000000000000014, -59.80000000000027, -45.09999999999979, 33.50000000000024, 200.0, 200.0, 155.89999999999972, 20.000000000000014, 164.0, 185.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 143.3, 200.0, 197.3, 200.0, 170.0, 1.0999999999999723, 200.0, 20.000000000000014, 68.0, 124.39999999999998, 200.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 179.0, 200.0, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 164.0, 11.599999999999966, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 193.7, -5.1999999999999265, 200.0, -127.00000000000045, 20.000000000000014, -288.7, -11.499999999999819, 20.000000000000014, 20.000000000000014, 1.0999999999999635, 20.000000000000014, 18.499999999999986, 200.0, 20.000000000000014, 196.4, -229.9000000000002, 20.000000000000014, -362.19999999999976, -3.099999999999972, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 155.0, 7.399999999999965, 1.0999999999999865, 13.699999999999964, 20.000000000000014, 197.0, 20.000000000000014, 176.0, -78.7000000000004, 177.5, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 34.40000000000014, 24.50000000000009, 11.599999999999964, 155.0, 20.000000000000014, 20.000000000000014, 161.0, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 83.89999999999998, 20.000000000000014, 13.699999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 185.0, 20.000000000000014, 200.0, 20.000000000000014, 59.59999999999996, 182.0, 20.000000000000014, 170.0, 109.09999999999998, 193.7, 182.0, 20.000000000000014, 175.7, 83.89999999999998, 20.000000000000014, 173.0, 200.0, 173.0, 158.0, 197.0, 185.0, 158.6, 200.0, -0.9999999999999846, 197.0, 20.000000000000014, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 200.0, 128.89999999999998, -38.799999999999756, 174.8, 20.000000000000014, 200.0, 170.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 10.0, 17.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 3.0, 33.0, 9.0, 0.0, 13.0, 0.0, 13.0, 8.0, 2.0, 4.0, 12.0, 0.0, 0.0, 0.0, 186.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 9.0, 178.0, 200.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 9.0, 3.0, 27.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 70.0, 0.0, 0.0, 162.0, 0.0, 0.0, 9.0, 0.0, 19.0, 7.0, 0.0, 0.0, 119.0, 0.0, 182.0, 11.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 18.0, 9.0, 0.0, 3.0, 0.0, 0.0, 1.0, 24.0, 37.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 19.0, 0.0, 0.0, 5.0, 16.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 9.0, 9.0, 0.0, 0.0, 9.0, 14.0, 0.0, 5.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 8.0, 0.0, 16.0, 0.0, 0.0, 20.0, 27.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8514100662062785, "mean_inference_ms": 2.4614821904020037, "mean_action_processing_ms": 0.3759912314821365, "mean_env_wait_ms": 0.30769517267283286, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008547544479370117, "StateBufferConnector_ms": 0.0033832788467407227, "ViewRequirementAgentConnector_ms": 0.25255417823791504}, "num_episodes": 18, "episode_return_max": 397.3, "episode_return_min": -172.30000000000078, "episode_return_mean": 156.03099999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.5704438808651, "num_env_steps_trained_throughput_per_sec": 292.5704438808651, "timesteps_total": 704000, "num_env_steps_sampled_lifetime": 704000, "num_agent_steps_sampled_lifetime": 2816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2816000, "timers": {"training_iteration_time_ms": 13221.376, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13221.305, "sample_time_ms": 2812.717, "learn_time_ms": 10383.162, "learn_throughput": 385.239, "synch_weights_time_ms": 22.296}, "counters": {"num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "done": false, "training_iteration": 176, "trial_id": "04dec_00002", "date": "2024-08-13_17-02-00", "timestamp": 1723582920, "time_this_iter_s": 13.7299063205719, "time_total_s": 2346.8008942604065, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0774940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2346.8008942604065, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 66.55, "ram_util_percent": 83.47}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1056782298026577, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.23124350705947824, "policy_loss": -0.0012486108697004734, "vf_loss": 0.23249211831110106, "vf_explained_var": 0.005874491210967775, "kl": 0.010477711174862703, "entropy": 0.40232756357029004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 333585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.964778146352717, "cur_kl_coeff": 0.021968945505102495, "cur_lr": 0.00010000000000000003, "total_loss": 1.9550431352443796, "policy_loss": -0.0002986031351611018, "vf_loss": 1.9524983135796097, "vf_explained_var": 0.9654036874808962, "kl": 0.1294289849856453, "entropy": 0.3151027214866151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 333585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "env_runners": {"episode_reward_max": 398.0, "episode_reward_min": -172.30000000000078, "episode_reward_mean": 154.70099999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 67.5005, "predator_policy": 9.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [191.5999999999994, 40.0000000000003, -164.60000000000062, -41.899999999999615, 233.49999999999915, 355.9000000000011, 195.99999999999937, 209.9999999999993, 31.200000000000166, 30.10000000000015, -1.9999999999999587, 181.29999999999944, 397.3, 380.0, 213.09999999999928, 148.99999999999963, 324.3999999999999, 40.0000000000003, 37.80000000000027, 205.99999999999932, 205.99999999999932, 219.99999999999926, 215.59999999999928, 32.30000000000018, 40.0000000000003, 219.99999999999926, 190.5999999999994, 27.900000000000116, 213.69999999999928, 206.79999999999933, -36.99999999999956, -138.20000000000047, 40.0000000000003, 30.100000000000158, 244.49999999999974, 216.39999999999927, -90.90000000000036, -172.30000000000078, 193.99999999999937, 219.99999999999926, 40.0000000000003, 219.99999999999926, 361.0, 17.50000000000001, 36.70000000000025, 217.99999999999926, 158.29999999999956, 197.49999999999937, 208.99999999999932, 40.0000000000003, 61.90000000000029, 185.59999999999943, 40.0000000000003, 195.69999999999936, 40.0000000000003, 207.99999999999932, 103.89999999999995, 36.70000000000025, 40.0000000000003, 37.80000000000027, 209.9999999999993, 219.99999999999926, 247.59999999999957, 199.99999999999935, 302.79999999999984, 201.99999999999935, 274.5999999999999, 201.99999999999935, 382.0, 369.0, 348.6, 208.99999999999932, 217.99999999999926, 193.49999999999937, 22.400000000000013, 219.99999999999926, 137.0999999999997, 194.7999999999994, 380.0, 209.99999999999932, 40.0000000000003, 40.0000000000003, 138.29999999999964, 206.79999999999933, 188.9999999999994, 179.89999999999947, 182.09999999999945, 398.0, 219.99999999999926, 40.0000000000003, 205.99999999999932, 37.80000000000027, 40.0000000000003, 32.300000000000196, 382.0, 219.99999999999926, 36.70000000000025, 40.0000000000003, 204.99999999999935, 357.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 164.0, 20.000000000000014, 20.000000000000014, -370.59999999999997, 20.000000000000014, -59.80000000000027, -45.09999999999979, 33.50000000000024, 200.0, 200.0, 155.89999999999972, 20.000000000000014, 164.0, 185.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 143.3, 200.0, 197.3, 200.0, 170.0, 1.0999999999999723, 200.0, 20.000000000000014, 68.0, 124.39999999999998, 200.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 179.0, 200.0, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 164.0, 11.599999999999966, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 193.7, -5.1999999999999265, 200.0, -127.00000000000045, 20.000000000000014, -288.7, -11.499999999999819, 20.000000000000014, 20.000000000000014, 1.0999999999999635, 20.000000000000014, 18.499999999999986, 200.0, 20.000000000000014, 196.4, -229.9000000000002, 20.000000000000014, -362.19999999999976, -3.099999999999972, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 155.0, 7.399999999999965, 1.0999999999999865, 13.699999999999964, 20.000000000000014, 197.0, 20.000000000000014, 176.0, -78.7000000000004, 177.5, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 34.40000000000014, 24.50000000000009, 11.599999999999964, 155.0, 20.000000000000014, 20.000000000000014, 161.0, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 83.89999999999998, 20.000000000000014, 13.699999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 185.0, 20.000000000000014, 200.0, 20.000000000000014, 59.59999999999996, 182.0, 20.000000000000014, 170.0, 109.09999999999998, 193.7, 182.0, 20.000000000000014, 175.7, 83.89999999999998, 20.000000000000014, 173.0, 200.0, 173.0, 158.0, 197.0, 185.0, 158.6, 200.0, -0.9999999999999846, 197.0, 20.000000000000014, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 200.0, 128.89999999999998, -38.799999999999756, 174.8, 20.000000000000014, 200.0, 170.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 124.39999999999999, 200.0, -5.199999999999962, 20.000000000000014, 146.0, -3.0999999999999757, 158.0, -19.899999999999743, 167.0, 197.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 194.0, -1.0000000000000098, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.299999999999969, 20.000000000000014, 161.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 167.0, 176.0], "policy_predator_policy_reward": [4.0, 12.0, 0.0, 0.0, 0.0, 186.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 9.0, 178.0, 200.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 9.0, 3.0, 27.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 70.0, 0.0, 0.0, 162.0, 0.0, 0.0, 9.0, 0.0, 19.0, 7.0, 0.0, 0.0, 119.0, 0.0, 182.0, 11.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 18.0, 9.0, 0.0, 3.0, 0.0, 0.0, 1.0, 24.0, 37.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 19.0, 0.0, 0.0, 5.0, 16.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 9.0, 9.0, 0.0, 0.0, 9.0, 14.0, 0.0, 5.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 8.0, 0.0, 16.0, 0.0, 0.0, 20.0, 27.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 11.0, 0.0, 12.0, 14.0, 9.0, 9.0, 16.0, 17.0, 18.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 13.0, 8.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 7.0, 6.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8533532625008118, "mean_inference_ms": 2.4678056689227175, "mean_action_processing_ms": 0.3766265654759251, "mean_env_wait_ms": 0.30830977955092026, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007752060890197754, "StateBufferConnector_ms": 0.0033751726150512695, "ViewRequirementAgentConnector_ms": 0.20421266555786133}, "num_episodes": 18, "episode_return_max": 398.0, "episode_return_min": -172.30000000000078, "episode_return_mean": 154.70099999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.02664921955267, "num_env_steps_trained_throughput_per_sec": 300.02664921955267, "timesteps_total": 708000, "num_env_steps_sampled_lifetime": 708000, "num_agent_steps_sampled_lifetime": 2832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2832000, "timers": {"training_iteration_time_ms": 13320.313, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13320.248, "sample_time_ms": 2869.562, "learn_time_ms": 10425.954, "learn_throughput": 383.658, "synch_weights_time_ms": 21.466}, "counters": {"num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "done": false, "training_iteration": 177, "trial_id": "04dec_00002", "date": "2024-08-13_17-02-13", "timestamp": 1723582933, "time_this_iter_s": 13.371160984039307, "time_total_s": 2360.172055244446, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b04c44c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2360.172055244446, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 65.84210526315789, "ram_util_percent": 83.63684210526316}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2507393373225733, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.2230572427076007, "policy_loss": 0.0007815687562383357, "vf_loss": 1.2222756730343298, "vf_explained_var": 0.000568250815073649, "kl": 0.008965587014137624, "entropy": 0.4084005592992066, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 335475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.79997760070064, "cur_kl_coeff": 0.032953418257653744, "cur_lr": 0.00010000000000000003, "total_loss": 1.7298612347986333, "policy_loss": 0.0025529128193815865, "vf_loss": 1.7261407616592588, "vf_explained_var": 0.5454315858227866, "kl": 0.0354306716123157, "entropy": 0.21727412998203247, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 335475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -172.30000000000078, "episode_reward_mean": 155.9989999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 69.0995, "predator_policy": 8.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.900000000000116, 213.69999999999928, 206.79999999999933, -36.99999999999956, -138.20000000000047, 40.0000000000003, 30.100000000000158, 244.49999999999974, 216.39999999999927, -90.90000000000036, -172.30000000000078, 193.99999999999937, 219.99999999999926, 40.0000000000003, 219.99999999999926, 361.0, 17.50000000000001, 36.70000000000025, 217.99999999999926, 158.29999999999956, 197.49999999999937, 208.99999999999932, 40.0000000000003, 61.90000000000029, 185.59999999999943, 40.0000000000003, 195.69999999999936, 40.0000000000003, 207.99999999999932, 103.89999999999995, 36.70000000000025, 40.0000000000003, 37.80000000000027, 209.9999999999993, 219.99999999999926, 247.59999999999957, 199.99999999999935, 302.79999999999984, 201.99999999999935, 274.5999999999999, 201.99999999999935, 382.0, 369.0, 348.6, 208.99999999999932, 217.99999999999926, 193.49999999999937, 22.400000000000013, 219.99999999999926, 137.0999999999997, 194.7999999999994, 380.0, 209.99999999999932, 40.0000000000003, 40.0000000000003, 138.29999999999964, 206.79999999999933, 188.9999999999994, 179.89999999999947, 182.09999999999945, 398.0, 219.99999999999926, 40.0000000000003, 205.99999999999932, 37.80000000000027, 40.0000000000003, 32.300000000000196, 382.0, 219.99999999999926, 36.70000000000025, 40.0000000000003, 204.99999999999935, 357.0, 400.0, 188.4999999999994, 215.99999999999926, 207.89999999999932, 40.0000000000003, 217.99999999999926, 218.89999999999927, 219.99999999999926, 195.1999999999994, 171.3999999999995, 384.0, 172.6999999999995, 367.1, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, -150.6000000000005, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.99999999999932, 114.0, 40.0000000000003, 211.1999999999993, 183.79999999999936, 38.90000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.0999999999999686, 20.000000000000014, 20.000000000000014, 193.7, -5.1999999999999265, 200.0, -127.00000000000045, 20.000000000000014, -288.7, -11.499999999999819, 20.000000000000014, 20.000000000000014, 1.0999999999999635, 20.000000000000014, 18.499999999999986, 200.0, 20.000000000000014, 196.4, -229.9000000000002, 20.000000000000014, -362.19999999999976, -3.099999999999972, 161.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 155.0, 7.399999999999965, 1.0999999999999865, 13.699999999999964, 20.000000000000014, 197.0, 20.000000000000014, 176.0, -78.7000000000004, 177.5, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 34.40000000000014, 24.50000000000009, 11.599999999999964, 155.0, 20.000000000000014, 20.000000000000014, 161.0, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 83.89999999999998, 20.000000000000014, 13.699999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 185.0, 20.000000000000014, 200.0, 20.000000000000014, 59.59999999999996, 182.0, 20.000000000000014, 170.0, 109.09999999999998, 193.7, 182.0, 20.000000000000014, 175.7, 83.89999999999998, 20.000000000000014, 173.0, 200.0, 173.0, 158.0, 197.0, 185.0, 158.6, 200.0, -0.9999999999999846, 197.0, 20.000000000000014, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 200.0, 128.89999999999998, -38.799999999999756, 174.8, 20.000000000000014, 200.0, 170.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 124.39999999999999, 200.0, -5.199999999999962, 20.000000000000014, 146.0, -3.0999999999999757, 158.0, -19.899999999999743, 167.0, 197.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 194.0, -1.0000000000000098, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.299999999999969, 20.000000000000014, 161.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 167.0, 176.0, 200.0, 200.0, 161.0, 9.499999999999964, 194.0, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 20.000000000000014, 197.0, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 20.000000000000014, 168.2, 20.000000000000014, 20.000000000000014, 151.4, 200.0, 176.0, 20.000000000000014, 133.7, 163.1, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, -343.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 200.0, 3.1999999999999615, 161.6, 20.000000000000014, 17.899999999999988], "policy_predator_policy_reward": [11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 70.0, 0.0, 0.0, 162.0, 0.0, 0.0, 9.0, 0.0, 19.0, 7.0, 0.0, 0.0, 119.0, 0.0, 182.0, 11.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 18.0, 9.0, 0.0, 3.0, 0.0, 0.0, 1.0, 24.0, 37.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 19.0, 0.0, 0.0, 5.0, 16.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 9.0, 9.0, 0.0, 0.0, 9.0, 14.0, 0.0, 5.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 8.0, 0.0, 16.0, 0.0, 0.0, 20.0, 27.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 11.0, 0.0, 12.0, 14.0, 9.0, 9.0, 16.0, 17.0, 18.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 13.0, 8.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 7.0, 6.0, 8.0, 0.0, 0.0, 15.0, 3.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 5.0, 14.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 188.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 200.0, 114.0, 0.0, 0.0, 8.0, 0.0, 0.0, 19.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8559348509533912, "mean_inference_ms": 2.4748659227469174, "mean_action_processing_ms": 0.37774436995447114, "mean_env_wait_ms": 0.3092194493351908, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006673097610473633, "StateBufferConnector_ms": 0.003312230110168457, "ViewRequirementAgentConnector_ms": 0.18402433395385742}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -172.30000000000078, "episode_return_mean": 155.9989999999997, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 303.93877809416045, "num_env_steps_trained_throughput_per_sec": 303.93877809416045, "timesteps_total": 712000, "num_env_steps_sampled_lifetime": 712000, "num_agent_steps_sampled_lifetime": 2848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2848000, "timers": {"training_iteration_time_ms": 13278.167, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13278.102, "sample_time_ms": 2824.331, "learn_time_ms": 10429.138, "learn_throughput": 383.541, "synch_weights_time_ms": 21.019}, "counters": {"num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "done": false, "training_iteration": 178, "trial_id": "04dec_00002", "date": "2024-08-13_17-02-27", "timestamp": 1723582947, "time_this_iter_s": 13.211788892745972, "time_total_s": 2373.3838441371918, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b061a9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2373.3838441371918, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 66.87222222222222, "ram_util_percent": 83.53333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7680016314384168, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.9324890571296531, "policy_loss": -0.0006917382783882281, "vf_loss": 1.9331807939148453, "vf_explained_var": 0.0006411187232486785, "kl": 0.00755679580267803, "entropy": 0.38763627853027727, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 337365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 24.360734680216147, "cur_kl_coeff": 0.0494301273864806, "cur_lr": 0.00010000000000000003, "total_loss": 4.024195972321525, "policy_loss": -0.022534728187466505, "vf_loss": 4.0416063100572615, "vf_explained_var": 0.34163637549158127, "kl": 0.10366929823966636, "entropy": 0.22678808609329204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 337365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -338.1, "episode_reward_mean": 160.83399999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 69.31700000000001, "predator_policy": 11.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [217.99999999999926, 158.29999999999956, 197.49999999999937, 208.99999999999932, 40.0000000000003, 61.90000000000029, 185.59999999999943, 40.0000000000003, 195.69999999999936, 40.0000000000003, 207.99999999999932, 103.89999999999995, 36.70000000000025, 40.0000000000003, 37.80000000000027, 209.9999999999993, 219.99999999999926, 247.59999999999957, 199.99999999999935, 302.79999999999984, 201.99999999999935, 274.5999999999999, 201.99999999999935, 382.0, 369.0, 348.6, 208.99999999999932, 217.99999999999926, 193.49999999999937, 22.400000000000013, 219.99999999999926, 137.0999999999997, 194.7999999999994, 380.0, 209.99999999999932, 40.0000000000003, 40.0000000000003, 138.29999999999964, 206.79999999999933, 188.9999999999994, 179.89999999999947, 182.09999999999945, 398.0, 219.99999999999926, 40.0000000000003, 205.99999999999932, 37.80000000000027, 40.0000000000003, 32.300000000000196, 382.0, 219.99999999999926, 36.70000000000025, 40.0000000000003, 204.99999999999935, 357.0, 400.0, 188.4999999999994, 215.99999999999926, 207.89999999999932, 40.0000000000003, 217.99999999999926, 218.89999999999927, 219.99999999999926, 195.1999999999994, 171.3999999999995, 384.0, 172.6999999999995, 367.1, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, -150.6000000000005, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.99999999999932, 114.0, 40.0000000000003, 211.1999999999993, 183.79999999999936, 38.90000000000028, 400.0, -4.30000000000002, 221.79999999999924, 219.99999999999926, -139.3000000000004, 250.7, 205.69999999999933, 40.0000000000003, 40.0000000000003, 177.99999999999946, 16.000000000000092, 40.0000000000003, 30.100000000000147, -338.1, 33.400000000000205, 361.0, 338.7, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [197.0, 20.000000000000014, 176.0, -78.7000000000004, 177.5, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 34.40000000000014, 24.50000000000009, 11.599999999999964, 155.0, 20.000000000000014, 20.000000000000014, 161.0, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 83.89999999999998, 20.000000000000014, 13.699999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 185.0, 20.000000000000014, 200.0, 20.000000000000014, 59.59999999999996, 182.0, 20.000000000000014, 170.0, 109.09999999999998, 193.7, 182.0, 20.000000000000014, 175.7, 83.89999999999998, 20.000000000000014, 173.0, 200.0, 173.0, 158.0, 197.0, 185.0, 158.6, 200.0, -0.9999999999999846, 197.0, 20.000000000000014, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 200.0, 128.89999999999998, -38.799999999999756, 174.8, 20.000000000000014, 200.0, 170.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 124.39999999999999, 200.0, -5.199999999999962, 20.000000000000014, 146.0, -3.0999999999999757, 158.0, -19.899999999999743, 167.0, 197.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 194.0, -1.0000000000000098, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.299999999999969, 20.000000000000014, 161.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 167.0, 176.0, 200.0, 200.0, 161.0, 9.499999999999964, 194.0, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 20.000000000000014, 197.0, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 20.000000000000014, 168.2, 20.000000000000014, 20.000000000000014, 151.4, 200.0, 176.0, 20.000000000000014, 133.7, 163.1, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, -343.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 200.0, 3.1999999999999615, 161.6, 20.000000000000014, 17.899999999999988, 200.0, 200.0, -133.0, 13.699999999999964, 21.80000000000004, 200.0, 20.000000000000014, 200.0, 20.000000000000014, -322.3, -160.3, 188.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, -393.7, -336.4, 20.000000000000014, 7.399999999999967, 146.0, 182.0, 179.0, 133.7, 20.000000000000014, 200.0], "policy_predator_policy_reward": [0.0, 1.0, 24.0, 37.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 19.0, 0.0, 0.0, 5.0, 16.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 9.0, 9.0, 0.0, 0.0, 9.0, 14.0, 0.0, 5.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 8.0, 0.0, 16.0, 0.0, 0.0, 20.0, 27.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 11.0, 0.0, 12.0, 14.0, 9.0, 9.0, 16.0, 17.0, 18.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 13.0, 8.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 7.0, 6.0, 8.0, 0.0, 0.0, 15.0, 3.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 5.0, 14.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 188.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 200.0, 114.0, 0.0, 0.0, 8.0, 0.0, 0.0, 19.0, 1.0, 0.0, 0.0, 0.0, 114.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 163.0, 109.0, 114.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 3.0, 0.0, 102.0, 0.0, 0.0, 0.0, 9.0, 200.0, 192.0, 6.0, 0.0, 15.0, 18.0, 8.0, 18.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8577209035688323, "mean_inference_ms": 2.482672817092782, "mean_action_processing_ms": 0.37818350992186306, "mean_env_wait_ms": 0.30975229857210357, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005475282669067383, "StateBufferConnector_ms": 0.0033092498779296875, "ViewRequirementAgentConnector_ms": 0.19584393501281738}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -338.1, "episode_return_mean": 160.83399999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.90567507830076, "num_env_steps_trained_throughput_per_sec": 311.90567507830076, "timesteps_total": 716000, "num_env_steps_sampled_lifetime": 716000, "num_agent_steps_sampled_lifetime": 2864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2864000, "timers": {"training_iteration_time_ms": 13162.463, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13162.398, "sample_time_ms": 2733.168, "learn_time_ms": 10404.544, "learn_throughput": 384.447, "synch_weights_time_ms": 20.859}, "counters": {"num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "done": false, "training_iteration": 179, "trial_id": "04dec_00002", "date": "2024-08-13_17-02-40", "timestamp": 1723582960, "time_this_iter_s": 12.880500078201294, "time_total_s": 2386.264344215393, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0724ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2386.264344215393, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 64.26842105263158, "ram_util_percent": 83.56315789473685}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.143353535676444, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 2.056157260912436, "policy_loss": -0.000472663866144127, "vf_loss": 2.056629922844115, "vf_explained_var": 0.0011836375193621117, "kl": 0.008517799049866692, "entropy": 0.36386498699270226, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 339255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.28360273497445, "cur_kl_coeff": 0.07414519107972092, "cur_lr": 0.00010000000000000003, "total_loss": 2.6869606858208064, "policy_loss": 0.0021037956145370292, "vf_loss": 2.6835793203777736, "vf_explained_var": 0.506895227091653, "kl": 0.01723062591906621, "entropy": 0.24431293673379711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 339255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -430.0, "episode_reward_mean": 146.6419999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 58.24100000000002, "predator_policy": 15.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [199.99999999999935, 302.79999999999984, 201.99999999999935, 274.5999999999999, 201.99999999999935, 382.0, 369.0, 348.6, 208.99999999999932, 217.99999999999926, 193.49999999999937, 22.400000000000013, 219.99999999999926, 137.0999999999997, 194.7999999999994, 380.0, 209.99999999999932, 40.0000000000003, 40.0000000000003, 138.29999999999964, 206.79999999999933, 188.9999999999994, 179.89999999999947, 182.09999999999945, 398.0, 219.99999999999926, 40.0000000000003, 205.99999999999932, 37.80000000000027, 40.0000000000003, 32.300000000000196, 382.0, 219.99999999999926, 36.70000000000025, 40.0000000000003, 204.99999999999935, 357.0, 400.0, 188.4999999999994, 215.99999999999926, 207.89999999999932, 40.0000000000003, 217.99999999999926, 218.89999999999927, 219.99999999999926, 195.1999999999994, 171.3999999999995, 384.0, 172.6999999999995, 367.1, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, -150.6000000000005, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.99999999999932, 114.0, 40.0000000000003, 211.1999999999993, 183.79999999999936, 38.90000000000028, 400.0, -4.30000000000002, 221.79999999999924, 219.99999999999926, -139.3000000000004, 250.7, 205.69999999999933, 40.0000000000003, 40.0000000000003, 177.99999999999946, 16.000000000000092, 40.0000000000003, 30.100000000000147, -338.1, 33.400000000000205, 361.0, 338.7, 219.99999999999926, 34.50000000000022, 25.6000000000001, 40.0000000000003, 219.99999999999926, 32.30000000000018, 40.700000000000315, 203.99999999999935, 58.000000000000185, 40.0000000000003, 30.100000000000147, -430.0, 32.00000000000019, 21.600000000000197, 37.80000000000027, 195.99999999999937, 180.69999999999973, 219.99999999999926, 47.500000000000135], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 170.0, 109.09999999999998, 193.7, 182.0, 20.000000000000014, 175.7, 83.89999999999998, 20.000000000000014, 173.0, 200.0, 173.0, 158.0, 197.0, 185.0, 158.6, 200.0, -0.9999999999999846, 197.0, 20.000000000000014, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 200.0, 128.89999999999998, -38.799999999999756, 174.8, 20.000000000000014, 200.0, 170.0, 20.000000000000014, 185.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 124.39999999999999, 200.0, -5.199999999999962, 20.000000000000014, 146.0, -3.0999999999999757, 158.0, -19.899999999999743, 167.0, 197.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 194.0, -1.0000000000000098, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.299999999999969, 20.000000000000014, 161.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 167.0, 176.0, 200.0, 200.0, 161.0, 9.499999999999964, 194.0, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 20.000000000000014, 197.0, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 20.000000000000014, 168.2, 20.000000000000014, 20.000000000000014, 151.4, 200.0, 176.0, 20.000000000000014, 133.7, 163.1, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, -343.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 200.0, 3.1999999999999615, 161.6, 20.000000000000014, 17.899999999999988, 200.0, 200.0, -133.0, 13.699999999999964, 21.80000000000004, 200.0, 20.000000000000014, 200.0, 20.000000000000014, -322.3, -160.3, 188.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, -393.7, -336.4, 20.000000000000014, 7.399999999999967, 146.0, 182.0, 179.0, 133.7, 20.000000000000014, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 5.299999999999967, 20.000000000000014, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -169.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, -370.0, -391.0, 20.000000000000014, -18.999999999999744, 5.2999999999999705, -84.7, 15.799999999999963, 20.000000000000014, 164.0, 20.000000000000014, 200.0, -154.3, 20.000000000000014, 200.0, 40.999999999999964, -23.49999999999975], "policy_predator_policy_reward": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 9.0, 9.0, 0.0, 0.0, 9.0, 14.0, 0.0, 5.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 8.0, 0.0, 16.0, 0.0, 0.0, 20.0, 27.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 11.0, 0.0, 12.0, 14.0, 9.0, 9.0, 16.0, 17.0, 18.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 13.0, 8.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 7.0, 6.0, 8.0, 0.0, 0.0, 15.0, 3.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 5.0, 14.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 188.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 200.0, 114.0, 0.0, 0.0, 8.0, 0.0, 0.0, 19.0, 1.0, 0.0, 0.0, 0.0, 114.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 163.0, 109.0, 114.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 3.0, 0.0, 102.0, 0.0, 0.0, 0.0, 9.0, 200.0, 192.0, 6.0, 0.0, 15.0, 18.0, 8.0, 18.0, 0.0, 0.0, 5.0, 0.0, 24.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 10.0, 8.0, 0.0, 111.0, 96.0, 0.0, 0.0, 9.0, 0.0, 189.0, 142.0, 16.0, 15.0, 101.0, 0.0, 0.0, 2.0, 12.0, 0.0, 82.0, 53.0, 0.0, 0.0, 8.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8593537474358248, "mean_inference_ms": 2.487954427355172, "mean_action_processing_ms": 0.378786029002918, "mean_env_wait_ms": 0.3104220103936865, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00838017463684082, "StateBufferConnector_ms": 0.0033971071243286133, "ViewRequirementAgentConnector_ms": 0.19719207286834717}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -430.0, "episode_return_mean": 146.6419999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.26023941814674, "num_env_steps_trained_throughput_per_sec": 291.26023941814674, "timesteps_total": 720000, "num_env_steps_sampled_lifetime": 720000, "num_agent_steps_sampled_lifetime": 2880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2880000, "timers": {"training_iteration_time_ms": 13227.09, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13227.025, "sample_time_ms": 2740.087, "learn_time_ms": 10462.997, "learn_throughput": 382.3, "synch_weights_time_ms": 19.815}, "counters": {"num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "done": false, "training_iteration": 180, "trial_id": "04dec_00002", "date": "2024-08-13_17-02-53", "timestamp": 1723582973, "time_this_iter_s": 13.782353162765503, "time_total_s": 2400.0466973781586, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0733700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2400.0466973781586, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 72.60526315789474, "ram_util_percent": 83.79473684210527}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9786193066015445, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.9504471498822409, "policy_loss": -0.0010004349960822355, "vf_loss": 1.9514475871961583, "vf_explained_var": 0.0017170824071086903, "kl": 0.010072567399829997, "entropy": 0.3596592874911727, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 341145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.337866846657302, "cur_kl_coeff": 0.07414519107972092, "cur_lr": 0.00010000000000000003, "total_loss": 2.2047747480175484, "policy_loss": -0.0018080537668158296, "vf_loss": 2.2040082224462396, "vf_explained_var": 0.2326289351024325, "kl": 0.034723515118535206, "entropy": 0.3012536304337638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 341145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -430.0, "episode_reward_mean": 121.54199999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 43.97600000000001, "predator_policy": 16.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 138.29999999999964, 206.79999999999933, 188.9999999999994, 179.89999999999947, 182.09999999999945, 398.0, 219.99999999999926, 40.0000000000003, 205.99999999999932, 37.80000000000027, 40.0000000000003, 32.300000000000196, 382.0, 219.99999999999926, 36.70000000000025, 40.0000000000003, 204.99999999999935, 357.0, 400.0, 188.4999999999994, 215.99999999999926, 207.89999999999932, 40.0000000000003, 217.99999999999926, 218.89999999999927, 219.99999999999926, 195.1999999999994, 171.3999999999995, 384.0, 172.6999999999995, 367.1, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, -150.6000000000005, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.99999999999932, 114.0, 40.0000000000003, 211.1999999999993, 183.79999999999936, 38.90000000000028, 400.0, -4.30000000000002, 221.79999999999924, 219.99999999999926, -139.3000000000004, 250.7, 205.69999999999933, 40.0000000000003, 40.0000000000003, 177.99999999999946, 16.000000000000092, 40.0000000000003, 30.100000000000147, -338.1, 33.400000000000205, 361.0, 338.7, 219.99999999999926, 34.50000000000022, 25.6000000000001, 40.0000000000003, 219.99999999999926, 32.30000000000018, 40.700000000000315, 203.99999999999935, 58.000000000000185, 40.0000000000003, 30.100000000000147, -430.0, 32.00000000000019, 21.600000000000197, 37.80000000000027, 195.99999999999937, 180.69999999999973, 219.99999999999926, 47.500000000000135, 33.400000000000205, 36.80000000000025, 212.69999999999928, 36.70000000000025, 17.19999999999995, 35.600000000000236, 21.900000000000006, 37.00000000000024, 213.69999999999928, 31.200000000000166, 219.99999999999926, 170.09999999999948, 211.8999999999993, -151.00000000000054, 42.20000000000033, 38.90000000000028, 356.0, 31.500000000000185], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -3.099999999999958, 124.39999999999999, 200.0, -5.199999999999962, 20.000000000000014, 146.0, -3.0999999999999757, 158.0, -19.899999999999743, 167.0, 197.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 194.0, -1.0000000000000098, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.299999999999969, 20.000000000000014, 161.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 167.0, 176.0, 200.0, 200.0, 161.0, 9.499999999999964, 194.0, 20.000000000000014, -3.099999999999958, 200.0, 20.000000000000014, 20.000000000000014, 197.0, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 20.000000000000014, 168.2, 20.000000000000014, 20.000000000000014, 151.4, 200.0, 176.0, 20.000000000000014, 133.7, 163.1, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, -343.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 200.0, 3.1999999999999615, 161.6, 20.000000000000014, 17.899999999999988, 200.0, 200.0, -133.0, 13.699999999999964, 21.80000000000004, 200.0, 20.000000000000014, 200.0, 20.000000000000014, -322.3, -160.3, 188.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, -393.7, -336.4, 20.000000000000014, 7.399999999999967, 146.0, 182.0, 179.0, 133.7, 20.000000000000014, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 5.299999999999967, 20.000000000000014, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -169.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, -370.0, -391.0, 20.000000000000014, -18.999999999999744, 5.2999999999999705, -84.7, 15.799999999999963, 20.000000000000014, 164.0, 20.000000000000014, 200.0, -154.3, 20.000000000000014, 200.0, 40.999999999999964, -23.49999999999975, 7.399999999999965, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 200.0, -7.299999999999891, 13.699999999999966, 20.000000000000014, -49.299999999999805, 9.499999999999968, 20.000000000000014, 11.599999999999966, -18.099999999999746, 20.000000000000014, 20.000000000000014, -58.000000000000014, 193.7, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, 146.3, 21.80000000000004, 20.000000000000014, 191.9, -346.0, -18.99999999999975, 17.899999999999984, 17.299999999999976, 17.899999999999988, 20.000000000000014, 164.0, 170.0, -29.49999999999978, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 6.0, 11.0, 0.0, 12.0, 14.0, 9.0, 9.0, 16.0, 17.0, 18.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 13.0, 8.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 7.0, 6.0, 8.0, 0.0, 0.0, 15.0, 3.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 5.0, 14.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 188.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 200.0, 114.0, 0.0, 0.0, 8.0, 0.0, 0.0, 19.0, 1.0, 0.0, 0.0, 0.0, 114.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 163.0, 109.0, 114.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 3.0, 0.0, 102.0, 0.0, 0.0, 0.0, 9.0, 200.0, 192.0, 6.0, 0.0, 15.0, 18.0, 8.0, 18.0, 0.0, 0.0, 5.0, 0.0, 24.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 10.0, 8.0, 0.0, 111.0, 96.0, 0.0, 0.0, 9.0, 0.0, 189.0, 142.0, 16.0, 15.0, 101.0, 0.0, 0.0, 2.0, 12.0, 0.0, 82.0, 53.0, 0.0, 0.0, 8.0, 22.0, 0.0, 6.0, 12.0, 10.0, 13.0, 7.0, 0.0, 3.0, 32.0, 25.0, 0.0, 4.0, 3.0, 17.0, 37.0, 38.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 25.0, 189.0, 7.0, 0.0, 1.0, 0.0, 12.0, 10.0, 23.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8610686522991838, "mean_inference_ms": 2.4938216213918962, "mean_action_processing_ms": 0.37948847280423037, "mean_env_wait_ms": 0.31114045942376367, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008947491645812988, "StateBufferConnector_ms": 0.0035299062728881836, "ViewRequirementAgentConnector_ms": 0.18049955368041992}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -430.0, "episode_return_mean": 121.54199999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.0584101341995, "num_env_steps_trained_throughput_per_sec": 290.0584101341995, "timesteps_total": 724000, "num_env_steps_sampled_lifetime": 724000, "num_agent_steps_sampled_lifetime": 2896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2896000, "timers": {"training_iteration_time_ms": 13303.046, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13302.978, "sample_time_ms": 2771.624, "learn_time_ms": 10506.717, "learn_throughput": 380.709, "synch_weights_time_ms": 20.271}, "counters": {"num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "done": false, "training_iteration": 181, "trial_id": "04dec_00002", "date": "2024-08-13_17-03-07", "timestamp": 1723582987, "time_this_iter_s": 13.821668863296509, "time_total_s": 2413.868366241455, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0733940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2413.868366241455, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 70.4, "ram_util_percent": 83.755}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3838307030932615, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.9386209259588252, "policy_loss": 1.2485789154808988e-05, "vf_loss": 1.938608440583345, "vf_explained_var": 0.00047255931077180087, "kl": 0.007977679834860881, "entropy": 0.3919492110531166, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 343035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.828037170947542, "cur_kl_coeff": 0.11121778661958139, "cur_lr": 0.00010000000000000003, "total_loss": 2.195523429799963, "policy_loss": -0.0017651871401107026, "vf_loss": 2.196365075451987, "vf_explained_var": 0.2066921700245489, "kl": 0.008303929999618829, "entropy": 0.20014105286626588, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 343035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -430.0, "episode_reward_mean": 98.48599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 25.763000000000005, "predator_policy": 23.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 217.99999999999926, 218.89999999999927, 219.99999999999926, 195.1999999999994, 171.3999999999995, 384.0, 172.6999999999995, 367.1, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, -150.6000000000005, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.99999999999932, 114.0, 40.0000000000003, 211.1999999999993, 183.79999999999936, 38.90000000000028, 400.0, -4.30000000000002, 221.79999999999924, 219.99999999999926, -139.3000000000004, 250.7, 205.69999999999933, 40.0000000000003, 40.0000000000003, 177.99999999999946, 16.000000000000092, 40.0000000000003, 30.100000000000147, -338.1, 33.400000000000205, 361.0, 338.7, 219.99999999999926, 34.50000000000022, 25.6000000000001, 40.0000000000003, 219.99999999999926, 32.30000000000018, 40.700000000000315, 203.99999999999935, 58.000000000000185, 40.0000000000003, 30.100000000000147, -430.0, 32.00000000000019, 21.600000000000197, 37.80000000000027, 195.99999999999937, 180.69999999999973, 219.99999999999926, 47.500000000000135, 33.400000000000205, 36.80000000000025, 212.69999999999928, 36.70000000000025, 17.19999999999995, 35.600000000000236, 21.900000000000006, 37.00000000000024, 213.69999999999928, 31.200000000000166, 219.99999999999926, 170.09999999999948, 211.8999999999993, -151.00000000000054, 42.20000000000033, 38.90000000000028, 356.0, 31.500000000000185, 38.90000000000028, 40.0000000000003, 30.10000000000015, 194.0, 194.39999999999938, 200.99999999999935, 27.00000000000009, 37.600000000000264, 47.200000000000145, 16.89999999999993, 372.0, 33.400000000000205, 40.0000000000003, 400.0, 22.400000000000013, -32.59999999999994, -180.00000000000065, 192.09999999999937, 40.0000000000003, -174.00000000000063, 71.50000000000007, 37.80000000000027, 207.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 197.0, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 20.000000000000014, 168.2, 20.000000000000014, 20.000000000000014, 151.4, 200.0, 176.0, 20.000000000000014, 133.7, 163.1, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, -343.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 200.0, 3.1999999999999615, 161.6, 20.000000000000014, 17.899999999999988, 200.0, 200.0, -133.0, 13.699999999999964, 21.80000000000004, 200.0, 20.000000000000014, 200.0, 20.000000000000014, -322.3, -160.3, 188.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, -393.7, -336.4, 20.000000000000014, 7.399999999999967, 146.0, 182.0, 179.0, 133.7, 20.000000000000014, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 5.299999999999967, 20.000000000000014, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -169.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, -370.0, -391.0, 20.000000000000014, -18.999999999999744, 5.2999999999999705, -84.7, 15.799999999999963, 20.000000000000014, 164.0, 20.000000000000014, 200.0, -154.3, 20.000000000000014, 200.0, 40.999999999999964, -23.49999999999975, 7.399999999999965, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 200.0, -7.299999999999891, 13.699999999999966, 20.000000000000014, -49.299999999999805, 9.499999999999968, 20.000000000000014, 11.599999999999966, -18.099999999999746, 20.000000000000014, 20.000000000000014, -58.000000000000014, 193.7, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, 146.3, 21.80000000000004, 20.000000000000014, 191.9, -346.0, -18.99999999999975, 17.899999999999984, 17.299999999999976, 17.899999999999988, 20.000000000000014, 164.0, 170.0, -29.49999999999978, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999759, 182.0, -358.0, 200.0, -34.59999999999979, 20.000000000000014, 170.0, 3.1999999999999615, 15.799999999999963, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -172.0, 3.1999999999999686, -7.2999999999999226, 158.0, 200.0, 20.000000000000014, 7.399999999999967, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 5.299999999999965, 1.0999999999999723, -277.5999999999999, 20.000000000000014, 20.000000000000014, -400.0, 146.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, -380.5, 9.499999999999966, 9.499999999999964, -142.0, 15.799999999999963, 20.000000000000014, 182.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 5.0, 14.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 188.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 200.0, 114.0, 0.0, 0.0, 8.0, 0.0, 0.0, 19.0, 1.0, 0.0, 0.0, 0.0, 114.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 163.0, 109.0, 114.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 3.0, 0.0, 102.0, 0.0, 0.0, 0.0, 9.0, 200.0, 192.0, 6.0, 0.0, 15.0, 18.0, 8.0, 18.0, 0.0, 0.0, 5.0, 0.0, 24.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 10.0, 8.0, 0.0, 111.0, 96.0, 0.0, 0.0, 9.0, 0.0, 189.0, 142.0, 16.0, 15.0, 101.0, 0.0, 0.0, 2.0, 12.0, 0.0, 82.0, 53.0, 0.0, 0.0, 8.0, 22.0, 0.0, 6.0, 12.0, 10.0, 13.0, 7.0, 0.0, 3.0, 32.0, 25.0, 0.0, 4.0, 3.0, 17.0, 37.0, 38.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 25.0, 189.0, 7.0, 0.0, 1.0, 0.0, 12.0, 10.0, 23.0, 18.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 185.0, 185.0, 19.0, 10.0, 10.0, 1.0, 8.0, 0.0, 2.0, 4.0, 107.0, 109.0, 4.0, 17.0, 0.0, 14.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 141.0, 84.0, 200.0, 0.0, 0.0, 18.0, 0.0, 0.0, 192.0, 5.0, 110.0, 94.0, 0.0, 2.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8629207197196442, "mean_inference_ms": 2.498344047283124, "mean_action_processing_ms": 0.3803736117062341, "mean_env_wait_ms": 0.31157095406657953, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009802460670471191, "StateBufferConnector_ms": 0.003652215003967285, "ViewRequirementAgentConnector_ms": 0.17853295803070068}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -430.0, "episode_return_mean": 98.48599999999989, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 328.3988985419214, "num_env_steps_trained_throughput_per_sec": 328.3988985419214, "timesteps_total": 728000, "num_env_steps_sampled_lifetime": 728000, "num_agent_steps_sampled_lifetime": 2912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2912000, "timers": {"training_iteration_time_ms": 13232.562, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13232.504, "sample_time_ms": 2668.055, "learn_time_ms": 10538.457, "learn_throughput": 379.562, "synch_weights_time_ms": 21.2}, "counters": {"num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "done": false, "training_iteration": 182, "trial_id": "04dec_00002", "date": "2024-08-13_17-03-20", "timestamp": 1723583000, "time_this_iter_s": 12.22589898109436, "time_total_s": 2426.0942652225494, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b06fcd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2426.0942652225494, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 67.47058823529412, "ram_util_percent": 83.37058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5507254054385518, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.48852335070333786, "policy_loss": 0.00014363132323576974, "vf_loss": 0.4883797190869079, "vf_explained_var": 0.006615387289612381, "kl": 0.009220811617919317, "entropy": 0.39359899696218903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 344925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.44244499947659, "cur_kl_coeff": 0.11121778661958139, "cur_lr": 0.00010000000000000003, "total_loss": 1.7295640344342227, "policy_loss": -0.010384595117571139, "vf_loss": 1.7376940274049366, "vf_explained_var": 0.9313112043199085, "kl": 0.02027196673342264, "entropy": 0.16636762303650063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 344925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -430.0, "episode_reward_mean": 90.68299999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 24.066500000000016, "predator_policy": 21.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.90000000000028, 400.0, -4.30000000000002, 221.79999999999924, 219.99999999999926, -139.3000000000004, 250.7, 205.69999999999933, 40.0000000000003, 40.0000000000003, 177.99999999999946, 16.000000000000092, 40.0000000000003, 30.100000000000147, -338.1, 33.400000000000205, 361.0, 338.7, 219.99999999999926, 34.50000000000022, 25.6000000000001, 40.0000000000003, 219.99999999999926, 32.30000000000018, 40.700000000000315, 203.99999999999935, 58.000000000000185, 40.0000000000003, 30.100000000000147, -430.0, 32.00000000000019, 21.600000000000197, 37.80000000000027, 195.99999999999937, 180.69999999999973, 219.99999999999926, 47.500000000000135, 33.400000000000205, 36.80000000000025, 212.69999999999928, 36.70000000000025, 17.19999999999995, 35.600000000000236, 21.900000000000006, 37.00000000000024, 213.69999999999928, 31.200000000000166, 219.99999999999926, 170.09999999999948, 211.8999999999993, -151.00000000000054, 42.20000000000033, 38.90000000000028, 356.0, 31.500000000000185, 38.90000000000028, 40.0000000000003, 30.10000000000015, 194.0, 194.39999999999938, 200.99999999999935, 27.00000000000009, 37.600000000000264, 47.200000000000145, 16.89999999999993, 372.0, 33.400000000000205, 40.0000000000003, 400.0, 22.400000000000013, -32.59999999999994, -180.00000000000065, 192.09999999999937, 40.0000000000003, -174.00000000000063, 71.50000000000007, 37.80000000000027, 207.99999999999926, 40.0000000000003, 40.0000000000003, 203.99999999999935, 217.99999999999926, 174.2999999999995, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 35.600000000000236, 25.400000000000066, 368.5, 40.0000000000003, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 300.1, 29.70000000000014, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 17.899999999999988, 200.0, 200.0, -133.0, 13.699999999999964, 21.80000000000004, 200.0, 20.000000000000014, 200.0, 20.000000000000014, -322.3, -160.3, 188.0, 200.0, -7.299999999999894, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, -393.7, -336.4, 20.000000000000014, 7.399999999999967, 146.0, 182.0, 179.0, 133.7, 20.000000000000014, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 5.299999999999967, 20.000000000000014, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -169.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, -370.0, -391.0, 20.000000000000014, -18.999999999999744, 5.2999999999999705, -84.7, 15.799999999999963, 20.000000000000014, 164.0, 20.000000000000014, 200.0, -154.3, 20.000000000000014, 200.0, 40.999999999999964, -23.49999999999975, 7.399999999999965, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 200.0, -7.299999999999891, 13.699999999999966, 20.000000000000014, -49.299999999999805, 9.499999999999968, 20.000000000000014, 11.599999999999966, -18.099999999999746, 20.000000000000014, 20.000000000000014, -58.000000000000014, 193.7, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, 146.3, 21.80000000000004, 20.000000000000014, 191.9, -346.0, -18.99999999999975, 17.899999999999984, 17.299999999999976, 17.899999999999988, 20.000000000000014, 164.0, 170.0, -29.49999999999978, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999759, 182.0, -358.0, 200.0, -34.59999999999979, 20.000000000000014, 170.0, 3.1999999999999615, 15.799999999999963, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -172.0, 3.1999999999999686, -7.2999999999999226, 158.0, 200.0, 20.000000000000014, 7.399999999999967, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 5.299999999999965, 1.0999999999999723, -277.5999999999999, 20.000000000000014, 20.000000000000014, -400.0, 146.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, -380.5, 9.499999999999966, 9.499999999999964, -142.0, 15.799999999999963, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 197.0, 20.000000000000014, 155.0, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 147.5, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 55.099999999999994, -1.2999999999999847, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [1.0, 0.0, 0.0, 0.0, 114.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 163.0, 109.0, 114.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 3.0, 0.0, 102.0, 0.0, 0.0, 0.0, 9.0, 200.0, 192.0, 6.0, 0.0, 15.0, 18.0, 8.0, 18.0, 0.0, 0.0, 5.0, 0.0, 24.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 10.0, 8.0, 0.0, 111.0, 96.0, 0.0, 0.0, 9.0, 0.0, 189.0, 142.0, 16.0, 15.0, 101.0, 0.0, 0.0, 2.0, 12.0, 0.0, 82.0, 53.0, 0.0, 0.0, 8.0, 22.0, 0.0, 6.0, 12.0, 10.0, 13.0, 7.0, 0.0, 3.0, 32.0, 25.0, 0.0, 4.0, 3.0, 17.0, 37.0, 38.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 25.0, 189.0, 7.0, 0.0, 1.0, 0.0, 12.0, 10.0, 23.0, 18.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 185.0, 185.0, 19.0, 10.0, 10.0, 1.0, 8.0, 0.0, 2.0, 4.0, 107.0, 109.0, 4.0, 17.0, 0.0, 14.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 141.0, 84.0, 200.0, 0.0, 0.0, 18.0, 0.0, 0.0, 192.0, 5.0, 110.0, 94.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 23.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 16.0, 3.0, 7.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 45.0, 10.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.863351798063844, "mean_inference_ms": 2.5019495922674846, "mean_action_processing_ms": 0.38038375368246624, "mean_env_wait_ms": 0.3121535207961487, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012698173522949219, "StateBufferConnector_ms": 0.004147171974182129, "ViewRequirementAgentConnector_ms": 0.17473208904266357}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -430.0, "episode_return_mean": 90.68299999999994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.13800098667906, "num_env_steps_trained_throughput_per_sec": 324.13800098667906, "timesteps_total": 732000, "num_env_steps_sampled_lifetime": 732000, "num_agent_steps_sampled_lifetime": 2928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2928000, "timers": {"training_iteration_time_ms": 13124.916, "restore_workers_time_ms": 0.048, "training_step_time_ms": 13124.804, "sample_time_ms": 2555.697, "learn_time_ms": 10547.924, "learn_throughput": 379.222, "synch_weights_time_ms": 16.67}, "counters": {"num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "done": false, "training_iteration": 183, "trial_id": "04dec_00002", "date": "2024-08-13_17-03-32", "timestamp": 1723583012, "time_this_iter_s": 12.394826889038086, "time_total_s": 2438.4890921115875, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0724c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2438.4890921115875, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 64.41666666666667, "ram_util_percent": 83.51666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.549214719724718, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.5330504596233367, "policy_loss": 0.0005726697812812827, "vf_loss": 1.5324777851659785, "vf_explained_var": 0.00010126229947206205, "kl": 0.009436234487175997, "entropy": 0.3942597908948464, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 346815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.316545923235555, "cur_kl_coeff": 0.16682667992937214, "cur_lr": 0.00010000000000000003, "total_loss": 2.8834281518976526, "policy_loss": -0.0018401380986832673, "vf_loss": 2.8827540451887423, "vf_explained_var": 0.43493680783680505, "kl": 0.015071015631522182, "entropy": 0.25362363268458654, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 346815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -430.0, "episode_reward_mean": 85.42299999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 23.43650000000001, "predator_policy": 19.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 34.50000000000022, 25.6000000000001, 40.0000000000003, 219.99999999999926, 32.30000000000018, 40.700000000000315, 203.99999999999935, 58.000000000000185, 40.0000000000003, 30.100000000000147, -430.0, 32.00000000000019, 21.600000000000197, 37.80000000000027, 195.99999999999937, 180.69999999999973, 219.99999999999926, 47.500000000000135, 33.400000000000205, 36.80000000000025, 212.69999999999928, 36.70000000000025, 17.19999999999995, 35.600000000000236, 21.900000000000006, 37.00000000000024, 213.69999999999928, 31.200000000000166, 219.99999999999926, 170.09999999999948, 211.8999999999993, -151.00000000000054, 42.20000000000033, 38.90000000000028, 356.0, 31.500000000000185, 38.90000000000028, 40.0000000000003, 30.10000000000015, 194.0, 194.39999999999938, 200.99999999999935, 27.00000000000009, 37.600000000000264, 47.200000000000145, 16.89999999999993, 372.0, 33.400000000000205, 40.0000000000003, 400.0, 22.400000000000013, -32.59999999999994, -180.00000000000065, 192.09999999999937, 40.0000000000003, -174.00000000000063, 71.50000000000007, 37.80000000000027, 207.99999999999926, 40.0000000000003, 40.0000000000003, 203.99999999999935, 217.99999999999926, 174.2999999999995, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 35.600000000000236, 25.400000000000066, 368.5, 40.0000000000003, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 300.1, 29.70000000000014, 40.0000000000003, 13.59999999999997, 31.60000000000018, 34.50000000000022, 378.0, 40.0000000000003, 27.700000000000124, 40.0000000000003, 27.900000000000116, 27.90000000000011, 47.30000000000042, 200.99999999999935, 164.1999999999995, 38.20000000000027, 29.000000000000128, 38.90000000000028, 40.0000000000003, 175.1, 51.70000000000049], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 9.499999999999964, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 5.299999999999967, 20.000000000000014, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -169.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, -370.0, -391.0, 20.000000000000014, -18.999999999999744, 5.2999999999999705, -84.7, 15.799999999999963, 20.000000000000014, 164.0, 20.000000000000014, 200.0, -154.3, 20.000000000000014, 200.0, 40.999999999999964, -23.49999999999975, 7.399999999999965, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 200.0, -7.299999999999891, 13.699999999999966, 20.000000000000014, -49.299999999999805, 9.499999999999968, 20.000000000000014, 11.599999999999966, -18.099999999999746, 20.000000000000014, 20.000000000000014, -58.000000000000014, 193.7, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, 146.3, 21.80000000000004, 20.000000000000014, 191.9, -346.0, -18.99999999999975, 17.899999999999984, 17.299999999999976, 17.899999999999988, 20.000000000000014, 164.0, 170.0, -29.49999999999978, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999759, 182.0, -358.0, 200.0, -34.59999999999979, 20.000000000000014, 170.0, 3.1999999999999615, 15.799999999999963, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -172.0, 3.1999999999999686, -7.2999999999999226, 158.0, 200.0, 20.000000000000014, 7.399999999999967, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 5.299999999999965, 1.0999999999999723, -277.5999999999999, 20.000000000000014, 20.000000000000014, -400.0, 146.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, -380.5, 9.499999999999966, 9.499999999999964, -142.0, 15.799999999999963, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 197.0, 20.000000000000014, 155.0, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 147.5, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 55.099999999999994, -1.2999999999999847, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 17.899999999999988, -31.299999999999763, 15.799999999999962, 13.699999999999966, 167.0, 200.0, 20.000000000000014, 20.000000000000014, -1.0000000000000204, 13.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, -3.099999999999958, 20.000000000000014, 20.000000000000014, -3.6999999999999797, 188.0, -0.9999999999999881, -161.8000000000006, 200.0, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 161.0, -370.9, 20.000000000000014, 31.700000000000212], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 0.0, 24.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 10.0, 8.0, 0.0, 111.0, 96.0, 0.0, 0.0, 9.0, 0.0, 189.0, 142.0, 16.0, 15.0, 101.0, 0.0, 0.0, 2.0, 12.0, 0.0, 82.0, 53.0, 0.0, 0.0, 8.0, 22.0, 0.0, 6.0, 12.0, 10.0, 13.0, 7.0, 0.0, 3.0, 32.0, 25.0, 0.0, 4.0, 3.0, 17.0, 37.0, 38.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 25.0, 189.0, 7.0, 0.0, 1.0, 0.0, 12.0, 10.0, 23.0, 18.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 185.0, 185.0, 19.0, 10.0, 10.0, 1.0, 8.0, 0.0, 2.0, 4.0, 107.0, 109.0, 4.0, 17.0, 0.0, 14.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 141.0, 84.0, 200.0, 0.0, 0.0, 18.0, 0.0, 0.0, 192.0, 5.0, 110.0, 94.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 23.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 16.0, 3.0, 7.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 45.0, 10.0, 1.0, 0.0, 0.0, 0.0, 24.0, 28.0, 17.0, 5.0, 0.0, 0.0, 11.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 11.0, 0.0, 11.0, 0.0, 16.0, 15.0, 10.0, 4.0, 76.0, 50.0, 8.0, 7.0, 0.0, 10.0, 0.0, 1.0, 0.0, 0.0, 185.0, 200.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8638248307430927, "mean_inference_ms": 2.5038536773909605, "mean_action_processing_ms": 0.38046082471270837, "mean_env_wait_ms": 0.3123664923255701, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01554417610168457, "StateBufferConnector_ms": 0.0042906999588012695, "ViewRequirementAgentConnector_ms": 0.170143723487854}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -430.0, "episode_return_mean": 85.42299999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.67759531888026, "num_env_steps_trained_throughput_per_sec": 269.67759531888026, "timesteps_total": 736000, "num_env_steps_sampled_lifetime": 736000, "num_agent_steps_sampled_lifetime": 2944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2944000, "timers": {"training_iteration_time_ms": 13284.79, "restore_workers_time_ms": 0.048, "training_step_time_ms": 13284.679, "sample_time_ms": 2481.578, "learn_time_ms": 10782.512, "learn_throughput": 370.971, "synch_weights_time_ms": 16.044}, "counters": {"num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "done": false, "training_iteration": 184, "trial_id": "04dec_00002", "date": "2024-08-13_17-03-47", "timestamp": 1723583027, "time_this_iter_s": 14.871404886245728, "time_total_s": 2453.3604969978333, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b061aee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2453.3604969978333, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 79.10000000000001, "ram_util_percent": 83.36190476190475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0662549506734917, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 2.119381038284806, "policy_loss": -0.00017683706985461333, "vf_loss": 2.119557880629938, "vf_explained_var": 0.0019038014311008353, "kl": 0.005411257262466562, "entropy": 0.31799139082431793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 348705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.079908142928725, "cur_kl_coeff": 0.16682667992937214, "cur_lr": 0.00010000000000000003, "total_loss": 3.4890958169780713, "policy_loss": -0.026238254659498732, "vf_loss": 3.5086014763388054, "vf_explained_var": 0.3294249760410773, "kl": 0.04035684801691491, "entropy": 0.2613420042253676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 348705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -189.90000000000074, "episode_reward_mean": 84.53999999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 22.475000000000012, "predator_policy": 19.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.500000000000135, 33.400000000000205, 36.80000000000025, 212.69999999999928, 36.70000000000025, 17.19999999999995, 35.600000000000236, 21.900000000000006, 37.00000000000024, 213.69999999999928, 31.200000000000166, 219.99999999999926, 170.09999999999948, 211.8999999999993, -151.00000000000054, 42.20000000000033, 38.90000000000028, 356.0, 31.500000000000185, 38.90000000000028, 40.0000000000003, 30.10000000000015, 194.0, 194.39999999999938, 200.99999999999935, 27.00000000000009, 37.600000000000264, 47.200000000000145, 16.89999999999993, 372.0, 33.400000000000205, 40.0000000000003, 400.0, 22.400000000000013, -32.59999999999994, -180.00000000000065, 192.09999999999937, 40.0000000000003, -174.00000000000063, 71.50000000000007, 37.80000000000027, 207.99999999999926, 40.0000000000003, 40.0000000000003, 203.99999999999935, 217.99999999999926, 174.2999999999995, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 35.600000000000236, 25.400000000000066, 368.5, 40.0000000000003, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 300.1, 29.70000000000014, 40.0000000000003, 13.59999999999997, 31.60000000000018, 34.50000000000022, 378.0, 40.0000000000003, 27.700000000000124, 40.0000000000003, 27.900000000000116, 27.90000000000011, 47.30000000000042, 200.99999999999935, 164.1999999999995, 38.20000000000027, 29.000000000000128, 38.90000000000028, 40.0000000000003, 175.1, 51.70000000000049, -41.99999999999992, 40.0000000000003, 26.800000000000104, 211.9999999999993, -8.499999999999702, 87.20000000000005, 219.99999999999926, 400.0, 40.0000000000003, 8.100000000000103, 155.99999999999957, -189.90000000000074, 40.0000000000003, 40.0000000000003, -5.59999999999974, 51.50000000000047, -164.60000000000076, 203.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.999999999999964, -23.49999999999975, 7.399999999999965, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 200.0, -7.299999999999891, 13.699999999999966, 20.000000000000014, -49.299999999999805, 9.499999999999968, 20.000000000000014, 11.599999999999966, -18.099999999999746, 20.000000000000014, 20.000000000000014, -58.000000000000014, 193.7, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 200.0, 146.3, 21.80000000000004, 20.000000000000014, 191.9, -346.0, -18.99999999999975, 17.899999999999984, 17.299999999999976, 17.899999999999988, 20.000000000000014, 164.0, 170.0, -29.49999999999978, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999759, 182.0, -358.0, 200.0, -34.59999999999979, 20.000000000000014, 170.0, 3.1999999999999615, 15.799999999999963, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -172.0, 3.1999999999999686, -7.2999999999999226, 158.0, 200.0, 20.000000000000014, 7.399999999999967, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 5.299999999999965, 1.0999999999999723, -277.5999999999999, 20.000000000000014, 20.000000000000014, -400.0, 146.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, -380.5, 9.499999999999966, 9.499999999999964, -142.0, 15.799999999999963, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 197.0, 20.000000000000014, 155.0, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 147.5, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 55.099999999999994, -1.2999999999999847, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 17.899999999999988, -31.299999999999763, 15.799999999999962, 13.699999999999966, 167.0, 200.0, 20.000000000000014, 20.000000000000014, -1.0000000000000204, 13.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, -3.099999999999958, 20.000000000000014, 20.000000000000014, -3.6999999999999797, 188.0, -0.9999999999999881, -161.8000000000006, 200.0, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 161.0, -370.9, 20.000000000000014, 31.700000000000212, 20.000000000000014, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999948, 20.000000000000014, 188.0, -86.50000000000054, 20.000000000000014, 20.000000000000014, 0.20000000000000284, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -40.89999999999976, 1.0999999999999865, 110.90000000000003, -400.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.60000000000036, 20.000000000000014, 30.50000000000021, -370.5999999999997, 20.000000000000014, 20.000000000000014, 152.0], "policy_predator_policy_reward": [8.0, 22.0, 0.0, 6.0, 12.0, 10.0, 13.0, 7.0, 0.0, 3.0, 32.0, 25.0, 0.0, 4.0, 3.0, 17.0, 37.0, 38.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 25.0, 189.0, 7.0, 0.0, 1.0, 0.0, 12.0, 10.0, 23.0, 18.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 185.0, 185.0, 19.0, 10.0, 10.0, 1.0, 8.0, 0.0, 2.0, 4.0, 107.0, 109.0, 4.0, 17.0, 0.0, 14.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 141.0, 84.0, 200.0, 0.0, 0.0, 18.0, 0.0, 0.0, 192.0, 5.0, 110.0, 94.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 23.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 16.0, 3.0, 7.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 45.0, 10.0, 1.0, 0.0, 0.0, 0.0, 24.0, 28.0, 17.0, 5.0, 0.0, 0.0, 11.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 11.0, 0.0, 11.0, 0.0, 16.0, 15.0, 10.0, 4.0, 76.0, 50.0, 8.0, 7.0, 0.0, 10.0, 0.0, 1.0, 0.0, 0.0, 185.0, 200.0, 0.0, 0.0, 110.0, 186.0, 0.0, 0.0, 0.0, 12.0, 2.0, 2.0, 1.0, 57.0, 53.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 22.0, 22.0, 200.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 54.0, 1.0, 0.0, 0.0, 186.0, 16.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8638510557809433, "mean_inference_ms": 2.504533265156155, "mean_action_processing_ms": 0.3803630473933602, "mean_env_wait_ms": 0.312307591522898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011584758758544922, "StateBufferConnector_ms": 0.004090666770935059, "ViewRequirementAgentConnector_ms": 0.14616668224334717}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -189.90000000000074, "episode_return_mean": 84.53999999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.3619926489841, "num_env_steps_trained_throughput_per_sec": 295.3619926489841, "timesteps_total": 740000, "num_env_steps_sampled_lifetime": 740000, "num_agent_steps_sampled_lifetime": 2960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2960000, "timers": {"training_iteration_time_ms": 13340.9, "restore_workers_time_ms": 0.048, "training_step_time_ms": 13340.773, "sample_time_ms": 2360.888, "learn_time_ms": 10960.016, "learn_throughput": 364.963, "synch_weights_time_ms": 15.54}, "counters": {"num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "done": false, "training_iteration": 185, "trial_id": "04dec_00002", "date": "2024-08-13_17-04-01", "timestamp": 1723583041, "time_this_iter_s": 13.6598219871521, "time_total_s": 2467.0203189849854, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0774e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2467.0203189849854, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 80.47894736842105, "ram_util_percent": 82.24736842105264}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4539686466099093, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.8222779744516605, "policy_loss": -0.0022306749809080017, "vf_loss": 0.8245086471949304, "vf_explained_var": 0.0010653109146804406, "kl": 0.013145266526999749, "entropy": 0.33965324205223213, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 350595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.35359431498896, "cur_kl_coeff": 0.25024001989405814, "cur_lr": 0.00010000000000000003, "total_loss": 2.9033204784468998, "policy_loss": -0.0019646244176550125, "vf_loss": 2.900816531849917, "vf_explained_var": 0.6401819174251859, "kl": 0.01785715058809087, "entropy": 0.13825130470530697, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 350595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -189.90000000000074, "episode_reward_mean": 76.57299999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 15.861500000000014, "predator_policy": 22.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.500000000000185, 38.90000000000028, 40.0000000000003, 30.10000000000015, 194.0, 194.39999999999938, 200.99999999999935, 27.00000000000009, 37.600000000000264, 47.200000000000145, 16.89999999999993, 372.0, 33.400000000000205, 40.0000000000003, 400.0, 22.400000000000013, -32.59999999999994, -180.00000000000065, 192.09999999999937, 40.0000000000003, -174.00000000000063, 71.50000000000007, 37.80000000000027, 207.99999999999926, 40.0000000000003, 40.0000000000003, 203.99999999999935, 217.99999999999926, 174.2999999999995, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 35.600000000000236, 25.400000000000066, 368.5, 40.0000000000003, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 300.1, 29.70000000000014, 40.0000000000003, 13.59999999999997, 31.60000000000018, 34.50000000000022, 378.0, 40.0000000000003, 27.700000000000124, 40.0000000000003, 27.900000000000116, 27.90000000000011, 47.30000000000042, 200.99999999999935, 164.1999999999995, 38.20000000000027, 29.000000000000128, 38.90000000000028, 40.0000000000003, 175.1, 51.70000000000049, -41.99999999999992, 40.0000000000003, 26.800000000000104, 211.9999999999993, -8.499999999999702, 87.20000000000005, 219.99999999999926, 400.0, 40.0000000000003, 8.100000000000103, 155.99999999999957, -189.90000000000074, 40.0000000000003, 40.0000000000003, -5.59999999999974, 51.50000000000047, -164.60000000000076, 203.99999999999926, 48.000000000000014, 23.500000000000053, 30.800000000000193, 183.49999999999943, 40.0000000000003, 22.400000000000023, 20.000000000000064, 3.0000000000002016, 211.9999999999993, 40.0000000000003, 2.100000000000151, 25.80000000000007, 40.0000000000003, 40.0000000000003, 47.20000000000029, 165.79999999999953, 40.0000000000003, -169.0000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.49999999999978, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999759, 182.0, -358.0, 200.0, -34.59999999999979, 20.000000000000014, 170.0, 3.1999999999999615, 15.799999999999963, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -172.0, 3.1999999999999686, -7.2999999999999226, 158.0, 200.0, 20.000000000000014, 7.399999999999967, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 5.299999999999965, 1.0999999999999723, -277.5999999999999, 20.000000000000014, 20.000000000000014, -400.0, 146.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, -380.5, 9.499999999999966, 9.499999999999964, -142.0, 15.799999999999963, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 197.0, 20.000000000000014, 155.0, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 147.5, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 55.099999999999994, -1.2999999999999847, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 17.899999999999988, -31.299999999999763, 15.799999999999962, 13.699999999999966, 167.0, 200.0, 20.000000000000014, 20.000000000000014, -1.0000000000000204, 13.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, -3.099999999999958, 20.000000000000014, 20.000000000000014, -3.6999999999999797, 188.0, -0.9999999999999881, -161.8000000000006, 200.0, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 161.0, -370.9, 20.000000000000014, 31.700000000000212, 20.000000000000014, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999948, 20.000000000000014, 188.0, -86.50000000000054, 20.000000000000014, 20.000000000000014, 0.20000000000000284, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -40.89999999999976, 1.0999999999999865, 110.90000000000003, -400.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.60000000000036, 20.000000000000014, 30.50000000000021, -370.5999999999997, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, -58.0, -7.299999999999926, 15.79999999999996, 11.599999999999966, -257.79999999999905, 9.499999999999968, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999804, 20.000000000000014, -277.0, 5.299999999999967, -28.299999999999756, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000083, 17.899999999999988, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000117, -1.0000000000000133, 153.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0], "policy_predator_policy_reward": [23.0, 18.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 185.0, 185.0, 19.0, 10.0, 10.0, 1.0, 8.0, 0.0, 2.0, 4.0, 107.0, 109.0, 4.0, 17.0, 0.0, 14.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 141.0, 84.0, 200.0, 0.0, 0.0, 18.0, 0.0, 0.0, 192.0, 5.0, 110.0, 94.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 23.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 16.0, 3.0, 7.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 45.0, 10.0, 1.0, 0.0, 0.0, 0.0, 24.0, 28.0, 17.0, 5.0, 0.0, 0.0, 11.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 11.0, 0.0, 11.0, 0.0, 16.0, 15.0, 10.0, 4.0, 76.0, 50.0, 8.0, 7.0, 0.0, 10.0, 0.0, 1.0, 0.0, 0.0, 185.0, 200.0, 0.0, 0.0, 110.0, 186.0, 0.0, 0.0, 0.0, 12.0, 2.0, 2.0, 1.0, 57.0, 53.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 22.0, 22.0, 200.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 54.0, 1.0, 0.0, 0.0, 186.0, 16.0, 16.0, 86.0, 0.0, 14.0, 1.0, 141.0, 136.0, 5.0, 11.0, 0.0, 0.0, 6.0, 10.0, 122.0, 155.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 49.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 200.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.863698292746021, "mean_inference_ms": 2.5047559040186145, "mean_action_processing_ms": 0.3802102273454048, "mean_env_wait_ms": 0.3122270447635499, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013145089149475098, "StateBufferConnector_ms": 0.005126953125, "ViewRequirementAgentConnector_ms": 0.15334844589233398}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -189.90000000000074, "episode_return_mean": 76.57299999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.2738239861504, "num_env_steps_trained_throughput_per_sec": 290.2738239861504, "timesteps_total": 744000, "num_env_steps_sampled_lifetime": 744000, "num_agent_steps_sampled_lifetime": 2976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2976000, "timers": {"training_iteration_time_ms": 13351.717, "restore_workers_time_ms": 0.048, "training_step_time_ms": 13351.589, "sample_time_ms": 2371.366, "learn_time_ms": 10959.536, "learn_throughput": 364.979, "synch_weights_time_ms": 16.209}, "counters": {"num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "done": false, "training_iteration": 186, "trial_id": "04dec_00002", "date": "2024-08-13_17-04-14", "timestamp": 1723583054, "time_this_iter_s": 13.805328130722046, "time_total_s": 2480.8256471157074, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0876550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2480.8256471157074, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 73.65789473684211, "ram_util_percent": 83.47894736842106}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9030863097341604, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.6048437369248223, "policy_loss": -0.0006669281356076084, "vf_loss": 1.6055106584357206, "vf_explained_var": 0.0018461712138362662, "kl": 0.006195197233980476, "entropy": 0.2739684804800957, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 352485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.117267276181114, "cur_kl_coeff": 0.25024001989405814, "cur_lr": 0.00010000000000000003, "total_loss": 2.758813579372628, "policy_loss": 0.0016523314854277977, "vf_loss": 2.7492063322395244, "vf_explained_var": 0.5445810860426968, "kl": 0.031789113752534355, "entropy": 0.1633943578474736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 352485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -189.90000000000074, "episode_reward_mean": 90.81999999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 25.77500000000001, "predator_policy": 19.635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [217.99999999999926, 174.2999999999995, 40.0000000000003, 37.80000000000027, 40.0000000000003, 219.99999999999926, 35.600000000000236, 25.400000000000066, 368.5, 40.0000000000003, 40.0000000000003, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 197.99999999999937, 300.1, 29.70000000000014, 40.0000000000003, 13.59999999999997, 31.60000000000018, 34.50000000000022, 378.0, 40.0000000000003, 27.700000000000124, 40.0000000000003, 27.900000000000116, 27.90000000000011, 47.30000000000042, 200.99999999999935, 164.1999999999995, 38.20000000000027, 29.000000000000128, 38.90000000000028, 40.0000000000003, 175.1, 51.70000000000049, -41.99999999999992, 40.0000000000003, 26.800000000000104, 211.9999999999993, -8.499999999999702, 87.20000000000005, 219.99999999999926, 400.0, 40.0000000000003, 8.100000000000103, 155.99999999999957, -189.90000000000074, 40.0000000000003, 40.0000000000003, -5.59999999999974, 51.50000000000047, -164.60000000000076, 203.99999999999926, 48.000000000000014, 23.500000000000053, 30.800000000000193, 183.49999999999943, 40.0000000000003, 22.400000000000023, 20.000000000000064, 3.0000000000002016, 211.9999999999993, 40.0000000000003, 2.100000000000151, 25.80000000000007, 40.0000000000003, 40.0000000000003, 47.20000000000029, 165.79999999999953, 40.0000000000003, -169.0000000000006, 372.20000000000005, 207.89999999999932, 207.99999999999932, 40.0000000000003, 66.0, -180.00000000000065, 40.0000000000003, -15.800000000000283, 325.20000000000005, 324.0, 219.99999999999926, 219.99999999999926, 40.0000000000003, 30.100000000000147, 40.0000000000003, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 380.0, 43.800000000000054, 219.99999999999926, 202.99999999999935, 24.600000000000048, 24.000000000000036, 112.99999999999979, 131.89999999999978], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [197.0, 20.000000000000014, 155.0, -15.699999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, -13.599999999999783, 20.000000000000014, 147.5, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 55.099999999999994, -1.2999999999999847, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 17.899999999999988, -31.299999999999763, 15.799999999999962, 13.699999999999966, 167.0, 200.0, 20.000000000000014, 20.000000000000014, -1.0000000000000204, 13.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, -3.099999999999958, 20.000000000000014, 20.000000000000014, -3.6999999999999797, 188.0, -0.9999999999999881, -161.8000000000006, 200.0, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 161.0, -370.9, 20.000000000000014, 31.700000000000212, 20.000000000000014, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999948, 20.000000000000014, 188.0, -86.50000000000054, 20.000000000000014, 20.000000000000014, 0.20000000000000284, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -40.89999999999976, 1.0999999999999865, 110.90000000000003, -400.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.60000000000036, 20.000000000000014, 30.50000000000021, -370.5999999999997, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, -58.0, -7.299999999999926, 15.79999999999996, 11.599999999999966, -257.79999999999905, 9.499999999999968, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999804, 20.000000000000014, -277.0, 5.299999999999967, -28.299999999999756, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000083, 17.899999999999988, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000117, -1.0000000000000133, 153.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, 168.2, -3.099999999999958, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -220.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, -155.8, 20.000000000000014, 132.2, 155.0, 182.0, 92.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -30.399999999999757, -2.800000000000008, 200.0, 20.000000000000014, 174.2, 15.799999999999963, 5.299999999999965, 5.299999999999965, 9.499999999999964, 9.499999999999964, 20.000000000000014, -91.0, -3.099999999999958, 92.0], "policy_predator_policy_reward": [1.0, 0.0, 12.0, 23.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 16.0, 3.0, 7.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 45.0, 10.0, 1.0, 0.0, 0.0, 0.0, 24.0, 28.0, 17.0, 5.0, 0.0, 0.0, 11.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 11.0, 0.0, 11.0, 0.0, 16.0, 15.0, 10.0, 4.0, 76.0, 50.0, 8.0, 7.0, 0.0, 10.0, 0.0, 1.0, 0.0, 0.0, 185.0, 200.0, 0.0, 0.0, 110.0, 186.0, 0.0, 0.0, 0.0, 12.0, 2.0, 2.0, 1.0, 57.0, 53.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 22.0, 22.0, 200.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 54.0, 1.0, 0.0, 0.0, 186.0, 16.0, 16.0, 86.0, 0.0, 14.0, 1.0, 141.0, 136.0, 5.0, 11.0, 0.0, 0.0, 6.0, 10.0, 122.0, 155.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 49.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 200.0, 11.0, 4.0, 0.0, 11.0, 0.0, 6.0, 0.0, 0.0, 0.0, 140.0, 126.0, 0.0, 200.0, 0.0, 0.0, 115.0, 5.0, 13.0, 25.0, 17.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 25.0, 52.0, 0.0, 0.0, 10.0, 3.0, 7.0, 7.0, 0.0, 5.0, 97.0, 87.0, 7.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.863470468821183, "mean_inference_ms": 2.502930557544059, "mean_action_processing_ms": 0.3853951526916983, "mean_env_wait_ms": 0.31202247123441884, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011776328086853027, "StateBufferConnector_ms": 0.004877567291259766, "ViewRequirementAgentConnector_ms": 0.14930641651153564}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -189.90000000000074, "episode_return_mean": 90.81999999999996, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 274.813476664972, "num_env_steps_trained_throughput_per_sec": 274.813476664972, "timesteps_total": 748000, "num_env_steps_sampled_lifetime": 748000, "num_agent_steps_sampled_lifetime": 2992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2992000, "timers": {"training_iteration_time_ms": 13474.035, "restore_workers_time_ms": 0.049, "training_step_time_ms": 13473.905, "sample_time_ms": 2405.289, "learn_time_ms": 11047.329, "learn_throughput": 362.078, "synch_weights_time_ms": 16.932}, "counters": {"num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "done": false, "training_iteration": 187, "trial_id": "04dec_00002", "date": "2024-08-13_17-04-29", "timestamp": 1723583069, "time_this_iter_s": 14.591806888580322, "time_total_s": 2495.4174540042877, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0876820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2495.4174540042877, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 69.39999999999999, "ram_util_percent": 83.78571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.421916876583503, "cur_kl_coeff": 1.2211046997660932e-21, "cur_lr": 0.00010000000000000003, "total_loss": 1.197085459727459, "policy_loss": -0.0011155226871509244, "vf_loss": 1.1982009788669605, "vf_explained_var": 0.002795467458704792, "kl": 0.030762337664292996, "entropy": 0.28037111425683614, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 354375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.116813589624627, "cur_kl_coeff": 0.37536002984108724, "cur_lr": 0.00010000000000000003, "total_loss": 2.2527716591244653, "policy_loss": -0.005524386760837856, "vf_loss": 2.2547459061814363, "vf_explained_var": 0.5337971262200168, "kl": 0.009457941847518242, "entropy": 0.12459195959110739, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 354375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -189.90000000000074, "episode_reward_mean": 98.66299999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 27.171500000000005, "predator_policy": 22.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 13.59999999999997, 31.60000000000018, 34.50000000000022, 378.0, 40.0000000000003, 27.700000000000124, 40.0000000000003, 27.900000000000116, 27.90000000000011, 47.30000000000042, 200.99999999999935, 164.1999999999995, 38.20000000000027, 29.000000000000128, 38.90000000000028, 40.0000000000003, 175.1, 51.70000000000049, -41.99999999999992, 40.0000000000003, 26.800000000000104, 211.9999999999993, -8.499999999999702, 87.20000000000005, 219.99999999999926, 400.0, 40.0000000000003, 8.100000000000103, 155.99999999999957, -189.90000000000074, 40.0000000000003, 40.0000000000003, -5.59999999999974, 51.50000000000047, -164.60000000000076, 203.99999999999926, 48.000000000000014, 23.500000000000053, 30.800000000000193, 183.49999999999943, 40.0000000000003, 22.400000000000023, 20.000000000000064, 3.0000000000002016, 211.9999999999993, 40.0000000000003, 2.100000000000151, 25.80000000000007, 40.0000000000003, 40.0000000000003, 47.20000000000029, 165.79999999999953, 40.0000000000003, -169.0000000000006, 372.20000000000005, 207.89999999999932, 207.99999999999932, 40.0000000000003, 66.0, -180.00000000000065, 40.0000000000003, -15.800000000000283, 325.20000000000005, 324.0, 219.99999999999926, 219.99999999999926, 40.0000000000003, 30.100000000000147, 40.0000000000003, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 380.0, 43.800000000000054, 219.99999999999926, 202.99999999999935, 24.600000000000048, 24.000000000000036, 112.99999999999979, 131.89999999999978, 37.80000000000027, 181.99999999999946, 40.0000000000003, 206.19999999999933, 40.0000000000003, 318.3, 26.8000000000001, 219.99999999999926, 40.0000000000003, 213.3999999999993, 153.09999999999957, 215.59999999999928, 35.90000000000024, 219.99999999999926, 219.99999999999926, 366.4, 183.99999999999943, 172.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -30.39999999999977, 20.000000000000014, 17.899999999999988, -31.299999999999763, 15.799999999999962, 13.699999999999966, 167.0, 200.0, 20.000000000000014, 20.000000000000014, -1.0000000000000204, 13.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, -3.099999999999958, 20.000000000000014, 20.000000000000014, -3.6999999999999797, 188.0, -0.9999999999999881, -161.8000000000006, 200.0, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 161.0, -370.9, 20.000000000000014, 31.700000000000212, 20.000000000000014, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999948, 20.000000000000014, 188.0, -86.50000000000054, 20.000000000000014, 20.000000000000014, 0.20000000000000284, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -40.89999999999976, 1.0999999999999865, 110.90000000000003, -400.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.60000000000036, 20.000000000000014, 30.50000000000021, -370.5999999999997, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, -58.0, -7.299999999999926, 15.79999999999996, 11.599999999999966, -257.79999999999905, 9.499999999999968, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999804, 20.000000000000014, -277.0, 5.299999999999967, -28.299999999999756, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000083, 17.899999999999988, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000117, -1.0000000000000133, 153.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, 168.2, -3.099999999999958, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -220.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, -155.8, 20.000000000000014, 132.2, 155.0, 182.0, 92.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -30.399999999999757, -2.800000000000008, 200.0, 20.000000000000014, 174.2, 15.799999999999963, 5.299999999999965, 5.299999999999965, 9.499999999999964, 9.499999999999964, 20.000000000000014, -91.0, -3.099999999999958, 92.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 38.0, 182.3, 20.000000000000014, -5.199999999999937, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 200.0, 7.399999999999965, 55.7, 11.599999999999964, 200.0, 20.000000000000014, -3.099999999999979, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 151.4, 146.0, 20.000000000000014, 191.0, -383.8], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 24.0, 28.0, 17.0, 5.0, 0.0, 0.0, 11.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 11.0, 0.0, 11.0, 0.0, 16.0, 15.0, 10.0, 4.0, 76.0, 50.0, 8.0, 7.0, 0.0, 10.0, 0.0, 1.0, 0.0, 0.0, 185.0, 200.0, 0.0, 0.0, 110.0, 186.0, 0.0, 0.0, 0.0, 12.0, 2.0, 2.0, 1.0, 57.0, 53.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 22.0, 22.0, 200.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 54.0, 1.0, 0.0, 0.0, 186.0, 16.0, 16.0, 86.0, 0.0, 14.0, 1.0, 141.0, 136.0, 5.0, 11.0, 0.0, 0.0, 6.0, 10.0, 122.0, 155.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 49.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 200.0, 11.0, 4.0, 0.0, 11.0, 0.0, 6.0, 0.0, 0.0, 0.0, 140.0, 126.0, 0.0, 200.0, 0.0, 0.0, 115.0, 5.0, 13.0, 25.0, 17.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 25.0, 52.0, 0.0, 0.0, 10.0, 3.0, 7.0, 7.0, 0.0, 5.0, 97.0, 87.0, 7.0, 36.0, 0.0, 2.0, 19.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 52.0, 38.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 18.0, 0.0, 170.0, 195.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8633080285723677, "mean_inference_ms": 2.5053677809938733, "mean_action_processing_ms": 0.38854740835540674, "mean_env_wait_ms": 0.3120002712582176, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009543061256408691, "StateBufferConnector_ms": 0.004573464393615723, "ViewRequirementAgentConnector_ms": 0.14836621284484863}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -189.90000000000074, "episode_return_mean": 98.66299999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.0534518182608, "num_env_steps_trained_throughput_per_sec": 311.0534518182608, "timesteps_total": 752000, "num_env_steps_sampled_lifetime": 752000, "num_agent_steps_sampled_lifetime": 3008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3008000, "timers": {"training_iteration_time_ms": 13443.93, "restore_workers_time_ms": 0.049, "training_step_time_ms": 13443.799, "sample_time_ms": 2297.912, "learn_time_ms": 11123.755, "learn_throughput": 359.591, "synch_weights_time_ms": 17.806}, "counters": {"num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "done": false, "training_iteration": 188, "trial_id": "04dec_00002", "date": "2024-08-13_17-04-42", "timestamp": 1723583082, "time_this_iter_s": 12.916902780532837, "time_total_s": 2508.3343567848206, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b083bca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2508.3343567848206, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 68.0, "ram_util_percent": 83.75}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9256166631424868, "cur_kl_coeff": 1.8316570496491404e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.3445187444015155, "policy_loss": -0.0011712744506815122, "vf_loss": 0.34569001781166575, "vf_explained_var": 0.030679128188935537, "kl": 0.007303817987111105, "entropy": 0.28100985288619995, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 356265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.764556304235306, "cur_kl_coeff": 0.37536002984108724, "cur_lr": 0.00010000000000000003, "total_loss": 1.9732725794353183, "policy_loss": -0.002037678768540481, "vf_loss": 1.9708622697799925, "vf_explained_var": 0.9728687771098323, "kl": 0.011849928225649961, "entropy": 0.1030116153811967, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 356265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -189.90000000000074, "episode_reward_mean": 112.62499999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 35.80250000000001, "predator_policy": 20.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [51.70000000000049, -41.99999999999992, 40.0000000000003, 26.800000000000104, 211.9999999999993, -8.499999999999702, 87.20000000000005, 219.99999999999926, 400.0, 40.0000000000003, 8.100000000000103, 155.99999999999957, -189.90000000000074, 40.0000000000003, 40.0000000000003, -5.59999999999974, 51.50000000000047, -164.60000000000076, 203.99999999999926, 48.000000000000014, 23.500000000000053, 30.800000000000193, 183.49999999999943, 40.0000000000003, 22.400000000000023, 20.000000000000064, 3.0000000000002016, 211.9999999999993, 40.0000000000003, 2.100000000000151, 25.80000000000007, 40.0000000000003, 40.0000000000003, 47.20000000000029, 165.79999999999953, 40.0000000000003, -169.0000000000006, 372.20000000000005, 207.89999999999932, 207.99999999999932, 40.0000000000003, 66.0, -180.00000000000065, 40.0000000000003, -15.800000000000283, 325.20000000000005, 324.0, 219.99999999999926, 219.99999999999926, 40.0000000000003, 30.100000000000147, 40.0000000000003, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 380.0, 43.800000000000054, 219.99999999999926, 202.99999999999935, 24.600000000000048, 24.000000000000036, 112.99999999999979, 131.89999999999978, 37.80000000000027, 181.99999999999946, 40.0000000000003, 206.19999999999933, 40.0000000000003, 318.3, 26.8000000000001, 219.99999999999926, 40.0000000000003, 213.3999999999993, 153.09999999999957, 215.59999999999928, 35.90000000000024, 219.99999999999926, 219.99999999999926, 366.4, 183.99999999999943, 172.2, 197.69999999999936, 40.0000000000003, 177.29999999999944, 40.0000000000003, 211.3999999999993, 352.3, 145.09999999999962, 219.99999999999926, 40.0000000000003, 331.5, 400.0, 205.99999999999932, 40.0000000000003, 27.90000000000011, 106.0, 198.99999999999935, 30.10000000000015, 26.80000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 31.700000000000212, 20.000000000000014, -358.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999948, 20.000000000000014, 188.0, -86.50000000000054, 20.000000000000014, 20.000000000000014, 0.20000000000000284, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -40.89999999999976, 1.0999999999999865, 110.90000000000003, -400.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.60000000000036, 20.000000000000014, 30.50000000000021, -370.5999999999997, 20.000000000000014, 20.000000000000014, 152.0, 20.000000000000014, -58.0, -7.299999999999926, 15.79999999999996, 11.599999999999966, -257.79999999999905, 9.499999999999968, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999804, 20.000000000000014, -277.0, 5.299999999999967, -28.299999999999756, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000083, 17.899999999999988, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000117, -1.0000000000000133, 153.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, 168.2, -3.099999999999958, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -220.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, -155.8, 20.000000000000014, 132.2, 155.0, 182.0, 92.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -30.399999999999757, -2.800000000000008, 200.0, 20.000000000000014, 174.2, 15.799999999999963, 5.299999999999965, 5.299999999999965, 9.499999999999964, 9.499999999999964, 20.000000000000014, -91.0, -3.099999999999958, 92.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 38.0, 182.3, 20.000000000000014, -5.199999999999937, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 200.0, 7.399999999999965, 55.7, 11.599999999999964, 200.0, 20.000000000000014, -3.099999999999979, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 151.4, 146.0, 20.000000000000014, 191.0, -383.8, 20.000000000000014, 169.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.3, 20.000000000000014, 20.000000000000014, 197.0, 7.399999999999965, 167.3, 173.0, 20.000000000000014, 25.099999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 167.9, 134.60000000000002, 200.0, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 2.0, -49.0, 158.0, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -5.19999999999993], "policy_predator_policy_reward": [0.0, 0.0, 110.0, 186.0, 0.0, 0.0, 0.0, 12.0, 2.0, 2.0, 1.0, 57.0, 53.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 22.0, 22.0, 200.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 54.0, 1.0, 0.0, 0.0, 186.0, 16.0, 16.0, 86.0, 0.0, 14.0, 1.0, 141.0, 136.0, 5.0, 11.0, 0.0, 0.0, 6.0, 10.0, 122.0, 155.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 49.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 200.0, 11.0, 4.0, 0.0, 11.0, 0.0, 6.0, 0.0, 0.0, 0.0, 140.0, 126.0, 0.0, 200.0, 0.0, 0.0, 115.0, 5.0, 13.0, 25.0, 17.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 25.0, 52.0, 0.0, 0.0, 10.0, 3.0, 7.0, 7.0, 0.0, 5.0, 97.0, 87.0, 7.0, 36.0, 0.0, 2.0, 19.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 52.0, 38.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 18.0, 0.0, 170.0, 195.0, 8.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 6.0, 1.0, 12.0, 0.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 11.0, 0.0, 83.0, 70.0, 11.0, 10.0, 5.0, 4.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8631297942909232, "mean_inference_ms": 2.5056504940737336, "mean_action_processing_ms": 0.3918434050351547, "mean_env_wait_ms": 0.31190352988286363, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069800615310668945, "StateBufferConnector_ms": 0.004560947418212891, "ViewRequirementAgentConnector_ms": 0.15463924407958984}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -189.90000000000074, "episode_return_mean": 112.62499999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.9936654229427, "num_env_steps_trained_throughput_per_sec": 318.9936654229427, "timesteps_total": 756000, "num_env_steps_sampled_lifetime": 756000, "num_agent_steps_sampled_lifetime": 3024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3024000, "timers": {"training_iteration_time_ms": 13415.435, "restore_workers_time_ms": 0.049, "training_step_time_ms": 13415.304, "sample_time_ms": 2233.253, "learn_time_ms": 11160.648, "learn_throughput": 358.402, "synch_weights_time_ms": 17.5}, "counters": {"num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "done": false, "training_iteration": 189, "trial_id": "04dec_00002", "date": "2024-08-13_17-04-55", "timestamp": 1723583095, "time_this_iter_s": 12.577961921691895, "time_total_s": 2520.9123187065125, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b07740d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2520.9123187065125, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 69.5111111111111, "ram_util_percent": 83.75555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9771516258202533, "cur_kl_coeff": 1.8316570496491404e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.8310063310716518, "policy_loss": -0.003192860672802285, "vf_loss": 0.8341991915746971, "vf_explained_var": -0.000873590903307395, "kl": 0.007965917498046676, "entropy": 0.2818962748246218, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 358155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.87261089534356, "cur_kl_coeff": 0.37536002984108724, "cur_lr": 0.00010000000000000003, "total_loss": 1.638597517401453, "policy_loss": -0.00016515624805516193, "vf_loss": 1.6377290671149258, "vf_explained_var": 0.805085034723635, "kl": 0.002753645115766235, "entropy": 0.09387328728402733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 358155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -180.00000000000065, "episode_reward_mean": 132.58799999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 48.14900000000001, "predator_policy": 18.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [203.99999999999926, 48.000000000000014, 23.500000000000053, 30.800000000000193, 183.49999999999943, 40.0000000000003, 22.400000000000023, 20.000000000000064, 3.0000000000002016, 211.9999999999993, 40.0000000000003, 2.100000000000151, 25.80000000000007, 40.0000000000003, 40.0000000000003, 47.20000000000029, 165.79999999999953, 40.0000000000003, -169.0000000000006, 372.20000000000005, 207.89999999999932, 207.99999999999932, 40.0000000000003, 66.0, -180.00000000000065, 40.0000000000003, -15.800000000000283, 325.20000000000005, 324.0, 219.99999999999926, 219.99999999999926, 40.0000000000003, 30.100000000000147, 40.0000000000003, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 380.0, 43.800000000000054, 219.99999999999926, 202.99999999999935, 24.600000000000048, 24.000000000000036, 112.99999999999979, 131.89999999999978, 37.80000000000027, 181.99999999999946, 40.0000000000003, 206.19999999999933, 40.0000000000003, 318.3, 26.8000000000001, 219.99999999999926, 40.0000000000003, 213.3999999999993, 153.09999999999957, 215.59999999999928, 35.90000000000024, 219.99999999999926, 219.99999999999926, 366.4, 183.99999999999943, 172.2, 197.69999999999936, 40.0000000000003, 177.29999999999944, 40.0000000000003, 211.3999999999993, 352.3, 145.09999999999962, 219.99999999999926, 40.0000000000003, 331.5, 400.0, 205.99999999999932, 40.0000000000003, 27.90000000000011, 106.0, 198.99999999999935, 30.10000000000015, 26.80000000000009, 199.99999999999935, 141.60000000000002, 40.0000000000003, 40.0000000000003, 210.9999999999993, 40.0000000000003, 36.60000000000025, 36.70000000000025, 208.99999999999932, 187.99999999999943, 217.99999999999926, 40.0000000000003, 375.0, 394.6, 400.0, 314.0, 34.50000000000022, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 152.0, 20.000000000000014, -58.0, -7.299999999999926, 15.79999999999996, 11.599999999999966, -257.79999999999905, 9.499999999999968, 158.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.599999999999804, 20.000000000000014, -277.0, 5.299999999999967, -28.299999999999756, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000083, 17.899999999999988, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000117, -1.0000000000000133, 153.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -400.0, 200.0, 168.2, -3.099999999999958, 200.0, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, -220.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, -155.8, 20.000000000000014, 132.2, 155.0, 182.0, 92.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -30.399999999999757, -2.800000000000008, 200.0, 20.000000000000014, 174.2, 15.799999999999963, 5.299999999999965, 5.299999999999965, 9.499999999999964, 9.499999999999964, 20.000000000000014, -91.0, -3.099999999999958, 92.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 38.0, 182.3, 20.000000000000014, -5.199999999999937, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 200.0, 7.399999999999965, 55.7, 11.599999999999964, 200.0, 20.000000000000014, -3.099999999999979, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 151.4, 146.0, 20.000000000000014, 191.0, -383.8, 20.000000000000014, 169.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.3, 20.000000000000014, 20.000000000000014, 197.0, 7.399999999999965, 167.3, 173.0, 20.000000000000014, 25.099999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 167.9, 134.60000000000002, 200.0, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 2.0, -49.0, 158.0, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -5.19999999999993, 20.000000000000014, 170.0, -400.0, 176.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.9999999999999678, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -1.0000000000000098, 200.0, 20.000000000000014, 131.0, 20.000000000000014, 197.0, 20.000000000000014, 20.000000000000014, 182.0, 179.0, 194.6, 200.0, 200.0, 200.0, 137.0, 134.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [16.0, 16.0, 86.0, 0.0, 14.0, 1.0, 141.0, 136.0, 5.0, 11.0, 0.0, 0.0, 6.0, 10.0, 122.0, 155.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 49.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 200.0, 11.0, 4.0, 0.0, 11.0, 0.0, 6.0, 0.0, 0.0, 0.0, 140.0, 126.0, 0.0, 200.0, 0.0, 0.0, 115.0, 5.0, 13.0, 25.0, 17.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 25.0, 52.0, 0.0, 0.0, 10.0, 3.0, 7.0, 7.0, 0.0, 5.0, 97.0, 87.0, 7.0, 36.0, 0.0, 2.0, 19.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 52.0, 38.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 18.0, 0.0, 170.0, 195.0, 8.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 6.0, 1.0, 12.0, 0.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 11.0, 0.0, 83.0, 70.0, 11.0, 10.0, 5.0, 4.0, 12.0, 0.0, 10.0, 0.0, 165.0, 200.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 10.0, 14.0, 23.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 21.0, 22.0, 5.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8629443390515723, "mean_inference_ms": 2.505838400914304, "mean_action_processing_ms": 0.3951191388573973, "mean_env_wait_ms": 0.3118275200629186, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0066640377044677734, "StateBufferConnector_ms": 0.00504302978515625, "ViewRequirementAgentConnector_ms": 0.14872562885284424}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -180.00000000000065, "episode_return_mean": 132.58799999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.62321301038, "num_env_steps_trained_throughput_per_sec": 321.62321301038, "timesteps_total": 760000, "num_env_steps_sampled_lifetime": 760000, "num_agent_steps_sampled_lifetime": 3040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3040000, "timers": {"training_iteration_time_ms": 13285.784, "restore_workers_time_ms": 0.049, "training_step_time_ms": 13285.653, "sample_time_ms": 2130.608, "learn_time_ms": 11134.029, "learn_throughput": 359.259, "synch_weights_time_ms": 17.396}, "counters": {"num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "done": false, "training_iteration": 190, "trial_id": "04dec_00002", "date": "2024-08-13_17-05-07", "timestamp": 1723583107, "time_this_iter_s": 12.486517190933228, "time_total_s": 2533.3988358974457, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0720160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2533.3988358974457, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 68.77777777777777, "ram_util_percent": 83.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2627644755931757, "cur_kl_coeff": 1.8316570496491404e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.8032952805833211, "policy_loss": -0.0034537834184313262, "vf_loss": 0.8067490646921137, "vf_explained_var": 0.0011626866759446564, "kl": 0.07055537950291316, "entropy": 0.38291566294652446, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 360045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.94146076302049, "cur_kl_coeff": 0.18768001492054362, "cur_lr": 0.00010000000000000003, "total_loss": 1.320708648616044, "policy_loss": -0.0009725279738959023, "vf_loss": 1.3209652903849485, "vf_explained_var": 0.6961989108216826, "kl": 0.003814404833602523, "entropy": 0.0832094594688406, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 360045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -180.00000000000065, "episode_reward_mean": 142.7329999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 56.6465, "predator_policy": 14.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.0, -180.00000000000065, 40.0000000000003, -15.800000000000283, 325.20000000000005, 324.0, 219.99999999999926, 219.99999999999926, 40.0000000000003, 30.100000000000147, 40.0000000000003, 40.0000000000003, 219.99999999999926, 219.99999999999926, 40.0000000000003, 380.0, 43.800000000000054, 219.99999999999926, 202.99999999999935, 24.600000000000048, 24.000000000000036, 112.99999999999979, 131.89999999999978, 37.80000000000027, 181.99999999999946, 40.0000000000003, 206.19999999999933, 40.0000000000003, 318.3, 26.8000000000001, 219.99999999999926, 40.0000000000003, 213.3999999999993, 153.09999999999957, 215.59999999999928, 35.90000000000024, 219.99999999999926, 219.99999999999926, 366.4, 183.99999999999943, 172.2, 197.69999999999936, 40.0000000000003, 177.29999999999944, 40.0000000000003, 211.3999999999993, 352.3, 145.09999999999962, 219.99999999999926, 40.0000000000003, 331.5, 400.0, 205.99999999999932, 40.0000000000003, 27.90000000000011, 106.0, 198.99999999999935, 30.10000000000015, 26.80000000000009, 199.99999999999935, 141.60000000000002, 40.0000000000003, 40.0000000000003, 210.9999999999993, 40.0000000000003, 36.60000000000025, 36.70000000000025, 208.99999999999932, 187.99999999999943, 217.99999999999926, 40.0000000000003, 375.0, 394.6, 400.0, 314.0, 34.50000000000022, 40.0000000000003, 203.99999999999932, 201.99999999999935, 40.0000000000003, 200.99999999999935, 187.9999999999994, 216.39999999999927, 32.30000000000018, 38.90000000000028, 219.99999999999926, 32.300000000000175, 40.0000000000003, 40.0000000000003, 201.99999999999935, 37.80000000000027, 25.700000000000077, 184.29999999999944, 148.8999999999996, 219.99999999999926, 219.99999999999926, 3.3000000000000007, 148.49999999999963, 40.0000000000003, 176.29999999999947], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-220.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, -155.8, 20.000000000000014, 132.2, 155.0, 182.0, 92.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -30.399999999999757, -2.800000000000008, 200.0, 20.000000000000014, 174.2, 15.799999999999963, 5.299999999999965, 5.299999999999965, 9.499999999999964, 9.499999999999964, 20.000000000000014, -91.0, -3.099999999999958, 92.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 38.0, 182.3, 20.000000000000014, -5.199999999999937, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 200.0, 7.399999999999965, 55.7, 11.599999999999964, 200.0, 20.000000000000014, -3.099999999999979, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 151.4, 146.0, 20.000000000000014, 191.0, -383.8, 20.000000000000014, 169.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.3, 20.000000000000014, 20.000000000000014, 197.0, 7.399999999999965, 167.3, 173.0, 20.000000000000014, 25.099999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 167.9, 134.60000000000002, 200.0, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 2.0, -49.0, 158.0, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -5.19999999999993, 20.000000000000014, 170.0, -400.0, 176.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.9999999999999678, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -1.0000000000000098, 200.0, 20.000000000000014, 131.0, 20.000000000000014, 197.0, 20.000000000000014, 20.000000000000014, 182.0, 179.0, 194.6, 200.0, 200.0, 200.0, 137.0, 134.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 152.0, 20.000000000000014, 196.4, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 5.299999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 1.0999999999999652, 11.599999999999964, 156.2, 1.099999999999983, 119.9, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -393.7, -57.69999999999997, 159.2, 20.000000000000014, 20.000000000000014, 146.9, 7.399999999999977], "policy_predator_policy_reward": [140.0, 126.0, 0.0, 200.0, 0.0, 0.0, 115.0, 5.0, 13.0, 25.0, 17.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 25.0, 52.0, 0.0, 0.0, 10.0, 3.0, 7.0, 7.0, 0.0, 5.0, 97.0, 87.0, 7.0, 36.0, 0.0, 2.0, 19.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 52.0, 38.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 18.0, 0.0, 170.0, 195.0, 8.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 6.0, 1.0, 12.0, 0.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 11.0, 0.0, 83.0, 70.0, 11.0, 10.0, 5.0, 4.0, 12.0, 0.0, 10.0, 0.0, 165.0, 200.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 10.0, 14.0, 23.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 21.0, 22.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 9.0, 0.0, 0.0, 5.0, 6.0, 0.0, 16.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 13.0, 0.0, 12.0, 15.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 197.0, 0.0, 37.0, 10.0, 0.0, 0.0, 1.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8632486951671362, "mean_inference_ms": 2.50589868068354, "mean_action_processing_ms": 0.3990218349201393, "mean_env_wait_ms": 0.3116190002486568, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047607421875, "StateBufferConnector_ms": 0.005362272262573242, "ViewRequirementAgentConnector_ms": 0.17841577529907227}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -180.00000000000065, "episode_return_mean": 142.7329999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.27696511747183, "num_env_steps_trained_throughput_per_sec": 304.27696511747183, "timesteps_total": 764000, "num_env_steps_sampled_lifetime": 764000, "num_agent_steps_sampled_lifetime": 3056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3056000, "timers": {"training_iteration_time_ms": 13221.341, "restore_workers_time_ms": 0.048, "training_step_time_ms": 13221.213, "sample_time_ms": 2095.472, "learn_time_ms": 11105.907, "learn_throughput": 360.169, "synch_weights_time_ms": 16.479}, "counters": {"num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "done": false, "training_iteration": 191, "trial_id": "04dec_00002", "date": "2024-08-13_17-05-20", "timestamp": 1723583120, "time_this_iter_s": 13.201891899108887, "time_total_s": 2546.6007277965546, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0724670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2546.6007277965546, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 68.48333333333332, "ram_util_percent": 83.71111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5110765868393832, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.47764219480059134, "policy_loss": 1.1024821707338252e-05, "vf_loss": 0.47763117127041654, "vf_explained_var": 0.0038751565905475113, "kl": 0.01039483502455958, "entropy": 0.3856945692625626, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 361935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.673337406929207, "cur_kl_coeff": 0.09384000746027181, "cur_lr": 0.00010000000000000003, "total_loss": 1.7013476620590875, "policy_loss": -0.0021371462788289937, "vf_loss": 1.700310770260594, "vf_explained_var": 0.9562333626091165, "kl": 0.03382393106194997, "entropy": 0.09192923086069564, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 361935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -180.00000000000065, "episode_reward_mean": 146.75899999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 61.3445, "predator_policy": 12.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.89999999999978, 37.80000000000027, 181.99999999999946, 40.0000000000003, 206.19999999999933, 40.0000000000003, 318.3, 26.8000000000001, 219.99999999999926, 40.0000000000003, 213.3999999999993, 153.09999999999957, 215.59999999999928, 35.90000000000024, 219.99999999999926, 219.99999999999926, 366.4, 183.99999999999943, 172.2, 197.69999999999936, 40.0000000000003, 177.29999999999944, 40.0000000000003, 211.3999999999993, 352.3, 145.09999999999962, 219.99999999999926, 40.0000000000003, 331.5, 400.0, 205.99999999999932, 40.0000000000003, 27.90000000000011, 106.0, 198.99999999999935, 30.10000000000015, 26.80000000000009, 199.99999999999935, 141.60000000000002, 40.0000000000003, 40.0000000000003, 210.9999999999993, 40.0000000000003, 36.60000000000025, 36.70000000000025, 208.99999999999932, 187.99999999999943, 217.99999999999926, 40.0000000000003, 375.0, 394.6, 400.0, 314.0, 34.50000000000022, 40.0000000000003, 203.99999999999932, 201.99999999999935, 40.0000000000003, 200.99999999999935, 187.9999999999994, 216.39999999999927, 32.30000000000018, 38.90000000000028, 219.99999999999926, 32.300000000000175, 40.0000000000003, 40.0000000000003, 201.99999999999935, 37.80000000000027, 25.700000000000077, 184.29999999999944, 148.8999999999996, 219.99999999999926, 219.99999999999926, 3.3000000000000007, 148.49999999999963, 40.0000000000003, 176.29999999999947, 378.0, 219.99999999999926, 371.0, -180.00000000000065, 34.50000000000022, 40.0000000000003, 193.0999999999994, 385.4, 27.100000000000104, 214.4999999999993, 194.2999999999994, 368.5, 40.0000000000003, 40.0000000000003, 26.80000000000009, 23.500000000000036, 34.50000000000022, 159.49999999999955, 219.99999999999926, 34.50000000000022, 40.0000000000003, 175.29999999999947], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.099999999999958, 92.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 143.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 180.2, 20.000000000000014, 20.000000000000014, 38.0, 182.3, 20.000000000000014, -5.199999999999937, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 200.0, 7.399999999999965, 55.7, 11.599999999999964, 200.0, 20.000000000000014, -3.099999999999979, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 151.4, 146.0, 20.000000000000014, 191.0, -383.8, 20.000000000000014, 169.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.3, 20.000000000000014, 20.000000000000014, 197.0, 7.399999999999965, 167.3, 173.0, 20.000000000000014, 25.099999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 167.9, 134.60000000000002, 200.0, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 2.0, -49.0, 158.0, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -5.19999999999993, 20.000000000000014, 170.0, -400.0, 176.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.9999999999999678, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -1.0000000000000098, 200.0, 20.000000000000014, 131.0, 20.000000000000014, 197.0, 20.000000000000014, 20.000000000000014, 182.0, 179.0, 194.6, 200.0, 200.0, 200.0, 137.0, 134.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 152.0, 20.000000000000014, 196.4, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 5.299999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 1.0999999999999652, 11.599999999999964, 156.2, 1.099999999999983, 119.9, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -393.7, -57.69999999999997, 159.2, 20.000000000000014, 20.000000000000014, 146.9, 7.399999999999977, 200.0, 167.0, 20.000000000000014, 200.0, 200.0, 149.0, 20.000000000000014, -400.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 150.2, 17.899999999999984, 200.0, 169.4, 13.699999999999969, 7.39999999999997, 200.0, 9.499999999999964, -9.699999999999882, 155.0, 194.0, 150.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999965, 17.899999999999988, 20.000000000000014, -11.499999999999826, 9.499999999999964, 20.000000000000014, 20.000000000000014, 111.5, 20.000000000000014, 200.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 134.3, 20.000000000000014], "policy_predator_policy_reward": [7.0, 36.0, 0.0, 2.0, 19.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 50.0, 48.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 52.0, 38.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 18.0, 0.0, 170.0, 195.0, 8.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 6.0, 1.0, 12.0, 0.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 11.0, 0.0, 83.0, 70.0, 11.0, 10.0, 5.0, 4.0, 12.0, 0.0, 10.0, 0.0, 165.0, 200.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 10.0, 14.0, 23.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 21.0, 22.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 9.0, 0.0, 0.0, 5.0, 6.0, 0.0, 16.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 13.0, 0.0, 12.0, 15.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 197.0, 0.0, 37.0, 10.0, 0.0, 0.0, 1.0, 21.0, 11.0, 0.0, 0.0, 0.0, 6.0, 16.0, 200.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 12.0, 8.0, 8.0, 0.0, 6.0, 5.0, 0.0, 25.0, 24.0, 15.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 4.0, 0.0, 15.0, 5.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8634349773604384, "mean_inference_ms": 2.508311688295221, "mean_action_processing_ms": 0.39841342950685105, "mean_env_wait_ms": 0.31191342056833016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01055610179901123, "StateBufferConnector_ms": 0.005663037300109863, "ViewRequirementAgentConnector_ms": 0.22922909259796143}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -180.00000000000065, "episode_return_mean": 146.75899999999984, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.1838081038386, "num_env_steps_trained_throughput_per_sec": 300.1838081038386, "timesteps_total": 768000, "num_env_steps_sampled_lifetime": 768000, "num_agent_steps_sampled_lifetime": 3072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3072000, "timers": {"training_iteration_time_ms": 13335.828, "restore_workers_time_ms": 0.048, "training_step_time_ms": 13335.696, "sample_time_ms": 2202.392, "learn_time_ms": 11113.53, "learn_throughput": 359.922, "synch_weights_time_ms": 16.321}, "counters": {"num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "done": false, "training_iteration": 192, "trial_id": "04dec_00002", "date": "2024-08-13_17-05-34", "timestamp": 1723583134, "time_this_iter_s": 13.396446943283081, "time_total_s": 2559.9971747398376, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b088f3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2559.9971747398376, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 63.305263157894736, "ram_util_percent": 83.56315789473685}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1698418417147227, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.2292172945405125, "policy_loss": 7.304951829451417e-05, "vf_loss": 0.2291442445512287, "vf_explained_var": 0.0003750846499488467, "kl": 0.015238394135829164, "entropy": 0.4014413128927271, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 363825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.581031904712557, "cur_kl_coeff": 0.14076001119040768, "cur_lr": 0.00010000000000000003, "total_loss": 1.5756113058990902, "policy_loss": 0.0002950326144133532, "vf_loss": 1.5747023274974217, "vf_explained_var": 0.9338738853023165, "kl": 0.004361627734771344, "entropy": 0.06172678033678383, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 363825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -180.00000000000065, "episode_reward_mean": 139.89399999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 58.922, "predator_policy": 11.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [172.2, 197.69999999999936, 40.0000000000003, 177.29999999999944, 40.0000000000003, 211.3999999999993, 352.3, 145.09999999999962, 219.99999999999926, 40.0000000000003, 331.5, 400.0, 205.99999999999932, 40.0000000000003, 27.90000000000011, 106.0, 198.99999999999935, 30.10000000000015, 26.80000000000009, 199.99999999999935, 141.60000000000002, 40.0000000000003, 40.0000000000003, 210.9999999999993, 40.0000000000003, 36.60000000000025, 36.70000000000025, 208.99999999999932, 187.99999999999943, 217.99999999999926, 40.0000000000003, 375.0, 394.6, 400.0, 314.0, 34.50000000000022, 40.0000000000003, 203.99999999999932, 201.99999999999935, 40.0000000000003, 200.99999999999935, 187.9999999999994, 216.39999999999927, 32.30000000000018, 38.90000000000028, 219.99999999999926, 32.300000000000175, 40.0000000000003, 40.0000000000003, 201.99999999999935, 37.80000000000027, 25.700000000000077, 184.29999999999944, 148.8999999999996, 219.99999999999926, 219.99999999999926, 3.3000000000000007, 148.49999999999963, 40.0000000000003, 176.29999999999947, 378.0, 219.99999999999926, 371.0, -180.00000000000065, 34.50000000000022, 40.0000000000003, 193.0999999999994, 385.4, 27.100000000000104, 214.4999999999993, 194.2999999999994, 368.5, 40.0000000000003, 40.0000000000003, 26.80000000000009, 23.500000000000036, 34.50000000000022, 159.49999999999955, 219.99999999999926, 34.50000000000022, 40.0000000000003, 175.29999999999947, 204.59999999999934, 219.99999999999926, 40.0000000000003, 190.9999999999994, 40.0000000000003, 188.4999999999994, 40.0000000000003, 40.90000000000031, 214.4999999999993, 202.99999999999935, 29.000000000000142, 34.50000000000022, 69.00000000000009, 197.99999999999937, 177.8999999999994, 193.99999999999937, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [191.0, -383.8, 20.000000000000014, 169.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 152.3, 20.000000000000014, 20.000000000000014, 197.0, 7.399999999999965, 167.3, 173.0, 20.000000000000014, 25.099999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 167.9, 134.60000000000002, 200.0, 200.0, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 2.0, -49.0, 158.0, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, -5.19999999999993, 20.000000000000014, 170.0, -400.0, 176.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.9999999999999678, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -1.0000000000000098, 200.0, 20.000000000000014, 131.0, 20.000000000000014, 197.0, 20.000000000000014, 20.000000000000014, 182.0, 179.0, 194.6, 200.0, 200.0, 200.0, 137.0, 134.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 152.0, 20.000000000000014, 196.4, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 5.299999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 1.0999999999999652, 11.599999999999964, 156.2, 1.099999999999983, 119.9, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -393.7, -57.69999999999997, 159.2, 20.000000000000014, 20.000000000000014, 146.9, 7.399999999999977, 200.0, 167.0, 20.000000000000014, 200.0, 200.0, 149.0, 20.000000000000014, -400.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 150.2, 17.899999999999984, 200.0, 169.4, 13.699999999999969, 7.39999999999997, 200.0, 9.499999999999964, -9.699999999999882, 155.0, 194.0, 150.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999965, 17.899999999999988, 20.000000000000014, -11.499999999999826, 9.499999999999964, 20.000000000000014, 20.000000000000014, 111.5, 20.000000000000014, 200.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 134.3, 20.000000000000014, 200.0, -9.399999999999865, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999972, 200.0, 191.0, -0.9999999999999881, 20.000000000000014, -1.0000000000000098, 9.499999999999964, 20.000000000000014, 41.00000000000021, 20.000000000000014, 167.0, 20.000000000000014, 140.89999999999998, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [170.0, 195.0, 8.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 6.0, 1.0, 12.0, 0.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 11.0, 0.0, 83.0, 70.0, 11.0, 10.0, 5.0, 4.0, 12.0, 0.0, 10.0, 0.0, 165.0, 200.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 10.0, 14.0, 23.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 21.0, 22.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 9.0, 0.0, 0.0, 5.0, 6.0, 0.0, 16.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 13.0, 0.0, 12.0, 15.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 197.0, 0.0, 37.0, 10.0, 0.0, 0.0, 1.0, 21.0, 11.0, 0.0, 0.0, 0.0, 6.0, 16.0, 200.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 12.0, 8.0, 8.0, 0.0, 6.0, 5.0, 0.0, 25.0, 24.0, 15.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 4.0, 0.0, 15.0, 5.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 3.0, 10.0, 0.0, 10.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 17.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8641840058090443, "mean_inference_ms": 2.5103150360841577, "mean_action_processing_ms": 0.3983816695713974, "mean_env_wait_ms": 0.31211400510558207, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01073300838470459, "StateBufferConnector_ms": 0.005670785903930664, "ViewRequirementAgentConnector_ms": 0.23449254035949707}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -180.00000000000065, "episode_return_mean": 139.89399999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 296.60322346998146, "num_env_steps_trained_throughput_per_sec": 296.60322346998146, "timesteps_total": 772000, "num_env_steps_sampled_lifetime": 772000, "num_agent_steps_sampled_lifetime": 3088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3088000, "timers": {"training_iteration_time_ms": 13450.373, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13450.297, "sample_time_ms": 2259.538, "learn_time_ms": 11170.038, "learn_throughput": 358.101, "synch_weights_time_ms": 17.293}, "counters": {"num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "done": false, "training_iteration": 193, "trial_id": "04dec_00002", "date": "2024-08-13_17-05-47", "timestamp": 1723583147, "time_this_iter_s": 13.5259370803833, "time_total_s": 2573.523111820221, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b088f550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2573.523111820221, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 69.995, "ram_util_percent": 83.63000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0842151119950272, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.22283221211422372, "policy_loss": -0.0009584296029061079, "vf_loss": 0.22379064250407277, "vf_explained_var": -0.0074922298628186425, "kl": 0.010176791224450876, "entropy": 0.4400970186979052, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 365715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.045750182204776, "cur_kl_coeff": 0.07038000559520384, "cur_lr": 0.00010000000000000003, "total_loss": 1.8490860732459518, "policy_loss": -0.0036660492478096216, "vf_loss": 1.852229691970916, "vf_explained_var": 0.9449674492159849, "kl": 0.007423051581133175, "entropy": 0.06839695019972702, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 365715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -180.00000000000065, "episode_reward_mean": 137.92199999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 60.86600000000001, "predator_policy": 8.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.80000000000009, 199.99999999999935, 141.60000000000002, 40.0000000000003, 40.0000000000003, 210.9999999999993, 40.0000000000003, 36.60000000000025, 36.70000000000025, 208.99999999999932, 187.99999999999943, 217.99999999999926, 40.0000000000003, 375.0, 394.6, 400.0, 314.0, 34.50000000000022, 40.0000000000003, 203.99999999999932, 201.99999999999935, 40.0000000000003, 200.99999999999935, 187.9999999999994, 216.39999999999927, 32.30000000000018, 38.90000000000028, 219.99999999999926, 32.300000000000175, 40.0000000000003, 40.0000000000003, 201.99999999999935, 37.80000000000027, 25.700000000000077, 184.29999999999944, 148.8999999999996, 219.99999999999926, 219.99999999999926, 3.3000000000000007, 148.49999999999963, 40.0000000000003, 176.29999999999947, 378.0, 219.99999999999926, 371.0, -180.00000000000065, 34.50000000000022, 40.0000000000003, 193.0999999999994, 385.4, 27.100000000000104, 214.4999999999993, 194.2999999999994, 368.5, 40.0000000000003, 40.0000000000003, 26.80000000000009, 23.500000000000036, 34.50000000000022, 159.49999999999955, 219.99999999999926, 34.50000000000022, 40.0000000000003, 175.29999999999947, 204.59999999999934, 219.99999999999926, 40.0000000000003, 190.9999999999994, 40.0000000000003, 188.4999999999994, 40.0000000000003, 40.90000000000031, 214.4999999999993, 202.99999999999935, 29.000000000000142, 34.50000000000022, 69.00000000000009, 197.99999999999937, 177.8999999999994, 193.99999999999937, 40.0000000000003, 40.0000000000003, 30.300000000000146, 210.0999999999993, 139.9999999999997, 34.50000000000022, 360.7, 38.90000000000028, 219.99999999999926, 40.0000000000003, 185.99999999999943, 192.9999999999994, 40.0000000000003, 195.99999999999937, 40.0000000000003, 400.0, 203.99999999999932, 36.70000000000025, 40.0000000000003, 329.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -5.19999999999993, 20.000000000000014, 170.0, -400.0, 176.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.9999999999999678, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -1.0000000000000098, 200.0, 20.000000000000014, 131.0, 20.000000000000014, 197.0, 20.000000000000014, 20.000000000000014, 182.0, 179.0, 194.6, 200.0, 200.0, 200.0, 137.0, 134.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 152.0, 20.000000000000014, 196.4, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 5.299999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 1.0999999999999652, 11.599999999999964, 156.2, 1.099999999999983, 119.9, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -393.7, -57.69999999999997, 159.2, 20.000000000000014, 20.000000000000014, 146.9, 7.399999999999977, 200.0, 167.0, 20.000000000000014, 200.0, 200.0, 149.0, 20.000000000000014, -400.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 150.2, 17.899999999999984, 200.0, 169.4, 13.699999999999969, 7.39999999999997, 200.0, 9.499999999999964, -9.699999999999882, 155.0, 194.0, 150.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999965, 17.899999999999988, 20.000000000000014, -11.499999999999826, 9.499999999999964, 20.000000000000014, 20.000000000000014, 111.5, 20.000000000000014, 200.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 134.3, 20.000000000000014, 200.0, -9.399999999999865, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999972, 200.0, 191.0, -0.9999999999999881, 20.000000000000014, -1.0000000000000098, 9.499999999999964, 20.000000000000014, 41.00000000000021, 20.000000000000014, 167.0, 20.000000000000014, 140.89999999999998, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 200.0, 1.0999999999999865, 20.000000000000014, 80.0, 9.499999999999966, 20.000000000000014, 200.0, 148.70000000000002, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 155.0, 148.1], "policy_predator_policy_reward": [12.0, 0.0, 10.0, 0.0, 165.0, 200.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 10.0, 14.0, 23.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 21.0, 22.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 9.0, 0.0, 0.0, 5.0, 6.0, 0.0, 16.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 13.0, 0.0, 12.0, 15.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 197.0, 0.0, 37.0, 10.0, 0.0, 0.0, 1.0, 21.0, 11.0, 0.0, 0.0, 0.0, 6.0, 16.0, 200.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 12.0, 8.0, 8.0, 0.0, 6.0, 5.0, 0.0, 25.0, 24.0, 15.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 4.0, 0.0, 15.0, 5.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 3.0, 10.0, 0.0, 10.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 17.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 40.0, 0.0, 5.0, 0.0, 11.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 26.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8647886957009109, "mean_inference_ms": 2.511953065703695, "mean_action_processing_ms": 0.39831528256695814, "mean_env_wait_ms": 0.312280702516074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010476231575012207, "StateBufferConnector_ms": 0.005557060241699219, "ViewRequirementAgentConnector_ms": 0.2216651439666748}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -180.00000000000065, "episode_return_mean": 137.92199999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.2699587690287, "num_env_steps_trained_throughput_per_sec": 339.2699587690287, "timesteps_total": 776000, "num_env_steps_sampled_lifetime": 776000, "num_agent_steps_sampled_lifetime": 3104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3104000, "timers": {"training_iteration_time_ms": 13146.123, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13146.045, "sample_time_ms": 2222.683, "learn_time_ms": 10902.64, "learn_throughput": 366.884, "synch_weights_time_ms": 17.409}, "counters": {"num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "done": false, "training_iteration": 194, "trial_id": "04dec_00002", "date": "2024-08-13_17-05-59", "timestamp": 1723583159, "time_this_iter_s": 11.839170694351196, "time_total_s": 2585.362282514572, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b088fee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2585.362282514572, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 65.64999999999999, "ram_util_percent": 83.575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2657928878687834, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.11995487601235115, "policy_loss": 0.000540369376540184, "vf_loss": 0.11941450630338055, "vf_explained_var": -0.061432157780127554, "kl": 0.01867826472206769, "entropy": 0.40905066238193916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 367605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.382198753432622, "cur_kl_coeff": 0.07038000559520384, "cur_lr": 0.00010000000000000003, "total_loss": 1.767269684208764, "policy_loss": -0.007072540907997382, "vf_loss": 1.7733733806975935, "vf_explained_var": 0.9280241784279939, "kl": 0.01376586556098219, "entropy": 0.09188811946857385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 367605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -180.00000000000065, "episode_reward_mean": 140.5669999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 64.0235, "predator_policy": 6.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 203.99999999999932, 201.99999999999935, 40.0000000000003, 200.99999999999935, 187.9999999999994, 216.39999999999927, 32.30000000000018, 38.90000000000028, 219.99999999999926, 32.300000000000175, 40.0000000000003, 40.0000000000003, 201.99999999999935, 37.80000000000027, 25.700000000000077, 184.29999999999944, 148.8999999999996, 219.99999999999926, 219.99999999999926, 3.3000000000000007, 148.49999999999963, 40.0000000000003, 176.29999999999947, 378.0, 219.99999999999926, 371.0, -180.00000000000065, 34.50000000000022, 40.0000000000003, 193.0999999999994, 385.4, 27.100000000000104, 214.4999999999993, 194.2999999999994, 368.5, 40.0000000000003, 40.0000000000003, 26.80000000000009, 23.500000000000036, 34.50000000000022, 159.49999999999955, 219.99999999999926, 34.50000000000022, 40.0000000000003, 175.29999999999947, 204.59999999999934, 219.99999999999926, 40.0000000000003, 190.9999999999994, 40.0000000000003, 188.4999999999994, 40.0000000000003, 40.90000000000031, 214.4999999999993, 202.99999999999935, 29.000000000000142, 34.50000000000022, 69.00000000000009, 197.99999999999937, 177.8999999999994, 193.99999999999937, 40.0000000000003, 40.0000000000003, 30.300000000000146, 210.0999999999993, 139.9999999999997, 34.50000000000022, 360.7, 38.90000000000028, 219.99999999999926, 40.0000000000003, 185.99999999999943, 192.9999999999994, 40.0000000000003, 195.99999999999937, 40.0000000000003, 400.0, 203.99999999999932, 36.70000000000025, 40.0000000000003, 329.1, 40.0000000000003, 177.59999999999945, 40.0000000000003, 218.89999999999927, 400.0, 219.99999999999926, 208.99999999999932, 34.50000000000022, 207.99999999999932, 40.0000000000003, 193.89999999999938, 40.0000000000003, 363.1, 219.99999999999926, 197.99999999999937, 207.49999999999932, 189.9999999999994, 209.7999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 152.0, 20.000000000000014, 196.4, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 5.299999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 15.799999999999963, 1.0999999999999652, 11.599999999999964, 156.2, 1.099999999999983, 119.9, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, -393.7, -57.69999999999997, 159.2, 20.000000000000014, 20.000000000000014, 146.9, 7.399999999999977, 200.0, 167.0, 20.000000000000014, 200.0, 200.0, 149.0, 20.000000000000014, -400.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 150.2, 17.899999999999984, 200.0, 169.4, 13.699999999999969, 7.39999999999997, 200.0, 9.499999999999964, -9.699999999999882, 155.0, 194.0, 150.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999965, 17.899999999999988, 20.000000000000014, -11.499999999999826, 9.499999999999964, 20.000000000000014, 20.000000000000014, 111.5, 20.000000000000014, 200.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 134.3, 20.000000000000014, 200.0, -9.399999999999865, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999972, 200.0, 191.0, -0.9999999999999881, 20.000000000000014, -1.0000000000000098, 9.499999999999964, 20.000000000000014, 41.00000000000021, 20.000000000000014, 167.0, 20.000000000000014, 140.89999999999998, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 200.0, 1.0999999999999865, 20.000000000000014, 80.0, 9.499999999999966, 20.000000000000014, 200.0, 148.70000000000002, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 155.0, 148.1, 20.000000000000014, 20.000000000000014, 125.60000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 200.0, 200.0, 20.000000000000014, -0.9999999999999992, 200.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.9, 20.000000000000014, 20.000000000000014, 151.10000000000002, 197.0, 20.000000000000014, 200.0, -21.999999999999744, 200.0, 183.5, 20.000000000000014, 20.000000000000014, 155.0, 182.0, 15.799999999999963], "policy_predator_policy_reward": [0.0, 0.0, 2.0, 6.0, 0.0, 9.0, 0.0, 0.0, 5.0, 6.0, 0.0, 16.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 13.0, 0.0, 12.0, 15.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 197.0, 0.0, 37.0, 10.0, 0.0, 0.0, 1.0, 21.0, 11.0, 0.0, 0.0, 0.0, 6.0, 16.0, 200.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 12.0, 8.0, 8.0, 0.0, 6.0, 5.0, 0.0, 25.0, 24.0, 15.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 4.0, 0.0, 15.0, 5.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 3.0, 10.0, 0.0, 10.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 17.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 40.0, 0.0, 5.0, 0.0, 11.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 12.0, 12.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 20.0, 0.0, 0.0, 4.0, 15.0, 0.0, 6.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8654546763234134, "mean_inference_ms": 2.5137633785293296, "mean_action_processing_ms": 0.3982772994502484, "mean_env_wait_ms": 0.3124410041840854, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010495662689208984, "StateBufferConnector_ms": 0.005161285400390625, "ViewRequirementAgentConnector_ms": 0.22838616371154785}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -180.00000000000065, "episode_return_mean": 140.5669999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.495486615431, "num_env_steps_trained_throughput_per_sec": 319.495486615431, "timesteps_total": 780000, "num_env_steps_sampled_lifetime": 780000, "num_agent_steps_sampled_lifetime": 3120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3120000, "timers": {"training_iteration_time_ms": 13043.826, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13043.766, "sample_time_ms": 2236.836, "learn_time_ms": 10786.358, "learn_throughput": 370.839, "synch_weights_time_ms": 17.243}, "counters": {"num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "done": false, "training_iteration": 195, "trial_id": "04dec_00002", "date": "2024-08-13_17-06-12", "timestamp": 1723583172, "time_this_iter_s": 12.56722092628479, "time_total_s": 2597.929503440857, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0733ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2597.929503440857, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 68.57222222222224, "ram_util_percent": 83.43888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6205873918517557, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.37558032722069473, "policy_loss": -0.0005657580254904965, "vf_loss": 0.3761460862314654, "vf_explained_var": 0.054406994707369934, "kl": 0.014928394000799254, "entropy": 0.4479484625594326, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 369495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.707836577627393, "cur_kl_coeff": 0.07038000559520384, "cur_lr": 0.00010000000000000003, "total_loss": 1.3943733588728324, "policy_loss": -0.0028911444671432334, "vf_loss": 1.395783408987459, "vf_explained_var": 0.9287636477165121, "kl": 0.021044267958119006, "entropy": 0.0861477583932577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 369495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -180.00000000000065, "episode_reward_mean": 139.1749999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 64.6475, "predator_policy": 4.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-180.00000000000065, 34.50000000000022, 40.0000000000003, 193.0999999999994, 385.4, 27.100000000000104, 214.4999999999993, 194.2999999999994, 368.5, 40.0000000000003, 40.0000000000003, 26.80000000000009, 23.500000000000036, 34.50000000000022, 159.49999999999955, 219.99999999999926, 34.50000000000022, 40.0000000000003, 175.29999999999947, 204.59999999999934, 219.99999999999926, 40.0000000000003, 190.9999999999994, 40.0000000000003, 188.4999999999994, 40.0000000000003, 40.90000000000031, 214.4999999999993, 202.99999999999935, 29.000000000000142, 34.50000000000022, 69.00000000000009, 197.99999999999937, 177.8999999999994, 193.99999999999937, 40.0000000000003, 40.0000000000003, 30.300000000000146, 210.0999999999993, 139.9999999999997, 34.50000000000022, 360.7, 38.90000000000028, 219.99999999999926, 40.0000000000003, 185.99999999999943, 192.9999999999994, 40.0000000000003, 195.99999999999937, 40.0000000000003, 400.0, 203.99999999999932, 36.70000000000025, 40.0000000000003, 329.1, 40.0000000000003, 177.59999999999945, 40.0000000000003, 218.89999999999927, 400.0, 219.99999999999926, 208.99999999999932, 34.50000000000022, 207.99999999999932, 40.0000000000003, 193.89999999999938, 40.0000000000003, 363.1, 219.99999999999926, 197.99999999999937, 207.49999999999932, 189.9999999999994, 209.7999999999993, 245.1999999999991, 219.99999999999926, 40.0000000000003, 169.7999999999995, 207.99999999999932, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.30000000000051, 187.9999999999994, 218.19999999999925, 40.0000000000003, 219.99999999999926, 180.99999999999946, 38.90000000000028, 40.0000000000003, 175.49999999999946, 40.0000000000003, 25.700000000000067, 40.0000000000003, 40.0000000000003, 213.69999999999928, 48.50000000000044, 213.69999999999928, 382.0, 364.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -400.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 150.2, 17.899999999999984, 200.0, 169.4, 13.699999999999969, 7.39999999999997, 200.0, 9.499999999999964, -9.699999999999882, 155.0, 194.0, 150.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999965, 17.899999999999988, 20.000000000000014, -11.499999999999826, 9.499999999999964, 20.000000000000014, 20.000000000000014, 111.5, 20.000000000000014, 200.0, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 134.3, 20.000000000000014, 200.0, -9.399999999999865, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999972, 200.0, 191.0, -0.9999999999999881, 20.000000000000014, -1.0000000000000098, 9.499999999999964, 20.000000000000014, 41.00000000000021, 20.000000000000014, 167.0, 20.000000000000014, 140.89999999999998, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 200.0, 1.0999999999999865, 20.000000000000014, 80.0, 9.499999999999966, 20.000000000000014, 200.0, 148.70000000000002, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 155.0, 148.1, 20.000000000000014, 20.000000000000014, 125.60000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 200.0, 200.0, 20.000000000000014, -0.9999999999999992, 200.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.9, 20.000000000000014, 20.000000000000014, 151.10000000000002, 197.0, 20.000000000000014, 200.0, -21.999999999999744, 200.0, 183.5, 20.000000000000014, 20.000000000000014, 155.0, 182.0, 15.799999999999963, 45.200000000000244, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 126.80000000000001, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 149.0, 20.000000000000014, 198.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -0.9999999999999917, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 123.5, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 191.0, 21.500000000000036, 20.000000000000014, 193.7, 20.000000000000014, 200.0, 173.0, 161.0, 188.0], "policy_predator_policy_reward": [200.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 12.0, 8.0, 8.0, 0.0, 6.0, 5.0, 0.0, 25.0, 24.0, 15.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 4.0, 0.0, 15.0, 5.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 3.0, 10.0, 0.0, 10.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 17.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 40.0, 0.0, 5.0, 0.0, 11.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 12.0, 12.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 20.0, 0.0, 0.0, 4.0, 15.0, 0.0, 6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 2.0, 6.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 24.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 7.0, 0.0, 0.0, 3.0, 6.0, 5.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8658596740596463, "mean_inference_ms": 2.51264471118456, "mean_action_processing_ms": 0.39813733311834654, "mean_env_wait_ms": 0.31244572562672657, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010131239891052246, "StateBufferConnector_ms": 0.0035500526428222656, "ViewRequirementAgentConnector_ms": 0.16976332664489746}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -180.00000000000065, "episode_return_mean": 139.1749999999998, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.1012565646221, "num_env_steps_trained_throughput_per_sec": 322.1012565646221, "timesteps_total": 784000, "num_env_steps_sampled_lifetime": 784000, "num_agent_steps_sampled_lifetime": 3136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3136000, "timers": {"training_iteration_time_ms": 12907.662, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12907.602, "sample_time_ms": 2165.094, "learn_time_ms": 10722.453, "learn_throughput": 373.049, "synch_weights_time_ms": 16.657}, "counters": {"num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "done": false, "training_iteration": 196, "trial_id": "04dec_00002", "date": "2024-08-13_17-06-24", "timestamp": 1723583184, "time_this_iter_s": 12.468324661254883, "time_total_s": 2610.397828102112, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0774ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2610.397828102112, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 66.64444444444445, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0883139067147143, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.5864881104183576, "policy_loss": -0.0037628764194244193, "vf_loss": 0.5902509873407701, "vf_explained_var": 0.0016863634662022666, "kl": 0.01329385998690827, "entropy": 0.46643030868951607, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 371385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.488286000017137, "cur_kl_coeff": 0.10557000839280574, "cur_lr": 0.00010000000000000003, "total_loss": 2.413455864235207, "policy_loss": -0.001393360060900844, "vf_loss": 2.414584151525346, "vf_explained_var": 0.6606192164004795, "kl": 0.0025109272158575554, "entropy": 0.05540467816400071, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 371385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 8.999999999999998, "episode_reward_mean": 140.8019999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 65.786, "predator_policy": 4.615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [175.29999999999947, 204.59999999999934, 219.99999999999926, 40.0000000000003, 190.9999999999994, 40.0000000000003, 188.4999999999994, 40.0000000000003, 40.90000000000031, 214.4999999999993, 202.99999999999935, 29.000000000000142, 34.50000000000022, 69.00000000000009, 197.99999999999937, 177.8999999999994, 193.99999999999937, 40.0000000000003, 40.0000000000003, 30.300000000000146, 210.0999999999993, 139.9999999999997, 34.50000000000022, 360.7, 38.90000000000028, 219.99999999999926, 40.0000000000003, 185.99999999999943, 192.9999999999994, 40.0000000000003, 195.99999999999937, 40.0000000000003, 400.0, 203.99999999999932, 36.70000000000025, 40.0000000000003, 329.1, 40.0000000000003, 177.59999999999945, 40.0000000000003, 218.89999999999927, 400.0, 219.99999999999926, 208.99999999999932, 34.50000000000022, 207.99999999999932, 40.0000000000003, 193.89999999999938, 40.0000000000003, 363.1, 219.99999999999926, 197.99999999999937, 207.49999999999932, 189.9999999999994, 209.7999999999993, 245.1999999999991, 219.99999999999926, 40.0000000000003, 169.7999999999995, 207.99999999999932, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.30000000000051, 187.9999999999994, 218.19999999999925, 40.0000000000003, 219.99999999999926, 180.99999999999946, 38.90000000000028, 40.0000000000003, 175.49999999999946, 40.0000000000003, 25.700000000000067, 40.0000000000003, 40.0000000000003, 213.69999999999928, 48.50000000000044, 213.69999999999928, 382.0, 364.0, 368.3000000000003, 170.69999999999948, 188.09999999999908, 21.300000000000008, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 193.2999999999994, 196.59999999999937, 37.80000000000027, 40.0000000000003, 34.50000000000022, 29.30000000000013, 185.99999999999943, 40.0000000000003, 8.999999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [134.3, 20.000000000000014, 200.0, -9.399999999999865, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999972, 200.0, 191.0, -0.9999999999999881, 20.000000000000014, -1.0000000000000098, 9.499999999999964, 20.000000000000014, 41.00000000000021, 20.000000000000014, 167.0, 20.000000000000014, 140.89999999999998, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 200.0, 1.0999999999999865, 20.000000000000014, 80.0, 9.499999999999966, 20.000000000000014, 200.0, 148.70000000000002, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 155.0, 148.1, 20.000000000000014, 20.000000000000014, 125.60000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 200.0, 200.0, 20.000000000000014, -0.9999999999999992, 200.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.9, 20.000000000000014, 20.000000000000014, 151.10000000000002, 197.0, 20.000000000000014, 200.0, -21.999999999999744, 200.0, 183.5, 20.000000000000014, 20.000000000000014, 155.0, 182.0, 15.799999999999963, 45.200000000000244, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 126.80000000000001, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 149.0, 20.000000000000014, 198.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -0.9999999999999917, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 123.5, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 191.0, 21.500000000000036, 20.000000000000014, 193.7, 20.000000000000014, 200.0, 173.0, 161.0, 188.0, 200.0, 158.29999999999993, 7.399999999999965, 101.3, 166.09999999999982, 20.000000000000014, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 176.6, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 197.0, -379.0], "policy_predator_policy_reward": [21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 3.0, 10.0, 0.0, 10.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 17.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 40.0, 0.0, 5.0, 0.0, 11.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 12.0, 12.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 20.0, 0.0, 0.0, 4.0, 15.0, 0.0, 6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 2.0, 6.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 24.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 7.0, 0.0, 0.0, 3.0, 6.0, 5.0, 10.0, 10.0, 0.0, 30.0, 32.0, 0.0, 2.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 17.0, 0.0, 0.0, 0.0, 1.0, 190.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8655758875284182, "mean_inference_ms": 2.5145660109199084, "mean_action_processing_ms": 0.3976673130424787, "mean_env_wait_ms": 0.3123110381008315, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004393458366394043, "StateBufferConnector_ms": 0.0033469200134277344, "ViewRequirementAgentConnector_ms": 0.14658820629119873}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 8.999999999999998, "episode_return_mean": 140.8019999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.9555208693735, "num_env_steps_trained_throughput_per_sec": 324.9555208693735, "timesteps_total": 788000, "num_env_steps_sampled_lifetime": 788000, "num_agent_steps_sampled_lifetime": 3152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3152000, "timers": {"training_iteration_time_ms": 12683.073, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12683.005, "sample_time_ms": 1996.671, "learn_time_ms": 10666.112, "learn_throughput": 375.02, "synch_weights_time_ms": 16.642}, "counters": {"num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "done": false, "training_iteration": 197, "trial_id": "04dec_00002", "date": "2024-08-13_17-06-37", "timestamp": 1723583197, "time_this_iter_s": 12.376277923583984, "time_total_s": 2622.774106025696, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0774b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2622.774106025696, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 67.23529411764704, "ram_util_percent": 83.61764705882354}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7898602234741683, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.19558180839848266, "policy_loss": -0.0006194945040439802, "vf_loss": 0.19620130264361804, "vf_explained_var": -0.018848414585073157, "kl": 0.010198424263245576, "entropy": 0.4827714489408271, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 373275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.98671510847157, "cur_kl_coeff": 0.05278500419640287, "cur_lr": 0.00010000000000000003, "total_loss": 1.3007425311381224, "policy_loss": -3.876186052347144e-05, "vf_loss": 1.3005832393333394, "vf_explained_var": 0.9320461616314277, "kl": 0.0037520681468155674, "entropy": 0.047158323492480336, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 373275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 8.999999999999998, "episode_reward_mean": 137.95799999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 64.409, "predator_policy": 4.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 30.300000000000146, 210.0999999999993, 139.9999999999997, 34.50000000000022, 360.7, 38.90000000000028, 219.99999999999926, 40.0000000000003, 185.99999999999943, 192.9999999999994, 40.0000000000003, 195.99999999999937, 40.0000000000003, 400.0, 203.99999999999932, 36.70000000000025, 40.0000000000003, 329.1, 40.0000000000003, 177.59999999999945, 40.0000000000003, 218.89999999999927, 400.0, 219.99999999999926, 208.99999999999932, 34.50000000000022, 207.99999999999932, 40.0000000000003, 193.89999999999938, 40.0000000000003, 363.1, 219.99999999999926, 197.99999999999937, 207.49999999999932, 189.9999999999994, 209.7999999999993, 245.1999999999991, 219.99999999999926, 40.0000000000003, 169.7999999999995, 207.99999999999932, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.30000000000051, 187.9999999999994, 218.19999999999925, 40.0000000000003, 219.99999999999926, 180.99999999999946, 38.90000000000028, 40.0000000000003, 175.49999999999946, 40.0000000000003, 25.700000000000067, 40.0000000000003, 40.0000000000003, 213.69999999999928, 48.50000000000044, 213.69999999999928, 382.0, 364.0, 368.3000000000003, 170.69999999999948, 188.09999999999908, 21.300000000000008, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 193.2999999999994, 196.59999999999937, 37.80000000000027, 40.0000000000003, 34.50000000000022, 29.30000000000013, 185.99999999999943, 40.0000000000003, 8.999999999999998, 29.000000000000128, 40.0000000000003, 40.0000000000003, 40.0000000000003, 398.0, 40.0000000000003, 35.600000000000236, 33.400000000000205, 328.9, 40.0000000000003, 72.89999999999968, 40.0000000000003, 40.0000000000003, 203.39999999999935, 210.49999999999932, 191.9999999999994, 40.0000000000003, 192.0999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 200.0, 1.0999999999999865, 20.000000000000014, 80.0, 9.499999999999966, 20.000000000000014, 200.0, 148.70000000000002, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 155.0, 148.1, 20.000000000000014, 20.000000000000014, 125.60000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 200.0, 200.0, 20.000000000000014, -0.9999999999999992, 200.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.9, 20.000000000000014, 20.000000000000014, 151.10000000000002, 197.0, 20.000000000000014, 200.0, -21.999999999999744, 200.0, 183.5, 20.000000000000014, 20.000000000000014, 155.0, 182.0, 15.799999999999963, 45.200000000000244, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 126.80000000000001, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 149.0, 20.000000000000014, 198.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -0.9999999999999917, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 123.5, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 191.0, 21.500000000000036, 20.000000000000014, 193.7, 20.000000000000014, 200.0, 173.0, 161.0, 188.0, 200.0, 158.29999999999993, 7.399999999999965, 101.3, 166.09999999999982, 20.000000000000014, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 176.6, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 197.0, -379.0, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 7.399999999999965, 128.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, -27.099999999999852, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -1.0000000000000062, 193.4, 9.499999999999968, 185.0, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 172.1, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 40.0, 0.0, 5.0, 0.0, 11.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 12.0, 12.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 20.0, 0.0, 0.0, 4.0, 15.0, 0.0, 6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 2.0, 6.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 24.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 7.0, 0.0, 0.0, 3.0, 6.0, 5.0, 10.0, 10.0, 0.0, 30.0, 32.0, 0.0, 2.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 17.0, 0.0, 0.0, 0.0, 1.0, 190.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 38.0, 0.0, 0.0, 0.0, 0.0, 5.0, 6.0, 8.0, 8.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8654298084713596, "mean_inference_ms": 2.5144738403199978, "mean_action_processing_ms": 0.397357272513335, "mean_env_wait_ms": 0.3121243869924973, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00437474250793457, "StateBufferConnector_ms": 0.0036126375198364258, "ViewRequirementAgentConnector_ms": 0.13331961631774902}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 8.999999999999998, "episode_return_mean": 137.95799999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.0644325790197, "num_env_steps_trained_throughput_per_sec": 311.0644325790197, "timesteps_total": 792000, "num_env_steps_sampled_lifetime": 792000, "num_agent_steps_sampled_lifetime": 3168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3168000, "timers": {"training_iteration_time_ms": 12683.027, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12682.956, "sample_time_ms": 2060.216, "learn_time_ms": 10603.042, "learn_throughput": 377.25, "synch_weights_time_ms": 16.426}, "counters": {"num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "done": false, "training_iteration": 198, "trial_id": "04dec_00002", "date": "2024-08-13_17-06-50", "timestamp": 1723583210, "time_this_iter_s": 12.918667078018188, "time_total_s": 2635.692773103714, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0876e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2635.692773103714, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 70.88888888888889, "ram_util_percent": 83.74444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4918045707007566, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.9402205417553584, "policy_loss": -0.0003312953114608135, "vf_loss": 0.940551835511412, "vf_explained_var": 0.0025931708081058723, "kl": 0.011434534823501971, "entropy": 0.4973307919407648, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 375165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.703649279900958, "cur_kl_coeff": 0.026392502098201435, "cur_lr": 0.00010000000000000003, "total_loss": 1.6994316580118956, "policy_loss": 0.0008946413821023371, "vf_loss": 1.698327999487125, "vf_explained_var": 0.6881170833236957, "kl": 0.00791958718171372, "entropy": 0.04350725273261704, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 375165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -151.40000000000052, "episode_reward_mean": 137.95299999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 63.33650000000001, "predator_policy": 5.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [329.1, 40.0000000000003, 177.59999999999945, 40.0000000000003, 218.89999999999927, 400.0, 219.99999999999926, 208.99999999999932, 34.50000000000022, 207.99999999999932, 40.0000000000003, 193.89999999999938, 40.0000000000003, 363.1, 219.99999999999926, 197.99999999999937, 207.49999999999932, 189.9999999999994, 209.7999999999993, 245.1999999999991, 219.99999999999926, 40.0000000000003, 169.7999999999995, 207.99999999999932, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.30000000000051, 187.9999999999994, 218.19999999999925, 40.0000000000003, 219.99999999999926, 180.99999999999946, 38.90000000000028, 40.0000000000003, 175.49999999999946, 40.0000000000003, 25.700000000000067, 40.0000000000003, 40.0000000000003, 213.69999999999928, 48.50000000000044, 213.69999999999928, 382.0, 364.0, 368.3000000000003, 170.69999999999948, 188.09999999999908, 21.300000000000008, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 193.2999999999994, 196.59999999999937, 37.80000000000027, 40.0000000000003, 34.50000000000022, 29.30000000000013, 185.99999999999943, 40.0000000000003, 8.999999999999998, 29.000000000000128, 40.0000000000003, 40.0000000000003, 40.0000000000003, 398.0, 40.0000000000003, 35.600000000000236, 33.400000000000205, 328.9, 40.0000000000003, 72.89999999999968, 40.0000000000003, 40.0000000000003, 203.39999999999935, 210.49999999999932, 191.9999999999994, 40.0000000000003, 192.0999999999994, 173.9999999999995, 29.000000000000128, 187.59999999999943, 188.9999999999994, 386.0, 197.99999999999937, 217.99999999999926, 40.0000000000003, 374.0, 211.9999999999993, 40.0000000000003, 30.100000000000147, 40.0000000000003, 36.70000000000025, 209.9999999999993, 36.70000000000025, 199.99999999999935, -151.40000000000052], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [155.0, 148.1, 20.000000000000014, 20.000000000000014, 125.60000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 200.0, 200.0, 20.000000000000014, -0.9999999999999992, 200.0, 20.000000000000014, 9.499999999999964, 20.000000000000014, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.9, 20.000000000000014, 20.000000000000014, 151.10000000000002, 197.0, 20.000000000000014, 200.0, -21.999999999999744, 200.0, 183.5, 20.000000000000014, 20.000000000000014, 155.0, 182.0, 15.799999999999963, 45.200000000000244, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 126.80000000000001, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 149.0, 20.000000000000014, 198.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -0.9999999999999917, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 123.5, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 191.0, 21.500000000000036, 20.000000000000014, 193.7, 20.000000000000014, 200.0, 173.0, 161.0, 188.0, 200.0, 158.29999999999993, 7.399999999999965, 101.3, 166.09999999999982, 20.000000000000014, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 176.6, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 197.0, -379.0, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 7.399999999999965, 128.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, -27.099999999999852, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -1.0000000000000062, 193.4, 9.499999999999968, 185.0, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 172.1, 20.000000000000014, 20.000000000000014, 122.0, 20.000000000000014, -0.9999999999999992, 162.2, 7.399999999999965, 161.0, -0.9999999999999846, 185.0, 194.0, 20.000000000000014, 167.0, 20.000000000000014, 197.0, 20.000000000000014, 20.000000000000014, 161.0, 200.0, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, 20.000000000000014, 13.699999999999966, 20.000000000000014, 185.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 170.0, 20.000000000000014, -322.3, -3.099999999999965], "policy_predator_policy_reward": [26.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 12.0, 12.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 20.0, 0.0, 0.0, 4.0, 15.0, 0.0, 6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 2.0, 6.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 24.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 7.0, 0.0, 0.0, 3.0, 6.0, 5.0, 10.0, 10.0, 0.0, 30.0, 32.0, 0.0, 2.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 17.0, 0.0, 0.0, 0.0, 1.0, 190.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 38.0, 0.0, 0.0, 0.0, 0.0, 5.0, 6.0, 8.0, 8.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 17.0, 2.0, 8.0, 6.0, 12.0, 17.0, 12.0, 7.0, 0.0, 11.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 13.0, 0.0, 4.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 3.0, 0.0, 0.0, 5.0, 3.0, 0.0, 10.0, 0.0, 174.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8653746287858276, "mean_inference_ms": 2.514619292230358, "mean_action_processing_ms": 0.39707988320712195, "mean_env_wait_ms": 0.31195538665790723, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004912614822387695, "StateBufferConnector_ms": 0.00458836555480957, "ViewRequirementAgentConnector_ms": 0.1467278003692627}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -151.40000000000052, "episode_return_mean": 137.95299999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.29929333400156, "num_env_steps_trained_throughput_per_sec": 317.29929333400156, "timesteps_total": 796000, "num_env_steps_sampled_lifetime": 796000, "num_agent_steps_sampled_lifetime": 3184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3184000, "timers": {"training_iteration_time_ms": 12689.723, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12689.651, "sample_time_ms": 2046.774, "learn_time_ms": 10621.415, "learn_throughput": 376.598, "synch_weights_time_ms": 17.738}, "counters": {"num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "done": false, "training_iteration": 199, "trial_id": "04dec_00002", "date": "2024-08-13_17-07-03", "timestamp": 1723583223, "time_this_iter_s": 12.642581939697266, "time_total_s": 2648.3353550434113, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b086f310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2648.3353550434113, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 66.83333333333333, "ram_util_percent": 83.3777777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.005011236328612, "cur_kl_coeff": 2.747485574473709e-21, "cur_lr": 0.00010000000000000003, "total_loss": 0.7208903527764416, "policy_loss": -0.001066094660569751, "vf_loss": 0.7219564467392586, "vf_explained_var": 0.0018185995873950776, "kl": 0.01040439152311974, "entropy": 0.5045766178893034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 377055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.224990034261078, "cur_kl_coeff": 0.026392502098201435, "cur_lr": 0.00010000000000000003, "total_loss": 1.8188920182210429, "policy_loss": -0.01320476828219379, "vf_loss": 1.8315313304227496, "vf_explained_var": 0.8142530808373103, "kl": 0.02142476442557326, "entropy": 0.13551653175067807, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 377055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "env_runners": {"episode_reward_max": 398.0, "episode_reward_min": -180.00000000000065, "episode_reward_mean": 130.38899999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 56.3345, "predator_policy": 8.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 55.30000000000051, 187.9999999999994, 218.19999999999925, 40.0000000000003, 219.99999999999926, 180.99999999999946, 38.90000000000028, 40.0000000000003, 175.49999999999946, 40.0000000000003, 25.700000000000067, 40.0000000000003, 40.0000000000003, 213.69999999999928, 48.50000000000044, 213.69999999999928, 382.0, 364.0, 368.3000000000003, 170.69999999999948, 188.09999999999908, 21.300000000000008, 203.99999999999935, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 193.2999999999994, 196.59999999999937, 37.80000000000027, 40.0000000000003, 34.50000000000022, 29.30000000000013, 185.99999999999943, 40.0000000000003, 8.999999999999998, 29.000000000000128, 40.0000000000003, 40.0000000000003, 40.0000000000003, 398.0, 40.0000000000003, 35.600000000000236, 33.400000000000205, 328.9, 40.0000000000003, 72.89999999999968, 40.0000000000003, 40.0000000000003, 203.39999999999935, 210.49999999999932, 191.9999999999994, 40.0000000000003, 192.0999999999994, 173.9999999999995, 29.000000000000128, 187.59999999999943, 188.9999999999994, 386.0, 197.99999999999937, 217.99999999999926, 40.0000000000003, 374.0, 211.9999999999993, 40.0000000000003, 30.100000000000147, 40.0000000000003, 36.70000000000025, 209.9999999999993, 36.70000000000025, 199.99999999999935, -151.40000000000052, 349.0, 216.39999999999927, 219.09999999999926, -180.00000000000065, 219.99999999999926, 32.30000000000019, 203.99999999999935, 160.0999999999996, -148.10000000000048, 216.69999999999928, 179.59999999999945, 34.50000000000022, 7.699999999999996, 362.3, 219.09999999999926, 192.4999999999994, 209.99999999999932, 190.5999999999994, 40.0000000000003, 40.0000000000003, 374.4, 166.39999999999952, 151.5999999999996, 193.99999999999937, 37.80000000000027, 40.0000000000003, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 149.0, 20.000000000000014, 198.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -0.9999999999999917, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 123.5, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 191.0, 21.500000000000036, 20.000000000000014, 193.7, 20.000000000000014, 200.0, 173.0, 161.0, 188.0, 200.0, 158.29999999999993, 7.399999999999965, 101.3, 166.09999999999982, 20.000000000000014, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 176.6, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 149.0, 20.000000000000014, 20.000000000000014, 197.0, -379.0, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 7.399999999999965, 128.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, -27.099999999999852, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -1.0000000000000062, 193.4, 9.499999999999968, 185.0, 20.000000000000014, 158.0, 20.000000000000014, 20.000000000000014, 172.1, 20.000000000000014, 20.000000000000014, 122.0, 20.000000000000014, -0.9999999999999992, 162.2, 7.399999999999965, 161.0, -0.9999999999999846, 185.0, 194.0, 20.000000000000014, 167.0, 20.000000000000014, 197.0, 20.000000000000014, 20.000000000000014, 161.0, 200.0, 188.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, 20.000000000000014, 13.699999999999966, 20.000000000000014, 185.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 170.0, 20.000000000000014, -322.3, -3.099999999999965, 137.0, 179.0, 196.4, 20.000000000000014, 20.000000000000014, 199.1, 20.000000000000014, -400.0, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999967, 20.000000000000014, 176.0, 20.000000000000014, 109.1, -339.1, 20.000000000000014, 13.699999999999964, 200.0, -9.399999999999855, 164.0, 9.499999999999973, 20.000000000000014, -343.3, 167.0, 185.0, 158.3, 199.1, 20.000000000000014, 167.0, 9.499999999999968, 20.000000000000014, 185.0, 179.0, -9.399999999999858, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 166.4, 121.4, 20.000000000000014, 20.000000000000014, 56.599999999999994, 161.0, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 24.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 7.0, 0.0, 0.0, 3.0, 6.0, 5.0, 10.0, 10.0, 0.0, 30.0, 32.0, 0.0, 2.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 17.0, 0.0, 0.0, 0.0, 1.0, 190.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 38.0, 0.0, 0.0, 0.0, 0.0, 5.0, 6.0, 8.0, 8.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 17.0, 2.0, 8.0, 6.0, 12.0, 17.0, 12.0, 7.0, 0.0, 11.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 13.0, 0.0, 4.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 3.0, 0.0, 0.0, 5.0, 3.0, 0.0, 10.0, 0.0, 174.0, 0.0, 23.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 0.0, 0.0, 7.0, 0.0, 8.0, 0.0, 13.0, 18.0, 171.0, 0.0, 3.0, 0.0, 10.0, 15.0, 5.0, 0.0, 173.0, 11.0, 8.0, 11.0, 0.0, 0.0, 5.0, 11.0, 0.0, 5.0, 7.0, 14.0, 0.0, 0.0, 0.0, 0.0, 1.0, 10.0, 0.0, 25.0, 33.0, 42.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8655427681515511, "mean_inference_ms": 2.5140873834278588, "mean_action_processing_ms": 0.3970605425483743, "mean_env_wait_ms": 0.31163251215194865, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004849076271057129, "StateBufferConnector_ms": 0.004483342170715332, "ViewRequirementAgentConnector_ms": 0.13164496421813965}, "num_episodes": 27, "episode_return_max": 398.0, "episode_return_min": -180.00000000000065, "episode_return_mean": 130.38899999999984, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 314.9876170362381, "num_env_steps_trained_throughput_per_sec": 314.9876170362381, "timesteps_total": 800000, "num_env_steps_sampled_lifetime": 800000, "num_agent_steps_sampled_lifetime": 3200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3200000, "timers": {"training_iteration_time_ms": 12715.924, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12715.847, "sample_time_ms": 2062.988, "learn_time_ms": 10630.897, "learn_throughput": 376.262, "synch_weights_time_ms": 18.231}, "counters": {"num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "done": true, "training_iteration": 200, "trial_id": "04dec_00002", "date": "2024-08-13_17-07-15", "timestamp": 1723583235, "time_this_iter_s": 12.761307954788208, "time_total_s": 2661.0966629981995, "pid": 72741, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0728550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2661.0966629981995, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 67.3722222222222, "ram_util_percent": 83.61111111111111}}
