{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.201895286473963, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9000976636926965, "policy_loss": -0.00024516177166588406, "vf_loss": 3.900269818558264, "vf_explained_var": -0.0006598116859557136, "kl": 0.0003650069513530275, "entropy": 1.609077691716492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1412261124483492, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.329422998428345, "policy_loss": -0.00017535139205397438, "vf_loss": 8.329155651980606, "vf_explained_var": 0.0016015981870984273, "kl": 0.002213495066145724, "entropy": 1.60721493347612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 244.99999999999926, "episode_reward_min": -208.90000000000052, "episode_reward_mean": 18.344444444444317, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -313.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.89999999999995, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": -29.188888888888926, "predator_policy": 38.361111111111114}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-71.99999999999974, -80.50000000000034, 211.79999999999998, -107.50000000000028, 40.0000000000003, 27.800000000000136, 77.79999999999951, 46.30000000000029, 244.99999999999926, 130.6999999999998, 17.40000000000005, -90.2000000000001, -10.499999999999824, -10.399999999999872, 103.19999999999953, -208.90000000000052, -37.69999999999996, 47.899999999999444], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-40.8999999999998, -137.1000000000003, -116.80000000000042, -81.70000000000002, 110.29999999999998, 75.50000000000006, -275.50000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, -11.499999999999911, 52.40000000000013, 25.40000000000008, 20.000000000000014, 26.300000000000004, 188.89999999999995, 55.100000000000186, 72.80000000000001, 17.899999999999977, 42.199999999999974, -92.80000000000041, -233.50000000000003, 5.299999999999969, 8.900000000000055, -93.39999999999995, -142.9000000000001, 42.50000000000005, 129.79999999999984, -76.6000000000002, -313.0, -160.90000000000052, -157.3000000000001, -30.400000000000006, 34.10000000000014, -59.20000000000001], "policy_predator_policy_reward": [0.0, 106.0, 86.0, 32.0, 0.0, 26.0, 0.0, 148.0, 0.0, 0.0, 26.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 40.0, 0.0, 67.0, 1.0, 138.0, 0.0, 51.0, 23.0, 0.0, 90.0, 32.0, 18.0, 81.0, 184.0, 111.0, 39.0, 67.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6575052211347145, "mean_inference_ms": 2.0073494349500747, "mean_action_processing_ms": 0.2559355028266006, "mean_env_wait_ms": 0.24245270280014786, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006060467825995551, "StateBufferConnector_ms": 0.0031769275665283203, "ViewRequirementAgentConnector_ms": 0.10132789611816406}, "num_episodes": 18, "episode_return_max": 244.99999999999926, "episode_return_min": -208.90000000000052, "episode_return_mean": 18.344444444444317, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.54711833404957, "num_env_steps_trained_throughput_per_sec": 358.54711833404957, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 11156.146, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11156.09, "sample_time_ms": 1542.593, "learn_time_ms": 9582.257, "learn_throughput": 417.438, "synch_weights_time_ms": 30.058}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "0b081_00000", "date": "2024-08-13_00-47-06", "timestamp": 1723524426, "time_this_iter_s": 11.21577000617981, "time_total_s": 11.21577000617981, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327c9e5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11.21577000617981, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 34.917647058823526, "ram_util_percent": 83.49411764705883}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24459835296624868, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5278471069991904, "policy_loss": -0.002832208426358799, "vf_loss": 3.530234002814722, "vf_explained_var": 0.004122982674805576, "kl": 0.00445315379097372, "entropy": 1.6053081823404505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.950865908763396, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.99998963068402, "policy_loss": -0.006776462729019975, "vf_loss": 7.004510537404863, "vf_explained_var": 0.011814680868986422, "kl": 0.022555288006557216, "entropy": 1.5755184311084647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 244.99999999999926, "episode_reward_min": -208.90000000000052, "episode_reward_mean": 31.813888888888716, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -313.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.89999999999995, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": -16.398611111111176, "predator_policy": 32.30555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-71.99999999999974, -80.50000000000034, 211.79999999999998, -107.50000000000028, 40.0000000000003, 27.800000000000136, 77.79999999999951, 46.30000000000029, 244.99999999999926, 130.6999999999998, 17.40000000000005, -90.2000000000001, -10.499999999999824, -10.399999999999872, 103.19999999999953, -208.90000000000052, -37.69999999999996, 47.899999999999444, 136.39999999999944, 117.09999999999911, -87.60000000000002, 177.899999999999, 95.59999999999998, -98.6000000000015, -2.6999999999999695, -20.099999999999703, 73.20000000000013, -55.69999999999988, 11.100000000000094, 93.09999999999985, 147.39999999999972, 107.79999999999946, 93.9, 16.299999999999947, -15.599999999999953, 25.60000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-40.8999999999998, -137.1000000000003, -116.80000000000042, -81.70000000000002, 110.29999999999998, 75.50000000000006, -275.50000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, -11.499999999999911, 52.40000000000013, 25.40000000000008, 20.000000000000014, 26.300000000000004, 188.89999999999995, 55.100000000000186, 72.80000000000001, 17.899999999999977, 42.199999999999974, -92.80000000000041, -233.50000000000003, 5.299999999999969, 8.900000000000055, -93.39999999999995, -142.9000000000001, 42.50000000000005, 129.79999999999984, -76.6000000000002, -313.0, -160.90000000000052, -157.3000000000001, -30.400000000000006, 34.10000000000014, -59.20000000000001, 118.0999999999999, 5.299999999999972, -11.500000000000036, 95.59999999999947, -87.09999999999995, -113.50000000000043, 80.59999999999934, 71.30000000000001, 46.70000000000013, 47.89999999999999, -147.10000000000068, -32.499999999999794, 20.000000000000014, -69.70000000000002, 77.59999999999961, -204.70000000000053, 67.09999999999997, -58.900000000000034, 20.000000000000014, -162.70000000000022, 33.50000000000024, -81.40000000000066, 43.40000000000008, 22.700000000000053, 88.40000000000009, 47.00000000000005, 68.00000000000003, 18.80000000000011, -50.50000000000003, -4.600000000000012, 18.500000000000007, -26.199999999999825, -9.400000000000023, -59.20000000000002, 20.000000000000014, -21.399999999999913], "policy_predator_policy_reward": [0.0, 106.0, 86.0, 32.0, 0.0, 26.0, 0.0, 148.0, 0.0, 0.0, 26.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 40.0, 0.0, 67.0, 1.0, 138.0, 0.0, 51.0, 23.0, 0.0, 90.0, 32.0, 18.0, 81.0, 184.0, 111.0, 39.0, 67.0, 6.0, 4.0, 9.0, 6.0, 27.0, 91.0, 22.0, 5.0, 21.0, 1.0, 0.0, 81.0, 0.0, 0.0, 47.0, 0.0, 107.0, 65.0, 0.0, 0.0, 87.0, 59.0, 0.0, 27.0, 0.0, 0.0, 12.0, 10.0, 11.0, 116.0, 33.0, 21.0, 3.0, 0.0, 53.0, 27.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6527879890127158, "mean_inference_ms": 1.9946417679004513, "mean_action_processing_ms": 0.2534494946176897, "mean_env_wait_ms": 0.23446945360416038, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006155172983805339, "StateBufferConnector_ms": 0.0031216277016533744, "ViewRequirementAgentConnector_ms": 0.10262330373128255}, "num_episodes": 18, "episode_return_max": 244.99999999999926, "episode_return_min": -208.90000000000052, "episode_return_mean": 31.813888888888716, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 375.16846528824016, "num_env_steps_trained_throughput_per_sec": 375.16846528824016, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 10909.075, "restore_workers_time_ms": 0.105, "training_step_time_ms": 10908.822, "sample_time_ms": 1521.87, "learn_time_ms": 9364.851, "learn_throughput": 427.129, "synch_weights_time_ms": 20.745}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "0b081_00000", "date": "2024-08-13_00-47-20", "timestamp": 1723524440, "time_this_iter_s": 10.711407899856567, "time_total_s": 21.927177906036377, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327c5bdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 21.927177906036377, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 39.25789473684211, "ram_util_percent": 83.28421052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35508787136465786, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.010089580217997, "policy_loss": -0.0014392294849530256, "vf_loss": 5.011279320086121, "vf_explained_var": 0.003463852153253303, "kl": 0.0049896769715683355, "entropy": 1.6001072857115004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.744059049696834, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.031232912325986, "policy_loss": -0.0033084984398175955, "vf_loss": 6.033091685885474, "vf_explained_var": -0.0072744645454265455, "kl": 0.009664822605888981, "entropy": 1.5697627005753694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 244.99999999999926, "episode_reward_min": -313.89999999999884, "episode_reward_mean": 10.768518518518416, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -313.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.89999999999995, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": -28.726851851851897, "predator_policy": 34.111111111111114}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-71.99999999999974, -80.50000000000034, 211.79999999999998, -107.50000000000028, 40.0000000000003, 27.800000000000136, 77.79999999999951, 46.30000000000029, 244.99999999999926, 130.6999999999998, 17.40000000000005, -90.2000000000001, -10.499999999999824, -10.399999999999872, 103.19999999999953, -208.90000000000052, -37.69999999999996, 47.899999999999444, 136.39999999999944, 117.09999999999911, -87.60000000000002, 177.899999999999, 95.59999999999998, -98.6000000000015, -2.6999999999999695, -20.099999999999703, 73.20000000000013, -55.69999999999988, 11.100000000000094, 93.09999999999985, 147.39999999999972, 107.79999999999946, 93.9, 16.299999999999947, -15.599999999999953, 25.60000000000025, -234.5000000000004, -313.89999999999884, 42.80000000000002, 3.0000000000002176, -10.699999999999948, 6.400000000000073, 53.50000000000052, 32.40000000000023, 75.69999999999908, 16.500000000000057, -82.70000000000013, 12.700000000000204, -92.40000000000043, -1.4999999999997735, 45.000000000000405, -0.6999999999997644, -43.19999999999987, -72.20000000000095], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-40.8999999999998, -137.1000000000003, -116.80000000000042, -81.70000000000002, 110.29999999999998, 75.50000000000006, -275.50000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, -11.499999999999911, 52.40000000000013, 25.40000000000008, 20.000000000000014, 26.300000000000004, 188.89999999999995, 55.100000000000186, 72.80000000000001, 17.899999999999977, 42.199999999999974, -92.80000000000041, -233.50000000000003, 5.299999999999969, 8.900000000000055, -93.39999999999995, -142.9000000000001, 42.50000000000005, 129.79999999999984, -76.6000000000002, -313.0, -160.90000000000052, -157.3000000000001, -30.400000000000006, 34.10000000000014, -59.20000000000001, 118.0999999999999, 5.299999999999972, -11.500000000000036, 95.59999999999947, -87.09999999999995, -113.50000000000043, 80.59999999999934, 71.30000000000001, 46.70000000000013, 47.89999999999999, -147.10000000000068, -32.499999999999794, 20.000000000000014, -69.70000000000002, 77.59999999999961, -204.70000000000053, 67.09999999999997, -58.900000000000034, 20.000000000000014, -162.70000000000022, 33.50000000000024, -81.40000000000066, 43.40000000000008, 22.700000000000053, 88.40000000000009, 47.00000000000005, 68.00000000000003, 18.80000000000011, -50.50000000000003, -4.600000000000012, 18.500000000000007, -26.199999999999825, -9.400000000000023, -59.20000000000002, 20.000000000000014, -21.399999999999913, -223.60000000000022, -145.90000000000023, -286.59999999999906, -238.30000000000035, 4.1000000000000005, -28.299999999999997, 43.69999999999987, -129.70000000000067, -114.40000000000015, 34.70000000000017, -70.30000000000007, 13.700000000000006, 20.000000000000014, 33.50000000000024, 13.699999999999946, -25.299999999999926, 20.000000000000014, 19.70000000000011, -1.0, -11.499999999999833, -168.70000000000002, -15.999999999999995, -48.39999999999988, -19.89999999999999, -286.59999999999957, 45.20000000000022, -77.20000000000016, 22.700000000000053, 17.899999999999988, 7.099999999999984, 7.399999999999965, -45.09999999999976, 3.1999999999999478, -117.40000000000003, -194.20000000000053, 20.000000000000014], "policy_predator_policy_reward": [0.0, 106.0, 86.0, 32.0, 0.0, 26.0, 0.0, 148.0, 0.0, 0.0, 26.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 40.0, 0.0, 67.0, 1.0, 138.0, 0.0, 51.0, 23.0, 0.0, 90.0, 32.0, 18.0, 81.0, 184.0, 111.0, 39.0, 67.0, 6.0, 4.0, 9.0, 6.0, 27.0, 91.0, 22.0, 5.0, 21.0, 1.0, 0.0, 81.0, 0.0, 0.0, 47.0, 0.0, 107.0, 65.0, 0.0, 0.0, 87.0, 59.0, 0.0, 27.0, 0.0, 0.0, 12.0, 10.0, 11.0, 116.0, 33.0, 21.0, 3.0, 0.0, 53.0, 27.0, 0.0, 123.0, 12.0, 110.0, 101.0, 3.0, 64.0, 83.0, 6.0, 5.0, 64.0, 0.0, 63.0, 0.0, 0.0, 31.0, 13.0, 8.0, 28.0, 13.0, 16.0, 61.0, 41.0, 25.0, 56.0, 66.0, 83.0, 34.0, 19.0, 20.0, 0.0, 31.0, 6.0, 71.0, 0.0, 0.0, 102.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.64111677793364, "mean_inference_ms": 1.9546800303120557, "mean_action_processing_ms": 0.24933968567236112, "mean_env_wait_ms": 0.2270961679670379, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00628652396025481, "StateBufferConnector_ms": 0.0032451417711046007, "ViewRequirementAgentConnector_ms": 0.10121111516599302}, "num_episodes": 18, "episode_return_max": 244.99999999999926, "episode_return_min": -313.89999999999884, "episode_return_mean": 10.768518518518416, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 385.3639918978362, "num_env_steps_trained_throughput_per_sec": 385.3639918978362, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 10732.652, "restore_workers_time_ms": 0.075, "training_step_time_ms": 10732.468, "sample_time_ms": 1434.596, "learn_time_ms": 9279.056, "learn_throughput": 431.078, "synch_weights_time_ms": 17.483}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "0b081_00000", "date": "2024-08-13_00-47-30", "timestamp": 1723524450, "time_this_iter_s": 10.383959770202637, "time_total_s": 32.311137676239014, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327c23c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 32.311137676239014, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 31.36666666666667, "ram_util_percent": 82.40666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36086391131516804, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.660489898888522, "policy_loss": -0.0012225191330625896, "vf_loss": 4.661554123232604, "vf_explained_var": 0.0007318577753803717, "kl": 0.006331767410623067, "entropy": 1.5860934804987024, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7249352296508809, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.716493308607233, "policy_loss": -0.006060360136032893, "vf_loss": 5.720035316326, "vf_explained_var": -0.0005675432227906726, "kl": 0.01678907866108168, "entropy": 1.5644954637875632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 287.5000000000001, "episode_reward_min": -313.89999999999884, "episode_reward_mean": 11.058333333333259, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -355.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.89999999999995, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": -28.48472222222225, "predator_policy": 34.013888888888886}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-71.99999999999974, -80.50000000000034, 211.79999999999998, -107.50000000000028, 40.0000000000003, 27.800000000000136, 77.79999999999951, 46.30000000000029, 244.99999999999926, 130.6999999999998, 17.40000000000005, -90.2000000000001, -10.499999999999824, -10.399999999999872, 103.19999999999953, -208.90000000000052, -37.69999999999996, 47.899999999999444, 136.39999999999944, 117.09999999999911, -87.60000000000002, 177.899999999999, 95.59999999999998, -98.6000000000015, -2.6999999999999695, -20.099999999999703, 73.20000000000013, -55.69999999999988, 11.100000000000094, 93.09999999999985, 147.39999999999972, 107.79999999999946, 93.9, 16.299999999999947, -15.599999999999953, 25.60000000000025, -234.5000000000004, -313.89999999999884, 42.80000000000002, 3.0000000000002176, -10.699999999999948, 6.400000000000073, 53.50000000000052, 32.40000000000023, 75.69999999999908, 16.500000000000057, -82.70000000000013, 12.700000000000204, -92.40000000000043, -1.4999999999997735, 45.000000000000405, -0.6999999999997644, -43.19999999999987, -72.20000000000095, 37.80000000000029, -31.199999999999818, -74.30000000000004, 113.19999999999925, 13.39999999999996, -37.49999999999992, 48.70000000000023, 20.099999999999937, -82.3999999999999, 287.5000000000001, 45.00000000000037, -84.90000000000059, -13.699999999999813, 61.600000000000506, 45.700000000000486, -137.30000000000086, -21.399999999999793, 24.39999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-40.8999999999998, -137.1000000000003, -116.80000000000042, -81.70000000000002, 110.29999999999998, 75.50000000000006, -275.50000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, -11.499999999999911, 52.40000000000013, 25.40000000000008, 20.000000000000014, 26.300000000000004, 188.89999999999995, 55.100000000000186, 72.80000000000001, 17.899999999999977, 42.199999999999974, -92.80000000000041, -233.50000000000003, 5.299999999999969, 8.900000000000055, -93.39999999999995, -142.9000000000001, 42.50000000000005, 129.79999999999984, -76.6000000000002, -313.0, -160.90000000000052, -157.3000000000001, -30.400000000000006, 34.10000000000014, -59.20000000000001, 118.0999999999999, 5.299999999999972, -11.500000000000036, 95.59999999999947, -87.09999999999995, -113.50000000000043, 80.59999999999934, 71.30000000000001, 46.70000000000013, 47.89999999999999, -147.10000000000068, -32.499999999999794, 20.000000000000014, -69.70000000000002, 77.59999999999961, -204.70000000000053, 67.09999999999997, -58.900000000000034, 20.000000000000014, -162.70000000000022, 33.50000000000024, -81.40000000000066, 43.40000000000008, 22.700000000000053, 88.40000000000009, 47.00000000000005, 68.00000000000003, 18.80000000000011, -50.50000000000003, -4.600000000000012, 18.500000000000007, -26.199999999999825, -9.400000000000023, -59.20000000000002, 20.000000000000014, -21.399999999999913, -223.60000000000022, -145.90000000000023, -286.59999999999906, -238.30000000000035, 4.1000000000000005, -28.299999999999997, 43.69999999999987, -129.70000000000067, -114.40000000000015, 34.70000000000017, -70.30000000000007, 13.700000000000006, 20.000000000000014, 33.50000000000024, 13.699999999999946, -25.299999999999926, 20.000000000000014, 19.70000000000011, -1.0, -11.499999999999833, -168.70000000000002, -15.999999999999995, -48.39999999999988, -19.89999999999999, -286.59999999999957, 45.20000000000022, -77.20000000000016, 22.700000000000053, 17.899999999999988, 7.099999999999984, 7.399999999999965, -45.09999999999976, 3.1999999999999478, -117.40000000000003, -194.20000000000053, 20.000000000000014, 10.999999999999975, 15.799999999999946, -120.70000000000012, 21.500000000000078, -14.499999999999929, -227.8000000000001, 23.599999999999966, 23.600000000000065, -32.49999999999975, 20.90000000000003, 47.0000000000002, -179.50000000000048, -4.600000000000023, -15.700000000000017, -7.299999999999976, 4.399999999999952, -106.00000000000009, -114.39999999999998, 136.1, 151.39999999999972, -3.70000000000003, 19.70000000000004, -205.90000000000035, -4.000000000000059, -74.50000000000004, 15.800000000000008, 20.000000000000014, 41.60000000000025, 27.20000000000013, -2.4999999999999587, -355.9000000000001, -9.39999999999989, -58.89999999999978, -14.499999999999876, 28.100000000000193, -54.699999999999974], "policy_predator_policy_reward": [0.0, 106.0, 86.0, 32.0, 0.0, 26.0, 0.0, 148.0, 0.0, 0.0, 26.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 40.0, 0.0, 67.0, 1.0, 138.0, 0.0, 51.0, 23.0, 0.0, 90.0, 32.0, 18.0, 81.0, 184.0, 111.0, 39.0, 67.0, 6.0, 4.0, 9.0, 6.0, 27.0, 91.0, 22.0, 5.0, 21.0, 1.0, 0.0, 81.0, 0.0, 0.0, 47.0, 0.0, 107.0, 65.0, 0.0, 0.0, 87.0, 59.0, 0.0, 27.0, 0.0, 0.0, 12.0, 10.0, 11.0, 116.0, 33.0, 21.0, 3.0, 0.0, 53.0, 27.0, 0.0, 123.0, 12.0, 110.0, 101.0, 3.0, 64.0, 83.0, 6.0, 5.0, 64.0, 0.0, 63.0, 0.0, 0.0, 31.0, 13.0, 8.0, 28.0, 13.0, 16.0, 61.0, 41.0, 25.0, 56.0, 66.0, 83.0, 34.0, 19.0, 20.0, 0.0, 31.0, 6.0, 71.0, 0.0, 0.0, 102.0, 0.0, 11.0, 0.0, 68.0, 22.0, 146.0, 50.0, 16.0, 0.0, 25.0, 63.0, 32.0, 43.0, 26.0, 13.0, 10.0, 52.0, 86.0, 0.0, 0.0, 29.0, 0.0, 15.0, 110.0, 0.0, 45.0, 0.0, 0.0, 21.0, 0.0, 143.0, 85.0, 52.0, 0.0, 51.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6298254562548625, "mean_inference_ms": 1.919051894368081, "mean_action_processing_ms": 0.2458355892976246, "mean_env_wait_ms": 0.22091309988455882, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006144576602511936, "StateBufferConnector_ms": 0.003146794107225206, "ViewRequirementAgentConnector_ms": 0.09758356544706556}, "num_episodes": 18, "episode_return_max": 287.5000000000001, "episode_return_min": -313.89999999999884, "episode_return_mean": 11.058333333333259, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.80064068650273, "num_env_steps_trained_throughput_per_sec": 380.80064068650273, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 10675.537, "restore_workers_time_ms": 0.059, "training_step_time_ms": 10675.39, "sample_time_ms": 1398.36, "learn_time_ms": 9259.146, "learn_throughput": 432.005, "synch_weights_time_ms": 16.57}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "0b081_00000", "date": "2024-08-13_00-47-41", "timestamp": 1723524461, "time_this_iter_s": 10.510334014892578, "time_total_s": 42.82147169113159, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e01160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 42.82147169113159, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 30.98, "ram_util_percent": 82.73333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29752089978052826, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3140104886716006, "policy_loss": -0.005674541786820603, "vf_loss": 2.319384410141637, "vf_explained_var": 0.005793319965796496, "kl": 0.012024648889430545, "entropy": 1.5973816069345625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.736165992308546, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.5290978793744685, "policy_loss": -0.0015870108490898495, "vf_loss": 4.529879626016768, "vf_explained_var": 0.02203510047266723, "kl": 0.005368418089958725, "entropy": 1.565658122269565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 294.7000000000004, "episode_reward_min": -313.89999999999884, "episode_reward_mean": 9.72323232323228, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -355.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.89999999999995, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": -28.456565656565704, "predator_policy": 33.31818181818182}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-71.99999999999974, -80.50000000000034, 211.79999999999998, -107.50000000000028, 40.0000000000003, 27.800000000000136, 77.79999999999951, 46.30000000000029, 244.99999999999926, 130.6999999999998, 17.40000000000005, -90.2000000000001, -10.499999999999824, -10.399999999999872, 103.19999999999953, -208.90000000000052, -37.69999999999996, 47.899999999999444, 136.39999999999944, 117.09999999999911, -87.60000000000002, 177.899999999999, 95.59999999999998, -98.6000000000015, -2.6999999999999695, -20.099999999999703, 73.20000000000013, -55.69999999999988, 11.100000000000094, 93.09999999999985, 147.39999999999972, 107.79999999999946, 93.9, 16.299999999999947, -15.599999999999953, 25.60000000000025, -234.5000000000004, -313.89999999999884, 42.80000000000002, 3.0000000000002176, -10.699999999999948, 6.400000000000073, 53.50000000000052, 32.40000000000023, 75.69999999999908, 16.500000000000057, -82.70000000000013, 12.700000000000204, -92.40000000000043, -1.4999999999997735, 45.000000000000405, -0.6999999999997644, -43.19999999999987, -72.20000000000095, 37.80000000000029, -31.199999999999818, -74.30000000000004, 113.19999999999925, 13.39999999999996, -37.49999999999992, 48.70000000000023, 20.099999999999937, -82.3999999999999, 287.5000000000001, 45.00000000000037, -84.90000000000059, -13.699999999999813, 61.600000000000506, 45.700000000000486, -137.30000000000086, -21.399999999999793, 24.39999999999995, -156.50000000000026, -147.00000000000108, 68.50000000000018, 40.9000000000003, 294.7000000000004, -14.099999999999778, -44.5999999999997, 60.200000000000344, 47.20000000000029, 11.500000000000245, -117.60000000000007, -7.099999999999799, -283.90000000000043, 104.09999999999971, -2.6999999999997044, -175.5000000000011, -33.999999999999616, 32.70000000000016, 40.0000000000003, 30.500000000000174, -19.19999999999977, 54.400000000000446, 32.30000000000019, 60.70000000000051, 40.0000000000003, 138.89999999999972, 111.99999999999858], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-40.8999999999998, -137.1000000000003, -116.80000000000042, -81.70000000000002, 110.29999999999998, 75.50000000000006, -275.50000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, -11.499999999999911, 52.40000000000013, 25.40000000000008, 20.000000000000014, 26.300000000000004, 188.89999999999995, 55.100000000000186, 72.80000000000001, 17.899999999999977, 42.199999999999974, -92.80000000000041, -233.50000000000003, 5.299999999999969, 8.900000000000055, -93.39999999999995, -142.9000000000001, 42.50000000000005, 129.79999999999984, -76.6000000000002, -313.0, -160.90000000000052, -157.3000000000001, -30.400000000000006, 34.10000000000014, -59.20000000000001, 118.0999999999999, 5.299999999999972, -11.500000000000036, 95.59999999999947, -87.09999999999995, -113.50000000000043, 80.59999999999934, 71.30000000000001, 46.70000000000013, 47.89999999999999, -147.10000000000068, -32.499999999999794, 20.000000000000014, -69.70000000000002, 77.59999999999961, -204.70000000000053, 67.09999999999997, -58.900000000000034, 20.000000000000014, -162.70000000000022, 33.50000000000024, -81.40000000000066, 43.40000000000008, 22.700000000000053, 88.40000000000009, 47.00000000000005, 68.00000000000003, 18.80000000000011, -50.50000000000003, -4.600000000000012, 18.500000000000007, -26.199999999999825, -9.400000000000023, -59.20000000000002, 20.000000000000014, -21.399999999999913, -223.60000000000022, -145.90000000000023, -286.59999999999906, -238.30000000000035, 4.1000000000000005, -28.299999999999997, 43.69999999999987, -129.70000000000067, -114.40000000000015, 34.70000000000017, -70.30000000000007, 13.700000000000006, 20.000000000000014, 33.50000000000024, 13.699999999999946, -25.299999999999926, 20.000000000000014, 19.70000000000011, -1.0, -11.499999999999833, -168.70000000000002, -15.999999999999995, -48.39999999999988, -19.89999999999999, -286.59999999999957, 45.20000000000022, -77.20000000000016, 22.700000000000053, 17.899999999999988, 7.099999999999984, 7.399999999999965, -45.09999999999976, 3.1999999999999478, -117.40000000000003, -194.20000000000053, 20.000000000000014, 10.999999999999975, 15.799999999999946, -120.70000000000012, 21.500000000000078, -14.499999999999929, -227.8000000000001, 23.599999999999966, 23.600000000000065, -32.49999999999975, 20.90000000000003, 47.0000000000002, -179.50000000000048, -4.600000000000023, -15.700000000000017, -7.299999999999976, 4.399999999999952, -106.00000000000009, -114.39999999999998, 136.1, 151.39999999999972, -3.70000000000003, 19.70000000000004, -205.90000000000035, -4.000000000000059, -74.50000000000004, 15.800000000000008, 20.000000000000014, 41.60000000000025, 27.20000000000013, -2.4999999999999587, -355.9000000000001, -9.39999999999989, -58.89999999999978, -14.499999999999876, 28.100000000000193, -54.699999999999974, -187.6000000000002, -175.9, -44.199999999999775, -311.7999999999997, 62.90000000000018, -27.39999999999978, 20.000000000000014, 20.900000000000013, 120.7999999999995, 173.90000000000003, -111.40000000000038, -12.699999999999935, 20.600000000000037, -164.20000000000053, 24.500000000000085, 10.699999999999976, 20.000000000000014, 27.200000000000124, 20.000000000000014, -65.50000000000006, -101.79999999999998, -80.80000000000011, -87.10000000000068, 20.000000000000014, -169.00000000000043, -301.9000000000001, 124.39999999999999, -91.3000000000008, -78.30000000000086, 23.60000000000001, -331.90000000000015, -52.60000000000012, -91.30000000000067, -15.699999999999797, -2.199999999999966, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000086, 57.800000000000225, -100.90000000000035, -37.29999999999993, 54.200000000000216, -17.799999999999926, 5.299999999999965, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 1.0999999999999732, 96.80000000000001, 20.900000000000013, 91.09999999999931], "policy_predator_policy_reward": [0.0, 106.0, 86.0, 32.0, 0.0, 26.0, 0.0, 148.0, 0.0, 0.0, 26.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 40.0, 0.0, 67.0, 1.0, 138.0, 0.0, 51.0, 23.0, 0.0, 90.0, 32.0, 18.0, 81.0, 184.0, 111.0, 39.0, 67.0, 6.0, 4.0, 9.0, 6.0, 27.0, 91.0, 22.0, 5.0, 21.0, 1.0, 0.0, 81.0, 0.0, 0.0, 47.0, 0.0, 107.0, 65.0, 0.0, 0.0, 87.0, 59.0, 0.0, 27.0, 0.0, 0.0, 12.0, 10.0, 11.0, 116.0, 33.0, 21.0, 3.0, 0.0, 53.0, 27.0, 0.0, 123.0, 12.0, 110.0, 101.0, 3.0, 64.0, 83.0, 6.0, 5.0, 64.0, 0.0, 63.0, 0.0, 0.0, 31.0, 13.0, 8.0, 28.0, 13.0, 16.0, 61.0, 41.0, 25.0, 56.0, 66.0, 83.0, 34.0, 19.0, 20.0, 0.0, 31.0, 6.0, 71.0, 0.0, 0.0, 102.0, 0.0, 11.0, 0.0, 68.0, 22.0, 146.0, 50.0, 16.0, 0.0, 25.0, 63.0, 32.0, 43.0, 26.0, 13.0, 10.0, 52.0, 86.0, 0.0, 0.0, 29.0, 0.0, 15.0, 110.0, 0.0, 45.0, 0.0, 0.0, 21.0, 0.0, 143.0, 85.0, 52.0, 0.0, 51.0, 0.0, 47.0, 160.0, 76.0, 133.0, 7.0, 26.0, 0.0, 0.0, 0.0, 0.0, 43.0, 67.0, 10.0, 89.0, 0.0, 25.0, 0.0, 0.0, 15.0, 42.0, 13.0, 52.0, 51.0, 9.0, 166.0, 21.0, 53.0, 18.0, 0.0, 52.0, 161.0, 48.0, 43.0, 30.0, 4.0, 10.0, 0.0, 0.0, 0.0, 43.0, 80.0, 39.0, 18.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6208847010101798, "mean_inference_ms": 1.893204009699856, "mean_action_processing_ms": 0.24321624945235515, "mean_env_wait_ms": 0.21577962345733268, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008048072005763199, "StateBufferConnector_ms": 0.0031909557303997, "ViewRequirementAgentConnector_ms": 0.09837174656415226}, "num_episodes": 27, "episode_return_max": 294.7000000000004, "episode_return_min": -313.89999999999884, "episode_return_mean": 9.72323232323228, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 390.9612106316777, "num_env_steps_trained_throughput_per_sec": 390.9612106316777, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 10586.67, "restore_workers_time_ms": 0.05, "training_step_time_ms": 10586.544, "sample_time_ms": 1394.137, "learn_time_ms": 9174.858, "learn_throughput": 435.974, "synch_weights_time_ms": 16.153}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "0b081_00000", "date": "2024-08-13_00-47-51", "timestamp": 1723524471, "time_this_iter_s": 10.235373973846436, "time_total_s": 53.05684566497803, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327f9bee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 53.05684566497803, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 29.86666666666667, "ram_util_percent": 83.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36520350597128665, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.850576268428217, "policy_loss": -0.0032978917982074475, "vf_loss": 3.8536587972489613, "vf_explained_var": 0.0085182681916252, "kl": 0.008614437735966835, "entropy": 1.5907517287466262, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4780087758939733, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.999098213892134, "policy_loss": -0.0037494045687179087, "vf_loss": 7.001244687277174, "vf_explained_var": 0.03494252098931207, "kl": 0.01068626384607171, "entropy": 1.541815237582676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 294.7000000000004, "episode_reward_min": -313.89999999999884, "episode_reward_mean": 16.957999999999885, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.90000000000003, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": -23.186000000000067, "predator_policy": 31.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.899999999999444, 136.39999999999944, 117.09999999999911, -87.60000000000002, 177.899999999999, 95.59999999999998, -98.6000000000015, -2.6999999999999695, -20.099999999999703, 73.20000000000013, -55.69999999999988, 11.100000000000094, 93.09999999999985, 147.39999999999972, 107.79999999999946, 93.9, 16.299999999999947, -15.599999999999953, 25.60000000000025, -234.5000000000004, -313.89999999999884, 42.80000000000002, 3.0000000000002176, -10.699999999999948, 6.400000000000073, 53.50000000000052, 32.40000000000023, 75.69999999999908, 16.500000000000057, -82.70000000000013, 12.700000000000204, -92.40000000000043, -1.4999999999997735, 45.000000000000405, -0.6999999999997644, -43.19999999999987, -72.20000000000095, 37.80000000000029, -31.199999999999818, -74.30000000000004, 113.19999999999925, 13.39999999999996, -37.49999999999992, 48.70000000000023, 20.099999999999937, -82.3999999999999, 287.5000000000001, 45.00000000000037, -84.90000000000059, -13.699999999999813, 61.600000000000506, 45.700000000000486, -137.30000000000086, -21.399999999999793, 24.39999999999995, -156.50000000000026, -147.00000000000108, 68.50000000000018, 40.9000000000003, 294.7000000000004, -14.099999999999778, -44.5999999999997, 60.200000000000344, 47.20000000000029, 11.500000000000245, -117.60000000000007, -7.099999999999799, -283.90000000000043, 104.09999999999971, -2.6999999999997044, -175.5000000000011, -33.999999999999616, 32.70000000000016, 40.0000000000003, 30.500000000000174, -19.19999999999977, 54.400000000000446, 32.30000000000019, 60.70000000000051, 40.0000000000003, 138.89999999999972, 111.99999999999858, 19.40000000000027, -113.70000000000041, -119.6000000000003, 163.39999999999958, 53.20000000000003, 115.59999999999863, 107.49999999999855, -70.6000000000007, 182.0999999999993, 265.6000000000001, -2.1000000000000396, 76.3999999999997, -77.900000000001, 180.39999999999873, 7.500000000000143, 131.69999999999928, -19.200000000000003, 115.79999999999953], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [34.10000000000014, -59.20000000000001, 118.0999999999999, 5.299999999999972, -11.500000000000036, 95.59999999999947, -87.09999999999995, -113.50000000000043, 80.59999999999934, 71.30000000000001, 46.70000000000013, 47.89999999999999, -147.10000000000068, -32.499999999999794, 20.000000000000014, -69.70000000000002, 77.59999999999961, -204.70000000000053, 67.09999999999997, -58.900000000000034, 20.000000000000014, -162.70000000000022, 33.50000000000024, -81.40000000000066, 43.40000000000008, 22.700000000000053, 88.40000000000009, 47.00000000000005, 68.00000000000003, 18.80000000000011, -50.50000000000003, -4.600000000000012, 18.500000000000007, -26.199999999999825, -9.400000000000023, -59.20000000000002, 20.000000000000014, -21.399999999999913, -223.60000000000022, -145.90000000000023, -286.59999999999906, -238.30000000000035, 4.1000000000000005, -28.299999999999997, 43.69999999999987, -129.70000000000067, -114.40000000000015, 34.70000000000017, -70.30000000000007, 13.700000000000006, 20.000000000000014, 33.50000000000024, 13.699999999999946, -25.299999999999926, 20.000000000000014, 19.70000000000011, -1.0, -11.499999999999833, -168.70000000000002, -15.999999999999995, -48.39999999999988, -19.89999999999999, -286.59999999999957, 45.20000000000022, -77.20000000000016, 22.700000000000053, 17.899999999999988, 7.099999999999984, 7.399999999999965, -45.09999999999976, 3.1999999999999478, -117.40000000000003, -194.20000000000053, 20.000000000000014, 10.999999999999975, 15.799999999999946, -120.70000000000012, 21.500000000000078, -14.499999999999929, -227.8000000000001, 23.599999999999966, 23.600000000000065, -32.49999999999975, 20.90000000000003, 47.0000000000002, -179.50000000000048, -4.600000000000023, -15.700000000000017, -7.299999999999976, 4.399999999999952, -106.00000000000009, -114.39999999999998, 136.1, 151.39999999999972, -3.70000000000003, 19.70000000000004, -205.90000000000035, -4.000000000000059, -74.50000000000004, 15.800000000000008, 20.000000000000014, 41.60000000000025, 27.20000000000013, -2.4999999999999587, -355.9000000000001, -9.39999999999989, -58.89999999999978, -14.499999999999876, 28.100000000000193, -54.699999999999974, -187.6000000000002, -175.9, -44.199999999999775, -311.7999999999997, 62.90000000000018, -27.39999999999978, 20.000000000000014, 20.900000000000013, 120.7999999999995, 173.90000000000003, -111.40000000000038, -12.699999999999935, 20.600000000000037, -164.20000000000053, 24.500000000000085, 10.699999999999976, 20.000000000000014, 27.200000000000124, 20.000000000000014, -65.50000000000006, -101.79999999999998, -80.80000000000011, -87.10000000000068, 20.000000000000014, -169.00000000000043, -301.9000000000001, 124.39999999999999, -91.3000000000008, -78.30000000000086, 23.60000000000001, -331.90000000000015, -52.60000000000012, -91.30000000000067, -15.699999999999797, -2.199999999999966, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000086, 57.800000000000225, -100.90000000000035, -37.29999999999993, 54.200000000000216, -17.799999999999926, 5.299999999999965, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 1.0999999999999732, 96.80000000000001, 20.900000000000013, 91.09999999999931, 74.9, -131.50000000000006, -74.50000000000036, -182.20000000000016, -202.6000000000003, -39.99999999999995, 157.70000000000002, -7.3000000000000504, -8.499999999999957, 1.6999999999999957, 20.000000000000014, 95.59999999999935, 20.000000000000014, 87.49999999999929, -133.30000000000052, -28.299999999999933, 150.2, 17.899999999999977, 129.80000000000004, 111.79999999999995, -4.899999999999974, -50.19999999999984, -89.20000000000083, 113.59999999999968, -80.8000000000008, -96.10000000000022, 47.0000000000002, 124.39999999999952, -61.30000000000029, -35.20000000000016, 63.79999999999997, 17.899999999999658, -187.0000000000003, 42.79999999999997, 87.79999999999986, 20.000000000000014], "policy_predator_policy_reward": [67.0, 6.0, 4.0, 9.0, 6.0, 27.0, 91.0, 22.0, 5.0, 21.0, 1.0, 0.0, 81.0, 0.0, 0.0, 47.0, 0.0, 107.0, 65.0, 0.0, 0.0, 87.0, 59.0, 0.0, 27.0, 0.0, 0.0, 12.0, 10.0, 11.0, 116.0, 33.0, 21.0, 3.0, 0.0, 53.0, 27.0, 0.0, 123.0, 12.0, 110.0, 101.0, 3.0, 64.0, 83.0, 6.0, 5.0, 64.0, 0.0, 63.0, 0.0, 0.0, 31.0, 13.0, 8.0, 28.0, 13.0, 16.0, 61.0, 41.0, 25.0, 56.0, 66.0, 83.0, 34.0, 19.0, 20.0, 0.0, 31.0, 6.0, 71.0, 0.0, 0.0, 102.0, 0.0, 11.0, 0.0, 68.0, 22.0, 146.0, 50.0, 16.0, 0.0, 25.0, 63.0, 32.0, 43.0, 26.0, 13.0, 10.0, 52.0, 86.0, 0.0, 0.0, 29.0, 0.0, 15.0, 110.0, 0.0, 45.0, 0.0, 0.0, 21.0, 0.0, 143.0, 85.0, 52.0, 0.0, 51.0, 0.0, 47.0, 160.0, 76.0, 133.0, 7.0, 26.0, 0.0, 0.0, 0.0, 0.0, 43.0, 67.0, 10.0, 89.0, 0.0, 25.0, 0.0, 0.0, 15.0, 42.0, 13.0, 52.0, 51.0, 9.0, 166.0, 21.0, 53.0, 18.0, 0.0, 52.0, 161.0, 48.0, 43.0, 30.0, 4.0, 10.0, 0.0, 0.0, 0.0, 43.0, 80.0, 39.0, 18.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 0.0, 0.0, 76.0, 0.0, 52.0, 91.0, 59.0, 64.0, 0.0, 13.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 13.0, 1.0, 24.0, 0.0, 14.0, 39.0, 0.0, 52.0, 1.0, 98.0, 9.0, 0.0, 12.0, 92.0, 38.0, 12.0, 99.0, 26.0, 6.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6083484215117636, "mean_inference_ms": 1.8522734232418827, "mean_action_processing_ms": 0.23905854013837705, "mean_env_wait_ms": 0.20764869251660545, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007663369178771973, "StateBufferConnector_ms": 0.003447890281677246, "ViewRequirementAgentConnector_ms": 0.09734666347503662}, "num_episodes": 18, "episode_return_max": 294.7000000000004, "episode_return_min": -313.89999999999884, "episode_return_mean": 16.957999999999885, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.5525438333263, "num_env_steps_trained_throughput_per_sec": 398.5525438333263, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 10494.946, "restore_workers_time_ms": 0.044, "training_step_time_ms": 10494.834, "sample_time_ms": 1358.533, "learn_time_ms": 9119.645, "learn_throughput": 438.614, "synch_weights_time_ms": 15.35}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "0b081_00000", "date": "2024-08-13_00-48-01", "timestamp": 1723524481, "time_this_iter_s": 10.04450798034668, "time_total_s": 63.10135364532471, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e41700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 63.10135364532471, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 29.335714285714285, "ram_util_percent": 83.47857142857141}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.19826391528128948, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1363488734083833, "policy_loss": -0.004261224476433305, "vf_loss": 2.1403933591312834, "vf_explained_var": -0.0008005409329025834, "kl": 0.008669762942586612, "entropy": 1.592430244425617, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3747344570303406, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.147182628465077, "policy_loss": -0.006489845395344433, "vf_loss": 5.151159147484592, "vf_explained_var": 0.01410792734887865, "kl": 0.016755495871132998, "entropy": 1.5004363536834717, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 294.7000000000004, "episode_reward_min": -313.89999999999884, "episode_reward_mean": 18.727999999999863, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.90000000000003, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": -21.151000000000067, "predator_policy": 30.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.60000000000025, -234.5000000000004, -313.89999999999884, 42.80000000000002, 3.0000000000002176, -10.699999999999948, 6.400000000000073, 53.50000000000052, 32.40000000000023, 75.69999999999908, 16.500000000000057, -82.70000000000013, 12.700000000000204, -92.40000000000043, -1.4999999999997735, 45.000000000000405, -0.6999999999997644, -43.19999999999987, -72.20000000000095, 37.80000000000029, -31.199999999999818, -74.30000000000004, 113.19999999999925, 13.39999999999996, -37.49999999999992, 48.70000000000023, 20.099999999999937, -82.3999999999999, 287.5000000000001, 45.00000000000037, -84.90000000000059, -13.699999999999813, 61.600000000000506, 45.700000000000486, -137.30000000000086, -21.399999999999793, 24.39999999999995, -156.50000000000026, -147.00000000000108, 68.50000000000018, 40.9000000000003, 294.7000000000004, -14.099999999999778, -44.5999999999997, 60.200000000000344, 47.20000000000029, 11.500000000000245, -117.60000000000007, -7.099999999999799, -283.90000000000043, 104.09999999999971, -2.6999999999997044, -175.5000000000011, -33.999999999999616, 32.70000000000016, 40.0000000000003, 30.500000000000174, -19.19999999999977, 54.400000000000446, 32.30000000000019, 60.70000000000051, 40.0000000000003, 138.89999999999972, 111.99999999999858, 19.40000000000027, -113.70000000000041, -119.6000000000003, 163.39999999999958, 53.20000000000003, 115.59999999999863, 107.49999999999855, -70.6000000000007, 182.0999999999993, 265.6000000000001, -2.1000000000000396, 76.3999999999997, -77.900000000001, 180.39999999999873, 7.500000000000143, 131.69999999999928, -19.200000000000003, 115.79999999999953, 153.09999999999945, 43.60000000000029, -66.90000000000089, 25.70000000000007, 132.6999999999987, 152.49999999999946, 139.79999999999865, 69.19999999999995, 192.0999999999993, -80.20000000000084, 23.500000000000032, -26.800000000000082, 48.600000000000094, 115.59999999999977, -115.49999999999997, 109.2999999999991, 25.700000000000166, 72.40000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -21.399999999999913, -223.60000000000022, -145.90000000000023, -286.59999999999906, -238.30000000000035, 4.1000000000000005, -28.299999999999997, 43.69999999999987, -129.70000000000067, -114.40000000000015, 34.70000000000017, -70.30000000000007, 13.700000000000006, 20.000000000000014, 33.50000000000024, 13.699999999999946, -25.299999999999926, 20.000000000000014, 19.70000000000011, -1.0, -11.499999999999833, -168.70000000000002, -15.999999999999995, -48.39999999999988, -19.89999999999999, -286.59999999999957, 45.20000000000022, -77.20000000000016, 22.700000000000053, 17.899999999999988, 7.099999999999984, 7.399999999999965, -45.09999999999976, 3.1999999999999478, -117.40000000000003, -194.20000000000053, 20.000000000000014, 10.999999999999975, 15.799999999999946, -120.70000000000012, 21.500000000000078, -14.499999999999929, -227.8000000000001, 23.599999999999966, 23.600000000000065, -32.49999999999975, 20.90000000000003, 47.0000000000002, -179.50000000000048, -4.600000000000023, -15.700000000000017, -7.299999999999976, 4.399999999999952, -106.00000000000009, -114.39999999999998, 136.1, 151.39999999999972, -3.70000000000003, 19.70000000000004, -205.90000000000035, -4.000000000000059, -74.50000000000004, 15.800000000000008, 20.000000000000014, 41.60000000000025, 27.20000000000013, -2.4999999999999587, -355.9000000000001, -9.39999999999989, -58.89999999999978, -14.499999999999876, 28.100000000000193, -54.699999999999974, -187.6000000000002, -175.9, -44.199999999999775, -311.7999999999997, 62.90000000000018, -27.39999999999978, 20.000000000000014, 20.900000000000013, 120.7999999999995, 173.90000000000003, -111.40000000000038, -12.699999999999935, 20.600000000000037, -164.20000000000053, 24.500000000000085, 10.699999999999976, 20.000000000000014, 27.200000000000124, 20.000000000000014, -65.50000000000006, -101.79999999999998, -80.80000000000011, -87.10000000000068, 20.000000000000014, -169.00000000000043, -301.9000000000001, 124.39999999999999, -91.3000000000008, -78.30000000000086, 23.60000000000001, -331.90000000000015, -52.60000000000012, -91.30000000000067, -15.699999999999797, -2.199999999999966, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000086, 57.800000000000225, -100.90000000000035, -37.29999999999993, 54.200000000000216, -17.799999999999926, 5.299999999999965, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 1.0999999999999732, 96.80000000000001, 20.900000000000013, 91.09999999999931, 74.9, -131.50000000000006, -74.50000000000036, -182.20000000000016, -202.6000000000003, -39.99999999999995, 157.70000000000002, -7.3000000000000504, -8.499999999999957, 1.6999999999999957, 20.000000000000014, 95.59999999999935, 20.000000000000014, 87.49999999999929, -133.30000000000052, -28.299999999999933, 150.2, 17.899999999999977, 129.80000000000004, 111.79999999999995, -4.899999999999974, -50.19999999999984, -89.20000000000083, 113.59999999999968, -80.8000000000008, -96.10000000000022, 47.0000000000002, 124.39999999999952, -61.30000000000029, -35.20000000000016, 63.79999999999997, 17.899999999999658, -187.0000000000003, 42.79999999999997, 87.79999999999986, 20.000000000000014, 85.39999999999989, -1.29999999999999, 23.600000000000062, 20.000000000000014, -79.00000000000031, -40.899999999999906, 20.000000000000014, -7.299999999999894, 20.90000000000003, 111.79999999999944, 111.79999999999976, 13.70000000000013, 95.89999999999938, 38.90000000000012, 40.70000000000008, -14.499999999999929, 122.59999999999977, 69.49999999999972, -208.90000000000038, 13.699999999999953, 20.000000000000014, -11.499999999999822, -18.399999999999842, -123.40000000000043, -85.00000000000003, 74.59999999999994, 62.30000000000006, 53.30000000000004, -47.60000000000004, -229.90000000000018, 82.09999999999971, 27.200000000000145, -97.60000000000015, 65.30000000000011, 79.39999999999986, -33.99999999999976], "policy_predator_policy_reward": [27.0, 0.0, 123.0, 12.0, 110.0, 101.0, 3.0, 64.0, 83.0, 6.0, 5.0, 64.0, 0.0, 63.0, 0.0, 0.0, 31.0, 13.0, 8.0, 28.0, 13.0, 16.0, 61.0, 41.0, 25.0, 56.0, 66.0, 83.0, 34.0, 19.0, 20.0, 0.0, 31.0, 6.0, 71.0, 0.0, 0.0, 102.0, 0.0, 11.0, 0.0, 68.0, 22.0, 146.0, 50.0, 16.0, 0.0, 25.0, 63.0, 32.0, 43.0, 26.0, 13.0, 10.0, 52.0, 86.0, 0.0, 0.0, 29.0, 0.0, 15.0, 110.0, 0.0, 45.0, 0.0, 0.0, 21.0, 0.0, 143.0, 85.0, 52.0, 0.0, 51.0, 0.0, 47.0, 160.0, 76.0, 133.0, 7.0, 26.0, 0.0, 0.0, 0.0, 0.0, 43.0, 67.0, 10.0, 89.0, 0.0, 25.0, 0.0, 0.0, 15.0, 42.0, 13.0, 52.0, 51.0, 9.0, 166.0, 21.0, 53.0, 18.0, 0.0, 52.0, 161.0, 48.0, 43.0, 30.0, 4.0, 10.0, 0.0, 0.0, 0.0, 43.0, 80.0, 39.0, 18.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 0.0, 0.0, 76.0, 0.0, 52.0, 91.0, 59.0, 64.0, 0.0, 13.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 13.0, 1.0, 24.0, 0.0, 14.0, 39.0, 0.0, 52.0, 1.0, 98.0, 9.0, 0.0, 12.0, 92.0, 38.0, 12.0, 99.0, 26.0, 6.0, 2.0, 38.0, 31.0, 0.0, 0.0, 0.0, 53.0, 13.0, 0.0, 0.0, 0.0, 0.0, 27.0, 3.0, 2.0, 14.0, 29.0, 0.0, 0.0, 27.0, 88.0, 15.0, 0.0, 44.0, 71.0, 59.0, 0.0, 0.0, 0.0, 43.0, 119.0, 0.0, 0.0, 58.0, 0.0, 27.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5957081297299632, "mean_inference_ms": 1.8137083100174822, "mean_action_processing_ms": 0.23552280576524873, "mean_env_wait_ms": 0.20170933354662893, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007259249687194824, "StateBufferConnector_ms": 0.0033881664276123047, "ViewRequirementAgentConnector_ms": 0.09304487705230713}, "num_episodes": 18, "episode_return_max": 294.7000000000004, "episode_return_min": -313.89999999999884, "episode_return_mean": 18.727999999999863, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 403.04593775669014, "num_env_steps_trained_throughput_per_sec": 403.04593775669014, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 10413.445, "restore_workers_time_ms": 0.04, "training_step_time_ms": 10413.339, "sample_time_ms": 1340.113, "learn_time_ms": 9056.762, "learn_throughput": 441.659, "synch_weights_time_ms": 15.117}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "0b081_00000", "date": "2024-08-13_00-48-11", "timestamp": 1723524491, "time_this_iter_s": 9.934981107711792, "time_total_s": 73.0363347530365, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e4f310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 73.0363347530365, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 30.071428571428573, "ram_util_percent": 83.48571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.20328769007569583, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.883081567918182, "policy_loss": -0.0011222791734826628, "vf_loss": 1.884118527583975, "vf_explained_var": 0.0010873081822874685, "kl": 0.003413010595591726, "entropy": 1.5786410345602289, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3847810072006372, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9250977507344, "policy_loss": 0.0002777015824836713, "vf_loss": 3.924634586692487, "vf_explained_var": 0.019513683785837163, "kl": 0.0012363779544218123, "entropy": 1.498912209808511, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 294.7000000000004, "episode_reward_min": -283.90000000000043, "episode_reward_mean": 28.81599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.90000000000003, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": -12.922000000000072, "predator_policy": 27.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-72.20000000000095, 37.80000000000029, -31.199999999999818, -74.30000000000004, 113.19999999999925, 13.39999999999996, -37.49999999999992, 48.70000000000023, 20.099999999999937, -82.3999999999999, 287.5000000000001, 45.00000000000037, -84.90000000000059, -13.699999999999813, 61.600000000000506, 45.700000000000486, -137.30000000000086, -21.399999999999793, 24.39999999999995, -156.50000000000026, -147.00000000000108, 68.50000000000018, 40.9000000000003, 294.7000000000004, -14.099999999999778, -44.5999999999997, 60.200000000000344, 47.20000000000029, 11.500000000000245, -117.60000000000007, -7.099999999999799, -283.90000000000043, 104.09999999999971, -2.6999999999997044, -175.5000000000011, -33.999999999999616, 32.70000000000016, 40.0000000000003, 30.500000000000174, -19.19999999999977, 54.400000000000446, 32.30000000000019, 60.70000000000051, 40.0000000000003, 138.89999999999972, 111.99999999999858, 19.40000000000027, -113.70000000000041, -119.6000000000003, 163.39999999999958, 53.20000000000003, 115.59999999999863, 107.49999999999855, -70.6000000000007, 182.0999999999993, 265.6000000000001, -2.1000000000000396, 76.3999999999997, -77.900000000001, 180.39999999999873, 7.500000000000143, 131.69999999999928, -19.200000000000003, 115.79999999999953, 153.09999999999945, 43.60000000000029, -66.90000000000089, 25.70000000000007, 132.6999999999987, 152.49999999999946, 139.79999999999865, 69.19999999999995, 192.0999999999993, -80.20000000000084, 23.500000000000032, -26.800000000000082, 48.600000000000094, 115.59999999999977, -115.49999999999997, 109.2999999999991, 25.700000000000166, 72.40000000000002, 57.70000000000041, 77.80000000000015, 165.59999999999937, 36.70000000000028, 60.500000000000426, -27.09999999999978, 10.900000000000034, -9.899999999999805, 11.600000000000056, -16.099999999999532, 40.0000000000003, -20.09999999999956, 42.60000000000028, 69.59999999999998, 39.000000000000284, 64.30000000000027, -32.19999999999964, -28.09999999999961], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-194.20000000000053, 20.000000000000014, 10.999999999999975, 15.799999999999946, -120.70000000000012, 21.500000000000078, -14.499999999999929, -227.8000000000001, 23.599999999999966, 23.600000000000065, -32.49999999999975, 20.90000000000003, 47.0000000000002, -179.50000000000048, -4.600000000000023, -15.700000000000017, -7.299999999999976, 4.399999999999952, -106.00000000000009, -114.39999999999998, 136.1, 151.39999999999972, -3.70000000000003, 19.70000000000004, -205.90000000000035, -4.000000000000059, -74.50000000000004, 15.800000000000008, 20.000000000000014, 41.60000000000025, 27.20000000000013, -2.4999999999999587, -355.9000000000001, -9.39999999999989, -58.89999999999978, -14.499999999999876, 28.100000000000193, -54.699999999999974, -187.6000000000002, -175.9, -44.199999999999775, -311.7999999999997, 62.90000000000018, -27.39999999999978, 20.000000000000014, 20.900000000000013, 120.7999999999995, 173.90000000000003, -111.40000000000038, -12.699999999999935, 20.600000000000037, -164.20000000000053, 24.500000000000085, 10.699999999999976, 20.000000000000014, 27.200000000000124, 20.000000000000014, -65.50000000000006, -101.79999999999998, -80.80000000000011, -87.10000000000068, 20.000000000000014, -169.00000000000043, -301.9000000000001, 124.39999999999999, -91.3000000000008, -78.30000000000086, 23.60000000000001, -331.90000000000015, -52.60000000000012, -91.30000000000067, -15.699999999999797, -2.199999999999966, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000086, 57.800000000000225, -100.90000000000035, -37.29999999999993, 54.200000000000216, -17.799999999999926, 5.299999999999965, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 1.0999999999999732, 96.80000000000001, 20.900000000000013, 91.09999999999931, 74.9, -131.50000000000006, -74.50000000000036, -182.20000000000016, -202.6000000000003, -39.99999999999995, 157.70000000000002, -7.3000000000000504, -8.499999999999957, 1.6999999999999957, 20.000000000000014, 95.59999999999935, 20.000000000000014, 87.49999999999929, -133.30000000000052, -28.299999999999933, 150.2, 17.899999999999977, 129.80000000000004, 111.79999999999995, -4.899999999999974, -50.19999999999984, -89.20000000000083, 113.59999999999968, -80.8000000000008, -96.10000000000022, 47.0000000000002, 124.39999999999952, -61.30000000000029, -35.20000000000016, 63.79999999999997, 17.899999999999658, -187.0000000000003, 42.79999999999997, 87.79999999999986, 20.000000000000014, 85.39999999999989, -1.29999999999999, 23.600000000000062, 20.000000000000014, -79.00000000000031, -40.899999999999906, 20.000000000000014, -7.299999999999894, 20.90000000000003, 111.79999999999944, 111.79999999999976, 13.70000000000013, 95.89999999999938, 38.90000000000012, 40.70000000000008, -14.499999999999929, 122.59999999999977, 69.49999999999972, -208.90000000000038, 13.699999999999953, 20.000000000000014, -11.499999999999822, -18.399999999999842, -123.40000000000043, -85.00000000000003, 74.59999999999994, 62.30000000000006, 53.30000000000004, -47.60000000000004, -229.90000000000018, 82.09999999999971, 27.200000000000145, -97.60000000000015, 65.30000000000011, 79.39999999999986, -33.99999999999976, -12.399999999999858, 46.10000000000021, 56.89999999999996, 20.90000000000003, 23.600000000000037, 121.9999999999999, 9.499999999999972, -38.80000000000004, 9.79999999999996, 31.700000000000216, -59.80000000000025, -28.29999999999997, 20.900000000000027, -61.0, -160.60000000000014, 58.700000000000216, 20.000000000000014, -42.399999999999885, 20.000000000000014, -87.10000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -102.1000000000007, 20.000000000000014, -27.399999999999885, 20.000000000000014, 35.600000000000115, 29.000000000000167, -3.9999999999999587, 41.599999999999994, 22.700000000000056, -38.79999999999983, -36.399999999999814, -49.000000000000014, -24.099999999999817], "policy_predator_policy_reward": [0.0, 102.0, 0.0, 11.0, 0.0, 68.0, 22.0, 146.0, 50.0, 16.0, 0.0, 25.0, 63.0, 32.0, 43.0, 26.0, 13.0, 10.0, 52.0, 86.0, 0.0, 0.0, 29.0, 0.0, 15.0, 110.0, 0.0, 45.0, 0.0, 0.0, 21.0, 0.0, 143.0, 85.0, 52.0, 0.0, 51.0, 0.0, 47.0, 160.0, 76.0, 133.0, 7.0, 26.0, 0.0, 0.0, 0.0, 0.0, 43.0, 67.0, 10.0, 89.0, 0.0, 25.0, 0.0, 0.0, 15.0, 42.0, 13.0, 52.0, 51.0, 9.0, 166.0, 21.0, 53.0, 18.0, 0.0, 52.0, 161.0, 48.0, 43.0, 30.0, 4.0, 10.0, 0.0, 0.0, 0.0, 43.0, 80.0, 39.0, 18.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 0.0, 0.0, 76.0, 0.0, 52.0, 91.0, 59.0, 64.0, 0.0, 13.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 13.0, 1.0, 24.0, 0.0, 14.0, 39.0, 0.0, 52.0, 1.0, 98.0, 9.0, 0.0, 12.0, 92.0, 38.0, 12.0, 99.0, 26.0, 6.0, 2.0, 38.0, 31.0, 0.0, 0.0, 0.0, 53.0, 13.0, 0.0, 0.0, 0.0, 0.0, 27.0, 3.0, 2.0, 14.0, 29.0, 0.0, 0.0, 27.0, 88.0, 15.0, 0.0, 44.0, 71.0, 59.0, 0.0, 0.0, 0.0, 43.0, 119.0, 0.0, 0.0, 58.0, 0.0, 27.0, 0.0, 21.0, 3.0, 0.0, 0.0, 20.0, 0.0, 5.0, 61.0, 0.0, 19.0, 38.0, 23.0, 51.0, 0.0, 92.0, 0.0, 0.0, 34.0, 51.0, 0.0, 0.0, 0.0, 0.0, 62.0, 50.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 43.0, 0.0, 45.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5874100430380227, "mean_inference_ms": 1.7905771308193346, "mean_action_processing_ms": 0.23349861830694152, "mean_env_wait_ms": 0.1979733365169667, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00676274299621582, "StateBufferConnector_ms": 0.00348508358001709, "ViewRequirementAgentConnector_ms": 0.09232461452484131}, "num_episodes": 18, "episode_return_max": 294.7000000000004, "episode_return_min": -283.90000000000043, "episode_return_mean": 28.81599999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 407.6376962218617, "num_env_steps_trained_throughput_per_sec": 407.6376962218617, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 10338.344, "restore_workers_time_ms": 0.037, "training_step_time_ms": 10338.247, "sample_time_ms": 1328.025, "learn_time_ms": 8993.931, "learn_throughput": 444.744, "synch_weights_time_ms": 15.0}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "0b081_00000", "date": "2024-08-13_00-48-21", "timestamp": 1723524501, "time_this_iter_s": 9.8317129611969, "time_total_s": 82.8680477142334, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e4fee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 82.8680477142334, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 29.157142857142855, "ram_util_percent": 83.34285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25828777751318677, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5246490088089435, "policy_loss": -0.003906324692316865, "vf_loss": 2.5284356425678918, "vf_explained_var": 0.006757289738882156, "kl": 0.009575961073232471, "entropy": 1.5771336430595035, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4497462687511293, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.28628675382604, "policy_loss": -0.0025978941225234873, "vf_loss": 5.288011668598841, "vf_explained_var": 0.028961573643659158, "kl": 0.011639406574820866, "entropy": 1.5172394056168814, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 294.7000000000004, "episode_reward_min": -283.90000000000043, "episode_reward_mean": 48.48499999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -331.90000000000015, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.90000000000003, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": 2.0374999999999153, "predator_policy": 22.205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.9000000000003, 294.7000000000004, -14.099999999999778, -44.5999999999997, 60.200000000000344, 47.20000000000029, 11.500000000000245, -117.60000000000007, -7.099999999999799, -283.90000000000043, 104.09999999999971, -2.6999999999997044, -175.5000000000011, -33.999999999999616, 32.70000000000016, 40.0000000000003, 30.500000000000174, -19.19999999999977, 54.400000000000446, 32.30000000000019, 60.70000000000051, 40.0000000000003, 138.89999999999972, 111.99999999999858, 19.40000000000027, -113.70000000000041, -119.6000000000003, 163.39999999999958, 53.20000000000003, 115.59999999999863, 107.49999999999855, -70.6000000000007, 182.0999999999993, 265.6000000000001, -2.1000000000000396, 76.3999999999997, -77.900000000001, 180.39999999999873, 7.500000000000143, 131.69999999999928, -19.200000000000003, 115.79999999999953, 153.09999999999945, 43.60000000000029, -66.90000000000089, 25.70000000000007, 132.6999999999987, 152.49999999999946, 139.79999999999865, 69.19999999999995, 192.0999999999993, -80.20000000000084, 23.500000000000032, -26.800000000000082, 48.600000000000094, 115.59999999999977, -115.49999999999997, 109.2999999999991, 25.700000000000166, 72.40000000000002, 57.70000000000041, 77.80000000000015, 165.59999999999937, 36.70000000000028, 60.500000000000426, -27.09999999999978, 10.900000000000034, -9.899999999999805, 11.600000000000056, -16.099999999999532, 40.0000000000003, -20.09999999999956, 42.60000000000028, 69.59999999999998, 39.000000000000284, 64.30000000000027, -32.19999999999964, -28.09999999999961, 24.20000000000006, 95.69999999999965, 38.30000000000029, 37.500000000000384, 119.5999999999998, 143.79999999999993, 85.7999999999991, 121.29999999999963, 143.49999999999915, 86.09999999999965, 56.50000000000048, 54.400000000000524, 90.09999999999867, 220.5999999999994, 88.59999999999872, -37.09999999999976, 40.0000000000003, -41.69999999999974, 92.79999999999978, 150.2999999999991, 200.1999999999989, 63.90000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.900000000000013, 120.7999999999995, 173.90000000000003, -111.40000000000038, -12.699999999999935, 20.600000000000037, -164.20000000000053, 24.500000000000085, 10.699999999999976, 20.000000000000014, 27.200000000000124, 20.000000000000014, -65.50000000000006, -101.79999999999998, -80.80000000000011, -87.10000000000068, 20.000000000000014, -169.00000000000043, -301.9000000000001, 124.39999999999999, -91.3000000000008, -78.30000000000086, 23.60000000000001, -331.90000000000015, -52.60000000000012, -91.30000000000067, -15.699999999999797, -2.199999999999966, 20.90000000000003, 20.000000000000014, 20.000000000000014, -70.30000000000086, 57.800000000000225, -100.90000000000035, -37.29999999999993, 54.200000000000216, -17.799999999999926, 5.299999999999965, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 1.0999999999999732, 96.80000000000001, 20.900000000000013, 91.09999999999931, 74.9, -131.50000000000006, -74.50000000000036, -182.20000000000016, -202.6000000000003, -39.99999999999995, 157.70000000000002, -7.3000000000000504, -8.499999999999957, 1.6999999999999957, 20.000000000000014, 95.59999999999935, 20.000000000000014, 87.49999999999929, -133.30000000000052, -28.299999999999933, 150.2, 17.899999999999977, 129.80000000000004, 111.79999999999995, -4.899999999999974, -50.19999999999984, -89.20000000000083, 113.59999999999968, -80.8000000000008, -96.10000000000022, 47.0000000000002, 124.39999999999952, -61.30000000000029, -35.20000000000016, 63.79999999999997, 17.899999999999658, -187.0000000000003, 42.79999999999997, 87.79999999999986, 20.000000000000014, 85.39999999999989, -1.29999999999999, 23.600000000000062, 20.000000000000014, -79.00000000000031, -40.899999999999906, 20.000000000000014, -7.299999999999894, 20.90000000000003, 111.79999999999944, 111.79999999999976, 13.70000000000013, 95.89999999999938, 38.90000000000012, 40.70000000000008, -14.499999999999929, 122.59999999999977, 69.49999999999972, -208.90000000000038, 13.699999999999953, 20.000000000000014, -11.499999999999822, -18.399999999999842, -123.40000000000043, -85.00000000000003, 74.59999999999994, 62.30000000000006, 53.30000000000004, -47.60000000000004, -229.90000000000018, 82.09999999999971, 27.200000000000145, -97.60000000000015, 65.30000000000011, 79.39999999999986, -33.99999999999976, -12.399999999999858, 46.10000000000021, 56.89999999999996, 20.90000000000003, 23.600000000000037, 121.9999999999999, 9.499999999999972, -38.80000000000004, 9.79999999999996, 31.700000000000216, -59.80000000000025, -28.29999999999997, 20.900000000000027, -61.0, -160.60000000000014, 58.700000000000216, 20.000000000000014, -42.399999999999885, 20.000000000000014, -87.10000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -102.1000000000007, 20.000000000000014, -27.399999999999885, 20.000000000000014, 35.600000000000115, 29.000000000000167, -3.9999999999999587, 41.599999999999994, 22.700000000000056, -38.79999999999983, -36.399999999999814, -49.000000000000014, -24.099999999999817, -30.69999999999977, -3.0999999999999863, 38.00000000000011, 22.699999999999974, 20.000000000000014, 14.29999999999995, 41.60000000000025, -81.10000000000068, -59.200000000000074, 81.79999999999947, -1.6000000000000014, 97.39999999999998, 20.900000000000052, 23.900000000000002, 76.09999999999968, -29.800000000000104, 95.59999999999988, 47.90000000000024, 98.29999999999981, -47.19999999999991, 33.500000000000234, 20.000000000000014, 34.40000000000026, 20.000000000000014, 20.300000000000118, 48.799999999999784, 144.19999999999987, 70.39999999999966, 68.59999999999988, 20.000000000000014, -30.399999999999963, -120.7000000000003, 20.000000000000014, 20.000000000000014, -141.70000000000041, 20.000000000000014, 8.600000000000017, 51.20000000000016, 3.1999999999999704, 136.09999999999974, 97.39999999999972, 102.79999999999957, 23.60000000000008, 38.300000000000125], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 43.0, 67.0, 10.0, 89.0, 0.0, 25.0, 0.0, 0.0, 15.0, 42.0, 13.0, 52.0, 51.0, 9.0, 166.0, 21.0, 53.0, 18.0, 0.0, 52.0, 161.0, 48.0, 43.0, 30.0, 4.0, 10.0, 0.0, 0.0, 0.0, 43.0, 80.0, 39.0, 18.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 0.0, 0.0, 76.0, 0.0, 52.0, 91.0, 59.0, 64.0, 0.0, 13.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 13.0, 1.0, 24.0, 0.0, 14.0, 39.0, 0.0, 52.0, 1.0, 98.0, 9.0, 0.0, 12.0, 92.0, 38.0, 12.0, 99.0, 26.0, 6.0, 2.0, 38.0, 31.0, 0.0, 0.0, 0.0, 53.0, 13.0, 0.0, 0.0, 0.0, 0.0, 27.0, 3.0, 2.0, 14.0, 29.0, 0.0, 0.0, 27.0, 88.0, 15.0, 0.0, 44.0, 71.0, 59.0, 0.0, 0.0, 0.0, 43.0, 119.0, 0.0, 0.0, 58.0, 0.0, 27.0, 0.0, 21.0, 3.0, 0.0, 0.0, 20.0, 0.0, 5.0, 61.0, 0.0, 19.0, 38.0, 23.0, 51.0, 0.0, 92.0, 0.0, 0.0, 34.0, 51.0, 0.0, 0.0, 0.0, 0.0, 62.0, 50.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 43.0, 0.0, 45.0, 0.0, 28.0, 30.0, 2.0, 33.0, 4.0, 0.0, 47.0, 30.0, 45.0, 52.0, 0.0, 48.0, 41.0, 0.0, 64.0, 11.0, 0.0, 0.0, 35.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 0.0, 85.0, 29.0, 0.0, 0.0, 6.0, 74.0, 3.0, 30.0, 11.0, 0.0, 0.0, 0.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5816339568294293, "mean_inference_ms": 1.7749241210651387, "mean_action_processing_ms": 0.23180973330993662, "mean_env_wait_ms": 0.19551688854093183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005824089050292969, "StateBufferConnector_ms": 0.0034586191177368164, "ViewRequirementAgentConnector_ms": 0.0911785364151001}, "num_episodes": 22, "episode_return_max": 294.7000000000004, "episode_return_min": -283.90000000000043, "episode_return_mean": 48.48499999999986, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.84717367746197, "num_env_steps_trained_throughput_per_sec": 398.84717367746197, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 10303.963, "restore_workers_time_ms": 0.034, "training_step_time_ms": 10303.872, "sample_time_ms": 1322.385, "learn_time_ms": 8965.402, "learn_throughput": 446.16, "synch_weights_time_ms": 14.86}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "0b081_00000", "date": "2024-08-13_00-48-31", "timestamp": 1723524511, "time_this_iter_s": 10.033947944641113, "time_total_s": 92.90199565887451, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e41430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 92.90199565887451, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 29.6, "ram_util_percent": 83.24285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2816215805472836, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2681336772504939, "policy_loss": -0.00285340630592256, "vf_loss": 1.270887264388579, "vf_explained_var": 0.00988658865292867, "kl": 0.007985547655732327, "entropy": 1.5470832564212658, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.282308269658732, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9935625316604737, "policy_loss": -0.0040988459717482325, "vf_loss": 2.996658758322398, "vf_explained_var": -0.0003156979563374999, "kl": 0.013368183029475718, "entropy": 1.4705048896648265, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 265.6000000000001, "episode_reward_min": -154.10000000000136, "episode_reward_mean": 56.46199999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.90000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 157.70000000000002, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": 8.915999999999922, "predator_policy": 19.315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [111.99999999999858, 19.40000000000027, -113.70000000000041, -119.6000000000003, 163.39999999999958, 53.20000000000003, 115.59999999999863, 107.49999999999855, -70.6000000000007, 182.0999999999993, 265.6000000000001, -2.1000000000000396, 76.3999999999997, -77.900000000001, 180.39999999999873, 7.500000000000143, 131.69999999999928, -19.200000000000003, 115.79999999999953, 153.09999999999945, 43.60000000000029, -66.90000000000089, 25.70000000000007, 132.6999999999987, 152.49999999999946, 139.79999999999865, 69.19999999999995, 192.0999999999993, -80.20000000000084, 23.500000000000032, -26.800000000000082, 48.600000000000094, 115.59999999999977, -115.49999999999997, 109.2999999999991, 25.700000000000166, 72.40000000000002, 57.70000000000041, 77.80000000000015, 165.59999999999937, 36.70000000000028, 60.500000000000426, -27.09999999999978, 10.900000000000034, -9.899999999999805, 11.600000000000056, -16.099999999999532, 40.0000000000003, -20.09999999999956, 42.60000000000028, 69.59999999999998, 39.000000000000284, 64.30000000000027, -32.19999999999964, -28.09999999999961, 24.20000000000006, 95.69999999999965, 38.30000000000029, 37.500000000000384, 119.5999999999998, 143.79999999999993, 85.7999999999991, 121.29999999999963, 143.49999999999915, 86.09999999999965, 56.50000000000048, 54.400000000000524, 90.09999999999867, 220.5999999999994, 88.59999999999872, -37.09999999999976, 40.0000000000003, -41.69999999999974, 92.79999999999978, 150.2999999999991, 200.1999999999989, 63.90000000000023, 55.90000000000048, 115.3999999999987, -28.000000000000057, 37.80000000000027, 41.50000000000028, -43.79999999999975, 90.39999999999907, 35.600000000000236, 42.20000000000018, 131.49999999999878, 121.39999999999975, 150.29999999999916, 19.09999999999997, 134.49999999999903, -73.10000000000011, 42.500000000000334, 50.700000000000394, 128.19999999999982, 55.30000000000039, 91.29999999999866, -29.299999999999905, -154.10000000000136, 71.79999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.900000000000013, 91.09999999999931, 74.9, -131.50000000000006, -74.50000000000036, -182.20000000000016, -202.6000000000003, -39.99999999999995, 157.70000000000002, -7.3000000000000504, -8.499999999999957, 1.6999999999999957, 20.000000000000014, 95.59999999999935, 20.000000000000014, 87.49999999999929, -133.30000000000052, -28.299999999999933, 150.2, 17.899999999999977, 129.80000000000004, 111.79999999999995, -4.899999999999974, -50.19999999999984, -89.20000000000083, 113.59999999999968, -80.8000000000008, -96.10000000000022, 47.0000000000002, 124.39999999999952, -61.30000000000029, -35.20000000000016, 63.79999999999997, 17.899999999999658, -187.0000000000003, 42.79999999999997, 87.79999999999986, 20.000000000000014, 85.39999999999989, -1.29999999999999, 23.600000000000062, 20.000000000000014, -79.00000000000031, -40.899999999999906, 20.000000000000014, -7.299999999999894, 20.90000000000003, 111.79999999999944, 111.79999999999976, 13.70000000000013, 95.89999999999938, 38.90000000000012, 40.70000000000008, -14.499999999999929, 122.59999999999977, 69.49999999999972, -208.90000000000038, 13.699999999999953, 20.000000000000014, -11.499999999999822, -18.399999999999842, -123.40000000000043, -85.00000000000003, 74.59999999999994, 62.30000000000006, 53.30000000000004, -47.60000000000004, -229.90000000000018, 82.09999999999971, 27.200000000000145, -97.60000000000015, 65.30000000000011, 79.39999999999986, -33.99999999999976, -12.399999999999858, 46.10000000000021, 56.89999999999996, 20.90000000000003, 23.600000000000037, 121.9999999999999, 9.499999999999972, -38.80000000000004, 9.79999999999996, 31.700000000000216, -59.80000000000025, -28.29999999999997, 20.900000000000027, -61.0, -160.60000000000014, 58.700000000000216, 20.000000000000014, -42.399999999999885, 20.000000000000014, -87.10000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -102.1000000000007, 20.000000000000014, -27.399999999999885, 20.000000000000014, 35.600000000000115, 29.000000000000167, -3.9999999999999587, 41.599999999999994, 22.700000000000056, -38.79999999999983, -36.399999999999814, -49.000000000000014, -24.099999999999817, -30.69999999999977, -3.0999999999999863, 38.00000000000011, 22.699999999999974, 20.000000000000014, 14.29999999999995, 41.60000000000025, -81.10000000000068, -59.200000000000074, 81.79999999999947, -1.6000000000000014, 97.39999999999998, 20.900000000000052, 23.900000000000002, 76.09999999999968, -29.800000000000104, 95.59999999999988, 47.90000000000024, 98.29999999999981, -47.19999999999991, 33.500000000000234, 20.000000000000014, 34.40000000000026, 20.000000000000014, 20.300000000000118, 48.799999999999784, 144.19999999999987, 70.39999999999966, 68.59999999999988, 20.000000000000014, -30.399999999999963, -120.7000000000003, 20.000000000000014, 20.000000000000014, -141.70000000000041, 20.000000000000014, 8.600000000000017, 51.20000000000016, 3.1999999999999704, 136.09999999999974, 97.39999999999972, 102.79999999999957, 23.60000000000008, 38.300000000000125, 29.900000000000187, 20.000000000000014, 17.899999999999988, 96.4999999999994, -47.79999999999983, -47.1999999999999, 20.000000000000014, 15.799999999999963, -17.19999999999986, 13.699999999999946, -87.10000000000039, -69.70000000000067, 70.39999999999965, 20.000000000000014, 11.599999999999964, 20.000000000000014, -36.70000000000017, 20.90000000000003, 84.79999999999929, 40.70000000000012, 5.299999999999965, 109.1, 100.39999999999992, 20.90000000000003, -19.89999999999985, 20.000000000000014, 22.700000000000053, 111.79999999999964, -40.300000000000004, -179.8000000000005, 21.500000000000036, 20.000000000000014, 20.000000000000014, 7.6999999999999895, 89.29999999999998, 38.900000000000105, 35.300000000000196, 20.000000000000014, 42.50000000000025, 48.800000000000196, 20.000000000000014, -112.30000000000025, -109.60000000000069, -122.50000000000063, 48.800000000000225, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 76.0, 0.0, 52.0, 91.0, 59.0, 64.0, 0.0, 13.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 13.0, 1.0, 24.0, 0.0, 14.0, 39.0, 0.0, 52.0, 1.0, 98.0, 9.0, 0.0, 12.0, 92.0, 38.0, 12.0, 99.0, 26.0, 6.0, 2.0, 38.0, 31.0, 0.0, 0.0, 0.0, 53.0, 13.0, 0.0, 0.0, 0.0, 0.0, 27.0, 3.0, 2.0, 14.0, 29.0, 0.0, 0.0, 27.0, 88.0, 15.0, 0.0, 44.0, 71.0, 59.0, 0.0, 0.0, 0.0, 43.0, 119.0, 0.0, 0.0, 58.0, 0.0, 27.0, 0.0, 21.0, 3.0, 0.0, 0.0, 20.0, 0.0, 5.0, 61.0, 0.0, 19.0, 38.0, 23.0, 51.0, 0.0, 92.0, 0.0, 0.0, 34.0, 51.0, 0.0, 0.0, 0.0, 0.0, 62.0, 50.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 43.0, 0.0, 45.0, 0.0, 28.0, 30.0, 2.0, 33.0, 4.0, 0.0, 47.0, 30.0, 45.0, 52.0, 0.0, 48.0, 41.0, 0.0, 64.0, 11.0, 0.0, 0.0, 35.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 0.0, 85.0, 29.0, 0.0, 0.0, 6.0, 74.0, 3.0, 30.0, 11.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 2.0, 0.0, 45.0, 55.0, 58.0, 0.0, 0.0, 0.0, 4.0, 1.0, 57.0, 0.0, 6.0, 7.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 0.0, 48.0, 99.0, 1.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 63.0, 0.0, 78.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.57433983445913, "mean_inference_ms": 1.7553846022713493, "mean_action_processing_ms": 0.2303765766563696, "mean_env_wait_ms": 0.19272761299926824, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038781166076660156, "StateBufferConnector_ms": 0.00344240665435791, "ViewRequirementAgentConnector_ms": 0.09306347370147705}, "num_episodes": 23, "episode_return_max": 265.6000000000001, "episode_return_min": -154.10000000000136, "episode_return_mean": 56.46199999999976, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 381.76886344433046, "num_env_steps_trained_throughput_per_sec": 381.76886344433046, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 10321.322, "restore_workers_time_ms": 0.032, "training_step_time_ms": 10321.234, "sample_time_ms": 1317.648, "learn_time_ms": 8987.116, "learn_throughput": 445.082, "synch_weights_time_ms": 14.909}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "0b081_00000", "date": "2024-08-13_00-48-42", "timestamp": 1723524522, "time_this_iter_s": 10.50678014755249, "time_total_s": 103.408775806427, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327c9e700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 103.408775806427, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 30.706666666666663, "ram_util_percent": 83.25333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2788280154780421, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7883787555038615, "policy_loss": -0.003590186929980677, "vf_loss": 3.7918499735928086, "vf_explained_var": 0.0024491022503565227, "kl": 0.009517817251287605, "entropy": 1.5507194536072868, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4463632550898684, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.342990070802194, "policy_loss": -0.002823516497728489, "vf_loss": 5.344904367759745, "vf_explained_var": 0.0027700211635973086, "kl": 0.012122949704494878, "entropy": 1.4825654821421104, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 220.5999999999994, "episode_reward_min": -189.00000000000045, "episode_reward_mean": 43.460999999999856, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -274.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 144.19999999999987, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": 1.0754999999999426, "predator_policy": 20.655}, "custom_metrics": {}, "hist_stats": {"episode_reward": [115.79999999999953, 153.09999999999945, 43.60000000000029, -66.90000000000089, 25.70000000000007, 132.6999999999987, 152.49999999999946, 139.79999999999865, 69.19999999999995, 192.0999999999993, -80.20000000000084, 23.500000000000032, -26.800000000000082, 48.600000000000094, 115.59999999999977, -115.49999999999997, 109.2999999999991, 25.700000000000166, 72.40000000000002, 57.70000000000041, 77.80000000000015, 165.59999999999937, 36.70000000000028, 60.500000000000426, -27.09999999999978, 10.900000000000034, -9.899999999999805, 11.600000000000056, -16.099999999999532, 40.0000000000003, -20.09999999999956, 42.60000000000028, 69.59999999999998, 39.000000000000284, 64.30000000000027, -32.19999999999964, -28.09999999999961, 24.20000000000006, 95.69999999999965, 38.30000000000029, 37.500000000000384, 119.5999999999998, 143.79999999999993, 85.7999999999991, 121.29999999999963, 143.49999999999915, 86.09999999999965, 56.50000000000048, 54.400000000000524, 90.09999999999867, 220.5999999999994, 88.59999999999872, -37.09999999999976, 40.0000000000003, -41.69999999999974, 92.79999999999978, 150.2999999999991, 200.1999999999989, 63.90000000000023, 55.90000000000048, 115.3999999999987, -28.000000000000057, 37.80000000000027, 41.50000000000028, -43.79999999999975, 90.39999999999907, 35.600000000000236, 42.20000000000018, 131.49999999999878, 121.39999999999975, 150.29999999999916, 19.09999999999997, 134.49999999999903, -73.10000000000011, 42.500000000000334, 50.700000000000394, 128.19999999999982, 55.30000000000039, 91.29999999999866, -29.299999999999905, -154.10000000000136, 71.79999999999993, -124.6000000000007, -125.1000000000002, 43.60000000000029, -184.5000000000002, 40.0000000000003, -122.80000000000095, -19.499999999999815, 10.200000000000076, 40.0000000000003, 69.30000000000004, 98.40000000000009, 108.19999999999926, 25.100000000000215, 60.700000000000486, -126.70000000000027, 46.20000000000048, 62.10000000000036, -189.00000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [87.79999999999986, 20.000000000000014, 85.39999999999989, -1.29999999999999, 23.600000000000062, 20.000000000000014, -79.00000000000031, -40.899999999999906, 20.000000000000014, -7.299999999999894, 20.90000000000003, 111.79999999999944, 111.79999999999976, 13.70000000000013, 95.89999999999938, 38.90000000000012, 40.70000000000008, -14.499999999999929, 122.59999999999977, 69.49999999999972, -208.90000000000038, 13.699999999999953, 20.000000000000014, -11.499999999999822, -18.399999999999842, -123.40000000000043, -85.00000000000003, 74.59999999999994, 62.30000000000006, 53.30000000000004, -47.60000000000004, -229.90000000000018, 82.09999999999971, 27.200000000000145, -97.60000000000015, 65.30000000000011, 79.39999999999986, -33.99999999999976, -12.399999999999858, 46.10000000000021, 56.89999999999996, 20.90000000000003, 23.600000000000037, 121.9999999999999, 9.499999999999972, -38.80000000000004, 9.79999999999996, 31.700000000000216, -59.80000000000025, -28.29999999999997, 20.900000000000027, -61.0, -160.60000000000014, 58.700000000000216, 20.000000000000014, -42.399999999999885, 20.000000000000014, -87.10000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -102.1000000000007, 20.000000000000014, -27.399999999999885, 20.000000000000014, 35.600000000000115, 29.000000000000167, -3.9999999999999587, 41.599999999999994, 22.700000000000056, -38.79999999999983, -36.399999999999814, -49.000000000000014, -24.099999999999817, -30.69999999999977, -3.0999999999999863, 38.00000000000011, 22.699999999999974, 20.000000000000014, 14.29999999999995, 41.60000000000025, -81.10000000000068, -59.200000000000074, 81.79999999999947, -1.6000000000000014, 97.39999999999998, 20.900000000000052, 23.900000000000002, 76.09999999999968, -29.800000000000104, 95.59999999999988, 47.90000000000024, 98.29999999999981, -47.19999999999991, 33.500000000000234, 20.000000000000014, 34.40000000000026, 20.000000000000014, 20.300000000000118, 48.799999999999784, 144.19999999999987, 70.39999999999966, 68.59999999999988, 20.000000000000014, -30.399999999999963, -120.7000000000003, 20.000000000000014, 20.000000000000014, -141.70000000000041, 20.000000000000014, 8.600000000000017, 51.20000000000016, 3.1999999999999704, 136.09999999999974, 97.39999999999972, 102.79999999999957, 23.60000000000008, 38.300000000000125, 29.900000000000187, 20.000000000000014, 17.899999999999988, 96.4999999999994, -47.79999999999983, -47.1999999999999, 20.000000000000014, 15.799999999999963, -17.19999999999986, 13.699999999999946, -87.10000000000039, -69.70000000000067, 70.39999999999965, 20.000000000000014, 11.599999999999964, 20.000000000000014, -36.70000000000017, 20.90000000000003, 84.79999999999929, 40.70000000000012, 5.299999999999965, 109.1, 100.39999999999992, 20.90000000000003, -19.89999999999985, 20.000000000000014, 22.700000000000053, 111.79999999999964, -40.300000000000004, -179.8000000000005, 21.500000000000036, 20.000000000000014, 20.000000000000014, 7.6999999999999895, 89.29999999999998, 38.900000000000105, 35.300000000000196, 20.000000000000014, 42.50000000000025, 48.800000000000196, 20.000000000000014, -112.30000000000025, -109.60000000000069, -122.50000000000063, 48.800000000000225, 20.000000000000014, -147.4000000000001, -98.20000000000061, -244.6000000000002, -47.49999999999994, 23.600000000000044, 20.000000000000014, -274.00000000000017, -74.49999999999989, 20.000000000000014, 20.000000000000014, -129.10000000000016, -141.7000000000007, -15.100000000000085, -93.39999999999984, -31.8999999999998, -7.899999999999945, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.300000000000196, -25.300000000000388, 82.69999999999928, 59.59999999999984, 2.5999999999999805, 2.0000000000000178, 7.099999999999966, 20.000000000000014, 40.70000000000024, -122.8000000000003, -220.9, 20.000000000000014, 12.200000000000145, 20.000000000000014, 13.099999999999973, -246.70000000000013, -133.30000000000024], "policy_predator_policy_reward": [6.0, 2.0, 38.0, 31.0, 0.0, 0.0, 0.0, 53.0, 13.0, 0.0, 0.0, 0.0, 0.0, 27.0, 3.0, 2.0, 14.0, 29.0, 0.0, 0.0, 27.0, 88.0, 15.0, 0.0, 44.0, 71.0, 59.0, 0.0, 0.0, 0.0, 43.0, 119.0, 0.0, 0.0, 58.0, 0.0, 27.0, 0.0, 21.0, 3.0, 0.0, 0.0, 20.0, 0.0, 5.0, 61.0, 0.0, 19.0, 38.0, 23.0, 51.0, 0.0, 92.0, 0.0, 0.0, 34.0, 51.0, 0.0, 0.0, 0.0, 0.0, 62.0, 50.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 43.0, 0.0, 45.0, 0.0, 28.0, 30.0, 2.0, 33.0, 4.0, 0.0, 47.0, 30.0, 45.0, 52.0, 0.0, 48.0, 41.0, 0.0, 64.0, 11.0, 0.0, 0.0, 35.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 0.0, 85.0, 29.0, 0.0, 0.0, 6.0, 74.0, 3.0, 30.0, 11.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 2.0, 0.0, 45.0, 55.0, 58.0, 0.0, 0.0, 0.0, 4.0, 1.0, 57.0, 0.0, 6.0, 7.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 0.0, 48.0, 99.0, 1.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 63.0, 0.0, 78.0, 0.0, 3.0, 121.0, 0.0, 152.0, 15.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 77.0, 71.0, 52.0, 37.0, 15.0, 35.0, 0.0, 0.0, 11.0, 0.0, 1.0, 40.0, 18.0, 28.0, 9.0, 7.0, 0.0, 0.0, 105.0, 112.0, 14.0, 0.0, 27.0, 2.0, 74.0, 117.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5703345572095929, "mean_inference_ms": 1.7487841547748904, "mean_action_processing_ms": 0.22959805154671012, "mean_env_wait_ms": 0.1917615593320361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038117170333862305, "StateBufferConnector_ms": 0.0031185150146484375, "ViewRequirementAgentConnector_ms": 0.09261488914489746}, "num_episodes": 18, "episode_return_max": 220.5999999999994, "episode_return_min": -189.00000000000045, "episode_return_mean": 43.460999999999856, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.97710077215027, "num_env_steps_trained_throughput_per_sec": 388.97710077215027, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 10234.046, "restore_workers_time_ms": 0.031, "training_step_time_ms": 10233.961, "sample_time_ms": 1298.363, "learn_time_ms": 8920.813, "learn_throughput": 448.39, "synch_weights_time_ms": 13.274}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "0b081_00000", "date": "2024-08-13_00-48-52", "timestamp": 1723524532, "time_this_iter_s": 10.287503719329834, "time_total_s": 113.69627952575684, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fb95e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 113.69627952575684, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 30.26, "ram_util_percent": 83.46000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26653993672755344, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.112906143652699, "policy_loss": -0.002000505731209482, "vf_loss": 4.114796972905517, "vf_explained_var": -0.000930310084075524, "kl": 0.008772990729064806, "entropy": 1.5609789351306895, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3545643768140248, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.138091626242986, "policy_loss": -0.005619424024705218, "vf_loss": 6.142444396902014, "vf_explained_var": 0.02069627598479942, "kl": 0.01688867280024277, "entropy": 1.4634067109652928, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -189.00000000000045, "episode_reward_mean": 35.0109999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -274.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -6.854500000000053, "predator_policy": 24.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [72.40000000000002, 57.70000000000041, 77.80000000000015, 165.59999999999937, 36.70000000000028, 60.500000000000426, -27.09999999999978, 10.900000000000034, -9.899999999999805, 11.600000000000056, -16.099999999999532, 40.0000000000003, -20.09999999999956, 42.60000000000028, 69.59999999999998, 39.000000000000284, 64.30000000000027, -32.19999999999964, -28.09999999999961, 24.20000000000006, 95.69999999999965, 38.30000000000029, 37.500000000000384, 119.5999999999998, 143.79999999999993, 85.7999999999991, 121.29999999999963, 143.49999999999915, 86.09999999999965, 56.50000000000048, 54.400000000000524, 90.09999999999867, 220.5999999999994, 88.59999999999872, -37.09999999999976, 40.0000000000003, -41.69999999999974, 92.79999999999978, 150.2999999999991, 200.1999999999989, 63.90000000000023, 55.90000000000048, 115.3999999999987, -28.000000000000057, 37.80000000000027, 41.50000000000028, -43.79999999999975, 90.39999999999907, 35.600000000000236, 42.20000000000018, 131.49999999999878, 121.39999999999975, 150.29999999999916, 19.09999999999997, 134.49999999999903, -73.10000000000011, 42.500000000000334, 50.700000000000394, 128.19999999999982, 55.30000000000039, 91.29999999999866, -29.299999999999905, -154.10000000000136, 71.79999999999993, -124.6000000000007, -125.1000000000002, 43.60000000000029, -184.5000000000002, 40.0000000000003, -122.80000000000095, -19.499999999999815, 10.200000000000076, 40.0000000000003, 69.30000000000004, 98.40000000000009, 108.19999999999926, 25.100000000000215, 60.700000000000486, -126.70000000000027, 46.20000000000048, 62.10000000000036, -189.00000000000045, -36.39999999999978, 33.2000000000002, -27.099999999999902, 82.49999999999967, -102.20000000000022, 12.9, 9.599999999999453, -63.19999999999982, 16.89999999999998, -128.0999999999999, -4.000000000000096, 33.099999999999994, 107.99999999999929, -25.899999999999757, -18.49999999999968, 366.69999999999993, -146.70000000000016, 101.99999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [79.39999999999986, -33.99999999999976, -12.399999999999858, 46.10000000000021, 56.89999999999996, 20.90000000000003, 23.600000000000037, 121.9999999999999, 9.499999999999972, -38.80000000000004, 9.79999999999996, 31.700000000000216, -59.80000000000025, -28.29999999999997, 20.900000000000027, -61.0, -160.60000000000014, 58.700000000000216, 20.000000000000014, -42.399999999999885, 20.000000000000014, -87.10000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -102.1000000000007, 20.000000000000014, -27.399999999999885, 20.000000000000014, 35.600000000000115, 29.000000000000167, -3.9999999999999587, 41.599999999999994, 22.700000000000056, -38.79999999999983, -36.399999999999814, -49.000000000000014, -24.099999999999817, -30.69999999999977, -3.0999999999999863, 38.00000000000011, 22.699999999999974, 20.000000000000014, 14.29999999999995, 41.60000000000025, -81.10000000000068, -59.200000000000074, 81.79999999999947, -1.6000000000000014, 97.39999999999998, 20.900000000000052, 23.900000000000002, 76.09999999999968, -29.800000000000104, 95.59999999999988, 47.90000000000024, 98.29999999999981, -47.19999999999991, 33.500000000000234, 20.000000000000014, 34.40000000000026, 20.000000000000014, 20.300000000000118, 48.799999999999784, 144.19999999999987, 70.39999999999966, 68.59999999999988, 20.000000000000014, -30.399999999999963, -120.7000000000003, 20.000000000000014, 20.000000000000014, -141.70000000000041, 20.000000000000014, 8.600000000000017, 51.20000000000016, 3.1999999999999704, 136.09999999999974, 97.39999999999972, 102.79999999999957, 23.60000000000008, 38.300000000000125, 29.900000000000187, 20.000000000000014, 17.899999999999988, 96.4999999999994, -47.79999999999983, -47.1999999999999, 20.000000000000014, 15.799999999999963, -17.19999999999986, 13.699999999999946, -87.10000000000039, -69.70000000000067, 70.39999999999965, 20.000000000000014, 11.599999999999964, 20.000000000000014, -36.70000000000017, 20.90000000000003, 84.79999999999929, 40.70000000000012, 5.299999999999965, 109.1, 100.39999999999992, 20.90000000000003, -19.89999999999985, 20.000000000000014, 22.700000000000053, 111.79999999999964, -40.300000000000004, -179.8000000000005, 21.500000000000036, 20.000000000000014, 20.000000000000014, 7.6999999999999895, 89.29999999999998, 38.900000000000105, 35.300000000000196, 20.000000000000014, 42.50000000000025, 48.800000000000196, 20.000000000000014, -112.30000000000025, -109.60000000000069, -122.50000000000063, 48.800000000000225, 20.000000000000014, -147.4000000000001, -98.20000000000061, -244.6000000000002, -47.49999999999994, 23.600000000000044, 20.000000000000014, -274.00000000000017, -74.49999999999989, 20.000000000000014, 20.000000000000014, -129.10000000000016, -141.7000000000007, -15.100000000000085, -93.39999999999984, -31.8999999999998, -7.899999999999945, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.300000000000196, -25.300000000000388, 82.69999999999928, 59.59999999999984, 2.5999999999999805, 2.0000000000000178, 7.099999999999966, 20.000000000000014, 40.70000000000024, -122.8000000000003, -220.9, 20.000000000000014, 12.200000000000145, 20.000000000000014, 13.099999999999973, -246.70000000000013, -133.30000000000024, 20.000000000000014, -168.40000000000018, 17.899999999999988, -9.699999999999896, -124.90000000000049, 9.800000000000153, 20.000000000000014, 36.5, -61.90000000000068, -175.30000000000013, 20.000000000000014, -39.099999999999774, 10.700000000000049, -66.10000000000005, -194.2, 20.000000000000014, 28.100000000000147, -68.2000000000004, -69.50000000000003, -228.60000000000008, -61.89999999999994, 17.900000000000013, 92.59999999999997, -264.5000000000001, 32.000000000000036, 38.00000000000024, -213.1000000000003, 36.200000000000216, -181.49999999999997, 20.000000000000014, 195.49999999999997, 171.20000000000002, -120.70000000000012, -106.00000000000021, 20.000000000000014, 76.99999999999972], "policy_predator_policy_reward": [27.0, 0.0, 21.0, 3.0, 0.0, 0.0, 20.0, 0.0, 5.0, 61.0, 0.0, 19.0, 38.0, 23.0, 51.0, 0.0, 92.0, 0.0, 0.0, 34.0, 51.0, 0.0, 0.0, 0.0, 0.0, 62.0, 50.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 43.0, 0.0, 45.0, 0.0, 28.0, 30.0, 2.0, 33.0, 4.0, 0.0, 47.0, 30.0, 45.0, 52.0, 0.0, 48.0, 41.0, 0.0, 64.0, 11.0, 0.0, 0.0, 35.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 0.0, 85.0, 29.0, 0.0, 0.0, 6.0, 74.0, 3.0, 30.0, 11.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 2.0, 0.0, 45.0, 55.0, 58.0, 0.0, 0.0, 0.0, 4.0, 1.0, 57.0, 0.0, 6.0, 7.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 0.0, 48.0, 99.0, 1.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 63.0, 0.0, 78.0, 0.0, 3.0, 121.0, 0.0, 152.0, 15.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 77.0, 71.0, 52.0, 37.0, 15.0, 35.0, 0.0, 0.0, 11.0, 0.0, 1.0, 40.0, 18.0, 28.0, 9.0, 7.0, 0.0, 0.0, 105.0, 112.0, 14.0, 0.0, 27.0, 2.0, 74.0, 117.0, 14.0, 98.0, 0.0, 25.0, 0.0, 88.0, 26.0, 0.0, 96.0, 39.0, 0.0, 32.0, 65.0, 0.0, 0.0, 111.0, 42.0, 15.0, 170.0, 0.0, 0.0, 40.0, 61.0, 144.0, 38.0, 0.0, 109.0, 42.0, 1.0, 142.0, 0.0, 0.0, 80.0, 0.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5682664446819666, "mean_inference_ms": 1.7453749537001817, "mean_action_processing_ms": 0.22936761438358996, "mean_env_wait_ms": 0.191006769637378, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004389762878417969, "StateBufferConnector_ms": 0.003207087516784668, "ViewRequirementAgentConnector_ms": 0.09436118602752686}, "num_episodes": 18, "episode_return_max": 366.69999999999993, "episode_return_min": -189.00000000000045, "episode_return_mean": 35.0109999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 403.87563477132585, "num_env_steps_trained_throughput_per_sec": 403.87563477132585, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 10158.251, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10158.205, "sample_time_ms": 1281.78, "learn_time_ms": 8861.425, "learn_throughput": 451.395, "synch_weights_time_ms": 13.563}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "0b081_00000", "date": "2024-08-13_00-49-02", "timestamp": 1723524542, "time_this_iter_s": 9.915730953216553, "time_total_s": 123.61201047897339, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fd5040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 123.61201047897339, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 28.492857142857133, "ram_util_percent": 83.02857142857144}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28090497363339023, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4777616218284324, "policy_loss": -0.0037177094810262874, "vf_loss": 3.4813691773742597, "vf_explained_var": 0.0025450285149629785, "kl": 0.008812232646078343, "entropy": 1.5522797665268024, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5228322148165374, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.711203473207181, "policy_loss": -0.006733129375303785, "vf_loss": 5.716315680963022, "vf_explained_var": 0.0282190532596023, "kl": 0.02161237278430868, "entropy": 1.3738623594480848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -189.00000000000045, "episode_reward_mean": 36.728999999999814, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -274.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -8.375500000000072, "predator_policy": 26.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.09999999999961, 24.20000000000006, 95.69999999999965, 38.30000000000029, 37.500000000000384, 119.5999999999998, 143.79999999999993, 85.7999999999991, 121.29999999999963, 143.49999999999915, 86.09999999999965, 56.50000000000048, 54.400000000000524, 90.09999999999867, 220.5999999999994, 88.59999999999872, -37.09999999999976, 40.0000000000003, -41.69999999999974, 92.79999999999978, 150.2999999999991, 200.1999999999989, 63.90000000000023, 55.90000000000048, 115.3999999999987, -28.000000000000057, 37.80000000000027, 41.50000000000028, -43.79999999999975, 90.39999999999907, 35.600000000000236, 42.20000000000018, 131.49999999999878, 121.39999999999975, 150.29999999999916, 19.09999999999997, 134.49999999999903, -73.10000000000011, 42.500000000000334, 50.700000000000394, 128.19999999999982, 55.30000000000039, 91.29999999999866, -29.299999999999905, -154.10000000000136, 71.79999999999993, -124.6000000000007, -125.1000000000002, 43.60000000000029, -184.5000000000002, 40.0000000000003, -122.80000000000095, -19.499999999999815, 10.200000000000076, 40.0000000000003, 69.30000000000004, 98.40000000000009, 108.19999999999926, 25.100000000000215, 60.700000000000486, -126.70000000000027, 46.20000000000048, 62.10000000000036, -189.00000000000045, -36.39999999999978, 33.2000000000002, -27.099999999999902, 82.49999999999967, -102.20000000000022, 12.9, 9.599999999999453, -63.19999999999982, 16.89999999999998, -128.0999999999999, -4.000000000000096, 33.099999999999994, 107.99999999999929, -25.899999999999757, -18.49999999999968, 366.69999999999993, -146.70000000000016, 101.99999999999935, -117.90000000000002, 128.89999999999966, 89.49999999999868, -115.80000000000112, 89.79999999999937, -28.19999999999964, 174.89999999999932, 176.29999999999956, 30.000000000000178, 40.0000000000003, -65.99999999999991, 33.70000000000023, 91.90000000000006, 108.49999999999942, -13.9999999999999, 92.3999999999989, -35.19999999999997, 136.29999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-49.000000000000014, -24.099999999999817, -30.69999999999977, -3.0999999999999863, 38.00000000000011, 22.699999999999974, 20.000000000000014, 14.29999999999995, 41.60000000000025, -81.10000000000068, -59.200000000000074, 81.79999999999947, -1.6000000000000014, 97.39999999999998, 20.900000000000052, 23.900000000000002, 76.09999999999968, -29.800000000000104, 95.59999999999988, 47.90000000000024, 98.29999999999981, -47.19999999999991, 33.500000000000234, 20.000000000000014, 34.40000000000026, 20.000000000000014, 20.300000000000118, 48.799999999999784, 144.19999999999987, 70.39999999999966, 68.59999999999988, 20.000000000000014, -30.399999999999963, -120.7000000000003, 20.000000000000014, 20.000000000000014, -141.70000000000041, 20.000000000000014, 8.600000000000017, 51.20000000000016, 3.1999999999999704, 136.09999999999974, 97.39999999999972, 102.79999999999957, 23.60000000000008, 38.300000000000125, 29.900000000000187, 20.000000000000014, 17.899999999999988, 96.4999999999994, -47.79999999999983, -47.1999999999999, 20.000000000000014, 15.799999999999963, -17.19999999999986, 13.699999999999946, -87.10000000000039, -69.70000000000067, 70.39999999999965, 20.000000000000014, 11.599999999999964, 20.000000000000014, -36.70000000000017, 20.90000000000003, 84.79999999999929, 40.70000000000012, 5.299999999999965, 109.1, 100.39999999999992, 20.90000000000003, -19.89999999999985, 20.000000000000014, 22.700000000000053, 111.79999999999964, -40.300000000000004, -179.8000000000005, 21.500000000000036, 20.000000000000014, 20.000000000000014, 7.6999999999999895, 89.29999999999998, 38.900000000000105, 35.300000000000196, 20.000000000000014, 42.50000000000025, 48.800000000000196, 20.000000000000014, -112.30000000000025, -109.60000000000069, -122.50000000000063, 48.800000000000225, 20.000000000000014, -147.4000000000001, -98.20000000000061, -244.6000000000002, -47.49999999999994, 23.600000000000044, 20.000000000000014, -274.00000000000017, -74.49999999999989, 20.000000000000014, 20.000000000000014, -129.10000000000016, -141.7000000000007, -15.100000000000085, -93.39999999999984, -31.8999999999998, -7.899999999999945, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.300000000000196, -25.300000000000388, 82.69999999999928, 59.59999999999984, 2.5999999999999805, 2.0000000000000178, 7.099999999999966, 20.000000000000014, 40.70000000000024, -122.8000000000003, -220.9, 20.000000000000014, 12.200000000000145, 20.000000000000014, 13.099999999999973, -246.70000000000013, -133.30000000000024, 20.000000000000014, -168.40000000000018, 17.899999999999988, -9.699999999999896, -124.90000000000049, 9.800000000000153, 20.000000000000014, 36.5, -61.90000000000068, -175.30000000000013, 20.000000000000014, -39.099999999999774, 10.700000000000049, -66.10000000000005, -194.2, 20.000000000000014, 28.100000000000147, -68.2000000000004, -69.50000000000003, -228.60000000000008, -61.89999999999994, 17.900000000000013, 92.59999999999997, -264.5000000000001, 32.000000000000036, 38.00000000000024, -213.1000000000003, 36.200000000000216, -181.49999999999997, 20.000000000000014, 195.49999999999997, 171.20000000000002, -120.70000000000012, -106.00000000000021, 20.000000000000014, 76.99999999999972, -263.5000000000002, 8.600000000000065, 100.09999999999997, 18.8, 48.80000000000024, 40.70000000000025, -99.10000000000042, -162.70000000000064, 98.2999999999997, -74.50000000000011, 20.000000000000014, -119.20000000000061, 47.90000000000002, 112.99999999999973, 195.2, -70.90000000000053, -190.0, 85.99999999999997, 20.000000000000014, 20.000000000000014, -115.30000000000017, -57.70000000000003, -48.39999999999992, 28.10000000000016, 100.10000000000002, -95.20000000000019, -37.599999999999994, 115.0999999999998, 22.700000000000045, -117.70000000000002, 20.000000000000014, 37.39999999999975, -131.20000000000022, 16.99999999999997, 20.000000000000014, 116.29999999999993], "policy_predator_policy_reward": [45.0, 0.0, 28.0, 30.0, 2.0, 33.0, 4.0, 0.0, 47.0, 30.0, 45.0, 52.0, 0.0, 48.0, 41.0, 0.0, 64.0, 11.0, 0.0, 0.0, 35.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 0.0, 85.0, 29.0, 0.0, 0.0, 6.0, 74.0, 3.0, 30.0, 11.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 2.0, 0.0, 45.0, 55.0, 58.0, 0.0, 0.0, 0.0, 4.0, 1.0, 57.0, 0.0, 6.0, 7.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 0.0, 48.0, 99.0, 1.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 63.0, 0.0, 78.0, 0.0, 3.0, 121.0, 0.0, 152.0, 15.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 77.0, 71.0, 52.0, 37.0, 15.0, 35.0, 0.0, 0.0, 11.0, 0.0, 1.0, 40.0, 18.0, 28.0, 9.0, 7.0, 0.0, 0.0, 105.0, 112.0, 14.0, 0.0, 27.0, 2.0, 74.0, 117.0, 14.0, 98.0, 0.0, 25.0, 0.0, 88.0, 26.0, 0.0, 96.0, 39.0, 0.0, 32.0, 65.0, 0.0, 0.0, 111.0, 42.0, 15.0, 170.0, 0.0, 0.0, 40.0, 61.0, 144.0, 38.0, 0.0, 109.0, 42.0, 1.0, 142.0, 0.0, 0.0, 80.0, 0.0, 2.0, 3.0, 137.0, 0.0, 0.0, 10.0, 0.0, 0.0, 33.0, 113.0, 65.0, 1.0, 71.0, 0.0, 14.0, 0.0, 1.0, 51.0, 101.0, 33.0, 0.0, 0.0, 74.0, 33.0, 2.0, 52.0, 0.0, 87.0, 20.0, 11.0, 73.0, 8.0, 0.0, 35.0, 7.0, 72.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5670868369025382, "mean_inference_ms": 1.7435362008165312, "mean_action_processing_ms": 0.22921597918747316, "mean_env_wait_ms": 0.19044775461145208, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00437009334564209, "StateBufferConnector_ms": 0.0030252933502197266, "ViewRequirementAgentConnector_ms": 0.0956583023071289}, "num_episodes": 18, "episode_return_max": 366.69999999999993, "episode_return_min": -189.00000000000045, "episode_return_mean": 36.728999999999814, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.7225528131644, "num_env_steps_trained_throughput_per_sec": 373.7225528131644, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 10190.583, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10190.539, "sample_time_ms": 1283.984, "learn_time_ms": 8891.021, "learn_throughput": 449.892, "synch_weights_time_ms": 14.033}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "0b081_00000", "date": "2024-08-13_00-49-13", "timestamp": 1723524553, "time_this_iter_s": 10.757198095321655, "time_total_s": 134.36920857429504, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fd5940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 134.36920857429504, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 31.54666666666667, "ram_util_percent": 83.17999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2909422532177318, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1752361158845286, "policy_loss": -0.002780254584830747, "vf_loss": 2.1778924523837984, "vf_explained_var": 0.005231911070132381, "kl": 0.009913644942381209, "entropy": 1.5663996386149572, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.549494891057885, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.432123385787641, "policy_loss": -0.005626413526220454, "vf_loss": 5.435457347435926, "vf_explained_var": 0.05577496365895347, "kl": 0.020377146294540172, "entropy": 1.390959866841634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -189.00000000000045, "episode_reward_mean": 33.81799999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -274.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -10.606000000000058, "predator_policy": 27.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [41.50000000000028, -43.79999999999975, 90.39999999999907, 35.600000000000236, 42.20000000000018, 131.49999999999878, 121.39999999999975, 150.29999999999916, 19.09999999999997, 134.49999999999903, -73.10000000000011, 42.500000000000334, 50.700000000000394, 128.19999999999982, 55.30000000000039, 91.29999999999866, -29.299999999999905, -154.10000000000136, 71.79999999999993, -124.6000000000007, -125.1000000000002, 43.60000000000029, -184.5000000000002, 40.0000000000003, -122.80000000000095, -19.499999999999815, 10.200000000000076, 40.0000000000003, 69.30000000000004, 98.40000000000009, 108.19999999999926, 25.100000000000215, 60.700000000000486, -126.70000000000027, 46.20000000000048, 62.10000000000036, -189.00000000000045, -36.39999999999978, 33.2000000000002, -27.099999999999902, 82.49999999999967, -102.20000000000022, 12.9, 9.599999999999453, -63.19999999999982, 16.89999999999998, -128.0999999999999, -4.000000000000096, 33.099999999999994, 107.99999999999929, -25.899999999999757, -18.49999999999968, 366.69999999999993, -146.70000000000016, 101.99999999999935, -117.90000000000002, 128.89999999999966, 89.49999999999868, -115.80000000000112, 89.79999999999937, -28.19999999999964, 174.89999999999932, 176.29999999999956, 30.000000000000178, 40.0000000000003, -65.99999999999991, 33.70000000000023, 91.90000000000006, 108.49999999999942, -13.9999999999999, 92.3999999999989, -35.19999999999997, 136.29999999999956, 40.0000000000003, 7.199999999999864, 78.1000000000001, 50.80000000000035, 218.6999999999992, -10.299999999999928, 66.89999999999964, -32.599999999999795, 174.29999999999936, -82.99999999999997, 32.600000000000335, -25.999999999999524, 121.90000000000003, 165.3999999999996, 129.99999999999991, 126.59999999999992, 61.20000000000047, 92.39999999999915, 73.39999999999978, 96.69999999999973, 68.09999999999997, 62.300000000000054, 56.50000000000021, 93.3999999999999, 45.00000000000013, -16.099999999999532, 42.80000000000034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-17.19999999999986, 13.699999999999946, -87.10000000000039, -69.70000000000067, 70.39999999999965, 20.000000000000014, 11.599999999999964, 20.000000000000014, -36.70000000000017, 20.90000000000003, 84.79999999999929, 40.70000000000012, 5.299999999999965, 109.1, 100.39999999999992, 20.90000000000003, -19.89999999999985, 20.000000000000014, 22.700000000000053, 111.79999999999964, -40.300000000000004, -179.8000000000005, 21.500000000000036, 20.000000000000014, 20.000000000000014, 7.6999999999999895, 89.29999999999998, 38.900000000000105, 35.300000000000196, 20.000000000000014, 42.50000000000025, 48.800000000000196, 20.000000000000014, -112.30000000000025, -109.60000000000069, -122.50000000000063, 48.800000000000225, 20.000000000000014, -147.4000000000001, -98.20000000000061, -244.6000000000002, -47.49999999999994, 23.600000000000044, 20.000000000000014, -274.00000000000017, -74.49999999999989, 20.000000000000014, 20.000000000000014, -129.10000000000016, -141.7000000000007, -15.100000000000085, -93.39999999999984, -31.8999999999998, -7.899999999999945, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.300000000000196, -25.300000000000388, 82.69999999999928, 59.59999999999984, 2.5999999999999805, 2.0000000000000178, 7.099999999999966, 20.000000000000014, 40.70000000000024, -122.8000000000003, -220.9, 20.000000000000014, 12.200000000000145, 20.000000000000014, 13.099999999999973, -246.70000000000013, -133.30000000000024, 20.000000000000014, -168.40000000000018, 17.899999999999988, -9.699999999999896, -124.90000000000049, 9.800000000000153, 20.000000000000014, 36.5, -61.90000000000068, -175.30000000000013, 20.000000000000014, -39.099999999999774, 10.700000000000049, -66.10000000000005, -194.2, 20.000000000000014, 28.100000000000147, -68.2000000000004, -69.50000000000003, -228.60000000000008, -61.89999999999994, 17.900000000000013, 92.59999999999997, -264.5000000000001, 32.000000000000036, 38.00000000000024, -213.1000000000003, 36.200000000000216, -181.49999999999997, 20.000000000000014, 195.49999999999997, 171.20000000000002, -120.70000000000012, -106.00000000000021, 20.000000000000014, 76.99999999999972, -263.5000000000002, 8.600000000000065, 100.09999999999997, 18.8, 48.80000000000024, 40.70000000000025, -99.10000000000042, -162.70000000000064, 98.2999999999997, -74.50000000000011, 20.000000000000014, -119.20000000000061, 47.90000000000002, 112.99999999999973, 195.2, -70.90000000000053, -190.0, 85.99999999999997, 20.000000000000014, 20.000000000000014, -115.30000000000017, -57.70000000000003, -48.39999999999992, 28.10000000000016, 100.10000000000002, -95.20000000000019, -37.599999999999994, 115.0999999999998, 22.700000000000045, -117.70000000000002, 20.000000000000014, 37.39999999999975, -131.20000000000022, 16.99999999999997, 20.000000000000014, 116.29999999999993, 20.000000000000014, 20.000000000000014, -35.500000000000064, -10.299999999999958, -14.199999999999958, 17.300000000000033, 24.50000000000008, 26.300000000000125, 175.7, 41.0000000000002, -88.29999999999995, 20.000000000000014, -5.799999999999912, 31.700000000000124, -118.60000000000034, 20.000000000000014, 156.19999999999993, 10.099999999999966, -133.00000000000003, -70.00000000000064, 20.000000000000014, -33.40000000000015, -32.49999999999975, -53.50000000000016, 20.900000000000027, 101.00000000000016, 124.39999999999999, 20.000000000000014, 63.19999999999998, 66.79999999999984, -16.299999999999848, 101.90000000000005, 26.30000000000004, 23.90000000000009, 46.40000000000012, 20.000000000000014, 22.400000000000112, 20.000000000000014, 21.800000000000047, 74.90000000000002, 33.20000000000019, 17.899999999999995, -42.99999999999997, 26.300000000000054, -59.50000000000025, 40.99999999999996, -27.69999999999989, 19.1, 20.000000000000014, -4.000000000000014, 7.399999999999955, -74.50000000000088, 18.799999999999994, 20.000000000000014], "policy_predator_policy_reward": [0.0, 45.0, 55.0, 58.0, 0.0, 0.0, 0.0, 4.0, 1.0, 57.0, 0.0, 6.0, 7.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 0.0, 48.0, 99.0, 1.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 63.0, 0.0, 78.0, 0.0, 3.0, 121.0, 0.0, 152.0, 15.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 77.0, 71.0, 52.0, 37.0, 15.0, 35.0, 0.0, 0.0, 11.0, 0.0, 1.0, 40.0, 18.0, 28.0, 9.0, 7.0, 0.0, 0.0, 105.0, 112.0, 14.0, 0.0, 27.0, 2.0, 74.0, 117.0, 14.0, 98.0, 0.0, 25.0, 0.0, 88.0, 26.0, 0.0, 96.0, 39.0, 0.0, 32.0, 65.0, 0.0, 0.0, 111.0, 42.0, 15.0, 170.0, 0.0, 0.0, 40.0, 61.0, 144.0, 38.0, 0.0, 109.0, 42.0, 1.0, 142.0, 0.0, 0.0, 80.0, 0.0, 2.0, 3.0, 137.0, 0.0, 0.0, 10.0, 0.0, 0.0, 33.0, 113.0, 65.0, 1.0, 71.0, 0.0, 14.0, 0.0, 1.0, 51.0, 101.0, 33.0, 0.0, 0.0, 74.0, 33.0, 2.0, 52.0, 0.0, 87.0, 20.0, 11.0, 73.0, 8.0, 0.0, 35.0, 7.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.0, 43.0, 32.0, 0.0, 0.0, 0.0, 2.0, 0.0, 58.0, 0.0, 41.0, 66.0, 0.0, 8.0, 0.0, 0.0, 120.0, 46.0, 0.0, 25.0, 35.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 40.0, 1.0, 0.0, 11.0, 0.0, 26.0, 0.0, 31.0, 0.0, 0.0, 17.0, 0.0, 70.0, 9.0, 0.0, 75.0, 40.0, 62.0, 29.0, 0.0, 51.0, 0.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5671923202859857, "mean_inference_ms": 1.7411573990848934, "mean_action_processing_ms": 0.2289290524703498, "mean_env_wait_ms": 0.1900152331055603, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004551529884338379, "StateBufferConnector_ms": 0.0031189918518066406, "ViewRequirementAgentConnector_ms": 0.09864568710327148}, "num_episodes": 27, "episode_return_max": 366.69999999999993, "episode_return_min": -189.00000000000045, "episode_return_mean": 33.81799999999987, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 389.26469270840306, "num_env_steps_trained_throughput_per_sec": 389.26469270840306, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 10167.743, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10167.699, "sample_time_ms": 1289.701, "learn_time_ms": 8862.561, "learn_throughput": 451.337, "synch_weights_time_ms": 13.999}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "0b081_00000", "date": "2024-08-13_00-49-23", "timestamp": 1723524563, "time_this_iter_s": 10.279117822647095, "time_total_s": 144.64832639694214, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fd51f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 144.64832639694214, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 29.38, "ram_util_percent": 83.33999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25969174596525374, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.26469942261933, "policy_loss": -0.0031088303037914177, "vf_loss": 3.26764504783368, "vf_explained_var": -0.001236426104944219, "kl": 0.013056437545901481, "entropy": 1.5508091953065661, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4906144874594198, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.577005316719176, "policy_loss": -0.003271056369942411, "vf_loss": 6.5789723340796415, "vf_explained_var": 0.03530765759251105, "kl": 0.007727651238994882, "entropy": 1.3865037262755096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -337.9999999999999, "episode_reward_mean": 37.194999999999865, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.89999999999975, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -11.212500000000068, "predator_policy": 29.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [71.79999999999993, -124.6000000000007, -125.1000000000002, 43.60000000000029, -184.5000000000002, 40.0000000000003, -122.80000000000095, -19.499999999999815, 10.200000000000076, 40.0000000000003, 69.30000000000004, 98.40000000000009, 108.19999999999926, 25.100000000000215, 60.700000000000486, -126.70000000000027, 46.20000000000048, 62.10000000000036, -189.00000000000045, -36.39999999999978, 33.2000000000002, -27.099999999999902, 82.49999999999967, -102.20000000000022, 12.9, 9.599999999999453, -63.19999999999982, 16.89999999999998, -128.0999999999999, -4.000000000000096, 33.099999999999994, 107.99999999999929, -25.899999999999757, -18.49999999999968, 366.69999999999993, -146.70000000000016, 101.99999999999935, -117.90000000000002, 128.89999999999966, 89.49999999999868, -115.80000000000112, 89.79999999999937, -28.19999999999964, 174.89999999999932, 176.29999999999956, 30.000000000000178, 40.0000000000003, -65.99999999999991, 33.70000000000023, 91.90000000000006, 108.49999999999942, -13.9999999999999, 92.3999999999989, -35.19999999999997, 136.29999999999956, 40.0000000000003, 7.199999999999864, 78.1000000000001, 50.80000000000035, 218.6999999999992, -10.299999999999928, 66.89999999999964, -32.599999999999795, 174.29999999999936, -82.99999999999997, 32.600000000000335, -25.999999999999524, 121.90000000000003, 165.3999999999996, 129.99999999999991, 126.59999999999992, 61.20000000000047, 92.39999999999915, 73.39999999999978, 96.69999999999973, 68.09999999999997, 62.300000000000054, 56.50000000000021, 93.3999999999999, 45.00000000000013, -16.099999999999532, 42.80000000000034, 132.69999999999902, 122.79999999999967, 130.6999999999987, 232.8999999999996, 137.69999999999956, 110.19999999999978, 33.50000000000005, 18.80000000000007, -45.49999999999961, 164.79999999999913, 161.79999999999953, 38.300000000000296, -337.9999999999999, 112.49999999999918, 78.7999999999995, 74.99999999999967, -8.599999999999744, 13.500000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [48.800000000000225, 20.000000000000014, -147.4000000000001, -98.20000000000061, -244.6000000000002, -47.49999999999994, 23.600000000000044, 20.000000000000014, -274.00000000000017, -74.49999999999989, 20.000000000000014, 20.000000000000014, -129.10000000000016, -141.7000000000007, -15.100000000000085, -93.39999999999984, -31.8999999999998, -7.899999999999945, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.300000000000196, -25.300000000000388, 82.69999999999928, 59.59999999999984, 2.5999999999999805, 2.0000000000000178, 7.099999999999966, 20.000000000000014, 40.70000000000024, -122.8000000000003, -220.9, 20.000000000000014, 12.200000000000145, 20.000000000000014, 13.099999999999973, -246.70000000000013, -133.30000000000024, 20.000000000000014, -168.40000000000018, 17.899999999999988, -9.699999999999896, -124.90000000000049, 9.800000000000153, 20.000000000000014, 36.5, -61.90000000000068, -175.30000000000013, 20.000000000000014, -39.099999999999774, 10.700000000000049, -66.10000000000005, -194.2, 20.000000000000014, 28.100000000000147, -68.2000000000004, -69.50000000000003, -228.60000000000008, -61.89999999999994, 17.900000000000013, 92.59999999999997, -264.5000000000001, 32.000000000000036, 38.00000000000024, -213.1000000000003, 36.200000000000216, -181.49999999999997, 20.000000000000014, 195.49999999999997, 171.20000000000002, -120.70000000000012, -106.00000000000021, 20.000000000000014, 76.99999999999972, -263.5000000000002, 8.600000000000065, 100.09999999999997, 18.8, 48.80000000000024, 40.70000000000025, -99.10000000000042, -162.70000000000064, 98.2999999999997, -74.50000000000011, 20.000000000000014, -119.20000000000061, 47.90000000000002, 112.99999999999973, 195.2, -70.90000000000053, -190.0, 85.99999999999997, 20.000000000000014, 20.000000000000014, -115.30000000000017, -57.70000000000003, -48.39999999999992, 28.10000000000016, 100.10000000000002, -95.20000000000019, -37.599999999999994, 115.0999999999998, 22.700000000000045, -117.70000000000002, 20.000000000000014, 37.39999999999975, -131.20000000000022, 16.99999999999997, 20.000000000000014, 116.29999999999993, 20.000000000000014, 20.000000000000014, -35.500000000000064, -10.299999999999958, -14.199999999999958, 17.300000000000033, 24.50000000000008, 26.300000000000125, 175.7, 41.0000000000002, -88.29999999999995, 20.000000000000014, -5.799999999999912, 31.700000000000124, -118.60000000000034, 20.000000000000014, 156.19999999999993, 10.099999999999966, -133.00000000000003, -70.00000000000064, 20.000000000000014, -33.40000000000015, -32.49999999999975, -53.50000000000016, 20.900000000000027, 101.00000000000016, 124.39999999999999, 20.000000000000014, 63.19999999999998, 66.79999999999984, -16.299999999999848, 101.90000000000005, 26.30000000000004, 23.90000000000009, 46.40000000000012, 20.000000000000014, 22.400000000000112, 20.000000000000014, 21.800000000000047, 74.90000000000002, 33.20000000000019, 17.899999999999995, -42.99999999999997, 26.300000000000054, -59.50000000000025, 40.99999999999996, -27.69999999999989, 19.1, 20.000000000000014, -4.000000000000014, 7.399999999999955, -74.50000000000088, 18.799999999999994, 20.000000000000014, 35.29999999999999, 88.39999999999961, 26.300000000000114, 96.49999999999989, 109.69999999999945, 20.000000000000014, 80.29999999999973, 140.59999999999985, -36.39999999999989, 109.09999999999994, 54.199999999999996, 56.00000000000023, -105.40000000000057, 74.90000000000018, 5.900000000000059, -48.09999999999987, 11.299999999999965, -143.80000000000058, 72.79999999999993, 49.99999999999999, -68.49999999999991, 164.29999999999987, -101.80000000000078, 82.09999999999926, -255.09999999999997, -325.89999999999975, 51.7999999999999, 13.699999999999967, -127.00000000000017, 129.79999999999956, 50.00000000000021, 20.000000000000014, 33.50000000000024, -129.10000000000073, -229.1000000000003, 113.59999999999971], "policy_predator_policy_reward": [0.0, 3.0, 121.0, 0.0, 152.0, 15.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 77.0, 71.0, 52.0, 37.0, 15.0, 35.0, 0.0, 0.0, 11.0, 0.0, 1.0, 40.0, 18.0, 28.0, 9.0, 7.0, 0.0, 0.0, 105.0, 112.0, 14.0, 0.0, 27.0, 2.0, 74.0, 117.0, 14.0, 98.0, 0.0, 25.0, 0.0, 88.0, 26.0, 0.0, 96.0, 39.0, 0.0, 32.0, 65.0, 0.0, 0.0, 111.0, 42.0, 15.0, 170.0, 0.0, 0.0, 40.0, 61.0, 144.0, 38.0, 0.0, 109.0, 42.0, 1.0, 142.0, 0.0, 0.0, 80.0, 0.0, 2.0, 3.0, 137.0, 0.0, 0.0, 10.0, 0.0, 0.0, 33.0, 113.0, 65.0, 1.0, 71.0, 0.0, 14.0, 0.0, 1.0, 51.0, 101.0, 33.0, 0.0, 0.0, 74.0, 33.0, 2.0, 52.0, 0.0, 87.0, 20.0, 11.0, 73.0, 8.0, 0.0, 35.0, 7.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.0, 43.0, 32.0, 0.0, 0.0, 0.0, 2.0, 0.0, 58.0, 0.0, 41.0, 66.0, 0.0, 8.0, 0.0, 0.0, 120.0, 46.0, 0.0, 25.0, 35.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 40.0, 1.0, 0.0, 11.0, 0.0, 26.0, 0.0, 31.0, 0.0, 0.0, 17.0, 0.0, 70.0, 9.0, 0.0, 75.0, 40.0, 62.0, 29.0, 0.0, 51.0, 0.0, 4.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 12.0, 0.0, 45.0, 20.0, 0.0, 0.0, 61.0, 3.0, 38.0, 23.0, 36.0, 51.0, 14.0, 28.0, 16.0, 50.0, 58.0, 0.0, 193.0, 50.0, 47.0, 0.0, 10.0, 66.0, 0.0, 5.0, 71.0, 16.0, 129.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5742251961572274, "mean_inference_ms": 1.7577856811857193, "mean_action_processing_ms": 0.23099684953489377, "mean_env_wait_ms": 0.1913606601598598, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005626797676086426, "StateBufferConnector_ms": 0.0031957626342773438, "ViewRequirementAgentConnector_ms": 0.14036667346954346}, "num_episodes": 18, "episode_return_max": 366.69999999999993, "episode_return_min": -337.9999999999999, "episode_return_mean": 37.194999999999865, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.5221991582095, "num_env_steps_trained_throughput_per_sec": 365.5221991582095, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 10238.948, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10238.904, "sample_time_ms": 1364.531, "learn_time_ms": 8859.268, "learn_throughput": 451.505, "synch_weights_time_ms": 13.751}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "0b081_00000", "date": "2024-08-13_00-49-34", "timestamp": 1723524574, "time_this_iter_s": 10.953252077102661, "time_total_s": 155.6015784740448, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fb95e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 155.6015784740448, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 38.287499999999994, "ram_util_percent": 83.35624999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23555605457652182, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4430454309655243, "policy_loss": -0.0031531039597072377, "vf_loss": 2.446064907753909, "vf_explained_var": 0.0016718113863909685, "kl": 0.010689863756054817, "entropy": 1.524794779820417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4686572948066645, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.379100438778993, "policy_loss": -0.006307729425785876, "vf_loss": 5.382882628365168, "vf_explained_var": 0.03372551275308801, "kl": 0.014966182726929773, "entropy": 1.3384144593168188, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -337.9999999999999, "episode_reward_mean": 48.82299999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.89999999999975, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -4.988500000000065, "predator_policy": 29.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.00000000000045, -36.39999999999978, 33.2000000000002, -27.099999999999902, 82.49999999999967, -102.20000000000022, 12.9, 9.599999999999453, -63.19999999999982, 16.89999999999998, -128.0999999999999, -4.000000000000096, 33.099999999999994, 107.99999999999929, -25.899999999999757, -18.49999999999968, 366.69999999999993, -146.70000000000016, 101.99999999999935, -117.90000000000002, 128.89999999999966, 89.49999999999868, -115.80000000000112, 89.79999999999937, -28.19999999999964, 174.89999999999932, 176.29999999999956, 30.000000000000178, 40.0000000000003, -65.99999999999991, 33.70000000000023, 91.90000000000006, 108.49999999999942, -13.9999999999999, 92.3999999999989, -35.19999999999997, 136.29999999999956, 40.0000000000003, 7.199999999999864, 78.1000000000001, 50.80000000000035, 218.6999999999992, -10.299999999999928, 66.89999999999964, -32.599999999999795, 174.29999999999936, -82.99999999999997, 32.600000000000335, -25.999999999999524, 121.90000000000003, 165.3999999999996, 129.99999999999991, 126.59999999999992, 61.20000000000047, 92.39999999999915, 73.39999999999978, 96.69999999999973, 68.09999999999997, 62.300000000000054, 56.50000000000021, 93.3999999999999, 45.00000000000013, -16.099999999999532, 42.80000000000034, 132.69999999999902, 122.79999999999967, 130.6999999999987, 232.8999999999996, 137.69999999999956, 110.19999999999978, 33.50000000000005, 18.80000000000007, -45.49999999999961, 164.79999999999913, 161.79999999999953, 38.300000000000296, -337.9999999999999, 112.49999999999918, 78.7999999999995, 74.99999999999967, -8.599999999999744, 13.500000000000028, 117.69999999999948, 33.60000000000018, 133.0999999999995, -22.799999999999876, 95.79999999999944, 126.89999999999972, 79.59999999999913, -21.99999999999971, -49.29999999999979, 245.99999999999926, -56.40000000000035, 103.29999999999976, 66.10000000000028, 57.00000000000032, 9.90000000000017, 57.60000000000007, 120.09999999999886, 39.000000000000114], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-246.70000000000013, -133.30000000000024, 20.000000000000014, -168.40000000000018, 17.899999999999988, -9.699999999999896, -124.90000000000049, 9.800000000000153, 20.000000000000014, 36.5, -61.90000000000068, -175.30000000000013, 20.000000000000014, -39.099999999999774, 10.700000000000049, -66.10000000000005, -194.2, 20.000000000000014, 28.100000000000147, -68.2000000000004, -69.50000000000003, -228.60000000000008, -61.89999999999994, 17.900000000000013, 92.59999999999997, -264.5000000000001, 32.000000000000036, 38.00000000000024, -213.1000000000003, 36.200000000000216, -181.49999999999997, 20.000000000000014, 195.49999999999997, 171.20000000000002, -120.70000000000012, -106.00000000000021, 20.000000000000014, 76.99999999999972, -263.5000000000002, 8.600000000000065, 100.09999999999997, 18.8, 48.80000000000024, 40.70000000000025, -99.10000000000042, -162.70000000000064, 98.2999999999997, -74.50000000000011, 20.000000000000014, -119.20000000000061, 47.90000000000002, 112.99999999999973, 195.2, -70.90000000000053, -190.0, 85.99999999999997, 20.000000000000014, 20.000000000000014, -115.30000000000017, -57.70000000000003, -48.39999999999992, 28.10000000000016, 100.10000000000002, -95.20000000000019, -37.599999999999994, 115.0999999999998, 22.700000000000045, -117.70000000000002, 20.000000000000014, 37.39999999999975, -131.20000000000022, 16.99999999999997, 20.000000000000014, 116.29999999999993, 20.000000000000014, 20.000000000000014, -35.500000000000064, -10.299999999999958, -14.199999999999958, 17.300000000000033, 24.50000000000008, 26.300000000000125, 175.7, 41.0000000000002, -88.29999999999995, 20.000000000000014, -5.799999999999912, 31.700000000000124, -118.60000000000034, 20.000000000000014, 156.19999999999993, 10.099999999999966, -133.00000000000003, -70.00000000000064, 20.000000000000014, -33.40000000000015, -32.49999999999975, -53.50000000000016, 20.900000000000027, 101.00000000000016, 124.39999999999999, 20.000000000000014, 63.19999999999998, 66.79999999999984, -16.299999999999848, 101.90000000000005, 26.30000000000004, 23.90000000000009, 46.40000000000012, 20.000000000000014, 22.400000000000112, 20.000000000000014, 21.800000000000047, 74.90000000000002, 33.20000000000019, 17.899999999999995, -42.99999999999997, 26.300000000000054, -59.50000000000025, 40.99999999999996, -27.69999999999989, 19.1, 20.000000000000014, -4.000000000000014, 7.399999999999955, -74.50000000000088, 18.799999999999994, 20.000000000000014, 35.29999999999999, 88.39999999999961, 26.300000000000114, 96.49999999999989, 109.69999999999945, 20.000000000000014, 80.29999999999973, 140.59999999999985, -36.39999999999989, 109.09999999999994, 54.199999999999996, 56.00000000000023, -105.40000000000057, 74.90000000000018, 5.900000000000059, -48.09999999999987, 11.299999999999965, -143.80000000000058, 72.79999999999993, 49.99999999999999, -68.49999999999991, 164.29999999999987, -101.80000000000078, 82.09999999999926, -255.09999999999997, -325.89999999999975, 51.7999999999999, 13.699999999999967, -127.00000000000017, 129.79999999999956, 50.00000000000021, 20.000000000000014, 33.50000000000024, -129.10000000000073, -229.1000000000003, 113.59999999999971, 109.09999999999984, -15.399999999999762, -18.399999999999807, 20.000000000000014, 129.79999999999993, -42.69999999999983, 59.000000000000156, -215.80000000000015, 22.700000000000088, -31.90000000000012, 17.899999999999988, 98.00000000000003, -51.40000000000018, 20.000000000000014, -121.60000000000042, 23.600000000000065, -210.30000000000004, -64.00000000000071, 131.00000000000003, 100.99999999999937, -150.4000000000004, -0.9999999999999846, 80.29999999999977, -6.999999999999851, 41.59999999999998, 24.500000000000096, 40.70000000000008, -15.699999999999818, 31.40000000000017, -77.50000000000014, 17.600000000000176, 20.000000000000014, 40.70000000000007, 79.39999999999938, 20.90000000000003, -4.900000000000025], "policy_predator_policy_reward": [74.0, 117.0, 14.0, 98.0, 0.0, 25.0, 0.0, 88.0, 26.0, 0.0, 96.0, 39.0, 0.0, 32.0, 65.0, 0.0, 0.0, 111.0, 42.0, 15.0, 170.0, 0.0, 0.0, 40.0, 61.0, 144.0, 38.0, 0.0, 109.0, 42.0, 1.0, 142.0, 0.0, 0.0, 80.0, 0.0, 2.0, 3.0, 137.0, 0.0, 0.0, 10.0, 0.0, 0.0, 33.0, 113.0, 65.0, 1.0, 71.0, 0.0, 14.0, 0.0, 1.0, 51.0, 101.0, 33.0, 0.0, 0.0, 74.0, 33.0, 2.0, 52.0, 0.0, 87.0, 20.0, 11.0, 73.0, 8.0, 0.0, 35.0, 7.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.0, 43.0, 32.0, 0.0, 0.0, 0.0, 2.0, 0.0, 58.0, 0.0, 41.0, 66.0, 0.0, 8.0, 0.0, 0.0, 120.0, 46.0, 0.0, 25.0, 35.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 40.0, 1.0, 0.0, 11.0, 0.0, 26.0, 0.0, 31.0, 0.0, 0.0, 17.0, 0.0, 70.0, 9.0, 0.0, 75.0, 40.0, 62.0, 29.0, 0.0, 51.0, 0.0, 4.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 12.0, 0.0, 45.0, 20.0, 0.0, 0.0, 61.0, 3.0, 38.0, 23.0, 36.0, 51.0, 14.0, 28.0, 16.0, 50.0, 58.0, 0.0, 193.0, 50.0, 47.0, 0.0, 10.0, 66.0, 0.0, 5.0, 71.0, 16.0, 129.0, 0.0, 0.0, 24.0, 0.0, 32.0, 0.0, 46.0, 116.0, 18.0, 54.0, 51.0, 10.0, 1.0, 60.0, 51.0, 49.0, 27.0, 150.0, 75.0, 13.0, 1.0, 10.0, 85.0, 30.0, 0.0, 0.0, 0.0, 0.0, 32.0, 52.0, 4.0, 0.0, 20.0, 0.0, 0.0, 9.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.581331029845014, "mean_inference_ms": 1.7695626531793485, "mean_action_processing_ms": 0.23271705311084204, "mean_env_wait_ms": 0.19224503857940128, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005613565444946289, "StateBufferConnector_ms": 0.003278017044067383, "ViewRequirementAgentConnector_ms": 0.1390695571899414}, "num_episodes": 18, "episode_return_max": 366.69999999999993, "episode_return_min": -337.9999999999999, "episode_return_mean": 48.82299999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.85274310608946, "num_env_steps_trained_throughput_per_sec": 374.85274310608946, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 10302.402, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10302.358, "sample_time_ms": 1378.782, "learn_time_ms": 8907.884, "learn_throughput": 449.04, "synch_weights_time_ms": 14.017}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "0b081_00000", "date": "2024-08-13_00-49-45", "timestamp": 1723524585, "time_this_iter_s": 10.707491159439087, "time_total_s": 166.3090696334839, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fb9310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 166.3090696334839, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 30.019999999999996, "ram_util_percent": 82.90666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.20883352730876553, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1038783370344727, "policy_loss": -0.004711878745910273, "vf_loss": 1.108409990682932, "vf_explained_var": 0.008828615259241175, "kl": 0.014418011276169205, "entropy": 1.5440156549373, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4271641811050435, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.384613446079234, "policy_loss": -0.006173836992728332, "vf_loss": 3.388004031004729, "vf_explained_var": 0.048263054613083126, "kl": 0.016493306732956018, "entropy": 1.3510980093289935, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 245.99999999999926, "episode_reward_min": -337.9999999999999, "episode_reward_mean": 60.19599999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.89999999999975, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.2, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": 6.367999999999934, "predator_policy": 23.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [101.99999999999935, -117.90000000000002, 128.89999999999966, 89.49999999999868, -115.80000000000112, 89.79999999999937, -28.19999999999964, 174.89999999999932, 176.29999999999956, 30.000000000000178, 40.0000000000003, -65.99999999999991, 33.70000000000023, 91.90000000000006, 108.49999999999942, -13.9999999999999, 92.3999999999989, -35.19999999999997, 136.29999999999956, 40.0000000000003, 7.199999999999864, 78.1000000000001, 50.80000000000035, 218.6999999999992, -10.299999999999928, 66.89999999999964, -32.599999999999795, 174.29999999999936, -82.99999999999997, 32.600000000000335, -25.999999999999524, 121.90000000000003, 165.3999999999996, 129.99999999999991, 126.59999999999992, 61.20000000000047, 92.39999999999915, 73.39999999999978, 96.69999999999973, 68.09999999999997, 62.300000000000054, 56.50000000000021, 93.3999999999999, 45.00000000000013, -16.099999999999532, 42.80000000000034, 132.69999999999902, 122.79999999999967, 130.6999999999987, 232.8999999999996, 137.69999999999956, 110.19999999999978, 33.50000000000005, 18.80000000000007, -45.49999999999961, 164.79999999999913, 161.79999999999953, 38.300000000000296, -337.9999999999999, 112.49999999999918, 78.7999999999995, 74.99999999999967, -8.599999999999744, 13.500000000000028, 117.69999999999948, 33.60000000000018, 133.0999999999995, -22.799999999999876, 95.79999999999944, 126.89999999999972, 79.59999999999913, -21.99999999999971, -49.29999999999979, 245.99999999999926, -56.40000000000035, 103.29999999999976, 66.10000000000028, 57.00000000000032, 9.90000000000017, 57.60000000000007, 120.09999999999886, 39.000000000000114, 127.89999999999968, 122.39999999999948, 109.29999999999889, 3.7000000000001205, 95.8999999999993, 71.49999999999973, -2.8999999999998014, 33.0000000000002, 61.60000000000049, 138.59999999999968, 100.29999999999876, -17.599999999999916, -1.1999999999999846, 86.79999999999932, 34.50000000000022, -4.499999999999751, 40.0000000000003, 59.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 76.99999999999972, -263.5000000000002, 8.600000000000065, 100.09999999999997, 18.8, 48.80000000000024, 40.70000000000025, -99.10000000000042, -162.70000000000064, 98.2999999999997, -74.50000000000011, 20.000000000000014, -119.20000000000061, 47.90000000000002, 112.99999999999973, 195.2, -70.90000000000053, -190.0, 85.99999999999997, 20.000000000000014, 20.000000000000014, -115.30000000000017, -57.70000000000003, -48.39999999999992, 28.10000000000016, 100.10000000000002, -95.20000000000019, -37.599999999999994, 115.0999999999998, 22.700000000000045, -117.70000000000002, 20.000000000000014, 37.39999999999975, -131.20000000000022, 16.99999999999997, 20.000000000000014, 116.29999999999993, 20.000000000000014, 20.000000000000014, -35.500000000000064, -10.299999999999958, -14.199999999999958, 17.300000000000033, 24.50000000000008, 26.300000000000125, 175.7, 41.0000000000002, -88.29999999999995, 20.000000000000014, -5.799999999999912, 31.700000000000124, -118.60000000000034, 20.000000000000014, 156.19999999999993, 10.099999999999966, -133.00000000000003, -70.00000000000064, 20.000000000000014, -33.40000000000015, -32.49999999999975, -53.50000000000016, 20.900000000000027, 101.00000000000016, 124.39999999999999, 20.000000000000014, 63.19999999999998, 66.79999999999984, -16.299999999999848, 101.90000000000005, 26.30000000000004, 23.90000000000009, 46.40000000000012, 20.000000000000014, 22.400000000000112, 20.000000000000014, 21.800000000000047, 74.90000000000002, 33.20000000000019, 17.899999999999995, -42.99999999999997, 26.300000000000054, -59.50000000000025, 40.99999999999996, -27.69999999999989, 19.1, 20.000000000000014, -4.000000000000014, 7.399999999999955, -74.50000000000088, 18.799999999999994, 20.000000000000014, 35.29999999999999, 88.39999999999961, 26.300000000000114, 96.49999999999989, 109.69999999999945, 20.000000000000014, 80.29999999999973, 140.59999999999985, -36.39999999999989, 109.09999999999994, 54.199999999999996, 56.00000000000023, -105.40000000000057, 74.90000000000018, 5.900000000000059, -48.09999999999987, 11.299999999999965, -143.80000000000058, 72.79999999999993, 49.99999999999999, -68.49999999999991, 164.29999999999987, -101.80000000000078, 82.09999999999926, -255.09999999999997, -325.89999999999975, 51.7999999999999, 13.699999999999967, -127.00000000000017, 129.79999999999956, 50.00000000000021, 20.000000000000014, 33.50000000000024, -129.10000000000073, -229.1000000000003, 113.59999999999971, 109.09999999999984, -15.399999999999762, -18.399999999999807, 20.000000000000014, 129.79999999999993, -42.69999999999983, 59.000000000000156, -215.80000000000015, 22.700000000000088, -31.90000000000012, 17.899999999999988, 98.00000000000003, -51.40000000000018, 20.000000000000014, -121.60000000000042, 23.600000000000065, -210.30000000000004, -64.00000000000071, 131.00000000000003, 100.99999999999937, -150.4000000000004, -0.9999999999999846, 80.29999999999977, -6.999999999999851, 41.59999999999998, 24.500000000000096, 40.70000000000008, -15.699999999999818, 31.40000000000017, -77.50000000000014, 17.600000000000176, 20.000000000000014, 40.70000000000007, 79.39999999999938, 20.90000000000003, -4.900000000000025, -12.400000000000247, 71.29999999999976, 104.29999999999986, -28.899999999999785, 20.000000000000014, 89.29999999999949, -49.299999999999805, 20.000000000000014, -101.8000000000008, 139.69999999999968, 20.90000000000003, 50.60000000000002, 39.80000000000022, -99.70000000000081, -10.899999999999835, -0.10000000000004367, 20.000000000000014, 41.60000000000024, 68.9, 40.70000000000019, 80.29999999999939, 20.000000000000014, 5.900000000000041, -125.50000000000071, -18.9999999999999, -53.1999999999999, 20.000000000000014, 66.79999999999987, 9.499999999999964, 20.000000000000014, -6.699999999999912, -17.799999999999756, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.80000000000008], "policy_predator_policy_reward": [2.0, 3.0, 137.0, 0.0, 0.0, 10.0, 0.0, 0.0, 33.0, 113.0, 65.0, 1.0, 71.0, 0.0, 14.0, 0.0, 1.0, 51.0, 101.0, 33.0, 0.0, 0.0, 74.0, 33.0, 2.0, 52.0, 0.0, 87.0, 20.0, 11.0, 73.0, 8.0, 0.0, 35.0, 7.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.0, 43.0, 32.0, 0.0, 0.0, 0.0, 2.0, 0.0, 58.0, 0.0, 41.0, 66.0, 0.0, 8.0, 0.0, 0.0, 120.0, 46.0, 0.0, 25.0, 35.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 40.0, 1.0, 0.0, 11.0, 0.0, 26.0, 0.0, 31.0, 0.0, 0.0, 17.0, 0.0, 70.0, 9.0, 0.0, 75.0, 40.0, 62.0, 29.0, 0.0, 51.0, 0.0, 4.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 12.0, 0.0, 45.0, 20.0, 0.0, 0.0, 61.0, 3.0, 38.0, 23.0, 36.0, 51.0, 14.0, 28.0, 16.0, 50.0, 58.0, 0.0, 193.0, 50.0, 47.0, 0.0, 10.0, 66.0, 0.0, 5.0, 71.0, 16.0, 129.0, 0.0, 0.0, 24.0, 0.0, 32.0, 0.0, 46.0, 116.0, 18.0, 54.0, 51.0, 10.0, 1.0, 60.0, 51.0, 49.0, 27.0, 150.0, 75.0, 13.0, 1.0, 10.0, 85.0, 30.0, 0.0, 0.0, 0.0, 0.0, 32.0, 52.0, 4.0, 0.0, 20.0, 0.0, 0.0, 9.0, 14.0, 35.0, 34.0, 25.0, 22.0, 0.0, 0.0, 33.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 57.0, 18.0, 26.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 15.0, 87.0, 59.0, 12.0, 0.0, 0.0, 5.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5878847861238097, "mean_inference_ms": 1.7802844275089165, "mean_action_processing_ms": 0.23426346886736332, "mean_env_wait_ms": 0.19325498515280798, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052481889724731445, "StateBufferConnector_ms": 0.0032966136932373047, "ViewRequirementAgentConnector_ms": 0.14267730712890625}, "num_episodes": 18, "episode_return_max": 245.99999999999926, "episode_return_min": -337.9999999999999, "episode_return_mean": 60.19599999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 394.44911882301676, "num_env_steps_trained_throughput_per_sec": 394.44911882301676, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 10324.033, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10323.99, "sample_time_ms": 1389.896, "learn_time_ms": 8918.719, "learn_throughput": 448.495, "synch_weights_time_ms": 13.773}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "0b081_00000", "date": "2024-08-13_00-49-55", "timestamp": 1723524595, "time_this_iter_s": 10.146090030670166, "time_total_s": 176.45515966415405, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327f9bf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 176.45515966415405, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 29.93571428571429, "ram_util_percent": 83.29285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1806308962927057, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5193383153153475, "policy_loss": -0.0020112098832787187, "vf_loss": 0.5212836334070378, "vf_explained_var": 0.005623847056948949, "kl": 0.0052712647222988756, "entropy": 1.568478091494747, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2897694565079831, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6041369195968387, "policy_loss": -0.003515113109634036, "vf_loss": 2.6057599553355466, "vf_explained_var": 0.08965908941768465, "kl": 0.01121230111565786, "entropy": 1.3287521233003605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 245.99999999999926, "episode_reward_min": -337.9999999999999, "episode_reward_mean": 66.69099999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.89999999999975, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.7, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": 13.530499999999952, "predator_policy": 19.815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.80000000000035, 218.6999999999992, -10.299999999999928, 66.89999999999964, -32.599999999999795, 174.29999999999936, -82.99999999999997, 32.600000000000335, -25.999999999999524, 121.90000000000003, 165.3999999999996, 129.99999999999991, 126.59999999999992, 61.20000000000047, 92.39999999999915, 73.39999999999978, 96.69999999999973, 68.09999999999997, 62.300000000000054, 56.50000000000021, 93.3999999999999, 45.00000000000013, -16.099999999999532, 42.80000000000034, 132.69999999999902, 122.79999999999967, 130.6999999999987, 232.8999999999996, 137.69999999999956, 110.19999999999978, 33.50000000000005, 18.80000000000007, -45.49999999999961, 164.79999999999913, 161.79999999999953, 38.300000000000296, -337.9999999999999, 112.49999999999918, 78.7999999999995, 74.99999999999967, -8.599999999999744, 13.500000000000028, 117.69999999999948, 33.60000000000018, 133.0999999999995, -22.799999999999876, 95.79999999999944, 126.89999999999972, 79.59999999999913, -21.99999999999971, -49.29999999999979, 245.99999999999926, -56.40000000000035, 103.29999999999976, 66.10000000000028, 57.00000000000032, 9.90000000000017, 57.60000000000007, 120.09999999999886, 39.000000000000114, 127.89999999999968, 122.39999999999948, 109.29999999999889, 3.7000000000001205, 95.8999999999993, 71.49999999999973, -2.8999999999998014, 33.0000000000002, 61.60000000000049, 138.59999999999968, 100.29999999999876, -17.599999999999916, -1.1999999999999846, 86.79999999999932, 34.50000000000022, -4.499999999999751, 40.0000000000003, 59.80000000000027, 74.20000000000033, 111.1, 77.79999999999986, 12.80000000000006, 15.199999999999998, 20.29999999999999, 234.4999999999992, 113.79999999999947, 107.09999999999883, 56.50000000000038, 112.09999999999872, 45.000000000000405, 55.600000000000456, 72.39999999999989, -12.599999999999616, 40.80000000000031, 55.20000000000025, 145.0999999999988, 1.400000000000165, 124.59999999999866, 102.59999999999962, 126.39999999999904], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [24.50000000000008, 26.300000000000125, 175.7, 41.0000000000002, -88.29999999999995, 20.000000000000014, -5.799999999999912, 31.700000000000124, -118.60000000000034, 20.000000000000014, 156.19999999999993, 10.099999999999966, -133.00000000000003, -70.00000000000064, 20.000000000000014, -33.40000000000015, -32.49999999999975, -53.50000000000016, 20.900000000000027, 101.00000000000016, 124.39999999999999, 20.000000000000014, 63.19999999999998, 66.79999999999984, -16.299999999999848, 101.90000000000005, 26.30000000000004, 23.90000000000009, 46.40000000000012, 20.000000000000014, 22.400000000000112, 20.000000000000014, 21.800000000000047, 74.90000000000002, 33.20000000000019, 17.899999999999995, -42.99999999999997, 26.300000000000054, -59.50000000000025, 40.99999999999996, -27.69999999999989, 19.1, 20.000000000000014, -4.000000000000014, 7.399999999999955, -74.50000000000088, 18.799999999999994, 20.000000000000014, 35.29999999999999, 88.39999999999961, 26.300000000000114, 96.49999999999989, 109.69999999999945, 20.000000000000014, 80.29999999999973, 140.59999999999985, -36.39999999999989, 109.09999999999994, 54.199999999999996, 56.00000000000023, -105.40000000000057, 74.90000000000018, 5.900000000000059, -48.09999999999987, 11.299999999999965, -143.80000000000058, 72.79999999999993, 49.99999999999999, -68.49999999999991, 164.29999999999987, -101.80000000000078, 82.09999999999926, -255.09999999999997, -325.89999999999975, 51.7999999999999, 13.699999999999967, -127.00000000000017, 129.79999999999956, 50.00000000000021, 20.000000000000014, 33.50000000000024, -129.10000000000073, -229.1000000000003, 113.59999999999971, 109.09999999999984, -15.399999999999762, -18.399999999999807, 20.000000000000014, 129.79999999999993, -42.69999999999983, 59.000000000000156, -215.80000000000015, 22.700000000000088, -31.90000000000012, 17.899999999999988, 98.00000000000003, -51.40000000000018, 20.000000000000014, -121.60000000000042, 23.600000000000065, -210.30000000000004, -64.00000000000071, 131.00000000000003, 100.99999999999937, -150.4000000000004, -0.9999999999999846, 80.29999999999977, -6.999999999999851, 41.59999999999998, 24.500000000000096, 40.70000000000008, -15.699999999999818, 31.40000000000017, -77.50000000000014, 17.600000000000176, 20.000000000000014, 40.70000000000007, 79.39999999999938, 20.90000000000003, -4.900000000000025, -12.400000000000247, 71.29999999999976, 104.29999999999986, -28.899999999999785, 20.000000000000014, 89.29999999999949, -49.299999999999805, 20.000000000000014, -101.8000000000008, 139.69999999999968, 20.90000000000003, 50.60000000000002, 39.80000000000022, -99.70000000000081, -10.899999999999835, -0.10000000000004367, 20.000000000000014, 41.60000000000024, 68.9, 40.70000000000019, 80.29999999999939, 20.000000000000014, 5.900000000000041, -125.50000000000071, -18.9999999999999, -53.1999999999999, 20.000000000000014, 66.79999999999987, 9.499999999999964, 20.000000000000014, -6.699999999999912, -17.799999999999756, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.80000000000008, 36.499999999999986, 28.700000000000173, 20.000000000000014, 91.10000000000001, 20.000000000000014, 57.800000000000146, -42.699999999999925, -29.49999999999988, -44.799999999999855, 20.000000000000014, 24.500000000000096, -26.199999999999797, 135.8, 88.69999999999936, 123.4999999999998, -36.69999999999976, 34.70000000000021, 61.40000000000014, 15.499999999999968, 20.000000000000014, 58.40000000000016, 40.7000000000002, 20.000000000000014, 2.0000000000000013, 23.600000000000083, 20.000000000000014, 20.000000000000014, 52.40000000000023, -0.4000000000000401, -44.19999999999977, -5.199999999999934, 32.000000000000156, 10.69999999999996, 3.5000000000000355, 20.000000000000014, 124.09999999999954, 20.000000000000014, -58.60000000000049, 104.5999999999994, 20.000000000000014, -10.899999999999892, 60.49999999999995, 69.49999999999973, 56.9000000000001], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 2.0, 0.0, 58.0, 0.0, 41.0, 66.0, 0.0, 8.0, 0.0, 0.0, 120.0, 46.0, 0.0, 25.0, 35.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 40.0, 1.0, 0.0, 11.0, 0.0, 26.0, 0.0, 31.0, 0.0, 0.0, 17.0, 0.0, 70.0, 9.0, 0.0, 75.0, 40.0, 62.0, 29.0, 0.0, 51.0, 0.0, 4.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 12.0, 0.0, 45.0, 20.0, 0.0, 0.0, 61.0, 3.0, 38.0, 23.0, 36.0, 51.0, 14.0, 28.0, 16.0, 50.0, 58.0, 0.0, 193.0, 50.0, 47.0, 0.0, 10.0, 66.0, 0.0, 5.0, 71.0, 16.0, 129.0, 0.0, 0.0, 24.0, 0.0, 32.0, 0.0, 46.0, 116.0, 18.0, 54.0, 51.0, 10.0, 1.0, 60.0, 51.0, 49.0, 27.0, 150.0, 75.0, 13.0, 1.0, 10.0, 85.0, 30.0, 0.0, 0.0, 0.0, 0.0, 32.0, 52.0, 4.0, 0.0, 20.0, 0.0, 0.0, 9.0, 14.0, 35.0, 34.0, 25.0, 22.0, 0.0, 0.0, 33.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 57.0, 18.0, 26.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 15.0, 87.0, 59.0, 12.0, 0.0, 0.0, 5.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 30.0, 55.0, 33.0, 7.0, 10.0, 12.0, 0.0, 10.0, 0.0, 27.0, 2.0, 9.0, 21.0, 0.0, 13.0, 0.0, 14.0, 9.0, 10.0, 2.0, 0.0, 0.0, 32.0, 0.0, 2.0, 12.0, 41.0, 0.0, 1.0, 0.0, 22.0, 18.0, 0.0, 0.0, 21.0, 32.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.595180746211836, "mean_inference_ms": 1.7912270103495487, "mean_action_processing_ms": 0.2358682523514247, "mean_env_wait_ms": 0.19438816530471656, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00518035888671875, "StateBufferConnector_ms": 0.003266572952270508, "ViewRequirementAgentConnector_ms": 0.13851118087768555}, "num_episodes": 22, "episode_return_max": 245.99999999999926, "episode_return_min": -337.9999999999999, "episode_return_mean": 66.69099999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 393.6266017489494, "num_env_steps_trained_throughput_per_sec": 393.6266017489494, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 10358.961, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10358.918, "sample_time_ms": 1389.489, "learn_time_ms": 8954.334, "learn_throughput": 446.711, "synch_weights_time_ms": 13.47}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "0b081_00000", "date": "2024-08-13_00-50-05", "timestamp": 1723524605, "time_this_iter_s": 10.16759705543518, "time_total_s": 186.62275671958923, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e4f550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 186.62275671958923, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 27.420000000000005, "ram_util_percent": 83.42000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.18900965306927603, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.458232033662695, "policy_loss": -0.0022169005629611473, "vf_loss": 1.460391948194731, "vf_explained_var": 0.012158660913901354, "kl": 0.004558574946872036, "entropy": 1.5875389489547285, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5258623411809957, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.647339656491759, "policy_loss": -0.00040095957690879466, "vf_loss": 4.647380575301155, "vf_explained_var": 0.0630716431077826, "kl": 0.00213347307040441, "entropy": 1.289967027732304, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 245.99999999999926, "episode_reward_min": -337.9999999999999, "episode_reward_mean": 68.44999999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.89999999999975, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 164.29999999999987, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": 16.444999999999947, "predator_policy": 17.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.80000000000034, 132.69999999999902, 122.79999999999967, 130.6999999999987, 232.8999999999996, 137.69999999999956, 110.19999999999978, 33.50000000000005, 18.80000000000007, -45.49999999999961, 164.79999999999913, 161.79999999999953, 38.300000000000296, -337.9999999999999, 112.49999999999918, 78.7999999999995, 74.99999999999967, -8.599999999999744, 13.500000000000028, 117.69999999999948, 33.60000000000018, 133.0999999999995, -22.799999999999876, 95.79999999999944, 126.89999999999972, 79.59999999999913, -21.99999999999971, -49.29999999999979, 245.99999999999926, -56.40000000000035, 103.29999999999976, 66.10000000000028, 57.00000000000032, 9.90000000000017, 57.60000000000007, 120.09999999999886, 39.000000000000114, 127.89999999999968, 122.39999999999948, 109.29999999999889, 3.7000000000001205, 95.8999999999993, 71.49999999999973, -2.8999999999998014, 33.0000000000002, 61.60000000000049, 138.59999999999968, 100.29999999999876, -17.599999999999916, -1.1999999999999846, 86.79999999999932, 34.50000000000022, -4.499999999999751, 40.0000000000003, 59.80000000000027, 74.20000000000033, 111.1, 77.79999999999986, 12.80000000000006, 15.199999999999998, 20.29999999999999, 234.4999999999992, 113.79999999999947, 107.09999999999883, 56.50000000000038, 112.09999999999872, 45.000000000000405, 55.600000000000456, 72.39999999999989, -12.599999999999616, 40.80000000000031, 55.20000000000025, 145.0999999999988, 1.400000000000165, 124.59999999999866, 102.59999999999962, 126.39999999999904, 40.0000000000003, 56.20000000000027, 57.10000000000046, 182.9999999999998, 125.29999999999927, 76.89999999999944, 102.29999999999951, 67.30000000000025, 46.3000000000004, 49.20000000000016, 7.800000000000345, 121.09999999999866, 112.89999999999873, 123.69999999999989, 36.40000000000025, 141.6999999999988, 85.10000000000002, 31.200000000000166, 99.39999999999876, 2.700000000000002, 40.0000000000003, 72.39999999999979, 66.10000000000021], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [18.799999999999994, 20.000000000000014, 35.29999999999999, 88.39999999999961, 26.300000000000114, 96.49999999999989, 109.69999999999945, 20.000000000000014, 80.29999999999973, 140.59999999999985, -36.39999999999989, 109.09999999999994, 54.199999999999996, 56.00000000000023, -105.40000000000057, 74.90000000000018, 5.900000000000059, -48.09999999999987, 11.299999999999965, -143.80000000000058, 72.79999999999993, 49.99999999999999, -68.49999999999991, 164.29999999999987, -101.80000000000078, 82.09999999999926, -255.09999999999997, -325.89999999999975, 51.7999999999999, 13.699999999999967, -127.00000000000017, 129.79999999999956, 50.00000000000021, 20.000000000000014, 33.50000000000024, -129.10000000000073, -229.1000000000003, 113.59999999999971, 109.09999999999984, -15.399999999999762, -18.399999999999807, 20.000000000000014, 129.79999999999993, -42.69999999999983, 59.000000000000156, -215.80000000000015, 22.700000000000088, -31.90000000000012, 17.899999999999988, 98.00000000000003, -51.40000000000018, 20.000000000000014, -121.60000000000042, 23.600000000000065, -210.30000000000004, -64.00000000000071, 131.00000000000003, 100.99999999999937, -150.4000000000004, -0.9999999999999846, 80.29999999999977, -6.999999999999851, 41.59999999999998, 24.500000000000096, 40.70000000000008, -15.699999999999818, 31.40000000000017, -77.50000000000014, 17.600000000000176, 20.000000000000014, 40.70000000000007, 79.39999999999938, 20.90000000000003, -4.900000000000025, -12.400000000000247, 71.29999999999976, 104.29999999999986, -28.899999999999785, 20.000000000000014, 89.29999999999949, -49.299999999999805, 20.000000000000014, -101.8000000000008, 139.69999999999968, 20.90000000000003, 50.60000000000002, 39.80000000000022, -99.70000000000081, -10.899999999999835, -0.10000000000004367, 20.000000000000014, 41.60000000000024, 68.9, 40.70000000000019, 80.29999999999939, 20.000000000000014, 5.900000000000041, -125.50000000000071, -18.9999999999999, -53.1999999999999, 20.000000000000014, 66.79999999999987, 9.499999999999964, 20.000000000000014, -6.699999999999912, -17.799999999999756, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.80000000000008, 36.499999999999986, 28.700000000000173, 20.000000000000014, 91.10000000000001, 20.000000000000014, 57.800000000000146, -42.699999999999925, -29.49999999999988, -44.799999999999855, 20.000000000000014, 24.500000000000096, -26.199999999999797, 135.8, 88.69999999999936, 123.4999999999998, -36.69999999999976, 34.70000000000021, 61.40000000000014, 15.499999999999968, 20.000000000000014, 58.40000000000016, 40.7000000000002, 20.000000000000014, 2.0000000000000013, 23.600000000000083, 20.000000000000014, 20.000000000000014, 52.40000000000023, -0.4000000000000401, -44.19999999999977, -5.199999999999934, 32.000000000000156, 10.69999999999996, 3.5000000000000355, 20.000000000000014, 124.09999999999954, 20.000000000000014, -58.60000000000049, 104.5999999999994, 20.000000000000014, -10.899999999999892, 60.49999999999995, 69.49999999999973, 56.9000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000001, 37.10000000000023, 20.000000000000014, 62.000000000000085, 80.00000000000001, 20.000000000000014, 95.29999999999983, 20.000000000000014, 56.90000000000016, -15.399999999999933, 49.70000000000007, -23.799999999999955, 25.100000000000055, 26.300000000000118, 20.000000000000014, -7.899999999999945, 22.100000000000072, -62.20000000000039, -3.9999999999998295, 100.0999999999994, 16.999999999999975, 20.000000000000014, 92.89999999999947, 94.09999999999997, 20.600000000000023, -12.399999999999816, 30.800000000000203, 20.000000000000014, 121.69999999999952, -101.80000000000078, 128.89999999999992, 20.000000000000014, 3.1999999999999615, 79.39999999999938, 20.000000000000014, -15.699999999999761, -31.59999999999991, 20.000000000000014, 20.000000000000014, 82.99999999999926, -46.59999999999978, 38.90000000000009, 27.20000000000013], "policy_predator_policy_reward": [4.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 12.0, 0.0, 45.0, 20.0, 0.0, 0.0, 61.0, 3.0, 38.0, 23.0, 36.0, 51.0, 14.0, 28.0, 16.0, 50.0, 58.0, 0.0, 193.0, 50.0, 47.0, 0.0, 10.0, 66.0, 0.0, 5.0, 71.0, 16.0, 129.0, 0.0, 0.0, 24.0, 0.0, 32.0, 0.0, 46.0, 116.0, 18.0, 54.0, 51.0, 10.0, 1.0, 60.0, 51.0, 49.0, 27.0, 150.0, 75.0, 13.0, 1.0, 10.0, 85.0, 30.0, 0.0, 0.0, 0.0, 0.0, 32.0, 52.0, 4.0, 0.0, 20.0, 0.0, 0.0, 9.0, 14.0, 35.0, 34.0, 25.0, 22.0, 0.0, 0.0, 33.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 57.0, 18.0, 26.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 15.0, 87.0, 59.0, 12.0, 0.0, 0.0, 5.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 30.0, 55.0, 33.0, 7.0, 10.0, 12.0, 0.0, 10.0, 0.0, 27.0, 2.0, 9.0, 21.0, 0.0, 13.0, 0.0, 14.0, 9.0, 10.0, 2.0, 0.0, 0.0, 32.0, 0.0, 2.0, 12.0, 41.0, 0.0, 1.0, 0.0, 22.0, 18.0, 0.0, 0.0, 21.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 10.0, 0.0, 0.0, 0.0, 25.0, 43.0, 42.0, 24.0, 0.0, 0.0, 2.0, 33.0, 18.0, 56.0, 0.0, 4.0, 0.0, 0.0, 2.0, 7.0, 12.0, 6.0, 0.0, 0.0, 58.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6018276352128994, "mean_inference_ms": 1.8001208260059878, "mean_action_processing_ms": 0.2374785197963602, "mean_env_wait_ms": 0.1951062111064335, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00519108772277832, "StateBufferConnector_ms": 0.003310561180114746, "ViewRequirementAgentConnector_ms": 0.14142239093780518}, "num_episodes": 23, "episode_return_max": 245.99999999999926, "episode_return_min": -337.9999999999999, "episode_return_mean": 68.44999999999979, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.3103582975492, "num_env_steps_trained_throughput_per_sec": 391.3103582975492, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 10378.277, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10378.235, "sample_time_ms": 1388.115, "learn_time_ms": 8968.13, "learn_throughput": 446.024, "synch_weights_time_ms": 20.351}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "0b081_00000", "date": "2024-08-13_00-50-15", "timestamp": 1723524615, "time_this_iter_s": 10.227907180786133, "time_total_s": 196.85066390037537, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fa7700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 196.85066390037537, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 31.18571428571428, "ram_util_percent": 83.33571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30088268781780564, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.62403372904611, "policy_loss": -0.005165773995279793, "vf_loss": 2.629130535529404, "vf_explained_var": 0.011727178979803014, "kl": 0.011034656863693279, "entropy": 1.593275901627919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3327143920161737, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.339878631647302, "policy_loss": -0.0039036874720954863, "vf_loss": 5.342267098124065, "vf_explained_var": 0.031157020948551318, "kl": 0.017958188404404295, "entropy": 1.2554702484418476, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 245.99999999999926, "episode_reward_min": -75.60000000000025, "episode_reward_mean": 66.50399999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.1000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 139.69999999999968, "predator_policy": 150.0}, "policy_reward_mean": {"prey_policy": 15.781999999999949, "predator_policy": 17.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.500000000000028, 117.69999999999948, 33.60000000000018, 133.0999999999995, -22.799999999999876, 95.79999999999944, 126.89999999999972, 79.59999999999913, -21.99999999999971, -49.29999999999979, 245.99999999999926, -56.40000000000035, 103.29999999999976, 66.10000000000028, 57.00000000000032, 9.90000000000017, 57.60000000000007, 120.09999999999886, 39.000000000000114, 127.89999999999968, 122.39999999999948, 109.29999999999889, 3.7000000000001205, 95.8999999999993, 71.49999999999973, -2.8999999999998014, 33.0000000000002, 61.60000000000049, 138.59999999999968, 100.29999999999876, -17.599999999999916, -1.1999999999999846, 86.79999999999932, 34.50000000000022, -4.499999999999751, 40.0000000000003, 59.80000000000027, 74.20000000000033, 111.1, 77.79999999999986, 12.80000000000006, 15.199999999999998, 20.29999999999999, 234.4999999999992, 113.79999999999947, 107.09999999999883, 56.50000000000038, 112.09999999999872, 45.000000000000405, 55.600000000000456, 72.39999999999989, -12.599999999999616, 40.80000000000031, 55.20000000000025, 145.0999999999988, 1.400000000000165, 124.59999999999866, 102.59999999999962, 126.39999999999904, 40.0000000000003, 56.20000000000027, 57.10000000000046, 182.9999999999998, 125.29999999999927, 76.89999999999944, 102.29999999999951, 67.30000000000025, 46.3000000000004, 49.20000000000016, 7.800000000000345, 121.09999999999866, 112.89999999999873, 123.69999999999989, 36.40000000000025, 141.6999999999988, 85.10000000000002, 31.200000000000166, 99.39999999999876, 2.700000000000002, 40.0000000000003, 72.39999999999979, 66.10000000000021, -74.4999999999998, 84.89999999999993, -44.100000000000314, 228.99999999999986, -1.8000000000000034, 57.70000000000035, 66.69999999999976, 77.69999999999982, -75.60000000000025, 7.099999999999939, 108.39999999999904, 155.19999999999845, 64.1000000000003, 82.99999999999922, -2.4999999999999254, 136.69999999999882, 100.2999999999997, 34.29999999999921], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-229.1000000000003, 113.59999999999971, 109.09999999999984, -15.399999999999762, -18.399999999999807, 20.000000000000014, 129.79999999999993, -42.69999999999983, 59.000000000000156, -215.80000000000015, 22.700000000000088, -31.90000000000012, 17.899999999999988, 98.00000000000003, -51.40000000000018, 20.000000000000014, -121.60000000000042, 23.600000000000065, -210.30000000000004, -64.00000000000071, 131.00000000000003, 100.99999999999937, -150.4000000000004, -0.9999999999999846, 80.29999999999977, -6.999999999999851, 41.59999999999998, 24.500000000000096, 40.70000000000008, -15.699999999999818, 31.40000000000017, -77.50000000000014, 17.600000000000176, 20.000000000000014, 40.70000000000007, 79.39999999999938, 20.90000000000003, -4.900000000000025, -12.400000000000247, 71.29999999999976, 104.29999999999986, -28.899999999999785, 20.000000000000014, 89.29999999999949, -49.299999999999805, 20.000000000000014, -101.8000000000008, 139.69999999999968, 20.90000000000003, 50.60000000000002, 39.80000000000022, -99.70000000000081, -10.899999999999835, -0.10000000000004367, 20.000000000000014, 41.60000000000024, 68.9, 40.70000000000019, 80.29999999999939, 20.000000000000014, 5.900000000000041, -125.50000000000071, -18.9999999999999, -53.1999999999999, 20.000000000000014, 66.79999999999987, 9.499999999999964, 20.000000000000014, -6.699999999999912, -17.799999999999756, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.80000000000008, 36.499999999999986, 28.700000000000173, 20.000000000000014, 91.10000000000001, 20.000000000000014, 57.800000000000146, -42.699999999999925, -29.49999999999988, -44.799999999999855, 20.000000000000014, 24.500000000000096, -26.199999999999797, 135.8, 88.69999999999936, 123.4999999999998, -36.69999999999976, 34.70000000000021, 61.40000000000014, 15.499999999999968, 20.000000000000014, 58.40000000000016, 40.7000000000002, 20.000000000000014, 2.0000000000000013, 23.600000000000083, 20.000000000000014, 20.000000000000014, 52.40000000000023, -0.4000000000000401, -44.19999999999977, -5.199999999999934, 32.000000000000156, 10.69999999999996, 3.5000000000000355, 20.000000000000014, 124.09999999999954, 20.000000000000014, -58.60000000000049, 104.5999999999994, 20.000000000000014, -10.899999999999892, 60.49999999999995, 69.49999999999973, 56.9000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000001, 37.10000000000023, 20.000000000000014, 62.000000000000085, 80.00000000000001, 20.000000000000014, 95.29999999999983, 20.000000000000014, 56.90000000000016, -15.399999999999933, 49.70000000000007, -23.799999999999955, 25.100000000000055, 26.300000000000118, 20.000000000000014, -7.899999999999945, 22.100000000000072, -62.20000000000039, -3.9999999999998295, 100.0999999999994, 16.999999999999975, 20.000000000000014, 92.89999999999947, 94.09999999999997, 20.600000000000023, -12.399999999999816, 30.800000000000203, 20.000000000000014, 121.69999999999952, -101.80000000000078, 128.89999999999992, 20.000000000000014, 3.1999999999999615, 79.39999999999938, 20.000000000000014, -15.699999999999761, -31.59999999999991, 20.000000000000014, 20.000000000000014, 82.99999999999926, -46.59999999999978, 38.90000000000009, 27.20000000000013, -112.3000000000006, -71.2, 32.89999999999999, 20.000000000000014, 9.49999999999997, -175.60000000000008, 122.59999999999982, 106.39999999999998, -66.40000000000052, -9.400000000000025, -5.199999999999941, 11.899999999999972, 85.39999999999978, -123.7000000000003, 31.39999999999999, -15.700000000000244, -214.60000000000016, 20.000000000000014, -36.69999999999984, 15.79999999999996, 20.000000000000014, 88.39999999999955, 98.29999999999936, 56.900000000000226, 17.899999999999988, 45.200000000000074, -18.99999999999984, 65.00000000000014, -68.20000000000078, 16.700000000000017, 69.49999999999979, 42.200000000000124, 20.000000000000014, 80.29999999999987, -36.69999999999994, 20.000000000000014], "policy_predator_policy_reward": [129.0, 0.0, 0.0, 24.0, 0.0, 32.0, 0.0, 46.0, 116.0, 18.0, 54.0, 51.0, 10.0, 1.0, 60.0, 51.0, 49.0, 27.0, 150.0, 75.0, 13.0, 1.0, 10.0, 85.0, 30.0, 0.0, 0.0, 0.0, 0.0, 32.0, 52.0, 4.0, 0.0, 20.0, 0.0, 0.0, 9.0, 14.0, 35.0, 34.0, 25.0, 22.0, 0.0, 0.0, 33.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 57.0, 18.0, 26.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 15.0, 87.0, 59.0, 12.0, 0.0, 0.0, 5.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 30.0, 55.0, 33.0, 7.0, 10.0, 12.0, 0.0, 10.0, 0.0, 27.0, 2.0, 9.0, 21.0, 0.0, 13.0, 0.0, 14.0, 9.0, 10.0, 2.0, 0.0, 0.0, 32.0, 0.0, 2.0, 12.0, 41.0, 0.0, 1.0, 0.0, 22.0, 18.0, 0.0, 0.0, 21.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 10.0, 0.0, 0.0, 0.0, 25.0, 43.0, 42.0, 24.0, 0.0, 0.0, 2.0, 33.0, 18.0, 56.0, 0.0, 4.0, 0.0, 0.0, 2.0, 7.0, 12.0, 6.0, 0.0, 0.0, 58.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 109.0, 0.0, 32.0, 0.0, 28.0, 94.0, 0.0, 0.0, 50.0, 24.0, 0.0, 51.0, 83.0, 22.0, 0.0, 62.0, 58.0, 61.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 37.0, 0.0, 49.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6010037954880363, "mean_inference_ms": 1.7972394315652342, "mean_action_processing_ms": 0.23732725075523128, "mean_env_wait_ms": 0.19460294756141405, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005509734153747559, "StateBufferConnector_ms": 0.003324747085571289, "ViewRequirementAgentConnector_ms": 0.10618281364440918}, "num_episodes": 18, "episode_return_max": 245.99999999999926, "episode_return_min": -75.60000000000025, "episode_return_mean": 66.50399999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 395.0714499783275, "num_env_steps_trained_throughput_per_sec": 395.0714499783275, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 10342.998, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10342.957, "sample_time_ms": 1403.876, "learn_time_ms": 8917.686, "learn_throughput": 448.547, "synch_weights_time_ms": 20.088}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "0b081_00000", "date": "2024-08-13_00-50-25", "timestamp": 1723524625, "time_this_iter_s": 10.129361867904663, "time_total_s": 206.98002576828003, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e410d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 206.98002576828003, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 31.533333333333328, "ram_util_percent": 83.45333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3410797696107279, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2603866813044067, "policy_loss": -0.007417495171761229, "vf_loss": 3.267697149357468, "vf_explained_var": 0.028498141254697528, "kl": 0.017124157589125135, "entropy": 1.5926399295292204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.27615248870755, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.636493691565499, "policy_loss": -0.006628390459747857, "vf_loss": 5.641954834246762, "vf_explained_var": 0.0033901192208446525, "kl": 0.013834202803372043, "entropy": 1.2295506496908803, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 253.29999999999944, "episode_reward_min": -75.60000000000025, "episode_reward_mean": 64.7889999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -214.60000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.5, "predator_policy": 111.0}, "policy_reward_mean": {"prey_policy": 15.63949999999995, "predator_policy": 16.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.000000000000114, 127.89999999999968, 122.39999999999948, 109.29999999999889, 3.7000000000001205, 95.8999999999993, 71.49999999999973, -2.8999999999998014, 33.0000000000002, 61.60000000000049, 138.59999999999968, 100.29999999999876, -17.599999999999916, -1.1999999999999846, 86.79999999999932, 34.50000000000022, -4.499999999999751, 40.0000000000003, 59.80000000000027, 74.20000000000033, 111.1, 77.79999999999986, 12.80000000000006, 15.199999999999998, 20.29999999999999, 234.4999999999992, 113.79999999999947, 107.09999999999883, 56.50000000000038, 112.09999999999872, 45.000000000000405, 55.600000000000456, 72.39999999999989, -12.599999999999616, 40.80000000000031, 55.20000000000025, 145.0999999999988, 1.400000000000165, 124.59999999999866, 102.59999999999962, 126.39999999999904, 40.0000000000003, 56.20000000000027, 57.10000000000046, 182.9999999999998, 125.29999999999927, 76.89999999999944, 102.29999999999951, 67.30000000000025, 46.3000000000004, 49.20000000000016, 7.800000000000345, 121.09999999999866, 112.89999999999873, 123.69999999999989, 36.40000000000025, 141.6999999999988, 85.10000000000002, 31.200000000000166, 99.39999999999876, 2.700000000000002, 40.0000000000003, 72.39999999999979, 66.10000000000021, -74.4999999999998, 84.89999999999993, -44.100000000000314, 228.99999999999986, -1.8000000000000034, 57.70000000000035, 66.69999999999976, 77.69999999999982, -75.60000000000025, 7.099999999999939, 108.39999999999904, 155.19999999999845, 64.1000000000003, 82.99999999999922, -2.4999999999999254, 136.69999999999882, 100.2999999999997, 34.29999999999921, -27.000000000000256, -10.199999999999966, 195.79999999999973, -65.00000000000017, 253.29999999999944, 40.0000000000003, 54.49999999999946, 56.50000000000007, 98.49999999999878, -46.899999999999615, 18.700000000000287, 40.0000000000003, 59.19999999999983, 39.900000000000304, 116.19999999999973, -25.999999999999638, 56.10000000000005, 84.6000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.90000000000003, -4.900000000000025, -12.400000000000247, 71.29999999999976, 104.29999999999986, -28.899999999999785, 20.000000000000014, 89.29999999999949, -49.299999999999805, 20.000000000000014, -101.8000000000008, 139.69999999999968, 20.90000000000003, 50.60000000000002, 39.80000000000022, -99.70000000000081, -10.899999999999835, -0.10000000000004367, 20.000000000000014, 41.60000000000024, 68.9, 40.70000000000019, 80.29999999999939, 20.000000000000014, 5.900000000000041, -125.50000000000071, -18.9999999999999, -53.1999999999999, 20.000000000000014, 66.79999999999987, 9.499999999999964, 20.000000000000014, -6.699999999999912, -17.799999999999756, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.80000000000008, 36.499999999999986, 28.700000000000173, 20.000000000000014, 91.10000000000001, 20.000000000000014, 57.800000000000146, -42.699999999999925, -29.49999999999988, -44.799999999999855, 20.000000000000014, 24.500000000000096, -26.199999999999797, 135.8, 88.69999999999936, 123.4999999999998, -36.69999999999976, 34.70000000000021, 61.40000000000014, 15.499999999999968, 20.000000000000014, 58.40000000000016, 40.7000000000002, 20.000000000000014, 2.0000000000000013, 23.600000000000083, 20.000000000000014, 20.000000000000014, 52.40000000000023, -0.4000000000000401, -44.19999999999977, -5.199999999999934, 32.000000000000156, 10.69999999999996, 3.5000000000000355, 20.000000000000014, 124.09999999999954, 20.000000000000014, -58.60000000000049, 104.5999999999994, 20.000000000000014, -10.899999999999892, 60.49999999999995, 69.49999999999973, 56.9000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000001, 37.10000000000023, 20.000000000000014, 62.000000000000085, 80.00000000000001, 20.000000000000014, 95.29999999999983, 20.000000000000014, 56.90000000000016, -15.399999999999933, 49.70000000000007, -23.799999999999955, 25.100000000000055, 26.300000000000118, 20.000000000000014, -7.899999999999945, 22.100000000000072, -62.20000000000039, -3.9999999999998295, 100.0999999999994, 16.999999999999975, 20.000000000000014, 92.89999999999947, 94.09999999999997, 20.600000000000023, -12.399999999999816, 30.800000000000203, 20.000000000000014, 121.69999999999952, -101.80000000000078, 128.89999999999992, 20.000000000000014, 3.1999999999999615, 79.39999999999938, 20.000000000000014, -15.699999999999761, -31.59999999999991, 20.000000000000014, 20.000000000000014, 82.99999999999926, -46.59999999999978, 38.90000000000009, 27.20000000000013, -112.3000000000006, -71.2, 32.89999999999999, 20.000000000000014, 9.49999999999997, -175.60000000000008, 122.59999999999982, 106.39999999999998, -66.40000000000052, -9.400000000000025, -5.199999999999941, 11.899999999999972, 85.39999999999978, -123.7000000000003, 31.39999999999999, -15.700000000000244, -214.60000000000016, 20.000000000000014, -36.69999999999984, 15.79999999999996, 20.000000000000014, 88.39999999999955, 98.29999999999936, 56.900000000000226, 17.899999999999988, 45.200000000000074, -18.99999999999984, 65.00000000000014, -68.20000000000078, 16.700000000000017, 69.49999999999979, 42.200000000000124, 20.000000000000014, 80.29999999999987, -36.69999999999994, 20.000000000000014, -143.80000000000047, -11.199999999999946, -97.60000000000073, -1.600000000000005, 96.19999999999999, 95.59999999999965, -89.49999999999996, -98.49999999999999, 84.79999999999984, 168.5, 20.000000000000014, 20.000000000000014, -10.599999999999916, -55.89999999999993, 3.800000000000109, 13.699999999999951, 67.69999999999995, -14.200000000000028, -35.799999999999756, -147.10000000000053, -49.29999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -108.10000000000056, 65.29999999999993, 22.70000000000006, -11.79999999999986, 102.19999999999999, -1.0000000000000333, -65.20000000000044, -35.7999999999998, 20.000000000000014, 4.100000000000076, 76.70000000000019, -3.100000000000001], "policy_predator_policy_reward": [9.0, 14.0, 35.0, 34.0, 25.0, 22.0, 0.0, 0.0, 33.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 57.0, 18.0, 26.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 15.0, 87.0, 59.0, 12.0, 0.0, 0.0, 5.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 30.0, 55.0, 33.0, 7.0, 10.0, 12.0, 0.0, 10.0, 0.0, 27.0, 2.0, 9.0, 21.0, 0.0, 13.0, 0.0, 14.0, 9.0, 10.0, 2.0, 0.0, 0.0, 32.0, 0.0, 2.0, 12.0, 41.0, 0.0, 1.0, 0.0, 22.0, 18.0, 0.0, 0.0, 21.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 10.0, 0.0, 0.0, 0.0, 25.0, 43.0, 42.0, 24.0, 0.0, 0.0, 2.0, 33.0, 18.0, 56.0, 0.0, 4.0, 0.0, 0.0, 2.0, 7.0, 12.0, 6.0, 0.0, 0.0, 58.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 109.0, 0.0, 32.0, 0.0, 28.0, 94.0, 0.0, 0.0, 50.0, 24.0, 0.0, 51.0, 83.0, 22.0, 0.0, 62.0, 58.0, 61.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 37.0, 0.0, 49.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 51.0, 20.0, 108.0, 33.0, 56.0, 4.0, 0.0, 111.0, 12.0, 0.0, 0.0, 0.0, 0.0, 67.0, 54.0, 39.0, 0.0, 0.0, 45.0, 62.0, 74.0, 23.0, 25.0, 0.0, 0.0, 67.0, 35.0, 6.0, 23.0, 0.0, 15.0, 0.0, 75.0, 1.0, 31.0, 1.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5996013961879811, "mean_inference_ms": 1.7942556929545335, "mean_action_processing_ms": 0.23717318459637338, "mean_env_wait_ms": 0.19412214296623728, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005445122718811035, "StateBufferConnector_ms": 0.0032194852828979492, "ViewRequirementAgentConnector_ms": 0.1039729118347168}, "num_episodes": 18, "episode_return_max": 253.29999999999944, "episode_return_min": -75.60000000000025, "episode_return_mean": 64.7889999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.0998849079694, "num_env_steps_trained_throughput_per_sec": 402.0998849079694, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 10309.437, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10309.396, "sample_time_ms": 1398.291, "learn_time_ms": 8889.5, "learn_throughput": 449.969, "synch_weights_time_ms": 20.296}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "0b081_00000", "date": "2024-08-13_00-50-35", "timestamp": 1723524635, "time_this_iter_s": 9.95314884185791, "time_total_s": 216.93317461013794, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327f9bee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 216.93317461013794, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 28.085714285714285, "ram_util_percent": 83.45714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3998969099706128, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3084423253145165, "policy_loss": -0.002479456023500355, "vf_loss": 3.310900179923527, "vf_explained_var": 0.01577225201344364, "kl": 0.0034560089615680687, "entropy": 1.5906594501601325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.319617714192817, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.951165590084419, "policy_loss": -0.004243831826551329, "vf_loss": 5.953867144054836, "vf_explained_var": 0.031415677102154524, "kl": 0.018278546980114153, "entropy": 1.1995610879211829, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 253.29999999999944, "episode_reward_min": -215.20000000000078, "episode_reward_mean": 59.90799999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -223.60000000000042, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.5, "predator_policy": 145.0}, "policy_reward_mean": {"prey_policy": 10.873999999999944, "predator_policy": 19.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.80000000000027, 74.20000000000033, 111.1, 77.79999999999986, 12.80000000000006, 15.199999999999998, 20.29999999999999, 234.4999999999992, 113.79999999999947, 107.09999999999883, 56.50000000000038, 112.09999999999872, 45.000000000000405, 55.600000000000456, 72.39999999999989, -12.599999999999616, 40.80000000000031, 55.20000000000025, 145.0999999999988, 1.400000000000165, 124.59999999999866, 102.59999999999962, 126.39999999999904, 40.0000000000003, 56.20000000000027, 57.10000000000046, 182.9999999999998, 125.29999999999927, 76.89999999999944, 102.29999999999951, 67.30000000000025, 46.3000000000004, 49.20000000000016, 7.800000000000345, 121.09999999999866, 112.89999999999873, 123.69999999999989, 36.40000000000025, 141.6999999999988, 85.10000000000002, 31.200000000000166, 99.39999999999876, 2.700000000000002, 40.0000000000003, 72.39999999999979, 66.10000000000021, -74.4999999999998, 84.89999999999993, -44.100000000000314, 228.99999999999986, -1.8000000000000034, 57.70000000000035, 66.69999999999976, 77.69999999999982, -75.60000000000025, 7.099999999999939, 108.39999999999904, 155.19999999999845, 64.1000000000003, 82.99999999999922, -2.4999999999999254, 136.69999999999882, 100.2999999999997, 34.29999999999921, -27.000000000000256, -10.199999999999966, 195.79999999999973, -65.00000000000017, 253.29999999999944, 40.0000000000003, 54.49999999999946, 56.50000000000007, 98.49999999999878, -46.899999999999615, 18.700000000000287, 40.0000000000003, 59.19999999999983, 39.900000000000304, 116.19999999999973, -25.999999999999638, 56.10000000000005, 84.6000000000003, -210.40000000000109, 5.599999999999964, 93.09999999999947, 82.69999999999916, 94.5999999999992, 51.700000000000315, 16.899999999999963, -43.09999999999994, 22.40000000000019, -58.19999999999994, -215.20000000000078, 138.79999999999933, 65.90000000000036, 83.29999999999998, 39.90000000000009, 191.2999999999995, 32.99999999999963, 157.89999999999887], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 39.80000000000008, 36.499999999999986, 28.700000000000173, 20.000000000000014, 91.10000000000001, 20.000000000000014, 57.800000000000146, -42.699999999999925, -29.49999999999988, -44.799999999999855, 20.000000000000014, 24.500000000000096, -26.199999999999797, 135.8, 88.69999999999936, 123.4999999999998, -36.69999999999976, 34.70000000000021, 61.40000000000014, 15.499999999999968, 20.000000000000014, 58.40000000000016, 40.7000000000002, 20.000000000000014, 2.0000000000000013, 23.600000000000083, 20.000000000000014, 20.000000000000014, 52.40000000000023, -0.4000000000000401, -44.19999999999977, -5.199999999999934, 32.000000000000156, 10.69999999999996, 3.5000000000000355, 20.000000000000014, 124.09999999999954, 20.000000000000014, -58.60000000000049, 104.5999999999994, 20.000000000000014, -10.899999999999892, 60.49999999999995, 69.49999999999973, 56.9000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000001, 37.10000000000023, 20.000000000000014, 62.000000000000085, 80.00000000000001, 20.000000000000014, 95.29999999999983, 20.000000000000014, 56.90000000000016, -15.399999999999933, 49.70000000000007, -23.799999999999955, 25.100000000000055, 26.300000000000118, 20.000000000000014, -7.899999999999945, 22.100000000000072, -62.20000000000039, -3.9999999999998295, 100.0999999999994, 16.999999999999975, 20.000000000000014, 92.89999999999947, 94.09999999999997, 20.600000000000023, -12.399999999999816, 30.800000000000203, 20.000000000000014, 121.69999999999952, -101.80000000000078, 128.89999999999992, 20.000000000000014, 3.1999999999999615, 79.39999999999938, 20.000000000000014, -15.699999999999761, -31.59999999999991, 20.000000000000014, 20.000000000000014, 82.99999999999926, -46.59999999999978, 38.90000000000009, 27.20000000000013, -112.3000000000006, -71.2, 32.89999999999999, 20.000000000000014, 9.49999999999997, -175.60000000000008, 122.59999999999982, 106.39999999999998, -66.40000000000052, -9.400000000000025, -5.199999999999941, 11.899999999999972, 85.39999999999978, -123.7000000000003, 31.39999999999999, -15.700000000000244, -214.60000000000016, 20.000000000000014, -36.69999999999984, 15.79999999999996, 20.000000000000014, 88.39999999999955, 98.29999999999936, 56.900000000000226, 17.899999999999988, 45.200000000000074, -18.99999999999984, 65.00000000000014, -68.20000000000078, 16.700000000000017, 69.49999999999979, 42.200000000000124, 20.000000000000014, 80.29999999999987, -36.69999999999994, 20.000000000000014, -143.80000000000047, -11.199999999999946, -97.60000000000073, -1.600000000000005, 96.19999999999999, 95.59999999999965, -89.49999999999996, -98.49999999999999, 84.79999999999984, 168.5, 20.000000000000014, 20.000000000000014, -10.599999999999916, -55.89999999999993, 3.800000000000109, 13.699999999999951, 67.69999999999995, -14.200000000000028, -35.799999999999756, -147.10000000000053, -49.29999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -108.10000000000056, 65.29999999999993, 22.70000000000006, -11.79999999999986, 102.19999999999999, -1.0000000000000333, -65.20000000000044, -35.7999999999998, 20.000000000000014, 4.100000000000076, 76.70000000000019, -3.100000000000001, -150.10000000000065, -196.30000000000044, 20.000000000000014, -69.40000000000028, 73.09999999999975, 20.000000000000014, 20.000000000000014, 55.7000000000001, -7.3000000000000504, 77.89999999999966, 31.70000000000003, 20.000000000000014, -66.10000000000082, 16.999999999999975, -117.39999999999998, -21.69999999999976, -1.2999999999999714, -64.30000000000008, -44.19999999999978, -151.0, -136.60000000000034, -223.60000000000042, -22.000000000000014, 132.79999999999987, 44.00000000000024, 20.90000000000003, 20.000000000000014, 41.300000000000125, 7.399999999999979, -23.500000000000014, 115.39999999999947, -15.100000000000044, 11.599999999999946, -49.59999999999995, 20.000000000000014, 137.8999999999996], "policy_predator_policy_reward": [0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 30.0, 55.0, 33.0, 7.0, 10.0, 12.0, 0.0, 10.0, 0.0, 27.0, 2.0, 9.0, 21.0, 0.0, 13.0, 0.0, 14.0, 9.0, 10.0, 2.0, 0.0, 0.0, 32.0, 0.0, 2.0, 12.0, 41.0, 0.0, 1.0, 0.0, 22.0, 18.0, 0.0, 0.0, 21.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.0, 10.0, 0.0, 0.0, 0.0, 25.0, 43.0, 42.0, 24.0, 0.0, 0.0, 2.0, 33.0, 18.0, 56.0, 0.0, 4.0, 0.0, 0.0, 2.0, 7.0, 12.0, 6.0, 0.0, 0.0, 58.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 109.0, 0.0, 32.0, 0.0, 28.0, 94.0, 0.0, 0.0, 50.0, 24.0, 0.0, 51.0, 83.0, 22.0, 0.0, 62.0, 58.0, 61.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 37.0, 0.0, 49.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 51.0, 20.0, 108.0, 33.0, 56.0, 4.0, 0.0, 111.0, 12.0, 0.0, 0.0, 0.0, 0.0, 67.0, 54.0, 39.0, 0.0, 0.0, 45.0, 62.0, 74.0, 23.0, 25.0, 0.0, 0.0, 67.0, 35.0, 6.0, 23.0, 0.0, 15.0, 0.0, 75.0, 1.0, 31.0, 1.0, 10.0, 0.0, 136.0, 0.0, 55.0, 0.0, 0.0, 0.0, 7.0, 23.0, 1.0, 0.0, 0.0, 54.0, 12.0, 82.0, 14.0, 16.0, 72.0, 11.0, 126.0, 0.0, 145.0, 20.0, 8.0, 0.0, 1.0, 0.0, 22.0, 32.0, 24.0, 50.0, 41.0, 55.0, 16.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5978959011777032, "mean_inference_ms": 1.790457143532456, "mean_action_processing_ms": 0.23684278088777608, "mean_env_wait_ms": 0.1934845134183892, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052640438079833984, "StateBufferConnector_ms": 0.0031998157501220703, "ViewRequirementAgentConnector_ms": 0.10335350036621094}, "num_episodes": 18, "episode_return_max": 253.29999999999944, "episode_return_min": -215.20000000000078, "episode_return_mean": 59.90799999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 379.93964434012713, "num_env_steps_trained_throughput_per_sec": 379.93964434012713, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 10371.832, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10371.791, "sample_time_ms": 1389.437, "learn_time_ms": 8960.379, "learn_throughput": 446.41, "synch_weights_time_ms": 20.354}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "0b081_00000", "date": "2024-08-13_00-50-46", "timestamp": 1723524646, "time_this_iter_s": 10.57297396659851, "time_total_s": 227.50614857673645, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fb9820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 227.50614857673645, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 30.659999999999993, "ram_util_percent": 83.41333333333336}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25382850603372964, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.77106358538229, "policy_loss": -0.0038870357204888943, "vf_loss": 3.774915550499366, "vf_explained_var": 0.0010568905444372269, "kl": 0.011221630736707254, "entropy": 1.570130503556085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4754169088507456, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.9663626496754, "policy_loss": -0.004504042333262978, "vf_loss": 5.969572492377468, "vf_explained_var": 0.0013672496906664007, "kl": 0.015338696117808248, "entropy": 1.224194241705395, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 296.800000000001, "episode_reward_min": -302.70000000000016, "episode_reward_mean": 42.57399999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -271.19999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.5, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -4.093000000000077, "predator_policy": 25.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [125.29999999999927, 76.89999999999944, 102.29999999999951, 67.30000000000025, 46.3000000000004, 49.20000000000016, 7.800000000000345, 121.09999999999866, 112.89999999999873, 123.69999999999989, 36.40000000000025, 141.6999999999988, 85.10000000000002, 31.200000000000166, 99.39999999999876, 2.700000000000002, 40.0000000000003, 72.39999999999979, 66.10000000000021, -74.4999999999998, 84.89999999999993, -44.100000000000314, 228.99999999999986, -1.8000000000000034, 57.70000000000035, 66.69999999999976, 77.69999999999982, -75.60000000000025, 7.099999999999939, 108.39999999999904, 155.19999999999845, 64.1000000000003, 82.99999999999922, -2.4999999999999254, 136.69999999999882, 100.2999999999997, 34.29999999999921, -27.000000000000256, -10.199999999999966, 195.79999999999973, -65.00000000000017, 253.29999999999944, 40.0000000000003, 54.49999999999946, 56.50000000000007, 98.49999999999878, -46.899999999999615, 18.700000000000287, 40.0000000000003, 59.19999999999983, 39.900000000000304, 116.19999999999973, -25.999999999999638, 56.10000000000005, 84.6000000000003, -210.40000000000109, 5.599999999999964, 93.09999999999947, 82.69999999999916, 94.5999999999992, 51.700000000000315, 16.899999999999963, -43.09999999999994, 22.40000000000019, -58.19999999999994, -215.20000000000078, 138.79999999999933, 65.90000000000036, 83.29999999999998, 39.90000000000009, 191.2999999999995, 32.99999999999963, 157.89999999999887, 162.8999999999993, 30.700000000000152, -1.8999999999998574, 63.40000000000014, -0.6000000000000179, 69.70000000000022, 71.5000000000002, -50.99999999999962, -302.70000000000016, 83.69999999999854, 77.59999999999977, 52.20000000000027, 296.800000000001, 59.000000000000306, -107.60000000000025, -0.5000000000004139, -135.50000000000014, -84.40000000000012, 141.29999999999936, -0.9999999999997531, 26.50000000000016, -21.699999999999967, -80.90000000000055, -14.89999999999996, 55.30000000000042, -24.99999999999975, -8.299999999999702], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 95.29999999999983, 20.000000000000014, 56.90000000000016, -15.399999999999933, 49.70000000000007, -23.799999999999955, 25.100000000000055, 26.300000000000118, 20.000000000000014, -7.899999999999945, 22.100000000000072, -62.20000000000039, -3.9999999999998295, 100.0999999999994, 16.999999999999975, 20.000000000000014, 92.89999999999947, 94.09999999999997, 20.600000000000023, -12.399999999999816, 30.800000000000203, 20.000000000000014, 121.69999999999952, -101.80000000000078, 128.89999999999992, 20.000000000000014, 3.1999999999999615, 79.39999999999938, 20.000000000000014, -15.699999999999761, -31.59999999999991, 20.000000000000014, 20.000000000000014, 82.99999999999926, -46.59999999999978, 38.90000000000009, 27.20000000000013, -112.3000000000006, -71.2, 32.89999999999999, 20.000000000000014, 9.49999999999997, -175.60000000000008, 122.59999999999982, 106.39999999999998, -66.40000000000052, -9.400000000000025, -5.199999999999941, 11.899999999999972, 85.39999999999978, -123.7000000000003, 31.39999999999999, -15.700000000000244, -214.60000000000016, 20.000000000000014, -36.69999999999984, 15.79999999999996, 20.000000000000014, 88.39999999999955, 98.29999999999936, 56.900000000000226, 17.899999999999988, 45.200000000000074, -18.99999999999984, 65.00000000000014, -68.20000000000078, 16.700000000000017, 69.49999999999979, 42.200000000000124, 20.000000000000014, 80.29999999999987, -36.69999999999994, 20.000000000000014, -143.80000000000047, -11.199999999999946, -97.60000000000073, -1.600000000000005, 96.19999999999999, 95.59999999999965, -89.49999999999996, -98.49999999999999, 84.79999999999984, 168.5, 20.000000000000014, 20.000000000000014, -10.599999999999916, -55.89999999999993, 3.800000000000109, 13.699999999999951, 67.69999999999995, -14.200000000000028, -35.799999999999756, -147.10000000000053, -49.29999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -108.10000000000056, 65.29999999999993, 22.70000000000006, -11.79999999999986, 102.19999999999999, -1.0000000000000333, -65.20000000000044, -35.7999999999998, 20.000000000000014, 4.100000000000076, 76.70000000000019, -3.100000000000001, -150.10000000000065, -196.30000000000044, 20.000000000000014, -69.40000000000028, 73.09999999999975, 20.000000000000014, 20.000000000000014, 55.7000000000001, -7.3000000000000504, 77.89999999999966, 31.70000000000003, 20.000000000000014, -66.10000000000082, 16.999999999999975, -117.39999999999998, -21.69999999999976, -1.2999999999999714, -64.30000000000008, -44.19999999999978, -151.0, -136.60000000000034, -223.60000000000042, -22.000000000000014, 132.79999999999987, 44.00000000000024, 20.90000000000003, 20.000000000000014, 41.300000000000125, 7.399999999999979, -23.500000000000014, 115.39999999999947, -15.100000000000044, 11.599999999999946, -49.59999999999995, 20.000000000000014, 137.8999999999996, 14.899999999999968, 139.9999999999999, -16.599999999999916, -21.69999999999985, -69.70000000000067, 15.79999999999996, 29.299999999999727, -64.9, -9.400000000000006, -26.199999999999957, 49.70000000000023, 20.000000000000014, 20.000000000000014, 51.499999999999964, -30.699999999999996, -91.30000000000051, -271.19999999999993, -266.5000000000001, 20.000000000000014, 52.69999999999952, 22.70000000000003, 53.900000000000134, 20.000000000000014, -26.800000000000068, 160.39999999999975, 124.39999999999998, 20.000000000000014, -10.000000000000103, -37.89999999999977, -262.70000000000005, -49.29999999999998, -68.20000000000005, -130.00000000000034, -146.5000000000002, -220.3, 17.899999999999984, 20.000000000000014, 110.2999999999999, -110.5, 45.50000000000009, 20.000000000000014, -20.49999999999978, -84.99999999999999, 8.299999999999983, -223.90000000000023, 20.000000000000014, -64.00000000000006, -40.899999999999935, 20.000000000000014, 35.30000000000021, 2.600000000000027, -91.60000000000045, 20.000000000000014, -79.30000000000078], "policy_predator_policy_reward": [10.0, 0.0, 0.0, 0.0, 25.0, 43.0, 42.0, 24.0, 0.0, 0.0, 2.0, 33.0, 18.0, 56.0, 0.0, 4.0, 0.0, 0.0, 2.0, 7.0, 12.0, 6.0, 0.0, 0.0, 58.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 109.0, 0.0, 32.0, 0.0, 28.0, 94.0, 0.0, 0.0, 50.0, 24.0, 0.0, 51.0, 83.0, 22.0, 0.0, 62.0, 58.0, 61.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 37.0, 0.0, 49.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 51.0, 20.0, 108.0, 33.0, 56.0, 4.0, 0.0, 111.0, 12.0, 0.0, 0.0, 0.0, 0.0, 67.0, 54.0, 39.0, 0.0, 0.0, 45.0, 62.0, 74.0, 23.0, 25.0, 0.0, 0.0, 67.0, 35.0, 6.0, 23.0, 0.0, 15.0, 0.0, 75.0, 1.0, 31.0, 1.0, 10.0, 0.0, 136.0, 0.0, 55.0, 0.0, 0.0, 0.0, 7.0, 23.0, 1.0, 0.0, 0.0, 54.0, 12.0, 82.0, 14.0, 16.0, 72.0, 11.0, 126.0, 0.0, 145.0, 20.0, 8.0, 0.0, 1.0, 0.0, 22.0, 32.0, 24.0, 50.0, 41.0, 55.0, 16.0, 0.0, 0.0, 8.0, 0.0, 25.0, 44.0, 43.0, 9.0, 61.0, 38.0, 35.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 0.0, 235.0, 11.0, 0.0, 1.0, 0.0, 57.0, 2.0, 12.0, 0.0, 0.0, 49.0, 56.0, 137.0, 75.0, 42.0, 141.0, 0.0, 118.0, 0.0, 0.0, 11.0, 0.0, 64.0, 0.0, 27.0, 0.0, 55.0, 0.0, 123.0, 0.0, 90.0, 0.0, 0.0, 10.0, 54.0, 35.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5968435459855065, "mean_inference_ms": 1.784530722827517, "mean_action_processing_ms": 0.2364967176534749, "mean_env_wait_ms": 0.1927844725082127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005676865577697754, "StateBufferConnector_ms": 0.003209233283996582, "ViewRequirementAgentConnector_ms": 0.10782980918884277}, "num_episodes": 27, "episode_return_max": 296.800000000001, "episode_return_min": -302.70000000000016, "episode_return_mean": 42.57399999999982, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.8019890332164, "num_env_steps_trained_throughput_per_sec": 380.8019890332164, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 10351.934, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10351.892, "sample_time_ms": 1391.857, "learn_time_ms": 8937.958, "learn_throughput": 447.53, "synch_weights_time_ms": 20.295}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "0b081_00000", "date": "2024-08-13_00-50-57", "timestamp": 1723524657, "time_this_iter_s": 10.567539930343628, "time_total_s": 238.07368850708008, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fa7a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 238.07368850708008, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 30.573333333333334, "ram_util_percent": 83.57333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2707533841312089, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7502513743582226, "policy_loss": -0.003335619099911243, "vf_loss": 2.7535455477300776, "vf_explained_var": 0.0014167149546285155, "kl": 0.013264014451466624, "entropy": 1.5356162724040803, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5912834875719257, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.694530429032745, "policy_loss": -0.004408078658931627, "vf_loss": 5.697305177759241, "vf_explained_var": 0.04691210307141461, "kl": 0.01935811105896252, "entropy": 1.2145699764054918, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 296.800000000001, "episode_reward_min": -302.70000000000016, "episode_reward_mean": 41.84499999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -271.19999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.5, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -7.552500000000082, "predator_policy": 28.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.10000000000021, -74.4999999999998, 84.89999999999993, -44.100000000000314, 228.99999999999986, -1.8000000000000034, 57.70000000000035, 66.69999999999976, 77.69999999999982, -75.60000000000025, 7.099999999999939, 108.39999999999904, 155.19999999999845, 64.1000000000003, 82.99999999999922, -2.4999999999999254, 136.69999999999882, 100.2999999999997, 34.29999999999921, -27.000000000000256, -10.199999999999966, 195.79999999999973, -65.00000000000017, 253.29999999999944, 40.0000000000003, 54.49999999999946, 56.50000000000007, 98.49999999999878, -46.899999999999615, 18.700000000000287, 40.0000000000003, 59.19999999999983, 39.900000000000304, 116.19999999999973, -25.999999999999638, 56.10000000000005, 84.6000000000003, -210.40000000000109, 5.599999999999964, 93.09999999999947, 82.69999999999916, 94.5999999999992, 51.700000000000315, 16.899999999999963, -43.09999999999994, 22.40000000000019, -58.19999999999994, -215.20000000000078, 138.79999999999933, 65.90000000000036, 83.29999999999998, 39.90000000000009, 191.2999999999995, 32.99999999999963, 157.89999999999887, 162.8999999999993, 30.700000000000152, -1.8999999999998574, 63.40000000000014, -0.6000000000000179, 69.70000000000022, 71.5000000000002, -50.99999999999962, -302.70000000000016, 83.69999999999854, 77.59999999999977, 52.20000000000027, 296.800000000001, 59.000000000000306, -107.60000000000025, -0.5000000000004139, -135.50000000000014, -84.40000000000012, 141.29999999999936, -0.9999999999997531, 26.50000000000016, -21.699999999999967, -80.90000000000055, -14.89999999999996, 55.30000000000042, -24.99999999999975, -8.299999999999702, 81.70000000000002, 3.7000000000001525, -70.00000000000114, 111.10000000000002, -3.3999999999997628, 119.79999999999933, 18.79999999999966, 193.8999999999988, 22.400000000000013, 184.09999999999945, 163.69999999999902, -60.30000000000012, 42.60000000000032, -7.800000000000068, 162.5999999999996, 44.50000000000024, 85.0000000000001, 176.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [38.90000000000009, 27.20000000000013, -112.3000000000006, -71.2, 32.89999999999999, 20.000000000000014, 9.49999999999997, -175.60000000000008, 122.59999999999982, 106.39999999999998, -66.40000000000052, -9.400000000000025, -5.199999999999941, 11.899999999999972, 85.39999999999978, -123.7000000000003, 31.39999999999999, -15.700000000000244, -214.60000000000016, 20.000000000000014, -36.69999999999984, 15.79999999999996, 20.000000000000014, 88.39999999999955, 98.29999999999936, 56.900000000000226, 17.899999999999988, 45.200000000000074, -18.99999999999984, 65.00000000000014, -68.20000000000078, 16.700000000000017, 69.49999999999979, 42.200000000000124, 20.000000000000014, 80.29999999999987, -36.69999999999994, 20.000000000000014, -143.80000000000047, -11.199999999999946, -97.60000000000073, -1.600000000000005, 96.19999999999999, 95.59999999999965, -89.49999999999996, -98.49999999999999, 84.79999999999984, 168.5, 20.000000000000014, 20.000000000000014, -10.599999999999916, -55.89999999999993, 3.800000000000109, 13.699999999999951, 67.69999999999995, -14.200000000000028, -35.799999999999756, -147.10000000000053, -49.29999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -108.10000000000056, 65.29999999999993, 22.70000000000006, -11.79999999999986, 102.19999999999999, -1.0000000000000333, -65.20000000000044, -35.7999999999998, 20.000000000000014, 4.100000000000076, 76.70000000000019, -3.100000000000001, -150.10000000000065, -196.30000000000044, 20.000000000000014, -69.40000000000028, 73.09999999999975, 20.000000000000014, 20.000000000000014, 55.7000000000001, -7.3000000000000504, 77.89999999999966, 31.70000000000003, 20.000000000000014, -66.10000000000082, 16.999999999999975, -117.39999999999998, -21.69999999999976, -1.2999999999999714, -64.30000000000008, -44.19999999999978, -151.0, -136.60000000000034, -223.60000000000042, -22.000000000000014, 132.79999999999987, 44.00000000000024, 20.90000000000003, 20.000000000000014, 41.300000000000125, 7.399999999999979, -23.500000000000014, 115.39999999999947, -15.100000000000044, 11.599999999999946, -49.59999999999995, 20.000000000000014, 137.8999999999996, 14.899999999999968, 139.9999999999999, -16.599999999999916, -21.69999999999985, -69.70000000000067, 15.79999999999996, 29.299999999999727, -64.9, -9.400000000000006, -26.199999999999957, 49.70000000000023, 20.000000000000014, 20.000000000000014, 51.499999999999964, -30.699999999999996, -91.30000000000051, -271.19999999999993, -266.5000000000001, 20.000000000000014, 52.69999999999952, 22.70000000000003, 53.900000000000134, 20.000000000000014, -26.800000000000068, 160.39999999999975, 124.39999999999998, 20.000000000000014, -10.000000000000103, -37.89999999999977, -262.70000000000005, -49.29999999999998, -68.20000000000005, -130.00000000000034, -146.5000000000002, -220.3, 17.899999999999984, 20.000000000000014, 110.2999999999999, -110.5, 45.50000000000009, 20.000000000000014, -20.49999999999978, -84.99999999999999, 8.299999999999983, -223.90000000000023, 20.000000000000014, -64.00000000000006, -40.899999999999935, 20.000000000000014, 35.30000000000021, 2.600000000000027, -91.60000000000045, 20.000000000000014, -79.30000000000078, -47.49999999999984, 81.19999999999995, -49.29999999999986, 20.000000000000014, -109.60000000000048, -111.40000000000072, 91.10000000000011, 20.000000000000014, -69.40000000000083, 20.000000000000014, 20.000000000000014, 66.79999999999987, -21.400000000000034, -62.799999999999955, 102.79999999999951, 91.09999999999931, -13.599999999999783, 20.000000000000014, 28.700000000000042, 124.39999999999978, 66.20000000000019, 75.49999999999964, -223.60000000000036, 5.300000000000009, -28.899999999999842, 9.499999999999964, -164.90000000000006, -49.899999999999835, 116.6, 20.000000000000014, 15.499999999999957, 20.000000000000014, -37.60000000000005, 50.600000000000065, 2.299999999999507, 136.09999999999982], "policy_predator_policy_reward": [0.0, 0.0, 109.0, 0.0, 32.0, 0.0, 28.0, 94.0, 0.0, 0.0, 50.0, 24.0, 0.0, 51.0, 83.0, 22.0, 0.0, 62.0, 58.0, 61.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 37.0, 0.0, 49.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 51.0, 20.0, 108.0, 33.0, 56.0, 4.0, 0.0, 111.0, 12.0, 0.0, 0.0, 0.0, 0.0, 67.0, 54.0, 39.0, 0.0, 0.0, 45.0, 62.0, 74.0, 23.0, 25.0, 0.0, 0.0, 67.0, 35.0, 6.0, 23.0, 0.0, 15.0, 0.0, 75.0, 1.0, 31.0, 1.0, 10.0, 0.0, 136.0, 0.0, 55.0, 0.0, 0.0, 0.0, 7.0, 23.0, 1.0, 0.0, 0.0, 54.0, 12.0, 82.0, 14.0, 16.0, 72.0, 11.0, 126.0, 0.0, 145.0, 20.0, 8.0, 0.0, 1.0, 0.0, 22.0, 32.0, 24.0, 50.0, 41.0, 55.0, 16.0, 0.0, 0.0, 8.0, 0.0, 25.0, 44.0, 43.0, 9.0, 61.0, 38.0, 35.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 0.0, 235.0, 11.0, 0.0, 1.0, 0.0, 57.0, 2.0, 12.0, 0.0, 0.0, 49.0, 56.0, 137.0, 75.0, 42.0, 141.0, 0.0, 118.0, 0.0, 0.0, 11.0, 0.0, 64.0, 0.0, 27.0, 0.0, 55.0, 0.0, 123.0, 0.0, 90.0, 0.0, 0.0, 10.0, 54.0, 35.0, 16.0, 48.0, 0.0, 33.0, 0.0, 63.0, 88.0, 0.0, 0.0, 11.0, 35.0, 15.0, 18.0, 76.0, 27.0, 0.0, 0.0, 16.0, 0.0, 0.0, 31.0, 0.0, 22.0, 38.0, 120.0, 43.0, 19.0, 132.0, 75.0, 6.0, 20.0, 0.0, 9.0, 3.0, 69.0, 0.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.595386254686507, "mean_inference_ms": 1.78749728835035, "mean_action_processing_ms": 0.2363813033551604, "mean_env_wait_ms": 0.19263624866895745, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006137371063232422, "StateBufferConnector_ms": 0.0032362937927246094, "ViewRequirementAgentConnector_ms": 0.1066436767578125}, "num_episodes": 18, "episode_return_max": 296.800000000001, "episode_return_min": -302.70000000000016, "episode_return_mean": 41.84499999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.8045857491796, "num_env_steps_trained_throughput_per_sec": 398.8045857491796, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 10327.353, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10327.311, "sample_time_ms": 1395.858, "learn_time_ms": 8909.469, "learn_throughput": 448.961, "synch_weights_time_ms": 20.201}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "0b081_00000", "date": "2024-08-13_00-51-07", "timestamp": 1723524667, "time_this_iter_s": 10.034127950668335, "time_total_s": 248.1078164577484, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fa71f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 248.1078164577484, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 29.871428571428574, "ram_util_percent": 83.52142857142859}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2537377743651627, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4391482840454768, "policy_loss": -0.005345818988126382, "vf_loss": 1.4444638203376186, "vf_explained_var": 0.0037148834851683764, "kl": 0.009692643259500136, "entropy": 1.5314472744073817, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6792404579974356, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.823441431005165, "policy_loss": -0.00525961491949462, "vf_loss": 3.8274887154342006, "vf_explained_var": 0.09596631574252296, "kl": 0.01436846219116761, "entropy": 1.2178626093284164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 296.800000000001, "episode_reward_min": -302.70000000000016, "episode_reward_mean": 44.672999999999796, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -271.19999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.5, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -5.293500000000079, "predator_policy": 27.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.29999999999921, -27.000000000000256, -10.199999999999966, 195.79999999999973, -65.00000000000017, 253.29999999999944, 40.0000000000003, 54.49999999999946, 56.50000000000007, 98.49999999999878, -46.899999999999615, 18.700000000000287, 40.0000000000003, 59.19999999999983, 39.900000000000304, 116.19999999999973, -25.999999999999638, 56.10000000000005, 84.6000000000003, -210.40000000000109, 5.599999999999964, 93.09999999999947, 82.69999999999916, 94.5999999999992, 51.700000000000315, 16.899999999999963, -43.09999999999994, 22.40000000000019, -58.19999999999994, -215.20000000000078, 138.79999999999933, 65.90000000000036, 83.29999999999998, 39.90000000000009, 191.2999999999995, 32.99999999999963, 157.89999999999887, 162.8999999999993, 30.700000000000152, -1.8999999999998574, 63.40000000000014, -0.6000000000000179, 69.70000000000022, 71.5000000000002, -50.99999999999962, -302.70000000000016, 83.69999999999854, 77.59999999999977, 52.20000000000027, 296.800000000001, 59.000000000000306, -107.60000000000025, -0.5000000000004139, -135.50000000000014, -84.40000000000012, 141.29999999999936, -0.9999999999997531, 26.50000000000016, -21.699999999999967, -80.90000000000055, -14.89999999999996, 55.30000000000042, -24.99999999999975, -8.299999999999702, 81.70000000000002, 3.7000000000001525, -70.00000000000114, 111.10000000000002, -3.3999999999997628, 119.79999999999933, 18.79999999999966, 193.8999999999988, 22.400000000000013, 184.09999999999945, 163.69999999999902, -60.30000000000012, 42.60000000000032, -7.800000000000068, 162.5999999999996, 44.50000000000024, 85.0000000000001, 176.4, 40.0000000000003, 67.09999999999997, 58.99999999999979, 36.700000000000244, 238.99999999999932, 43.60000000000029, 93.89999999999881, 161.79999999999887, 40.30000000000003, 120.99999999999898, 45.40000000000029, 153.49999999999883, 19.000000000000078, 96.59999999999897, 12.600000000000247, -76.3000000000016, 98.29999999999953, 69.70000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-36.69999999999994, 20.000000000000014, -143.80000000000047, -11.199999999999946, -97.60000000000073, -1.600000000000005, 96.19999999999999, 95.59999999999965, -89.49999999999996, -98.49999999999999, 84.79999999999984, 168.5, 20.000000000000014, 20.000000000000014, -10.599999999999916, -55.89999999999993, 3.800000000000109, 13.699999999999951, 67.69999999999995, -14.200000000000028, -35.799999999999756, -147.10000000000053, -49.29999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -108.10000000000056, 65.29999999999993, 22.70000000000006, -11.79999999999986, 102.19999999999999, -1.0000000000000333, -65.20000000000044, -35.7999999999998, 20.000000000000014, 4.100000000000076, 76.70000000000019, -3.100000000000001, -150.10000000000065, -196.30000000000044, 20.000000000000014, -69.40000000000028, 73.09999999999975, 20.000000000000014, 20.000000000000014, 55.7000000000001, -7.3000000000000504, 77.89999999999966, 31.70000000000003, 20.000000000000014, -66.10000000000082, 16.999999999999975, -117.39999999999998, -21.69999999999976, -1.2999999999999714, -64.30000000000008, -44.19999999999978, -151.0, -136.60000000000034, -223.60000000000042, -22.000000000000014, 132.79999999999987, 44.00000000000024, 20.90000000000003, 20.000000000000014, 41.300000000000125, 7.399999999999979, -23.500000000000014, 115.39999999999947, -15.100000000000044, 11.599999999999946, -49.59999999999995, 20.000000000000014, 137.8999999999996, 14.899999999999968, 139.9999999999999, -16.599999999999916, -21.69999999999985, -69.70000000000067, 15.79999999999996, 29.299999999999727, -64.9, -9.400000000000006, -26.199999999999957, 49.70000000000023, 20.000000000000014, 20.000000000000014, 51.499999999999964, -30.699999999999996, -91.30000000000051, -271.19999999999993, -266.5000000000001, 20.000000000000014, 52.69999999999952, 22.70000000000003, 53.900000000000134, 20.000000000000014, -26.800000000000068, 160.39999999999975, 124.39999999999998, 20.000000000000014, -10.000000000000103, -37.89999999999977, -262.70000000000005, -49.29999999999998, -68.20000000000005, -130.00000000000034, -146.5000000000002, -220.3, 17.899999999999984, 20.000000000000014, 110.2999999999999, -110.5, 45.50000000000009, 20.000000000000014, -20.49999999999978, -84.99999999999999, 8.299999999999983, -223.90000000000023, 20.000000000000014, -64.00000000000006, -40.899999999999935, 20.000000000000014, 35.30000000000021, 2.600000000000027, -91.60000000000045, 20.000000000000014, -79.30000000000078, -47.49999999999984, 81.19999999999995, -49.29999999999986, 20.000000000000014, -109.60000000000048, -111.40000000000072, 91.10000000000011, 20.000000000000014, -69.40000000000083, 20.000000000000014, 20.000000000000014, 66.79999999999987, -21.400000000000034, -62.799999999999955, 102.79999999999951, 91.09999999999931, -13.599999999999783, 20.000000000000014, 28.700000000000042, 124.39999999999978, 66.20000000000019, 75.49999999999964, -223.60000000000036, 5.300000000000009, -28.899999999999842, 9.499999999999964, -164.90000000000006, -49.899999999999835, 116.6, 20.000000000000014, 15.499999999999957, 20.000000000000014, -37.60000000000005, 50.600000000000065, 2.299999999999507, 136.09999999999982, 20.000000000000014, 20.000000000000014, 38.90000000000015, -11.799999999999866, -14.800000000000246, -80.19999999999999, 20.000000000000014, 13.69999999999997, 69.19999999999976, 165.7999999999998, 23.60000000000001, 20.000000000000014, 55.100000000000115, 6.799999999999967, 81.19999999999925, 50.600000000000094, 21.800000000000047, -38.5, 86.59999999999953, 34.40000000000026, 25.400000000000105, 20.000000000000014, 105.79999999999959, 19.699999999999985, -72.69999999999999, 22.700000000000063, 67.39999999999988, -5.799999999999963, 20.000000000000014, -81.40000000000032, -55.60000000000022, -75.7000000000008, 90.1999999999998, -55.90000000000017, 20.000000000000014, 49.70000000000024], "policy_predator_policy_reward": [0.0, 51.0, 20.0, 108.0, 33.0, 56.0, 4.0, 0.0, 111.0, 12.0, 0.0, 0.0, 0.0, 0.0, 67.0, 54.0, 39.0, 0.0, 0.0, 45.0, 62.0, 74.0, 23.0, 25.0, 0.0, 0.0, 67.0, 35.0, 6.0, 23.0, 0.0, 15.0, 0.0, 75.0, 1.0, 31.0, 1.0, 10.0, 0.0, 136.0, 0.0, 55.0, 0.0, 0.0, 0.0, 7.0, 23.0, 1.0, 0.0, 0.0, 54.0, 12.0, 82.0, 14.0, 16.0, 72.0, 11.0, 126.0, 0.0, 145.0, 20.0, 8.0, 0.0, 1.0, 0.0, 22.0, 32.0, 24.0, 50.0, 41.0, 55.0, 16.0, 0.0, 0.0, 8.0, 0.0, 25.0, 44.0, 43.0, 9.0, 61.0, 38.0, 35.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 0.0, 235.0, 11.0, 0.0, 1.0, 0.0, 57.0, 2.0, 12.0, 0.0, 0.0, 49.0, 56.0, 137.0, 75.0, 42.0, 141.0, 0.0, 118.0, 0.0, 0.0, 11.0, 0.0, 64.0, 0.0, 27.0, 0.0, 55.0, 0.0, 123.0, 0.0, 90.0, 0.0, 0.0, 10.0, 54.0, 35.0, 16.0, 48.0, 0.0, 33.0, 0.0, 63.0, 88.0, 0.0, 0.0, 11.0, 35.0, 15.0, 18.0, 76.0, 27.0, 0.0, 0.0, 16.0, 0.0, 0.0, 31.0, 0.0, 22.0, 38.0, 120.0, 43.0, 19.0, 132.0, 75.0, 6.0, 20.0, 0.0, 9.0, 3.0, 69.0, 0.0, 38.0, 0.0, 0.0, 29.0, 11.0, 93.0, 61.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 0.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 40.0, 29.0, 7.0, 28.0, 74.0, 0.0, 55.0, 0.0, 64.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5940407100917269, "mean_inference_ms": 1.7856768340404228, "mean_action_processing_ms": 0.2360508034218427, "mean_env_wait_ms": 0.19230827920798188, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005005478858947754, "StateBufferConnector_ms": 0.0031588077545166016, "ViewRequirementAgentConnector_ms": 0.09669768810272217}, "num_episodes": 18, "episode_return_max": 296.800000000001, "episode_return_min": -302.70000000000016, "episode_return_mean": 44.672999999999796, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 393.20328847493977, "num_env_steps_trained_throughput_per_sec": 393.20328847493977, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 10250.314, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10250.272, "sample_time_ms": 1317.271, "learn_time_ms": 8910.801, "learn_throughput": 448.893, "synch_weights_time_ms": 20.33}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "0b081_00000", "date": "2024-08-13_00-51-17", "timestamp": 1723524677, "time_this_iter_s": 10.193726062774658, "time_total_s": 258.30154252052307, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fcbd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 258.30154252052307, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 29.19333333333334, "ram_util_percent": 83.41333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26548586291847404, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.413470841021765, "policy_loss": -0.0051972625311464075, "vf_loss": 2.4186300554603495, "vf_explained_var": 0.0031430501155752352, "kl": 0.012177702243511149, "entropy": 1.5485076325911062, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7379727733907877, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.659541181660203, "policy_loss": -0.005019346673273181, "vf_loss": 4.662775357311996, "vf_explained_var": 0.04268914672432753, "kl": 0.021157501833356195, "entropy": 1.201530077659264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 296.800000000001, "episode_reward_min": -302.70000000000016, "episode_reward_mean": 49.32399999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -271.19999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.7999999999998, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -0.3030000000000769, "predator_policy": 24.965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [84.6000000000003, -210.40000000000109, 5.599999999999964, 93.09999999999947, 82.69999999999916, 94.5999999999992, 51.700000000000315, 16.899999999999963, -43.09999999999994, 22.40000000000019, -58.19999999999994, -215.20000000000078, 138.79999999999933, 65.90000000000036, 83.29999999999998, 39.90000000000009, 191.2999999999995, 32.99999999999963, 157.89999999999887, 162.8999999999993, 30.700000000000152, -1.8999999999998574, 63.40000000000014, -0.6000000000000179, 69.70000000000022, 71.5000000000002, -50.99999999999962, -302.70000000000016, 83.69999999999854, 77.59999999999977, 52.20000000000027, 296.800000000001, 59.000000000000306, -107.60000000000025, -0.5000000000004139, -135.50000000000014, -84.40000000000012, 141.29999999999936, -0.9999999999997531, 26.50000000000016, -21.699999999999967, -80.90000000000055, -14.89999999999996, 55.30000000000042, -24.99999999999975, -8.299999999999702, 81.70000000000002, 3.7000000000001525, -70.00000000000114, 111.10000000000002, -3.3999999999997628, 119.79999999999933, 18.79999999999966, 193.8999999999988, 22.400000000000013, 184.09999999999945, 163.69999999999902, -60.30000000000012, 42.60000000000032, -7.800000000000068, 162.5999999999996, 44.50000000000024, 85.0000000000001, 176.4, 40.0000000000003, 67.09999999999997, 58.99999999999979, 36.700000000000244, 238.99999999999932, 43.60000000000029, 93.89999999999881, 161.79999999999887, 40.30000000000003, 120.99999999999898, 45.40000000000029, 153.49999999999883, 19.000000000000078, 96.59999999999897, 12.600000000000247, -76.3000000000016, 98.29999999999953, 69.70000000000009, 110.39999999999881, 49.90000000000034, 85.69999999999901, 38.900000000000276, 21.300000000000225, 117.19999999999986, 89.4999999999999, -11.699999999999605, 2.6000000000000876, 43.60000000000031, 224.39999999999958, 40.0000000000003, 51.20000000000018, 226.59999999999937, 74.89999999999945, 50.600000000000165, 38.400000000000155, 99.49999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [76.70000000000019, -3.100000000000001, -150.10000000000065, -196.30000000000044, 20.000000000000014, -69.40000000000028, 73.09999999999975, 20.000000000000014, 20.000000000000014, 55.7000000000001, -7.3000000000000504, 77.89999999999966, 31.70000000000003, 20.000000000000014, -66.10000000000082, 16.999999999999975, -117.39999999999998, -21.69999999999976, -1.2999999999999714, -64.30000000000008, -44.19999999999978, -151.0, -136.60000000000034, -223.60000000000042, -22.000000000000014, 132.79999999999987, 44.00000000000024, 20.90000000000003, 20.000000000000014, 41.300000000000125, 7.399999999999979, -23.500000000000014, 115.39999999999947, -15.100000000000044, 11.599999999999946, -49.59999999999995, 20.000000000000014, 137.8999999999996, 14.899999999999968, 139.9999999999999, -16.599999999999916, -21.69999999999985, -69.70000000000067, 15.79999999999996, 29.299999999999727, -64.9, -9.400000000000006, -26.199999999999957, 49.70000000000023, 20.000000000000014, 20.000000000000014, 51.499999999999964, -30.699999999999996, -91.30000000000051, -271.19999999999993, -266.5000000000001, 20.000000000000014, 52.69999999999952, 22.70000000000003, 53.900000000000134, 20.000000000000014, -26.800000000000068, 160.39999999999975, 124.39999999999998, 20.000000000000014, -10.000000000000103, -37.89999999999977, -262.70000000000005, -49.29999999999998, -68.20000000000005, -130.00000000000034, -146.5000000000002, -220.3, 17.899999999999984, 20.000000000000014, 110.2999999999999, -110.5, 45.50000000000009, 20.000000000000014, -20.49999999999978, -84.99999999999999, 8.299999999999983, -223.90000000000023, 20.000000000000014, -64.00000000000006, -40.899999999999935, 20.000000000000014, 35.30000000000021, 2.600000000000027, -91.60000000000045, 20.000000000000014, -79.30000000000078, -47.49999999999984, 81.19999999999995, -49.29999999999986, 20.000000000000014, -109.60000000000048, -111.40000000000072, 91.10000000000011, 20.000000000000014, -69.40000000000083, 20.000000000000014, 20.000000000000014, 66.79999999999987, -21.400000000000034, -62.799999999999955, 102.79999999999951, 91.09999999999931, -13.599999999999783, 20.000000000000014, 28.700000000000042, 124.39999999999978, 66.20000000000019, 75.49999999999964, -223.60000000000036, 5.300000000000009, -28.899999999999842, 9.499999999999964, -164.90000000000006, -49.899999999999835, 116.6, 20.000000000000014, 15.499999999999957, 20.000000000000014, -37.60000000000005, 50.600000000000065, 2.299999999999507, 136.09999999999982, 20.000000000000014, 20.000000000000014, 38.90000000000015, -11.799999999999866, -14.800000000000246, -80.19999999999999, 20.000000000000014, 13.69999999999997, 69.19999999999976, 165.7999999999998, 23.60000000000001, 20.000000000000014, 55.100000000000115, 6.799999999999967, 81.19999999999925, 50.600000000000094, 21.800000000000047, -38.5, 86.59999999999953, 34.40000000000026, 25.400000000000105, 20.000000000000014, 105.79999999999959, 19.699999999999985, -72.69999999999999, 22.700000000000063, 67.39999999999988, -5.799999999999963, 20.000000000000014, -81.40000000000032, -55.60000000000022, -75.7000000000008, 90.1999999999998, -55.90000000000017, 20.000000000000014, 49.70000000000024, 65.00000000000013, 10.400000000000002, 20.000000000000014, 29.900000000000063, 53.90000000000018, 21.80000000000001, 17.899999999999977, 20.000000000000014, -59.79999999999996, 10.099999999999977, -15.099999999999998, 47.300000000000026, 30.800000000000004, 58.70000000000013, -76.60000000000088, 17.899999999999977, 20.000000000000014, -51.39999999999985, 20.000000000000014, 23.600000000000026, 89.29999999999988, 112.09999999999997, 20.000000000000014, 20.000000000000014, 10.400000000000066, 15.799999999999963, 104.60000000000001, 100.99999999999937, 56.000000000000064, 17.899999999999988, -69.70000000000002, 26.300000000000058, 3.1999999999999633, 27.20000000000002, 125.29999999999977, -74.80000000000041], "policy_predator_policy_reward": [1.0, 10.0, 0.0, 136.0, 0.0, 55.0, 0.0, 0.0, 0.0, 7.0, 23.0, 1.0, 0.0, 0.0, 54.0, 12.0, 82.0, 14.0, 16.0, 72.0, 11.0, 126.0, 0.0, 145.0, 20.0, 8.0, 0.0, 1.0, 0.0, 22.0, 32.0, 24.0, 50.0, 41.0, 55.0, 16.0, 0.0, 0.0, 8.0, 0.0, 25.0, 44.0, 43.0, 9.0, 61.0, 38.0, 35.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 0.0, 235.0, 11.0, 0.0, 1.0, 0.0, 57.0, 2.0, 12.0, 0.0, 0.0, 49.0, 56.0, 137.0, 75.0, 42.0, 141.0, 0.0, 118.0, 0.0, 0.0, 11.0, 0.0, 64.0, 0.0, 27.0, 0.0, 55.0, 0.0, 123.0, 0.0, 90.0, 0.0, 0.0, 10.0, 54.0, 35.0, 16.0, 48.0, 0.0, 33.0, 0.0, 63.0, 88.0, 0.0, 0.0, 11.0, 35.0, 15.0, 18.0, 76.0, 27.0, 0.0, 0.0, 16.0, 0.0, 0.0, 31.0, 0.0, 22.0, 38.0, 120.0, 43.0, 19.0, 132.0, 75.0, 6.0, 20.0, 0.0, 9.0, 3.0, 69.0, 0.0, 38.0, 0.0, 0.0, 29.0, 11.0, 93.0, 61.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 0.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 40.0, 29.0, 7.0, 28.0, 74.0, 0.0, 55.0, 0.0, 64.0, 0.0, 0.0, 0.0, 6.0, 29.0, 0.0, 0.0, 10.0, 0.0, 1.0, 0.0, 7.0, 64.0, 42.0, 43.0, 0.0, 0.0, 1.0, 46.0, 18.0, 16.0, 0.0, 0.0, 11.0, 12.0, 0.0, 0.0, 22.0, 3.0, 5.0, 16.0, 0.0, 1.0, 83.0, 11.0, 0.0, 8.0, 29.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5928556198497337, "mean_inference_ms": 1.7834492446218622, "mean_action_processing_ms": 0.23569948649665984, "mean_env_wait_ms": 0.19205185028959446, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0056536197662353516, "StateBufferConnector_ms": 0.0031725168228149414, "ViewRequirementAgentConnector_ms": 0.09766137599945068}, "num_episodes": 18, "episode_return_max": 296.800000000001, "episode_return_min": -302.70000000000016, "episode_return_mean": 49.32399999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 408.3073424163126, "num_env_steps_trained_throughput_per_sec": 408.3073424163126, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 10162.882, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10162.841, "sample_time_ms": 1315.561, "learn_time_ms": 8825.766, "learn_throughput": 453.218, "synch_weights_time_ms": 19.956}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "0b081_00000", "date": "2024-08-13_00-51-27", "timestamp": 1723524687, "time_this_iter_s": 9.800537109375, "time_total_s": 268.10207962989807, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fcb5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 268.10207962989807, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 28.935714285714287, "ram_util_percent": 83.22142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30411888058223424, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8554615784574437, "policy_loss": -0.008115525654807845, "vf_loss": 1.8635225969016866, "vf_explained_var": 0.0006793753179923567, "kl": 0.017441313194966827, "entropy": 1.512079015421489, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3704486855635882, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.987870068840249, "policy_loss": -0.0016537166658848051, "vf_loss": 2.9887818357931875, "vf_explained_var": 0.025871399439201154, "kl": 0.005862371996871237, "entropy": 1.156512638816127, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 296.800000000001, "episode_reward_min": -302.70000000000016, "episode_reward_mean": 50.29199999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -271.19999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.7999999999998, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": 1.310999999999937, "predator_policy": 23.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [63.40000000000014, -0.6000000000000179, 69.70000000000022, 71.5000000000002, -50.99999999999962, -302.70000000000016, 83.69999999999854, 77.59999999999977, 52.20000000000027, 296.800000000001, 59.000000000000306, -107.60000000000025, -0.5000000000004139, -135.50000000000014, -84.40000000000012, 141.29999999999936, -0.9999999999997531, 26.50000000000016, -21.699999999999967, -80.90000000000055, -14.89999999999996, 55.30000000000042, -24.99999999999975, -8.299999999999702, 81.70000000000002, 3.7000000000001525, -70.00000000000114, 111.10000000000002, -3.3999999999997628, 119.79999999999933, 18.79999999999966, 193.8999999999988, 22.400000000000013, 184.09999999999945, 163.69999999999902, -60.30000000000012, 42.60000000000032, -7.800000000000068, 162.5999999999996, 44.50000000000024, 85.0000000000001, 176.4, 40.0000000000003, 67.09999999999997, 58.99999999999979, 36.700000000000244, 238.99999999999932, 43.60000000000029, 93.89999999999881, 161.79999999999887, 40.30000000000003, 120.99999999999898, 45.40000000000029, 153.49999999999883, 19.000000000000078, 96.59999999999897, 12.600000000000247, -76.3000000000016, 98.29999999999953, 69.70000000000009, 110.39999999999881, 49.90000000000034, 85.69999999999901, 38.900000000000276, 21.300000000000225, 117.19999999999986, 89.4999999999999, -11.699999999999605, 2.6000000000000876, 43.60000000000031, 224.39999999999958, 40.0000000000003, 51.20000000000018, 226.59999999999937, 74.89999999999945, 50.600000000000165, 38.400000000000155, 99.49999999999952, 116.29999999999905, -2.8999999999997446, 32.20000000000019, -19.399999999999743, 123.69999999999865, -37.39999999999963, 40.0000000000003, 43.60000000000035, 19.099999999999977, -10.399999999999904, 135.8999999999989, 34.10000000000021, 9.600000000000197, 36.50000000000027, -28.499999999999737, 53.80000000000032, 120.7999999999995, 40.0000000000003, 14.999999999999996, 46.900000000000425, 134.4999999999992, 19.899999999999977], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.299999999999727, -64.9, -9.400000000000006, -26.199999999999957, 49.70000000000023, 20.000000000000014, 20.000000000000014, 51.499999999999964, -30.699999999999996, -91.30000000000051, -271.19999999999993, -266.5000000000001, 20.000000000000014, 52.69999999999952, 22.70000000000003, 53.900000000000134, 20.000000000000014, -26.800000000000068, 160.39999999999975, 124.39999999999998, 20.000000000000014, -10.000000000000103, -37.89999999999977, -262.70000000000005, -49.29999999999998, -68.20000000000005, -130.00000000000034, -146.5000000000002, -220.3, 17.899999999999984, 20.000000000000014, 110.2999999999999, -110.5, 45.50000000000009, 20.000000000000014, -20.49999999999978, -84.99999999999999, 8.299999999999983, -223.90000000000023, 20.000000000000014, -64.00000000000006, -40.899999999999935, 20.000000000000014, 35.30000000000021, 2.600000000000027, -91.60000000000045, 20.000000000000014, -79.30000000000078, -47.49999999999984, 81.19999999999995, -49.29999999999986, 20.000000000000014, -109.60000000000048, -111.40000000000072, 91.10000000000011, 20.000000000000014, -69.40000000000083, 20.000000000000014, 20.000000000000014, 66.79999999999987, -21.400000000000034, -62.799999999999955, 102.79999999999951, 91.09999999999931, -13.599999999999783, 20.000000000000014, 28.700000000000042, 124.39999999999978, 66.20000000000019, 75.49999999999964, -223.60000000000036, 5.300000000000009, -28.899999999999842, 9.499999999999964, -164.90000000000006, -49.899999999999835, 116.6, 20.000000000000014, 15.499999999999957, 20.000000000000014, -37.60000000000005, 50.600000000000065, 2.299999999999507, 136.09999999999982, 20.000000000000014, 20.000000000000014, 38.90000000000015, -11.799999999999866, -14.800000000000246, -80.19999999999999, 20.000000000000014, 13.69999999999997, 69.19999999999976, 165.7999999999998, 23.60000000000001, 20.000000000000014, 55.100000000000115, 6.799999999999967, 81.19999999999925, 50.600000000000094, 21.800000000000047, -38.5, 86.59999999999953, 34.40000000000026, 25.400000000000105, 20.000000000000014, 105.79999999999959, 19.699999999999985, -72.69999999999999, 22.700000000000063, 67.39999999999988, -5.799999999999963, 20.000000000000014, -81.40000000000032, -55.60000000000022, -75.7000000000008, 90.1999999999998, -55.90000000000017, 20.000000000000014, 49.70000000000024, 65.00000000000013, 10.400000000000002, 20.000000000000014, 29.900000000000063, 53.90000000000018, 21.80000000000001, 17.899999999999977, 20.000000000000014, -59.79999999999996, 10.099999999999977, -15.099999999999998, 47.300000000000026, 30.800000000000004, 58.70000000000013, -76.60000000000088, 17.899999999999977, 20.000000000000014, -51.39999999999985, 20.000000000000014, 23.600000000000026, 89.29999999999988, 112.09999999999997, 20.000000000000014, 20.000000000000014, 10.400000000000066, 15.799999999999963, 104.60000000000001, 100.99999999999937, 56.000000000000064, 17.899999999999988, -69.70000000000002, 26.300000000000058, 3.1999999999999633, 27.20000000000002, 125.29999999999977, -74.80000000000041, 86.29999999999959, 20.000000000000014, 20.000000000000014, -61.90000000000074, 37.70000000000024, -47.49999999999981, -145.0000000000002, 17.600000000000055, 20.000000000000014, 103.69999999999939, -14.79999999999982, -88.60000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -19.899999999999743, 20.000000000000014, 47.900000000000105, -178.3000000000003, -8.500000000000007, 97.39999999999941, 10.399999999999961, -10.299999999999923, 17.899999999999988, -79.3000000000001, -5.500000000000032, 20.000000000000014, -254.20000000000005, 22.700000000000063, 20.000000000000014, 3.800000000000023, -11.499999999999819, 95.29999999999998, 20.000000000000014, 20.000000000000014, -55.00000000000048, 20.000000000000014, 30.800000000000203, 1.0999999999999688, 59.60000000000021, 74.89999999999966, -24.099999999999774, 20.000000000000014], "policy_predator_policy_reward": [61.0, 38.0, 35.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 0.0, 235.0, 11.0, 0.0, 1.0, 0.0, 57.0, 2.0, 12.0, 0.0, 0.0, 49.0, 56.0, 137.0, 75.0, 42.0, 141.0, 0.0, 118.0, 0.0, 0.0, 11.0, 0.0, 64.0, 0.0, 27.0, 0.0, 55.0, 0.0, 123.0, 0.0, 90.0, 0.0, 0.0, 10.0, 54.0, 35.0, 16.0, 48.0, 0.0, 33.0, 0.0, 63.0, 88.0, 0.0, 0.0, 11.0, 35.0, 15.0, 18.0, 76.0, 27.0, 0.0, 0.0, 16.0, 0.0, 0.0, 31.0, 0.0, 22.0, 38.0, 120.0, 43.0, 19.0, 132.0, 75.0, 6.0, 20.0, 0.0, 9.0, 3.0, 69.0, 0.0, 38.0, 0.0, 0.0, 29.0, 11.0, 93.0, 61.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 0.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 40.0, 29.0, 7.0, 28.0, 74.0, 0.0, 55.0, 0.0, 64.0, 0.0, 0.0, 0.0, 6.0, 29.0, 0.0, 0.0, 10.0, 0.0, 1.0, 0.0, 7.0, 64.0, 42.0, 43.0, 0.0, 0.0, 1.0, 46.0, 18.0, 16.0, 0.0, 0.0, 11.0, 12.0, 0.0, 0.0, 22.0, 3.0, 5.0, 16.0, 0.0, 1.0, 83.0, 11.0, 0.0, 8.0, 29.0, 20.0, 2.0, 8.0, 0.0, 39.0, 24.0, 18.0, 23.0, 85.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 120.0, 8.0, 39.0, 29.0, 5.0, 71.0, 0.0, 0.0, 22.0, 68.0, 135.0, 30.0, 0.0, 3.0, 34.0, 0.0, 0.0, 37.0, 13.0, 9.0, 6.0, 0.0, 0.0, 24.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5916148993354219, "mean_inference_ms": 1.781532627474185, "mean_action_processing_ms": 0.23539893595102007, "mean_env_wait_ms": 0.19188072527966418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006103396415710449, "StateBufferConnector_ms": 0.0031472444534301758, "ViewRequirementAgentConnector_ms": 0.0955437421798706}, "num_episodes": 22, "episode_return_max": 296.800000000001, "episode_return_min": -302.70000000000016, "episode_return_mean": 50.29199999999985, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 406.7009352498122, "num_env_steps_trained_throughput_per_sec": 406.7009352498122, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 10132.332, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10132.293, "sample_time_ms": 1309.751, "learn_time_ms": 8801.022, "learn_throughput": 454.493, "synch_weights_time_ms": 19.914}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "0b081_00000", "date": "2024-08-13_00-51-37", "timestamp": 1723524697, "time_this_iter_s": 9.840755939483643, "time_total_s": 277.9428355693817, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fcbf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 277.9428355693817, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 29.192857142857147, "ram_util_percent": 83.24285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4966360054240025, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.1066048895871194, "policy_loss": -0.005110176184421612, "vf_loss": 5.1116361624349365, "vf_explained_var": 0.0002610216065058632, "kl": 0.02524686791300678, "entropy": 1.457254716769728, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8033826898330103, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.526764839919156, "policy_loss": -0.002744557238898422, "vf_loss": 6.528002507093722, "vf_explained_var": 0.006510654549119334, "kl": 0.011906225012984602, "entropy": 1.1806280761799484, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 238.99999999999932, "episode_reward_min": -342.79999999999967, "episode_reward_mean": 51.64599999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -366.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.7999999999998, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": -0.24200000000005162, "predator_policy": 26.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.299999999999702, 81.70000000000002, 3.7000000000001525, -70.00000000000114, 111.10000000000002, -3.3999999999997628, 119.79999999999933, 18.79999999999966, 193.8999999999988, 22.400000000000013, 184.09999999999945, 163.69999999999902, -60.30000000000012, 42.60000000000032, -7.800000000000068, 162.5999999999996, 44.50000000000024, 85.0000000000001, 176.4, 40.0000000000003, 67.09999999999997, 58.99999999999979, 36.700000000000244, 238.99999999999932, 43.60000000000029, 93.89999999999881, 161.79999999999887, 40.30000000000003, 120.99999999999898, 45.40000000000029, 153.49999999999883, 19.000000000000078, 96.59999999999897, 12.600000000000247, -76.3000000000016, 98.29999999999953, 69.70000000000009, 110.39999999999881, 49.90000000000034, 85.69999999999901, 38.900000000000276, 21.300000000000225, 117.19999999999986, 89.4999999999999, -11.699999999999605, 2.6000000000000876, 43.60000000000031, 224.39999999999958, 40.0000000000003, 51.20000000000018, 226.59999999999937, 74.89999999999945, 50.600000000000165, 38.400000000000155, 99.49999999999952, 116.29999999999905, -2.8999999999997446, 32.20000000000019, -19.399999999999743, 123.69999999999865, -37.39999999999963, 40.0000000000003, 43.60000000000035, 19.099999999999977, -10.399999999999904, 135.8999999999989, 34.10000000000021, 9.600000000000197, 36.50000000000027, -28.499999999999737, 53.80000000000032, 120.7999999999995, 40.0000000000003, 14.999999999999996, 46.900000000000425, 134.4999999999992, 19.899999999999977, -78.79999999999987, 27.40000000000021, 181.099999999999, -66.99999999999983, 108.99999999999841, 61.89999999999995, 144.49999999999977, -55.599999999999895, 18.499999999999968, -342.79999999999967, 209.29999999999936, 10.800000000000129, 14.20000000000014, -86.99999999999997, 49.40000000000025, 50.999999999999574, 109.29999999999964, -38.59999999999994, -38.29999999999979, 11.500000000000068, 10.600000000000021, -18.499999999999908, 24.700000000000063], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -79.30000000000078, -47.49999999999984, 81.19999999999995, -49.29999999999986, 20.000000000000014, -109.60000000000048, -111.40000000000072, 91.10000000000011, 20.000000000000014, -69.40000000000083, 20.000000000000014, 20.000000000000014, 66.79999999999987, -21.400000000000034, -62.799999999999955, 102.79999999999951, 91.09999999999931, -13.599999999999783, 20.000000000000014, 28.700000000000042, 124.39999999999978, 66.20000000000019, 75.49999999999964, -223.60000000000036, 5.300000000000009, -28.899999999999842, 9.499999999999964, -164.90000000000006, -49.899999999999835, 116.6, 20.000000000000014, 15.499999999999957, 20.000000000000014, -37.60000000000005, 50.600000000000065, 2.299999999999507, 136.09999999999982, 20.000000000000014, 20.000000000000014, 38.90000000000015, -11.799999999999866, -14.800000000000246, -80.19999999999999, 20.000000000000014, 13.69999999999997, 69.19999999999976, 165.7999999999998, 23.60000000000001, 20.000000000000014, 55.100000000000115, 6.799999999999967, 81.19999999999925, 50.600000000000094, 21.800000000000047, -38.5, 86.59999999999953, 34.40000000000026, 25.400000000000105, 20.000000000000014, 105.79999999999959, 19.699999999999985, -72.69999999999999, 22.700000000000063, 67.39999999999988, -5.799999999999963, 20.000000000000014, -81.40000000000032, -55.60000000000022, -75.7000000000008, 90.1999999999998, -55.90000000000017, 20.000000000000014, 49.70000000000024, 65.00000000000013, 10.400000000000002, 20.000000000000014, 29.900000000000063, 53.90000000000018, 21.80000000000001, 17.899999999999977, 20.000000000000014, -59.79999999999996, 10.099999999999977, -15.099999999999998, 47.300000000000026, 30.800000000000004, 58.70000000000013, -76.60000000000088, 17.899999999999977, 20.000000000000014, -51.39999999999985, 20.000000000000014, 23.600000000000026, 89.29999999999988, 112.09999999999997, 20.000000000000014, 20.000000000000014, 10.400000000000066, 15.799999999999963, 104.60000000000001, 100.99999999999937, 56.000000000000064, 17.899999999999988, -69.70000000000002, 26.300000000000058, 3.1999999999999633, 27.20000000000002, 125.29999999999977, -74.80000000000041, 86.29999999999959, 20.000000000000014, 20.000000000000014, -61.90000000000074, 37.70000000000024, -47.49999999999981, -145.0000000000002, 17.600000000000055, 20.000000000000014, 103.69999999999939, -14.79999999999982, -88.60000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -19.899999999999743, 20.000000000000014, 47.900000000000105, -178.3000000000003, -8.500000000000007, 97.39999999999941, 10.399999999999961, -10.299999999999923, 17.899999999999988, -79.3000000000001, -5.500000000000032, 20.000000000000014, -254.20000000000005, 22.700000000000063, 20.000000000000014, 3.800000000000023, -11.499999999999819, 95.29999999999998, 20.000000000000014, 20.000000000000014, -55.00000000000048, 20.000000000000014, 30.800000000000203, 1.0999999999999688, 59.60000000000021, 74.89999999999966, -24.099999999999774, 20.000000000000014, 20.000000000000014, -227.79999999999998, 14.600000000000165, -77.2000000000003, 28.10000000000023, 142.99999999999974, -366.1, 13.099999999999957, 47.90000000000006, 43.10000000000024, 20.000000000000014, 29.900000000000148, 59.3000000000002, 81.19999999999999, -312.4, 63.79999999999997, 20.000000000000014, -23.49999999999975, -329.1999999999998, -265.59999999999997, 91.69999999999953, 104.59999999999995, 20.000000000000014, -83.20000000000005, -45.09999999999998, -24.699999999999875, 20.000000000000014, -243.99999999999997, 36.20000000000009, -59.80000000000021, -56.19999999999993, 54.20000000000021, 83.89999999999986, 25.400000000000006, -170.20000000000005, 14.599999999999964, 13.699999999999946, -188.0, -46.29999999999978, 18.799999999999997, -58.300000000000026, 20.900000000000013, 11.300000000000004, -248.79999999999998, 17.899999999999977, -5.200000000000051], "policy_predator_policy_reward": [35.0, 16.0, 48.0, 0.0, 33.0, 0.0, 63.0, 88.0, 0.0, 0.0, 11.0, 35.0, 15.0, 18.0, 76.0, 27.0, 0.0, 0.0, 16.0, 0.0, 0.0, 31.0, 0.0, 22.0, 38.0, 120.0, 43.0, 19.0, 132.0, 75.0, 6.0, 20.0, 0.0, 9.0, 3.0, 69.0, 0.0, 38.0, 0.0, 0.0, 29.0, 11.0, 93.0, 61.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 0.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 40.0, 29.0, 7.0, 28.0, 74.0, 0.0, 55.0, 0.0, 64.0, 0.0, 0.0, 0.0, 6.0, 29.0, 0.0, 0.0, 10.0, 0.0, 1.0, 0.0, 7.0, 64.0, 42.0, 43.0, 0.0, 0.0, 1.0, 46.0, 18.0, 16.0, 0.0, 0.0, 11.0, 12.0, 0.0, 0.0, 22.0, 3.0, 5.0, 16.0, 0.0, 1.0, 83.0, 11.0, 0.0, 8.0, 29.0, 20.0, 2.0, 8.0, 0.0, 39.0, 24.0, 18.0, 23.0, 85.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 120.0, 8.0, 39.0, 29.0, 5.0, 71.0, 0.0, 0.0, 22.0, 68.0, 135.0, 30.0, 0.0, 3.0, 34.0, 0.0, 0.0, 37.0, 13.0, 9.0, 6.0, 0.0, 0.0, 24.0, 0.0, 127.0, 2.0, 63.0, 27.0, 1.0, 9.0, 119.0, 167.0, 13.0, 5.0, 12.0, 0.0, 4.0, 0.0, 82.0, 111.0, 22.0, 0.0, 123.0, 129.0, 6.0, 7.0, 3.0, 71.0, 46.0, 38.0, 6.0, 131.0, 45.0, 28.0, 53.0, 0.0, 0.0, 0.0, 39.0, 78.0, 3.0, 133.0, 4.0, 35.0, 42.0, 6.0, 120.0, 99.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5904712589530192, "mean_inference_ms": 1.7804447906367122, "mean_action_processing_ms": 0.24129427018146507, "mean_env_wait_ms": 0.19169513463555418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006014585494995117, "StateBufferConnector_ms": 0.0031654834747314453, "ViewRequirementAgentConnector_ms": 0.09304118156433105}, "num_episodes": 23, "episode_return_max": 238.99999999999932, "episode_return_min": -342.79999999999967, "episode_return_mean": 51.64599999999983, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.61467642840455, "num_env_steps_trained_throughput_per_sec": 369.61467642840455, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 10198.348, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10198.309, "sample_time_ms": 1363.406, "learn_time_ms": 8812.867, "learn_throughput": 453.882, "synch_weights_time_ms": 20.415}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "0b081_00000", "date": "2024-08-13_00-51-47", "timestamp": 1723524707, "time_this_iter_s": 10.877409934997559, "time_total_s": 288.8202455043793, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fd5b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 288.8202455043793, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 32.89999999999999, "ram_util_percent": 82.82666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4745191751767403, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.951659775537158, "policy_loss": -0.0019057523604561254, "vf_loss": 3.9535044566664115, "vf_explained_var": 0.0063504617050211265, "kl": 0.013030262808763753, "entropy": 1.4581888203267699, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6427296531578852, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.979396448942719, "policy_loss": -0.0065303741821220946, "vf_loss": 5.983590886201808, "vf_explained_var": 0.028599583408819934, "kl": 0.01845682595534621, "entropy": 1.1717332400342144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 238.99999999999932, "episode_reward_min": -342.79999999999967, "episode_reward_mean": 47.00799999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -366.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.30000000000004, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": -2.2110000000000425, "predator_policy": 25.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [176.4, 40.0000000000003, 67.09999999999997, 58.99999999999979, 36.700000000000244, 238.99999999999932, 43.60000000000029, 93.89999999999881, 161.79999999999887, 40.30000000000003, 120.99999999999898, 45.40000000000029, 153.49999999999883, 19.000000000000078, 96.59999999999897, 12.600000000000247, -76.3000000000016, 98.29999999999953, 69.70000000000009, 110.39999999999881, 49.90000000000034, 85.69999999999901, 38.900000000000276, 21.300000000000225, 117.19999999999986, 89.4999999999999, -11.699999999999605, 2.6000000000000876, 43.60000000000031, 224.39999999999958, 40.0000000000003, 51.20000000000018, 226.59999999999937, 74.89999999999945, 50.600000000000165, 38.400000000000155, 99.49999999999952, 116.29999999999905, -2.8999999999997446, 32.20000000000019, -19.399999999999743, 123.69999999999865, -37.39999999999963, 40.0000000000003, 43.60000000000035, 19.099999999999977, -10.399999999999904, 135.8999999999989, 34.10000000000021, 9.600000000000197, 36.50000000000027, -28.499999999999737, 53.80000000000032, 120.7999999999995, 40.0000000000003, 14.999999999999996, 46.900000000000425, 134.4999999999992, 19.899999999999977, -78.79999999999987, 27.40000000000021, 181.099999999999, -66.99999999999983, 108.99999999999841, 61.89999999999995, 144.49999999999977, -55.599999999999895, 18.499999999999968, -342.79999999999967, 209.29999999999936, 10.800000000000129, 14.20000000000014, -86.99999999999997, 49.40000000000025, 50.999999999999574, 109.29999999999964, -38.59999999999994, -38.29999999999979, 11.500000000000068, 10.600000000000021, -18.499999999999908, 24.700000000000063, 80.9, 159.0999999999993, 61.20000000000044, 40.0000000000003, 47.60000000000016, -106.10000000000142, 69.19999999999908, 9.199999999999946, -34.699999999999754, 67.60000000000002, 63.40000000000017, 45.20000000000026, 89.89999999999998, -13.199999999999982, 67.90000000000023, -29.39999999999992, -117.60000000000116, 120.09999999999965], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.299999999999507, 136.09999999999982, 20.000000000000014, 20.000000000000014, 38.90000000000015, -11.799999999999866, -14.800000000000246, -80.19999999999999, 20.000000000000014, 13.69999999999997, 69.19999999999976, 165.7999999999998, 23.60000000000001, 20.000000000000014, 55.100000000000115, 6.799999999999967, 81.19999999999925, 50.600000000000094, 21.800000000000047, -38.5, 86.59999999999953, 34.40000000000026, 25.400000000000105, 20.000000000000014, 105.79999999999959, 19.699999999999985, -72.69999999999999, 22.700000000000063, 67.39999999999988, -5.799999999999963, 20.000000000000014, -81.40000000000032, -55.60000000000022, -75.7000000000008, 90.1999999999998, -55.90000000000017, 20.000000000000014, 49.70000000000024, 65.00000000000013, 10.400000000000002, 20.000000000000014, 29.900000000000063, 53.90000000000018, 21.80000000000001, 17.899999999999977, 20.000000000000014, -59.79999999999996, 10.099999999999977, -15.099999999999998, 47.300000000000026, 30.800000000000004, 58.70000000000013, -76.60000000000088, 17.899999999999977, 20.000000000000014, -51.39999999999985, 20.000000000000014, 23.600000000000026, 89.29999999999988, 112.09999999999997, 20.000000000000014, 20.000000000000014, 10.400000000000066, 15.799999999999963, 104.60000000000001, 100.99999999999937, 56.000000000000064, 17.899999999999988, -69.70000000000002, 26.300000000000058, 3.1999999999999633, 27.20000000000002, 125.29999999999977, -74.80000000000041, 86.29999999999959, 20.000000000000014, 20.000000000000014, -61.90000000000074, 37.70000000000024, -47.49999999999981, -145.0000000000002, 17.600000000000055, 20.000000000000014, 103.69999999999939, -14.79999999999982, -88.60000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -19.899999999999743, 20.000000000000014, 47.900000000000105, -178.3000000000003, -8.500000000000007, 97.39999999999941, 10.399999999999961, -10.299999999999923, 17.899999999999988, -79.3000000000001, -5.500000000000032, 20.000000000000014, -254.20000000000005, 22.700000000000063, 20.000000000000014, 3.800000000000023, -11.499999999999819, 95.29999999999998, 20.000000000000014, 20.000000000000014, -55.00000000000048, 20.000000000000014, 30.800000000000203, 1.0999999999999688, 59.60000000000021, 74.89999999999966, -24.099999999999774, 20.000000000000014, 20.000000000000014, -227.79999999999998, 14.600000000000165, -77.2000000000003, 28.10000000000023, 142.99999999999974, -366.1, 13.099999999999957, 47.90000000000006, 43.10000000000024, 20.000000000000014, 29.900000000000148, 59.3000000000002, 81.19999999999999, -312.4, 63.79999999999997, 20.000000000000014, -23.49999999999975, -329.1999999999998, -265.59999999999997, 91.69999999999953, 104.59999999999995, 20.000000000000014, -83.20000000000005, -45.09999999999998, -24.699999999999875, 20.000000000000014, -243.99999999999997, 36.20000000000009, -59.80000000000021, -56.19999999999993, 54.20000000000021, 83.89999999999986, 25.400000000000006, -170.20000000000005, 14.599999999999964, 13.699999999999946, -188.0, -46.29999999999978, 18.799999999999997, -58.300000000000026, 20.900000000000013, 11.300000000000004, -248.79999999999998, 17.899999999999977, -5.200000000000051, -32.49999999999999, -1.599999999999845, 138.19999999999987, 17.900000000000013, 9.499999999999947, 46.70000000000021, 20.000000000000014, 20.000000000000014, -160.6, 120.19999999999993, -133.29999999999995, -59.800000000000125, 116.29999999999947, -108.10000000000011, -38.79999999999988, 20.000000000000014, 18.800000000000153, -143.5000000000002, 167.30000000000004, -222.70000000000033, -43.599999999999994, 20.000000000000014, 20.000000000000014, 15.199999999999955, 20.000000000000014, 53.89999999999998, 4.099999999999977, -79.30000000000003, 20.000000000000014, 47.90000000000002, -118.30000000000013, 5.899999999999999, -82.90000000000069, -129.7000000000005, 20.000000000000014, 55.100000000000016], "policy_predator_policy_reward": [0.0, 38.0, 0.0, 0.0, 29.0, 11.0, 93.0, 61.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 0.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 40.0, 29.0, 7.0, 28.0, 74.0, 0.0, 55.0, 0.0, 64.0, 0.0, 0.0, 0.0, 6.0, 29.0, 0.0, 0.0, 10.0, 0.0, 1.0, 0.0, 7.0, 64.0, 42.0, 43.0, 0.0, 0.0, 1.0, 46.0, 18.0, 16.0, 0.0, 0.0, 11.0, 12.0, 0.0, 0.0, 22.0, 3.0, 5.0, 16.0, 0.0, 1.0, 83.0, 11.0, 0.0, 8.0, 29.0, 20.0, 2.0, 8.0, 0.0, 39.0, 24.0, 18.0, 23.0, 85.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 120.0, 8.0, 39.0, 29.0, 5.0, 71.0, 0.0, 0.0, 22.0, 68.0, 135.0, 30.0, 0.0, 3.0, 34.0, 0.0, 0.0, 37.0, 13.0, 9.0, 6.0, 0.0, 0.0, 24.0, 0.0, 127.0, 2.0, 63.0, 27.0, 1.0, 9.0, 119.0, 167.0, 13.0, 5.0, 12.0, 0.0, 4.0, 0.0, 82.0, 111.0, 22.0, 0.0, 123.0, 129.0, 6.0, 7.0, 3.0, 71.0, 46.0, 38.0, 6.0, 131.0, 45.0, 28.0, 53.0, 0.0, 0.0, 0.0, 39.0, 78.0, 3.0, 133.0, 4.0, 35.0, 42.0, 6.0, 120.0, 99.0, 0.0, 12.0, 96.0, 19.0, 1.0, 2.0, 0.0, 5.0, 0.0, 0.0, 88.0, 0.0, 87.0, 0.0, 0.0, 61.0, 10.0, 18.0, 25.0, 65.0, 123.0, 0.0, 69.0, 18.0, 10.0, 0.0, 0.0, 16.0, 32.0, 30.0, 0.0, 0.0, 25.0, 58.0, 0.0, 95.0, 45.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5898710566012573, "mean_inference_ms": 1.7798222995537702, "mean_action_processing_ms": 0.24583799411373214, "mean_env_wait_ms": 0.19159560418731977, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00558316707611084, "StateBufferConnector_ms": 0.003159642219543457, "ViewRequirementAgentConnector_ms": 0.09274685382843018}, "num_episodes": 18, "episode_return_max": 238.99999999999932, "episode_return_min": -342.79999999999967, "episode_return_mean": 47.00799999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 405.7435443120201, "num_env_steps_trained_throughput_per_sec": 405.7435443120201, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 10161.986, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10161.947, "sample_time_ms": 1373.534, "learn_time_ms": 8773.318, "learn_throughput": 455.928, "synch_weights_time_ms": 13.497}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "0b081_00000", "date": "2024-08-13_00-51-57", "timestamp": 1723524717, "time_this_iter_s": 9.862025022506714, "time_total_s": 298.682270526886, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fb9820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 298.682270526886, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 32.85714285714286, "ram_util_percent": 83.55714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35409227223899314, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8126190528510109, "policy_loss": -0.0021245385239285135, "vf_loss": 0.8147067245825258, "vf_explained_var": 0.013159807869996975, "kl": 0.007865184494036483, "entropy": 1.483220480106495, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.576091824637519, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3410299640483956, "policy_loss": -0.005751890307489448, "vf_loss": 2.3451175052022175, "vf_explained_var": 0.1003582138233084, "kl": 0.01315035651780375, "entropy": 1.1934412579057079, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 226.59999999999937, "episode_reward_min": -342.79999999999967, "episode_reward_mean": 41.132999999999946, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -366.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.30000000000004, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": -4.03350000000002, "predator_policy": 24.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [69.70000000000009, 110.39999999999881, 49.90000000000034, 85.69999999999901, 38.900000000000276, 21.300000000000225, 117.19999999999986, 89.4999999999999, -11.699999999999605, 2.6000000000000876, 43.60000000000031, 224.39999999999958, 40.0000000000003, 51.20000000000018, 226.59999999999937, 74.89999999999945, 50.600000000000165, 38.400000000000155, 99.49999999999952, 116.29999999999905, -2.8999999999997446, 32.20000000000019, -19.399999999999743, 123.69999999999865, -37.39999999999963, 40.0000000000003, 43.60000000000035, 19.099999999999977, -10.399999999999904, 135.8999999999989, 34.10000000000021, 9.600000000000197, 36.50000000000027, -28.499999999999737, 53.80000000000032, 120.7999999999995, 40.0000000000003, 14.999999999999996, 46.900000000000425, 134.4999999999992, 19.899999999999977, -78.79999999999987, 27.40000000000021, 181.099999999999, -66.99999999999983, 108.99999999999841, 61.89999999999995, 144.49999999999977, -55.599999999999895, 18.499999999999968, -342.79999999999967, 209.29999999999936, 10.800000000000129, 14.20000000000014, -86.99999999999997, 49.40000000000025, 50.999999999999574, 109.29999999999964, -38.59999999999994, -38.29999999999979, 11.500000000000068, 10.600000000000021, -18.499999999999908, 24.700000000000063, 80.9, 159.0999999999993, 61.20000000000044, 40.0000000000003, 47.60000000000016, -106.10000000000142, 69.19999999999908, 9.199999999999946, -34.699999999999754, 67.60000000000002, 63.40000000000017, 45.20000000000026, 89.89999999999998, -13.199999999999982, 67.90000000000023, -29.39999999999992, -117.60000000000116, 120.09999999999965, 58.900000000000475, 107.59999999999988, 11.199999999999683, 55.90000000000034, 67.79999999999986, 40.900000000000176, -5.300000000000072, 99.79999999999879, -21.09999999999951, 63.900000000000496, 44.500000000000306, 53.80000000000036, 55.000000000000234, 30.100000000000147, 40.0000000000003, 40.90000000000031, 56.500000000000334, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 49.70000000000024, 65.00000000000013, 10.400000000000002, 20.000000000000014, 29.900000000000063, 53.90000000000018, 21.80000000000001, 17.899999999999977, 20.000000000000014, -59.79999999999996, 10.099999999999977, -15.099999999999998, 47.300000000000026, 30.800000000000004, 58.70000000000013, -76.60000000000088, 17.899999999999977, 20.000000000000014, -51.39999999999985, 20.000000000000014, 23.600000000000026, 89.29999999999988, 112.09999999999997, 20.000000000000014, 20.000000000000014, 10.400000000000066, 15.799999999999963, 104.60000000000001, 100.99999999999937, 56.000000000000064, 17.899999999999988, -69.70000000000002, 26.300000000000058, 3.1999999999999633, 27.20000000000002, 125.29999999999977, -74.80000000000041, 86.29999999999959, 20.000000000000014, 20.000000000000014, -61.90000000000074, 37.70000000000024, -47.49999999999981, -145.0000000000002, 17.600000000000055, 20.000000000000014, 103.69999999999939, -14.79999999999982, -88.60000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -19.899999999999743, 20.000000000000014, 47.900000000000105, -178.3000000000003, -8.500000000000007, 97.39999999999941, 10.399999999999961, -10.299999999999923, 17.899999999999988, -79.3000000000001, -5.500000000000032, 20.000000000000014, -254.20000000000005, 22.700000000000063, 20.000000000000014, 3.800000000000023, -11.499999999999819, 95.29999999999998, 20.000000000000014, 20.000000000000014, -55.00000000000048, 20.000000000000014, 30.800000000000203, 1.0999999999999688, 59.60000000000021, 74.89999999999966, -24.099999999999774, 20.000000000000014, 20.000000000000014, -227.79999999999998, 14.600000000000165, -77.2000000000003, 28.10000000000023, 142.99999999999974, -366.1, 13.099999999999957, 47.90000000000006, 43.10000000000024, 20.000000000000014, 29.900000000000148, 59.3000000000002, 81.19999999999999, -312.4, 63.79999999999997, 20.000000000000014, -23.49999999999975, -329.1999999999998, -265.59999999999997, 91.69999999999953, 104.59999999999995, 20.000000000000014, -83.20000000000005, -45.09999999999998, -24.699999999999875, 20.000000000000014, -243.99999999999997, 36.20000000000009, -59.80000000000021, -56.19999999999993, 54.20000000000021, 83.89999999999986, 25.400000000000006, -170.20000000000005, 14.599999999999964, 13.699999999999946, -188.0, -46.29999999999978, 18.799999999999997, -58.300000000000026, 20.900000000000013, 11.300000000000004, -248.79999999999998, 17.899999999999977, -5.200000000000051, -32.49999999999999, -1.599999999999845, 138.19999999999987, 17.900000000000013, 9.499999999999947, 46.70000000000021, 20.000000000000014, 20.000000000000014, -160.6, 120.19999999999993, -133.29999999999995, -59.800000000000125, 116.29999999999947, -108.10000000000011, -38.79999999999988, 20.000000000000014, 18.800000000000153, -143.5000000000002, 167.30000000000004, -222.70000000000033, -43.599999999999994, 20.000000000000014, 20.000000000000014, 15.199999999999955, 20.000000000000014, 53.89999999999998, 4.099999999999977, -79.30000000000003, 20.000000000000014, 47.90000000000002, -118.30000000000013, 5.899999999999999, -82.90000000000069, -129.7000000000005, 20.000000000000014, 55.100000000000016, 45.20000000000023, 4.699999999999967, 22.700000000000014, 26.900000000000027, -19.599999999999753, -14.200000000000092, 24.500000000000075, 7.399999999999965, 34.70000000000012, -1.900000000000039, 28.700000000000024, -5.799999999999946, 24.500000000000032, -101.80000000000024, 16.399999999999963, 55.40000000000022, -15.699999999999747, -51.39999999999999, 20.000000000000014, 41.90000000000024, 20.000000000000014, 24.500000000000075, 12.799999999999981, 20.000000000000014, 19.400000000000023, -45.39999999999995, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 49.700000000000145, -5.200000000000005, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 6.0, 29.0, 0.0, 0.0, 10.0, 0.0, 1.0, 0.0, 7.0, 64.0, 42.0, 43.0, 0.0, 0.0, 1.0, 46.0, 18.0, 16.0, 0.0, 0.0, 11.0, 12.0, 0.0, 0.0, 22.0, 3.0, 5.0, 16.0, 0.0, 1.0, 83.0, 11.0, 0.0, 8.0, 29.0, 20.0, 2.0, 8.0, 0.0, 39.0, 24.0, 18.0, 23.0, 85.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 120.0, 8.0, 39.0, 29.0, 5.0, 71.0, 0.0, 0.0, 22.0, 68.0, 135.0, 30.0, 0.0, 3.0, 34.0, 0.0, 0.0, 37.0, 13.0, 9.0, 6.0, 0.0, 0.0, 24.0, 0.0, 127.0, 2.0, 63.0, 27.0, 1.0, 9.0, 119.0, 167.0, 13.0, 5.0, 12.0, 0.0, 4.0, 0.0, 82.0, 111.0, 22.0, 0.0, 123.0, 129.0, 6.0, 7.0, 3.0, 71.0, 46.0, 38.0, 6.0, 131.0, 45.0, 28.0, 53.0, 0.0, 0.0, 0.0, 39.0, 78.0, 3.0, 133.0, 4.0, 35.0, 42.0, 6.0, 120.0, 99.0, 0.0, 12.0, 96.0, 19.0, 1.0, 2.0, 0.0, 5.0, 0.0, 0.0, 88.0, 0.0, 87.0, 0.0, 0.0, 61.0, 10.0, 18.0, 25.0, 65.0, 123.0, 0.0, 69.0, 18.0, 10.0, 0.0, 0.0, 16.0, 32.0, 30.0, 0.0, 0.0, 25.0, 58.0, 0.0, 95.0, 45.0, 0.0, 0.0, 9.0, 31.0, 27.0, 45.0, 0.0, 17.0, 7.0, 19.0, 16.0, 0.0, 18.0, 31.0, 41.0, 13.0, 15.0, 34.0, 12.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 22.0, 59.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.58903813883532, "mean_inference_ms": 1.779555569622433, "mean_action_processing_ms": 0.2502702097932328, "mean_env_wait_ms": 0.1915089447113464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005237221717834473, "StateBufferConnector_ms": 0.0032095909118652344, "ViewRequirementAgentConnector_ms": 0.09512364864349365}, "num_episodes": 18, "episode_return_max": 226.59999999999937, "episode_return_min": -342.79999999999967, "episode_return_mean": 41.132999999999946, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 392.0195776874685, "num_env_steps_trained_throughput_per_sec": 392.0195776874685, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 10169.869, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10169.828, "sample_time_ms": 1362.986, "learn_time_ms": 8791.66, "learn_throughput": 454.977, "synch_weights_time_ms": 13.626}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "0b081_00000", "date": "2024-08-13_00-52-08", "timestamp": 1723524728, "time_this_iter_s": 10.222490072250366, "time_total_s": 308.90476059913635, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e415e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 308.90476059913635, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 41.28, "ram_util_percent": 83.58666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3632404966447404, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.491789456460842, "policy_loss": -0.0049238227933605825, "vf_loss": 2.4966432116019033, "vf_explained_var": -0.0004744321580917116, "kl": 0.014947052723607851, "entropy": 1.4964166694217258, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4740447126683736, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.751255265745536, "policy_loss": -0.00806185111930722, "vf_loss": 5.756386058797281, "vf_explained_var": 0.03504630478601607, "kl": 0.023159046828719127, "entropy": 1.1534179231477162, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 252.79999999999916, "episode_reward_min": -342.79999999999967, "episode_reward_mean": 40.58999999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -366.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.30000000000004, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": -4.575000000000009, "predator_policy": 24.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [99.49999999999952, 116.29999999999905, -2.8999999999997446, 32.20000000000019, -19.399999999999743, 123.69999999999865, -37.39999999999963, 40.0000000000003, 43.60000000000035, 19.099999999999977, -10.399999999999904, 135.8999999999989, 34.10000000000021, 9.600000000000197, 36.50000000000027, -28.499999999999737, 53.80000000000032, 120.7999999999995, 40.0000000000003, 14.999999999999996, 46.900000000000425, 134.4999999999992, 19.899999999999977, -78.79999999999987, 27.40000000000021, 181.099999999999, -66.99999999999983, 108.99999999999841, 61.89999999999995, 144.49999999999977, -55.599999999999895, 18.499999999999968, -342.79999999999967, 209.29999999999936, 10.800000000000129, 14.20000000000014, -86.99999999999997, 49.40000000000025, 50.999999999999574, 109.29999999999964, -38.59999999999994, -38.29999999999979, 11.500000000000068, 10.600000000000021, -18.499999999999908, 24.700000000000063, 80.9, 159.0999999999993, 61.20000000000044, 40.0000000000003, 47.60000000000016, -106.10000000000142, 69.19999999999908, 9.199999999999946, -34.699999999999754, 67.60000000000002, 63.40000000000017, 45.20000000000026, 89.89999999999998, -13.199999999999982, 67.90000000000023, -29.39999999999992, -117.60000000000116, 120.09999999999965, 58.900000000000475, 107.59999999999988, 11.199999999999683, 55.90000000000034, 67.79999999999986, 40.900000000000176, -5.300000000000072, 99.79999999999879, -21.09999999999951, 63.900000000000496, 44.500000000000306, 53.80000000000036, 55.000000000000234, 30.100000000000147, 40.0000000000003, 40.90000000000031, 56.500000000000334, 40.0000000000003, 88.59999999999872, 252.79999999999916, 158.89999999999895, 65.20000000000041, 1.9000000000001638, 106.19999999999948, 9.700000000000097, 112.59999999999982, 40.0000000000003, -191.10000000000042, 37.80000000000027, 70.60000000000002, 30.900000000000066, 40.0000000000003, 120.99999999999956, 139.8999999999997, 17.900000000000055, 165.9999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [125.29999999999977, -74.80000000000041, 86.29999999999959, 20.000000000000014, 20.000000000000014, -61.90000000000074, 37.70000000000024, -47.49999999999981, -145.0000000000002, 17.600000000000055, 20.000000000000014, 103.69999999999939, -14.79999999999982, -88.60000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -19.899999999999743, 20.000000000000014, 47.900000000000105, -178.3000000000003, -8.500000000000007, 97.39999999999941, 10.399999999999961, -10.299999999999923, 17.899999999999988, -79.3000000000001, -5.500000000000032, 20.000000000000014, -254.20000000000005, 22.700000000000063, 20.000000000000014, 3.800000000000023, -11.499999999999819, 95.29999999999998, 20.000000000000014, 20.000000000000014, -55.00000000000048, 20.000000000000014, 30.800000000000203, 1.0999999999999688, 59.60000000000021, 74.89999999999966, -24.099999999999774, 20.000000000000014, 20.000000000000014, -227.79999999999998, 14.600000000000165, -77.2000000000003, 28.10000000000023, 142.99999999999974, -366.1, 13.099999999999957, 47.90000000000006, 43.10000000000024, 20.000000000000014, 29.900000000000148, 59.3000000000002, 81.19999999999999, -312.4, 63.79999999999997, 20.000000000000014, -23.49999999999975, -329.1999999999998, -265.59999999999997, 91.69999999999953, 104.59999999999995, 20.000000000000014, -83.20000000000005, -45.09999999999998, -24.699999999999875, 20.000000000000014, -243.99999999999997, 36.20000000000009, -59.80000000000021, -56.19999999999993, 54.20000000000021, 83.89999999999986, 25.400000000000006, -170.20000000000005, 14.599999999999964, 13.699999999999946, -188.0, -46.29999999999978, 18.799999999999997, -58.300000000000026, 20.900000000000013, 11.300000000000004, -248.79999999999998, 17.899999999999977, -5.200000000000051, -32.49999999999999, -1.599999999999845, 138.19999999999987, 17.900000000000013, 9.499999999999947, 46.70000000000021, 20.000000000000014, 20.000000000000014, -160.6, 120.19999999999993, -133.29999999999995, -59.800000000000125, 116.29999999999947, -108.10000000000011, -38.79999999999988, 20.000000000000014, 18.800000000000153, -143.5000000000002, 167.30000000000004, -222.70000000000033, -43.599999999999994, 20.000000000000014, 20.000000000000014, 15.199999999999955, 20.000000000000014, 53.89999999999998, 4.099999999999977, -79.30000000000003, 20.000000000000014, 47.90000000000002, -118.30000000000013, 5.899999999999999, -82.90000000000069, -129.7000000000005, 20.000000000000014, 55.100000000000016, 45.20000000000023, 4.699999999999967, 22.700000000000014, 26.900000000000027, -19.599999999999753, -14.200000000000092, 24.500000000000075, 7.399999999999965, 34.70000000000012, -1.900000000000039, 28.700000000000024, -5.799999999999946, 24.500000000000032, -101.80000000000024, 16.399999999999963, 55.40000000000022, -15.699999999999747, -51.39999999999999, 20.000000000000014, 41.90000000000024, 20.000000000000014, 24.500000000000075, 12.799999999999981, 20.000000000000014, 19.400000000000023, -45.39999999999995, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 49.700000000000145, -5.200000000000005, 20.000000000000014, 20.000000000000014, 68.59999999999988, 20.000000000000014, 118.7000000000001, 127.09999999999988, 107.90000000000009, 38.00000000000024, 44.300000000000246, 20.90000000000003, -28.299999999999812, -11.799999999999796, 127.09999999999977, -61.89999999999981, -0.9999999999999952, -7.299999999999891, 79.99999999999972, -63.40000000000026, 20.000000000000014, 20.000000000000014, -286.0, -147.10000000000028, 15.799999999999962, 20.000000000000014, 50.600000000000236, 20.000000000000014, 20.000000000000014, -3.0999999999998833, 20.000000000000014, 20.000000000000014, 71.30000000000021, 49.70000000000021, 68.59999999999974, 71.30000000000021, 3.8000000000000185, -19.899999999999743, 88.39999999999975, 77.59999999999994], "policy_predator_policy_reward": [29.0, 20.0, 2.0, 8.0, 0.0, 39.0, 24.0, 18.0, 23.0, 85.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 120.0, 8.0, 39.0, 29.0, 5.0, 71.0, 0.0, 0.0, 22.0, 68.0, 135.0, 30.0, 0.0, 3.0, 34.0, 0.0, 0.0, 37.0, 13.0, 9.0, 6.0, 0.0, 0.0, 24.0, 0.0, 127.0, 2.0, 63.0, 27.0, 1.0, 9.0, 119.0, 167.0, 13.0, 5.0, 12.0, 0.0, 4.0, 0.0, 82.0, 111.0, 22.0, 0.0, 123.0, 129.0, 6.0, 7.0, 3.0, 71.0, 46.0, 38.0, 6.0, 131.0, 45.0, 28.0, 53.0, 0.0, 0.0, 0.0, 39.0, 78.0, 3.0, 133.0, 4.0, 35.0, 42.0, 6.0, 120.0, 99.0, 0.0, 12.0, 96.0, 19.0, 1.0, 2.0, 0.0, 5.0, 0.0, 0.0, 88.0, 0.0, 87.0, 0.0, 0.0, 61.0, 10.0, 18.0, 25.0, 65.0, 123.0, 0.0, 69.0, 18.0, 10.0, 0.0, 0.0, 16.0, 32.0, 30.0, 0.0, 0.0, 25.0, 58.0, 0.0, 95.0, 45.0, 0.0, 0.0, 9.0, 31.0, 27.0, 45.0, 0.0, 17.0, 7.0, 19.0, 16.0, 0.0, 18.0, 31.0, 41.0, 13.0, 15.0, 34.0, 12.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 22.0, 59.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 42.0, 30.0, 11.0, 18.0, 0.0, 72.0, 24.0, 0.0, 0.0, 106.0, 136.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5885373797243975, "mean_inference_ms": 1.7809262720199497, "mean_action_processing_ms": 0.2546173750767649, "mean_env_wait_ms": 0.19154293613413756, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004652976989746094, "StateBufferConnector_ms": 0.003157973289489746, "ViewRequirementAgentConnector_ms": 0.09597373008728027}, "num_episodes": 18, "episode_return_max": 252.79999999999916, "episode_return_min": -342.79999999999967, "episode_return_mean": 40.58999999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 387.2093901349448, "num_env_steps_trained_throughput_per_sec": 387.2093901349448, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 10208.124, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10208.084, "sample_time_ms": 1376.07, "learn_time_ms": 8817.065, "learn_throughput": 453.666, "synch_weights_time_ms": 13.393}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "0b081_00000", "date": "2024-08-13_00-52-18", "timestamp": 1723524738, "time_this_iter_s": 10.335897207260132, "time_total_s": 319.2406578063965, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327faa280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 319.2406578063965, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 42.986666666666665, "ram_util_percent": 82.72666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3089206023821755, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.791718312546059, "policy_loss": -0.0060094054758785265, "vf_loss": 1.7976436039758108, "vf_explained_var": 0.00713810021915133, "kl": 0.01794481386596094, "entropy": 1.4948158729644048, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.680387181863583, "cur_kl_coeff": 0.18984375000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.903436543891039, "policy_loss": -0.0001193046513156443, "vf_loss": 2.9032466170649047, "vf_explained_var": -0.00121244160586564, "kl": 0.0016288785116608479, "entropy": 1.1852600923921697, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 252.79999999999916, "episode_reward_min": -342.79999999999967, "episode_reward_mean": 42.412999999999904, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -329.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 136.0}, "policy_reward_mean": {"prey_policy": -1.5285000000000184, "predator_policy": 22.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [108.99999999999841, 61.89999999999995, 144.49999999999977, -55.599999999999895, 18.499999999999968, -342.79999999999967, 209.29999999999936, 10.800000000000129, 14.20000000000014, -86.99999999999997, 49.40000000000025, 50.999999999999574, 109.29999999999964, -38.59999999999994, -38.29999999999979, 11.500000000000068, 10.600000000000021, -18.499999999999908, 24.700000000000063, 80.9, 159.0999999999993, 61.20000000000044, 40.0000000000003, 47.60000000000016, -106.10000000000142, 69.19999999999908, 9.199999999999946, -34.699999999999754, 67.60000000000002, 63.40000000000017, 45.20000000000026, 89.89999999999998, -13.199999999999982, 67.90000000000023, -29.39999999999992, -117.60000000000116, 120.09999999999965, 58.900000000000475, 107.59999999999988, 11.199999999999683, 55.90000000000034, 67.79999999999986, 40.900000000000176, -5.300000000000072, 99.79999999999879, -21.09999999999951, 63.900000000000496, 44.500000000000306, 53.80000000000036, 55.000000000000234, 30.100000000000147, 40.0000000000003, 40.90000000000031, 56.500000000000334, 40.0000000000003, 88.59999999999872, 252.79999999999916, 158.89999999999895, 65.20000000000041, 1.9000000000001638, 106.19999999999948, 9.700000000000097, 112.59999999999982, 40.0000000000003, -191.10000000000042, 37.80000000000027, 70.60000000000002, 30.900000000000066, 40.0000000000003, 120.99999999999956, 139.8999999999997, 17.900000000000055, 165.9999999999993, 231.69999999999936, 36.70000000000025, 92.5999999999986, 31.999999999999655, 7.300000000000346, 50.80000000000042, -130.70000000000127, 28.400000000000137, -40.99999999999996, 38.299999999999976, 40.0000000000003, 25.80000000000009, 170.7999999999998, 73.29999999999983, -17.399999999999643, 222.69999999999925, 71.19999999999993, 0.1000000000001432, 111.39999999999951, 78.79999999999933, -7.2999999999996845, 37.80000000000027, -14.999999999999764, 56.30000000000043, 38.199999999999385, 40.0000000000003, -4.999999999999973], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [47.90000000000006, 43.10000000000024, 20.000000000000014, 29.900000000000148, 59.3000000000002, 81.19999999999999, -312.4, 63.79999999999997, 20.000000000000014, -23.49999999999975, -329.1999999999998, -265.59999999999997, 91.69999999999953, 104.59999999999995, 20.000000000000014, -83.20000000000005, -45.09999999999998, -24.699999999999875, 20.000000000000014, -243.99999999999997, 36.20000000000009, -59.80000000000021, -56.19999999999993, 54.20000000000021, 83.89999999999986, 25.400000000000006, -170.20000000000005, 14.599999999999964, 13.699999999999946, -188.0, -46.29999999999978, 18.799999999999997, -58.300000000000026, 20.900000000000013, 11.300000000000004, -248.79999999999998, 17.899999999999977, -5.200000000000051, -32.49999999999999, -1.599999999999845, 138.19999999999987, 17.900000000000013, 9.499999999999947, 46.70000000000021, 20.000000000000014, 20.000000000000014, -160.6, 120.19999999999993, -133.29999999999995, -59.800000000000125, 116.29999999999947, -108.10000000000011, -38.79999999999988, 20.000000000000014, 18.800000000000153, -143.5000000000002, 167.30000000000004, -222.70000000000033, -43.599999999999994, 20.000000000000014, 20.000000000000014, 15.199999999999955, 20.000000000000014, 53.89999999999998, 4.099999999999977, -79.30000000000003, 20.000000000000014, 47.90000000000002, -118.30000000000013, 5.899999999999999, -82.90000000000069, -129.7000000000005, 20.000000000000014, 55.100000000000016, 45.20000000000023, 4.699999999999967, 22.700000000000014, 26.900000000000027, -19.599999999999753, -14.200000000000092, 24.500000000000075, 7.399999999999965, 34.70000000000012, -1.900000000000039, 28.700000000000024, -5.799999999999946, 24.500000000000032, -101.80000000000024, 16.399999999999963, 55.40000000000022, -15.699999999999747, -51.39999999999999, 20.000000000000014, 41.90000000000024, 20.000000000000014, 24.500000000000075, 12.799999999999981, 20.000000000000014, 19.400000000000023, -45.39999999999995, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 49.700000000000145, -5.200000000000005, 20.000000000000014, 20.000000000000014, 68.59999999999988, 20.000000000000014, 118.7000000000001, 127.09999999999988, 107.90000000000009, 38.00000000000024, 44.300000000000246, 20.90000000000003, -28.299999999999812, -11.799999999999796, 127.09999999999977, -61.89999999999981, -0.9999999999999952, -7.299999999999891, 79.99999999999972, -63.40000000000026, 20.000000000000014, 20.000000000000014, -286.0, -147.10000000000028, 15.799999999999962, 20.000000000000014, 50.600000000000236, 20.000000000000014, 20.000000000000014, -3.0999999999998833, 20.000000000000014, 20.000000000000014, 71.30000000000021, 49.70000000000021, 68.59999999999974, 71.30000000000021, 3.8000000000000185, -19.899999999999743, 88.39999999999975, 77.59999999999994, 51.50000000000002, 180.19999999999993, 13.699999999999969, 20.000000000000014, 70.39999999999972, -5.799999999999953, -16.0, -82.00000000000067, -8.499999999999872, -26.19999999999979, 20.000000000000014, 30.800000000000143, -61.90000000000067, -188.80000000000032, 20.000000000000014, -13.599999999999875, -63.10000000000064, -82.90000000000046, 3.500000000000089, -47.19999999999979, 20.000000000000014, 20.000000000000014, -29.199999999999825, 20.000000000000014, 91.99999999999999, 48.800000000000054, 20.000000000000014, 53.30000000000023, -22.900000000000006, -74.50000000000085, 41.60000000000018, 181.09999999999994, 44.30000000000022, 20.90000000000003, 12.499999999999964, -66.40000000000066, -70.30000000000088, 124.69999999999982, 45.800000000000175, 20.000000000000014, -66.10000000000089, 15.799999999999962, 15.799999999999963, 20.000000000000014, 49.7000000000002, -141.70000000000036, 31.100000000000204, 3.19999999999999, 21.800000000000047, -61.60000000000022, 20.000000000000014, 20.000000000000014, 24.500000000000007, -74.50000000000013], "policy_predator_policy_reward": [13.0, 5.0, 12.0, 0.0, 4.0, 0.0, 82.0, 111.0, 22.0, 0.0, 123.0, 129.0, 6.0, 7.0, 3.0, 71.0, 46.0, 38.0, 6.0, 131.0, 45.0, 28.0, 53.0, 0.0, 0.0, 0.0, 39.0, 78.0, 3.0, 133.0, 4.0, 35.0, 42.0, 6.0, 120.0, 99.0, 0.0, 12.0, 96.0, 19.0, 1.0, 2.0, 0.0, 5.0, 0.0, 0.0, 88.0, 0.0, 87.0, 0.0, 0.0, 61.0, 10.0, 18.0, 25.0, 65.0, 123.0, 0.0, 69.0, 18.0, 10.0, 0.0, 0.0, 16.0, 32.0, 30.0, 0.0, 0.0, 25.0, 58.0, 0.0, 95.0, 45.0, 0.0, 0.0, 9.0, 31.0, 27.0, 45.0, 0.0, 17.0, 7.0, 19.0, 16.0, 0.0, 18.0, 31.0, 41.0, 13.0, 15.0, 34.0, 12.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 22.0, 59.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 42.0, 30.0, 11.0, 18.0, 0.0, 72.0, 24.0, 0.0, 0.0, 106.0, 136.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 20.0, 8.0, 56.0, 74.0, 14.0, 28.0, 0.0, 0.0, 22.0, 98.0, 22.0, 0.0, 29.0, 76.0, 68.0, 14.0, 0.0, 0.0, 0.0, 35.0, 29.0, 1.0, 0.0, 0.0, 35.0, 45.0, 0.0, 0.0, 6.0, 0.0, 15.0, 39.0, 43.0, 14.0, 0.0, 13.0, 2.0, 41.0, 0.0, 2.0, 77.0, 0.0, 11.0, 11.0, 68.0, 10.0, 0.0, 0.0, 0.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.588657891086215, "mean_inference_ms": 1.781131731640406, "mean_action_processing_ms": 0.2598548550695656, "mean_env_wait_ms": 0.19174208593195513, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004153251647949219, "StateBufferConnector_ms": 0.00331723690032959, "ViewRequirementAgentConnector_ms": 0.09900200366973877}, "num_episodes": 27, "episode_return_max": 252.79999999999916, "episode_return_min": -342.79999999999967, "episode_return_mean": 42.412999999999904, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 406.2166988675472, "num_env_steps_trained_throughput_per_sec": 406.2166988675472, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 10140.021, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10139.981, "sample_time_ms": 1384.587, "learn_time_ms": 8740.774, "learn_throughput": 457.625, "synch_weights_time_ms": 13.311}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "0b081_00000", "date": "2024-08-13_00-52-28", "timestamp": 1723524748, "time_this_iter_s": 9.850797891616821, "time_total_s": 329.0914556980133, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327faab80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 329.0914556980133, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 43.27857142857143, "ram_util_percent": 82.92142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.39208757249372345, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.680578930289657, "policy_loss": -0.010792328888998816, "vf_loss": 3.6912832899699137, "vf_explained_var": 0.00658747531749584, "kl": 0.018768197401457257, "entropy": 1.4678333888608943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6746477115406562, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.527399180679725, "policy_loss": -0.0016325063701650058, "vf_loss": 4.528240073168719, "vf_explained_var": -0.0006474300667091653, "kl": 0.008339700974003366, "entropy": 1.166632219660219, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 252.79999999999916, "episode_reward_min": -191.10000000000042, "episode_reward_mean": 36.60899999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -286.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 136.0}, "policy_reward_mean": {"prey_policy": -3.1555000000000484, "predator_policy": 21.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.700000000000063, 80.9, 159.0999999999993, 61.20000000000044, 40.0000000000003, 47.60000000000016, -106.10000000000142, 69.19999999999908, 9.199999999999946, -34.699999999999754, 67.60000000000002, 63.40000000000017, 45.20000000000026, 89.89999999999998, -13.199999999999982, 67.90000000000023, -29.39999999999992, -117.60000000000116, 120.09999999999965, 58.900000000000475, 107.59999999999988, 11.199999999999683, 55.90000000000034, 67.79999999999986, 40.900000000000176, -5.300000000000072, 99.79999999999879, -21.09999999999951, 63.900000000000496, 44.500000000000306, 53.80000000000036, 55.000000000000234, 30.100000000000147, 40.0000000000003, 40.90000000000031, 56.500000000000334, 40.0000000000003, 88.59999999999872, 252.79999999999916, 158.89999999999895, 65.20000000000041, 1.9000000000001638, 106.19999999999948, 9.700000000000097, 112.59999999999982, 40.0000000000003, -191.10000000000042, 37.80000000000027, 70.60000000000002, 30.900000000000066, 40.0000000000003, 120.99999999999956, 139.8999999999997, 17.900000000000055, 165.9999999999993, 231.69999999999936, 36.70000000000025, 92.5999999999986, 31.999999999999655, 7.300000000000346, 50.80000000000042, -130.70000000000127, 28.400000000000137, -40.99999999999996, 38.299999999999976, 40.0000000000003, 25.80000000000009, 170.7999999999998, 73.29999999999983, -17.399999999999643, 222.69999999999925, 71.19999999999993, 0.1000000000001432, 111.39999999999951, 78.79999999999933, -7.2999999999996845, 37.80000000000027, -14.999999999999764, 56.30000000000043, 38.199999999999385, 40.0000000000003, -4.999999999999973, -61.79999999999998, -42.49999999999985, 40.90000000000031, 35.60000000000029, -52.59999999999973, -68.90000000000029, -40.59999999999975, -90.4999999999998, -132.3000000000012, 31.000000000000448, 36.0000000000002, 39.0000000000003, -40.799999999999756, 21.50000000000003, -39.299999999999685, -30.29999999999969, 95.79999999999848, -61.400000000000105], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999977, -5.200000000000051, -32.49999999999999, -1.599999999999845, 138.19999999999987, 17.900000000000013, 9.499999999999947, 46.70000000000021, 20.000000000000014, 20.000000000000014, -160.6, 120.19999999999993, -133.29999999999995, -59.800000000000125, 116.29999999999947, -108.10000000000011, -38.79999999999988, 20.000000000000014, 18.800000000000153, -143.5000000000002, 167.30000000000004, -222.70000000000033, -43.599999999999994, 20.000000000000014, 20.000000000000014, 15.199999999999955, 20.000000000000014, 53.89999999999998, 4.099999999999977, -79.30000000000003, 20.000000000000014, 47.90000000000002, -118.30000000000013, 5.899999999999999, -82.90000000000069, -129.7000000000005, 20.000000000000014, 55.100000000000016, 45.20000000000023, 4.699999999999967, 22.700000000000014, 26.900000000000027, -19.599999999999753, -14.200000000000092, 24.500000000000075, 7.399999999999965, 34.70000000000012, -1.900000000000039, 28.700000000000024, -5.799999999999946, 24.500000000000032, -101.80000000000024, 16.399999999999963, 55.40000000000022, -15.699999999999747, -51.39999999999999, 20.000000000000014, 41.90000000000024, 20.000000000000014, 24.500000000000075, 12.799999999999981, 20.000000000000014, 19.400000000000023, -45.39999999999995, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 49.700000000000145, -5.200000000000005, 20.000000000000014, 20.000000000000014, 68.59999999999988, 20.000000000000014, 118.7000000000001, 127.09999999999988, 107.90000000000009, 38.00000000000024, 44.300000000000246, 20.90000000000003, -28.299999999999812, -11.799999999999796, 127.09999999999977, -61.89999999999981, -0.9999999999999952, -7.299999999999891, 79.99999999999972, -63.40000000000026, 20.000000000000014, 20.000000000000014, -286.0, -147.10000000000028, 15.799999999999962, 20.000000000000014, 50.600000000000236, 20.000000000000014, 20.000000000000014, -3.0999999999998833, 20.000000000000014, 20.000000000000014, 71.30000000000021, 49.70000000000021, 68.59999999999974, 71.30000000000021, 3.8000000000000185, -19.899999999999743, 88.39999999999975, 77.59999999999994, 51.50000000000002, 180.19999999999993, 13.699999999999969, 20.000000000000014, 70.39999999999972, -5.799999999999953, -16.0, -82.00000000000067, -8.499999999999872, -26.19999999999979, 20.000000000000014, 30.800000000000143, -61.90000000000067, -188.80000000000032, 20.000000000000014, -13.599999999999875, -63.10000000000064, -82.90000000000046, 3.500000000000089, -47.19999999999979, 20.000000000000014, 20.000000000000014, -29.199999999999825, 20.000000000000014, 91.99999999999999, 48.800000000000054, 20.000000000000014, 53.30000000000023, -22.900000000000006, -74.50000000000085, 41.60000000000018, 181.09999999999994, 44.30000000000022, 20.90000000000003, 12.499999999999964, -66.40000000000066, -70.30000000000088, 124.69999999999982, 45.800000000000175, 20.000000000000014, -66.10000000000089, 15.799999999999962, 15.799999999999963, 20.000000000000014, 49.7000000000002, -141.70000000000036, 31.100000000000204, 3.19999999999999, 21.800000000000047, -61.60000000000022, 20.000000000000014, 20.000000000000014, 24.500000000000007, -74.50000000000013, -129.10000000000045, -15.700000000000056, 20.000000000000014, -137.50000000000026, 20.000000000000014, 20.90000000000003, 15.799999999999988, 15.799999999999994, -132.40000000000063, -5.200000000000051, -5.200000000000049, -141.7000000000007, -187.90000000000003, 41.30000000000022, -213.10000000000008, 11.600000000000007, -208.90000000000052, -87.40000000000069, -24.999999999999815, 20.000000000000014, 1.0999999999999674, 14.899999999999965, 20.000000000000014, -4.000000000000023, 20.90000000000003, -225.70000000000041, -0.4000000000000028, -27.099999999999802, -145.30000000000052, 20.000000000000018, -133.30000000000052, 29.000000000000167, 20.000000000000014, 75.79999999999936, -11.799999999999867, -130.60000000000045], "policy_predator_policy_reward": [0.0, 12.0, 96.0, 19.0, 1.0, 2.0, 0.0, 5.0, 0.0, 0.0, 88.0, 0.0, 87.0, 0.0, 0.0, 61.0, 10.0, 18.0, 25.0, 65.0, 123.0, 0.0, 69.0, 18.0, 10.0, 0.0, 0.0, 16.0, 32.0, 30.0, 0.0, 0.0, 25.0, 58.0, 0.0, 95.0, 45.0, 0.0, 0.0, 9.0, 31.0, 27.0, 45.0, 0.0, 17.0, 7.0, 19.0, 16.0, 0.0, 18.0, 31.0, 41.0, 13.0, 15.0, 34.0, 12.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 22.0, 59.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 42.0, 30.0, 11.0, 18.0, 0.0, 72.0, 24.0, 0.0, 0.0, 106.0, 136.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 20.0, 8.0, 56.0, 74.0, 14.0, 28.0, 0.0, 0.0, 22.0, 98.0, 22.0, 0.0, 29.0, 76.0, 68.0, 14.0, 0.0, 0.0, 0.0, 35.0, 29.0, 1.0, 0.0, 0.0, 35.0, 45.0, 0.0, 0.0, 6.0, 0.0, 15.0, 39.0, 43.0, 14.0, 0.0, 13.0, 2.0, 41.0, 0.0, 2.0, 77.0, 0.0, 11.0, 11.0, 68.0, 10.0, 0.0, 0.0, 0.0, 45.0, 83.0, 0.0, 75.0, 0.0, 0.0, 0.0, 2.0, 2.0, 85.0, 0.0, 45.0, 33.0, 106.0, 0.0, 0.0, 111.0, 55.0, 109.0, 0.0, 36.0, 13.0, 7.0, 6.0, 17.0, 79.0, 85.0, 43.0, 6.0, 0.0, 86.0, 36.0, 38.0, 0.0, 0.0, 20.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5880420032228164, "mean_inference_ms": 1.786221670060519, "mean_action_processing_ms": 0.2593814816838783, "mean_env_wait_ms": 0.19191276001042795, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003981947898864746, "StateBufferConnector_ms": 0.0032879114151000977, "ViewRequirementAgentConnector_ms": 0.09957516193389893}, "num_episodes": 18, "episode_return_max": 252.79999999999916, "episode_return_min": -191.10000000000042, "episode_return_mean": 36.60899999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.6356266554707, "num_env_steps_trained_throughput_per_sec": 404.6356266554707, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 10078.15, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10078.111, "sample_time_ms": 1389.678, "learn_time_ms": 8674.109, "learn_throughput": 461.142, "synch_weights_time_ms": 13.282}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "0b081_00000", "date": "2024-08-13_00-52-38", "timestamp": 1723524758, "time_this_iter_s": 9.891110897064209, "time_total_s": 338.9825665950775, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e4f550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 338.9825665950775, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 39.7, "ram_util_percent": 83.1857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4844369151289501, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.939673899847364, "policy_loss": -0.004495417136482146, "vf_loss": 5.94410786149363, "vf_explained_var": 0.002312158907532061, "kl": 0.013108272987803222, "entropy": 1.4366902443466993, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0526233030847771, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.996044709947374, "policy_loss": -0.003569142729359329, "vf_loss": 6.999027840801017, "vf_explained_var": -0.0036888977522572513, "kl": 0.006173473919419277, "entropy": 1.2174428613728316, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 252.79999999999916, "episode_reward_min": -339.1999999999997, "episode_reward_mean": 17.55699999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -326.20000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -18.121500000000047, "predator_policy": 26.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.09999999999965, 58.900000000000475, 107.59999999999988, 11.199999999999683, 55.90000000000034, 67.79999999999986, 40.900000000000176, -5.300000000000072, 99.79999999999879, -21.09999999999951, 63.900000000000496, 44.500000000000306, 53.80000000000036, 55.000000000000234, 30.100000000000147, 40.0000000000003, 40.90000000000031, 56.500000000000334, 40.0000000000003, 88.59999999999872, 252.79999999999916, 158.89999999999895, 65.20000000000041, 1.9000000000001638, 106.19999999999948, 9.700000000000097, 112.59999999999982, 40.0000000000003, -191.10000000000042, 37.80000000000027, 70.60000000000002, 30.900000000000066, 40.0000000000003, 120.99999999999956, 139.8999999999997, 17.900000000000055, 165.9999999999993, 231.69999999999936, 36.70000000000025, 92.5999999999986, 31.999999999999655, 7.300000000000346, 50.80000000000042, -130.70000000000127, 28.400000000000137, -40.99999999999996, 38.299999999999976, 40.0000000000003, 25.80000000000009, 170.7999999999998, 73.29999999999983, -17.399999999999643, 222.69999999999925, 71.19999999999993, 0.1000000000001432, 111.39999999999951, 78.79999999999933, -7.2999999999996845, 37.80000000000027, -14.999999999999764, 56.30000000000043, 38.199999999999385, 40.0000000000003, -4.999999999999973, -61.79999999999998, -42.49999999999985, 40.90000000000031, 35.60000000000029, -52.59999999999973, -68.90000000000029, -40.59999999999975, -90.4999999999998, -132.3000000000012, 31.000000000000448, 36.0000000000002, 39.0000000000003, -40.799999999999756, 21.50000000000003, -39.299999999999685, -30.29999999999969, 95.79999999999848, -61.400000000000105, 40.70000000000026, 22.100000000000108, 66.10000000000036, 14.600000000000223, 5.100000000000261, 21.400000000000034, 75.79999999999885, -138.30000000000018, -217.4000000000001, -339.1999999999997, -68.40000000000035, -173.7000000000003, -193.4000000000003, -146.60000000000088, -49.69999999999993, -74.10000000000005, -96.70000000000047, -128.60000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 55.100000000000016, 45.20000000000023, 4.699999999999967, 22.700000000000014, 26.900000000000027, -19.599999999999753, -14.200000000000092, 24.500000000000075, 7.399999999999965, 34.70000000000012, -1.900000000000039, 28.700000000000024, -5.799999999999946, 24.500000000000032, -101.80000000000024, 16.399999999999963, 55.40000000000022, -15.699999999999747, -51.39999999999999, 20.000000000000014, 41.90000000000024, 20.000000000000014, 24.500000000000075, 12.799999999999981, 20.000000000000014, 19.400000000000023, -45.39999999999995, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 49.700000000000145, -5.200000000000005, 20.000000000000014, 20.000000000000014, 68.59999999999988, 20.000000000000014, 118.7000000000001, 127.09999999999988, 107.90000000000009, 38.00000000000024, 44.300000000000246, 20.90000000000003, -28.299999999999812, -11.799999999999796, 127.09999999999977, -61.89999999999981, -0.9999999999999952, -7.299999999999891, 79.99999999999972, -63.40000000000026, 20.000000000000014, 20.000000000000014, -286.0, -147.10000000000028, 15.799999999999962, 20.000000000000014, 50.600000000000236, 20.000000000000014, 20.000000000000014, -3.0999999999998833, 20.000000000000014, 20.000000000000014, 71.30000000000021, 49.70000000000021, 68.59999999999974, 71.30000000000021, 3.8000000000000185, -19.899999999999743, 88.39999999999975, 77.59999999999994, 51.50000000000002, 180.19999999999993, 13.699999999999969, 20.000000000000014, 70.39999999999972, -5.799999999999953, -16.0, -82.00000000000067, -8.499999999999872, -26.19999999999979, 20.000000000000014, 30.800000000000143, -61.90000000000067, -188.80000000000032, 20.000000000000014, -13.599999999999875, -63.10000000000064, -82.90000000000046, 3.500000000000089, -47.19999999999979, 20.000000000000014, 20.000000000000014, -29.199999999999825, 20.000000000000014, 91.99999999999999, 48.800000000000054, 20.000000000000014, 53.30000000000023, -22.900000000000006, -74.50000000000085, 41.60000000000018, 181.09999999999994, 44.30000000000022, 20.90000000000003, 12.499999999999964, -66.40000000000066, -70.30000000000088, 124.69999999999982, 45.800000000000175, 20.000000000000014, -66.10000000000089, 15.799999999999962, 15.799999999999963, 20.000000000000014, 49.7000000000002, -141.70000000000036, 31.100000000000204, 3.19999999999999, 21.800000000000047, -61.60000000000022, 20.000000000000014, 20.000000000000014, 24.500000000000007, -74.50000000000013, -129.10000000000045, -15.700000000000056, 20.000000000000014, -137.50000000000026, 20.000000000000014, 20.90000000000003, 15.799999999999988, 15.799999999999994, -132.40000000000063, -5.200000000000051, -5.200000000000049, -141.7000000000007, -187.90000000000003, 41.30000000000022, -213.10000000000008, 11.600000000000007, -208.90000000000052, -87.40000000000069, -24.999999999999815, 20.000000000000014, 1.0999999999999674, 14.899999999999965, 20.000000000000014, -4.000000000000023, 20.90000000000003, -225.70000000000041, -0.4000000000000028, -27.099999999999802, -145.30000000000052, 20.000000000000018, -133.30000000000052, 29.000000000000167, 20.000000000000014, 75.79999999999936, -11.799999999999867, -130.60000000000045, 20.000000000000014, 10.699999999999951, 20.000000000000014, -37.899999999999814, 27.20000000000013, 38.900000000000254, -108.40000000000065, 32.00000000000016, -41.19999999999983, -42.70000000000003, 44.30000000000024, -61.90000000000031, 44.600000000000236, -14.799999999999963, -137.5000000000007, -179.8, -162.70000000000002, -162.7000000000001, -196.00000000000006, -326.20000000000005, -40.89999999999995, -92.50000000000026, -250.90000000000018, -71.80000000000001, -51.99999999999981, -316.40000000000015, -261.4999999999993, -129.10000000000062, -17.199999999999783, -283.49999999999994, -169.0, -12.100000000000032, -198.40000000000032, -37.300000000000026, -250.90000000000012, -15.700000000000026], "policy_predator_policy_reward": [45.0, 0.0, 0.0, 9.0, 31.0, 27.0, 45.0, 0.0, 17.0, 7.0, 19.0, 16.0, 0.0, 18.0, 31.0, 41.0, 13.0, 15.0, 34.0, 12.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 22.0, 59.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 42.0, 30.0, 11.0, 18.0, 0.0, 72.0, 24.0, 0.0, 0.0, 106.0, 136.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 20.0, 8.0, 56.0, 74.0, 14.0, 28.0, 0.0, 0.0, 22.0, 98.0, 22.0, 0.0, 29.0, 76.0, 68.0, 14.0, 0.0, 0.0, 0.0, 35.0, 29.0, 1.0, 0.0, 0.0, 35.0, 45.0, 0.0, 0.0, 6.0, 0.0, 15.0, 39.0, 43.0, 14.0, 0.0, 13.0, 2.0, 41.0, 0.0, 2.0, 77.0, 0.0, 11.0, 11.0, 68.0, 10.0, 0.0, 0.0, 0.0, 45.0, 83.0, 0.0, 75.0, 0.0, 0.0, 0.0, 2.0, 2.0, 85.0, 0.0, 45.0, 33.0, 106.0, 0.0, 0.0, 111.0, 55.0, 109.0, 0.0, 36.0, 13.0, 7.0, 6.0, 17.0, 79.0, 85.0, 43.0, 6.0, 0.0, 86.0, 36.0, 38.0, 0.0, 0.0, 20.0, 61.0, 2.0, 8.0, 40.0, 0.0, 0.0, 0.0, 37.0, 54.0, 66.0, 23.0, 8.0, 31.0, 2.0, 44.0, 163.0, 16.0, 104.0, 4.0, 31.0, 152.0, 65.0, 0.0, 22.0, 127.0, 0.0, 175.0, 84.0, 160.0, 16.0, 235.0, 49.0, 58.0, 130.0, 9.0, 0.0, 138.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5883192759091816, "mean_inference_ms": 1.7901231240077846, "mean_action_processing_ms": 0.25886174926613503, "mean_env_wait_ms": 0.19225605000436707, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004016876220703125, "StateBufferConnector_ms": 0.0033856630325317383, "ViewRequirementAgentConnector_ms": 0.10507214069366455}, "num_episodes": 18, "episode_return_max": 252.79999999999916, "episode_return_min": -339.1999999999997, "episode_return_mean": 17.55699999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 382.6108405480444, "num_env_steps_trained_throughput_per_sec": 382.6108405480444, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 10120.601, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10120.562, "sample_time_ms": 1411.405, "learn_time_ms": 8694.821, "learn_throughput": 460.044, "synch_weights_time_ms": 13.267}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "0b081_00000", "date": "2024-08-13_00-52-48", "timestamp": 1723524768, "time_this_iter_s": 10.463409185409546, "time_total_s": 349.44597578048706, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e4fe50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 349.44597578048706, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 42.65, "ram_util_percent": 83.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6612648809870715, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.465621703516238, "policy_loss": -0.002827890634674717, "vf_loss": 8.46838154389114, "vf_explained_var": 0.010668568636374498, "kl": 0.0145226554518065, "entropy": 1.4340931899333127, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0454690413066634, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.451437398617861, "policy_loss": -0.0016082269996995965, "vf_loss": 7.4522176808150355, "vf_explained_var": -0.0016706711085385116, "kl": 0.008722467209390903, "entropy": 1.2515292990144598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 252.79999999999916, "episode_reward_min": -339.1999999999997, "episode_reward_mean": -8.518000000000088, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 246.0}, "policy_reward_mean": {"prey_policy": -44.31400000000005, "predator_policy": 40.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 88.59999999999872, 252.79999999999916, 158.89999999999895, 65.20000000000041, 1.9000000000001638, 106.19999999999948, 9.700000000000097, 112.59999999999982, 40.0000000000003, -191.10000000000042, 37.80000000000027, 70.60000000000002, 30.900000000000066, 40.0000000000003, 120.99999999999956, 139.8999999999997, 17.900000000000055, 165.9999999999993, 231.69999999999936, 36.70000000000025, 92.5999999999986, 31.999999999999655, 7.300000000000346, 50.80000000000042, -130.70000000000127, 28.400000000000137, -40.99999999999996, 38.299999999999976, 40.0000000000003, 25.80000000000009, 170.7999999999998, 73.29999999999983, -17.399999999999643, 222.69999999999925, 71.19999999999993, 0.1000000000001432, 111.39999999999951, 78.79999999999933, -7.2999999999996845, 37.80000000000027, -14.999999999999764, 56.30000000000043, 38.199999999999385, 40.0000000000003, -4.999999999999973, -61.79999999999998, -42.49999999999985, 40.90000000000031, 35.60000000000029, -52.59999999999973, -68.90000000000029, -40.59999999999975, -90.4999999999998, -132.3000000000012, 31.000000000000448, 36.0000000000002, 39.0000000000003, -40.799999999999756, 21.50000000000003, -39.299999999999685, -30.29999999999969, 95.79999999999848, -61.400000000000105, 40.70000000000026, 22.100000000000108, 66.10000000000036, 14.600000000000223, 5.100000000000261, 21.400000000000034, 75.79999999999885, -138.30000000000018, -217.4000000000001, -339.1999999999997, -68.40000000000035, -173.7000000000003, -193.4000000000003, -146.60000000000088, -49.69999999999993, -74.10000000000005, -96.70000000000047, -128.60000000000005, -105.89999999999979, -101.00000000000028, -139.90000000000006, -107.10000000000008, 37.800000000000296, -279.0000000000002, -89.50000000000003, -95.60000000000002, -106.20000000000019, -28.799999999999834, -24.099999999999916, -7.300000000000045, -178.0000000000002, 8.100000000000092, -275.10000000000014, -198.50000000000023, 23.5000000000002, -20.399999999999913], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 68.59999999999988, 20.000000000000014, 118.7000000000001, 127.09999999999988, 107.90000000000009, 38.00000000000024, 44.300000000000246, 20.90000000000003, -28.299999999999812, -11.799999999999796, 127.09999999999977, -61.89999999999981, -0.9999999999999952, -7.299999999999891, 79.99999999999972, -63.40000000000026, 20.000000000000014, 20.000000000000014, -286.0, -147.10000000000028, 15.799999999999962, 20.000000000000014, 50.600000000000236, 20.000000000000014, 20.000000000000014, -3.0999999999998833, 20.000000000000014, 20.000000000000014, 71.30000000000021, 49.70000000000021, 68.59999999999974, 71.30000000000021, 3.8000000000000185, -19.899999999999743, 88.39999999999975, 77.59999999999994, 51.50000000000002, 180.19999999999993, 13.699999999999969, 20.000000000000014, 70.39999999999972, -5.799999999999953, -16.0, -82.00000000000067, -8.499999999999872, -26.19999999999979, 20.000000000000014, 30.800000000000143, -61.90000000000067, -188.80000000000032, 20.000000000000014, -13.599999999999875, -63.10000000000064, -82.90000000000046, 3.500000000000089, -47.19999999999979, 20.000000000000014, 20.000000000000014, -29.199999999999825, 20.000000000000014, 91.99999999999999, 48.800000000000054, 20.000000000000014, 53.30000000000023, -22.900000000000006, -74.50000000000085, 41.60000000000018, 181.09999999999994, 44.30000000000022, 20.90000000000003, 12.499999999999964, -66.40000000000066, -70.30000000000088, 124.69999999999982, 45.800000000000175, 20.000000000000014, -66.10000000000089, 15.799999999999962, 15.799999999999963, 20.000000000000014, 49.7000000000002, -141.70000000000036, 31.100000000000204, 3.19999999999999, 21.800000000000047, -61.60000000000022, 20.000000000000014, 20.000000000000014, 24.500000000000007, -74.50000000000013, -129.10000000000045, -15.700000000000056, 20.000000000000014, -137.50000000000026, 20.000000000000014, 20.90000000000003, 15.799999999999988, 15.799999999999994, -132.40000000000063, -5.200000000000051, -5.200000000000049, -141.7000000000007, -187.90000000000003, 41.30000000000022, -213.10000000000008, 11.600000000000007, -208.90000000000052, -87.40000000000069, -24.999999999999815, 20.000000000000014, 1.0999999999999674, 14.899999999999965, 20.000000000000014, -4.000000000000023, 20.90000000000003, -225.70000000000041, -0.4000000000000028, -27.099999999999802, -145.30000000000052, 20.000000000000018, -133.30000000000052, 29.000000000000167, 20.000000000000014, 75.79999999999936, -11.799999999999867, -130.60000000000045, 20.000000000000014, 10.699999999999951, 20.000000000000014, -37.899999999999814, 27.20000000000013, 38.900000000000254, -108.40000000000065, 32.00000000000016, -41.19999999999983, -42.70000000000003, 44.30000000000024, -61.90000000000031, 44.600000000000236, -14.799999999999963, -137.5000000000007, -179.8, -162.70000000000002, -162.7000000000001, -196.00000000000006, -326.20000000000005, -40.89999999999995, -92.50000000000026, -250.90000000000018, -71.80000000000001, -51.99999999999981, -316.40000000000015, -261.4999999999993, -129.10000000000062, -17.199999999999783, -283.49999999999994, -169.0, -12.100000000000032, -198.40000000000032, -37.300000000000026, -250.90000000000012, -15.700000000000026, -70.29999999999995, -223.60000000000002, -250.00000000000009, 20.000000000000014, -175.30000000000004, -178.60000000000005, -283.60000000000014, -2.500000000000018, 20.000000000000014, 15.799999999999992, -389.5999999999999, -261.40000000000015, -241.30000000000004, 3.8000000000000385, -134.5000000000002, -150.09999999999982, -250.90000000000026, 7.7000000000000615, 27.20000000000013, -190.00000000000003, -196.3, -59.800000000000566, 20.000000000000014, -70.29999999999993, -143.8, -278.1999999999997, 20.000000000000014, -256.9, -328.8999999999997, -192.2000000000003, -279.3999999999996, -135.09999999999997, -1.000000000000012, 9.499999999999964, -193.0, -30.399999999999764], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 42.0, 30.0, 11.0, 18.0, 0.0, 72.0, 24.0, 0.0, 0.0, 106.0, 136.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 20.0, 8.0, 56.0, 74.0, 14.0, 28.0, 0.0, 0.0, 22.0, 98.0, 22.0, 0.0, 29.0, 76.0, 68.0, 14.0, 0.0, 0.0, 0.0, 35.0, 29.0, 1.0, 0.0, 0.0, 35.0, 45.0, 0.0, 0.0, 6.0, 0.0, 15.0, 39.0, 43.0, 14.0, 0.0, 13.0, 2.0, 41.0, 0.0, 2.0, 77.0, 0.0, 11.0, 11.0, 68.0, 10.0, 0.0, 0.0, 0.0, 45.0, 83.0, 0.0, 75.0, 0.0, 0.0, 0.0, 2.0, 2.0, 85.0, 0.0, 45.0, 33.0, 106.0, 0.0, 0.0, 111.0, 55.0, 109.0, 0.0, 36.0, 13.0, 7.0, 6.0, 17.0, 79.0, 85.0, 43.0, 6.0, 0.0, 86.0, 36.0, 38.0, 0.0, 0.0, 20.0, 61.0, 2.0, 8.0, 40.0, 0.0, 0.0, 0.0, 37.0, 54.0, 66.0, 23.0, 8.0, 31.0, 2.0, 44.0, 163.0, 16.0, 104.0, 4.0, 31.0, 152.0, 65.0, 0.0, 22.0, 127.0, 0.0, 175.0, 84.0, 160.0, 16.0, 235.0, 49.0, 58.0, 130.0, 9.0, 0.0, 138.0, 66.0, 122.0, 51.0, 78.0, 107.0, 107.0, 83.0, 96.0, 2.0, 0.0, 145.0, 227.0, 148.0, 0.0, 125.0, 64.0, 49.0, 88.0, 83.0, 51.0, 84.0, 148.0, 43.0, 0.0, 140.0, 104.0, 134.0, 111.0, 0.0, 246.0, 173.0, 43.0, 5.0, 10.0, 107.0, 96.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5888095676944903, "mean_inference_ms": 1.7943847203671788, "mean_action_processing_ms": 0.2584316415848668, "mean_env_wait_ms": 0.1926786169762896, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040013790130615234, "StateBufferConnector_ms": 0.003363370895385742, "ViewRequirementAgentConnector_ms": 0.10414481163024902}, "num_episodes": 18, "episode_return_max": 252.79999999999916, "episode_return_min": -339.1999999999997, "episode_return_mean": -8.518000000000088, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.4093827205656, "num_env_steps_trained_throughput_per_sec": 391.4093827205656, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 10125.264, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10125.225, "sample_time_ms": 1417.373, "learn_time_ms": 8693.568, "learn_throughput": 460.11, "synch_weights_time_ms": 13.297}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "0b081_00000", "date": "2024-08-13_00-52-58", "timestamp": 1723524778, "time_this_iter_s": 10.224143981933594, "time_total_s": 359.67011976242065, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fb9940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 359.67011976242065, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 37.50666666666667, "ram_util_percent": 83.30666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7694604040453674, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.781370025210911, "policy_loss": -0.0060592763677791315, "vf_loss": 5.787360395956291, "vf_explained_var": 0.015064541498819988, "kl": 0.014697815239548629, "entropy": 1.4371439891517477, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0123957934202972, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.94171531490548, "policy_loss": -0.005851945990115089, "vf_loss": 5.946011310910421, "vf_explained_var": -0.004216546640194282, "kl": 0.016392018088128013, "entropy": 1.25622013044105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 222.69999999999925, "episode_reward_min": -480.3999999999995, "episode_reward_mean": -44.211000000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 246.0}, "policy_reward_mean": {"prey_policy": -76.16050000000004, "predator_policy": 54.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.999999999999655, 7.300000000000346, 50.80000000000042, -130.70000000000127, 28.400000000000137, -40.99999999999996, 38.299999999999976, 40.0000000000003, 25.80000000000009, 170.7999999999998, 73.29999999999983, -17.399999999999643, 222.69999999999925, 71.19999999999993, 0.1000000000001432, 111.39999999999951, 78.79999999999933, -7.2999999999996845, 37.80000000000027, -14.999999999999764, 56.30000000000043, 38.199999999999385, 40.0000000000003, -4.999999999999973, -61.79999999999998, -42.49999999999985, 40.90000000000031, 35.60000000000029, -52.59999999999973, -68.90000000000029, -40.59999999999975, -90.4999999999998, -132.3000000000012, 31.000000000000448, 36.0000000000002, 39.0000000000003, -40.799999999999756, 21.50000000000003, -39.299999999999685, -30.29999999999969, 95.79999999999848, -61.400000000000105, 40.70000000000026, 22.100000000000108, 66.10000000000036, 14.600000000000223, 5.100000000000261, 21.400000000000034, 75.79999999999885, -138.30000000000018, -217.4000000000001, -339.1999999999997, -68.40000000000035, -173.7000000000003, -193.4000000000003, -146.60000000000088, -49.69999999999993, -74.10000000000005, -96.70000000000047, -128.60000000000005, -105.89999999999979, -101.00000000000028, -139.90000000000006, -107.10000000000008, 37.800000000000296, -279.0000000000002, -89.50000000000003, -95.60000000000002, -106.20000000000019, -28.799999999999834, -24.099999999999916, -7.300000000000045, -178.0000000000002, 8.100000000000092, -275.10000000000014, -198.50000000000023, 23.5000000000002, -20.399999999999913, -125.00000000000043, -320.4999999999982, -3.9999999999999054, -80.09999999999997, -68.59999999999982, 47.30000000000031, -11.399999999999778, -40.1999999999996, -9.59999999999989, -67.6000000000003, 7.400000000000379, 17.799999999999947, -371.9000000000001, -18.599999999999724, -64.99999999999997, -28.39999999999992, -95.00000000000017, 4.999999999999984, -167.59999999999985, 18.699999999999847, -41.69999999999967, -480.3999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0, -82.00000000000067, -8.499999999999872, -26.19999999999979, 20.000000000000014, 30.800000000000143, -61.90000000000067, -188.80000000000032, 20.000000000000014, -13.599999999999875, -63.10000000000064, -82.90000000000046, 3.500000000000089, -47.19999999999979, 20.000000000000014, 20.000000000000014, -29.199999999999825, 20.000000000000014, 91.99999999999999, 48.800000000000054, 20.000000000000014, 53.30000000000023, -22.900000000000006, -74.50000000000085, 41.60000000000018, 181.09999999999994, 44.30000000000022, 20.90000000000003, 12.499999999999964, -66.40000000000066, -70.30000000000088, 124.69999999999982, 45.800000000000175, 20.000000000000014, -66.10000000000089, 15.799999999999962, 15.799999999999963, 20.000000000000014, 49.7000000000002, -141.70000000000036, 31.100000000000204, 3.19999999999999, 21.800000000000047, -61.60000000000022, 20.000000000000014, 20.000000000000014, 24.500000000000007, -74.50000000000013, -129.10000000000045, -15.700000000000056, 20.000000000000014, -137.50000000000026, 20.000000000000014, 20.90000000000003, 15.799999999999988, 15.799999999999994, -132.40000000000063, -5.200000000000051, -5.200000000000049, -141.7000000000007, -187.90000000000003, 41.30000000000022, -213.10000000000008, 11.600000000000007, -208.90000000000052, -87.40000000000069, -24.999999999999815, 20.000000000000014, 1.0999999999999674, 14.899999999999965, 20.000000000000014, -4.000000000000023, 20.90000000000003, -225.70000000000041, -0.4000000000000028, -27.099999999999802, -145.30000000000052, 20.000000000000018, -133.30000000000052, 29.000000000000167, 20.000000000000014, 75.79999999999936, -11.799999999999867, -130.60000000000045, 20.000000000000014, 10.699999999999951, 20.000000000000014, -37.899999999999814, 27.20000000000013, 38.900000000000254, -108.40000000000065, 32.00000000000016, -41.19999999999983, -42.70000000000003, 44.30000000000024, -61.90000000000031, 44.600000000000236, -14.799999999999963, -137.5000000000007, -179.8, -162.70000000000002, -162.7000000000001, -196.00000000000006, -326.20000000000005, -40.89999999999995, -92.50000000000026, -250.90000000000018, -71.80000000000001, -51.99999999999981, -316.40000000000015, -261.4999999999993, -129.10000000000062, -17.199999999999783, -283.49999999999994, -169.0, -12.100000000000032, -198.40000000000032, -37.300000000000026, -250.90000000000012, -15.700000000000026, -70.29999999999995, -223.60000000000002, -250.00000000000009, 20.000000000000014, -175.30000000000004, -178.60000000000005, -283.60000000000014, -2.500000000000018, 20.000000000000014, 15.799999999999992, -389.5999999999999, -261.40000000000015, -241.30000000000004, 3.8000000000000385, -134.5000000000002, -150.09999999999982, -250.90000000000026, 7.7000000000000615, 27.20000000000013, -190.00000000000003, -196.3, -59.800000000000566, 20.000000000000014, -70.29999999999993, -143.8, -278.1999999999997, 20.000000000000014, -256.9, -328.8999999999997, -192.2000000000003, -279.3999999999996, -135.09999999999997, -1.000000000000012, 9.499999999999964, -193.0, -30.399999999999764, -253.3000000000001, -57.69999999999994, -284.4999999999989, -226.0000000000004, -64.00000000000061, 20.000000000000014, -15.700000000000014, -219.39999999999998, -32.7999999999998, -260.8, 31.700000000000156, 11.599999999999953, 20.000000000000014, -108.39999999999993, -164.2000000000006, 20.000000000000014, 39.80000000000017, -177.40000000000012, -225.4, -110.20000000000047, -57.700000000000024, 1.0999999999999688, 9.799999999999967, -21.999999999999844, -355.9000000000001, -400.0, -7.0000000000000355, -130.60000000000036, -59.79999999999986, -194.20000000000002, -114.40000000000023, 20.000000000000014, -200.50000000000017, -95.50000000000006, 20.000000000000014, -91.00000000000009, -84.39999999999995, -320.20000000000016, -100.90000000000015, -9.40000000000005, 20.90000000000003, -265.5999999999992, -370.5999999999999, -374.7999999999998], "policy_predator_policy_reward": [56.0, 74.0, 14.0, 28.0, 0.0, 0.0, 22.0, 98.0, 22.0, 0.0, 29.0, 76.0, 68.0, 14.0, 0.0, 0.0, 0.0, 35.0, 29.0, 1.0, 0.0, 0.0, 35.0, 45.0, 0.0, 0.0, 6.0, 0.0, 15.0, 39.0, 43.0, 14.0, 0.0, 13.0, 2.0, 41.0, 0.0, 2.0, 77.0, 0.0, 11.0, 11.0, 68.0, 10.0, 0.0, 0.0, 0.0, 45.0, 83.0, 0.0, 75.0, 0.0, 0.0, 0.0, 2.0, 2.0, 85.0, 0.0, 45.0, 33.0, 106.0, 0.0, 0.0, 111.0, 55.0, 109.0, 0.0, 36.0, 13.0, 7.0, 6.0, 17.0, 79.0, 85.0, 43.0, 6.0, 0.0, 86.0, 36.0, 38.0, 0.0, 0.0, 20.0, 61.0, 2.0, 8.0, 40.0, 0.0, 0.0, 0.0, 37.0, 54.0, 66.0, 23.0, 8.0, 31.0, 2.0, 44.0, 163.0, 16.0, 104.0, 4.0, 31.0, 152.0, 65.0, 0.0, 22.0, 127.0, 0.0, 175.0, 84.0, 160.0, 16.0, 235.0, 49.0, 58.0, 130.0, 9.0, 0.0, 138.0, 66.0, 122.0, 51.0, 78.0, 107.0, 107.0, 83.0, 96.0, 2.0, 0.0, 145.0, 227.0, 148.0, 0.0, 125.0, 64.0, 49.0, 88.0, 83.0, 51.0, 84.0, 148.0, 43.0, 0.0, 140.0, 104.0, 134.0, 111.0, 0.0, 246.0, 173.0, 43.0, 5.0, 10.0, 107.0, 96.0, 88.0, 98.0, 141.0, 49.0, 40.0, 0.0, 113.0, 42.0, 117.0, 108.0, 0.0, 4.0, 0.0, 77.0, 89.0, 15.0, 128.0, 0.0, 131.0, 137.0, 46.0, 18.0, 22.0, 8.0, 185.0, 199.0, 85.0, 34.0, 89.0, 100.0, 15.0, 51.0, 124.0, 77.0, 76.0, 0.0, 132.0, 105.0, 57.0, 72.0, 94.0, 109.0, 65.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5898982765987157, "mean_inference_ms": 1.8003476513016112, "mean_action_processing_ms": 0.2581298793561877, "mean_env_wait_ms": 0.19335441203546452, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039937496185302734, "StateBufferConnector_ms": 0.0034563541412353516, "ViewRequirementAgentConnector_ms": 0.10536742210388184}, "num_episodes": 22, "episode_return_max": 222.69999999999925, "episode_return_min": -480.3999999999995, "episode_return_mean": -44.211000000000006, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 393.90409506130874, "num_env_steps_trained_throughput_per_sec": 393.90409506130874, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 10161.085, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10161.047, "sample_time_ms": 1441.053, "learn_time_ms": 8705.445, "learn_throughput": 459.483, "synch_weights_time_ms": 13.59}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "0b081_00000", "date": "2024-08-13_00-53-09", "timestamp": 1723524789, "time_this_iter_s": 10.159875869750977, "time_total_s": 369.82999563217163, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fa71f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 369.82999563217163, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 38.15714285714285, "ram_util_percent": 83.39285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7825562939087235, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.977274155238318, "policy_loss": -0.006222999386400694, "vf_loss": 6.983402452519331, "vf_explained_var": 0.0001810603040866751, "kl": 0.0201990625396895, "entropy": 1.3607280219673479, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3989610616098005, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.63099588540496, "policy_loss": -0.008416543716549992, "vf_loss": 7.637152930416128, "vf_explained_var": -0.0008790467466626849, "kl": 0.0238039059356099, "entropy": 1.2793904840000092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 118.29999999999866, "episode_reward_min": -480.3999999999995, "episode_reward_mean": -68.42599999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.2000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 98.29999999999939, "predator_policy": 246.0}, "policy_reward_mean": {"prey_policy": -99.47300000000004, "predator_policy": 65.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999973, -61.79999999999998, -42.49999999999985, 40.90000000000031, 35.60000000000029, -52.59999999999973, -68.90000000000029, -40.59999999999975, -90.4999999999998, -132.3000000000012, 31.000000000000448, 36.0000000000002, 39.0000000000003, -40.799999999999756, 21.50000000000003, -39.299999999999685, -30.29999999999969, 95.79999999999848, -61.400000000000105, 40.70000000000026, 22.100000000000108, 66.10000000000036, 14.600000000000223, 5.100000000000261, 21.400000000000034, 75.79999999999885, -138.30000000000018, -217.4000000000001, -339.1999999999997, -68.40000000000035, -173.7000000000003, -193.4000000000003, -146.60000000000088, -49.69999999999993, -74.10000000000005, -96.70000000000047, -128.60000000000005, -105.89999999999979, -101.00000000000028, -139.90000000000006, -107.10000000000008, 37.800000000000296, -279.0000000000002, -89.50000000000003, -95.60000000000002, -106.20000000000019, -28.799999999999834, -24.099999999999916, -7.300000000000045, -178.0000000000002, 8.100000000000092, -275.10000000000014, -198.50000000000023, 23.5000000000002, -20.399999999999913, -125.00000000000043, -320.4999999999982, -3.9999999999999054, -80.09999999999997, -68.59999999999982, 47.30000000000031, -11.399999999999778, -40.1999999999996, -9.59999999999989, -67.6000000000003, 7.400000000000379, 17.799999999999947, -371.9000000000001, -18.599999999999724, -64.99999999999997, -28.39999999999992, -95.00000000000017, 4.999999999999984, -167.59999999999985, 18.699999999999847, -41.69999999999967, -480.3999999999995, 10.700000000000248, 27.3000000000003, -200.80000000000047, 19.89999999999877, 91.09999999999913, -77.19999999999993, -52.60000000000005, -121.80000000000067, -134.89999999999995, -24.299999999999898, -222.3, -281.39999999999975, 2.0000000000001563, -325.59999999999945, 118.29999999999866, -18.39999999999975, -68.69999999999996, -38.19999999999975, 2.19999999999998, -29.89999999999985, 71.7999999999999, -200.3000000000002, -56.59999999999964], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [24.500000000000007, -74.50000000000013, -129.10000000000045, -15.700000000000056, 20.000000000000014, -137.50000000000026, 20.000000000000014, 20.90000000000003, 15.799999999999988, 15.799999999999994, -132.40000000000063, -5.200000000000051, -5.200000000000049, -141.7000000000007, -187.90000000000003, 41.30000000000022, -213.10000000000008, 11.600000000000007, -208.90000000000052, -87.40000000000069, -24.999999999999815, 20.000000000000014, 1.0999999999999674, 14.899999999999965, 20.000000000000014, -4.000000000000023, 20.90000000000003, -225.70000000000041, -0.4000000000000028, -27.099999999999802, -145.30000000000052, 20.000000000000018, -133.30000000000052, 29.000000000000167, 20.000000000000014, 75.79999999999936, -11.799999999999867, -130.60000000000045, 20.000000000000014, 10.699999999999951, 20.000000000000014, -37.899999999999814, 27.20000000000013, 38.900000000000254, -108.40000000000065, 32.00000000000016, -41.19999999999983, -42.70000000000003, 44.30000000000024, -61.90000000000031, 44.600000000000236, -14.799999999999963, -137.5000000000007, -179.8, -162.70000000000002, -162.7000000000001, -196.00000000000006, -326.20000000000005, -40.89999999999995, -92.50000000000026, -250.90000000000018, -71.80000000000001, -51.99999999999981, -316.40000000000015, -261.4999999999993, -129.10000000000062, -17.199999999999783, -283.49999999999994, -169.0, -12.100000000000032, -198.40000000000032, -37.300000000000026, -250.90000000000012, -15.700000000000026, -70.29999999999995, -223.60000000000002, -250.00000000000009, 20.000000000000014, -175.30000000000004, -178.60000000000005, -283.60000000000014, -2.500000000000018, 20.000000000000014, 15.799999999999992, -389.5999999999999, -261.40000000000015, -241.30000000000004, 3.8000000000000385, -134.5000000000002, -150.09999999999982, -250.90000000000026, 7.7000000000000615, 27.20000000000013, -190.00000000000003, -196.3, -59.800000000000566, 20.000000000000014, -70.29999999999993, -143.8, -278.1999999999997, 20.000000000000014, -256.9, -328.8999999999997, -192.2000000000003, -279.3999999999996, -135.09999999999997, -1.000000000000012, 9.499999999999964, -193.0, -30.399999999999764, -253.3000000000001, -57.69999999999994, -284.4999999999989, -226.0000000000004, -64.00000000000061, 20.000000000000014, -15.700000000000014, -219.39999999999998, -32.7999999999998, -260.8, 31.700000000000156, 11.599999999999953, 20.000000000000014, -108.39999999999993, -164.2000000000006, 20.000000000000014, 39.80000000000017, -177.40000000000012, -225.4, -110.20000000000047, -57.700000000000024, 1.0999999999999688, 9.799999999999967, -21.999999999999844, -355.9000000000001, -400.0, -7.0000000000000355, -130.60000000000036, -59.79999999999986, -194.20000000000002, -114.40000000000023, 20.000000000000014, -200.50000000000017, -95.50000000000006, 20.000000000000014, -91.00000000000009, -84.39999999999995, -320.20000000000016, -100.90000000000015, -9.40000000000005, 20.90000000000003, -265.5999999999992, -370.5999999999999, -374.7999999999998, 11.59999999999999, -28.90000000000004, -42.99999999999987, 35.30000000000025, -118.60000000000018, -409.2000000000001, 11.299999999999567, -27.399999999999807, 20.000000000000014, -25.900000000000176, -198.6000000000002, 7.399999999999984, -68.20000000000005, -93.40000000000003, -313.5999999999997, 15.800000000000011, -189.40000000000026, -170.5000000000003, 8.599999999999973, -169.90000000000032, -133.0999999999999, -341.20000000000005, -290.79999999999984, -265.6, -33.39999999999985, -109.60000000000005, -240.70000000000005, -271.9, 98.29999999999939, 20.000000000000014, 20.000000000000014, -243.4000000000003, -158.5000000000005, -26.200000000000017, -36.9999999999998, -62.200000000000685, -27.39999999999978, -33.399999999999864, -219.69999999999996, -5.200000000000003, 20.000000000000014, 15.799999999999958, -177.4000000000004, -274.9, -244.60000000000042, 20.000000000000014], "policy_predator_policy_reward": [0.0, 45.0, 83.0, 0.0, 75.0, 0.0, 0.0, 0.0, 2.0, 2.0, 85.0, 0.0, 45.0, 33.0, 106.0, 0.0, 0.0, 111.0, 55.0, 109.0, 0.0, 36.0, 13.0, 7.0, 6.0, 17.0, 79.0, 85.0, 43.0, 6.0, 0.0, 86.0, 36.0, 38.0, 0.0, 0.0, 20.0, 61.0, 2.0, 8.0, 40.0, 0.0, 0.0, 0.0, 37.0, 54.0, 66.0, 23.0, 8.0, 31.0, 2.0, 44.0, 163.0, 16.0, 104.0, 4.0, 31.0, 152.0, 65.0, 0.0, 22.0, 127.0, 0.0, 175.0, 84.0, 160.0, 16.0, 235.0, 49.0, 58.0, 130.0, 9.0, 0.0, 138.0, 66.0, 122.0, 51.0, 78.0, 107.0, 107.0, 83.0, 96.0, 2.0, 0.0, 145.0, 227.0, 148.0, 0.0, 125.0, 64.0, 49.0, 88.0, 83.0, 51.0, 84.0, 148.0, 43.0, 0.0, 140.0, 104.0, 134.0, 111.0, 0.0, 246.0, 173.0, 43.0, 5.0, 10.0, 107.0, 96.0, 88.0, 98.0, 141.0, 49.0, 40.0, 0.0, 113.0, 42.0, 117.0, 108.0, 0.0, 4.0, 0.0, 77.0, 89.0, 15.0, 128.0, 0.0, 131.0, 137.0, 46.0, 18.0, 22.0, 8.0, 185.0, 199.0, 85.0, 34.0, 89.0, 100.0, 15.0, 51.0, 124.0, 77.0, 76.0, 0.0, 132.0, 105.0, 57.0, 72.0, 94.0, 109.0, 65.0, 200.0, 6.0, 22.0, 5.0, 30.0, 85.0, 242.0, 0.0, 36.0, 61.0, 36.0, 114.0, 0.0, 49.0, 60.0, 18.0, 158.0, 114.0, 111.0, 0.0, 137.0, 224.0, 28.0, 168.0, 107.0, 77.0, 68.0, 0.0, 187.0, 0.0, 0.0, 85.0, 120.0, 72.0, 44.0, 0.0, 61.0, 63.0, 0.0, 92.0, 103.0, 16.0, 20.0, 94.0, 158.0, 85.0, 83.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5908185657077613, "mean_inference_ms": 1.806557025385864, "mean_action_processing_ms": 0.25794124488998127, "mean_env_wait_ms": 0.19412617858030853, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003997445106506348, "StateBufferConnector_ms": 0.0033494234085083008, "ViewRequirementAgentConnector_ms": 0.10607969760894775}, "num_episodes": 23, "episode_return_max": 118.29999999999866, "episode_return_min": -480.3999999999995, "episode_return_mean": -68.42599999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 395.6310929162926, "num_env_steps_trained_throughput_per_sec": 395.6310929162926, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 10188.604, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10188.565, "sample_time_ms": 1450.388, "learn_time_ms": 8723.378, "learn_throughput": 458.538, "synch_weights_time_ms": 13.9}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "0b081_00000", "date": "2024-08-13_00-53-19", "timestamp": 1723524799, "time_this_iter_s": 10.121054887771606, "time_total_s": 379.95105051994324, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fcb3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 379.95105051994324, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 36.973333333333336, "ram_util_percent": 83.33333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6093149366911756, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8748950783537808, "policy_loss": -0.0010644365459306056, "vf_loss": 2.875896359751464, "vf_explained_var": 0.001424663817441022, "kl": 0.008981849115825656, "entropy": 1.4054273168245952, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3434697223639993, "cur_kl_coeff": 0.14238281249999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.810123598512518, "policy_loss": -0.007556421680390717, "vf_loss": 3.8144797127082866, "vf_explained_var": 0.03085337590288233, "kl": 0.02247681250434241, "entropy": 1.2200081343373295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 220.99999999999912, "episode_reward_min": -480.3999999999995, "episode_reward_mean": -54.870000000000026, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.2000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 114.19999999999956, "predator_policy": 246.0}, "policy_reward_mean": {"prey_policy": -92.15500000000003, "predator_policy": 64.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-61.400000000000105, 40.70000000000026, 22.100000000000108, 66.10000000000036, 14.600000000000223, 5.100000000000261, 21.400000000000034, 75.79999999999885, -138.30000000000018, -217.4000000000001, -339.1999999999997, -68.40000000000035, -173.7000000000003, -193.4000000000003, -146.60000000000088, -49.69999999999993, -74.10000000000005, -96.70000000000047, -128.60000000000005, -105.89999999999979, -101.00000000000028, -139.90000000000006, -107.10000000000008, 37.800000000000296, -279.0000000000002, -89.50000000000003, -95.60000000000002, -106.20000000000019, -28.799999999999834, -24.099999999999916, -7.300000000000045, -178.0000000000002, 8.100000000000092, -275.10000000000014, -198.50000000000023, 23.5000000000002, -20.399999999999913, -125.00000000000043, -320.4999999999982, -3.9999999999999054, -80.09999999999997, -68.59999999999982, 47.30000000000031, -11.399999999999778, -40.1999999999996, -9.59999999999989, -67.6000000000003, 7.400000000000379, 17.799999999999947, -371.9000000000001, -18.599999999999724, -64.99999999999997, -28.39999999999992, -95.00000000000017, 4.999999999999984, -167.59999999999985, 18.699999999999847, -41.69999999999967, -480.3999999999995, 10.700000000000248, 27.3000000000003, -200.80000000000047, 19.89999999999877, 91.09999999999913, -77.19999999999993, -52.60000000000005, -121.80000000000067, -134.89999999999995, -24.299999999999898, -222.3, -281.39999999999975, 2.0000000000001563, -325.59999999999945, 118.29999999999866, -18.39999999999975, -68.69999999999996, -38.19999999999975, 2.19999999999998, -29.89999999999985, 71.7999999999999, -200.3000000000002, -56.59999999999964, 65.70000000000012, -5.5999999999999, 69.99999999999993, 20.0000000000002, 25.30000000000009, 92.5999999999994, 30.30000000000026, 81.69999999999919, -4.29999999999988, 20.99999999999995, 42.700000000000344, 120.99999999999899, 220.99999999999912, 93.10000000000008, 31.300000000000153, 66.10000000000024, 46.30000000000017, 32.600000000000186], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.799999999999867, -130.60000000000045, 20.000000000000014, 10.699999999999951, 20.000000000000014, -37.899999999999814, 27.20000000000013, 38.900000000000254, -108.40000000000065, 32.00000000000016, -41.19999999999983, -42.70000000000003, 44.30000000000024, -61.90000000000031, 44.600000000000236, -14.799999999999963, -137.5000000000007, -179.8, -162.70000000000002, -162.7000000000001, -196.00000000000006, -326.20000000000005, -40.89999999999995, -92.50000000000026, -250.90000000000018, -71.80000000000001, -51.99999999999981, -316.40000000000015, -261.4999999999993, -129.10000000000062, -17.199999999999783, -283.49999999999994, -169.0, -12.100000000000032, -198.40000000000032, -37.300000000000026, -250.90000000000012, -15.700000000000026, -70.29999999999995, -223.60000000000002, -250.00000000000009, 20.000000000000014, -175.30000000000004, -178.60000000000005, -283.60000000000014, -2.500000000000018, 20.000000000000014, 15.799999999999992, -389.5999999999999, -261.40000000000015, -241.30000000000004, 3.8000000000000385, -134.5000000000002, -150.09999999999982, -250.90000000000026, 7.7000000000000615, 27.20000000000013, -190.00000000000003, -196.3, -59.800000000000566, 20.000000000000014, -70.29999999999993, -143.8, -278.1999999999997, 20.000000000000014, -256.9, -328.8999999999997, -192.2000000000003, -279.3999999999996, -135.09999999999997, -1.000000000000012, 9.499999999999964, -193.0, -30.399999999999764, -253.3000000000001, -57.69999999999994, -284.4999999999989, -226.0000000000004, -64.00000000000061, 20.000000000000014, -15.700000000000014, -219.39999999999998, -32.7999999999998, -260.8, 31.700000000000156, 11.599999999999953, 20.000000000000014, -108.39999999999993, -164.2000000000006, 20.000000000000014, 39.80000000000017, -177.40000000000012, -225.4, -110.20000000000047, -57.700000000000024, 1.0999999999999688, 9.799999999999967, -21.999999999999844, -355.9000000000001, -400.0, -7.0000000000000355, -130.60000000000036, -59.79999999999986, -194.20000000000002, -114.40000000000023, 20.000000000000014, -200.50000000000017, -95.50000000000006, 20.000000000000014, -91.00000000000009, -84.39999999999995, -320.20000000000016, -100.90000000000015, -9.40000000000005, 20.90000000000003, -265.5999999999992, -370.5999999999999, -374.7999999999998, 11.59999999999999, -28.90000000000004, -42.99999999999987, 35.30000000000025, -118.60000000000018, -409.2000000000001, 11.299999999999567, -27.399999999999807, 20.000000000000014, -25.900000000000176, -198.6000000000002, 7.399999999999984, -68.20000000000005, -93.40000000000003, -313.5999999999997, 15.800000000000011, -189.40000000000026, -170.5000000000003, 8.599999999999973, -169.90000000000032, -133.0999999999999, -341.20000000000005, -290.79999999999984, -265.6, -33.39999999999985, -109.60000000000005, -240.70000000000005, -271.9, 98.29999999999939, 20.000000000000014, 20.000000000000014, -243.4000000000003, -158.5000000000005, -26.200000000000017, -36.9999999999998, -62.200000000000685, -27.39999999999978, -33.399999999999864, -219.69999999999996, -5.200000000000003, 20.000000000000014, 15.799999999999958, -177.4000000000004, -274.9, -244.60000000000042, 20.000000000000014, 45.500000000000114, -17.79999999999974, 17.29999999999998, -337.9000000000001, -42.99999999999979, 82.99999999999937, -45.09999999999976, -22.89999999999982, 35.30000000000017, -60.99999999999984, 74.59999999999974, -15.999999999999803, 46.100000000000136, -175.80000000000032, 58.70000000000021, 20.000000000000014, 28.10000000000015, -99.40000000000057, -19.899999999999743, -161.10000000000002, 22.700000000000063, 20.000000000000014, 67.69999999999995, 53.3000000000001, 114.19999999999956, 102.79999999999956, 68.59999999999995, 24.50000000000008, 7.999999999999969, -3.7000000000000157, 15.199999999999962, 32.90000000000019, 1.9999999999999873, 35.300000000000075, -24.099999999999774, 7.699999999999971], "policy_predator_policy_reward": [20.0, 61.0, 2.0, 8.0, 40.0, 0.0, 0.0, 0.0, 37.0, 54.0, 66.0, 23.0, 8.0, 31.0, 2.0, 44.0, 163.0, 16.0, 104.0, 4.0, 31.0, 152.0, 65.0, 0.0, 22.0, 127.0, 0.0, 175.0, 84.0, 160.0, 16.0, 235.0, 49.0, 58.0, 130.0, 9.0, 0.0, 138.0, 66.0, 122.0, 51.0, 78.0, 107.0, 107.0, 83.0, 96.0, 2.0, 0.0, 145.0, 227.0, 148.0, 0.0, 125.0, 64.0, 49.0, 88.0, 83.0, 51.0, 84.0, 148.0, 43.0, 0.0, 140.0, 104.0, 134.0, 111.0, 0.0, 246.0, 173.0, 43.0, 5.0, 10.0, 107.0, 96.0, 88.0, 98.0, 141.0, 49.0, 40.0, 0.0, 113.0, 42.0, 117.0, 108.0, 0.0, 4.0, 0.0, 77.0, 89.0, 15.0, 128.0, 0.0, 131.0, 137.0, 46.0, 18.0, 22.0, 8.0, 185.0, 199.0, 85.0, 34.0, 89.0, 100.0, 15.0, 51.0, 124.0, 77.0, 76.0, 0.0, 132.0, 105.0, 57.0, 72.0, 94.0, 109.0, 65.0, 200.0, 6.0, 22.0, 5.0, 30.0, 85.0, 242.0, 0.0, 36.0, 61.0, 36.0, 114.0, 0.0, 49.0, 60.0, 18.0, 158.0, 114.0, 111.0, 0.0, 137.0, 224.0, 28.0, 168.0, 107.0, 77.0, 68.0, 0.0, 187.0, 0.0, 0.0, 85.0, 120.0, 72.0, 44.0, 0.0, 61.0, 63.0, 0.0, 92.0, 103.0, 16.0, 20.0, 94.0, 158.0, 85.0, 83.0, 0.0, 38.0, 177.0, 138.0, 0.0, 30.0, 65.0, 23.0, 34.0, 17.0, 18.0, 16.0, 111.0, 49.0, 3.0, 0.0, 17.0, 50.0, 92.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 20.0, 16.0, 2.0, 0.0, 9.0, 22.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5913894348800216, "mean_inference_ms": 1.810710151750042, "mean_action_processing_ms": 0.25777293502177795, "mean_env_wait_ms": 0.19463179647372278, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00397336483001709, "StateBufferConnector_ms": 0.003345489501953125, "ViewRequirementAgentConnector_ms": 0.10682320594787598}, "num_episodes": 18, "episode_return_max": 220.99999999999912, "episode_return_min": -480.3999999999995, "episode_return_mean": -54.870000000000026, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.4370748319657, "num_env_steps_trained_throughput_per_sec": 409.4370748319657, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 10083.347, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10083.309, "sample_time_ms": 1400.612, "learn_time_ms": 8668.282, "learn_throughput": 461.452, "synch_weights_time_ms": 13.578}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "0b081_00000", "date": "2024-08-13_00-53-29", "timestamp": 1723524809, "time_this_iter_s": 9.774060010910034, "time_total_s": 389.72511053085327, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d57280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 389.72511053085327, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 36.06428571428571, "ram_util_percent": 82.99285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48549497049085044, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.36543157084514855, "policy_loss": -0.005109506697645263, "vf_loss": 0.3704265644842828, "vf_explained_var": 0.011015438402771319, "kl": 0.016286341712645532, "entropy": 1.390315233904218, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1412683650378197, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0263799321044373, "policy_loss": -0.0014559932041386015, "vf_loss": 1.0274808177596362, "vf_explained_var": 0.0977519862550907, "kl": 0.001662691085641191, "entropy": 1.245337556215821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 220.99999999999912, "episode_reward_min": -480.3999999999995, "episode_reward_mean": -33.21799999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.2000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 114.19999999999956, "predator_policy": 246.0}, "policy_reward_mean": {"prey_policy": -73.37400000000001, "predator_policy": 56.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-128.60000000000005, -105.89999999999979, -101.00000000000028, -139.90000000000006, -107.10000000000008, 37.800000000000296, -279.0000000000002, -89.50000000000003, -95.60000000000002, -106.20000000000019, -28.799999999999834, -24.099999999999916, -7.300000000000045, -178.0000000000002, 8.100000000000092, -275.10000000000014, -198.50000000000023, 23.5000000000002, -20.399999999999913, -125.00000000000043, -320.4999999999982, -3.9999999999999054, -80.09999999999997, -68.59999999999982, 47.30000000000031, -11.399999999999778, -40.1999999999996, -9.59999999999989, -67.6000000000003, 7.400000000000379, 17.799999999999947, -371.9000000000001, -18.599999999999724, -64.99999999999997, -28.39999999999992, -95.00000000000017, 4.999999999999984, -167.59999999999985, 18.699999999999847, -41.69999999999967, -480.3999999999995, 10.700000000000248, 27.3000000000003, -200.80000000000047, 19.89999999999877, 91.09999999999913, -77.19999999999993, -52.60000000000005, -121.80000000000067, -134.89999999999995, -24.299999999999898, -222.3, -281.39999999999975, 2.0000000000001563, -325.59999999999945, 118.29999999999866, -18.39999999999975, -68.69999999999996, -38.19999999999975, 2.19999999999998, -29.89999999999985, 71.7999999999999, -200.3000000000002, -56.59999999999964, 65.70000000000012, -5.5999999999999, 69.99999999999993, 20.0000000000002, 25.30000000000009, 92.5999999999994, 30.30000000000026, 81.69999999999919, -4.29999999999988, 20.99999999999995, 42.700000000000344, 120.99999999999899, 220.99999999999912, 93.10000000000008, 31.300000000000153, 66.10000000000024, 46.30000000000017, 32.600000000000186, 94.99999999999893, 69.70000000000002, 38.90000000000028, 39.100000000000286, -3.1999999999999225, 19.099999999999966, -16.099999999999568, 25.700000000000077, 118.89999999999915, 50.800000000000466, 77.7999999999995, 48.0000000000002, 71.99999999999982, 41.800000000000296, 35.40000000000024, 46.100000000000406, 61.40000000000038, 31.700000000000184], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-250.90000000000012, -15.700000000000026, -70.29999999999995, -223.60000000000002, -250.00000000000009, 20.000000000000014, -175.30000000000004, -178.60000000000005, -283.60000000000014, -2.500000000000018, 20.000000000000014, 15.799999999999992, -389.5999999999999, -261.40000000000015, -241.30000000000004, 3.8000000000000385, -134.5000000000002, -150.09999999999982, -250.90000000000026, 7.7000000000000615, 27.20000000000013, -190.00000000000003, -196.3, -59.800000000000566, 20.000000000000014, -70.29999999999993, -143.8, -278.1999999999997, 20.000000000000014, -256.9, -328.8999999999997, -192.2000000000003, -279.3999999999996, -135.09999999999997, -1.000000000000012, 9.499999999999964, -193.0, -30.399999999999764, -253.3000000000001, -57.69999999999994, -284.4999999999989, -226.0000000000004, -64.00000000000061, 20.000000000000014, -15.700000000000014, -219.39999999999998, -32.7999999999998, -260.8, 31.700000000000156, 11.599999999999953, 20.000000000000014, -108.39999999999993, -164.2000000000006, 20.000000000000014, 39.80000000000017, -177.40000000000012, -225.4, -110.20000000000047, -57.700000000000024, 1.0999999999999688, 9.799999999999967, -21.999999999999844, -355.9000000000001, -400.0, -7.0000000000000355, -130.60000000000036, -59.79999999999986, -194.20000000000002, -114.40000000000023, 20.000000000000014, -200.50000000000017, -95.50000000000006, 20.000000000000014, -91.00000000000009, -84.39999999999995, -320.20000000000016, -100.90000000000015, -9.40000000000005, 20.90000000000003, -265.5999999999992, -370.5999999999999, -374.7999999999998, 11.59999999999999, -28.90000000000004, -42.99999999999987, 35.30000000000025, -118.60000000000018, -409.2000000000001, 11.299999999999567, -27.399999999999807, 20.000000000000014, -25.900000000000176, -198.6000000000002, 7.399999999999984, -68.20000000000005, -93.40000000000003, -313.5999999999997, 15.800000000000011, -189.40000000000026, -170.5000000000003, 8.599999999999973, -169.90000000000032, -133.0999999999999, -341.20000000000005, -290.79999999999984, -265.6, -33.39999999999985, -109.60000000000005, -240.70000000000005, -271.9, 98.29999999999939, 20.000000000000014, 20.000000000000014, -243.4000000000003, -158.5000000000005, -26.200000000000017, -36.9999999999998, -62.200000000000685, -27.39999999999978, -33.399999999999864, -219.69999999999996, -5.200000000000003, 20.000000000000014, 15.799999999999958, -177.4000000000004, -274.9, -244.60000000000042, 20.000000000000014, 45.500000000000114, -17.79999999999974, 17.29999999999998, -337.9000000000001, -42.99999999999979, 82.99999999999937, -45.09999999999976, -22.89999999999982, 35.30000000000017, -60.99999999999984, 74.59999999999974, -15.999999999999803, 46.100000000000136, -175.80000000000032, 58.70000000000021, 20.000000000000014, 28.10000000000015, -99.40000000000057, -19.899999999999743, -161.10000000000002, 22.700000000000063, 20.000000000000014, 67.69999999999995, 53.3000000000001, 114.19999999999956, 102.79999999999956, 68.59999999999995, 24.50000000000008, 7.999999999999969, -3.7000000000000157, 15.199999999999962, 32.90000000000019, 1.9999999999999873, 35.300000000000075, -24.099999999999774, 7.699999999999971, -5.799999999999953, 75.79999999999947, 14.599999999999966, 37.1000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, 10.09999999999997, -18.999999999999847, -26.199999999999868, 20.000000000000014, -19.899999999999764, 7.9999999999999725, -140.10000000000076, 20.000000000000014, -7.299999999999901, 56.90000000000009, 56.00000000000023, 20.000000000000014, 30.800000000000203, 57.800000000000225, 20.000000000000014, -65.20000000000056, 54.20000000000023, 24.500000000000107, 9.499999999999982, 21.800000000000047, 20.000000000000014, 10.399999999999961, 20.000000000000014, -19.89999999999975, 47.00000000000024, -0.9999999999999846, 52.40000000000019, 23.600000000000083, -16.899999999999757], "policy_predator_policy_reward": [0.0, 138.0, 66.0, 122.0, 51.0, 78.0, 107.0, 107.0, 83.0, 96.0, 2.0, 0.0, 145.0, 227.0, 148.0, 0.0, 125.0, 64.0, 49.0, 88.0, 83.0, 51.0, 84.0, 148.0, 43.0, 0.0, 140.0, 104.0, 134.0, 111.0, 0.0, 246.0, 173.0, 43.0, 5.0, 10.0, 107.0, 96.0, 88.0, 98.0, 141.0, 49.0, 40.0, 0.0, 113.0, 42.0, 117.0, 108.0, 0.0, 4.0, 0.0, 77.0, 89.0, 15.0, 128.0, 0.0, 131.0, 137.0, 46.0, 18.0, 22.0, 8.0, 185.0, 199.0, 85.0, 34.0, 89.0, 100.0, 15.0, 51.0, 124.0, 77.0, 76.0, 0.0, 132.0, 105.0, 57.0, 72.0, 94.0, 109.0, 65.0, 200.0, 6.0, 22.0, 5.0, 30.0, 85.0, 242.0, 0.0, 36.0, 61.0, 36.0, 114.0, 0.0, 49.0, 60.0, 18.0, 158.0, 114.0, 111.0, 0.0, 137.0, 224.0, 28.0, 168.0, 107.0, 77.0, 68.0, 0.0, 187.0, 0.0, 0.0, 85.0, 120.0, 72.0, 44.0, 0.0, 61.0, 63.0, 0.0, 92.0, 103.0, 16.0, 20.0, 94.0, 158.0, 85.0, 83.0, 0.0, 38.0, 177.0, 138.0, 0.0, 30.0, 65.0, 23.0, 34.0, 17.0, 18.0, 16.0, 111.0, 49.0, 3.0, 0.0, 17.0, 50.0, 92.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 20.0, 16.0, 2.0, 0.0, 9.0, 22.0, 27.0, 25.0, 0.0, 18.0, 0.0, 1.0, 0.0, 4.0, 5.0, 40.0, 2.0, 4.0, 15.0, 14.0, 102.0, 0.0, 13.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 38.0, 0.0, 0.0, 5.0, 0.0, 16.0, 3.0, 10.0, 0.0, 25.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5913510707080512, "mean_inference_ms": 1.8126991551361562, "mean_action_processing_ms": 0.25748288713652023, "mean_env_wait_ms": 0.19487517568940188, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039566755294799805, "StateBufferConnector_ms": 0.0038033723831176758, "ViewRequirementAgentConnector_ms": 0.10570394992828369}, "num_episodes": 18, "episode_return_max": 220.99999999999912, "episode_return_min": -480.3999999999995, "episode_return_mean": -33.21799999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 385.9380673647293, "num_env_steps_trained_throughput_per_sec": 385.9380673647293, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 10133.938, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10133.899, "sample_time_ms": 1398.379, "learn_time_ms": 8720.812, "learn_throughput": 458.673, "synch_weights_time_ms": 13.564}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "0b081_00000", "date": "2024-08-13_00-53-39", "timestamp": 1723524819, "time_this_iter_s": 10.394999980926514, "time_total_s": 400.1201105117798, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fcbdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 400.1201105117798, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 36.25000000000001, "ram_util_percent": 83.10000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3970287032070614, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23618863124262404, "policy_loss": -0.0049869587112750325, "vf_loss": 0.24104932126830572, "vf_explained_var": 0.0007798787778016752, "kl": 0.017958265156459145, "entropy": 1.458082610274118, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8593649168769834, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6869675796774645, "policy_loss": -0.0023268293361450552, "vf_loss": 0.68851803740112, "vf_explained_var": 0.11775378610091235, "kl": 0.0072702747403136665, "entropy": 1.2668979460600192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 220.99999999999912, "episode_reward_min": -480.3999999999995, "episode_reward_mean": -0.6989999999999681, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.2000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 114.19999999999956, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": -39.42949999999999, "predator_policy": 39.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-80.09999999999997, -68.59999999999982, 47.30000000000031, -11.399999999999778, -40.1999999999996, -9.59999999999989, -67.6000000000003, 7.400000000000379, 17.799999999999947, -371.9000000000001, -18.599999999999724, -64.99999999999997, -28.39999999999992, -95.00000000000017, 4.999999999999984, -167.59999999999985, 18.699999999999847, -41.69999999999967, -480.3999999999995, 10.700000000000248, 27.3000000000003, -200.80000000000047, 19.89999999999877, 91.09999999999913, -77.19999999999993, -52.60000000000005, -121.80000000000067, -134.89999999999995, -24.299999999999898, -222.3, -281.39999999999975, 2.0000000000001563, -325.59999999999945, 118.29999999999866, -18.39999999999975, -68.69999999999996, -38.19999999999975, 2.19999999999998, -29.89999999999985, 71.7999999999999, -200.3000000000002, -56.59999999999964, 65.70000000000012, -5.5999999999999, 69.99999999999993, 20.0000000000002, 25.30000000000009, 92.5999999999994, 30.30000000000026, 81.69999999999919, -4.29999999999988, 20.99999999999995, 42.700000000000344, 120.99999999999899, 220.99999999999912, 93.10000000000008, 31.300000000000153, 66.10000000000024, 46.30000000000017, 32.600000000000186, 94.99999999999893, 69.70000000000002, 38.90000000000028, 39.100000000000286, -3.1999999999999225, 19.099999999999966, -16.099999999999568, 25.700000000000077, 118.89999999999915, 50.800000000000466, 77.7999999999995, 48.0000000000002, 71.99999999999982, 41.800000000000296, 35.40000000000024, 46.100000000000406, 61.40000000000038, 31.700000000000184, 20.8, 37.30000000000026, 50.70000000000048, 59.80000000000051, 69.00000000000001, 16.90000000000002, 75.79999999999967, 24.60000000000005, 40.0000000000003, 40.0000000000003, 89.4999999999988, 49.40000000000042, 34.50000000000022, 35.600000000000236, 34.50000000000022, 67.90000000000019, 23.100000000000026, 26.80000000000009, 48.100000000000385, 54.40000000000052, 48.10000000000039, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.700000000000014, -219.39999999999998, -32.7999999999998, -260.8, 31.700000000000156, 11.599999999999953, 20.000000000000014, -108.39999999999993, -164.2000000000006, 20.000000000000014, 39.80000000000017, -177.40000000000012, -225.4, -110.20000000000047, -57.700000000000024, 1.0999999999999688, 9.799999999999967, -21.999999999999844, -355.9000000000001, -400.0, -7.0000000000000355, -130.60000000000036, -59.79999999999986, -194.20000000000002, -114.40000000000023, 20.000000000000014, -200.50000000000017, -95.50000000000006, 20.000000000000014, -91.00000000000009, -84.39999999999995, -320.20000000000016, -100.90000000000015, -9.40000000000005, 20.90000000000003, -265.5999999999992, -370.5999999999999, -374.7999999999998, 11.59999999999999, -28.90000000000004, -42.99999999999987, 35.30000000000025, -118.60000000000018, -409.2000000000001, 11.299999999999567, -27.399999999999807, 20.000000000000014, -25.900000000000176, -198.6000000000002, 7.399999999999984, -68.20000000000005, -93.40000000000003, -313.5999999999997, 15.800000000000011, -189.40000000000026, -170.5000000000003, 8.599999999999973, -169.90000000000032, -133.0999999999999, -341.20000000000005, -290.79999999999984, -265.6, -33.39999999999985, -109.60000000000005, -240.70000000000005, -271.9, 98.29999999999939, 20.000000000000014, 20.000000000000014, -243.4000000000003, -158.5000000000005, -26.200000000000017, -36.9999999999998, -62.200000000000685, -27.39999999999978, -33.399999999999864, -219.69999999999996, -5.200000000000003, 20.000000000000014, 15.799999999999958, -177.4000000000004, -274.9, -244.60000000000042, 20.000000000000014, 45.500000000000114, -17.79999999999974, 17.29999999999998, -337.9000000000001, -42.99999999999979, 82.99999999999937, -45.09999999999976, -22.89999999999982, 35.30000000000017, -60.99999999999984, 74.59999999999974, -15.999999999999803, 46.100000000000136, -175.80000000000032, 58.70000000000021, 20.000000000000014, 28.10000000000015, -99.40000000000057, -19.899999999999743, -161.10000000000002, 22.700000000000063, 20.000000000000014, 67.69999999999995, 53.3000000000001, 114.19999999999956, 102.79999999999956, 68.59999999999995, 24.50000000000008, 7.999999999999969, -3.7000000000000157, 15.199999999999962, 32.90000000000019, 1.9999999999999873, 35.300000000000075, -24.099999999999774, 7.699999999999971, -5.799999999999953, 75.79999999999947, 14.599999999999966, 37.1000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, 10.09999999999997, -18.999999999999847, -26.199999999999868, 20.000000000000014, -19.899999999999764, 7.9999999999999725, -140.10000000000076, 20.000000000000014, -7.299999999999901, 56.90000000000009, 56.00000000000023, 20.000000000000014, 30.800000000000203, 57.800000000000225, 20.000000000000014, -65.20000000000056, 54.20000000000023, 24.500000000000107, 9.499999999999982, 21.800000000000047, 20.000000000000014, 10.399999999999961, 20.000000000000014, -19.89999999999975, 47.00000000000024, -0.9999999999999846, 52.40000000000019, 23.600000000000083, -16.899999999999757, -0.9999999999999846, 9.799999999999967, 8.299999999999969, 20.000000000000014, 20.000000000000014, 25.70000000000011, 20.000000000000014, 39.80000000000025, 45.20000000000016, 15.799999999999962, -14.199999999999838, 1.099999999999983, 28.100000000000147, 46.70000000000024, -9.399999999999862, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000017, 37.10000000000025, 17.299999999999976, 1.0999999999999794, 9.499999999999964, 20.000000000000014, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, 30.800000000000196, 37.10000000000023, -15.699999999999747, 21.80000000000004, 20.000000000000014, -5.1999999999999265, 22.700000000000053, 25.400000000000112, 20.000000000000014, 34.40000000000026, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [113.0, 42.0, 117.0, 108.0, 0.0, 4.0, 0.0, 77.0, 89.0, 15.0, 128.0, 0.0, 131.0, 137.0, 46.0, 18.0, 22.0, 8.0, 185.0, 199.0, 85.0, 34.0, 89.0, 100.0, 15.0, 51.0, 124.0, 77.0, 76.0, 0.0, 132.0, 105.0, 57.0, 72.0, 94.0, 109.0, 65.0, 200.0, 6.0, 22.0, 5.0, 30.0, 85.0, 242.0, 0.0, 36.0, 61.0, 36.0, 114.0, 0.0, 49.0, 60.0, 18.0, 158.0, 114.0, 111.0, 0.0, 137.0, 224.0, 28.0, 168.0, 107.0, 77.0, 68.0, 0.0, 187.0, 0.0, 0.0, 85.0, 120.0, 72.0, 44.0, 0.0, 61.0, 63.0, 0.0, 92.0, 103.0, 16.0, 20.0, 94.0, 158.0, 85.0, 83.0, 0.0, 38.0, 177.0, 138.0, 0.0, 30.0, 65.0, 23.0, 34.0, 17.0, 18.0, 16.0, 111.0, 49.0, 3.0, 0.0, 17.0, 50.0, 92.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 20.0, 16.0, 2.0, 0.0, 9.0, 22.0, 27.0, 25.0, 0.0, 18.0, 0.0, 1.0, 0.0, 4.0, 5.0, 40.0, 2.0, 4.0, 15.0, 14.0, 102.0, 0.0, 13.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 38.0, 0.0, 0.0, 5.0, 0.0, 16.0, 3.0, 10.0, 0.0, 25.0, 0.0, 12.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 30.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 5.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 16.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5912503939006579, "mean_inference_ms": 1.8154336840154683, "mean_action_processing_ms": 0.25716193832085577, "mean_env_wait_ms": 0.1951359079197131, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040062665939331055, "StateBufferConnector_ms": 0.0037915706634521484, "ViewRequirementAgentConnector_ms": 0.10533106327056885}, "num_episodes": 22, "episode_return_max": 220.99999999999912, "episode_return_min": -480.3999999999995, "episode_return_mean": -0.6989999999999681, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 405.5656907398001, "num_env_steps_trained_throughput_per_sec": 405.5656907398001, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 10099.858, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10099.82, "sample_time_ms": 1407.102, "learn_time_ms": 8678.01, "learn_throughput": 460.935, "synch_weights_time_ms": 13.583}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "0b081_00000", "date": "2024-08-13_00-53-49", "timestamp": 1723524829, "time_this_iter_s": 9.867634296417236, "time_total_s": 409.987744808197, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fcb5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 409.987744808197, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 37.85000000000001, "ram_util_percent": 83.28571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4330776684340977, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6315142237635517, "policy_loss": -0.003055628658661609, "vf_loss": 0.6344907488417688, "vf_explained_var": 0.012118277820960555, "kl": 0.011250569301750696, "entropy": 1.4488150187901088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0324193755076045, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.013869350616421, "policy_loss": -0.0031767858128265414, "vf_loss": 1.0155678873260816, "vf_explained_var": 0.007436885404839087, "kl": 0.013842976947278903, "entropy": 1.2645919632659388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 220.99999999999912, "episode_reward_min": -325.59999999999945, "episode_reward_mean": 24.85800000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -341.20000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 114.19999999999956, "predator_policy": 224.0}, "policy_reward_mean": {"prey_policy": -10.830999999999985, "predator_policy": 23.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [91.09999999999913, -77.19999999999993, -52.60000000000005, -121.80000000000067, -134.89999999999995, -24.299999999999898, -222.3, -281.39999999999975, 2.0000000000001563, -325.59999999999945, 118.29999999999866, -18.39999999999975, -68.69999999999996, -38.19999999999975, 2.19999999999998, -29.89999999999985, 71.7999999999999, -200.3000000000002, -56.59999999999964, 65.70000000000012, -5.5999999999999, 69.99999999999993, 20.0000000000002, 25.30000000000009, 92.5999999999994, 30.30000000000026, 81.69999999999919, -4.29999999999988, 20.99999999999995, 42.700000000000344, 120.99999999999899, 220.99999999999912, 93.10000000000008, 31.300000000000153, 66.10000000000024, 46.30000000000017, 32.600000000000186, 94.99999999999893, 69.70000000000002, 38.90000000000028, 39.100000000000286, -3.1999999999999225, 19.099999999999966, -16.099999999999568, 25.700000000000077, 118.89999999999915, 50.800000000000466, 77.7999999999995, 48.0000000000002, 71.99999999999982, 41.800000000000296, 35.40000000000024, 46.100000000000406, 61.40000000000038, 31.700000000000184, 20.8, 37.30000000000026, 50.70000000000048, 59.80000000000051, 69.00000000000001, 16.90000000000002, 75.79999999999967, 24.60000000000005, 40.0000000000003, 40.0000000000003, 89.4999999999988, 49.40000000000042, 34.50000000000022, 35.600000000000236, 34.50000000000022, 67.90000000000019, 23.100000000000026, 26.80000000000009, 48.100000000000385, 54.40000000000052, 48.10000000000039, 40.0000000000003, 23.500000000000036, 40.0000000000003, 40.0000000000003, 56.70000000000041, 37.80000000000027, 6.700000000000154, 47.000000000000426, 81.39999999999922, 19.099999999999977, 53.500000000000526, 58.70000000000047, 40.0000000000003, 48.10000000000043, 31.300000000000164, 26.80000000000009, 23.200000000000035, 72.39999999999986, 50.80000000000048, 40.90000000000031, 55.300000000000516, 36.90000000000027, 32.80000000000019, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -25.900000000000176, -198.6000000000002, 7.399999999999984, -68.20000000000005, -93.40000000000003, -313.5999999999997, 15.800000000000011, -189.40000000000026, -170.5000000000003, 8.599999999999973, -169.90000000000032, -133.0999999999999, -341.20000000000005, -290.79999999999984, -265.6, -33.39999999999985, -109.60000000000005, -240.70000000000005, -271.9, 98.29999999999939, 20.000000000000014, 20.000000000000014, -243.4000000000003, -158.5000000000005, -26.200000000000017, -36.9999999999998, -62.200000000000685, -27.39999999999978, -33.399999999999864, -219.69999999999996, -5.200000000000003, 20.000000000000014, 15.799999999999958, -177.4000000000004, -274.9, -244.60000000000042, 20.000000000000014, 45.500000000000114, -17.79999999999974, 17.29999999999998, -337.9000000000001, -42.99999999999979, 82.99999999999937, -45.09999999999976, -22.89999999999982, 35.30000000000017, -60.99999999999984, 74.59999999999974, -15.999999999999803, 46.100000000000136, -175.80000000000032, 58.70000000000021, 20.000000000000014, 28.10000000000015, -99.40000000000057, -19.899999999999743, -161.10000000000002, 22.700000000000063, 20.000000000000014, 67.69999999999995, 53.3000000000001, 114.19999999999956, 102.79999999999956, 68.59999999999995, 24.50000000000008, 7.999999999999969, -3.7000000000000157, 15.199999999999962, 32.90000000000019, 1.9999999999999873, 35.300000000000075, -24.099999999999774, 7.699999999999971, -5.799999999999953, 75.79999999999947, 14.599999999999966, 37.1000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, 10.09999999999997, -18.999999999999847, -26.199999999999868, 20.000000000000014, -19.899999999999764, 7.9999999999999725, -140.10000000000076, 20.000000000000014, -7.299999999999901, 56.90000000000009, 56.00000000000023, 20.000000000000014, 30.800000000000203, 57.800000000000225, 20.000000000000014, -65.20000000000056, 54.20000000000023, 24.500000000000107, 9.499999999999982, 21.800000000000047, 20.000000000000014, 10.399999999999961, 20.000000000000014, -19.89999999999975, 47.00000000000024, -0.9999999999999846, 52.40000000000019, 23.600000000000083, -16.899999999999757, -0.9999999999999846, 9.799999999999967, 8.299999999999969, 20.000000000000014, 20.000000000000014, 25.70000000000011, 20.000000000000014, 39.80000000000025, 45.20000000000016, 15.799999999999962, -14.199999999999838, 1.099999999999983, 28.100000000000147, 46.70000000000024, -9.399999999999862, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000017, 37.10000000000025, 17.299999999999976, 1.0999999999999794, 9.499999999999964, 20.000000000000014, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, 30.800000000000196, 37.10000000000023, -15.699999999999747, 21.80000000000004, 20.000000000000014, -5.1999999999999265, 22.700000000000053, 25.400000000000112, 20.000000000000014, 34.40000000000026, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999972, 11.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999978, 13.999999999999966, 15.799999999999963, 20.000000000000014, -0.9999999999999917, -7.299999999999891, 16.999999999999975, 20.000000000000014, 20.000000000000014, 61.40000000000021, 20.000000000000014, -19.899999999999743, 33.50000000000024, 20.000000000000014, 28.70000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 27.20000000000013, 20.000000000000014, -9.699999999999918, 20.000000000000014, -5.1999999999999265, 11.599999999999977, -3.399999999999983, 20.000000000000014, 43.400000000000205, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, 35.30000000000024, 3.199999999999972, 22.700000000000067, 20.000000000000014, -5.1999999999999655, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [61.0, 36.0, 114.0, 0.0, 49.0, 60.0, 18.0, 158.0, 114.0, 111.0, 0.0, 137.0, 224.0, 28.0, 168.0, 107.0, 77.0, 68.0, 0.0, 187.0, 0.0, 0.0, 85.0, 120.0, 72.0, 44.0, 0.0, 61.0, 63.0, 0.0, 92.0, 103.0, 16.0, 20.0, 94.0, 158.0, 85.0, 83.0, 0.0, 38.0, 177.0, 138.0, 0.0, 30.0, 65.0, 23.0, 34.0, 17.0, 18.0, 16.0, 111.0, 49.0, 3.0, 0.0, 17.0, 50.0, 92.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 20.0, 16.0, 2.0, 0.0, 9.0, 22.0, 27.0, 25.0, 0.0, 18.0, 0.0, 1.0, 0.0, 4.0, 5.0, 40.0, 2.0, 4.0, 15.0, 14.0, 102.0, 0.0, 13.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 38.0, 0.0, 0.0, 5.0, 0.0, 16.0, 3.0, 10.0, 0.0, 25.0, 0.0, 12.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 30.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 5.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 16.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 5.0, 24.0, 0.0, 2.0, 15.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 7.0, 0.0, 12.0, 0.0, 15.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 18.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5909597131992317, "mean_inference_ms": 1.812827540281263, "mean_action_processing_ms": 0.25640311216885264, "mean_env_wait_ms": 0.19514976973955814, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003953099250793457, "StateBufferConnector_ms": 0.004472851753234863, "ViewRequirementAgentConnector_ms": 0.10209190845489502}, "num_episodes": 23, "episode_return_max": 220.99999999999912, "episode_return_min": -325.59999999999945, "episode_return_mean": 24.85800000000007, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.79056780686756, "num_env_steps_trained_throughput_per_sec": 402.79056780686756, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 10059.897, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10059.859, "sample_time_ms": 1391.664, "learn_time_ms": 8653.332, "learn_throughput": 462.25, "synch_weights_time_ms": 13.737}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "0b081_00000", "date": "2024-08-13_00-53-59", "timestamp": 1723524839, "time_this_iter_s": 9.93718409538269, "time_total_s": 419.9249289035797, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fa7dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 419.9249289035797, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 36.32857142857143, "ram_util_percent": 83.21428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6385462732305602, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1372516925372773, "policy_loss": -0.004537547363717326, "vf_loss": 3.1416707396507264, "vf_explained_var": 0.003193768338551597, "kl": 0.016853773001257705, "entropy": 1.365180026601862, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0281755656831795, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2942473073485035, "policy_loss": -0.008321007628181071, "vf_loss": 3.3003323768181776, "vf_explained_var": 0.0072962829044886995, "kl": 0.020938218306082095, "entropy": 1.2246198950621185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 220.99999999999912, "episode_reward_min": -236.40000000000012, "episode_reward_mean": 40.95900000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 114.19999999999956, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": 6.22450000000003, "predator_policy": 14.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-56.59999999999964, 65.70000000000012, -5.5999999999999, 69.99999999999993, 20.0000000000002, 25.30000000000009, 92.5999999999994, 30.30000000000026, 81.69999999999919, -4.29999999999988, 20.99999999999995, 42.700000000000344, 120.99999999999899, 220.99999999999912, 93.10000000000008, 31.300000000000153, 66.10000000000024, 46.30000000000017, 32.600000000000186, 94.99999999999893, 69.70000000000002, 38.90000000000028, 39.100000000000286, -3.1999999999999225, 19.099999999999966, -16.099999999999568, 25.700000000000077, 118.89999999999915, 50.800000000000466, 77.7999999999995, 48.0000000000002, 71.99999999999982, 41.800000000000296, 35.40000000000024, 46.100000000000406, 61.40000000000038, 31.700000000000184, 20.8, 37.30000000000026, 50.70000000000048, 59.80000000000051, 69.00000000000001, 16.90000000000002, 75.79999999999967, 24.60000000000005, 40.0000000000003, 40.0000000000003, 89.4999999999988, 49.40000000000042, 34.50000000000022, 35.600000000000236, 34.50000000000022, 67.90000000000019, 23.100000000000026, 26.80000000000009, 48.100000000000385, 54.40000000000052, 48.10000000000039, 40.0000000000003, 23.500000000000036, 40.0000000000003, 40.0000000000003, 56.70000000000041, 37.80000000000027, 6.700000000000154, 47.000000000000426, 81.39999999999922, 19.099999999999977, 53.500000000000526, 58.70000000000047, 40.0000000000003, 48.10000000000043, 31.300000000000164, 26.80000000000009, 23.200000000000035, 72.39999999999986, 50.80000000000048, 40.90000000000031, 55.300000000000516, 36.90000000000027, 32.80000000000019, 40.0000000000003, 58.30000000000042, 29.70000000000033, 108.79999999999882, 21.20000000000001, 10.199999999999953, 32.30000000000017, 69.89999999999995, -236.40000000000012, 19.300000000000026, -0.8000000000000256, 85.19999999999942, 6.300000000000017, 40.0000000000003, 9.900000000000018, 49.20000000000043, 26.900000000000453, -6.999999999999707, -23.099999999999575], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-244.60000000000042, 20.000000000000014, 45.500000000000114, -17.79999999999974, 17.29999999999998, -337.9000000000001, -42.99999999999979, 82.99999999999937, -45.09999999999976, -22.89999999999982, 35.30000000000017, -60.99999999999984, 74.59999999999974, -15.999999999999803, 46.100000000000136, -175.80000000000032, 58.70000000000021, 20.000000000000014, 28.10000000000015, -99.40000000000057, -19.899999999999743, -161.10000000000002, 22.700000000000063, 20.000000000000014, 67.69999999999995, 53.3000000000001, 114.19999999999956, 102.79999999999956, 68.59999999999995, 24.50000000000008, 7.999999999999969, -3.7000000000000157, 15.199999999999962, 32.90000000000019, 1.9999999999999873, 35.300000000000075, -24.099999999999774, 7.699999999999971, -5.799999999999953, 75.79999999999947, 14.599999999999966, 37.1000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, 10.09999999999997, -18.999999999999847, -26.199999999999868, 20.000000000000014, -19.899999999999764, 7.9999999999999725, -140.10000000000076, 20.000000000000014, -7.299999999999901, 56.90000000000009, 56.00000000000023, 20.000000000000014, 30.800000000000203, 57.800000000000225, 20.000000000000014, -65.20000000000056, 54.20000000000023, 24.500000000000107, 9.499999999999982, 21.800000000000047, 20.000000000000014, 10.399999999999961, 20.000000000000014, -19.89999999999975, 47.00000000000024, -0.9999999999999846, 52.40000000000019, 23.600000000000083, -16.899999999999757, -0.9999999999999846, 9.799999999999967, 8.299999999999969, 20.000000000000014, 20.000000000000014, 25.70000000000011, 20.000000000000014, 39.80000000000025, 45.20000000000016, 15.799999999999962, -14.199999999999838, 1.099999999999983, 28.100000000000147, 46.70000000000024, -9.399999999999862, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000017, 37.10000000000025, 17.299999999999976, 1.0999999999999794, 9.499999999999964, 20.000000000000014, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, 30.800000000000196, 37.10000000000023, -15.699999999999747, 21.80000000000004, 20.000000000000014, -5.1999999999999265, 22.700000000000053, 25.400000000000112, 20.000000000000014, 34.40000000000026, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999972, 11.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999978, 13.999999999999966, 15.799999999999963, 20.000000000000014, -0.9999999999999917, -7.299999999999891, 16.999999999999975, 20.000000000000014, 20.000000000000014, 61.40000000000021, 20.000000000000014, -19.899999999999743, 33.50000000000024, 20.000000000000014, 28.70000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 27.20000000000013, 20.000000000000014, -9.699999999999918, 20.000000000000014, -5.1999999999999265, 11.599999999999977, -3.399999999999983, 20.000000000000014, 43.400000000000205, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, 35.30000000000024, 3.199999999999972, 22.700000000000067, 20.000000000000014, -5.1999999999999655, 20.000000000000014, 20.000000000000014, 17.899999999999988, 37.400000000000205, -17.199999999999775, -12.099999999999918, 63.200000000000145, 23.600000000000087, -44.799999999999784, 20.000000000000014, -1.0000000000000102, -41.79999999999983, 17.899999999999988, 7.399999999999983, 27.200000000000145, 16.69999999999997, -294.9999999999999, -137.40000000000012, 17.899999999999977, -43.599999999999866, -93.39999999999995, -9.399999999999975, 3.1999999999999633, 65.00000000000006, 20.000000000000014, -75.70000000000059, 20.000000000000014, 20.000000000000014, 24.80000000000009, -61.89999999999987, 20.000000000000014, 12.199999999999974, -53.49999999999997, 43.40000000000025, -73.00000000000068, 20.000000000000014, -20.199999999999775, -61.900000000000595], "policy_predator_policy_reward": [85.0, 83.0, 0.0, 38.0, 177.0, 138.0, 0.0, 30.0, 65.0, 23.0, 34.0, 17.0, 18.0, 16.0, 111.0, 49.0, 3.0, 0.0, 17.0, 50.0, 92.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 20.0, 16.0, 2.0, 0.0, 9.0, 22.0, 27.0, 25.0, 0.0, 18.0, 0.0, 1.0, 0.0, 4.0, 5.0, 40.0, 2.0, 4.0, 15.0, 14.0, 102.0, 0.0, 13.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 38.0, 0.0, 0.0, 5.0, 0.0, 16.0, 3.0, 10.0, 0.0, 25.0, 0.0, 12.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 30.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 5.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 16.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 5.0, 24.0, 0.0, 2.0, 15.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 7.0, 0.0, 12.0, 0.0, 15.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 18.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 35.0, 0.0, 22.0, 21.0, 25.0, 16.0, 37.0, 1.0, 6.0, 0.0, 26.0, 4.0, 192.0, 23.0, 22.0, 56.0, 46.0, 17.0, 0.0, 40.0, 22.0, 0.0, 0.0, 35.0, 12.0, 17.0, 0.0, 23.0, 14.0, 16.0, 30.0, 20.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5902319293699093, "mean_inference_ms": 1.815551571072429, "mean_action_processing_ms": 0.2560769115406804, "mean_env_wait_ms": 0.19498988123801048, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038259029388427734, "StateBufferConnector_ms": 0.004397869110107422, "ViewRequirementAgentConnector_ms": 0.09868669509887695}, "num_episodes": 18, "episode_return_max": 220.99999999999912, "episode_return_min": -236.40000000000012, "episode_return_mean": 40.95900000000009, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 397.8162664993696, "num_env_steps_trained_throughput_per_sec": 397.8162664993696, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 10080.691, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10080.651, "sample_time_ms": 1392.421, "learn_time_ms": 8673.649, "learn_throughput": 461.167, "synch_weights_time_ms": 13.53}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "0b081_00000", "date": "2024-08-13_00-54-09", "timestamp": 1723524849, "time_this_iter_s": 10.059735774993896, "time_total_s": 429.9846646785736, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e410d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 429.9846646785736, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 34.693333333333335, "ram_util_percent": 82.84666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5557323009169922, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5645201856181734, "policy_loss": -0.006929401968354507, "vf_loss": 1.5713273441350017, "vf_explained_var": 0.0034422334539827215, "kl": 0.017385833906327874, "entropy": 1.3992393846234317, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.143707282963411, "cur_kl_coeff": 0.16018066406250003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6649396967635584, "policy_loss": -0.0017576273908917472, "vf_loss": 2.665997977546914, "vf_explained_var": -0.0006711897711274486, "kl": 0.004365975067640617, "entropy": 1.1844943641354797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 118.89999999999915, "episode_reward_min": -236.40000000000012, "episode_reward_mean": 34.88500000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -294.9999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 75.79999999999947, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": 6.562500000000032, "predator_policy": 10.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.600000000000186, 94.99999999999893, 69.70000000000002, 38.90000000000028, 39.100000000000286, -3.1999999999999225, 19.099999999999966, -16.099999999999568, 25.700000000000077, 118.89999999999915, 50.800000000000466, 77.7999999999995, 48.0000000000002, 71.99999999999982, 41.800000000000296, 35.40000000000024, 46.100000000000406, 61.40000000000038, 31.700000000000184, 20.8, 37.30000000000026, 50.70000000000048, 59.80000000000051, 69.00000000000001, 16.90000000000002, 75.79999999999967, 24.60000000000005, 40.0000000000003, 40.0000000000003, 89.4999999999988, 49.40000000000042, 34.50000000000022, 35.600000000000236, 34.50000000000022, 67.90000000000019, 23.100000000000026, 26.80000000000009, 48.100000000000385, 54.40000000000052, 48.10000000000039, 40.0000000000003, 23.500000000000036, 40.0000000000003, 40.0000000000003, 56.70000000000041, 37.80000000000027, 6.700000000000154, 47.000000000000426, 81.39999999999922, 19.099999999999977, 53.500000000000526, 58.70000000000047, 40.0000000000003, 48.10000000000043, 31.300000000000164, 26.80000000000009, 23.200000000000035, 72.39999999999986, 50.80000000000048, 40.90000000000031, 55.300000000000516, 36.90000000000027, 32.80000000000019, 40.0000000000003, 58.30000000000042, 29.70000000000033, 108.79999999999882, 21.20000000000001, 10.199999999999953, 32.30000000000017, 69.89999999999995, -236.40000000000012, 19.300000000000026, -0.8000000000000256, 85.19999999999942, 6.300000000000017, 40.0000000000003, 9.900000000000018, 49.20000000000043, 26.900000000000453, -6.999999999999707, -23.099999999999575, 47.20000000000035, -153.5000000000003, 37.60000000000025, 25.700000000000077, 48.10000000000042, -2.5000000000001052, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, -38.09999999999966, 65.30000000000028, -41.19999999999962, 17.699999999999584, 74.20000000000012, 55.300000000000516, 18.40000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.099999999999774, 7.699999999999971, -5.799999999999953, 75.79999999999947, 14.599999999999966, 37.1000000000002, 20.000000000000014, 17.899999999999988, 20.000000000000014, 10.09999999999997, -18.999999999999847, -26.199999999999868, 20.000000000000014, -19.899999999999764, 7.9999999999999725, -140.10000000000076, 20.000000000000014, -7.299999999999901, 56.90000000000009, 56.00000000000023, 20.000000000000014, 30.800000000000203, 57.800000000000225, 20.000000000000014, -65.20000000000056, 54.20000000000023, 24.500000000000107, 9.499999999999982, 21.800000000000047, 20.000000000000014, 10.399999999999961, 20.000000000000014, -19.89999999999975, 47.00000000000024, -0.9999999999999846, 52.40000000000019, 23.600000000000083, -16.899999999999757, -0.9999999999999846, 9.799999999999967, 8.299999999999969, 20.000000000000014, 20.000000000000014, 25.70000000000011, 20.000000000000014, 39.80000000000025, 45.20000000000016, 15.799999999999962, -14.199999999999838, 1.099999999999983, 28.100000000000147, 46.70000000000024, -9.399999999999862, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000017, 37.10000000000025, 17.299999999999976, 1.0999999999999794, 9.499999999999964, 20.000000000000014, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, 30.800000000000196, 37.10000000000023, -15.699999999999747, 21.80000000000004, 20.000000000000014, -5.1999999999999265, 22.700000000000053, 25.400000000000112, 20.000000000000014, 34.40000000000026, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999972, 11.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999978, 13.999999999999966, 15.799999999999963, 20.000000000000014, -0.9999999999999917, -7.299999999999891, 16.999999999999975, 20.000000000000014, 20.000000000000014, 61.40000000000021, 20.000000000000014, -19.899999999999743, 33.50000000000024, 20.000000000000014, 28.70000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 27.20000000000013, 20.000000000000014, -9.699999999999918, 20.000000000000014, -5.1999999999999265, 11.599999999999977, -3.399999999999983, 20.000000000000014, 43.400000000000205, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, 35.30000000000024, 3.199999999999972, 22.700000000000067, 20.000000000000014, -5.1999999999999655, 20.000000000000014, 20.000000000000014, 17.899999999999988, 37.400000000000205, -17.199999999999775, -12.099999999999918, 63.200000000000145, 23.600000000000087, -44.799999999999784, 20.000000000000014, -1.0000000000000102, -41.79999999999983, 17.899999999999988, 7.399999999999983, 27.200000000000145, 16.69999999999997, -294.9999999999999, -137.40000000000012, 17.899999999999977, -43.599999999999866, -93.39999999999995, -9.399999999999975, 3.1999999999999633, 65.00000000000006, 20.000000000000014, -75.70000000000059, 20.000000000000014, 20.000000000000014, 24.80000000000009, -61.89999999999987, 20.000000000000014, 12.199999999999974, -53.49999999999997, 43.40000000000025, -73.00000000000068, 20.000000000000014, -20.199999999999775, -61.900000000000595, 20.000000000000014, 27.200000000000145, -90.7000000000001, -173.80000000000024, 5.599999999999971, 20.000000000000014, -7.300000000000004, 20.000000000000014, 28.100000000000158, 20.000000000000014, -38.19999999999991, -19.29999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.00000000000065, -0.09999999999992432, 56.000000000000185, -3.6999999999999584, -146.2000000000006, 20.000000000000014, -45.40000000000008, -16.900000000000286, 54.200000000000166, 20.000000000000014, 20.000000000000014, 35.30000000000026, 48.200000000000216, -92.80000000000055], "policy_predator_policy_reward": [22.0, 27.0, 25.0, 0.0, 18.0, 0.0, 1.0, 0.0, 4.0, 5.0, 40.0, 2.0, 4.0, 15.0, 14.0, 102.0, 0.0, 13.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 38.0, 0.0, 0.0, 5.0, 0.0, 16.0, 3.0, 10.0, 0.0, 25.0, 0.0, 12.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 30.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 5.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 16.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 5.0, 24.0, 0.0, 2.0, 15.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 7.0, 0.0, 12.0, 0.0, 15.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 18.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 35.0, 0.0, 22.0, 21.0, 25.0, 16.0, 37.0, 1.0, 6.0, 0.0, 26.0, 4.0, 192.0, 23.0, 22.0, 56.0, 46.0, 17.0, 0.0, 40.0, 22.0, 0.0, 0.0, 35.0, 12.0, 17.0, 0.0, 23.0, 14.0, 16.0, 30.0, 20.0, 39.0, 0.0, 0.0, 96.0, 15.0, 4.0, 8.0, 8.0, 5.0, 0.0, 0.0, 23.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 96.0, 0.0, 13.0, 27.0, 58.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, 36.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.589852354486638, "mean_inference_ms": 1.8156924357362385, "mean_action_processing_ms": 0.2556075786946853, "mean_env_wait_ms": 0.19498066459278163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038062334060668945, "StateBufferConnector_ms": 0.004507303237915039, "ViewRequirementAgentConnector_ms": 0.09902536869049072}, "num_episodes": 18, "episode_return_max": 118.89999999999915, "episode_return_min": -236.40000000000012, "episode_return_mean": 34.88500000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.8594996298264, "num_env_steps_trained_throughput_per_sec": 402.8594996298264, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 10085.049, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10085.009, "sample_time_ms": 1385.689, "learn_time_ms": 8684.788, "learn_throughput": 460.575, "synch_weights_time_ms": 13.503}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "0b081_00000", "date": "2024-08-13_00-54-19", "timestamp": 1723524859, "time_this_iter_s": 9.935005903244019, "time_total_s": 439.9196705818176, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327faa0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 439.9196705818176, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 36.864285714285714, "ram_util_percent": 83.01428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5661024478771699, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0363338996493625, "policy_loss": -0.00667250124286742, "vf_loss": 3.0428405658277886, "vf_explained_var": 0.007044841278166998, "kl": 0.02358566101635892, "entropy": 1.2975963314374288, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4930297342951966, "cur_kl_coeff": 0.08009033203125002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.283942271035815, "policy_loss": -0.0018769651799211426, "vf_loss": 4.285013046844926, "vf_explained_var": 0.00959476938954106, "kl": 0.010065927466427873, "entropy": 1.1261597184277086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 108.79999999999882, "episode_reward_min": -236.40000000000012, "episode_reward_mean": 26.36600000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -294.9999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 77.29999999999941, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": 0.9930000000000234, "predator_policy": 12.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.700000000000184, 20.8, 37.30000000000026, 50.70000000000048, 59.80000000000051, 69.00000000000001, 16.90000000000002, 75.79999999999967, 24.60000000000005, 40.0000000000003, 40.0000000000003, 89.4999999999988, 49.40000000000042, 34.50000000000022, 35.600000000000236, 34.50000000000022, 67.90000000000019, 23.100000000000026, 26.80000000000009, 48.100000000000385, 54.40000000000052, 48.10000000000039, 40.0000000000003, 23.500000000000036, 40.0000000000003, 40.0000000000003, 56.70000000000041, 37.80000000000027, 6.700000000000154, 47.000000000000426, 81.39999999999922, 19.099999999999977, 53.500000000000526, 58.70000000000047, 40.0000000000003, 48.10000000000043, 31.300000000000164, 26.80000000000009, 23.200000000000035, 72.39999999999986, 50.80000000000048, 40.90000000000031, 55.300000000000516, 36.90000000000027, 32.80000000000019, 40.0000000000003, 58.30000000000042, 29.70000000000033, 108.79999999999882, 21.20000000000001, 10.199999999999953, 32.30000000000017, 69.89999999999995, -236.40000000000012, 19.300000000000026, -0.8000000000000256, 85.19999999999942, 6.300000000000017, 40.0000000000003, 9.900000000000018, 49.20000000000043, 26.900000000000453, -6.999999999999707, -23.099999999999575, 47.20000000000035, -153.5000000000003, 37.60000000000025, 25.700000000000077, 48.10000000000042, -2.5000000000001052, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, -38.09999999999966, 65.30000000000028, -41.19999999999962, 17.699999999999584, 74.20000000000012, 55.300000000000516, 18.40000000000005, -36.099999999999774, 6.600000000000067, 32.00000000000017, -37.29999999999972, 49.900000000000375, -106.40000000000106, 70.6999999999999, 35.60000000000028, 32.30000000000029, -199.99999999999991, 70.60000000000001, 42.70000000000034, 5.800000000000161, -115.09999999999988, -28.899999999999743, 37.80000000000027, 100.0999999999988, 40.80000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.600000000000083, -16.899999999999757, -0.9999999999999846, 9.799999999999967, 8.299999999999969, 20.000000000000014, 20.000000000000014, 25.70000000000011, 20.000000000000014, 39.80000000000025, 45.20000000000016, 15.799999999999962, -14.199999999999838, 1.099999999999983, 28.100000000000147, 46.70000000000024, -9.399999999999862, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000017, 37.10000000000025, 17.299999999999976, 1.0999999999999794, 9.499999999999964, 20.000000000000014, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, 30.800000000000196, 37.10000000000023, -15.699999999999747, 21.80000000000004, 20.000000000000014, -5.1999999999999265, 22.700000000000053, 25.400000000000112, 20.000000000000014, 34.40000000000026, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999972, 11.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999978, 13.999999999999966, 15.799999999999963, 20.000000000000014, -0.9999999999999917, -7.299999999999891, 16.999999999999975, 20.000000000000014, 20.000000000000014, 61.40000000000021, 20.000000000000014, -19.899999999999743, 33.50000000000024, 20.000000000000014, 28.70000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 27.20000000000013, 20.000000000000014, -9.699999999999918, 20.000000000000014, -5.1999999999999265, 11.599999999999977, -3.399999999999983, 20.000000000000014, 43.400000000000205, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, 35.30000000000024, 3.199999999999972, 22.700000000000067, 20.000000000000014, -5.1999999999999655, 20.000000000000014, 20.000000000000014, 17.899999999999988, 37.400000000000205, -17.199999999999775, -12.099999999999918, 63.200000000000145, 23.600000000000087, -44.799999999999784, 20.000000000000014, -1.0000000000000102, -41.79999999999983, 17.899999999999988, 7.399999999999983, 27.200000000000145, 16.69999999999997, -294.9999999999999, -137.40000000000012, 17.899999999999977, -43.599999999999866, -93.39999999999995, -9.399999999999975, 3.1999999999999633, 65.00000000000006, 20.000000000000014, -75.70000000000059, 20.000000000000014, 20.000000000000014, 24.80000000000009, -61.89999999999987, 20.000000000000014, 12.199999999999974, -53.49999999999997, 43.40000000000025, -73.00000000000068, 20.000000000000014, -20.199999999999775, -61.900000000000595, 20.000000000000014, 27.200000000000145, -90.7000000000001, -173.80000000000024, 5.599999999999971, 20.000000000000014, -7.300000000000004, 20.000000000000014, 28.100000000000158, 20.000000000000014, -38.19999999999991, -19.29999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.00000000000065, -0.09999999999992432, 56.000000000000185, -3.6999999999999584, -146.2000000000006, 20.000000000000014, -45.40000000000008, -16.900000000000286, 54.200000000000166, 20.000000000000014, 20.000000000000014, 35.30000000000026, 48.200000000000216, -92.80000000000055, -58.60000000000003, -40.50000000000003, -141.69999999999987, 62.30000000000018, -0.9999999999999992, 20.000000000000014, -61.9, -30.400000000000023, 22.700000000000063, 27.200000000000145, -97.60000000000053, -80.8000000000005, 37.700000000000166, 20.000000000000014, 13.700000000000005, 17.899999999999984, 20.000000000000014, 5.2999999999999625, -147.99999999999986, -216.99999999999994, 20.000000000000014, 50.60000000000023, 20.000000000000014, 22.700000000000053, -9.399999999999855, -5.799999999999928, -93.40000000000005, -81.70000000000002, -174.70000000000005, 45.800000000000196, 15.799999999999962, 20.000000000000014, 21.80000000000004, 77.29999999999941, -11.799999999999882, 23.600000000000065], "policy_predator_policy_reward": [25.0, 0.0, 12.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 30.0, 0.0, 1.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 5.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 16.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 5.0, 24.0, 0.0, 2.0, 15.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 7.0, 0.0, 12.0, 0.0, 15.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 18.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 35.0, 0.0, 22.0, 21.0, 25.0, 16.0, 37.0, 1.0, 6.0, 0.0, 26.0, 4.0, 192.0, 23.0, 22.0, 56.0, 46.0, 17.0, 0.0, 40.0, 22.0, 0.0, 0.0, 35.0, 12.0, 17.0, 0.0, 23.0, 14.0, 16.0, 30.0, 20.0, 39.0, 0.0, 0.0, 96.0, 15.0, 4.0, 8.0, 8.0, 5.0, 0.0, 0.0, 23.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 96.0, 0.0, 13.0, 27.0, 58.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, 36.0, 27.0, 0.0, 63.0, 0.0, 86.0, 13.0, 0.0, 13.0, 42.0, 0.0, 0.0, 72.0, 0.0, 13.0, 0.0, 3.0, 1.0, 7.0, 0.0, 124.0, 41.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 55.0, 5.0, 85.0, 15.0, 1.0, 1.0, 1.0, 0.0, 1.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5895294972517897, "mean_inference_ms": 1.8161075307485808, "mean_action_processing_ms": 0.2551934471960927, "mean_env_wait_ms": 0.19504181289369288, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037006139755249023, "StateBufferConnector_ms": 0.003960967063903809, "ViewRequirementAgentConnector_ms": 0.09475672245025635}, "num_episodes": 18, "episode_return_max": 108.79999999999882, "episode_return_min": -236.40000000000012, "episode_return_mean": 26.36600000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 400.5058765489533, "num_env_steps_trained_throughput_per_sec": 400.5058765489533, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 10038.337, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10038.297, "sample_time_ms": 1360.753, "learn_time_ms": 8662.959, "learn_throughput": 461.736, "synch_weights_time_ms": 13.555}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "0b081_00000", "date": "2024-08-13_00-54-29", "timestamp": 1723524869, "time_this_iter_s": 9.994646072387695, "time_total_s": 449.9143166542053, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e694c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 449.9143166542053, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 36.43571428571428, "ram_util_percent": 82.78571428571426}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7378446492962736, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.684326130498654, "policy_loss": -0.005732123742234849, "vf_loss": 7.689854772507198, "vf_explained_var": 0.007064618919261549, "kl": 0.01929524043224751, "entropy": 1.2095206506037839, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8755125248913096, "cur_kl_coeff": 0.08009033203125002, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.823509405025098, "policy_loss": -0.006132214321513419, "vf_loss": 7.828386080454266, "vf_explained_var": 0.002643907732433743, "kl": 0.015676540067049466, "entropy": 1.1714989293189275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 144.49999999999966, "episode_reward_min": -424.9, "episode_reward_mean": 8.49800000000011, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -670.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 77.29999999999941, "predator_policy": 558.0}, "policy_reward_mean": {"prey_policy": -38.97599999999999, "predator_policy": 43.225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 23.500000000000036, 40.0000000000003, 40.0000000000003, 56.70000000000041, 37.80000000000027, 6.700000000000154, 47.000000000000426, 81.39999999999922, 19.099999999999977, 53.500000000000526, 58.70000000000047, 40.0000000000003, 48.10000000000043, 31.300000000000164, 26.80000000000009, 23.200000000000035, 72.39999999999986, 50.80000000000048, 40.90000000000031, 55.300000000000516, 36.90000000000027, 32.80000000000019, 40.0000000000003, 58.30000000000042, 29.70000000000033, 108.79999999999882, 21.20000000000001, 10.199999999999953, 32.30000000000017, 69.89999999999995, -236.40000000000012, 19.300000000000026, -0.8000000000000256, 85.19999999999942, 6.300000000000017, 40.0000000000003, 9.900000000000018, 49.20000000000043, 26.900000000000453, -6.999999999999707, -23.099999999999575, 47.20000000000035, -153.5000000000003, 37.60000000000025, 25.700000000000077, 48.10000000000042, -2.5000000000001052, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, -38.09999999999966, 65.30000000000028, -41.19999999999962, 17.699999999999584, 74.20000000000012, 55.300000000000516, 18.40000000000005, -36.099999999999774, 6.600000000000067, 32.00000000000017, -37.29999999999972, 49.900000000000375, -106.40000000000106, 70.6999999999999, 35.60000000000028, 32.30000000000029, -199.99999999999991, 70.60000000000001, 42.70000000000034, 5.800000000000161, -115.09999999999988, -28.899999999999743, 37.80000000000027, 100.0999999999988, 40.80000000000033, -77.70000000000005, -155.6000000000003, -138.1, 47.70000000000038, -136.7000000000003, -183.89999999999995, 57.500000000000426, -163.8000000000002, 91.90000000000035, 14.20000000000045, 25.10000000000005, 144.49999999999966, 38.40000000000037, -424.9, -92.20000000000044, -10.099999999999948, 72.69999999999986, 94.49999999999994, -32.20000000000003, 83.19999999999982, 43.60000000000035, -106.40000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -3.099999999999972, 11.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999978, 13.999999999999966, 15.799999999999963, 20.000000000000014, -0.9999999999999917, -7.299999999999891, 16.999999999999975, 20.000000000000014, 20.000000000000014, 61.40000000000021, 20.000000000000014, -19.899999999999743, 33.50000000000024, 20.000000000000014, 28.70000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 27.20000000000013, 20.000000000000014, -9.699999999999918, 20.000000000000014, -5.1999999999999265, 11.599999999999977, -3.399999999999983, 20.000000000000014, 43.400000000000205, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, 35.30000000000024, 3.199999999999972, 22.700000000000067, 20.000000000000014, -5.1999999999999655, 20.000000000000014, 20.000000000000014, 17.899999999999988, 37.400000000000205, -17.199999999999775, -12.099999999999918, 63.200000000000145, 23.600000000000087, -44.799999999999784, 20.000000000000014, -1.0000000000000102, -41.79999999999983, 17.899999999999988, 7.399999999999983, 27.200000000000145, 16.69999999999997, -294.9999999999999, -137.40000000000012, 17.899999999999977, -43.599999999999866, -93.39999999999995, -9.399999999999975, 3.1999999999999633, 65.00000000000006, 20.000000000000014, -75.70000000000059, 20.000000000000014, 20.000000000000014, 24.80000000000009, -61.89999999999987, 20.000000000000014, 12.199999999999974, -53.49999999999997, 43.40000000000025, -73.00000000000068, 20.000000000000014, -20.199999999999775, -61.900000000000595, 20.000000000000014, 27.200000000000145, -90.7000000000001, -173.80000000000024, 5.599999999999971, 20.000000000000014, -7.300000000000004, 20.000000000000014, 28.100000000000158, 20.000000000000014, -38.19999999999991, -19.29999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.00000000000065, -0.09999999999992432, 56.000000000000185, -3.6999999999999584, -146.2000000000006, 20.000000000000014, -45.40000000000008, -16.900000000000286, 54.200000000000166, 20.000000000000014, 20.000000000000014, 35.30000000000026, 48.200000000000216, -92.80000000000055, -58.60000000000003, -40.50000000000003, -141.69999999999987, 62.30000000000018, -0.9999999999999992, 20.000000000000014, -61.9, -30.400000000000023, 22.700000000000063, 27.200000000000145, -97.60000000000053, -80.8000000000005, 37.700000000000166, 20.000000000000014, 13.700000000000005, 17.899999999999984, 20.000000000000014, 5.2999999999999625, -147.99999999999986, -216.99999999999994, 20.000000000000014, 50.60000000000023, 20.000000000000014, 22.700000000000053, -9.399999999999855, -5.799999999999928, -93.40000000000005, -81.70000000000002, -174.70000000000005, 45.800000000000196, 15.799999999999962, 20.000000000000014, 21.80000000000004, 77.29999999999941, -11.799999999999882, 23.600000000000065, -185.8000000000001, -16.899999999999743, -193.2, -225.4, -103.09999999999997, -172.00000000000003, 23.60000000000008, 13.09999999999996, -630.0, -204.70000000000033, -480.90000000000003, -153.9999999999999, 21.500000000000064, 20.000000000000014, -270.4, -198.40000000000015, 20.000000000000014, -248.09999999999997, -74.1000000000001, 26.300000000000225, 31.700000000000212, -448.6, -44.9999999999998, -670.4999999999999, 13.699999999999957, 13.70000000000001, -631.3, -567.6, -301.5, -189.70000000000056, -17.199999999999925, -40.89999999999989, 56.00000000000023, 13.699999999999946, 20.000000000000014, -352.5, -99.70000000000003, -32.49999999999996, 38.900000000000254, -597.7, 20.000000000000014, 23.600000000000065, -89.5000000000006, -307.90000000000003], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 5.0, 24.0, 0.0, 2.0, 15.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 7.0, 0.0, 12.0, 0.0, 15.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 18.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 35.0, 0.0, 22.0, 21.0, 25.0, 16.0, 37.0, 1.0, 6.0, 0.0, 26.0, 4.0, 192.0, 23.0, 22.0, 56.0, 46.0, 17.0, 0.0, 40.0, 22.0, 0.0, 0.0, 35.0, 12.0, 17.0, 0.0, 23.0, 14.0, 16.0, 30.0, 20.0, 39.0, 0.0, 0.0, 96.0, 15.0, 4.0, 8.0, 8.0, 5.0, 0.0, 0.0, 23.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 96.0, 0.0, 13.0, 27.0, 58.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, 36.0, 27.0, 0.0, 63.0, 0.0, 86.0, 13.0, 0.0, 13.0, 42.0, 0.0, 0.0, 72.0, 0.0, 13.0, 0.0, 3.0, 1.0, 7.0, 0.0, 124.0, 41.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 55.0, 5.0, 85.0, 15.0, 1.0, 1.0, 1.0, 0.0, 1.0, 28.0, 99.0, 26.0, 125.0, 138.0, 0.0, 137.0, 0.0, 11.0, 373.0, 325.0, 440.0, 11.0, 7.0, 9.0, 208.0, 97.0, 133.0, 187.0, 20.0, 42.0, 265.0, 177.0, 359.0, 501.0, 3.0, 8.0, 558.0, 216.0, 203.0, 196.0, 14.0, 34.0, 3.0, 0.0, 196.0, 231.0, 66.0, 34.0, 242.0, 400.0, 0.0, 0.0, 291.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5888670558362455, "mean_inference_ms": 1.8157791619428008, "mean_action_processing_ms": 0.2546304402228818, "mean_env_wait_ms": 0.19498128053856306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003835439682006836, "StateBufferConnector_ms": 0.003987908363342285, "ViewRequirementAgentConnector_ms": 0.0951300859451294}, "num_episodes": 22, "episode_return_max": 144.49999999999966, "episode_return_min": -424.9, "episode_return_mean": 8.49800000000011, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.89808823592, "num_env_steps_trained_throughput_per_sec": 398.89808823592, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 10019.152, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10019.111, "sample_time_ms": 1351.927, "learn_time_ms": 8652.484, "learn_throughput": 462.295, "synch_weights_time_ms": 13.605}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "0b081_00000", "date": "2024-08-13_00-54-39", "timestamp": 1723524879, "time_this_iter_s": 10.040011167526245, "time_total_s": 459.95432782173157, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e69dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 459.95432782173157, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 37.17142857142858, "ram_util_percent": 83.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6610468258618047, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.30673806907008, "policy_loss": -0.006454765646614962, "vf_loss": 7.313002435240166, "vf_explained_var": 0.002143713532301484, "kl": 0.01805203809778668, "entropy": 1.2156246726475064, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3620347638057653, "cur_kl_coeff": 0.08009033203125002, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.8913356967704, "policy_loss": -0.008262644883457118, "vf_loss": 6.897954326710373, "vf_explained_var": 0.006005737075099239, "kl": 0.02052693913201582, "entropy": 1.1705836455657999, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 144.49999999999966, "episode_reward_min": -424.9, "episode_reward_mean": -7.396999999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -776.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 77.29999999999941, "predator_policy": 618.0}, "policy_reward_mean": {"prey_policy": -81.5735, "predator_policy": 77.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 58.30000000000042, 29.70000000000033, 108.79999999999882, 21.20000000000001, 10.199999999999953, 32.30000000000017, 69.89999999999995, -236.40000000000012, 19.300000000000026, -0.8000000000000256, 85.19999999999942, 6.300000000000017, 40.0000000000003, 9.900000000000018, 49.20000000000043, 26.900000000000453, -6.999999999999707, -23.099999999999575, 47.20000000000035, -153.5000000000003, 37.60000000000025, 25.700000000000077, 48.10000000000042, -2.5000000000001052, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, -38.09999999999966, 65.30000000000028, -41.19999999999962, 17.699999999999584, 74.20000000000012, 55.300000000000516, 18.40000000000005, -36.099999999999774, 6.600000000000067, 32.00000000000017, -37.29999999999972, 49.900000000000375, -106.40000000000106, 70.6999999999999, 35.60000000000028, 32.30000000000029, -199.99999999999991, 70.60000000000001, 42.70000000000034, 5.800000000000161, -115.09999999999988, -28.899999999999743, 37.80000000000027, 100.0999999999988, 40.80000000000033, -77.70000000000005, -155.6000000000003, -138.1, 47.70000000000038, -136.7000000000003, -183.89999999999995, 57.500000000000426, -163.8000000000002, 91.90000000000035, 14.20000000000045, 25.10000000000005, 144.49999999999966, 38.40000000000037, -424.9, -92.20000000000044, -10.099999999999948, 72.69999999999986, 94.49999999999994, -32.20000000000003, 83.19999999999982, 43.60000000000035, -106.40000000000006, -154.0000000000003, -52.699999999999754, 60.69999999999978, 123.99999999999837, 15.200000000000275, -170.00000000000037, -164.4000000000002, 80.59999999999971, -4.000000000000059, 17.90000000000004, -33.30000000000034, -199.2000000000002, 48.100000000000286, 121.89999999999992, -126.50000000000038, -201.3000000000007, 122.00000000000023, -211.50000000000077, 107.6999999999997, -2.999999999999929, 10.899999999999718, -9.199999999999777, -6.500000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 17.899999999999988, 37.400000000000205, -17.199999999999775, -12.099999999999918, 63.200000000000145, 23.600000000000087, -44.799999999999784, 20.000000000000014, -1.0000000000000102, -41.79999999999983, 17.899999999999988, 7.399999999999983, 27.200000000000145, 16.69999999999997, -294.9999999999999, -137.40000000000012, 17.899999999999977, -43.599999999999866, -93.39999999999995, -9.399999999999975, 3.1999999999999633, 65.00000000000006, 20.000000000000014, -75.70000000000059, 20.000000000000014, 20.000000000000014, 24.80000000000009, -61.89999999999987, 20.000000000000014, 12.199999999999974, -53.49999999999997, 43.40000000000025, -73.00000000000068, 20.000000000000014, -20.199999999999775, -61.900000000000595, 20.000000000000014, 27.200000000000145, -90.7000000000001, -173.80000000000024, 5.599999999999971, 20.000000000000014, -7.300000000000004, 20.000000000000014, 28.100000000000158, 20.000000000000014, -38.19999999999991, -19.29999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.00000000000065, -0.09999999999992432, 56.000000000000185, -3.6999999999999584, -146.2000000000006, 20.000000000000014, -45.40000000000008, -16.900000000000286, 54.200000000000166, 20.000000000000014, 20.000000000000014, 35.30000000000026, 48.200000000000216, -92.80000000000055, -58.60000000000003, -40.50000000000003, -141.69999999999987, 62.30000000000018, -0.9999999999999992, 20.000000000000014, -61.9, -30.400000000000023, 22.700000000000063, 27.200000000000145, -97.60000000000053, -80.8000000000005, 37.700000000000166, 20.000000000000014, 13.700000000000005, 17.899999999999984, 20.000000000000014, 5.2999999999999625, -147.99999999999986, -216.99999999999994, 20.000000000000014, 50.60000000000023, 20.000000000000014, 22.700000000000053, -9.399999999999855, -5.799999999999928, -93.40000000000005, -81.70000000000002, -174.70000000000005, 45.800000000000196, 15.799999999999962, 20.000000000000014, 21.80000000000004, 77.29999999999941, -11.799999999999882, 23.600000000000065, -185.8000000000001, -16.899999999999743, -193.2, -225.4, -103.09999999999997, -172.00000000000003, 23.60000000000008, 13.09999999999996, -630.0, -204.70000000000033, -480.90000000000003, -153.9999999999999, 21.500000000000064, 20.000000000000014, -270.4, -198.40000000000015, 20.000000000000014, -248.09999999999997, -74.1000000000001, 26.300000000000225, 31.700000000000212, -448.6, -44.9999999999998, -670.4999999999999, 13.699999999999957, 13.70000000000001, -631.3, -567.6, -301.5, -189.70000000000056, -17.199999999999925, -40.89999999999989, 56.00000000000023, 13.699999999999946, 20.000000000000014, -352.5, -99.70000000000003, -32.49999999999996, 38.900000000000254, -597.7, 20.000000000000014, 23.600000000000065, -89.5000000000006, -307.90000000000003, -131.2000000000002, -260.80000000000007, 0.7999999999999794, -263.5, -51.1, 48.80000000000007, 63.20000000000019, 57.80000000000022, -362.8000000000003, 20.000000000000014, -253.9999999999999, -232.00000000000017, -433.9, -776.5, 23.300000000000004, 44.300000000000246, -275.19999999999993, 3.1999999999999615, -234.60000000000002, -101.50000000000068, 22.400000000000045, -708.6999999999998, -65.80000000000001, -380.39999999999975, 20.000000000000014, 28.100000000000033, 47.00000000000003, -428.1, -482.70000000000005, 9.199999999999973, -364.69999999999857, -307.6000000000002, -202.10000000000002, 1.100000000000083, -463.1, -108.40000000000022, -51.39999999999996, -331.9, -19.89999999999982, -251.1, -38.79999999999983, -13.299999999999875, 7.399999999999953, -67.60000000000056, -370.9, -105.6], "policy_predator_policy_reward": [0.0, 0.0, 2.0, 1.0, 24.0, 35.0, 0.0, 22.0, 21.0, 25.0, 16.0, 37.0, 1.0, 6.0, 0.0, 26.0, 4.0, 192.0, 23.0, 22.0, 56.0, 46.0, 17.0, 0.0, 40.0, 22.0, 0.0, 0.0, 35.0, 12.0, 17.0, 0.0, 23.0, 14.0, 16.0, 30.0, 20.0, 39.0, 0.0, 0.0, 96.0, 15.0, 4.0, 8.0, 8.0, 5.0, 0.0, 0.0, 23.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 96.0, 0.0, 13.0, 27.0, 58.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, 36.0, 27.0, 0.0, 63.0, 0.0, 86.0, 13.0, 0.0, 13.0, 42.0, 0.0, 0.0, 72.0, 0.0, 13.0, 0.0, 3.0, 1.0, 7.0, 0.0, 124.0, 41.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 55.0, 5.0, 85.0, 15.0, 1.0, 1.0, 1.0, 0.0, 1.0, 28.0, 99.0, 26.0, 125.0, 138.0, 0.0, 137.0, 0.0, 11.0, 373.0, 325.0, 440.0, 11.0, 7.0, 9.0, 208.0, 97.0, 133.0, 187.0, 20.0, 42.0, 265.0, 177.0, 359.0, 501.0, 3.0, 8.0, 558.0, 216.0, 203.0, 196.0, 14.0, 34.0, 3.0, 0.0, 196.0, 231.0, 66.0, 34.0, 242.0, 400.0, 0.0, 0.0, 291.0, 0.0, 143.0, 95.0, 127.0, 83.0, 1.0, 62.0, 0.0, 3.0, 219.0, 139.0, 156.0, 160.0, 428.0, 618.0, 1.0, 12.0, 47.0, 221.0, 180.0, 174.0, 97.0, 556.0, 22.0, 225.0, 0.0, 0.0, 255.0, 248.0, 338.0, 9.0, 365.0, 106.0, 165.0, 158.0, 40.0, 320.0, 239.0, 252.0, 93.0, 175.0, 19.0, 44.0, 14.0, 37.0, 231.0, 239.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5883079960682267, "mean_inference_ms": 1.8156493070724506, "mean_action_processing_ms": 0.2540785204293314, "mean_env_wait_ms": 0.19498474784913114, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004391074180603027, "StateBufferConnector_ms": 0.00323486328125, "ViewRequirementAgentConnector_ms": 0.09588456153869629}, "num_episodes": 23, "episode_return_max": 144.49999999999966, "episode_return_min": -424.9, "episode_return_mean": -7.396999999999987, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.75422053478025, "num_env_steps_trained_throughput_per_sec": 402.75422053478025, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 9996.838, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9996.796, "sample_time_ms": 1331.474, "learn_time_ms": 8650.545, "learn_throughput": 462.399, "synch_weights_time_ms": 13.679}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "0b081_00000", "date": "2024-08-13_00-54-49", "timestamp": 1723524889, "time_this_iter_s": 9.950456857681274, "time_total_s": 469.90478467941284, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327faae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 469.90478467941284, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 36.9, "ram_util_percent": 81.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.791121387130842, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.390160190176081, "policy_loss": -0.00480145173277903, "vf_loss": 2.3947028808492834, "vf_explained_var": 0.0014210177477074679, "kl": 0.024534506869953735, "entropy": 1.234246785615487, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7536500729975246, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.300633934061363, "policy_loss": -0.005012623956993656, "vf_loss": 6.303607576360148, "vf_explained_var": 0.043436903802175374, "kl": 0.016972381566185787, "entropy": 1.1535609195472072, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 323.50000000000097, "episode_reward_min": -424.9, "episode_reward_mean": 11.271999999999968, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -776.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.6, "predator_policy": 618.0}, "policy_reward_mean": {"prey_policy": -72.65899999999999, "predator_policy": 78.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.099999999999575, 47.20000000000035, -153.5000000000003, 37.60000000000025, 25.700000000000077, 48.10000000000042, -2.5000000000001052, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, -38.09999999999966, 65.30000000000028, -41.19999999999962, 17.699999999999584, 74.20000000000012, 55.300000000000516, 18.40000000000005, -36.099999999999774, 6.600000000000067, 32.00000000000017, -37.29999999999972, 49.900000000000375, -106.40000000000106, 70.6999999999999, 35.60000000000028, 32.30000000000029, -199.99999999999991, 70.60000000000001, 42.70000000000034, 5.800000000000161, -115.09999999999988, -28.899999999999743, 37.80000000000027, 100.0999999999988, 40.80000000000033, -77.70000000000005, -155.6000000000003, -138.1, 47.70000000000038, -136.7000000000003, -183.89999999999995, 57.500000000000426, -163.8000000000002, 91.90000000000035, 14.20000000000045, 25.10000000000005, 144.49999999999966, 38.40000000000037, -424.9, -92.20000000000044, -10.099999999999948, 72.69999999999986, 94.49999999999994, -32.20000000000003, 83.19999999999982, 43.60000000000035, -106.40000000000006, -154.0000000000003, -52.699999999999754, 60.69999999999978, 123.99999999999837, 15.200000000000275, -170.00000000000037, -164.4000000000002, 80.59999999999971, -4.000000000000059, 17.90000000000004, -33.30000000000034, -199.2000000000002, 48.100000000000286, 121.89999999999992, -126.50000000000038, -201.3000000000007, 122.00000000000023, -211.50000000000077, 107.6999999999997, -2.999999999999929, 10.899999999999718, -9.199999999999777, -6.500000000000028, 223.7999999999994, 323.50000000000097, 40.9000000000003, 160.399999999999, 92.1000000000002, 90.00000000000011, 120.89999999999944, 40.30000000000037, 75.10000000000002, 129.8999999999999, 164.199999999999, 95.09999999999967, 139.99999999999898, 219.59999999999934, 84.10000000000008, 41.50000000000029, 39.60000000000022, 148.89999999999915], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-20.199999999999775, -61.900000000000595, 20.000000000000014, 27.200000000000145, -90.7000000000001, -173.80000000000024, 5.599999999999971, 20.000000000000014, -7.300000000000004, 20.000000000000014, 28.100000000000158, 20.000000000000014, -38.19999999999991, -19.29999999999979, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.00000000000065, -0.09999999999992432, 56.000000000000185, -3.6999999999999584, -146.2000000000006, 20.000000000000014, -45.40000000000008, -16.900000000000286, 54.200000000000166, 20.000000000000014, 20.000000000000014, 35.30000000000026, 48.200000000000216, -92.80000000000055, -58.60000000000003, -40.50000000000003, -141.69999999999987, 62.30000000000018, -0.9999999999999992, 20.000000000000014, -61.9, -30.400000000000023, 22.700000000000063, 27.200000000000145, -97.60000000000053, -80.8000000000005, 37.700000000000166, 20.000000000000014, 13.700000000000005, 17.899999999999984, 20.000000000000014, 5.2999999999999625, -147.99999999999986, -216.99999999999994, 20.000000000000014, 50.60000000000023, 20.000000000000014, 22.700000000000053, -9.399999999999855, -5.799999999999928, -93.40000000000005, -81.70000000000002, -174.70000000000005, 45.800000000000196, 15.799999999999962, 20.000000000000014, 21.80000000000004, 77.29999999999941, -11.799999999999882, 23.600000000000065, -185.8000000000001, -16.899999999999743, -193.2, -225.4, -103.09999999999997, -172.00000000000003, 23.60000000000008, 13.09999999999996, -630.0, -204.70000000000033, -480.90000000000003, -153.9999999999999, 21.500000000000064, 20.000000000000014, -270.4, -198.40000000000015, 20.000000000000014, -248.09999999999997, -74.1000000000001, 26.300000000000225, 31.700000000000212, -448.6, -44.9999999999998, -670.4999999999999, 13.699999999999957, 13.70000000000001, -631.3, -567.6, -301.5, -189.70000000000056, -17.199999999999925, -40.89999999999989, 56.00000000000023, 13.699999999999946, 20.000000000000014, -352.5, -99.70000000000003, -32.49999999999996, 38.900000000000254, -597.7, 20.000000000000014, 23.600000000000065, -89.5000000000006, -307.90000000000003, -131.2000000000002, -260.80000000000007, 0.7999999999999794, -263.5, -51.1, 48.80000000000007, 63.20000000000019, 57.80000000000022, -362.8000000000003, 20.000000000000014, -253.9999999999999, -232.00000000000017, -433.9, -776.5, 23.300000000000004, 44.300000000000246, -275.19999999999993, 3.1999999999999615, -234.60000000000002, -101.50000000000068, 22.400000000000045, -708.6999999999998, -65.80000000000001, -380.39999999999975, 20.000000000000014, 28.100000000000033, 47.00000000000003, -428.1, -482.70000000000005, 9.199999999999973, -364.69999999999857, -307.6000000000002, -202.10000000000002, 1.100000000000083, -463.1, -108.40000000000022, -51.39999999999996, -331.9, -19.89999999999982, -251.1, -38.79999999999983, -13.299999999999875, 7.399999999999953, -67.60000000000056, -370.9, -105.6, 78.79999999999995, 127.99999999999955, 176.6, 146.8999999999997, 20.000000000000014, 20.900000000000013, 107.89999999999975, 21.500000000000163, 20.000000000000014, 67.10000000000001, -27.699999999999797, 79.70000000000007, -343.79999999999995, 31.700000000000195, 7.999999999999966, 20.300000000000182, -161.20000000000022, 68.30000000000004, -12.400000000000045, 92.30000000000007, 23.600000000000065, 140.59999999999968, 58.10000000000012, 20.000000000000014, 46.40000000000016, 71.59999999999985, 110.89999999999944, 97.70000000000009, 20.000000000000014, 64.09999999999998, 13.700000000000008, 21.800000000000047, 13.099999999999971, -32.49999999999983, 123.50000000000011, 25.40000000000007], "policy_predator_policy_reward": [20.0, 39.0, 0.0, 0.0, 96.0, 15.0, 4.0, 8.0, 8.0, 5.0, 0.0, 0.0, 23.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 96.0, 0.0, 13.0, 27.0, 58.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, 36.0, 27.0, 0.0, 63.0, 0.0, 86.0, 13.0, 0.0, 13.0, 42.0, 0.0, 0.0, 72.0, 0.0, 13.0, 0.0, 3.0, 1.0, 7.0, 0.0, 124.0, 41.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 55.0, 5.0, 85.0, 15.0, 1.0, 1.0, 1.0, 0.0, 1.0, 28.0, 99.0, 26.0, 125.0, 138.0, 0.0, 137.0, 0.0, 11.0, 373.0, 325.0, 440.0, 11.0, 7.0, 9.0, 208.0, 97.0, 133.0, 187.0, 20.0, 42.0, 265.0, 177.0, 359.0, 501.0, 3.0, 8.0, 558.0, 216.0, 203.0, 196.0, 14.0, 34.0, 3.0, 0.0, 196.0, 231.0, 66.0, 34.0, 242.0, 400.0, 0.0, 0.0, 291.0, 0.0, 143.0, 95.0, 127.0, 83.0, 1.0, 62.0, 0.0, 3.0, 219.0, 139.0, 156.0, 160.0, 428.0, 618.0, 1.0, 12.0, 47.0, 221.0, 180.0, 174.0, 97.0, 556.0, 22.0, 225.0, 0.0, 0.0, 255.0, 248.0, 338.0, 9.0, 365.0, 106.0, 165.0, 158.0, 40.0, 320.0, 239.0, 252.0, 93.0, 175.0, 19.0, 44.0, 14.0, 37.0, 231.0, 239.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 0.0, 5.0, 27.0, 11.0, 206.0, 227.0, 3.0, 9.0, 76.0, 92.0, 37.0, 13.0, 0.0, 0.0, 17.0, 0.0, 0.0, 22.0, 11.0, 0.0, 0.0, 0.0, 3.0, 3.0, 32.0, 27.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5877659511747577, "mean_inference_ms": 1.8153315850816698, "mean_action_processing_ms": 0.2536472455763534, "mean_env_wait_ms": 0.19492775353958428, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004887700080871582, "StateBufferConnector_ms": 0.0032341480255126953, "ViewRequirementAgentConnector_ms": 0.09453308582305908}, "num_episodes": 18, "episode_return_max": 323.50000000000097, "episode_return_min": -424.9, "episode_return_mean": 11.271999999999968, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 406.690130133106, "num_env_steps_trained_throughput_per_sec": 406.690130133106, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 9969.345, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9969.304, "sample_time_ms": 1320.01, "learn_time_ms": 8634.519, "learn_throughput": 463.257, "synch_weights_time_ms": 13.632}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "0b081_00000", "date": "2024-08-13_00-54-59", "timestamp": 1723524899, "time_this_iter_s": 9.83957314491272, "time_total_s": 479.74435782432556, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e41040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 479.74435782432556, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 34.7, "ram_util_percent": 81.65}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.601721180112116, "cur_kl_coeff": 0.015820312499999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.081684461567137, "policy_loss": -0.006322075287372899, "vf_loss": 1.087666485438902, "vf_explained_var": -0.0077006159951447176, "kl": 0.021494483668767585, "entropy": 1.265375527566072, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5129383896709119, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.513319004275812, "policy_loss": -0.00469635137339571, "vf_loss": 4.516060241694173, "vf_explained_var": 0.07543294152254781, "kl": 0.016274172535061374, "entropy": 1.1632964154399892, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 323.50000000000097, "episode_reward_min": -424.9, "episode_reward_mean": 22.3619999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -776.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.6, "predator_policy": 618.0}, "policy_reward_mean": {"prey_policy": -66.73400000000001, "predator_policy": 77.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.40000000000005, -36.099999999999774, 6.600000000000067, 32.00000000000017, -37.29999999999972, 49.900000000000375, -106.40000000000106, 70.6999999999999, 35.60000000000028, 32.30000000000029, -199.99999999999991, 70.60000000000001, 42.70000000000034, 5.800000000000161, -115.09999999999988, -28.899999999999743, 37.80000000000027, 100.0999999999988, 40.80000000000033, -77.70000000000005, -155.6000000000003, -138.1, 47.70000000000038, -136.7000000000003, -183.89999999999995, 57.500000000000426, -163.8000000000002, 91.90000000000035, 14.20000000000045, 25.10000000000005, 144.49999999999966, 38.40000000000037, -424.9, -92.20000000000044, -10.099999999999948, 72.69999999999986, 94.49999999999994, -32.20000000000003, 83.19999999999982, 43.60000000000035, -106.40000000000006, -154.0000000000003, -52.699999999999754, 60.69999999999978, 123.99999999999837, 15.200000000000275, -170.00000000000037, -164.4000000000002, 80.59999999999971, -4.000000000000059, 17.90000000000004, -33.30000000000034, -199.2000000000002, 48.100000000000286, 121.89999999999992, -126.50000000000038, -201.3000000000007, 122.00000000000023, -211.50000000000077, 107.6999999999997, -2.999999999999929, 10.899999999999718, -9.199999999999777, -6.500000000000028, 223.7999999999994, 323.50000000000097, 40.9000000000003, 160.399999999999, 92.1000000000002, 90.00000000000011, 120.89999999999944, 40.30000000000037, 75.10000000000002, 129.8999999999999, 164.199999999999, 95.09999999999967, 139.99999999999898, 219.59999999999934, 84.10000000000008, 41.50000000000029, 39.60000000000022, 148.89999999999915, 13.300000000000027, 88.60000000000008, 80.40000000000016, 59.70000000000022, 108.99999999999866, 152.99999999999952, 23.200000000000028, 101.29999999999865, 75.99999999999999, -67.80000000000052, 218.99999999999974, 52.000000000000476, 239.8999999999993, 50.80000000000049, 39.90000000000031, 77.79999999999947, 77.40000000000006, 28.200000000000074], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [48.200000000000216, -92.80000000000055, -58.60000000000003, -40.50000000000003, -141.69999999999987, 62.30000000000018, -0.9999999999999992, 20.000000000000014, -61.9, -30.400000000000023, 22.700000000000063, 27.200000000000145, -97.60000000000053, -80.8000000000005, 37.700000000000166, 20.000000000000014, 13.700000000000005, 17.899999999999984, 20.000000000000014, 5.2999999999999625, -147.99999999999986, -216.99999999999994, 20.000000000000014, 50.60000000000023, 20.000000000000014, 22.700000000000053, -9.399999999999855, -5.799999999999928, -93.40000000000005, -81.70000000000002, -174.70000000000005, 45.800000000000196, 15.799999999999962, 20.000000000000014, 21.80000000000004, 77.29999999999941, -11.799999999999882, 23.600000000000065, -185.8000000000001, -16.899999999999743, -193.2, -225.4, -103.09999999999997, -172.00000000000003, 23.60000000000008, 13.09999999999996, -630.0, -204.70000000000033, -480.90000000000003, -153.9999999999999, 21.500000000000064, 20.000000000000014, -270.4, -198.40000000000015, 20.000000000000014, -248.09999999999997, -74.1000000000001, 26.300000000000225, 31.700000000000212, -448.6, -44.9999999999998, -670.4999999999999, 13.699999999999957, 13.70000000000001, -631.3, -567.6, -301.5, -189.70000000000056, -17.199999999999925, -40.89999999999989, 56.00000000000023, 13.699999999999946, 20.000000000000014, -352.5, -99.70000000000003, -32.49999999999996, 38.900000000000254, -597.7, 20.000000000000014, 23.600000000000065, -89.5000000000006, -307.90000000000003, -131.2000000000002, -260.80000000000007, 0.7999999999999794, -263.5, -51.1, 48.80000000000007, 63.20000000000019, 57.80000000000022, -362.8000000000003, 20.000000000000014, -253.9999999999999, -232.00000000000017, -433.9, -776.5, 23.300000000000004, 44.300000000000246, -275.19999999999993, 3.1999999999999615, -234.60000000000002, -101.50000000000068, 22.400000000000045, -708.6999999999998, -65.80000000000001, -380.39999999999975, 20.000000000000014, 28.100000000000033, 47.00000000000003, -428.1, -482.70000000000005, 9.199999999999973, -364.69999999999857, -307.6000000000002, -202.10000000000002, 1.100000000000083, -463.1, -108.40000000000022, -51.39999999999996, -331.9, -19.89999999999982, -251.1, -38.79999999999983, -13.299999999999875, 7.399999999999953, -67.60000000000056, -370.9, -105.6, 78.79999999999995, 127.99999999999955, 176.6, 146.8999999999997, 20.000000000000014, 20.900000000000013, 107.89999999999975, 21.500000000000163, 20.000000000000014, 67.10000000000001, -27.699999999999797, 79.70000000000007, -343.79999999999995, 31.700000000000195, 7.999999999999966, 20.300000000000182, -161.20000000000022, 68.30000000000004, -12.400000000000045, 92.30000000000007, 23.600000000000065, 140.59999999999968, 58.10000000000012, 20.000000000000014, 46.40000000000016, 71.59999999999985, 110.89999999999944, 97.70000000000009, 20.000000000000014, 64.09999999999998, 13.700000000000008, 21.800000000000047, 13.099999999999971, -32.49999999999983, 123.50000000000011, 25.40000000000007, 1.4000000000000228, -27.099999999999802, -26.199999999999797, 60.80000000000007, 4.999999999999837, 25.400000000000112, 31.700000000000163, -24.99999999999983, 87.19999999999936, 15.799999999999963, 135.20000000000007, 15.799999999999963, 26.30000000000013, -24.09999999999979, 20.000000000000014, 77.29999999999937, 49.70000000000024, 26.300000000000033, 20.000000000000014, -185.80000000000044, 63.80000000000003, 123.1999999999999, 5.299999999999976, 34.70000000000023, 136.0999999999996, 99.79999999999997, 20.000000000000014, 30.8000000000002, 20.000000000000014, -3.100000000000015, 12.499999999999945, 47.30000000000019, 28.400000000000098, 29.00000000000004, 20.000000000000014, -14.799999999999772], "policy_predator_policy_reward": [36.0, 27.0, 0.0, 63.0, 0.0, 86.0, 13.0, 0.0, 13.0, 42.0, 0.0, 0.0, 72.0, 0.0, 13.0, 0.0, 3.0, 1.0, 7.0, 0.0, 124.0, 41.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 55.0, 5.0, 85.0, 15.0, 1.0, 1.0, 1.0, 0.0, 1.0, 28.0, 99.0, 26.0, 125.0, 138.0, 0.0, 137.0, 0.0, 11.0, 373.0, 325.0, 440.0, 11.0, 7.0, 9.0, 208.0, 97.0, 133.0, 187.0, 20.0, 42.0, 265.0, 177.0, 359.0, 501.0, 3.0, 8.0, 558.0, 216.0, 203.0, 196.0, 14.0, 34.0, 3.0, 0.0, 196.0, 231.0, 66.0, 34.0, 242.0, 400.0, 0.0, 0.0, 291.0, 0.0, 143.0, 95.0, 127.0, 83.0, 1.0, 62.0, 0.0, 3.0, 219.0, 139.0, 156.0, 160.0, 428.0, 618.0, 1.0, 12.0, 47.0, 221.0, 180.0, 174.0, 97.0, 556.0, 22.0, 225.0, 0.0, 0.0, 255.0, 248.0, 338.0, 9.0, 365.0, 106.0, 165.0, 158.0, 40.0, 320.0, 239.0, 252.0, 93.0, 175.0, 19.0, 44.0, 14.0, 37.0, 231.0, 239.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 0.0, 5.0, 27.0, 11.0, 206.0, 227.0, 3.0, 9.0, 76.0, 92.0, 37.0, 13.0, 0.0, 0.0, 17.0, 0.0, 0.0, 22.0, 11.0, 0.0, 0.0, 0.0, 3.0, 3.0, 32.0, 27.0, 0.0, 0.0, 0.0, 39.0, 22.0, 32.0, 50.0, 0.0, 44.0, 9.0, 6.0, 0.0, 2.0, 0.0, 21.0, 0.0, 4.0, 0.0, 0.0, 0.0, 34.0, 64.0, 32.0, 0.0, 12.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 23.0, 0.0, 18.0, 3.0, 17.0, 0.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5872192036388425, "mean_inference_ms": 1.8151384367795225, "mean_action_processing_ms": 0.25321691087655845, "mean_env_wait_ms": 0.19482647104903664, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005287885665893555, "StateBufferConnector_ms": 0.003113985061645508, "ViewRequirementAgentConnector_ms": 0.09159624576568604}, "num_episodes": 18, "episode_return_max": 323.50000000000097, "episode_return_min": -424.9, "episode_return_mean": 22.3619999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 421.6516821441193, "num_env_steps_trained_throughput_per_sec": 421.6516821441193, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 9941.044, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9941.004, "sample_time_ms": 1320.938, "learn_time_ms": 8605.454, "learn_throughput": 464.821, "synch_weights_time_ms": 13.473}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "0b081_00000", "date": "2024-08-13_00-55-08", "timestamp": 1723524908, "time_this_iter_s": 9.490809917449951, "time_total_s": 489.2351677417755, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327c9e700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 489.2351677417755, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 36.707692307692305, "ram_util_percent": 81.76153846153845}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6600953347192555, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3708818197881103, "policy_loss": -0.003478195384470007, "vf_loss": 1.3741010391365283, "vf_explained_var": 0.020701604482358096, "kl": 0.010913315058619812, "entropy": 1.318170470661587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.594969627757867, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.099762622893802, "policy_loss": -0.001154172220193441, "vf_loss": 4.100412881311286, "vf_explained_var": 0.0895123785450345, "kl": 0.004194643098633422, "entropy": 1.1815281996651301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 323.50000000000097, "episode_reward_min": -424.9, "episode_reward_mean": 46.97299999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -776.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.6, "predator_policy": 618.0}, "policy_reward_mean": {"prey_policy": -50.1985, "predator_policy": 73.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.70000000000038, -136.7000000000003, -183.89999999999995, 57.500000000000426, -163.8000000000002, 91.90000000000035, 14.20000000000045, 25.10000000000005, 144.49999999999966, 38.40000000000037, -424.9, -92.20000000000044, -10.099999999999948, 72.69999999999986, 94.49999999999994, -32.20000000000003, 83.19999999999982, 43.60000000000035, -106.40000000000006, -154.0000000000003, -52.699999999999754, 60.69999999999978, 123.99999999999837, 15.200000000000275, -170.00000000000037, -164.4000000000002, 80.59999999999971, -4.000000000000059, 17.90000000000004, -33.30000000000034, -199.2000000000002, 48.100000000000286, 121.89999999999992, -126.50000000000038, -201.3000000000007, 122.00000000000023, -211.50000000000077, 107.6999999999997, -2.999999999999929, 10.899999999999718, -9.199999999999777, -6.500000000000028, 223.7999999999994, 323.50000000000097, 40.9000000000003, 160.399999999999, 92.1000000000002, 90.00000000000011, 120.89999999999944, 40.30000000000037, 75.10000000000002, 129.8999999999999, 164.199999999999, 95.09999999999967, 139.99999999999898, 219.59999999999934, 84.10000000000008, 41.50000000000029, 39.60000000000022, 148.89999999999915, 13.300000000000027, 88.60000000000008, 80.40000000000016, 59.70000000000022, 108.99999999999866, 152.99999999999952, 23.200000000000028, 101.29999999999865, 75.99999999999999, -67.80000000000052, 218.99999999999974, 52.000000000000476, 239.8999999999993, 50.80000000000049, 39.90000000000031, 77.79999999999947, 77.40000000000006, 28.200000000000074, 17.499999999999968, 39.8000000000003, 166.69999999999962, 120.69999999999968, 110.19999999999894, 211.39999999999955, 38.80000000000008, 32.30000000000019, 37.70000000000021, 189.39999999999904, 52.60000000000049, 157.3999999999996, 131.79999999999868, 37.300000000000274, 95.69999999999894, 58.90000000000033, 186.69999999999905, 138.39999999999998, 166.09999999999874, 58.400000000000034, 134.49999999999872, -73.1000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.60000000000008, 13.09999999999996, -630.0, -204.70000000000033, -480.90000000000003, -153.9999999999999, 21.500000000000064, 20.000000000000014, -270.4, -198.40000000000015, 20.000000000000014, -248.09999999999997, -74.1000000000001, 26.300000000000225, 31.700000000000212, -448.6, -44.9999999999998, -670.4999999999999, 13.699999999999957, 13.70000000000001, -631.3, -567.6, -301.5, -189.70000000000056, -17.199999999999925, -40.89999999999989, 56.00000000000023, 13.699999999999946, 20.000000000000014, -352.5, -99.70000000000003, -32.49999999999996, 38.900000000000254, -597.7, 20.000000000000014, 23.600000000000065, -89.5000000000006, -307.90000000000003, -131.2000000000002, -260.80000000000007, 0.7999999999999794, -263.5, -51.1, 48.80000000000007, 63.20000000000019, 57.80000000000022, -362.8000000000003, 20.000000000000014, -253.9999999999999, -232.00000000000017, -433.9, -776.5, 23.300000000000004, 44.300000000000246, -275.19999999999993, 3.1999999999999615, -234.60000000000002, -101.50000000000068, 22.400000000000045, -708.6999999999998, -65.80000000000001, -380.39999999999975, 20.000000000000014, 28.100000000000033, 47.00000000000003, -428.1, -482.70000000000005, 9.199999999999973, -364.69999999999857, -307.6000000000002, -202.10000000000002, 1.100000000000083, -463.1, -108.40000000000022, -51.39999999999996, -331.9, -19.89999999999982, -251.1, -38.79999999999983, -13.299999999999875, 7.399999999999953, -67.60000000000056, -370.9, -105.6, 78.79999999999995, 127.99999999999955, 176.6, 146.8999999999997, 20.000000000000014, 20.900000000000013, 107.89999999999975, 21.500000000000163, 20.000000000000014, 67.10000000000001, -27.699999999999797, 79.70000000000007, -343.79999999999995, 31.700000000000195, 7.999999999999966, 20.300000000000182, -161.20000000000022, 68.30000000000004, -12.400000000000045, 92.30000000000007, 23.600000000000065, 140.59999999999968, 58.10000000000012, 20.000000000000014, 46.40000000000016, 71.59999999999985, 110.89999999999944, 97.70000000000009, 20.000000000000014, 64.09999999999998, 13.700000000000008, 21.800000000000047, 13.099999999999971, -32.49999999999983, 123.50000000000011, 25.40000000000007, 1.4000000000000228, -27.099999999999802, -26.199999999999797, 60.80000000000007, 4.999999999999837, 25.400000000000112, 31.700000000000163, -24.99999999999983, 87.19999999999936, 15.799999999999963, 135.20000000000007, 15.799999999999963, 26.30000000000013, -24.09999999999979, 20.000000000000014, 77.29999999999937, 49.70000000000024, 26.300000000000033, 20.000000000000014, -185.80000000000044, 63.80000000000003, 123.1999999999999, 5.299999999999976, 34.70000000000023, 136.0999999999996, 99.79999999999997, 20.000000000000014, 30.8000000000002, 20.000000000000014, -3.100000000000015, 12.499999999999945, 47.30000000000019, 28.400000000000098, 29.00000000000004, 20.000000000000014, -14.799999999999772, -30.399999999999892, 20.90000000000003, 17.599999999999984, 18.19999999999999, 36.80000000000009, 101.90000000000002, 85.7, 20.000000000000014, 78.49999999999952, 13.699999999999964, 71.29999999999997, 133.09999999999997, 5.900000000000091, 17.899999999999988, 5.299999999999965, 20.000000000000014, 20.000000000000014, 10.699999999999951, 96.49999999999949, 74.90000000000003, 20.90000000000003, 31.700000000000212, 121.4, 20.000000000000014, 76.69999999999946, 40.1000000000002, 18.499999999999993, -17.19999999999977, -34.59999999999975, 104.29999999999949, 29.90000000000009, 20.000000000000014, 166.69999999999982, 20.000000000000014, 59.900000000000055, 39.500000000000064, 71.29999999999968, 75.79999999999998, -22.600000000000293, 20.000000000000014, 114.49999999999946, 20.000000000000014, -115.00000000000054, -24.099999999999795], "policy_predator_policy_reward": [0.0, 11.0, 373.0, 325.0, 440.0, 11.0, 7.0, 9.0, 208.0, 97.0, 133.0, 187.0, 20.0, 42.0, 265.0, 177.0, 359.0, 501.0, 3.0, 8.0, 558.0, 216.0, 203.0, 196.0, 14.0, 34.0, 3.0, 0.0, 196.0, 231.0, 66.0, 34.0, 242.0, 400.0, 0.0, 0.0, 291.0, 0.0, 143.0, 95.0, 127.0, 83.0, 1.0, 62.0, 0.0, 3.0, 219.0, 139.0, 156.0, 160.0, 428.0, 618.0, 1.0, 12.0, 47.0, 221.0, 180.0, 174.0, 97.0, 556.0, 22.0, 225.0, 0.0, 0.0, 255.0, 248.0, 338.0, 9.0, 365.0, 106.0, 165.0, 158.0, 40.0, 320.0, 239.0, 252.0, 93.0, 175.0, 19.0, 44.0, 14.0, 37.0, 231.0, 239.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 0.0, 5.0, 27.0, 11.0, 206.0, 227.0, 3.0, 9.0, 76.0, 92.0, 37.0, 13.0, 0.0, 0.0, 17.0, 0.0, 0.0, 22.0, 11.0, 0.0, 0.0, 0.0, 3.0, 3.0, 32.0, 27.0, 0.0, 0.0, 0.0, 39.0, 22.0, 32.0, 50.0, 0.0, 44.0, 9.0, 6.0, 0.0, 2.0, 0.0, 21.0, 0.0, 4.0, 0.0, 0.0, 0.0, 34.0, 64.0, 32.0, 0.0, 12.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 23.0, 0.0, 18.0, 3.0, 17.0, 0.0, 23.0, 9.0, 18.0, 0.0, 4.0, 7.0, 21.0, 0.0, 15.0, 18.0, 0.0, 7.0, 0.0, 0.0, 15.0, 7.0, 0.0, 0.0, 7.0, 3.0, 15.0, 0.0, 0.0, 4.0, 12.0, 15.0, 0.0, 25.0, 11.0, 0.0, 26.0, 0.0, 9.0, 0.0, 0.0, 25.0, 14.0, 1.0, 18.0, 29.0, 32.0, 0.0, 0.0, 66.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5863529887619583, "mean_inference_ms": 1.8146499523363906, "mean_action_processing_ms": 0.2526763575977776, "mean_env_wait_ms": 0.1945645537796542, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0058441162109375, "StateBufferConnector_ms": 0.0030630826950073242, "ViewRequirementAgentConnector_ms": 0.09243321418762207}, "num_episodes": 22, "episode_return_max": 323.50000000000097, "episode_return_min": -424.9, "episode_return_mean": 46.97299999999979, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.23887799698616, "num_env_steps_trained_throughput_per_sec": 416.23887799698616, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 9865.595, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9865.555, "sample_time_ms": 1315.67, "learn_time_ms": 8535.671, "learn_throughput": 468.622, "synch_weights_time_ms": 13.369}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "0b081_00000", "date": "2024-08-13_00-55-18", "timestamp": 1723524918, "time_this_iter_s": 9.621227025985718, "time_total_s": 498.85639476776123, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327faae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 498.85639476776123, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 36.935714285714276, "ram_util_percent": 81.72857142857141}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7627734360674386, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.086278301540506, "policy_loss": -0.001957194063881481, "vf_loss": 1.0880704580160676, "vf_explained_var": 0.07629556403588997, "kl": 0.006954426961886748, "entropy": 1.2888913287687553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3929098128799409, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2209646701812744, "policy_loss": -0.00197286472813517, "vf_loss": 3.2221525845073518, "vf_explained_var": 0.13052466401347407, "kl": 0.013067753272201742, "entropy": 1.186355908774825, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 323.50000000000097, "episode_reward_min": -211.50000000000077, "episode_reward_mean": 71.87499999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -776.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.6, "predator_policy": 618.0}, "policy_reward_mean": {"prey_policy": -8.447500000000014, "predator_policy": 44.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.200000000000275, -170.00000000000037, -164.4000000000002, 80.59999999999971, -4.000000000000059, 17.90000000000004, -33.30000000000034, -199.2000000000002, 48.100000000000286, 121.89999999999992, -126.50000000000038, -201.3000000000007, 122.00000000000023, -211.50000000000077, 107.6999999999997, -2.999999999999929, 10.899999999999718, -9.199999999999777, -6.500000000000028, 223.7999999999994, 323.50000000000097, 40.9000000000003, 160.399999999999, 92.1000000000002, 90.00000000000011, 120.89999999999944, 40.30000000000037, 75.10000000000002, 129.8999999999999, 164.199999999999, 95.09999999999967, 139.99999999999898, 219.59999999999934, 84.10000000000008, 41.50000000000029, 39.60000000000022, 148.89999999999915, 13.300000000000027, 88.60000000000008, 80.40000000000016, 59.70000000000022, 108.99999999999866, 152.99999999999952, 23.200000000000028, 101.29999999999865, 75.99999999999999, -67.80000000000052, 218.99999999999974, 52.000000000000476, 239.8999999999993, 50.80000000000049, 39.90000000000031, 77.79999999999947, 77.40000000000006, 28.200000000000074, 17.499999999999968, 39.8000000000003, 166.69999999999962, 120.69999999999968, 110.19999999999894, 211.39999999999955, 38.80000000000008, 32.30000000000019, 37.70000000000021, 189.39999999999904, 52.60000000000049, 157.3999999999996, 131.79999999999868, 37.300000000000274, 95.69999999999894, 58.90000000000033, 186.69999999999905, 138.39999999999998, 166.09999999999874, 58.400000000000034, 134.49999999999872, -73.1000000000013, 25.300000000000065, 114.09999999999906, 40.0000000000003, 24.900000000000063, 69.09999999999994, 124.19999999999882, 40.0000000000003, 41.200000000000294, 221.2999999999997, 133.19999999999914, 133.29999999999956, 51.20000000000027, 147.39999999999904, 54.90000000000046, 63.70000000000036, 62.00000000000036, 116.59999999999928, 3.00000000000023, 11.600000000000216, 94.69999999999881, 165.99999999999955, 148.59999999999968, 144.9999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-362.8000000000003, 20.000000000000014, -253.9999999999999, -232.00000000000017, -433.9, -776.5, 23.300000000000004, 44.300000000000246, -275.19999999999993, 3.1999999999999615, -234.60000000000002, -101.50000000000068, 22.400000000000045, -708.6999999999998, -65.80000000000001, -380.39999999999975, 20.000000000000014, 28.100000000000033, 47.00000000000003, -428.1, -482.70000000000005, 9.199999999999973, -364.69999999999857, -307.6000000000002, -202.10000000000002, 1.100000000000083, -463.1, -108.40000000000022, -51.39999999999996, -331.9, -19.89999999999982, -251.1, -38.79999999999983, -13.299999999999875, 7.399999999999953, -67.60000000000056, -370.9, -105.6, 78.79999999999995, 127.99999999999955, 176.6, 146.8999999999997, 20.000000000000014, 20.900000000000013, 107.89999999999975, 21.500000000000163, 20.000000000000014, 67.10000000000001, -27.699999999999797, 79.70000000000007, -343.79999999999995, 31.700000000000195, 7.999999999999966, 20.300000000000182, -161.20000000000022, 68.30000000000004, -12.400000000000045, 92.30000000000007, 23.600000000000065, 140.59999999999968, 58.10000000000012, 20.000000000000014, 46.40000000000016, 71.59999999999985, 110.89999999999944, 97.70000000000009, 20.000000000000014, 64.09999999999998, 13.700000000000008, 21.800000000000047, 13.099999999999971, -32.49999999999983, 123.50000000000011, 25.40000000000007, 1.4000000000000228, -27.099999999999802, -26.199999999999797, 60.80000000000007, 4.999999999999837, 25.400000000000112, 31.700000000000163, -24.99999999999983, 87.19999999999936, 15.799999999999963, 135.20000000000007, 15.799999999999963, 26.30000000000013, -24.09999999999979, 20.000000000000014, 77.29999999999937, 49.70000000000024, 26.300000000000033, 20.000000000000014, -185.80000000000044, 63.80000000000003, 123.1999999999999, 5.299999999999976, 34.70000000000023, 136.0999999999996, 99.79999999999997, 20.000000000000014, 30.8000000000002, 20.000000000000014, -3.100000000000015, 12.499999999999945, 47.30000000000019, 28.400000000000098, 29.00000000000004, 20.000000000000014, -14.799999999999772, -30.399999999999892, 20.90000000000003, 17.599999999999984, 18.19999999999999, 36.80000000000009, 101.90000000000002, 85.7, 20.000000000000014, 78.49999999999952, 13.699999999999964, 71.29999999999997, 133.09999999999997, 5.900000000000091, 17.899999999999988, 5.299999999999965, 20.000000000000014, 20.000000000000014, 10.699999999999951, 96.49999999999949, 74.90000000000003, 20.90000000000003, 31.700000000000212, 121.4, 20.000000000000014, 76.69999999999946, 40.1000000000002, 18.499999999999993, -17.19999999999977, -34.59999999999975, 104.29999999999949, 29.90000000000009, 20.000000000000014, 166.69999999999982, 20.000000000000014, 59.900000000000055, 39.500000000000064, 71.29999999999968, 75.79999999999998, -22.600000000000293, 20.000000000000014, 114.49999999999946, 20.000000000000014, -115.00000000000054, -24.099999999999795, -15.699999999999747, 20.000000000000014, 36.20000000000015, 74.89999999999955, 20.000000000000014, 20.000000000000014, 17.299999999999976, -9.399999999999862, -3.099999999999972, 60.20000000000013, 3.1999999999999615, 109.99999999999949, 20.000000000000014, 20.000000000000014, 18.2, 20.000000000000014, 43.99999999999997, 128.29999999999964, 109.99999999999969, 3.1999999999999615, 20.000000000000014, 107.2999999999999, 20.000000000000014, -20.79999999999989, 67.39999999999993, 41.00000000000006, 22.10000000000005, 21.80000000000004, 43.10000000000016, -9.399999999999876, -4.299999999999827, 41.300000000000246, 20.000000000000014, 53.600000000000065, -55.000000000000334, 16.999999999999982, -100.30000000000038, 11.899999999999958, 51.50000000000015, 24.20000000000009, 20.000000000000014, 146.0, 22.70000000000001, 119.89999999999999, 56.00000000000017, 82.99999999999986], "policy_predator_policy_reward": [219.0, 139.0, 156.0, 160.0, 428.0, 618.0, 1.0, 12.0, 47.0, 221.0, 180.0, 174.0, 97.0, 556.0, 22.0, 225.0, 0.0, 0.0, 255.0, 248.0, 338.0, 9.0, 365.0, 106.0, 165.0, 158.0, 40.0, 320.0, 239.0, 252.0, 93.0, 175.0, 19.0, 44.0, 14.0, 37.0, 231.0, 239.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 0.0, 5.0, 27.0, 11.0, 206.0, 227.0, 3.0, 9.0, 76.0, 92.0, 37.0, 13.0, 0.0, 0.0, 17.0, 0.0, 0.0, 22.0, 11.0, 0.0, 0.0, 0.0, 3.0, 3.0, 32.0, 27.0, 0.0, 0.0, 0.0, 39.0, 22.0, 32.0, 50.0, 0.0, 44.0, 9.0, 6.0, 0.0, 2.0, 0.0, 21.0, 0.0, 4.0, 0.0, 0.0, 0.0, 34.0, 64.0, 32.0, 0.0, 12.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 23.0, 0.0, 18.0, 3.0, 17.0, 0.0, 23.0, 9.0, 18.0, 0.0, 4.0, 7.0, 21.0, 0.0, 15.0, 18.0, 0.0, 7.0, 0.0, 0.0, 15.0, 7.0, 0.0, 0.0, 7.0, 3.0, 15.0, 0.0, 0.0, 4.0, 12.0, 15.0, 0.0, 25.0, 11.0, 0.0, 26.0, 0.0, 9.0, 0.0, 0.0, 25.0, 14.0, 1.0, 18.0, 29.0, 32.0, 0.0, 0.0, 66.0, 0.0, 4.0, 17.0, 0.0, 3.0, 0.0, 0.0, 14.0, 3.0, 12.0, 0.0, 3.0, 8.0, 0.0, 0.0, 0.0, 3.0, 34.0, 15.0, 8.0, 12.0, 6.0, 0.0, 52.0, 0.0, 39.0, 0.0, 4.0, 7.0, 14.0, 16.0, 8.0, 17.0, 18.0, 25.0, 37.0, 4.0, 80.0, 20.0, 0.0, 19.0, 0.0, 0.0, 1.0, 5.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5861554325944833, "mean_inference_ms": 1.8124772186344396, "mean_action_processing_ms": 0.2521770641256289, "mean_env_wait_ms": 0.19460844568114652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062291622161865234, "StateBufferConnector_ms": 0.00301361083984375, "ViewRequirementAgentConnector_ms": 0.09063875675201416}, "num_episodes": 23, "episode_return_max": 323.50000000000097, "episode_return_min": -211.50000000000077, "episode_return_mean": 71.87499999999976, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 384.90769228475, "num_env_steps_trained_throughput_per_sec": 384.90769228475, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 9918.528, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9918.488, "sample_time_ms": 1327.041, "learn_time_ms": 8577.317, "learn_throughput": 466.346, "synch_weights_time_ms": 13.214}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "0b081_00000", "date": "2024-08-13_00-55-28", "timestamp": 1723524928, "time_this_iter_s": 10.399993896484375, "time_total_s": 509.2563886642456, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fbd8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 509.2563886642456, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 39.792857142857144, "ram_util_percent": 82.52142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5321397771911015, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.875585644633051, "policy_loss": -0.003169307479309657, "vf_loss": 0.8784128170401331, "vf_explained_var": 0.018350710944523885, "kl": 0.01441760699189316, "entropy": 1.328328269625467, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.133227169095839, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0437352619473894, "policy_loss": -0.0027093264784309127, "vf_loss": 2.0455940426972807, "vf_explained_var": 0.057083537843492294, "kl": 0.014159764897515054, "entropy": 1.195006880369136, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 323.50000000000097, "episode_reward_min": -73.1000000000013, "episode_reward_mean": 87.69999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.6, "predator_policy": 239.0}, "policy_reward_mean": {"prey_policy": 28.514999999999986, "predator_policy": 15.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.500000000000028, 223.7999999999994, 323.50000000000097, 40.9000000000003, 160.399999999999, 92.1000000000002, 90.00000000000011, 120.89999999999944, 40.30000000000037, 75.10000000000002, 129.8999999999999, 164.199999999999, 95.09999999999967, 139.99999999999898, 219.59999999999934, 84.10000000000008, 41.50000000000029, 39.60000000000022, 148.89999999999915, 13.300000000000027, 88.60000000000008, 80.40000000000016, 59.70000000000022, 108.99999999999866, 152.99999999999952, 23.200000000000028, 101.29999999999865, 75.99999999999999, -67.80000000000052, 218.99999999999974, 52.000000000000476, 239.8999999999993, 50.80000000000049, 39.90000000000031, 77.79999999999947, 77.40000000000006, 28.200000000000074, 17.499999999999968, 39.8000000000003, 166.69999999999962, 120.69999999999968, 110.19999999999894, 211.39999999999955, 38.80000000000008, 32.30000000000019, 37.70000000000021, 189.39999999999904, 52.60000000000049, 157.3999999999996, 131.79999999999868, 37.300000000000274, 95.69999999999894, 58.90000000000033, 186.69999999999905, 138.39999999999998, 166.09999999999874, 58.400000000000034, 134.49999999999872, -73.1000000000013, 25.300000000000065, 114.09999999999906, 40.0000000000003, 24.900000000000063, 69.09999999999994, 124.19999999999882, 40.0000000000003, 41.200000000000294, 221.2999999999997, 133.19999999999914, 133.29999999999956, 51.20000000000027, 147.39999999999904, 54.90000000000046, 63.70000000000036, 62.00000000000036, 116.59999999999928, 3.00000000000023, 11.600000000000216, 94.69999999999881, 165.99999999999955, 148.59999999999968, 144.9999999999986, 28.400000000000116, -46.7999999999996, 209.9999999999992, 40.0000000000003, 52.00000000000031, 82.69999999999942, 56.10000000000035, 93.09999999999846, 56.50000000000035, 28.800000000000146, 32.100000000000186, 40.0000000000003, 69.20000000000036, 40.0000000000003, 45.60000000000041, 33.400000000000205, 45.20000000000026, 78.09999999999941], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-370.9, -105.6, 78.79999999999995, 127.99999999999955, 176.6, 146.8999999999997, 20.000000000000014, 20.900000000000013, 107.89999999999975, 21.500000000000163, 20.000000000000014, 67.10000000000001, -27.699999999999797, 79.70000000000007, -343.79999999999995, 31.700000000000195, 7.999999999999966, 20.300000000000182, -161.20000000000022, 68.30000000000004, -12.400000000000045, 92.30000000000007, 23.600000000000065, 140.59999999999968, 58.10000000000012, 20.000000000000014, 46.40000000000016, 71.59999999999985, 110.89999999999944, 97.70000000000009, 20.000000000000014, 64.09999999999998, 13.700000000000008, 21.800000000000047, 13.099999999999971, -32.49999999999983, 123.50000000000011, 25.40000000000007, 1.4000000000000228, -27.099999999999802, -26.199999999999797, 60.80000000000007, 4.999999999999837, 25.400000000000112, 31.700000000000163, -24.99999999999983, 87.19999999999936, 15.799999999999963, 135.20000000000007, 15.799999999999963, 26.30000000000013, -24.09999999999979, 20.000000000000014, 77.29999999999937, 49.70000000000024, 26.300000000000033, 20.000000000000014, -185.80000000000044, 63.80000000000003, 123.1999999999999, 5.299999999999976, 34.70000000000023, 136.0999999999996, 99.79999999999997, 20.000000000000014, 30.8000000000002, 20.000000000000014, -3.100000000000015, 12.499999999999945, 47.30000000000019, 28.400000000000098, 29.00000000000004, 20.000000000000014, -14.799999999999772, -30.399999999999892, 20.90000000000003, 17.599999999999984, 18.19999999999999, 36.80000000000009, 101.90000000000002, 85.7, 20.000000000000014, 78.49999999999952, 13.699999999999964, 71.29999999999997, 133.09999999999997, 5.900000000000091, 17.899999999999988, 5.299999999999965, 20.000000000000014, 20.000000000000014, 10.699999999999951, 96.49999999999949, 74.90000000000003, 20.90000000000003, 31.700000000000212, 121.4, 20.000000000000014, 76.69999999999946, 40.1000000000002, 18.499999999999993, -17.19999999999977, -34.59999999999975, 104.29999999999949, 29.90000000000009, 20.000000000000014, 166.69999999999982, 20.000000000000014, 59.900000000000055, 39.500000000000064, 71.29999999999968, 75.79999999999998, -22.600000000000293, 20.000000000000014, 114.49999999999946, 20.000000000000014, -115.00000000000054, -24.099999999999795, -15.699999999999747, 20.000000000000014, 36.20000000000015, 74.89999999999955, 20.000000000000014, 20.000000000000014, 17.299999999999976, -9.399999999999862, -3.099999999999972, 60.20000000000013, 3.1999999999999615, 109.99999999999949, 20.000000000000014, 20.000000000000014, 18.2, 20.000000000000014, 43.99999999999997, 128.29999999999964, 109.99999999999969, 3.1999999999999615, 20.000000000000014, 107.2999999999999, 20.000000000000014, -20.79999999999989, 67.39999999999993, 41.00000000000006, 22.10000000000005, 21.80000000000004, 43.10000000000016, -9.399999999999876, -4.299999999999827, 41.300000000000246, 20.000000000000014, 53.600000000000065, -55.000000000000334, 16.999999999999982, -100.30000000000038, 11.899999999999958, 51.50000000000015, 24.20000000000009, 20.000000000000014, 146.0, 22.70000000000001, 119.89999999999999, 56.00000000000017, 82.99999999999986, 2.8999999999999613, 12.499999999999964, -19.899999999999743, -118.90000000000062, 165.49999999999997, 30.500000000000203, 20.000000000000014, 20.000000000000014, 35.300000000000125, 13.699999999999964, -15.399999999999833, 64.10000000000011, 20.000000000000014, -1.9, 20.000000000000014, 73.09999999999955, 25.40000000000011, 19.100000000000005, -1.6000000000000405, 10.399999999999968, 4.0999999999999766, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.400000000000205, -17.19999999999991, 20.000000000000014, 20.000000000000014, 21.80000000000005, -2.2000000000000286, 20.000000000000014, 7.399999999999965, -1.0000000000000062, 36.20000000000012, 46.100000000000186, 20.000000000000014], "policy_predator_policy_reward": [231.0, 239.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 18.0, 0.0, 5.0, 27.0, 11.0, 206.0, 227.0, 3.0, 9.0, 76.0, 92.0, 37.0, 13.0, 0.0, 0.0, 17.0, 0.0, 0.0, 22.0, 11.0, 0.0, 0.0, 0.0, 3.0, 3.0, 32.0, 27.0, 0.0, 0.0, 0.0, 39.0, 22.0, 32.0, 50.0, 0.0, 44.0, 9.0, 6.0, 0.0, 2.0, 0.0, 21.0, 0.0, 4.0, 0.0, 0.0, 0.0, 34.0, 64.0, 32.0, 0.0, 12.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 23.0, 0.0, 18.0, 3.0, 17.0, 0.0, 23.0, 9.0, 18.0, 0.0, 4.0, 7.0, 21.0, 0.0, 15.0, 18.0, 0.0, 7.0, 0.0, 0.0, 15.0, 7.0, 0.0, 0.0, 7.0, 3.0, 15.0, 0.0, 0.0, 4.0, 12.0, 15.0, 0.0, 25.0, 11.0, 0.0, 26.0, 0.0, 9.0, 0.0, 0.0, 25.0, 14.0, 1.0, 18.0, 29.0, 32.0, 0.0, 0.0, 66.0, 0.0, 4.0, 17.0, 0.0, 3.0, 0.0, 0.0, 14.0, 3.0, 12.0, 0.0, 3.0, 8.0, 0.0, 0.0, 0.0, 3.0, 34.0, 15.0, 8.0, 12.0, 6.0, 0.0, 52.0, 0.0, 39.0, 0.0, 4.0, 7.0, 14.0, 16.0, 8.0, 17.0, 18.0, 25.0, 37.0, 4.0, 80.0, 20.0, 0.0, 19.0, 0.0, 0.0, 1.0, 5.0, 6.0, 0.0, 10.0, 3.0, 55.0, 37.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 18.0, 16.0, 15.0, 23.0, 0.0, 0.0, 0.0, 12.0, 0.0, 20.0, 8.0, 0.0, 0.0, 0.0, 1.0, 33.0, 0.0, 0.0, 21.0, 5.0, 6.0, 0.0, 0.0, 10.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5855997305752516, "mean_inference_ms": 1.8152414429206964, "mean_action_processing_ms": 0.25210346925524535, "mean_env_wait_ms": 0.1943873303533523, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00581514835357666, "StateBufferConnector_ms": 0.0029627084732055664, "ViewRequirementAgentConnector_ms": 0.09071111679077148}, "num_episodes": 18, "episode_return_max": 323.50000000000097, "episode_return_min": -73.1000000000013, "episode_return_mean": 87.69999999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.3700112519891, "num_env_steps_trained_throughput_per_sec": 351.3700112519891, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 10063.857, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10063.816, "sample_time_ms": 1331.463, "learn_time_ms": 8718.056, "learn_throughput": 458.818, "synch_weights_time_ms": 13.296}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "0b081_00000", "date": "2024-08-13_00-55-40", "timestamp": 1723524940, "time_this_iter_s": 11.454226970672607, "time_total_s": 520.7106156349182, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fbdaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 520.7106156349182, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 42.805882352941175, "ram_util_percent": 83.04705882352943}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4846529160503042, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7305531068611397, "policy_loss": -0.005249303525372866, "vf_loss": 0.7353730041459794, "vf_explained_var": 0.011233929256913524, "kl": 0.018095170829807668, "entropy": 1.3652341711458076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2015464449094402, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3882981829542334, "policy_loss": -0.004025614166277505, "vf_loss": 2.3910475482385625, "vf_explained_var": 0.11449298149063473, "kl": 0.02124690596477628, "entropy": 1.1941266698181314, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 239.8999999999993, "episode_reward_min": -73.1000000000013, "episode_reward_mean": 79.2979999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -185.80000000000044, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 166.69999999999982, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 29.803999999999977, "predator_policy": 9.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [148.89999999999915, 13.300000000000027, 88.60000000000008, 80.40000000000016, 59.70000000000022, 108.99999999999866, 152.99999999999952, 23.200000000000028, 101.29999999999865, 75.99999999999999, -67.80000000000052, 218.99999999999974, 52.000000000000476, 239.8999999999993, 50.80000000000049, 39.90000000000031, 77.79999999999947, 77.40000000000006, 28.200000000000074, 17.499999999999968, 39.8000000000003, 166.69999999999962, 120.69999999999968, 110.19999999999894, 211.39999999999955, 38.80000000000008, 32.30000000000019, 37.70000000000021, 189.39999999999904, 52.60000000000049, 157.3999999999996, 131.79999999999868, 37.300000000000274, 95.69999999999894, 58.90000000000033, 186.69999999999905, 138.39999999999998, 166.09999999999874, 58.400000000000034, 134.49999999999872, -73.1000000000013, 25.300000000000065, 114.09999999999906, 40.0000000000003, 24.900000000000063, 69.09999999999994, 124.19999999999882, 40.0000000000003, 41.200000000000294, 221.2999999999997, 133.19999999999914, 133.29999999999956, 51.20000000000027, 147.39999999999904, 54.90000000000046, 63.70000000000036, 62.00000000000036, 116.59999999999928, 3.00000000000023, 11.600000000000216, 94.69999999999881, 165.99999999999955, 148.59999999999968, 144.9999999999986, 28.400000000000116, -46.7999999999996, 209.9999999999992, 40.0000000000003, 52.00000000000031, 82.69999999999942, 56.10000000000035, 93.09999999999846, 56.50000000000035, 28.800000000000146, 32.100000000000186, 40.0000000000003, 69.20000000000036, 40.0000000000003, 45.60000000000041, 33.400000000000205, 45.20000000000026, 78.09999999999941, 40.0000000000003, 40.0000000000003, 63.70000000000009, 12.799999999999958, 71.39999999999979, 106.8999999999992, 40.0000000000003, 36.90000000000027, 132.69999999999942, 93.19999999999894, 57.70000000000041, 52.40000000000051, 42.70000000000034, 133.29999999999885, 40.0000000000003, 57.00000000000041, 42.90000000000035, 170.69999999999888], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [123.50000000000011, 25.40000000000007, 1.4000000000000228, -27.099999999999802, -26.199999999999797, 60.80000000000007, 4.999999999999837, 25.400000000000112, 31.700000000000163, -24.99999999999983, 87.19999999999936, 15.799999999999963, 135.20000000000007, 15.799999999999963, 26.30000000000013, -24.09999999999979, 20.000000000000014, 77.29999999999937, 49.70000000000024, 26.300000000000033, 20.000000000000014, -185.80000000000044, 63.80000000000003, 123.1999999999999, 5.299999999999976, 34.70000000000023, 136.0999999999996, 99.79999999999997, 20.000000000000014, 30.8000000000002, 20.000000000000014, -3.100000000000015, 12.499999999999945, 47.30000000000019, 28.400000000000098, 29.00000000000004, 20.000000000000014, -14.799999999999772, -30.399999999999892, 20.90000000000003, 17.599999999999984, 18.19999999999999, 36.80000000000009, 101.90000000000002, 85.7, 20.000000000000014, 78.49999999999952, 13.699999999999964, 71.29999999999997, 133.09999999999997, 5.900000000000091, 17.899999999999988, 5.299999999999965, 20.000000000000014, 20.000000000000014, 10.699999999999951, 96.49999999999949, 74.90000000000003, 20.90000000000003, 31.700000000000212, 121.4, 20.000000000000014, 76.69999999999946, 40.1000000000002, 18.499999999999993, -17.19999999999977, -34.59999999999975, 104.29999999999949, 29.90000000000009, 20.000000000000014, 166.69999999999982, 20.000000000000014, 59.900000000000055, 39.500000000000064, 71.29999999999968, 75.79999999999998, -22.600000000000293, 20.000000000000014, 114.49999999999946, 20.000000000000014, -115.00000000000054, -24.099999999999795, -15.699999999999747, 20.000000000000014, 36.20000000000015, 74.89999999999955, 20.000000000000014, 20.000000000000014, 17.299999999999976, -9.399999999999862, -3.099999999999972, 60.20000000000013, 3.1999999999999615, 109.99999999999949, 20.000000000000014, 20.000000000000014, 18.2, 20.000000000000014, 43.99999999999997, 128.29999999999964, 109.99999999999969, 3.1999999999999615, 20.000000000000014, 107.2999999999999, 20.000000000000014, -20.79999999999989, 67.39999999999993, 41.00000000000006, 22.10000000000005, 21.80000000000004, 43.10000000000016, -9.399999999999876, -4.299999999999827, 41.300000000000246, 20.000000000000014, 53.600000000000065, -55.000000000000334, 16.999999999999982, -100.30000000000038, 11.899999999999958, 51.50000000000015, 24.20000000000009, 20.000000000000014, 146.0, 22.70000000000001, 119.89999999999999, 56.00000000000017, 82.99999999999986, 2.8999999999999613, 12.499999999999964, -19.899999999999743, -118.90000000000062, 165.49999999999997, 30.500000000000203, 20.000000000000014, 20.000000000000014, 35.300000000000125, 13.699999999999964, -15.399999999999833, 64.10000000000011, 20.000000000000014, -1.9, 20.000000000000014, 73.09999999999955, 25.40000000000011, 19.100000000000005, -1.6000000000000405, 10.399999999999968, 4.0999999999999766, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.400000000000205, -17.19999999999991, 20.000000000000014, 20.000000000000014, 21.80000000000005, -2.2000000000000286, 20.000000000000014, 7.399999999999965, -1.0000000000000062, 36.20000000000012, 46.100000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 24.80000000000016, 5.299999999999965, -20.499999999999815, 16.400000000000045, 20.000000000000014, 72.49999999999964, 7.399999999999965, 20.000000000000014, 20.000000000000014, -3.100000000000001, 20.000000000000014, 20.000000000000014, 112.69999999999985, 70.09999999999971, 1.0999999999999794, 47.60000000000019, -22.89999999999977, 31.400000000000208, 20.000000000000014, 22.700000000000053, 20.000000000000014, 106.39999999999962, 20.900000000000027, 20.000000000000014, 20.000000000000014, 9.499999999999982, 24.50000000000008, 20.000000000000014, 5.8999999999999995, 86.59999999999937, 76.09999999999954], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 39.0, 22.0, 32.0, 50.0, 0.0, 44.0, 9.0, 6.0, 0.0, 2.0, 0.0, 21.0, 0.0, 4.0, 0.0, 0.0, 0.0, 34.0, 64.0, 32.0, 0.0, 12.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 23.0, 0.0, 18.0, 3.0, 17.0, 0.0, 23.0, 9.0, 18.0, 0.0, 4.0, 7.0, 21.0, 0.0, 15.0, 18.0, 0.0, 7.0, 0.0, 0.0, 15.0, 7.0, 0.0, 0.0, 7.0, 3.0, 15.0, 0.0, 0.0, 4.0, 12.0, 15.0, 0.0, 25.0, 11.0, 0.0, 26.0, 0.0, 9.0, 0.0, 0.0, 25.0, 14.0, 1.0, 18.0, 29.0, 32.0, 0.0, 0.0, 66.0, 0.0, 4.0, 17.0, 0.0, 3.0, 0.0, 0.0, 14.0, 3.0, 12.0, 0.0, 3.0, 8.0, 0.0, 0.0, 0.0, 3.0, 34.0, 15.0, 8.0, 12.0, 6.0, 0.0, 52.0, 0.0, 39.0, 0.0, 4.0, 7.0, 14.0, 16.0, 8.0, 17.0, 18.0, 25.0, 37.0, 4.0, 80.0, 20.0, 0.0, 19.0, 0.0, 0.0, 1.0, 5.0, 6.0, 0.0, 10.0, 3.0, 55.0, 37.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 18.0, 16.0, 15.0, 23.0, 0.0, 0.0, 0.0, 12.0, 0.0, 20.0, 8.0, 0.0, 0.0, 0.0, 1.0, 33.0, 0.0, 0.0, 21.0, 5.0, 6.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 21.0, 12.0, 23.0, 4.0, 23.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 13.0, 9.0, 27.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 11.0, 12.0, 17.0, 0.0, 8.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5868726061204275, "mean_inference_ms": 1.8191409735706514, "mean_action_processing_ms": 0.2522759862576986, "mean_env_wait_ms": 0.19456234546114776, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005650639533996582, "StateBufferConnector_ms": 0.004150748252868652, "ViewRequirementAgentConnector_ms": 0.11839497089385986}, "num_episodes": 18, "episode_return_max": 239.8999999999993, "episode_return_min": -73.1000000000013, "episode_return_mean": 79.2979999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.5415714073066, "num_env_steps_trained_throughput_per_sec": 341.5415714073066, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 10229.528, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10229.489, "sample_time_ms": 1402.368, "learn_time_ms": 8812.645, "learn_throughput": 453.893, "synch_weights_time_ms": 13.381}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "0b081_00000", "date": "2024-08-13_00-55-52", "timestamp": 1723524952, "time_this_iter_s": 11.718955039978027, "time_total_s": 532.4295706748962, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d57790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 532.4295706748962, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 49.181250000000006, "ram_util_percent": 83.17500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5075741500490242, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7812164712204505, "policy_loss": -0.004898545846821021, "vf_loss": 0.7858105858245855, "vf_explained_var": 0.005398629235212134, "kl": 0.012828618480659266, "entropy": 1.332213257734107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4970999325551684, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.022228186628806, "policy_loss": -0.003062804426662821, "vf_loss": 2.0244084243105833, "vf_explained_var": 0.0519017238780935, "kl": 0.009795263777499995, "entropy": 1.1775601736452215, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 221.2999999999997, "episode_reward_min": -73.1000000000013, "episode_reward_mean": 76.97999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -118.90000000000062, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 166.69999999999982, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 29.269999999999985, "predator_policy": 9.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.200000000000074, 17.499999999999968, 39.8000000000003, 166.69999999999962, 120.69999999999968, 110.19999999999894, 211.39999999999955, 38.80000000000008, 32.30000000000019, 37.70000000000021, 189.39999999999904, 52.60000000000049, 157.3999999999996, 131.79999999999868, 37.300000000000274, 95.69999999999894, 58.90000000000033, 186.69999999999905, 138.39999999999998, 166.09999999999874, 58.400000000000034, 134.49999999999872, -73.1000000000013, 25.300000000000065, 114.09999999999906, 40.0000000000003, 24.900000000000063, 69.09999999999994, 124.19999999999882, 40.0000000000003, 41.200000000000294, 221.2999999999997, 133.19999999999914, 133.29999999999956, 51.20000000000027, 147.39999999999904, 54.90000000000046, 63.70000000000036, 62.00000000000036, 116.59999999999928, 3.00000000000023, 11.600000000000216, 94.69999999999881, 165.99999999999955, 148.59999999999968, 144.9999999999986, 28.400000000000116, -46.7999999999996, 209.9999999999992, 40.0000000000003, 52.00000000000031, 82.69999999999942, 56.10000000000035, 93.09999999999846, 56.50000000000035, 28.800000000000146, 32.100000000000186, 40.0000000000003, 69.20000000000036, 40.0000000000003, 45.60000000000041, 33.400000000000205, 45.20000000000026, 78.09999999999941, 40.0000000000003, 40.0000000000003, 63.70000000000009, 12.799999999999958, 71.39999999999979, 106.8999999999992, 40.0000000000003, 36.90000000000027, 132.69999999999942, 93.19999999999894, 57.70000000000041, 52.40000000000051, 42.70000000000034, 133.29999999999885, 40.0000000000003, 57.00000000000041, 42.90000000000035, 170.69999999999888, 40.0000000000003, 14.899999999999952, 77.59999999999934, 59.00000000000033, 140.69999999999882, 97.59999999999897, 92.49999999999872, 96.39999999999863, 56.50000000000031, 71.49999999999996, 82.2999999999992, 40.0000000000003, 144.59999999999954, 40.0000000000003, 142.59999999999903, 21.299999999999994, 53.10000000000051, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -14.799999999999772, -30.399999999999892, 20.90000000000003, 17.599999999999984, 18.19999999999999, 36.80000000000009, 101.90000000000002, 85.7, 20.000000000000014, 78.49999999999952, 13.699999999999964, 71.29999999999997, 133.09999999999997, 5.900000000000091, 17.899999999999988, 5.299999999999965, 20.000000000000014, 20.000000000000014, 10.699999999999951, 96.49999999999949, 74.90000000000003, 20.90000000000003, 31.700000000000212, 121.4, 20.000000000000014, 76.69999999999946, 40.1000000000002, 18.499999999999993, -17.19999999999977, -34.59999999999975, 104.29999999999949, 29.90000000000009, 20.000000000000014, 166.69999999999982, 20.000000000000014, 59.900000000000055, 39.500000000000064, 71.29999999999968, 75.79999999999998, -22.600000000000293, 20.000000000000014, 114.49999999999946, 20.000000000000014, -115.00000000000054, -24.099999999999795, -15.699999999999747, 20.000000000000014, 36.20000000000015, 74.89999999999955, 20.000000000000014, 20.000000000000014, 17.299999999999976, -9.399999999999862, -3.099999999999972, 60.20000000000013, 3.1999999999999615, 109.99999999999949, 20.000000000000014, 20.000000000000014, 18.2, 20.000000000000014, 43.99999999999997, 128.29999999999964, 109.99999999999969, 3.1999999999999615, 20.000000000000014, 107.2999999999999, 20.000000000000014, -20.79999999999989, 67.39999999999993, 41.00000000000006, 22.10000000000005, 21.80000000000004, 43.10000000000016, -9.399999999999876, -4.299999999999827, 41.300000000000246, 20.000000000000014, 53.600000000000065, -55.000000000000334, 16.999999999999982, -100.30000000000038, 11.899999999999958, 51.50000000000015, 24.20000000000009, 20.000000000000014, 146.0, 22.70000000000001, 119.89999999999999, 56.00000000000017, 82.99999999999986, 2.8999999999999613, 12.499999999999964, -19.899999999999743, -118.90000000000062, 165.49999999999997, 30.500000000000203, 20.000000000000014, 20.000000000000014, 35.300000000000125, 13.699999999999964, -15.399999999999833, 64.10000000000011, 20.000000000000014, -1.9, 20.000000000000014, 73.09999999999955, 25.40000000000011, 19.100000000000005, -1.6000000000000405, 10.399999999999968, 4.0999999999999766, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.400000000000205, -17.19999999999991, 20.000000000000014, 20.000000000000014, 21.80000000000005, -2.2000000000000286, 20.000000000000014, 7.399999999999965, -1.0000000000000062, 36.20000000000012, 46.100000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 24.80000000000016, 5.299999999999965, -20.499999999999815, 16.400000000000045, 20.000000000000014, 72.49999999999964, 7.399999999999965, 20.000000000000014, 20.000000000000014, -3.100000000000001, 20.000000000000014, 20.000000000000014, 112.69999999999985, 70.09999999999971, 1.0999999999999794, 47.60000000000019, -22.89999999999977, 31.400000000000208, 20.000000000000014, 22.700000000000053, 20.000000000000014, 106.39999999999962, 20.900000000000027, 20.000000000000014, 20.000000000000014, 9.499999999999982, 24.50000000000008, 20.000000000000014, 5.8999999999999995, 86.59999999999937, 76.09999999999954, 20.000000000000014, 20.000000000000014, 5.599999999999975, -42.69999999999982, 20.60000000000007, 10.99999999999997, 20.000000000000014, 7.999999999999989, 72.19999999999956, 45.50000000000015, 75.7999999999995, 21.80000000000004, -19.299999999999784, 78.79999999999933, 57.80000000000017, 29.600000000000183, 20.000000000000014, 15.499999999999988, 20.000000000000014, 51.500000000000234, 41.60000000000025, 40.700000000000244, 20.000000000000014, 20.000000000000014, 40.100000000000136, 27.500000000000007, 20.000000000000014, 20.000000000000014, 38.900000000000254, 103.69999999999968, -15.699999999999747, 20.000000000000014, 31.100000000000204, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 23.0, 9.0, 18.0, 0.0, 4.0, 7.0, 21.0, 0.0, 15.0, 18.0, 0.0, 7.0, 0.0, 0.0, 15.0, 7.0, 0.0, 0.0, 7.0, 3.0, 15.0, 0.0, 0.0, 4.0, 12.0, 15.0, 0.0, 25.0, 11.0, 0.0, 26.0, 0.0, 9.0, 0.0, 0.0, 25.0, 14.0, 1.0, 18.0, 29.0, 32.0, 0.0, 0.0, 66.0, 0.0, 4.0, 17.0, 0.0, 3.0, 0.0, 0.0, 14.0, 3.0, 12.0, 0.0, 3.0, 8.0, 0.0, 0.0, 0.0, 3.0, 34.0, 15.0, 8.0, 12.0, 6.0, 0.0, 52.0, 0.0, 39.0, 0.0, 4.0, 7.0, 14.0, 16.0, 8.0, 17.0, 18.0, 25.0, 37.0, 4.0, 80.0, 20.0, 0.0, 19.0, 0.0, 0.0, 1.0, 5.0, 6.0, 0.0, 10.0, 3.0, 55.0, 37.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 18.0, 16.0, 15.0, 23.0, 0.0, 0.0, 0.0, 12.0, 0.0, 20.0, 8.0, 0.0, 0.0, 0.0, 1.0, 33.0, 0.0, 0.0, 21.0, 5.0, 6.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 21.0, 12.0, 23.0, 4.0, 23.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 13.0, 9.0, 27.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 11.0, 12.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 6.0, 46.0, 9.0, 37.0, 12.0, 19.0, 23.0, 0.0, 0.0, 0.0, 28.0, 5.0, 0.0, 9.0, 20.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.588182760755711, "mean_inference_ms": 1.8229710453392913, "mean_action_processing_ms": 0.2524437091255387, "mean_env_wait_ms": 0.19477218571727176, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005281805992126465, "StateBufferConnector_ms": 0.00417017936706543, "ViewRequirementAgentConnector_ms": 0.11919653415679932}, "num_episodes": 18, "episode_return_max": 221.2999999999997, "episode_return_min": -73.1000000000013, "episode_return_mean": 76.97999999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.7423213937373, "num_env_steps_trained_throughput_per_sec": 404.7423213937373, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 10224.909, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10224.871, "sample_time_ms": 1401.229, "learn_time_ms": 8809.284, "learn_throughput": 454.066, "synch_weights_time_ms": 13.266}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "0b081_00000", "date": "2024-08-13_00-56-02", "timestamp": 1723524962, "time_this_iter_s": 9.887722969055176, "time_total_s": 542.3172936439514, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d57670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 542.3172936439514, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 37.06428571428571, "ram_util_percent": 81.5142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5757521685942141, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.753846522172292, "policy_loss": -0.0041817701672987335, "vf_loss": 1.7578561439715996, "vf_explained_var": 0.001312047211581437, "kl": 0.007254297985894352, "entropy": 1.2327914080922566, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3486373415423765, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8496367568376835, "policy_loss": -0.0009757468813202447, "vf_loss": 1.850098178247926, "vf_explained_var": -0.016506127705649725, "kl": 0.005708277239630565, "entropy": 1.1853458600700217, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 221.2999999999997, "episode_reward_min": -73.1000000000013, "episode_reward_mean": 68.67899999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -118.90000000000062, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.49999999999997, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 24.174499999999988, "predator_policy": 10.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-73.1000000000013, 25.300000000000065, 114.09999999999906, 40.0000000000003, 24.900000000000063, 69.09999999999994, 124.19999999999882, 40.0000000000003, 41.200000000000294, 221.2999999999997, 133.19999999999914, 133.29999999999956, 51.20000000000027, 147.39999999999904, 54.90000000000046, 63.70000000000036, 62.00000000000036, 116.59999999999928, 3.00000000000023, 11.600000000000216, 94.69999999999881, 165.99999999999955, 148.59999999999968, 144.9999999999986, 28.400000000000116, -46.7999999999996, 209.9999999999992, 40.0000000000003, 52.00000000000031, 82.69999999999942, 56.10000000000035, 93.09999999999846, 56.50000000000035, 28.800000000000146, 32.100000000000186, 40.0000000000003, 69.20000000000036, 40.0000000000003, 45.60000000000041, 33.400000000000205, 45.20000000000026, 78.09999999999941, 40.0000000000003, 40.0000000000003, 63.70000000000009, 12.799999999999958, 71.39999999999979, 106.8999999999992, 40.0000000000003, 36.90000000000027, 132.69999999999942, 93.19999999999894, 57.70000000000041, 52.40000000000051, 42.70000000000034, 133.29999999999885, 40.0000000000003, 57.00000000000041, 42.90000000000035, 170.69999999999888, 40.0000000000003, 14.899999999999952, 77.59999999999934, 59.00000000000033, 140.69999999999882, 97.59999999999897, 92.49999999999872, 96.39999999999863, 56.50000000000031, 71.49999999999996, 82.2999999999992, 40.0000000000003, 144.59999999999954, 40.0000000000003, 142.59999999999903, 21.299999999999994, 53.10000000000051, 40.0000000000003, 141.69999999999848, 21.100000000000016, 42.500000000000256, 44.60000000000043, 57.40000000000038, 8.100000000000067, 57.10000000000024, 12.89999999999994, 117.09999999999938, 91.89999999999901, 40.0000000000003, 40.0000000000003, 83.69999999999906, 30.00000000000015, 68.60000000000012, 41.800000000000324, 40.0000000000003, 180.29999999999905, 93.09999999999897, 32.60000000000019, 86.79999999999883, 49.10000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-115.00000000000054, -24.099999999999795, -15.699999999999747, 20.000000000000014, 36.20000000000015, 74.89999999999955, 20.000000000000014, 20.000000000000014, 17.299999999999976, -9.399999999999862, -3.099999999999972, 60.20000000000013, 3.1999999999999615, 109.99999999999949, 20.000000000000014, 20.000000000000014, 18.2, 20.000000000000014, 43.99999999999997, 128.29999999999964, 109.99999999999969, 3.1999999999999615, 20.000000000000014, 107.2999999999999, 20.000000000000014, -20.79999999999989, 67.39999999999993, 41.00000000000006, 22.10000000000005, 21.80000000000004, 43.10000000000016, -9.399999999999876, -4.299999999999827, 41.300000000000246, 20.000000000000014, 53.600000000000065, -55.000000000000334, 16.999999999999982, -100.30000000000038, 11.899999999999958, 51.50000000000015, 24.20000000000009, 20.000000000000014, 146.0, 22.70000000000001, 119.89999999999999, 56.00000000000017, 82.99999999999986, 2.8999999999999613, 12.499999999999964, -19.899999999999743, -118.90000000000062, 165.49999999999997, 30.500000000000203, 20.000000000000014, 20.000000000000014, 35.300000000000125, 13.699999999999964, -15.399999999999833, 64.10000000000011, 20.000000000000014, -1.9, 20.000000000000014, 73.09999999999955, 25.40000000000011, 19.100000000000005, -1.6000000000000405, 10.399999999999968, 4.0999999999999766, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.400000000000205, -17.19999999999991, 20.000000000000014, 20.000000000000014, 21.80000000000005, -2.2000000000000286, 20.000000000000014, 7.399999999999965, -1.0000000000000062, 36.20000000000012, 46.100000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 24.80000000000016, 5.299999999999965, -20.499999999999815, 16.400000000000045, 20.000000000000014, 72.49999999999964, 7.399999999999965, 20.000000000000014, 20.000000000000014, -3.100000000000001, 20.000000000000014, 20.000000000000014, 112.69999999999985, 70.09999999999971, 1.0999999999999794, 47.60000000000019, -22.89999999999977, 31.400000000000208, 20.000000000000014, 22.700000000000053, 20.000000000000014, 106.39999999999962, 20.900000000000027, 20.000000000000014, 20.000000000000014, 9.499999999999982, 24.50000000000008, 20.000000000000014, 5.8999999999999995, 86.59999999999937, 76.09999999999954, 20.000000000000014, 20.000000000000014, 5.599999999999975, -42.69999999999982, 20.60000000000007, 10.99999999999997, 20.000000000000014, 7.999999999999989, 72.19999999999956, 45.50000000000015, 75.7999999999995, 21.80000000000004, -19.299999999999784, 78.79999999999933, 57.80000000000017, 29.600000000000183, 20.000000000000014, 15.499999999999988, 20.000000000000014, 51.500000000000234, 41.60000000000025, 40.700000000000244, 20.000000000000014, 20.000000000000014, 40.100000000000136, 27.500000000000007, 20.000000000000014, 20.000000000000014, 38.900000000000254, 103.69999999999968, -15.699999999999747, 20.000000000000014, 31.100000000000204, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 47.90000000000022, -3.0999999999999615, -23.799999999999827, 20.000000000000014, -50.49999999999991, -23.799999999999784, 37.40000000000024, -88.90000000000062, 53.30000000000023, -40.89999999999977, 20.000000000000014, -0.39999999999995095, 21.500000000000043, -57.09999999999999, 20.000000000000014, 23.60000000000007, 78.49999999999987, 76.39999999999947, -89.50000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.099999999999971, 59.60000000000022, -58.00000000000031, 20.000000000000014, 49.700000000000216, 17.899999999999988, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 72.19999999999962, 103.09999999999977, 20.000000000000014, 73.0999999999995, 20.000000000000014, 2.599999999999961, 45.20000000000021, 41.60000000000024, 20.000000000000014, 25.100000000000094], "policy_predator_policy_reward": [66.0, 0.0, 4.0, 17.0, 0.0, 3.0, 0.0, 0.0, 14.0, 3.0, 12.0, 0.0, 3.0, 8.0, 0.0, 0.0, 0.0, 3.0, 34.0, 15.0, 8.0, 12.0, 6.0, 0.0, 52.0, 0.0, 39.0, 0.0, 4.0, 7.0, 14.0, 16.0, 8.0, 17.0, 18.0, 25.0, 37.0, 4.0, 80.0, 20.0, 0.0, 19.0, 0.0, 0.0, 1.0, 5.0, 6.0, 0.0, 10.0, 3.0, 55.0, 37.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 18.0, 16.0, 15.0, 23.0, 0.0, 0.0, 0.0, 12.0, 0.0, 20.0, 8.0, 0.0, 0.0, 0.0, 1.0, 33.0, 0.0, 0.0, 21.0, 5.0, 6.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 21.0, 12.0, 23.0, 4.0, 23.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 13.0, 9.0, 27.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 11.0, 12.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 6.0, 46.0, 9.0, 37.0, 12.0, 19.0, 23.0, 0.0, 0.0, 0.0, 28.0, 5.0, 0.0, 9.0, 20.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 24.0, 54.0, 19.0, 26.0, 5.0, 36.0, 57.0, 29.0, 0.0, 11.0, 25.0, 42.0, 8.0, 14.0, 1.0, 59.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 22.0, 46.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5895385138961559, "mean_inference_ms": 1.8272052895792468, "mean_action_processing_ms": 0.25261107163969165, "mean_env_wait_ms": 0.19498785856340142, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004774808883666992, "StateBufferConnector_ms": 0.004212021827697754, "ViewRequirementAgentConnector_ms": 0.12321698665618896}, "num_episodes": 22, "episode_return_max": 221.2999999999997, "episode_return_min": -73.1000000000013, "episode_return_mean": 68.67899999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 408.93109415750604, "num_env_steps_trained_throughput_per_sec": 408.93109415750604, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 10204.332, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10204.294, "sample_time_ms": 1388.916, "learn_time_ms": 8801.092, "learn_throughput": 454.489, "synch_weights_time_ms": 13.215}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "0b081_00000", "date": "2024-08-13_00-56-11", "timestamp": 1723524971, "time_this_iter_s": 9.785887241363525, "time_total_s": 552.1031808853149, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fa7a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 552.1031808853149, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 35.607142857142854, "ram_util_percent": 81.58571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5641188343917882, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.179089077313741, "policy_loss": -0.004944437536750994, "vf_loss": 1.1837222961994707, "vf_explained_var": 0.002168975620673447, "kl": 0.013114698052750617, "entropy": 1.2056360968206294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2257236929245727, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8691633306956166, "policy_loss": -0.0010848188462972681, "vf_loss": 1.8698370077937998, "vf_explained_var": 0.0742871503350596, "kl": 0.004563056651170326, "entropy": 1.2169537924584888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 209.9999999999992, "episode_reward_min": -61.20000000000161, "episode_reward_mean": 59.90899999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -118.90000000000062, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.49999999999997, "predator_policy": 69.0}, "policy_reward_mean": {"prey_policy": 19.764499999999995, "predator_policy": 10.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [144.9999999999986, 28.400000000000116, -46.7999999999996, 209.9999999999992, 40.0000000000003, 52.00000000000031, 82.69999999999942, 56.10000000000035, 93.09999999999846, 56.50000000000035, 28.800000000000146, 32.100000000000186, 40.0000000000003, 69.20000000000036, 40.0000000000003, 45.60000000000041, 33.400000000000205, 45.20000000000026, 78.09999999999941, 40.0000000000003, 40.0000000000003, 63.70000000000009, 12.799999999999958, 71.39999999999979, 106.8999999999992, 40.0000000000003, 36.90000000000027, 132.69999999999942, 93.19999999999894, 57.70000000000041, 52.40000000000051, 42.70000000000034, 133.29999999999885, 40.0000000000003, 57.00000000000041, 42.90000000000035, 170.69999999999888, 40.0000000000003, 14.899999999999952, 77.59999999999934, 59.00000000000033, 140.69999999999882, 97.59999999999897, 92.49999999999872, 96.39999999999863, 56.50000000000031, 71.49999999999996, 82.2999999999992, 40.0000000000003, 144.59999999999954, 40.0000000000003, 142.59999999999903, 21.299999999999994, 53.10000000000051, 40.0000000000003, 141.69999999999848, 21.100000000000016, 42.500000000000256, 44.60000000000043, 57.40000000000038, 8.100000000000067, 57.10000000000024, 12.89999999999994, 117.09999999999938, 91.89999999999901, 40.0000000000003, 40.0000000000003, 83.69999999999906, 30.00000000000015, 68.60000000000012, 41.800000000000324, 40.0000000000003, 180.29999999999905, 93.09999999999897, 32.60000000000019, 86.79999999999883, 49.10000000000036, 40.800000000000345, 52.400000000000496, 0.10000000000019293, 40.600000000000314, 2.3000000000000056, 31.500000000000174, 58.000000000000426, 21.100000000000147, 49.900000000000404, -61.20000000000161, 62.50000000000031, 63.30000000000041, 40.0000000000003, 85.19999999999912, 31.60000000000018, 67.00000000000018, 40.0000000000003, 28.50000000000013, 57.400000000000354, 31.90000000000018, 62.200000000000514, 73.59999999999962, 57.5000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [56.00000000000017, 82.99999999999986, 2.8999999999999613, 12.499999999999964, -19.899999999999743, -118.90000000000062, 165.49999999999997, 30.500000000000203, 20.000000000000014, 20.000000000000014, 35.300000000000125, 13.699999999999964, -15.399999999999833, 64.10000000000011, 20.000000000000014, -1.9, 20.000000000000014, 73.09999999999955, 25.40000000000011, 19.100000000000005, -1.6000000000000405, 10.399999999999968, 4.0999999999999766, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.400000000000205, -17.19999999999991, 20.000000000000014, 20.000000000000014, 21.80000000000005, -2.2000000000000286, 20.000000000000014, 7.399999999999965, -1.0000000000000062, 36.20000000000012, 46.100000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 24.80000000000016, 5.299999999999965, -20.499999999999815, 16.400000000000045, 20.000000000000014, 72.49999999999964, 7.399999999999965, 20.000000000000014, 20.000000000000014, -3.100000000000001, 20.000000000000014, 20.000000000000014, 112.69999999999985, 70.09999999999971, 1.0999999999999794, 47.60000000000019, -22.89999999999977, 31.400000000000208, 20.000000000000014, 22.700000000000053, 20.000000000000014, 106.39999999999962, 20.900000000000027, 20.000000000000014, 20.000000000000014, 9.499999999999982, 24.50000000000008, 20.000000000000014, 5.8999999999999995, 86.59999999999937, 76.09999999999954, 20.000000000000014, 20.000000000000014, 5.599999999999975, -42.69999999999982, 20.60000000000007, 10.99999999999997, 20.000000000000014, 7.999999999999989, 72.19999999999956, 45.50000000000015, 75.7999999999995, 21.80000000000004, -19.299999999999784, 78.79999999999933, 57.80000000000017, 29.600000000000183, 20.000000000000014, 15.499999999999988, 20.000000000000014, 51.500000000000234, 41.60000000000025, 40.700000000000244, 20.000000000000014, 20.000000000000014, 40.100000000000136, 27.500000000000007, 20.000000000000014, 20.000000000000014, 38.900000000000254, 103.69999999999968, -15.699999999999747, 20.000000000000014, 31.100000000000204, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 47.90000000000022, -3.0999999999999615, -23.799999999999827, 20.000000000000014, -50.49999999999991, -23.799999999999784, 37.40000000000024, -88.90000000000062, 53.30000000000023, -40.89999999999977, 20.000000000000014, -0.39999999999995095, 21.500000000000043, -57.09999999999999, 20.000000000000014, 23.60000000000007, 78.49999999999987, 76.39999999999947, -89.50000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.099999999999971, 59.60000000000022, -58.00000000000031, 20.000000000000014, 49.700000000000216, 17.899999999999988, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 72.19999999999962, 103.09999999999977, 20.000000000000014, 73.0999999999995, 20.000000000000014, 2.599999999999961, 45.20000000000021, 41.60000000000024, 20.000000000000014, 25.100000000000094, 20.000000000000014, -11.199999999999891, 20.000000000000014, 22.400000000000052, -21.99999999999975, -28.899999999999785, 17.899999999999988, 10.69999999999997, -66.70000000000061, 20.000000000000014, 14.599999999999964, 2.8999999999999613, 38.000000000000206, 20.000000000000014, 7.7000000000000535, -13.599999999999794, 29.900000000000162, 20.000000000000014, -71.50000000000088, -33.69999999999977, 28.700000000000152, -11.199999999999884, 23.600000000000065, 19.70000000000001, 20.000000000000014, 20.000000000000014, 20.90000000000003, 26.30000000000011, 12.199999999999969, -4.599999999999964, -33.999999999999766, 73.99999999999947, 20.000000000000014, 20.000000000000014, -86.20000000000056, 1.699999999999971, 20.000000000000014, 25.400000000000134, 20.000000000000014, 2.89999999999997, 31.700000000000212, 24.50000000000009, 19.10000000000001, 42.50000000000017, 3.5000000000000093, 20.000000000000014], "policy_predator_policy_reward": [6.0, 0.0, 10.0, 3.0, 55.0, 37.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 18.0, 16.0, 15.0, 23.0, 0.0, 0.0, 0.0, 12.0, 0.0, 20.0, 8.0, 0.0, 0.0, 0.0, 1.0, 33.0, 0.0, 0.0, 21.0, 5.0, 6.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 21.0, 12.0, 23.0, 4.0, 23.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 13.0, 9.0, 27.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 11.0, 12.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 6.0, 46.0, 9.0, 37.0, 12.0, 19.0, 23.0, 0.0, 0.0, 0.0, 28.0, 5.0, 0.0, 9.0, 20.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 24.0, 54.0, 19.0, 26.0, 5.0, 36.0, 57.0, 29.0, 0.0, 11.0, 25.0, 42.0, 8.0, 14.0, 1.0, 59.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 22.0, 46.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 29.0, 3.0, 3.0, 7.0, 20.0, 31.0, 6.0, 6.0, 20.0, 29.0, 5.0, 9.0, 0.0, 0.0, 11.0, 16.0, 0.0, 0.0, 0.0, 44.0, 20.0, 25.0, 10.0, 10.0, 0.0, 0.0, 17.0, 21.0, 16.0, 8.0, 0.0, 27.0, 0.0, 0.0, 69.0, 44.0, 11.0, 1.0, 7.0, 2.0, 6.0, 0.0, 7.0, 5.0, 19.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5910069244748342, "mean_inference_ms": 1.8301370016545946, "mean_action_processing_ms": 0.2526007302632817, "mean_env_wait_ms": 0.19502618421345283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004072666168212891, "StateBufferConnector_ms": 0.004277467727661133, "ViewRequirementAgentConnector_ms": 0.12777245044708252}, "num_episodes": 23, "episode_return_max": 209.9999999999992, "episode_return_min": -61.20000000000161, "episode_return_mean": 59.90899999999991, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 395.9495521876952, "num_env_steps_trained_throughput_per_sec": 395.9495521876952, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 10211.8, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10211.762, "sample_time_ms": 1392.702, "learn_time_ms": 8804.88, "learn_throughput": 454.294, "synch_weights_time_ms": 13.188}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "0b081_00000", "date": "2024-08-13_00-56-22", "timestamp": 1723524982, "time_this_iter_s": 10.111271142959595, "time_total_s": 562.2144520282745, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327faa160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 562.2144520282745, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 37.1, "ram_util_percent": 81.22666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6273360293338854, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9906062961728485, "policy_loss": -0.00486370337013372, "vf_loss": 0.9951665280593767, "vf_explained_var": 0.0005104768528509392, "kl": 0.01278821250442228, "entropy": 1.211809707823254, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.086699593429843, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.815726938354906, "policy_loss": -0.000890478601422969, "vf_loss": 1.8164563697481912, "vf_explained_var": 0.043182716167793074, "kl": 0.003574878953704116, "entropy": 1.2064405455160394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 180.29999999999905, "episode_reward_min": -64.80000000000132, "episode_reward_mean": 58.16799999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -89.50000000000045, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 112.69999999999985, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 18.778999999999986, "predator_policy": 10.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [78.09999999999941, 40.0000000000003, 40.0000000000003, 63.70000000000009, 12.799999999999958, 71.39999999999979, 106.8999999999992, 40.0000000000003, 36.90000000000027, 132.69999999999942, 93.19999999999894, 57.70000000000041, 52.40000000000051, 42.70000000000034, 133.29999999999885, 40.0000000000003, 57.00000000000041, 42.90000000000035, 170.69999999999888, 40.0000000000003, 14.899999999999952, 77.59999999999934, 59.00000000000033, 140.69999999999882, 97.59999999999897, 92.49999999999872, 96.39999999999863, 56.50000000000031, 71.49999999999996, 82.2999999999992, 40.0000000000003, 144.59999999999954, 40.0000000000003, 142.59999999999903, 21.299999999999994, 53.10000000000051, 40.0000000000003, 141.69999999999848, 21.100000000000016, 42.500000000000256, 44.60000000000043, 57.40000000000038, 8.100000000000067, 57.10000000000024, 12.89999999999994, 117.09999999999938, 91.89999999999901, 40.0000000000003, 40.0000000000003, 83.69999999999906, 30.00000000000015, 68.60000000000012, 41.800000000000324, 40.0000000000003, 180.29999999999905, 93.09999999999897, 32.60000000000019, 86.79999999999883, 49.10000000000036, 40.800000000000345, 52.400000000000496, 0.10000000000019293, 40.600000000000314, 2.3000000000000056, 31.500000000000174, 58.000000000000426, 21.100000000000147, 49.900000000000404, -61.20000000000161, 62.50000000000031, 63.30000000000041, 40.0000000000003, 85.19999999999912, 31.60000000000018, 67.00000000000018, 40.0000000000003, 28.50000000000013, 57.400000000000354, 31.90000000000018, 62.200000000000514, 73.59999999999962, 57.5000000000002, 43.600000000000364, 3.5000000000000244, 33.1000000000002, 70.59999999999991, 159.399999999999, 25.70000000000008, 116.49999999999841, 32.40000000000018, 39.10000000000028, 38.90000000000028, 40.0000000000003, 20.200000000000156, -64.80000000000132, 19.899999999999988, 39.200000000000294, 84.599999999999, 74.09999999999962, 101.199999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.100000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 24.80000000000016, 5.299999999999965, -20.499999999999815, 16.400000000000045, 20.000000000000014, 72.49999999999964, 7.399999999999965, 20.000000000000014, 20.000000000000014, -3.100000000000001, 20.000000000000014, 20.000000000000014, 112.69999999999985, 70.09999999999971, 1.0999999999999794, 47.60000000000019, -22.89999999999977, 31.400000000000208, 20.000000000000014, 22.700000000000053, 20.000000000000014, 106.39999999999962, 20.900000000000027, 20.000000000000014, 20.000000000000014, 9.499999999999982, 24.50000000000008, 20.000000000000014, 5.8999999999999995, 86.59999999999937, 76.09999999999954, 20.000000000000014, 20.000000000000014, 5.599999999999975, -42.69999999999982, 20.60000000000007, 10.99999999999997, 20.000000000000014, 7.999999999999989, 72.19999999999956, 45.50000000000015, 75.7999999999995, 21.80000000000004, -19.299999999999784, 78.79999999999933, 57.80000000000017, 29.600000000000183, 20.000000000000014, 15.499999999999988, 20.000000000000014, 51.500000000000234, 41.60000000000025, 40.700000000000244, 20.000000000000014, 20.000000000000014, 40.100000000000136, 27.500000000000007, 20.000000000000014, 20.000000000000014, 38.900000000000254, 103.69999999999968, -15.699999999999747, 20.000000000000014, 31.100000000000204, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 47.90000000000022, -3.0999999999999615, -23.799999999999827, 20.000000000000014, -50.49999999999991, -23.799999999999784, 37.40000000000024, -88.90000000000062, 53.30000000000023, -40.89999999999977, 20.000000000000014, -0.39999999999995095, 21.500000000000043, -57.09999999999999, 20.000000000000014, 23.60000000000007, 78.49999999999987, 76.39999999999947, -89.50000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.099999999999971, 59.60000000000022, -58.00000000000031, 20.000000000000014, 49.700000000000216, 17.899999999999988, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 72.19999999999962, 103.09999999999977, 20.000000000000014, 73.0999999999995, 20.000000000000014, 2.599999999999961, 45.20000000000021, 41.60000000000024, 20.000000000000014, 25.100000000000094, 20.000000000000014, -11.199999999999891, 20.000000000000014, 22.400000000000052, -21.99999999999975, -28.899999999999785, 17.899999999999988, 10.69999999999997, -66.70000000000061, 20.000000000000014, 14.599999999999964, 2.8999999999999613, 38.000000000000206, 20.000000000000014, 7.7000000000000535, -13.599999999999794, 29.900000000000162, 20.000000000000014, -71.50000000000088, -33.69999999999977, 28.700000000000152, -11.199999999999884, 23.600000000000065, 19.70000000000001, 20.000000000000014, 20.000000000000014, 20.90000000000003, 26.30000000000011, 12.199999999999969, -4.599999999999964, -33.999999999999766, 73.99999999999947, 20.000000000000014, 20.000000000000014, -86.20000000000056, 1.699999999999971, 20.000000000000014, 25.400000000000134, 20.000000000000014, 2.89999999999997, 31.700000000000212, 24.50000000000009, 19.10000000000001, 42.50000000000017, 3.5000000000000093, 20.000000000000014, 23.60000000000008, 20.000000000000014, -44.19999999999985, 16.69999999999996, 15.799999999999963, -27.699999999999825, 20.000000000000014, 50.60000000000018, 62.30000000000014, 79.09999999999958, -7.299999999999912, 20.000000000000014, 42.50000000000024, 73.99999999999947, 17.899999999999988, 9.499999999999964, 22.700000000000053, 7.399999999999968, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, -0.9999999999999917, -74.80000000000045, -76.6000000000008, -68.20000000000061, 0.7999999999999794, 1.0999999999999865, 15.199999999999953, 20.000000000000014, 38.000000000000256, 44.60000000000017, 20.000000000000014, 37.100000000000165, 81.19999999999953, 20.000000000000014], "policy_predator_policy_reward": [12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 21.0, 12.0, 23.0, 4.0, 23.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 13.0, 9.0, 27.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 11.0, 12.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 6.0, 46.0, 9.0, 37.0, 12.0, 19.0, 23.0, 0.0, 0.0, 0.0, 28.0, 5.0, 0.0, 9.0, 20.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 24.0, 54.0, 19.0, 26.0, 5.0, 36.0, 57.0, 29.0, 0.0, 11.0, 25.0, 42.0, 8.0, 14.0, 1.0, 59.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 22.0, 46.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 29.0, 3.0, 3.0, 7.0, 20.0, 31.0, 6.0, 6.0, 20.0, 29.0, 5.0, 9.0, 0.0, 0.0, 11.0, 16.0, 0.0, 0.0, 0.0, 44.0, 20.0, 25.0, 10.0, 10.0, 0.0, 0.0, 17.0, 21.0, 16.0, 8.0, 0.0, 27.0, 0.0, 0.0, 69.0, 44.0, 11.0, 1.0, 7.0, 2.0, 6.0, 0.0, 7.0, 5.0, 19.0, 15.0, 0.0, 0.0, 0.0, 31.0, 33.0, 12.0, 0.0, 0.0, 6.0, 12.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 41.0, 55.0, 0.0, 80.0, 2.0, 16.0, 4.0, 0.0, 2.0, 0.0, 8.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5918820315410004, "mean_inference_ms": 1.8324681843613453, "mean_action_processing_ms": 0.2525882500324746, "mean_env_wait_ms": 0.1950399745978509, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00404667854309082, "StateBufferConnector_ms": 0.004249215126037598, "ViewRequirementAgentConnector_ms": 0.12587380409240723}, "num_episodes": 18, "episode_return_max": 180.29999999999905, "episode_return_min": -64.80000000000132, "episode_return_mean": 58.16799999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.73561914841224, "num_env_steps_trained_throughput_per_sec": 402.73561914841224, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 10211.845, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10211.808, "sample_time_ms": 1384.514, "learn_time_ms": 8813.209, "learn_throughput": 453.864, "synch_weights_time_ms": 13.071}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "0b081_00000", "date": "2024-08-13_00-56-32", "timestamp": 1723524992, "time_this_iter_s": 9.936682939529419, "time_total_s": 572.151134967804, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e695e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 572.151134967804, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 36.37142857142857, "ram_util_percent": 81.12142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6137231233889464, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6244255676786735, "policy_loss": -0.0037829709932868365, "vf_loss": 0.6278937170745204, "vf_explained_var": 0.003753508934898982, "kl": 0.013266551749978385, "entropy": 1.205478872950115, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1987599447448418, "cur_kl_coeff": 0.02252540588378906, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2910146464746466, "policy_loss": -0.002235365742521863, "vf_loss": 1.29295364522114, "vf_explained_var": 0.06641620870620485, "kl": 0.01315690922094633, "entropy": 1.1953215052841832, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 180.29999999999905, "episode_reward_min": -64.80000000000132, "episode_reward_mean": 54.768999999999906, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -89.50000000000045, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 103.69999999999968, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 16.19449999999999, "predator_policy": 11.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [170.69999999999888, 40.0000000000003, 14.899999999999952, 77.59999999999934, 59.00000000000033, 140.69999999999882, 97.59999999999897, 92.49999999999872, 96.39999999999863, 56.50000000000031, 71.49999999999996, 82.2999999999992, 40.0000000000003, 144.59999999999954, 40.0000000000003, 142.59999999999903, 21.299999999999994, 53.10000000000051, 40.0000000000003, 141.69999999999848, 21.100000000000016, 42.500000000000256, 44.60000000000043, 57.40000000000038, 8.100000000000067, 57.10000000000024, 12.89999999999994, 117.09999999999938, 91.89999999999901, 40.0000000000003, 40.0000000000003, 83.69999999999906, 30.00000000000015, 68.60000000000012, 41.800000000000324, 40.0000000000003, 180.29999999999905, 93.09999999999897, 32.60000000000019, 86.79999999999883, 49.10000000000036, 40.800000000000345, 52.400000000000496, 0.10000000000019293, 40.600000000000314, 2.3000000000000056, 31.500000000000174, 58.000000000000426, 21.100000000000147, 49.900000000000404, -61.20000000000161, 62.50000000000031, 63.30000000000041, 40.0000000000003, 85.19999999999912, 31.60000000000018, 67.00000000000018, 40.0000000000003, 28.50000000000013, 57.400000000000354, 31.90000000000018, 62.200000000000514, 73.59999999999962, 57.5000000000002, 43.600000000000364, 3.5000000000000244, 33.1000000000002, 70.59999999999991, 159.399999999999, 25.70000000000008, 116.49999999999841, 32.40000000000018, 39.10000000000028, 38.90000000000028, 40.0000000000003, 20.200000000000156, -64.80000000000132, 19.899999999999988, 39.200000000000294, 84.599999999999, 74.09999999999962, 101.199999999999, 87.89999999999927, 100.29999999999856, 68.60000000000016, 52.200000000000344, 21.90000000000015, 16.600000000000012, 61.400000000000375, 40.90000000000031, 41.80000000000033, 39.300000000000296, 40.0000000000003, 41.80000000000033, -9.299999999999756, 46.40000000000037, 63.60000000000043, -7.29999999999972, 40.50000000000032, 55.200000000000465], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [86.59999999999937, 76.09999999999954, 20.000000000000014, 20.000000000000014, 5.599999999999975, -42.69999999999982, 20.60000000000007, 10.99999999999997, 20.000000000000014, 7.999999999999989, 72.19999999999956, 45.50000000000015, 75.7999999999995, 21.80000000000004, -19.299999999999784, 78.79999999999933, 57.80000000000017, 29.600000000000183, 20.000000000000014, 15.499999999999988, 20.000000000000014, 51.500000000000234, 41.60000000000025, 40.700000000000244, 20.000000000000014, 20.000000000000014, 40.100000000000136, 27.500000000000007, 20.000000000000014, 20.000000000000014, 38.900000000000254, 103.69999999999968, -15.699999999999747, 20.000000000000014, 31.100000000000204, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 47.90000000000022, -3.0999999999999615, -23.799999999999827, 20.000000000000014, -50.49999999999991, -23.799999999999784, 37.40000000000024, -88.90000000000062, 53.30000000000023, -40.89999999999977, 20.000000000000014, -0.39999999999995095, 21.500000000000043, -57.09999999999999, 20.000000000000014, 23.60000000000007, 78.49999999999987, 76.39999999999947, -89.50000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.099999999999971, 59.60000000000022, -58.00000000000031, 20.000000000000014, 49.700000000000216, 17.899999999999988, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 72.19999999999962, 103.09999999999977, 20.000000000000014, 73.0999999999995, 20.000000000000014, 2.599999999999961, 45.20000000000021, 41.60000000000024, 20.000000000000014, 25.100000000000094, 20.000000000000014, -11.199999999999891, 20.000000000000014, 22.400000000000052, -21.99999999999975, -28.899999999999785, 17.899999999999988, 10.69999999999997, -66.70000000000061, 20.000000000000014, 14.599999999999964, 2.8999999999999613, 38.000000000000206, 20.000000000000014, 7.7000000000000535, -13.599999999999794, 29.900000000000162, 20.000000000000014, -71.50000000000088, -33.69999999999977, 28.700000000000152, -11.199999999999884, 23.600000000000065, 19.70000000000001, 20.000000000000014, 20.000000000000014, 20.90000000000003, 26.30000000000011, 12.199999999999969, -4.599999999999964, -33.999999999999766, 73.99999999999947, 20.000000000000014, 20.000000000000014, -86.20000000000056, 1.699999999999971, 20.000000000000014, 25.400000000000134, 20.000000000000014, 2.89999999999997, 31.700000000000212, 24.50000000000009, 19.10000000000001, 42.50000000000017, 3.5000000000000093, 20.000000000000014, 23.60000000000008, 20.000000000000014, -44.19999999999985, 16.69999999999996, 15.799999999999963, -27.699999999999825, 20.000000000000014, 50.60000000000018, 62.30000000000014, 79.09999999999958, -7.299999999999912, 20.000000000000014, 42.50000000000024, 73.99999999999947, 17.899999999999988, 9.499999999999964, 22.700000000000053, 7.399999999999968, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, -0.9999999999999917, -74.80000000000045, -76.6000000000008, -68.20000000000061, 0.7999999999999794, 1.0999999999999865, 15.199999999999953, 20.000000000000014, 38.000000000000256, 44.60000000000017, 20.000000000000014, 37.100000000000165, 81.19999999999953, 20.000000000000014, 37.70000000000016, 21.200000000000067, 31.70000000000018, 41.60000000000023, 20.000000000000014, 47.600000000000236, -9.999999999999945, 24.200000000000085, -32.49999999999993, -1.5999999999999996, 7.699999999999988, -45.09999999999976, 25.40000000000012, 20.000000000000014, 20.000000000000014, 20.900000000000027, 21.800000000000047, 20.000000000000014, -53.50000000000016, 57.800000000000225, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, -51.39999999999987, -16.899999999999807, 16.699999999999967, 7.700000000000001, 15.799999999999963, 30.800000000000182, -70.30000000000081, 20.000000000000014, 0.4999999999999635, 20.000000000000014, 33.800000000000225, 16.399999999999967], "policy_predator_policy_reward": [8.0, 0.0, 0.0, 0.0, 6.0, 46.0, 9.0, 37.0, 12.0, 19.0, 23.0, 0.0, 0.0, 0.0, 28.0, 5.0, 0.0, 9.0, 20.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 24.0, 54.0, 19.0, 26.0, 5.0, 36.0, 57.0, 29.0, 0.0, 11.0, 25.0, 42.0, 8.0, 14.0, 1.0, 59.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 22.0, 46.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 29.0, 3.0, 3.0, 7.0, 20.0, 31.0, 6.0, 6.0, 20.0, 29.0, 5.0, 9.0, 0.0, 0.0, 11.0, 16.0, 0.0, 0.0, 0.0, 44.0, 20.0, 25.0, 10.0, 10.0, 0.0, 0.0, 17.0, 21.0, 16.0, 8.0, 0.0, 27.0, 0.0, 0.0, 69.0, 44.0, 11.0, 1.0, 7.0, 2.0, 6.0, 0.0, 7.0, 5.0, 19.0, 15.0, 0.0, 0.0, 0.0, 31.0, 33.0, 12.0, 0.0, 0.0, 6.0, 12.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 41.0, 55.0, 0.0, 80.0, 2.0, 16.0, 4.0, 0.0, 2.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 29.0, 17.0, 10.0, 1.0, 0.0, 34.0, 4.0, 27.0, 29.0, 23.0, 31.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 4.0, 18.0, 4.0, 13.0, 0.0, 43.0, 20.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5912583094096762, "mean_inference_ms": 1.8310392777703615, "mean_action_processing_ms": 0.25215338758337924, "mean_env_wait_ms": 0.1947408307499803, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037070512771606445, "StateBufferConnector_ms": 0.0030248165130615234, "ViewRequirementAgentConnector_ms": 0.09762609004974365}, "num_episodes": 18, "episode_return_max": 180.29999999999905, "episode_return_min": -64.80000000000132, "episode_return_mean": 54.768999999999906, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.89043773247727, "num_env_steps_trained_throughput_per_sec": 352.89043773247727, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 10361.792, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10361.754, "sample_time_ms": 1385.439, "learn_time_ms": 8962.331, "learn_throughput": 446.312, "synch_weights_time_ms": 12.91}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "0b081_00000", "date": "2024-08-13_00-56-43", "timestamp": 1723525003, "time_this_iter_s": 11.385905027389526, "time_total_s": 583.5370399951935, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbea60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 583.5370399951935, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 42.6375, "ram_util_percent": 82.44375000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6115053492839689, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9403154863882317, "policy_loss": -0.00453298451063573, "vf_loss": 0.9445664756749043, "vf_explained_var": 0.001895483240248665, "kl": 0.011883318916097334, "entropy": 1.2103712179673412, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2653458605209986, "cur_kl_coeff": 0.02252540588378906, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5225951538041786, "policy_loss": -0.0008831262712923701, "vf_loss": 1.5233438087203515, "vf_explained_var": 0.03509120039208225, "kl": 0.005969701809851946, "entropy": 1.1654303927270193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 180.29999999999905, "episode_reward_min": -64.80000000000132, "episode_reward_mean": 46.01400000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -111.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 103.09999999999977, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 12.091999999999993, "predator_policy": 10.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.60000000000043, 57.40000000000038, 8.100000000000067, 57.10000000000024, 12.89999999999994, 117.09999999999938, 91.89999999999901, 40.0000000000003, 40.0000000000003, 83.69999999999906, 30.00000000000015, 68.60000000000012, 41.800000000000324, 40.0000000000003, 180.29999999999905, 93.09999999999897, 32.60000000000019, 86.79999999999883, 49.10000000000036, 40.800000000000345, 52.400000000000496, 0.10000000000019293, 40.600000000000314, 2.3000000000000056, 31.500000000000174, 58.000000000000426, 21.100000000000147, 49.900000000000404, -61.20000000000161, 62.50000000000031, 63.30000000000041, 40.0000000000003, 85.19999999999912, 31.60000000000018, 67.00000000000018, 40.0000000000003, 28.50000000000013, 57.400000000000354, 31.90000000000018, 62.200000000000514, 73.59999999999962, 57.5000000000002, 43.600000000000364, 3.5000000000000244, 33.1000000000002, 70.59999999999991, 159.399999999999, 25.70000000000008, 116.49999999999841, 32.40000000000018, 39.10000000000028, 38.90000000000028, 40.0000000000003, 20.200000000000156, -64.80000000000132, 19.899999999999988, 39.200000000000294, 84.599999999999, 74.09999999999962, 101.199999999999, 87.89999999999927, 100.29999999999856, 68.60000000000016, 52.200000000000344, 21.90000000000015, 16.600000000000012, 61.400000000000375, 40.90000000000031, 41.80000000000033, 39.300000000000296, 40.0000000000003, 41.80000000000033, -9.299999999999756, 46.40000000000037, 63.60000000000043, -7.29999999999972, 40.50000000000032, 55.200000000000465, 31.000000000000163, 34.50000000000029, 60.00000000000022, -7.1999999999996955, 44.50000000000029, 25.600000000000076, 99.5999999999987, 13.400000000000034, 67.70000000000014, 40.0000000000003, 53.8000000000005, 64.30000000000048, 33.6000000000002, 64.90000000000022, 40.0000000000003, -2.199999999999829, 38.90000000000028, 22.20000000000007, 58.90000000000042, 11.900000000000004, 40.0000000000003, -24.299999999999763], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-23.799999999999784, 37.40000000000024, -88.90000000000062, 53.30000000000023, -40.89999999999977, 20.000000000000014, -0.39999999999995095, 21.500000000000043, -57.09999999999999, 20.000000000000014, 23.60000000000007, 78.49999999999987, 76.39999999999947, -89.50000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.099999999999971, 59.60000000000022, -58.00000000000031, 20.000000000000014, 49.700000000000216, 17.899999999999988, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 72.19999999999962, 103.09999999999977, 20.000000000000014, 73.0999999999995, 20.000000000000014, 2.599999999999961, 45.20000000000021, 41.60000000000024, 20.000000000000014, 25.100000000000094, 20.000000000000014, -11.199999999999891, 20.000000000000014, 22.400000000000052, -21.99999999999975, -28.899999999999785, 17.899999999999988, 10.69999999999997, -66.70000000000061, 20.000000000000014, 14.599999999999964, 2.8999999999999613, 38.000000000000206, 20.000000000000014, 7.7000000000000535, -13.599999999999794, 29.900000000000162, 20.000000000000014, -71.50000000000088, -33.69999999999977, 28.700000000000152, -11.199999999999884, 23.600000000000065, 19.70000000000001, 20.000000000000014, 20.000000000000014, 20.90000000000003, 26.30000000000011, 12.199999999999969, -4.599999999999964, -33.999999999999766, 73.99999999999947, 20.000000000000014, 20.000000000000014, -86.20000000000056, 1.699999999999971, 20.000000000000014, 25.400000000000134, 20.000000000000014, 2.89999999999997, 31.700000000000212, 24.50000000000009, 19.10000000000001, 42.50000000000017, 3.5000000000000093, 20.000000000000014, 23.60000000000008, 20.000000000000014, -44.19999999999985, 16.69999999999996, 15.799999999999963, -27.699999999999825, 20.000000000000014, 50.60000000000018, 62.30000000000014, 79.09999999999958, -7.299999999999912, 20.000000000000014, 42.50000000000024, 73.99999999999947, 17.899999999999988, 9.499999999999964, 22.700000000000053, 7.399999999999968, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, -0.9999999999999917, -74.80000000000045, -76.6000000000008, -68.20000000000061, 0.7999999999999794, 1.0999999999999865, 15.199999999999953, 20.000000000000014, 38.000000000000256, 44.60000000000017, 20.000000000000014, 37.100000000000165, 81.19999999999953, 20.000000000000014, 37.70000000000016, 21.200000000000067, 31.70000000000018, 41.60000000000023, 20.000000000000014, 47.600000000000236, -9.999999999999945, 24.200000000000085, -32.49999999999993, -1.5999999999999996, 7.699999999999988, -45.09999999999976, 25.40000000000012, 20.000000000000014, 20.000000000000014, 20.900000000000027, 21.800000000000047, 20.000000000000014, -53.50000000000016, 57.800000000000225, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, -51.39999999999987, -16.899999999999807, 16.699999999999967, 7.700000000000001, 15.799999999999963, 30.800000000000182, -70.30000000000081, 20.000000000000014, 0.4999999999999635, 20.000000000000014, 33.800000000000225, 16.399999999999967, 1.099999999999983, 20.900000000000027, 9.499999999999952, 20.000000000000014, 13.999999999999977, 20.000000000000014, 5.299999999999983, -53.50000000000005, 20.000000000000014, 24.500000000000096, -3.999999999999966, 11.599999999999964, 11.59999999999997, 79.99999999999935, 0.7999999999999865, -3.3999999999999653, 20.000000000000014, 31.700000000000195, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.8000000000002, 44.300000000000246, 10.999999999999972, 19.70000000000001, -0.09999999999995807, 25.10000000000012, 15.799999999999962, 20.000000000000014, 20.000000000000014, -80.20000000000064, 20.000000000000014, 17.899999999999984, 20.000000000000014, -24.999999999999794, 12.199999999999966, 20.000000000000014, 29.900000000000198, -13.899999999999803, -2.1999999999999713, 20.000000000000014, 20.000000000000014, 21.800000000000047, -111.10000000000036], "policy_predator_policy_reward": [26.0, 5.0, 36.0, 57.0, 29.0, 0.0, 11.0, 25.0, 42.0, 8.0, 14.0, 1.0, 59.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 22.0, 46.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 29.0, 3.0, 3.0, 7.0, 20.0, 31.0, 6.0, 6.0, 20.0, 29.0, 5.0, 9.0, 0.0, 0.0, 11.0, 16.0, 0.0, 0.0, 0.0, 44.0, 20.0, 25.0, 10.0, 10.0, 0.0, 0.0, 17.0, 21.0, 16.0, 8.0, 0.0, 27.0, 0.0, 0.0, 69.0, 44.0, 11.0, 1.0, 7.0, 2.0, 6.0, 0.0, 7.0, 5.0, 19.0, 15.0, 0.0, 0.0, 0.0, 31.0, 33.0, 12.0, 0.0, 0.0, 6.0, 12.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 41.0, 55.0, 0.0, 80.0, 2.0, 16.0, 4.0, 0.0, 2.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 29.0, 17.0, 10.0, 1.0, 0.0, 34.0, 4.0, 27.0, 29.0, 23.0, 31.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 4.0, 18.0, 4.0, 13.0, 0.0, 43.0, 20.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 5.0, 0.0, 26.0, 37.0, 4.0, 0.0, 0.0, 13.0, 5.0, 1.0, 7.0, 16.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 13.0, 1.0, 9.0, 15.0, 0.0, 0.0, 55.0, 3.0, 0.0, 1.0, 35.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 65.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5904965829238357, "mean_inference_ms": 1.8300471933836573, "mean_action_processing_ms": 0.2517231439594527, "mean_env_wait_ms": 0.19443904413339078, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036368370056152344, "StateBufferConnector_ms": 0.002970099449157715, "ViewRequirementAgentConnector_ms": 0.09617924690246582}, "num_episodes": 22, "episode_return_max": 180.29999999999905, "episode_return_min": -64.80000000000132, "episode_return_mean": 46.01400000000002, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.47647011654556, "num_env_steps_trained_throughput_per_sec": 365.47647011654556, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 10507.603, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10507.565, "sample_time_ms": 1395.457, "learn_time_ms": 9097.81, "learn_throughput": 439.666, "synch_weights_time_ms": 13.165}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "0b081_00000", "date": "2024-08-13_00-56-54", "timestamp": 1723525014, "time_this_iter_s": 10.95114016532898, "time_total_s": 594.4881801605225, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e69550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 594.4881801605225, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 35.70625, "ram_util_percent": 82.44999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.603323072490711, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.47129538340701, "policy_loss": -0.003794070039555509, "vf_loss": 0.4748297299069929, "vf_explained_var": 0.01216138244936706, "kl": 0.010944713494535435, "entropy": 1.2279703943817704, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9535354095870856, "cur_kl_coeff": 0.02252540588378906, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7865070910917388, "policy_loss": -0.0021432532730546816, "vf_loss": 0.7884390695464043, "vf_explained_var": 0.009745464943073413, "kl": 0.009379453309866245, "entropy": 1.1549240213853342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 159.399999999999, "episode_reward_min": -64.80000000000132, "episode_reward_mean": 42.60700000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -111.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 81.19999999999953, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 11.778500000000008, "predator_policy": 9.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [49.10000000000036, 40.800000000000345, 52.400000000000496, 0.10000000000019293, 40.600000000000314, 2.3000000000000056, 31.500000000000174, 58.000000000000426, 21.100000000000147, 49.900000000000404, -61.20000000000161, 62.50000000000031, 63.30000000000041, 40.0000000000003, 85.19999999999912, 31.60000000000018, 67.00000000000018, 40.0000000000003, 28.50000000000013, 57.400000000000354, 31.90000000000018, 62.200000000000514, 73.59999999999962, 57.5000000000002, 43.600000000000364, 3.5000000000000244, 33.1000000000002, 70.59999999999991, 159.399999999999, 25.70000000000008, 116.49999999999841, 32.40000000000018, 39.10000000000028, 38.90000000000028, 40.0000000000003, 20.200000000000156, -64.80000000000132, 19.899999999999988, 39.200000000000294, 84.599999999999, 74.09999999999962, 101.199999999999, 87.89999999999927, 100.29999999999856, 68.60000000000016, 52.200000000000344, 21.90000000000015, 16.600000000000012, 61.400000000000375, 40.90000000000031, 41.80000000000033, 39.300000000000296, 40.0000000000003, 41.80000000000033, -9.299999999999756, 46.40000000000037, 63.60000000000043, -7.29999999999972, 40.50000000000032, 55.200000000000465, 31.000000000000163, 34.50000000000029, 60.00000000000022, -7.1999999999996955, 44.50000000000029, 25.600000000000076, 99.5999999999987, 13.400000000000034, 67.70000000000014, 40.0000000000003, 53.8000000000005, 64.30000000000048, 33.6000000000002, 64.90000000000022, 40.0000000000003, -2.199999999999829, 38.90000000000028, 22.20000000000007, 58.90000000000042, 11.900000000000004, 40.0000000000003, -24.299999999999763, 40.3000000000003, 47.700000000000394, 14.999999999999924, 75.99999999999947, 35.600000000000236, 38.400000000000276, 41.800000000000324, 50.40000000000048, 94.79999999999865, 9.200000000000035, 31.700000000000177, 40.0000000000003, 38.30000000000027, 40.0000000000003, 40.0000000000003, 46.600000000000406, 63.900000000000496, 35.600000000000236], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 25.100000000000094, 20.000000000000014, -11.199999999999891, 20.000000000000014, 22.400000000000052, -21.99999999999975, -28.899999999999785, 17.899999999999988, 10.69999999999997, -66.70000000000061, 20.000000000000014, 14.599999999999964, 2.8999999999999613, 38.000000000000206, 20.000000000000014, 7.7000000000000535, -13.599999999999794, 29.900000000000162, 20.000000000000014, -71.50000000000088, -33.69999999999977, 28.700000000000152, -11.199999999999884, 23.600000000000065, 19.70000000000001, 20.000000000000014, 20.000000000000014, 20.90000000000003, 26.30000000000011, 12.199999999999969, -4.599999999999964, -33.999999999999766, 73.99999999999947, 20.000000000000014, 20.000000000000014, -86.20000000000056, 1.699999999999971, 20.000000000000014, 25.400000000000134, 20.000000000000014, 2.89999999999997, 31.700000000000212, 24.50000000000009, 19.10000000000001, 42.50000000000017, 3.5000000000000093, 20.000000000000014, 23.60000000000008, 20.000000000000014, -44.19999999999985, 16.69999999999996, 15.799999999999963, -27.699999999999825, 20.000000000000014, 50.60000000000018, 62.30000000000014, 79.09999999999958, -7.299999999999912, 20.000000000000014, 42.50000000000024, 73.99999999999947, 17.899999999999988, 9.499999999999964, 22.700000000000053, 7.399999999999968, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, -0.9999999999999917, -74.80000000000045, -76.6000000000008, -68.20000000000061, 0.7999999999999794, 1.0999999999999865, 15.199999999999953, 20.000000000000014, 38.000000000000256, 44.60000000000017, 20.000000000000014, 37.100000000000165, 81.19999999999953, 20.000000000000014, 37.70000000000016, 21.200000000000067, 31.70000000000018, 41.60000000000023, 20.000000000000014, 47.600000000000236, -9.999999999999945, 24.200000000000085, -32.49999999999993, -1.5999999999999996, 7.699999999999988, -45.09999999999976, 25.40000000000012, 20.000000000000014, 20.000000000000014, 20.900000000000027, 21.800000000000047, 20.000000000000014, -53.50000000000016, 57.800000000000225, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, -51.39999999999987, -16.899999999999807, 16.699999999999967, 7.700000000000001, 15.799999999999963, 30.800000000000182, -70.30000000000081, 20.000000000000014, 0.4999999999999635, 20.000000000000014, 33.800000000000225, 16.399999999999967, 1.099999999999983, 20.900000000000027, 9.499999999999952, 20.000000000000014, 13.999999999999977, 20.000000000000014, 5.299999999999983, -53.50000000000005, 20.000000000000014, 24.500000000000096, -3.999999999999966, 11.599999999999964, 11.59999999999997, 79.99999999999935, 0.7999999999999865, -3.3999999999999653, 20.000000000000014, 31.700000000000195, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.8000000000002, 44.300000000000246, 10.999999999999972, 19.70000000000001, -0.09999999999995807, 25.10000000000012, 15.799999999999962, 20.000000000000014, 20.000000000000014, -80.20000000000064, 20.000000000000014, 17.899999999999984, 20.000000000000014, -24.999999999999794, 12.199999999999966, 20.000000000000014, 29.900000000000198, -13.899999999999803, -2.1999999999999713, 20.000000000000014, 20.000000000000014, 21.800000000000047, -111.10000000000036, 20.000000000000014, 8.299999999999972, 25.700000000000124, 20.000000000000014, 17.29999999999998, -28.29999999999977, -5.799999999999953, 45.800000000000125, 17.899999999999988, 13.699999999999964, -1.599999999999985, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.40000000000016, 20.000000000000014, 24.50000000000008, 65.3000000000001, 20.000000000000014, -38.79999999999978, -7.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.400000000000016, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 19.099999999999998, 20.000000000000014, 41.90000000000024, 11.59999999999997, 20.000000000000014], "policy_predator_policy_reward": [0.0, 4.0, 29.0, 3.0, 3.0, 7.0, 20.0, 31.0, 6.0, 6.0, 20.0, 29.0, 5.0, 9.0, 0.0, 0.0, 11.0, 16.0, 0.0, 0.0, 0.0, 44.0, 20.0, 25.0, 10.0, 10.0, 0.0, 0.0, 17.0, 21.0, 16.0, 8.0, 0.0, 27.0, 0.0, 0.0, 69.0, 44.0, 11.0, 1.0, 7.0, 2.0, 6.0, 0.0, 7.0, 5.0, 19.0, 15.0, 0.0, 0.0, 0.0, 31.0, 33.0, 12.0, 0.0, 0.0, 6.0, 12.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 41.0, 55.0, 0.0, 80.0, 2.0, 16.0, 4.0, 0.0, 2.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 29.0, 17.0, 10.0, 1.0, 0.0, 34.0, 4.0, 27.0, 29.0, 23.0, 31.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 4.0, 18.0, 4.0, 13.0, 0.0, 43.0, 20.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 5.0, 0.0, 26.0, 37.0, 4.0, 0.0, 0.0, 13.0, 5.0, 1.0, 7.0, 16.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 13.0, 1.0, 9.0, 15.0, 0.0, 0.0, 55.0, 3.0, 0.0, 1.0, 35.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 65.0, 0.0, 12.0, 0.0, 2.0, 26.0, 0.0, 19.0, 17.0, 0.0, 4.0, 11.0, 9.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 28.0, 19.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5902121070568593, "mean_inference_ms": 1.8296228994132793, "mean_action_processing_ms": 0.2514595043263638, "mean_env_wait_ms": 0.19423496938250287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003800630569458008, "StateBufferConnector_ms": 0.0030989646911621094, "ViewRequirementAgentConnector_ms": 0.09793412685394287}, "num_episodes": 18, "episode_return_max": 159.399999999999, "episode_return_min": -64.80000000000132, "episode_return_mean": 42.60700000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.62856274714477, "num_env_steps_trained_throughput_per_sec": 319.62856274714477, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 10798.069, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10798.03, "sample_time_ms": 1408.203, "learn_time_ms": 9375.106, "learn_throughput": 426.662, "synch_weights_time_ms": 13.107}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "0b081_00000", "date": "2024-08-13_00-57-06", "timestamp": 1723525026, "time_this_iter_s": 12.564213991165161, "time_total_s": 607.0523941516876, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e69700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 607.0523941516876, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 55.21764705882353, "ram_util_percent": 83.42941176470589}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5777444691017822, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9837432415712447, "policy_loss": -0.004544426847702612, "vf_loss": 0.9879970185971134, "vf_explained_var": 0.002354264732391115, "kl": 0.012247809233207164, "entropy": 1.2187741400703551, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3158297901943563, "cur_kl_coeff": 0.02252540588378906, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.087188211824528, "policy_loss": -0.00395174783158052, "vf_loss": 2.0906621517327726, "vf_explained_var": 0.05286826008842105, "kl": 0.021211910019175356, "entropy": 1.054062523791399, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 159.399999999999, "episode_reward_min": -64.80000000000132, "episode_reward_mean": 45.46600000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -111.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 108.19999999999942, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 14.168000000000005, "predator_policy": 8.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [57.5000000000002, 43.600000000000364, 3.5000000000000244, 33.1000000000002, 70.59999999999991, 159.399999999999, 25.70000000000008, 116.49999999999841, 32.40000000000018, 39.10000000000028, 38.90000000000028, 40.0000000000003, 20.200000000000156, -64.80000000000132, 19.899999999999988, 39.200000000000294, 84.599999999999, 74.09999999999962, 101.199999999999, 87.89999999999927, 100.29999999999856, 68.60000000000016, 52.200000000000344, 21.90000000000015, 16.600000000000012, 61.400000000000375, 40.90000000000031, 41.80000000000033, 39.300000000000296, 40.0000000000003, 41.80000000000033, -9.299999999999756, 46.40000000000037, 63.60000000000043, -7.29999999999972, 40.50000000000032, 55.200000000000465, 31.000000000000163, 34.50000000000029, 60.00000000000022, -7.1999999999996955, 44.50000000000029, 25.600000000000076, 99.5999999999987, 13.400000000000034, 67.70000000000014, 40.0000000000003, 53.8000000000005, 64.30000000000048, 33.6000000000002, 64.90000000000022, 40.0000000000003, -2.199999999999829, 38.90000000000028, 22.20000000000007, 58.90000000000042, 11.900000000000004, 40.0000000000003, -24.299999999999763, 40.3000000000003, 47.700000000000394, 14.999999999999924, 75.99999999999947, 35.600000000000236, 38.400000000000276, 41.800000000000324, 50.40000000000048, 94.79999999999865, 9.200000000000035, 31.700000000000177, 40.0000000000003, 38.30000000000027, 40.0000000000003, 40.0000000000003, 46.600000000000406, 63.900000000000496, 35.600000000000236, 128.19999999999868, 31.90000000000018, 81.19999999999911, 6.8000000000001, 42.10000000000033, 91.7999999999989, 48.100000000000435, 61.40000000000046, 33.7000000000002, 12.500000000000002, 90.89999999999952, 57.30000000000048, 40.0000000000003, 113.79999999999859, 35.600000000000236, 40.30000000000037, 35.000000000000355, 26.600000000000094, 37.80000000000027, 40.0000000000003, 37.600000000000264, 49.9000000000003, 71.19999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.5000000000000093, 20.000000000000014, 23.60000000000008, 20.000000000000014, -44.19999999999985, 16.69999999999996, 15.799999999999963, -27.699999999999825, 20.000000000000014, 50.60000000000018, 62.30000000000014, 79.09999999999958, -7.299999999999912, 20.000000000000014, 42.50000000000024, 73.99999999999947, 17.899999999999988, 9.499999999999964, 22.700000000000053, 7.399999999999968, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, -0.9999999999999917, -74.80000000000045, -76.6000000000008, -68.20000000000061, 0.7999999999999794, 1.0999999999999865, 15.199999999999953, 20.000000000000014, 38.000000000000256, 44.60000000000017, 20.000000000000014, 37.100000000000165, 81.19999999999953, 20.000000000000014, 37.70000000000016, 21.200000000000067, 31.70000000000018, 41.60000000000023, 20.000000000000014, 47.600000000000236, -9.999999999999945, 24.200000000000085, -32.49999999999993, -1.5999999999999996, 7.699999999999988, -45.09999999999976, 25.40000000000012, 20.000000000000014, 20.000000000000014, 20.900000000000027, 21.800000000000047, 20.000000000000014, -53.50000000000016, 57.800000000000225, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, -51.39999999999987, -16.899999999999807, 16.699999999999967, 7.700000000000001, 15.799999999999963, 30.800000000000182, -70.30000000000081, 20.000000000000014, 0.4999999999999635, 20.000000000000014, 33.800000000000225, 16.399999999999967, 1.099999999999983, 20.900000000000027, 9.499999999999952, 20.000000000000014, 13.999999999999977, 20.000000000000014, 5.299999999999983, -53.50000000000005, 20.000000000000014, 24.500000000000096, -3.999999999999966, 11.599999999999964, 11.59999999999997, 79.99999999999935, 0.7999999999999865, -3.3999999999999653, 20.000000000000014, 31.700000000000195, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.8000000000002, 44.300000000000246, 10.999999999999972, 19.70000000000001, -0.09999999999995807, 25.10000000000012, 15.799999999999962, 20.000000000000014, 20.000000000000014, -80.20000000000064, 20.000000000000014, 17.899999999999984, 20.000000000000014, -24.999999999999794, 12.199999999999966, 20.000000000000014, 29.900000000000198, -13.899999999999803, -2.1999999999999713, 20.000000000000014, 20.000000000000014, 21.800000000000047, -111.10000000000036, 20.000000000000014, 8.299999999999972, 25.700000000000124, 20.000000000000014, 17.29999999999998, -28.29999999999977, -5.799999999999953, 45.800000000000125, 17.899999999999988, 13.699999999999964, -1.599999999999985, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.40000000000016, 20.000000000000014, 24.50000000000008, 65.3000000000001, 20.000000000000014, -38.79999999999978, -7.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.400000000000016, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 19.099999999999998, 20.000000000000014, 41.90000000000024, 11.59999999999997, 20.000000000000014, 108.19999999999942, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 51.20000000000015, 20.000000000000014, 20.000000000000014, -80.2000000000005, 20.000000000000014, 10.09999999999997, 47.30000000000016, 33.50000000000019, 28.100000000000147, 20.000000000000014, 23.60000000000007, 0.799999999999967, 20.90000000000003, -14.19999999999981, -32.49999999999975, 20.000000000000014, 39.20000000000015, 31.700000000000223, 21.20000000000003, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 11.599999999999964, 20.000000000000014, -3.099999999999972, 13.399999999999972, -108.10000000000025, 82.09999999999926, 22.40000000000005, -20.799999999999756, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999964, 20.000000000000014, 29.90000000000014, 20.000000000000014, 20.000000000000014, 45.20000000000021], "policy_predator_policy_reward": [19.0, 15.0, 0.0, 0.0, 0.0, 31.0, 33.0, 12.0, 0.0, 0.0, 6.0, 12.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 41.0, 55.0, 0.0, 80.0, 2.0, 16.0, 4.0, 0.0, 2.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 29.0, 17.0, 10.0, 1.0, 0.0, 34.0, 4.0, 27.0, 29.0, 23.0, 31.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 4.0, 18.0, 4.0, 13.0, 0.0, 43.0, 20.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 5.0, 0.0, 26.0, 37.0, 4.0, 0.0, 0.0, 13.0, 5.0, 1.0, 7.0, 16.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 13.0, 1.0, 9.0, 15.0, 0.0, 0.0, 55.0, 3.0, 0.0, 1.0, 35.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 65.0, 0.0, 12.0, 0.0, 2.0, 26.0, 0.0, 19.0, 17.0, 0.0, 4.0, 11.0, 9.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 28.0, 19.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 4.0, 0.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 67.0, 6.0, 6.0, 11.0, 0.0, 0.0, 0.0, 22.0, 15.0, 10.0, 17.0, 4.0, 21.0, 15.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 19.0, 11.0, 0.0, 61.0, 11.0, 14.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5905808827063469, "mean_inference_ms": 1.831556348590284, "mean_action_processing_ms": 0.2514212815044835, "mean_env_wait_ms": 0.19424468437389603, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0056645870208740234, "StateBufferConnector_ms": 0.0037679672241210938, "ViewRequirementAgentConnector_ms": 0.1157529354095459}, "num_episodes": 23, "episode_return_max": 159.399999999999, "episode_return_min": -64.80000000000132, "episode_return_mean": 45.46600000000004, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.244422273031, "num_env_steps_trained_throughput_per_sec": 356.244422273031, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 10881.684, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10881.643, "sample_time_ms": 1435.754, "learn_time_ms": 9430.582, "learn_throughput": 424.152, "synch_weights_time_ms": 13.549}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "0b081_00000", "date": "2024-08-13_00-57-18", "timestamp": 1723525038, "time_this_iter_s": 11.277753829956055, "time_total_s": 618.3301479816437, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fb9790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 618.3301479816437, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 42.529411764705884, "ram_util_percent": 81.91176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5363594015518194, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6293692246394813, "policy_loss": -0.003368910060574611, "vf_loss": 0.632485303625701, "vf_explained_var": 0.0022843104506295826, "kl": 0.01065433426047179, "entropy": 1.2160676855889578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9590042102825704, "cur_kl_coeff": 0.0337881088256836, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1870723156859635, "policy_loss": -0.0024580435154752597, "vf_loss": 1.189114413658778, "vf_explained_var": 0.002776081126833719, "kl": 0.01231048454893101, "entropy": 1.0224180665281084, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 128.19999999999868, "episode_reward_min": -25.800000000000026, "episode_reward_mean": 46.547000000000025, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -111.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 108.19999999999942, "predator_policy": 67.0}, "policy_reward_mean": {"prey_policy": 15.828500000000025, "predator_policy": 7.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [101.199999999999, 87.89999999999927, 100.29999999999856, 68.60000000000016, 52.200000000000344, 21.90000000000015, 16.600000000000012, 61.400000000000375, 40.90000000000031, 41.80000000000033, 39.300000000000296, 40.0000000000003, 41.80000000000033, -9.299999999999756, 46.40000000000037, 63.60000000000043, -7.29999999999972, 40.50000000000032, 55.200000000000465, 31.000000000000163, 34.50000000000029, 60.00000000000022, -7.1999999999996955, 44.50000000000029, 25.600000000000076, 99.5999999999987, 13.400000000000034, 67.70000000000014, 40.0000000000003, 53.8000000000005, 64.30000000000048, 33.6000000000002, 64.90000000000022, 40.0000000000003, -2.199999999999829, 38.90000000000028, 22.20000000000007, 58.90000000000042, 11.900000000000004, 40.0000000000003, -24.299999999999763, 40.3000000000003, 47.700000000000394, 14.999999999999924, 75.99999999999947, 35.600000000000236, 38.400000000000276, 41.800000000000324, 50.40000000000048, 94.79999999999865, 9.200000000000035, 31.700000000000177, 40.0000000000003, 38.30000000000027, 40.0000000000003, 40.0000000000003, 46.600000000000406, 63.900000000000496, 35.600000000000236, 128.19999999999868, 31.90000000000018, 81.19999999999911, 6.8000000000001, 42.10000000000033, 91.7999999999989, 48.100000000000435, 61.40000000000046, 33.7000000000002, 12.500000000000002, 90.89999999999952, 57.30000000000048, 40.0000000000003, 113.79999999999859, 35.600000000000236, 40.30000000000037, 35.000000000000355, 26.600000000000094, 37.80000000000027, 40.0000000000003, 37.600000000000264, 49.9000000000003, 71.19999999999993, 31.300000000000157, 33.400000000000205, -25.800000000000026, 93.99999999999834, 110.49999999999896, 31.500000000000174, 102.09999999999829, 73.59999999999971, 20.600000000000005, 33.400000000000205, 86.79999999999885, 37.700000000000266, 82.29999999999917, 24.200000000000045, 56.600000000000406, 33.400000000000205, 40.0000000000003, 75.99999999999959], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [81.19999999999953, 20.000000000000014, 37.70000000000016, 21.200000000000067, 31.70000000000018, 41.60000000000023, 20.000000000000014, 47.600000000000236, -9.999999999999945, 24.200000000000085, -32.49999999999993, -1.5999999999999996, 7.699999999999988, -45.09999999999976, 25.40000000000012, 20.000000000000014, 20.000000000000014, 20.900000000000027, 21.800000000000047, 20.000000000000014, -53.50000000000016, 57.800000000000225, 20.000000000000014, 20.000000000000014, 21.800000000000047, 20.000000000000014, -51.39999999999987, -16.899999999999807, 16.699999999999967, 7.700000000000001, 15.799999999999963, 30.800000000000182, -70.30000000000081, 20.000000000000014, 0.4999999999999635, 20.000000000000014, 33.800000000000225, 16.399999999999967, 1.099999999999983, 20.900000000000027, 9.499999999999952, 20.000000000000014, 13.999999999999977, 20.000000000000014, 5.299999999999983, -53.50000000000005, 20.000000000000014, 24.500000000000096, -3.999999999999966, 11.599999999999964, 11.59999999999997, 79.99999999999935, 0.7999999999999865, -3.3999999999999653, 20.000000000000014, 31.700000000000195, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.8000000000002, 44.300000000000246, 10.999999999999972, 19.70000000000001, -0.09999999999995807, 25.10000000000012, 15.799999999999962, 20.000000000000014, 20.000000000000014, -80.20000000000064, 20.000000000000014, 17.899999999999984, 20.000000000000014, -24.999999999999794, 12.199999999999966, 20.000000000000014, 29.900000000000198, -13.899999999999803, -2.1999999999999713, 20.000000000000014, 20.000000000000014, 21.800000000000047, -111.10000000000036, 20.000000000000014, 8.299999999999972, 25.700000000000124, 20.000000000000014, 17.29999999999998, -28.29999999999977, -5.799999999999953, 45.800000000000125, 17.899999999999988, 13.699999999999964, -1.599999999999985, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.40000000000016, 20.000000000000014, 24.50000000000008, 65.3000000000001, 20.000000000000014, -38.79999999999978, -7.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.400000000000016, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 19.099999999999998, 20.000000000000014, 41.90000000000024, 11.59999999999997, 20.000000000000014, 108.19999999999942, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 51.20000000000015, 20.000000000000014, 20.000000000000014, -80.2000000000005, 20.000000000000014, 10.09999999999997, 47.30000000000016, 33.50000000000019, 28.100000000000147, 20.000000000000014, 23.60000000000007, 0.799999999999967, 20.90000000000003, -14.19999999999981, -32.49999999999975, 20.000000000000014, 39.20000000000015, 31.700000000000223, 21.20000000000003, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 11.599999999999964, 20.000000000000014, -3.099999999999972, 13.399999999999972, -108.10000000000025, 82.09999999999926, 22.40000000000005, -20.799999999999756, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999964, 20.000000000000014, 29.90000000000014, 20.000000000000014, 20.000000000000014, 45.20000000000021, 24.500000000000096, -5.199999999999937, 7.399999999999965, 20.000000000000014, -13.599999999999868, -47.19999999999976, 44.30000000000024, 49.70000000000024, 21.80000000000004, 85.69999999999953, 20.000000000000014, -11.499999999999819, 55.10000000000021, 47.00000000000024, 55.10000000000017, 9.49999999999998, 7.399999999999965, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 60.50000000000022, 26.300000000000118, 10.699999999999967, 20.000000000000014, 62.30000000000022, 20.000000000000014, -11.799999999999818, 20.000000000000014, 6.199999999999992, 34.400000000000226, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, 46.10000000000021], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 29.0, 17.0, 10.0, 1.0, 0.0, 34.0, 4.0, 27.0, 29.0, 23.0, 31.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 4.0, 18.0, 4.0, 13.0, 0.0, 43.0, 20.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 5.0, 0.0, 26.0, 37.0, 4.0, 0.0, 0.0, 13.0, 5.0, 1.0, 7.0, 16.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 13.0, 1.0, 9.0, 15.0, 0.0, 0.0, 55.0, 3.0, 0.0, 1.0, 35.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 65.0, 0.0, 12.0, 0.0, 2.0, 26.0, 0.0, 19.0, 17.0, 0.0, 4.0, 11.0, 9.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 28.0, 19.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 4.0, 0.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 67.0, 6.0, 6.0, 11.0, 0.0, 0.0, 0.0, 22.0, 15.0, 10.0, 17.0, 4.0, 21.0, 15.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 19.0, 11.0, 0.0, 61.0, 11.0, 14.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 3.0, 6.0, 0.0, 25.0, 10.0, 0.0, 0.0, 3.0, 0.0, 14.0, 9.0, 0.0, 0.0, 3.0, 6.0, 10.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 7.0, 0.0, 16.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5910291937019804, "mean_inference_ms": 1.8334947211962065, "mean_action_processing_ms": 0.25144217679646735, "mean_env_wait_ms": 0.1943500545857404, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005725383758544922, "StateBufferConnector_ms": 0.00380098819732666, "ViewRequirementAgentConnector_ms": 0.11619210243225098}, "num_episodes": 18, "episode_return_max": 128.19999999999868, "episode_return_min": -25.800000000000026, "episode_return_mean": 46.547000000000025, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.4133160781301, "num_env_steps_trained_throughput_per_sec": 368.4133160781301, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 10829.02, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10828.979, "sample_time_ms": 1444.237, "learn_time_ms": 9369.763, "learn_throughput": 426.905, "synch_weights_time_ms": 13.223}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "0b081_00000", "date": "2024-08-13_00-57-29", "timestamp": 1723525049, "time_this_iter_s": 10.920711040496826, "time_total_s": 629.2508590221405, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d57e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 629.2508590221405, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 37.56666666666667, "ram_util_percent": 82.91333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6200890077445558, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.414675651664141, "policy_loss": -0.0036839548498392104, "vf_loss": 0.4181848612301071, "vf_explained_var": 0.0015518241773837458, "kl": 0.007363762627737975, "entropy": 1.1780493321872894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8596553368740296, "cur_kl_coeff": 0.0337881088256836, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6513930338494006, "policy_loss": -0.0010327601311334149, "vf_loss": 0.6521754269522649, "vf_explained_var": -0.027309546016511463, "kl": 0.007409884821714037, "entropy": 1.1082344852427326, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 128.19999999999868, "episode_reward_min": -31.29999999999972, "episode_reward_mean": 44.630000000000045, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -111.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 108.19999999999942, "predator_policy": 77.0}, "policy_reward_mean": {"prey_policy": 15.44000000000002, "predator_policy": 6.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.200000000000465, 31.000000000000163, 34.50000000000029, 60.00000000000022, -7.1999999999996955, 44.50000000000029, 25.600000000000076, 99.5999999999987, 13.400000000000034, 67.70000000000014, 40.0000000000003, 53.8000000000005, 64.30000000000048, 33.6000000000002, 64.90000000000022, 40.0000000000003, -2.199999999999829, 38.90000000000028, 22.20000000000007, 58.90000000000042, 11.900000000000004, 40.0000000000003, -24.299999999999763, 40.3000000000003, 47.700000000000394, 14.999999999999924, 75.99999999999947, 35.600000000000236, 38.400000000000276, 41.800000000000324, 50.40000000000048, 94.79999999999865, 9.200000000000035, 31.700000000000177, 40.0000000000003, 38.30000000000027, 40.0000000000003, 40.0000000000003, 46.600000000000406, 63.900000000000496, 35.600000000000236, 128.19999999999868, 31.90000000000018, 81.19999999999911, 6.8000000000001, 42.10000000000033, 91.7999999999989, 48.100000000000435, 61.40000000000046, 33.7000000000002, 12.500000000000002, 90.89999999999952, 57.30000000000048, 40.0000000000003, 113.79999999999859, 35.600000000000236, 40.30000000000037, 35.000000000000355, 26.600000000000094, 37.80000000000027, 40.0000000000003, 37.600000000000264, 49.9000000000003, 71.19999999999993, 31.300000000000157, 33.400000000000205, -25.800000000000026, 93.99999999999834, 110.49999999999896, 31.500000000000174, 102.09999999999829, 73.59999999999971, 20.600000000000005, 33.400000000000205, 86.79999999999885, 37.700000000000266, 82.29999999999917, 24.200000000000045, 56.600000000000406, 33.400000000000205, 40.0000000000003, 75.99999999999959, 49.000000000000455, 25.70000000000007, 29.70000000000016, 5.600000000000183, 34.70000000000022, 41.80000000000033, -31.29999999999972, 49.00000000000045, 102.99999999999812, 43.60000000000037, -3.2999999999997947, 42.400000000000354, 40.900000000000325, 50.80000000000048, 37.80000000000027, 40.0000000000003, 46.80000000000039, 49.90000000000046], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [33.800000000000225, 16.399999999999967, 1.099999999999983, 20.900000000000027, 9.499999999999952, 20.000000000000014, 13.999999999999977, 20.000000000000014, 5.299999999999983, -53.50000000000005, 20.000000000000014, 24.500000000000096, -3.999999999999966, 11.599999999999964, 11.59999999999997, 79.99999999999935, 0.7999999999999865, -3.3999999999999653, 20.000000000000014, 31.700000000000195, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.8000000000002, 44.300000000000246, 10.999999999999972, 19.70000000000001, -0.09999999999995807, 25.10000000000012, 15.799999999999962, 20.000000000000014, 20.000000000000014, -80.20000000000064, 20.000000000000014, 17.899999999999984, 20.000000000000014, -24.999999999999794, 12.199999999999966, 20.000000000000014, 29.900000000000198, -13.899999999999803, -2.1999999999999713, 20.000000000000014, 20.000000000000014, 21.800000000000047, -111.10000000000036, 20.000000000000014, 8.299999999999972, 25.700000000000124, 20.000000000000014, 17.29999999999998, -28.29999999999977, -5.799999999999953, 45.800000000000125, 17.899999999999988, 13.699999999999964, -1.599999999999985, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.40000000000016, 20.000000000000014, 24.50000000000008, 65.3000000000001, 20.000000000000014, -38.79999999999978, -7.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.400000000000016, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 19.099999999999998, 20.000000000000014, 41.90000000000024, 11.59999999999997, 20.000000000000014, 108.19999999999942, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 51.20000000000015, 20.000000000000014, 20.000000000000014, -80.2000000000005, 20.000000000000014, 10.09999999999997, 47.30000000000016, 33.50000000000019, 28.100000000000147, 20.000000000000014, 23.60000000000007, 0.799999999999967, 20.90000000000003, -14.19999999999981, -32.49999999999975, 20.000000000000014, 39.20000000000015, 31.700000000000223, 21.20000000000003, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 11.599999999999964, 20.000000000000014, -3.099999999999972, 13.399999999999972, -108.10000000000025, 82.09999999999926, 22.40000000000005, -20.799999999999756, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999964, 20.000000000000014, 29.90000000000014, 20.000000000000014, 20.000000000000014, 45.20000000000021, 24.500000000000096, -5.199999999999937, 7.399999999999965, 20.000000000000014, -13.599999999999868, -47.19999999999976, 44.30000000000024, 49.70000000000024, 21.80000000000004, 85.69999999999953, 20.000000000000014, -11.499999999999819, 55.10000000000021, 47.00000000000024, 55.10000000000017, 9.49999999999998, 7.399999999999965, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 60.50000000000022, 26.300000000000118, 10.699999999999967, 20.000000000000014, 62.30000000000022, 20.000000000000014, -11.799999999999818, 20.000000000000014, 6.199999999999992, 34.400000000000226, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, 46.10000000000021, 24.200000000000085, 15.799999999999963, 20.000000000000014, -7.299999999999891, -3.0999999999999863, 21.80000000000004, -13.599999999999783, 3.1999999999999615, 9.799999999999967, 17.899999999999984, 20.900000000000027, 20.90000000000003, -28.299999999999876, -106.00000000000055, 20.000000000000014, 29.000000000000163, 55.10000000000023, 47.90000000000024, 15.799999999999963, 9.799999999999985, -73.30000000000074, 20.000000000000014, -25.599999999999795, 20.000000000000014, 17.299999999999972, 17.599999999999962, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999917, 23.60000000000007, 20.000000000000014, 29.90000000000018], "policy_predator_policy_reward": [0.0, 5.0, 0.0, 9.0, 0.0, 5.0, 0.0, 26.0, 37.0, 4.0, 0.0, 0.0, 13.0, 5.0, 1.0, 7.0, 16.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 13.0, 1.0, 9.0, 15.0, 0.0, 0.0, 55.0, 3.0, 0.0, 1.0, 35.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 65.0, 0.0, 12.0, 0.0, 2.0, 26.0, 0.0, 19.0, 17.0, 0.0, 4.0, 11.0, 9.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 28.0, 19.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 4.0, 0.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 67.0, 6.0, 6.0, 11.0, 0.0, 0.0, 0.0, 22.0, 15.0, 10.0, 17.0, 4.0, 21.0, 15.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 19.0, 11.0, 0.0, 61.0, 11.0, 14.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 3.0, 6.0, 0.0, 25.0, 10.0, 0.0, 0.0, 3.0, 0.0, 14.0, 9.0, 0.0, 0.0, 3.0, 6.0, 10.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 7.0, 0.0, 16.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 13.0, 0.0, 11.0, 0.0, 16.0, 0.0, 7.0, 0.0, 0.0, 0.0, 26.0, 77.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 50.0, 17.0, 31.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5917475346093616, "mean_inference_ms": 1.836541198220633, "mean_action_processing_ms": 0.2515591595855431, "mean_env_wait_ms": 0.19461439193457522, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0061986446380615234, "StateBufferConnector_ms": 0.003932833671569824, "ViewRequirementAgentConnector_ms": 0.1211014986038208}, "num_episodes": 18, "episode_return_max": 128.19999999999868, "episode_return_min": -31.29999999999972, "episode_return_mean": 44.630000000000045, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 379.37178406165623, "num_env_steps_trained_throughput_per_sec": 379.37178406165623, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 10712.234, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10712.191, "sample_time_ms": 1385.666, "learn_time_ms": 9311.252, "learn_throughput": 429.588, "synch_weights_time_ms": 13.286}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "0b081_00000", "date": "2024-08-13_00-57-39", "timestamp": 1723525059, "time_this_iter_s": 10.595902919769287, "time_total_s": 639.8467619419098, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dcac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 639.8467619419098, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 34.15333333333333, "ram_util_percent": 83.05999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6264552398688263, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7371205162118982, "policy_loss": -0.004683940639970676, "vf_loss": 0.7414691240856888, "vf_explained_var": 0.008699396552232208, "kl": 0.014130902924451835, "entropy": 1.1800114449369845, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9538161545302029, "cur_kl_coeff": 0.0337881088256836, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9692969350508912, "policy_loss": 0.0003234310675579956, "vf_loss": 0.9688693307694934, "vf_explained_var": -0.026694293343831624, "kl": 0.003083185219781835, "entropy": 1.1289114071578576, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 128.19999999999868, "episode_reward_min": -31.29999999999972, "episode_reward_mean": 44.238000000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -111.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 108.19999999999942, "predator_policy": 77.0}, "policy_reward_mean": {"prey_policy": 15.314000000000032, "predator_policy": 6.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.299999999999763, 40.3000000000003, 47.700000000000394, 14.999999999999924, 75.99999999999947, 35.600000000000236, 38.400000000000276, 41.800000000000324, 50.40000000000048, 94.79999999999865, 9.200000000000035, 31.700000000000177, 40.0000000000003, 38.30000000000027, 40.0000000000003, 40.0000000000003, 46.600000000000406, 63.900000000000496, 35.600000000000236, 128.19999999999868, 31.90000000000018, 81.19999999999911, 6.8000000000001, 42.10000000000033, 91.7999999999989, 48.100000000000435, 61.40000000000046, 33.7000000000002, 12.500000000000002, 90.89999999999952, 57.30000000000048, 40.0000000000003, 113.79999999999859, 35.600000000000236, 40.30000000000037, 35.000000000000355, 26.600000000000094, 37.80000000000027, 40.0000000000003, 37.600000000000264, 49.9000000000003, 71.19999999999993, 31.300000000000157, 33.400000000000205, -25.800000000000026, 93.99999999999834, 110.49999999999896, 31.500000000000174, 102.09999999999829, 73.59999999999971, 20.600000000000005, 33.400000000000205, 86.79999999999885, 37.700000000000266, 82.29999999999917, 24.200000000000045, 56.600000000000406, 33.400000000000205, 40.0000000000003, 75.99999999999959, 49.000000000000455, 25.70000000000007, 29.70000000000016, 5.600000000000183, 34.70000000000022, 41.80000000000033, -31.29999999999972, 49.00000000000045, 102.99999999999812, 43.60000000000037, -3.2999999999997947, 42.400000000000354, 40.900000000000325, 50.80000000000048, 37.80000000000027, 40.0000000000003, 46.80000000000039, 49.90000000000046, 26.800000000000104, 28.40000000000012, 15.699999999999983, 26.200000000000106, 63.000000000000405, 17.999999999999975, 15.499999999999927, 34.900000000000226, 29.000000000000128, 58.90000000000046, 98.29999999999856, 15.59999999999999, 54.00000000000051, 54.40000000000052, 38.90000000000028, 78.69999999999942, 67.60000000000024, 32.000000000000185, 24.60000000000007, 17.19999999999995, 34.50000000000022, 19.19999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [21.800000000000047, -111.10000000000036, 20.000000000000014, 8.299999999999972, 25.700000000000124, 20.000000000000014, 17.29999999999998, -28.29999999999977, -5.799999999999953, 45.800000000000125, 17.899999999999988, 13.699999999999964, -1.599999999999985, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.40000000000016, 20.000000000000014, 24.50000000000008, 65.3000000000001, 20.000000000000014, -38.79999999999978, -7.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.400000000000016, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 19.099999999999998, 20.000000000000014, 41.90000000000024, 11.59999999999997, 20.000000000000014, 108.19999999999942, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 51.20000000000015, 20.000000000000014, 20.000000000000014, -80.2000000000005, 20.000000000000014, 10.09999999999997, 47.30000000000016, 33.50000000000019, 28.100000000000147, 20.000000000000014, 23.60000000000007, 0.799999999999967, 20.90000000000003, -14.19999999999981, -32.49999999999975, 20.000000000000014, 39.20000000000015, 31.700000000000223, 21.20000000000003, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 11.599999999999964, 20.000000000000014, -3.099999999999972, 13.399999999999972, -108.10000000000025, 82.09999999999926, 22.40000000000005, -20.799999999999756, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999964, 20.000000000000014, 29.90000000000014, 20.000000000000014, 20.000000000000014, 45.20000000000021, 24.500000000000096, -5.199999999999937, 7.399999999999965, 20.000000000000014, -13.599999999999868, -47.19999999999976, 44.30000000000024, 49.70000000000024, 21.80000000000004, 85.69999999999953, 20.000000000000014, -11.499999999999819, 55.10000000000021, 47.00000000000024, 55.10000000000017, 9.49999999999998, 7.399999999999965, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 60.50000000000022, 26.300000000000118, 10.699999999999967, 20.000000000000014, 62.30000000000022, 20.000000000000014, -11.799999999999818, 20.000000000000014, 6.199999999999992, 34.400000000000226, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, 46.10000000000021, 24.200000000000085, 15.799999999999963, 20.000000000000014, -7.299999999999891, -3.0999999999999863, 21.80000000000004, -13.599999999999783, 3.1999999999999615, 9.799999999999967, 17.899999999999984, 20.900000000000027, 20.90000000000003, -28.299999999999876, -106.00000000000055, 20.000000000000014, 29.000000000000163, 55.10000000000023, 47.90000000000024, 15.799999999999963, 9.799999999999985, -73.30000000000074, 20.000000000000014, -25.599999999999795, 20.000000000000014, 17.299999999999972, 17.599999999999962, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999917, 23.60000000000007, 20.000000000000014, 29.90000000000018, 33.50000000000025, -36.699999999999754, 20.000000000000014, -40.59999999999981, -4.299999999999962, -0.9999999999999917, 20.000000000000014, -8.799999999999914, 21.80000000000004, 24.200000000000106, -21.999999999999744, 20.000000000000014, 21.20000000000003, -36.69999999999979, 2.8999999999999755, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 38.900000000000226, 20.000000000000014, 77.29999999999927, 20.000000000000014, 7.699999999999967, -12.099999999999817, 32.00000000000022, 20.000000000000014, 34.40000000000026, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 58.70000000000021, 34.700000000000244, 26.90000000000014, 20.000000000000014, -1.0000000000000133, -9.399999999999883, 20.000000000000014, 1.9999999999999731, -11.799999999999832, 9.499999999999964, 20.000000000000014, -13.599999999999783, 15.799999999999962], "policy_predator_policy_reward": [0.0, 65.0, 0.0, 12.0, 0.0, 2.0, 26.0, 0.0, 19.0, 17.0, 0.0, 4.0, 11.0, 9.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 28.0, 19.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 4.0, 0.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 67.0, 6.0, 6.0, 11.0, 0.0, 0.0, 0.0, 22.0, 15.0, 10.0, 17.0, 4.0, 21.0, 15.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 19.0, 11.0, 0.0, 61.0, 11.0, 14.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 3.0, 6.0, 0.0, 25.0, 10.0, 0.0, 0.0, 3.0, 0.0, 14.0, 9.0, 0.0, 0.0, 3.0, 6.0, 10.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 7.0, 0.0, 16.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 13.0, 0.0, 11.0, 0.0, 16.0, 0.0, 7.0, 0.0, 0.0, 0.0, 26.0, 77.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 50.0, 17.0, 31.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 11.0, 19.0, 33.0, 16.0, 13.0, 8.0, 0.0, 15.0, 6.0, 11.0, 0.0, 20.0, 1.0, 30.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 17.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 13.0, 0.0, 0.0, 14.0, 27.0, 0.0, 0.0, 5.0, 17.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5927670433837272, "mean_inference_ms": 1.8402911775219974, "mean_action_processing_ms": 0.25176501237872495, "mean_env_wait_ms": 0.1951087560780199, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00799250602722168, "StateBufferConnector_ms": 0.004667878150939941, "ViewRequirementAgentConnector_ms": 0.14015352725982666}, "num_episodes": 22, "episode_return_max": 128.19999999999868, "episode_return_min": -31.29999999999972, "episode_return_mean": 44.238000000000014, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 382.2109551772355, "num_env_steps_trained_throughput_per_sec": 382.2109551772355, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 10770.494, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10770.45, "sample_time_ms": 1400.645, "learn_time_ms": 9354.372, "learn_throughput": 427.608, "synch_weights_time_ms": 13.376}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "0b081_00000", "date": "2024-08-13_00-57-50", "timestamp": 1723525070, "time_this_iter_s": 10.498253107070923, "time_total_s": 650.3450150489807, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dcae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 650.3450150489807, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 31.233333333333334, "ram_util_percent": 83.33333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6381414255570798, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8854093124626805, "policy_loss": -0.002585564007016796, "vf_loss": 0.8877403872590216, "vf_explained_var": 0.003387108776304457, "kl": 0.010724198497012286, "entropy": 1.1834244562204552, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0625866040902794, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.237527005271937, "policy_loss": -0.0024377329851545037, "vf_loss": 1.2397033103244015, "vf_explained_var": 0.009653520962548635, "kl": 0.015474853049390004, "entropy": 1.1541970342555374, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 113.79999999999859, "episode_reward_min": -31.29999999999972, "episode_reward_mean": 43.81800000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -108.10000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 93.79999999999933, "predator_policy": 77.0}, "policy_reward_mean": {"prey_policy": 15.254000000000044, "predator_policy": 6.655}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.10000000000033, 91.7999999999989, 48.100000000000435, 61.40000000000046, 33.7000000000002, 12.500000000000002, 90.89999999999952, 57.30000000000048, 40.0000000000003, 113.79999999999859, 35.600000000000236, 40.30000000000037, 35.000000000000355, 26.600000000000094, 37.80000000000027, 40.0000000000003, 37.600000000000264, 49.9000000000003, 71.19999999999993, 31.300000000000157, 33.400000000000205, -25.800000000000026, 93.99999999999834, 110.49999999999896, 31.500000000000174, 102.09999999999829, 73.59999999999971, 20.600000000000005, 33.400000000000205, 86.79999999999885, 37.700000000000266, 82.29999999999917, 24.200000000000045, 56.600000000000406, 33.400000000000205, 40.0000000000003, 75.99999999999959, 49.000000000000455, 25.70000000000007, 29.70000000000016, 5.600000000000183, 34.70000000000022, 41.80000000000033, -31.29999999999972, 49.00000000000045, 102.99999999999812, 43.60000000000037, -3.2999999999997947, 42.400000000000354, 40.900000000000325, 50.80000000000048, 37.80000000000027, 40.0000000000003, 46.80000000000039, 49.90000000000046, 26.800000000000104, 28.40000000000012, 15.699999999999983, 26.200000000000106, 63.000000000000405, 17.999999999999975, 15.499999999999927, 34.900000000000226, 29.000000000000128, 58.90000000000046, 98.29999999999856, 15.59999999999999, 54.00000000000051, 54.40000000000052, 38.90000000000028, 78.69999999999942, 67.60000000000024, 32.000000000000185, 24.60000000000007, 17.19999999999995, 34.50000000000022, 19.19999999999998, 23.600000000000144, 40.0000000000003, 42.800000000000345, 35.600000000000236, 43.80000000000036, 54.40000000000037, 27.900000000000126, 105.99999999999898, 60.70000000000051, 6.300000000000145, 40.0000000000003, 3.0000000000001874, 80.39999999999927, 40.0000000000003, 52.70000000000051, 40.0000000000003, 42.90000000000036, 33.4000000000002, 46.80000000000043, 40.0000000000003, 45.40000000000038, 59.300000000000324, 2.1000000000001084], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 10.09999999999997, 47.30000000000016, 33.50000000000019, 28.100000000000147, 20.000000000000014, 23.60000000000007, 0.799999999999967, 20.90000000000003, -14.19999999999981, -32.49999999999975, 20.000000000000014, 39.20000000000015, 31.700000000000223, 21.20000000000003, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 93.79999999999933, 11.599999999999964, 20.000000000000014, -3.099999999999972, 13.399999999999972, -108.10000000000025, 82.09999999999926, 22.40000000000005, -20.799999999999756, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999964, 20.000000000000014, 29.90000000000014, 20.000000000000014, 20.000000000000014, 45.20000000000021, 24.500000000000096, -5.199999999999937, 7.399999999999965, 20.000000000000014, -13.599999999999868, -47.19999999999976, 44.30000000000024, 49.70000000000024, 21.80000000000004, 85.69999999999953, 20.000000000000014, -11.499999999999819, 55.10000000000021, 47.00000000000024, 55.10000000000017, 9.49999999999998, 7.399999999999965, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 60.50000000000022, 26.300000000000118, 10.699999999999967, 20.000000000000014, 62.30000000000022, 20.000000000000014, -11.799999999999818, 20.000000000000014, 6.199999999999992, 34.400000000000226, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, 46.10000000000021, 24.200000000000085, 15.799999999999963, 20.000000000000014, -7.299999999999891, -3.0999999999999863, 21.80000000000004, -13.599999999999783, 3.1999999999999615, 9.799999999999967, 17.899999999999984, 20.900000000000027, 20.90000000000003, -28.299999999999876, -106.00000000000055, 20.000000000000014, 29.000000000000163, 55.10000000000023, 47.90000000000024, 15.799999999999963, 9.799999999999985, -73.30000000000074, 20.000000000000014, -25.599999999999795, 20.000000000000014, 17.299999999999972, 17.599999999999962, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999917, 23.60000000000007, 20.000000000000014, 29.90000000000018, 33.50000000000025, -36.699999999999754, 20.000000000000014, -40.59999999999981, -4.299999999999962, -0.9999999999999917, 20.000000000000014, -8.799999999999914, 21.80000000000004, 24.200000000000106, -21.999999999999744, 20.000000000000014, 21.20000000000003, -36.69999999999979, 2.8999999999999755, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 38.900000000000226, 20.000000000000014, 77.29999999999927, 20.000000000000014, 7.699999999999967, -12.099999999999817, 32.00000000000022, 20.000000000000014, 34.40000000000026, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 58.70000000000021, 34.700000000000244, 26.90000000000014, 20.000000000000014, -1.0000000000000133, -9.399999999999883, 20.000000000000014, 1.9999999999999731, -11.799999999999832, 9.499999999999964, 20.000000000000014, -13.599999999999783, 15.799999999999962, -54.699999999999896, 41.300000000000246, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 11.59999999999997, 20.000000000000014, -3.099999999999958, 29.90000000000018, 13.699999999999969, 13.699999999999964, -3.09999999999999, 20.000000000000014, 58.10000000000015, 35.900000000000254, 20.90000000000003, 39.80000000000025, 3.199999999999965, -19.899999999999743, 20.000000000000014, 20.000000000000014, -21.99999999999976, 1.9999999999999607, 55.40000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999978, 37.10000000000026, 20.000000000000014, 20.000000000000014, -7.299999999999933, 36.20000000000021, 15.799999999999962, 11.59999999999998, 22.40000000000005, 4.399999999999981, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -8.499999999999893, 42.80000000000015, -58.30000000000049, -1.6000000000000352], "policy_predator_policy_reward": [6.0, 6.0, 11.0, 0.0, 0.0, 0.0, 22.0, 15.0, 10.0, 17.0, 4.0, 21.0, 15.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 19.0, 11.0, 0.0, 61.0, 11.0, 14.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 3.0, 6.0, 0.0, 25.0, 10.0, 0.0, 0.0, 3.0, 0.0, 14.0, 9.0, 0.0, 0.0, 3.0, 6.0, 10.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 7.0, 0.0, 16.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 13.0, 0.0, 11.0, 0.0, 16.0, 0.0, 7.0, 0.0, 0.0, 0.0, 26.0, 77.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 50.0, 17.0, 31.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 11.0, 19.0, 33.0, 16.0, 13.0, 8.0, 0.0, 15.0, 6.0, 11.0, 0.0, 20.0, 1.0, 30.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 17.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 13.0, 0.0, 0.0, 14.0, 27.0, 0.0, 0.0, 5.0, 17.0, 0.0, 37.0, 0.0, 0.0, 0.0, 5.0, 2.0, 4.0, 0.0, 11.0, 6.0, 0.0, 27.0, 0.0, 11.0, 1.0, 11.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 0.0, 23.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 8.0, 3.0, 3.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 18.0, 33.0, 29.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5941467772272546, "mean_inference_ms": 1.8402889936045193, "mean_action_processing_ms": 0.25166314653470556, "mean_env_wait_ms": 0.19556206788887973, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007833480834960938, "StateBufferConnector_ms": 0.004514098167419434, "ViewRequirementAgentConnector_ms": 0.13526904582977295}, "num_episodes": 23, "episode_return_max": 113.79999999999859, "episode_return_min": -31.29999999999972, "episode_return_mean": 43.81800000000005, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.4943629343116, "num_env_steps_trained_throughput_per_sec": 398.4943629343116, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 10796.112, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10796.067, "sample_time_ms": 1409.261, "learn_time_ms": 9370.762, "learn_throughput": 426.86, "synch_weights_time_ms": 13.948}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "0b081_00000", "date": "2024-08-13_00-58-00", "timestamp": 1723525080, "time_this_iter_s": 10.046434164047241, "time_total_s": 660.391449213028, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fbde50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 660.391449213028, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 29.94, "ram_util_percent": 83.29333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6447567231282986, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0508275908137126, "policy_loss": -0.005024869890548486, "vf_loss": 2.0555281619546273, "vf_explained_var": 0.0034271266725328232, "kl": 0.013665959939269804, "entropy": 1.1280214817435652, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3576411981431264, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3193291749903766, "policy_loss": -0.0031041142070005654, "vf_loss": 2.3222144257454644, "vf_explained_var": -0.010788816875881619, "kl": 0.012954389626401011, "entropy": 1.158515519818301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 110.49999999999896, "episode_reward_min": -31.29999999999972, "episode_reward_mean": 43.74600000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -108.40000000000026, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 87.49999999999929, "predator_policy": 77.0}, "policy_reward_mean": {"prey_policy": 13.433000000000042, "predator_policy": 8.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [71.19999999999993, 31.300000000000157, 33.400000000000205, -25.800000000000026, 93.99999999999834, 110.49999999999896, 31.500000000000174, 102.09999999999829, 73.59999999999971, 20.600000000000005, 33.400000000000205, 86.79999999999885, 37.700000000000266, 82.29999999999917, 24.200000000000045, 56.600000000000406, 33.400000000000205, 40.0000000000003, 75.99999999999959, 49.000000000000455, 25.70000000000007, 29.70000000000016, 5.600000000000183, 34.70000000000022, 41.80000000000033, -31.29999999999972, 49.00000000000045, 102.99999999999812, 43.60000000000037, -3.2999999999997947, 42.400000000000354, 40.900000000000325, 50.80000000000048, 37.80000000000027, 40.0000000000003, 46.80000000000039, 49.90000000000046, 26.800000000000104, 28.40000000000012, 15.699999999999983, 26.200000000000106, 63.000000000000405, 17.999999999999975, 15.499999999999927, 34.900000000000226, 29.000000000000128, 58.90000000000046, 98.29999999999856, 15.59999999999999, 54.00000000000051, 54.40000000000052, 38.90000000000028, 78.69999999999942, 67.60000000000024, 32.000000000000185, 24.60000000000007, 17.19999999999995, 34.50000000000022, 19.19999999999998, 23.600000000000144, 40.0000000000003, 42.800000000000345, 35.600000000000236, 43.80000000000036, 54.40000000000037, 27.900000000000126, 105.99999999999898, 60.70000000000051, 6.300000000000145, 40.0000000000003, 3.0000000000001874, 80.39999999999927, 40.0000000000003, 52.70000000000051, 40.0000000000003, 42.90000000000036, 33.4000000000002, 46.80000000000043, 40.0000000000003, 45.40000000000038, 59.300000000000324, 2.1000000000001084, 63.30000000000013, 41.40000000000027, 88.29999999999889, 71.19999999999992, -10.699999999999857, 39.30000000000028, 60.00000000000051, 49.2000000000003, 52.80000000000038, 30.300000000000153, 40.0000000000003, 109.59999999999857, 27.600000000000126, 50.40000000000034, 87.69999999999985, 20.60000000000007, 30.10000000000017, 36.10000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 45.20000000000021, 24.500000000000096, -5.199999999999937, 7.399999999999965, 20.000000000000014, -13.599999999999868, -47.19999999999976, 44.30000000000024, 49.70000000000024, 21.80000000000004, 85.69999999999953, 20.000000000000014, -11.499999999999819, 55.10000000000021, 47.00000000000024, 55.10000000000017, 9.49999999999998, 7.399999999999965, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 60.50000000000022, 26.300000000000118, 10.699999999999967, 20.000000000000014, 62.30000000000022, 20.000000000000014, -11.799999999999818, 20.000000000000014, 6.199999999999992, 34.400000000000226, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, 46.10000000000021, 24.200000000000085, 15.799999999999963, 20.000000000000014, -7.299999999999891, -3.0999999999999863, 21.80000000000004, -13.599999999999783, 3.1999999999999615, 9.799999999999967, 17.899999999999984, 20.900000000000027, 20.90000000000003, -28.299999999999876, -106.00000000000055, 20.000000000000014, 29.000000000000163, 55.10000000000023, 47.90000000000024, 15.799999999999963, 9.799999999999985, -73.30000000000074, 20.000000000000014, -25.599999999999795, 20.000000000000014, 17.299999999999972, 17.599999999999962, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999917, 23.60000000000007, 20.000000000000014, 29.90000000000018, 33.50000000000025, -36.699999999999754, 20.000000000000014, -40.59999999999981, -4.299999999999962, -0.9999999999999917, 20.000000000000014, -8.799999999999914, 21.80000000000004, 24.200000000000106, -21.999999999999744, 20.000000000000014, 21.20000000000003, -36.69999999999979, 2.8999999999999755, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 38.900000000000226, 20.000000000000014, 77.29999999999927, 20.000000000000014, 7.699999999999967, -12.099999999999817, 32.00000000000022, 20.000000000000014, 34.40000000000026, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 58.70000000000021, 34.700000000000244, 26.90000000000014, 20.000000000000014, -1.0000000000000133, -9.399999999999883, 20.000000000000014, 1.9999999999999731, -11.799999999999832, 9.499999999999964, 20.000000000000014, -13.599999999999783, 15.799999999999962, -54.699999999999896, 41.300000000000246, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 11.59999999999997, 20.000000000000014, -3.099999999999958, 29.90000000000018, 13.699999999999969, 13.699999999999964, -3.09999999999999, 20.000000000000014, 58.10000000000015, 35.900000000000254, 20.90000000000003, 39.80000000000025, 3.199999999999965, -19.899999999999743, 20.000000000000014, 20.000000000000014, -21.99999999999976, 1.9999999999999607, 55.40000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999978, 37.10000000000026, 20.000000000000014, 20.000000000000014, -7.299999999999933, 36.20000000000021, 15.799999999999962, 11.59999999999998, 22.40000000000005, 4.399999999999981, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -8.499999999999893, 42.80000000000015, -58.30000000000049, -1.6000000000000352, 40.70000000000025, 8.600000000000032, 20.000000000000014, -13.599999999999904, 58.40000000000014, 17.899999999999988, 20.000000000000014, 45.2000000000002, -108.40000000000026, -4.299999999999944, 20.000000000000014, 11.299999999999969, 16.399999999999967, 35.60000000000025, -8.799999999999978, 20.000000000000014, -58.00000000000023, 57.800000000000225, 20.000000000000014, -15.69999999999979, 20.000000000000014, 20.000000000000014, 51.50000000000017, 46.10000000000023, 2.8999999999999613, -19.299999999999855, 17.899999999999988, 9.499999999999988, 87.49999999999929, -53.80000000000059, -42.39999999999982, 20.000000000000014, 0.19999999999998833, -24.099999999999866, 7.399999999999965, -61.30000000000022], "policy_predator_policy_reward": [6.0, 0.0, 9.0, 3.0, 6.0, 0.0, 25.0, 10.0, 0.0, 0.0, 3.0, 0.0, 14.0, 9.0, 0.0, 0.0, 3.0, 6.0, 10.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 7.0, 0.0, 16.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 13.0, 0.0, 11.0, 0.0, 16.0, 0.0, 7.0, 0.0, 0.0, 0.0, 26.0, 77.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 50.0, 17.0, 31.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 11.0, 19.0, 33.0, 16.0, 13.0, 8.0, 0.0, 15.0, 6.0, 11.0, 0.0, 20.0, 1.0, 30.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 17.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 13.0, 0.0, 0.0, 14.0, 27.0, 0.0, 0.0, 5.0, 17.0, 0.0, 37.0, 0.0, 0.0, 0.0, 5.0, 2.0, 4.0, 0.0, 11.0, 6.0, 0.0, 27.0, 0.0, 11.0, 1.0, 11.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 0.0, 23.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 8.0, 3.0, 3.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 18.0, 33.0, 29.0, 12.0, 2.0, 1.0, 34.0, 1.0, 11.0, 6.0, 0.0, 29.0, 73.0, 8.0, 0.0, 0.0, 8.0, 30.0, 8.0, 30.0, 23.0, 26.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 44.0, 7.0, 16.0, 10.0, 44.0, 8.0, 35.0, 21.0, 33.0, 48.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5935023991017205, "mean_inference_ms": 1.8437547796319973, "mean_action_processing_ms": 0.251629365256693, "mean_env_wait_ms": 0.19562315944744135, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005906820297241211, "StateBufferConnector_ms": 0.00376129150390625, "ViewRequirementAgentConnector_ms": 0.11146080493927002}, "num_episodes": 18, "episode_return_max": 110.49999999999896, "episode_return_min": -31.29999999999972, "episode_return_mean": 43.74600000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.24986955130163, "num_env_steps_trained_throughput_per_sec": 409.24986955130163, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 10763.28, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10763.236, "sample_time_ms": 1403.158, "learn_time_ms": 9344.278, "learn_throughput": 428.069, "synch_weights_time_ms": 13.717}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "0b081_00000", "date": "2024-08-13_00-58-10", "timestamp": 1723525090, "time_this_iter_s": 9.778100967407227, "time_total_s": 670.1695501804352, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fbdd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 670.1695501804352, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 30.492307692307694, "ram_util_percent": 83.23846153846154}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5872089989877567, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5020244475789171, "policy_loss": -0.0037698205104639763, "vf_loss": 0.5055435775688026, "vf_explained_var": 0.008840431012804547, "kl": 0.010564128600297281, "entropy": 1.1182220993849334, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0252647804362434, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8323093607548684, "policy_loss": -0.0021992565491162834, "vf_loss": 0.8343423994524138, "vf_explained_var": -0.05033860487281961, "kl": 0.009838934177163436, "entropy": 1.140847324126612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 109.59999999999857, "episode_reward_min": -31.29999999999972, "episode_reward_mean": 42.53500000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -108.40000000000026, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 87.49999999999929, "predator_policy": 77.0}, "policy_reward_mean": {"prey_policy": 12.147500000000043, "predator_policy": 9.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [75.99999999999959, 49.000000000000455, 25.70000000000007, 29.70000000000016, 5.600000000000183, 34.70000000000022, 41.80000000000033, -31.29999999999972, 49.00000000000045, 102.99999999999812, 43.60000000000037, -3.2999999999997947, 42.400000000000354, 40.900000000000325, 50.80000000000048, 37.80000000000027, 40.0000000000003, 46.80000000000039, 49.90000000000046, 26.800000000000104, 28.40000000000012, 15.699999999999983, 26.200000000000106, 63.000000000000405, 17.999999999999975, 15.499999999999927, 34.900000000000226, 29.000000000000128, 58.90000000000046, 98.29999999999856, 15.59999999999999, 54.00000000000051, 54.40000000000052, 38.90000000000028, 78.69999999999942, 67.60000000000024, 32.000000000000185, 24.60000000000007, 17.19999999999995, 34.50000000000022, 19.19999999999998, 23.600000000000144, 40.0000000000003, 42.800000000000345, 35.600000000000236, 43.80000000000036, 54.40000000000037, 27.900000000000126, 105.99999999999898, 60.70000000000051, 6.300000000000145, 40.0000000000003, 3.0000000000001874, 80.39999999999927, 40.0000000000003, 52.70000000000051, 40.0000000000003, 42.90000000000036, 33.4000000000002, 46.80000000000043, 40.0000000000003, 45.40000000000038, 59.300000000000324, 2.1000000000001084, 63.30000000000013, 41.40000000000027, 88.29999999999889, 71.19999999999992, -10.699999999999857, 39.30000000000028, 60.00000000000051, 49.2000000000003, 52.80000000000038, 30.300000000000153, 40.0000000000003, 109.59999999999857, 27.600000000000126, 50.40000000000034, 87.69999999999985, 20.60000000000007, 30.10000000000017, 36.10000000000019, 55.500000000000426, 24.100000000000055, 82.29999999999914, 30.100000000000147, 71.99999999999986, 65.20000000000043, 48.100000000000435, 8.600000000000094, 29.400000000000148, 63.80000000000045, 48.80000000000039, 47.900000000000375, 45.500000000000405, 40.0000000000003, 50.60000000000048, 35.600000000000236, 28.20000000000016, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.90000000000018, 46.10000000000021, 24.200000000000085, 15.799999999999963, 20.000000000000014, -7.299999999999891, -3.0999999999999863, 21.80000000000004, -13.599999999999783, 3.1999999999999615, 9.799999999999967, 17.899999999999984, 20.900000000000027, 20.90000000000003, -28.299999999999876, -106.00000000000055, 20.000000000000014, 29.000000000000163, 55.10000000000023, 47.90000000000024, 15.799999999999963, 9.799999999999985, -73.30000000000074, 20.000000000000014, -25.599999999999795, 20.000000000000014, 17.299999999999972, 17.599999999999962, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999917, 23.60000000000007, 20.000000000000014, 29.90000000000018, 33.50000000000025, -36.699999999999754, 20.000000000000014, -40.59999999999981, -4.299999999999962, -0.9999999999999917, 20.000000000000014, -8.799999999999914, 21.80000000000004, 24.200000000000106, -21.999999999999744, 20.000000000000014, 21.20000000000003, -36.69999999999979, 2.8999999999999755, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 38.900000000000226, 20.000000000000014, 77.29999999999927, 20.000000000000014, 7.699999999999967, -12.099999999999817, 32.00000000000022, 20.000000000000014, 34.40000000000026, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 58.70000000000021, 34.700000000000244, 26.90000000000014, 20.000000000000014, -1.0000000000000133, -9.399999999999883, 20.000000000000014, 1.9999999999999731, -11.799999999999832, 9.499999999999964, 20.000000000000014, -13.599999999999783, 15.799999999999962, -54.699999999999896, 41.300000000000246, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 11.59999999999997, 20.000000000000014, -3.099999999999958, 29.90000000000018, 13.699999999999969, 13.699999999999964, -3.09999999999999, 20.000000000000014, 58.10000000000015, 35.900000000000254, 20.90000000000003, 39.80000000000025, 3.199999999999965, -19.899999999999743, 20.000000000000014, 20.000000000000014, -21.99999999999976, 1.9999999999999607, 55.40000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999978, 37.10000000000026, 20.000000000000014, 20.000000000000014, -7.299999999999933, 36.20000000000021, 15.799999999999962, 11.59999999999998, 22.40000000000005, 4.399999999999981, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -8.499999999999893, 42.80000000000015, -58.30000000000049, -1.6000000000000352, 40.70000000000025, 8.600000000000032, 20.000000000000014, -13.599999999999904, 58.40000000000014, 17.899999999999988, 20.000000000000014, 45.2000000000002, -108.40000000000026, -4.299999999999944, 20.000000000000014, 11.299999999999969, 16.399999999999967, 35.60000000000025, -8.799999999999978, 20.000000000000014, -58.00000000000023, 57.800000000000225, 20.000000000000014, -15.69999999999979, 20.000000000000014, 20.000000000000014, 51.50000000000017, 46.10000000000023, 2.8999999999999613, -19.299999999999855, 17.899999999999988, 9.499999999999988, 87.49999999999929, -53.80000000000059, -42.39999999999982, 20.000000000000014, 0.19999999999998833, -24.099999999999866, 7.399999999999965, -61.30000000000022, 18.499999999999993, 20.000000000000014, -13.899999999999796, 20.000000000000014, 20.000000000000014, 62.3000000000002, 1.0999999999999865, 20.000000000000014, 35.0000000000002, 20.000000000000014, 39.80000000000025, 25.400000000000098, 20.000000000000014, 28.100000000000147, -25.59999999999976, 3.1999999999999615, 20.000000000000014, -55.600000000000136, 3.4999999999999725, 41.30000000000022, 31.70000000000018, -19.899999999999807, 26.90000000000014, 20.000000000000014, 11.599999999999964, 29.900000000000187, 20.000000000000014, 20.000000000000014, 31.700000000000212, 17.899999999999988, 11.599999999999973, 20.000000000000014, -11.499999999999925, -28.299999999999763, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 2.0, 7.0, 13.0, 0.0, 11.0, 0.0, 16.0, 0.0, 7.0, 0.0, 0.0, 0.0, 26.0, 77.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 50.0, 17.0, 31.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 11.0, 19.0, 33.0, 16.0, 13.0, 8.0, 0.0, 15.0, 6.0, 11.0, 0.0, 20.0, 1.0, 30.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 17.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 13.0, 0.0, 0.0, 14.0, 27.0, 0.0, 0.0, 5.0, 17.0, 0.0, 37.0, 0.0, 0.0, 0.0, 5.0, 2.0, 4.0, 0.0, 11.0, 6.0, 0.0, 27.0, 0.0, 11.0, 1.0, 11.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 0.0, 23.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 8.0, 3.0, 3.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 18.0, 33.0, 29.0, 12.0, 2.0, 1.0, 34.0, 1.0, 11.0, 6.0, 0.0, 29.0, 73.0, 8.0, 0.0, 0.0, 8.0, 30.0, 8.0, 30.0, 23.0, 26.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 44.0, 7.0, 16.0, 10.0, 44.0, 8.0, 35.0, 21.0, 33.0, 48.0, 42.0, 16.0, 1.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 15.0, 16.0, 33.0, 32.0, 0.0, 19.0, 12.0, 25.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 27.0, 41.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5933299845701935, "mean_inference_ms": 1.8440699745320075, "mean_action_processing_ms": 0.25144158721820625, "mean_env_wait_ms": 0.19565701061341984, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005829215049743652, "StateBufferConnector_ms": 0.003696441650390625, "ViewRequirementAgentConnector_ms": 0.11045122146606445}, "num_episodes": 18, "episode_return_max": 109.59999999999857, "episode_return_min": -31.29999999999972, "episode_return_mean": 42.53500000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 401.17546220846435, "num_env_steps_trained_throughput_per_sec": 401.17546220846435, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 10767.143, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10767.097, "sample_time_ms": 1409.766, "learn_time_ms": 9341.366, "learn_throughput": 428.203, "synch_weights_time_ms": 13.83}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "0b081_00000", "date": "2024-08-13_00-58-20", "timestamp": 1723525100, "time_this_iter_s": 10.006439924240112, "time_total_s": 680.1759901046753, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327fb98b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 680.1759901046753, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 28.39333333333333, "ram_util_percent": 83.49333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6345790991116138, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.663278198778314, "policy_loss": -0.005202996388826736, "vf_loss": 0.6680987502817833, "vf_explained_var": 0.0031573739947465362, "kl": 0.016116162727566843, "entropy": 1.0856504509688685, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1061614525262957, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.79522981578632, "policy_loss": -0.003420540162918981, "vf_loss": 0.7983718251188596, "vf_explained_var": -0.20547822253413933, "kl": 0.016486932936159854, "entropy": 1.1621834791526593, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 109.59999999999857, "episode_reward_min": -24.599999999999532, "episode_reward_mean": 43.643000000000164, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -108.40000000000026, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 87.49999999999929, "predator_policy": 73.0}, "policy_reward_mean": {"prey_policy": 13.371500000000049, "predator_policy": 8.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.200000000000106, 63.000000000000405, 17.999999999999975, 15.499999999999927, 34.900000000000226, 29.000000000000128, 58.90000000000046, 98.29999999999856, 15.59999999999999, 54.00000000000051, 54.40000000000052, 38.90000000000028, 78.69999999999942, 67.60000000000024, 32.000000000000185, 24.60000000000007, 17.19999999999995, 34.50000000000022, 19.19999999999998, 23.600000000000144, 40.0000000000003, 42.800000000000345, 35.600000000000236, 43.80000000000036, 54.40000000000037, 27.900000000000126, 105.99999999999898, 60.70000000000051, 6.300000000000145, 40.0000000000003, 3.0000000000001874, 80.39999999999927, 40.0000000000003, 52.70000000000051, 40.0000000000003, 42.90000000000036, 33.4000000000002, 46.80000000000043, 40.0000000000003, 45.40000000000038, 59.300000000000324, 2.1000000000001084, 63.30000000000013, 41.40000000000027, 88.29999999999889, 71.19999999999992, -10.699999999999857, 39.30000000000028, 60.00000000000051, 49.2000000000003, 52.80000000000038, 30.300000000000153, 40.0000000000003, 109.59999999999857, 27.600000000000126, 50.40000000000034, 87.69999999999985, 20.60000000000007, 30.10000000000017, 36.10000000000019, 55.500000000000426, 24.100000000000055, 82.29999999999914, 30.100000000000147, 71.99999999999986, 65.20000000000043, 48.100000000000435, 8.600000000000094, 29.400000000000148, 63.80000000000045, 48.80000000000039, 47.900000000000375, 45.500000000000405, 40.0000000000003, 50.60000000000048, 35.600000000000236, 28.20000000000016, 40.0000000000003, 40.0000000000003, 61.600000000000506, 47.20000000000042, 31.000000000000163, 40.0000000000003, 40.90000000000031, 67.60000000000021, 52.40000000000044, 45.700000000000415, 36.30000000000025, 21.000000000000004, 48.20000000000047, 50.40000000000047, 37.80000000000027, 40.0000000000003, 38.90000000000028, 76.39999999999954, 40.0000000000003, 50.80000000000048, -24.599999999999532, 6.100000000000046, 66.10000000000034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -8.799999999999914, 21.80000000000004, 24.200000000000106, -21.999999999999744, 20.000000000000014, 21.20000000000003, -36.69999999999979, 2.8999999999999755, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 38.900000000000226, 20.000000000000014, 77.29999999999927, 20.000000000000014, 7.699999999999967, -12.099999999999817, 32.00000000000022, 20.000000000000014, 34.40000000000026, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 58.70000000000021, 34.700000000000244, 26.90000000000014, 20.000000000000014, -1.0000000000000133, -9.399999999999883, 20.000000000000014, 1.9999999999999731, -11.799999999999832, 9.499999999999964, 20.000000000000014, -13.599999999999783, 15.799999999999962, -54.699999999999896, 41.300000000000246, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 11.59999999999997, 20.000000000000014, -3.099999999999958, 29.90000000000018, 13.699999999999969, 13.699999999999964, -3.09999999999999, 20.000000000000014, 58.10000000000015, 35.900000000000254, 20.90000000000003, 39.80000000000025, 3.199999999999965, -19.899999999999743, 20.000000000000014, 20.000000000000014, -21.99999999999976, 1.9999999999999607, 55.40000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999978, 37.10000000000026, 20.000000000000014, 20.000000000000014, -7.299999999999933, 36.20000000000021, 15.799999999999962, 11.59999999999998, 22.40000000000005, 4.399999999999981, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -8.499999999999893, 42.80000000000015, -58.30000000000049, -1.6000000000000352, 40.70000000000025, 8.600000000000032, 20.000000000000014, -13.599999999999904, 58.40000000000014, 17.899999999999988, 20.000000000000014, 45.2000000000002, -108.40000000000026, -4.299999999999944, 20.000000000000014, 11.299999999999969, 16.399999999999967, 35.60000000000025, -8.799999999999978, 20.000000000000014, -58.00000000000023, 57.800000000000225, 20.000000000000014, -15.69999999999979, 20.000000000000014, 20.000000000000014, 51.50000000000017, 46.10000000000023, 2.8999999999999613, -19.299999999999855, 17.899999999999988, 9.499999999999988, 87.49999999999929, -53.80000000000059, -42.39999999999982, 20.000000000000014, 0.19999999999998833, -24.099999999999866, 7.399999999999965, -61.30000000000022, 18.499999999999993, 20.000000000000014, -13.899999999999796, 20.000000000000014, 20.000000000000014, 62.3000000000002, 1.0999999999999865, 20.000000000000014, 35.0000000000002, 20.000000000000014, 39.80000000000025, 25.400000000000098, 20.000000000000014, 28.100000000000147, -25.59999999999976, 3.1999999999999615, 20.000000000000014, -55.600000000000136, 3.4999999999999725, 41.30000000000022, 31.70000000000018, -19.899999999999807, 26.90000000000014, 20.000000000000014, 11.599999999999964, 29.900000000000187, 20.000000000000014, 20.000000000000014, 31.700000000000212, 17.899999999999988, 11.599999999999973, 20.000000000000014, -11.499999999999925, -28.299999999999763, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000025, 27.200000000000134, 20.000000000000014, 20.000000000000014, 1.9999999999999838, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 50.60000000000022, 10.999999999999966, 17.899999999999984, 12.499999999999972, 25.100000000000108, -9.399999999999883, 6.499999999999972, -11.199999999999898, -9.399999999999855, -1.6000000000000245, 20.000000000000014, 9.199999999999976, 32.600000000000236, 15.799999999999963, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 50.60000000000019, 12.799999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -32.79999999999977, -38.799999999999756, -6.399999999999965, -32.4999999999998, 33.5000000000002, 32.60000000000023], "policy_predator_policy_reward": [0.0, 15.0, 6.0, 11.0, 0.0, 20.0, 1.0, 30.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 17.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 13.0, 0.0, 0.0, 14.0, 27.0, 0.0, 0.0, 5.0, 17.0, 0.0, 37.0, 0.0, 0.0, 0.0, 5.0, 2.0, 4.0, 0.0, 11.0, 6.0, 0.0, 27.0, 0.0, 11.0, 1.0, 11.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 0.0, 23.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 8.0, 3.0, 3.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 18.0, 33.0, 29.0, 12.0, 2.0, 1.0, 34.0, 1.0, 11.0, 6.0, 0.0, 29.0, 73.0, 8.0, 0.0, 0.0, 8.0, 30.0, 8.0, 30.0, 23.0, 26.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 44.0, 7.0, 16.0, 10.0, 44.0, 8.0, 35.0, 21.0, 33.0, 48.0, 42.0, 16.0, 1.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 15.0, 16.0, 33.0, 32.0, 0.0, 19.0, 12.0, 25.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 27.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 0.0, 13.0, 17.0, 0.0, 41.0, 23.0, 9.0, 12.0, 7.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 18.0, 29.0, 15.0, 30.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5929210236594021, "mean_inference_ms": 1.8438887931888894, "mean_action_processing_ms": 0.251191471098926, "mean_env_wait_ms": 0.19555927722936922, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005682468414306641, "StateBufferConnector_ms": 0.0035920143127441406, "ViewRequirementAgentConnector_ms": 0.10666191577911377}, "num_episodes": 22, "episode_return_max": 109.59999999999857, "episode_return_min": -24.599999999999532, "episode_return_mean": 43.643000000000164, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 397.41934921471073, "num_env_steps_trained_throughput_per_sec": 397.41934921471073, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 10640.14, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10640.095, "sample_time_ms": 1416.03, "learn_time_ms": 9208.215, "learn_throughput": 434.395, "synch_weights_time_ms": 13.834}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "0b081_00000", "date": "2024-08-13_00-58-30", "timestamp": 1723525110, "time_this_iter_s": 10.070267915725708, "time_total_s": 690.246258020401, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbe5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 690.246258020401, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 30.721428571428568, "ram_util_percent": 83.37142857142855}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6584719084163823, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6870734316331369, "policy_loss": -0.006169893900573096, "vf_loss": 0.6930026126365182, "vf_explained_var": 0.006349607561000441, "kl": 0.010143738121450786, "entropy": 1.0858312550360563, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.11316663996962, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9021553005589537, "policy_loss": -0.004554921027184243, "vf_loss": 0.9064120759251256, "vf_explained_var": -0.0032094590247623506, "kl": 0.017647921491659745, "entropy": 1.135668248158914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 109.59999999999857, "episode_reward_min": -100.50000000000021, "episode_reward_mean": 42.48900000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -217.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 87.49999999999929, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 12.29450000000005, "predator_policy": 8.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.19999999999998, 23.600000000000144, 40.0000000000003, 42.800000000000345, 35.600000000000236, 43.80000000000036, 54.40000000000037, 27.900000000000126, 105.99999999999898, 60.70000000000051, 6.300000000000145, 40.0000000000003, 3.0000000000001874, 80.39999999999927, 40.0000000000003, 52.70000000000051, 40.0000000000003, 42.90000000000036, 33.4000000000002, 46.80000000000043, 40.0000000000003, 45.40000000000038, 59.300000000000324, 2.1000000000001084, 63.30000000000013, 41.40000000000027, 88.29999999999889, 71.19999999999992, -10.699999999999857, 39.30000000000028, 60.00000000000051, 49.2000000000003, 52.80000000000038, 30.300000000000153, 40.0000000000003, 109.59999999999857, 27.600000000000126, 50.40000000000034, 87.69999999999985, 20.60000000000007, 30.10000000000017, 36.10000000000019, 55.500000000000426, 24.100000000000055, 82.29999999999914, 30.100000000000147, 71.99999999999986, 65.20000000000043, 48.100000000000435, 8.600000000000094, 29.400000000000148, 63.80000000000045, 48.80000000000039, 47.900000000000375, 45.500000000000405, 40.0000000000003, 50.60000000000048, 35.600000000000236, 28.20000000000016, 40.0000000000003, 40.0000000000003, 61.600000000000506, 47.20000000000042, 31.000000000000163, 40.0000000000003, 40.90000000000031, 67.60000000000021, 52.40000000000044, 45.700000000000415, 36.30000000000025, 21.000000000000004, 48.20000000000047, 50.40000000000047, 37.80000000000027, 40.0000000000003, 38.90000000000028, 76.39999999999954, 40.0000000000003, 50.80000000000048, -24.599999999999532, 6.100000000000046, 66.10000000000034, 32.70000000000019, 57.10000000000054, 40.0000000000003, 35.600000000000236, 60.800000000000466, 38.10000000000027, 40.0000000000003, 56.300000000000445, 30.400000000000162, 49.00000000000045, 49.40000000000047, -100.50000000000021, 84.39999999999898, 61.600000000000456, 23.50000000000005, 39.40000000000029, 8.100000000000131, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-13.599999999999783, 15.799999999999962, -54.699999999999896, 41.300000000000246, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 11.59999999999997, 20.000000000000014, -3.099999999999958, 29.90000000000018, 13.699999999999969, 13.699999999999964, -3.09999999999999, 20.000000000000014, 58.10000000000015, 35.900000000000254, 20.90000000000003, 39.80000000000025, 3.199999999999965, -19.899999999999743, 20.000000000000014, 20.000000000000014, -21.99999999999976, 1.9999999999999607, 55.40000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999978, 37.10000000000026, 20.000000000000014, 20.000000000000014, -7.299999999999933, 36.20000000000021, 15.799999999999962, 11.59999999999998, 22.40000000000005, 4.399999999999981, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -8.499999999999893, 42.80000000000015, -58.30000000000049, -1.6000000000000352, 40.70000000000025, 8.600000000000032, 20.000000000000014, -13.599999999999904, 58.40000000000014, 17.899999999999988, 20.000000000000014, 45.2000000000002, -108.40000000000026, -4.299999999999944, 20.000000000000014, 11.299999999999969, 16.399999999999967, 35.60000000000025, -8.799999999999978, 20.000000000000014, -58.00000000000023, 57.800000000000225, 20.000000000000014, -15.69999999999979, 20.000000000000014, 20.000000000000014, 51.50000000000017, 46.10000000000023, 2.8999999999999613, -19.299999999999855, 17.899999999999988, 9.499999999999988, 87.49999999999929, -53.80000000000059, -42.39999999999982, 20.000000000000014, 0.19999999999998833, -24.099999999999866, 7.399999999999965, -61.30000000000022, 18.499999999999993, 20.000000000000014, -13.899999999999796, 20.000000000000014, 20.000000000000014, 62.3000000000002, 1.0999999999999865, 20.000000000000014, 35.0000000000002, 20.000000000000014, 39.80000000000025, 25.400000000000098, 20.000000000000014, 28.100000000000147, -25.59999999999976, 3.1999999999999615, 20.000000000000014, -55.600000000000136, 3.4999999999999725, 41.30000000000022, 31.70000000000018, -19.899999999999807, 26.90000000000014, 20.000000000000014, 11.599999999999964, 29.900000000000187, 20.000000000000014, 20.000000000000014, 31.700000000000212, 17.899999999999988, 11.599999999999973, 20.000000000000014, -11.499999999999925, -28.299999999999763, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000025, 27.200000000000134, 20.000000000000014, 20.000000000000014, 1.9999999999999838, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 50.60000000000022, 10.999999999999966, 17.899999999999984, 12.499999999999972, 25.100000000000108, -9.399999999999883, 6.499999999999972, -11.199999999999898, -9.399999999999855, -1.6000000000000245, 20.000000000000014, 9.199999999999976, 32.600000000000236, 15.799999999999963, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 50.60000000000019, 12.799999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -32.79999999999977, -38.799999999999756, -6.399999999999965, -32.4999999999998, 33.5000000000002, 32.60000000000023, 20.000000000000014, -1.2999999999999994, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 36.80000000000022, 20.000000000000014, 20.000000000000014, 13.099999999999966, 20.000000000000014, 20.000000000000014, 19.70000000000001, 23.60000000000008, -0.7000000000000134, 10.099999999999966, 29.000000000000163, 20.000000000000014, 20.000000000000014, 4.399999999999979, 0.7999999999999954, -217.30000000000007, 28.70000000000017, 43.70000000000022, 41.60000000000022, 20.000000000000014, 22.700000000000053, -47.19999999999977, 16.399999999999967, 20.000000000000014, -21.999999999999744, 1.0999999999999865, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [17.0, 0.0, 37.0, 0.0, 0.0, 0.0, 5.0, 2.0, 4.0, 0.0, 11.0, 6.0, 0.0, 27.0, 0.0, 11.0, 1.0, 11.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 0.0, 23.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 8.0, 3.0, 3.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 18.0, 33.0, 29.0, 12.0, 2.0, 1.0, 34.0, 1.0, 11.0, 6.0, 0.0, 29.0, 73.0, 8.0, 0.0, 0.0, 8.0, 30.0, 8.0, 30.0, 23.0, 26.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 44.0, 7.0, 16.0, 10.0, 44.0, 8.0, 35.0, 21.0, 33.0, 48.0, 42.0, 16.0, 1.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 15.0, 16.0, 33.0, 32.0, 0.0, 19.0, 12.0, 25.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 27.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 0.0, 13.0, 17.0, 0.0, 41.0, 23.0, 9.0, 12.0, 7.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 18.0, 29.0, 15.0, 30.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 3.0, 10.0, 21.0, 0.0, 0.0, 0.0, 16.0, 9.0, 116.0, 0.0, 5.0, 7.0, 0.0, 0.0, 16.0, 32.0, 0.0, 3.0, 20.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5924018081765822, "mean_inference_ms": 1.8428522204842364, "mean_action_processing_ms": 0.2509047196593604, "mean_env_wait_ms": 0.19534107955791366, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004148125648498535, "StateBufferConnector_ms": 0.0029230117797851562, "ViewRequirementAgentConnector_ms": 0.09228432178497314}, "num_episodes": 18, "episode_return_max": 109.59999999999857, "episode_return_min": -100.50000000000021, "episode_return_mean": 42.48900000000019, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 396.0211446178511, "num_env_steps_trained_throughput_per_sec": 396.0211446178511, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 10555.726, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10555.68, "sample_time_ms": 1403.554, "learn_time_ms": 9136.106, "learn_throughput": 437.823, "synch_weights_time_ms": 13.915}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "0b081_00000", "date": "2024-08-13_00-58-40", "timestamp": 1723525120, "time_this_iter_s": 10.143439054489136, "time_total_s": 700.3896970748901, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d16700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 700.3896970748901, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 30.378571428571426, "ram_util_percent": 83.25714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6510175608650401, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.45124867588439316, "policy_loss": -0.003751280383458213, "vf_loss": 0.4547861113424891, "vf_explained_var": 0.01042973414930717, "kl": 0.009011382508802497, "entropy": 1.1209945300268749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1119417437780945, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8306888741909196, "policy_loss": -0.003063663508848992, "vf_loss": 0.8334958750340674, "vf_explained_var": 0.06373664903893042, "kl": 0.015192522448872238, "entropy": 1.1202577541744898, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 109.59999999999857, "episode_reward_min": -100.50000000000021, "episode_reward_mean": 42.6520000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -217.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 87.49999999999929, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 12.476000000000049, "predator_policy": 8.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.1000000000001084, 63.30000000000013, 41.40000000000027, 88.29999999999889, 71.19999999999992, -10.699999999999857, 39.30000000000028, 60.00000000000051, 49.2000000000003, 52.80000000000038, 30.300000000000153, 40.0000000000003, 109.59999999999857, 27.600000000000126, 50.40000000000034, 87.69999999999985, 20.60000000000007, 30.10000000000017, 36.10000000000019, 55.500000000000426, 24.100000000000055, 82.29999999999914, 30.100000000000147, 71.99999999999986, 65.20000000000043, 48.100000000000435, 8.600000000000094, 29.400000000000148, 63.80000000000045, 48.80000000000039, 47.900000000000375, 45.500000000000405, 40.0000000000003, 50.60000000000048, 35.600000000000236, 28.20000000000016, 40.0000000000003, 40.0000000000003, 61.600000000000506, 47.20000000000042, 31.000000000000163, 40.0000000000003, 40.90000000000031, 67.60000000000021, 52.40000000000044, 45.700000000000415, 36.30000000000025, 21.000000000000004, 48.20000000000047, 50.40000000000047, 37.80000000000027, 40.0000000000003, 38.90000000000028, 76.39999999999954, 40.0000000000003, 50.80000000000048, -24.599999999999532, 6.100000000000046, 66.10000000000034, 32.70000000000019, 57.10000000000054, 40.0000000000003, 35.600000000000236, 60.800000000000466, 38.10000000000027, 40.0000000000003, 56.300000000000445, 30.400000000000162, 49.00000000000045, 49.40000000000047, -100.50000000000021, 84.39999999999898, 61.600000000000456, 23.50000000000005, 39.40000000000029, 8.100000000000131, 40.0000000000003, 2.0000000000001865, 57.100000000000485, 37.600000000000264, 27.70000000000011, 37.80000000000027, 50.7000000000005, 45.10000000000048, 61.60000000000051, 45.000000000000384, 34.50000000000022, 73.09999999999977, 40.0000000000003, 53.50000000000051, 60.30000000000042, 52.70000000000042, 33.7000000000002, 36.70000000000025, 15.69999999999992, 29.300000000000146, 49.30000000000045, 40.0000000000003, 79.59999999999938, 37.50000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-58.30000000000049, -1.6000000000000352, 40.70000000000025, 8.600000000000032, 20.000000000000014, -13.599999999999904, 58.40000000000014, 17.899999999999988, 20.000000000000014, 45.2000000000002, -108.40000000000026, -4.299999999999944, 20.000000000000014, 11.299999999999969, 16.399999999999967, 35.60000000000025, -8.799999999999978, 20.000000000000014, -58.00000000000023, 57.800000000000225, 20.000000000000014, -15.69999999999979, 20.000000000000014, 20.000000000000014, 51.50000000000017, 46.10000000000023, 2.8999999999999613, -19.299999999999855, 17.899999999999988, 9.499999999999988, 87.49999999999929, -53.80000000000059, -42.39999999999982, 20.000000000000014, 0.19999999999998833, -24.099999999999866, 7.399999999999965, -61.30000000000022, 18.499999999999993, 20.000000000000014, -13.899999999999796, 20.000000000000014, 20.000000000000014, 62.3000000000002, 1.0999999999999865, 20.000000000000014, 35.0000000000002, 20.000000000000014, 39.80000000000025, 25.400000000000098, 20.000000000000014, 28.100000000000147, -25.59999999999976, 3.1999999999999615, 20.000000000000014, -55.600000000000136, 3.4999999999999725, 41.30000000000022, 31.70000000000018, -19.899999999999807, 26.90000000000014, 20.000000000000014, 11.599999999999964, 29.900000000000187, 20.000000000000014, 20.000000000000014, 31.700000000000212, 17.899999999999988, 11.599999999999973, 20.000000000000014, -11.499999999999925, -28.299999999999763, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000025, 27.200000000000134, 20.000000000000014, 20.000000000000014, 1.9999999999999838, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 50.60000000000022, 10.999999999999966, 17.899999999999984, 12.499999999999972, 25.100000000000108, -9.399999999999883, 6.499999999999972, -11.199999999999898, -9.399999999999855, -1.6000000000000245, 20.000000000000014, 9.199999999999976, 32.600000000000236, 15.799999999999963, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 50.60000000000019, 12.799999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -32.79999999999977, -38.799999999999756, -6.399999999999965, -32.4999999999998, 33.5000000000002, 32.60000000000023, 20.000000000000014, -1.2999999999999994, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 36.80000000000022, 20.000000000000014, 20.000000000000014, 13.099999999999966, 20.000000000000014, 20.000000000000014, 19.70000000000001, 23.60000000000008, -0.7000000000000134, 10.099999999999966, 29.000000000000163, 20.000000000000014, 20.000000000000014, 4.399999999999979, 0.7999999999999954, -217.30000000000007, 28.70000000000017, 43.70000000000022, 41.60000000000022, 20.000000000000014, 22.700000000000053, -47.19999999999977, 16.399999999999967, 20.000000000000014, -21.999999999999744, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -4.899999999999956, -24.099999999999753, 20.000000000000014, 37.100000000000236, 13.699999999999966, 20.90000000000003, 20.000000000000014, -4.299999999999947, 15.799999999999963, 20.000000000000014, 21.20000000000003, 24.50000000000008, 37.40000000000024, -7.2999999999999545, 21.80000000000004, 39.80000000000025, 3.1999999999999615, 21.800000000000054, 13.09999999999997, 7.399999999999965, 20.000000000000014, 43.10000000000019, 20.000000000000014, 20.000000000000014, 30.800000000000196, 22.700000000000053, 15.799999999999963, 33.500000000000206, 17.899999999999984, 15.799999999999962, -4.299999999999972, 20.000000000000014, 13.699999999999967, 20.000000000000014, -24.099999999999774, 15.799999999999963, -9.399999999999887, 22.700000000000056, 25.400000000000098, 11.899999999999975, 20.000000000000014, 20.000000000000014, 45.20000000000023, 34.40000000000026, 12.799999999999972, 7.699999999999967], "policy_predator_policy_reward": [33.0, 29.0, 12.0, 2.0, 1.0, 34.0, 1.0, 11.0, 6.0, 0.0, 29.0, 73.0, 8.0, 0.0, 0.0, 8.0, 30.0, 8.0, 30.0, 23.0, 26.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 44.0, 7.0, 16.0, 10.0, 44.0, 8.0, 35.0, 21.0, 33.0, 48.0, 42.0, 16.0, 1.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 15.0, 16.0, 33.0, 32.0, 0.0, 19.0, 12.0, 25.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 27.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 0.0, 13.0, 17.0, 0.0, 41.0, 23.0, 9.0, 12.0, 7.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 18.0, 29.0, 15.0, 30.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 3.0, 10.0, 21.0, 0.0, 0.0, 0.0, 16.0, 9.0, 116.0, 0.0, 5.0, 7.0, 0.0, 0.0, 16.0, 32.0, 0.0, 3.0, 20.0, 9.0, 0.0, 0.0, 15.0, 16.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 2.0, 0.0, 1.0, 4.0, 13.0, 2.0, 0.0, 0.0, 8.0, 12.0, 6.0, 8.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 11.0, 8.0, 18.0, 0.0, 3.0, 0.0, 6.0, 18.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5923523880234219, "mean_inference_ms": 1.8427312213543496, "mean_action_processing_ms": 0.25071305524480714, "mean_env_wait_ms": 0.19524124875539264, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011572480201721191, "StateBufferConnector_ms": 0.005134224891662598, "ViewRequirementAgentConnector_ms": 0.1279832124710083}, "num_episodes": 23, "episode_return_max": 109.59999999999857, "episode_return_min": -100.50000000000021, "episode_return_mean": 42.6520000000002, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.6830428229895, "num_env_steps_trained_throughput_per_sec": 380.6830428229895, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 10355.016, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10354.97, "sample_time_ms": 1427.074, "learn_time_ms": 8912.073, "learn_throughput": 448.829, "synch_weights_time_ms": 14.192}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "0b081_00000", "date": "2024-08-13_00-58-51", "timestamp": 1723525131, "time_this_iter_s": 10.532957077026367, "time_total_s": 710.9226541519165, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d1a310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 710.9226541519165, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 32.32, "ram_util_percent": 83.30666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6317378846425858, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.417417220558439, "policy_loss": -0.004616571828555414, "vf_loss": 0.4217482141075562, "vf_explained_var": 0.0055171613655393085, "kl": 0.012034274122302574, "entropy": 1.0813594887496303, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.952904549091266, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6717541423057103, "policy_loss": -0.004261450212641013, "vf_loss": 0.675676264917409, "vf_explained_var": -0.005360944372005564, "kl": 0.020085600348294902, "entropy": 1.0322306175080558, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 84.39999999999898, "episode_reward_min": -100.50000000000021, "episode_reward_mean": 40.613000000000255, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -217.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.3000000000002, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 13.266500000000056, "predator_policy": 7.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.10000000000019, 55.500000000000426, 24.100000000000055, 82.29999999999914, 30.100000000000147, 71.99999999999986, 65.20000000000043, 48.100000000000435, 8.600000000000094, 29.400000000000148, 63.80000000000045, 48.80000000000039, 47.900000000000375, 45.500000000000405, 40.0000000000003, 50.60000000000048, 35.600000000000236, 28.20000000000016, 40.0000000000003, 40.0000000000003, 61.600000000000506, 47.20000000000042, 31.000000000000163, 40.0000000000003, 40.90000000000031, 67.60000000000021, 52.40000000000044, 45.700000000000415, 36.30000000000025, 21.000000000000004, 48.20000000000047, 50.40000000000047, 37.80000000000027, 40.0000000000003, 38.90000000000028, 76.39999999999954, 40.0000000000003, 50.80000000000048, -24.599999999999532, 6.100000000000046, 66.10000000000034, 32.70000000000019, 57.10000000000054, 40.0000000000003, 35.600000000000236, 60.800000000000466, 38.10000000000027, 40.0000000000003, 56.300000000000445, 30.400000000000162, 49.00000000000045, 49.40000000000047, -100.50000000000021, 84.39999999999898, 61.600000000000456, 23.50000000000005, 39.40000000000029, 8.100000000000131, 40.0000000000003, 2.0000000000001865, 57.100000000000485, 37.600000000000264, 27.70000000000011, 37.80000000000027, 50.7000000000005, 45.10000000000048, 61.60000000000051, 45.000000000000384, 34.50000000000022, 73.09999999999977, 40.0000000000003, 53.50000000000051, 60.30000000000042, 52.70000000000042, 33.7000000000002, 36.70000000000025, 15.69999999999992, 29.300000000000146, 49.30000000000045, 40.0000000000003, 79.59999999999938, 37.50000000000026, 47.00000000000041, 34.40000000000022, 45.4000000000004, 25.90000000000008, 39.800000000000296, 39.5000000000003, 39.00000000000029, 60.900000000000496, 58.00000000000051, 16.399999999999967, 24.400000000000055, 47.20000000000042, 32.30000000000016, 40.0000000000003, 53.50000000000048, 27.40000000000011, -18.799999999999564, 37.000000000000256], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, -61.30000000000022, 18.499999999999993, 20.000000000000014, -13.899999999999796, 20.000000000000014, 20.000000000000014, 62.3000000000002, 1.0999999999999865, 20.000000000000014, 35.0000000000002, 20.000000000000014, 39.80000000000025, 25.400000000000098, 20.000000000000014, 28.100000000000147, -25.59999999999976, 3.1999999999999615, 20.000000000000014, -55.600000000000136, 3.4999999999999725, 41.30000000000022, 31.70000000000018, -19.899999999999807, 26.90000000000014, 20.000000000000014, 11.599999999999964, 29.900000000000187, 20.000000000000014, 20.000000000000014, 31.700000000000212, 17.899999999999988, 11.599999999999973, 20.000000000000014, -11.499999999999925, -28.299999999999763, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000025, 27.200000000000134, 20.000000000000014, 20.000000000000014, 1.9999999999999838, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 50.60000000000022, 10.999999999999966, 17.899999999999984, 12.499999999999972, 25.100000000000108, -9.399999999999883, 6.499999999999972, -11.199999999999898, -9.399999999999855, -1.6000000000000245, 20.000000000000014, 9.199999999999976, 32.600000000000236, 15.799999999999963, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 50.60000000000019, 12.799999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -32.79999999999977, -38.799999999999756, -6.399999999999965, -32.4999999999998, 33.5000000000002, 32.60000000000023, 20.000000000000014, -1.2999999999999994, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 36.80000000000022, 20.000000000000014, 20.000000000000014, 13.099999999999966, 20.000000000000014, 20.000000000000014, 19.70000000000001, 23.60000000000008, -0.7000000000000134, 10.099999999999966, 29.000000000000163, 20.000000000000014, 20.000000000000014, 4.399999999999979, 0.7999999999999954, -217.30000000000007, 28.70000000000017, 43.70000000000022, 41.60000000000022, 20.000000000000014, 22.700000000000053, -47.19999999999977, 16.399999999999967, 20.000000000000014, -21.999999999999744, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -4.899999999999956, -24.099999999999753, 20.000000000000014, 37.100000000000236, 13.699999999999966, 20.90000000000003, 20.000000000000014, -4.299999999999947, 15.799999999999963, 20.000000000000014, 21.20000000000003, 24.50000000000008, 37.40000000000024, -7.2999999999999545, 21.80000000000004, 39.80000000000025, 3.1999999999999615, 21.800000000000054, 13.09999999999997, 7.399999999999965, 20.000000000000014, 43.10000000000019, 20.000000000000014, 20.000000000000014, 30.800000000000196, 22.700000000000053, 15.799999999999963, 33.500000000000206, 17.899999999999984, 15.799999999999962, -4.299999999999972, 20.000000000000014, 13.699999999999967, 20.000000000000014, -24.099999999999774, 15.799999999999963, -9.399999999999887, 22.700000000000056, 25.400000000000098, 11.899999999999975, 20.000000000000014, 20.000000000000014, 45.20000000000023, 34.40000000000026, 12.799999999999972, 7.699999999999967, 20.000000000000014, 26.00000000000011, 20.000000000000014, 4.399999999999968, 20.000000000000014, 25.400000000000112, 14.899999999999967, -3.9999999999999587, 9.79999999999997, 20.000000000000014, -3.699999999999987, 27.20000000000013, 21.800000000000047, 12.19999999999997, 19.400000000000006, 33.50000000000024, 20.000000000000014, 38.000000000000256, -6.399999999999926, -5.199999999999941, 25.400000000000098, -30.999999999999794, 18.199999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999981, 29.90000000000018, 1.0999999999999794, 20.000000000000014, 33.50000000000024, -10.59999999999985, 20.000000000000014, -72.40000000000069, -6.399999999999951, 10.999999999999966, 20.000000000000014], "policy_predator_policy_reward": [48.0, 42.0, 16.0, 1.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 15.0, 16.0, 33.0, 32.0, 0.0, 19.0, 12.0, 25.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 27.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 0.0, 13.0, 17.0, 0.0, 41.0, 23.0, 9.0, 12.0, 7.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 18.0, 29.0, 15.0, 30.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 3.0, 10.0, 21.0, 0.0, 0.0, 0.0, 16.0, 9.0, 116.0, 0.0, 5.0, 7.0, 0.0, 0.0, 16.0, 32.0, 0.0, 3.0, 20.0, 9.0, 0.0, 0.0, 15.0, 16.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 2.0, 0.0, 1.0, 4.0, 13.0, 2.0, 0.0, 0.0, 8.0, 12.0, 6.0, 8.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 11.0, 8.0, 18.0, 0.0, 3.0, 0.0, 6.0, 18.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 10.0, 0.0, 0.0, 0.0, 15.0, 0.0, 4.0, 6.0, 16.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 16.0, 12.0, 16.0, 14.0, 0.0, 9.0, 7.0, 0.0, 1.0, 8.0, 0.0, 0.0, 1.0, 17.0, 16.0, 44.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5924922772889759, "mean_inference_ms": 1.8429150742656932, "mean_action_processing_ms": 0.25062160424410446, "mean_env_wait_ms": 0.19522484410423224, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012204527854919434, "StateBufferConnector_ms": 0.005158066749572754, "ViewRequirementAgentConnector_ms": 0.13090813159942627}, "num_episodes": 18, "episode_return_max": 84.39999999999898, "episode_return_min": -100.50000000000021, "episode_return_mean": 40.613000000000255, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.7303630438727, "num_env_steps_trained_throughput_per_sec": 398.7303630438727, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 10235.375, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10235.331, "sample_time_ms": 1386.644, "learn_time_ms": 8833.406, "learn_throughput": 452.826, "synch_weights_time_ms": 13.862}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "0b081_00000", "date": "2024-08-13_00-59-01", "timestamp": 1723525141, "time_this_iter_s": 10.036588907241821, "time_total_s": 720.9592430591583, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbe550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 720.9592430591583, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 29.113333333333337, "ram_util_percent": 83.17999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5788723548844693, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15779990729280388, "policy_loss": -0.001402904347038616, "vf_loss": 0.1591212508593262, "vf_explained_var": 0.00041496085111426297, "kl": 0.003436982000298353, "entropy": 1.0884397599747573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8879403915413946, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.36733000234924945, "policy_loss": -0.0015689223725718284, "vf_loss": 0.3686992009687755, "vf_explained_var": 0.08738701832357537, "kl": 0.007881424048205165, "entropy": 1.0161996563591023, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 84.39999999999898, "episode_reward_min": -100.50000000000021, "episode_reward_mean": 40.71300000000027, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -217.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 50.60000000000022, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 14.571500000000055, "predator_policy": 5.785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, 61.600000000000506, 47.20000000000042, 31.000000000000163, 40.0000000000003, 40.90000000000031, 67.60000000000021, 52.40000000000044, 45.700000000000415, 36.30000000000025, 21.000000000000004, 48.20000000000047, 50.40000000000047, 37.80000000000027, 40.0000000000003, 38.90000000000028, 76.39999999999954, 40.0000000000003, 50.80000000000048, -24.599999999999532, 6.100000000000046, 66.10000000000034, 32.70000000000019, 57.10000000000054, 40.0000000000003, 35.600000000000236, 60.800000000000466, 38.10000000000027, 40.0000000000003, 56.300000000000445, 30.400000000000162, 49.00000000000045, 49.40000000000047, -100.50000000000021, 84.39999999999898, 61.600000000000456, 23.50000000000005, 39.40000000000029, 8.100000000000131, 40.0000000000003, 2.0000000000001865, 57.100000000000485, 37.600000000000264, 27.70000000000011, 37.80000000000027, 50.7000000000005, 45.10000000000048, 61.60000000000051, 45.000000000000384, 34.50000000000022, 73.09999999999977, 40.0000000000003, 53.50000000000051, 60.30000000000042, 52.70000000000042, 33.7000000000002, 36.70000000000025, 15.69999999999992, 29.300000000000146, 49.30000000000045, 40.0000000000003, 79.59999999999938, 37.50000000000026, 47.00000000000041, 34.40000000000022, 45.4000000000004, 25.90000000000008, 39.800000000000296, 39.5000000000003, 39.00000000000029, 60.900000000000496, 58.00000000000051, 16.399999999999967, 24.400000000000055, 47.20000000000042, 32.30000000000016, 40.0000000000003, 53.50000000000048, 27.40000000000011, -18.799999999999564, 37.000000000000256, 58.90000000000047, 45.3000000000004, 16.799999999999944, 40.400000000000304, 43.60000000000035, 39.000000000000284, 48.00000000000045, 68.80000000000018, 44.900000000000375, 37.500000000000256, 54.30000000000045, 29.000000000000128, 40.0000000000003, 61.80000000000048, 38.90000000000028, 47.60000000000043, 55.30000000000054, 51.70000000000049], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000025, 27.200000000000134, 20.000000000000014, 20.000000000000014, 1.9999999999999838, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 50.60000000000022, 10.999999999999966, 17.899999999999984, 12.499999999999972, 25.100000000000108, -9.399999999999883, 6.499999999999972, -11.199999999999898, -9.399999999999855, -1.6000000000000245, 20.000000000000014, 9.199999999999976, 32.600000000000236, 15.799999999999963, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 50.60000000000019, 12.799999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -32.79999999999977, -38.799999999999756, -6.399999999999965, -32.4999999999998, 33.5000000000002, 32.60000000000023, 20.000000000000014, -1.2999999999999994, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 36.80000000000022, 20.000000000000014, 20.000000000000014, 13.099999999999966, 20.000000000000014, 20.000000000000014, 19.70000000000001, 23.60000000000008, -0.7000000000000134, 10.099999999999966, 29.000000000000163, 20.000000000000014, 20.000000000000014, 4.399999999999979, 0.7999999999999954, -217.30000000000007, 28.70000000000017, 43.70000000000022, 41.60000000000022, 20.000000000000014, 22.700000000000053, -47.19999999999977, 16.399999999999967, 20.000000000000014, -21.999999999999744, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -4.899999999999956, -24.099999999999753, 20.000000000000014, 37.100000000000236, 13.699999999999966, 20.90000000000003, 20.000000000000014, -4.299999999999947, 15.799999999999963, 20.000000000000014, 21.20000000000003, 24.50000000000008, 37.40000000000024, -7.2999999999999545, 21.80000000000004, 39.80000000000025, 3.1999999999999615, 21.800000000000054, 13.09999999999997, 7.399999999999965, 20.000000000000014, 43.10000000000019, 20.000000000000014, 20.000000000000014, 30.800000000000196, 22.700000000000053, 15.799999999999963, 33.500000000000206, 17.899999999999984, 15.799999999999962, -4.299999999999972, 20.000000000000014, 13.699999999999967, 20.000000000000014, -24.099999999999774, 15.799999999999963, -9.399999999999887, 22.700000000000056, 25.400000000000098, 11.899999999999975, 20.000000000000014, 20.000000000000014, 45.20000000000023, 34.40000000000026, 12.799999999999972, 7.699999999999967, 20.000000000000014, 26.00000000000011, 20.000000000000014, 4.399999999999968, 20.000000000000014, 25.400000000000112, 14.899999999999967, -3.9999999999999587, 9.79999999999997, 20.000000000000014, -3.699999999999987, 27.20000000000013, 21.800000000000047, 12.19999999999997, 19.400000000000006, 33.50000000000024, 20.000000000000014, 38.000000000000256, -6.399999999999926, -5.199999999999941, 25.400000000000098, -30.999999999999794, 18.199999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999981, 29.90000000000018, 1.0999999999999794, 20.000000000000014, 33.50000000000024, -10.59999999999985, 20.000000000000014, -72.40000000000069, -6.399999999999951, 10.999999999999966, 20.000000000000014, 38.900000000000226, 20.000000000000014, 23.900000000000112, 16.399999999999967, -21.399999999999764, 6.199999999999976, 13.399999999999968, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 13.999999999999966, -7.899999999999924, 32.90000000000023, 29.90000000000018, 38.900000000000254, 32.60000000000023, 5.299999999999969, 22.100000000000044, 7.399999999999968, 29.90000000000018, 10.399999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 20.000000000000014, 12.799999999999972, 38.000000000000234, 20.000000000000014, 17.899999999999988, 16.099999999999962, 24.50000000000008, 29.90000000000018, 25.400000000000098, 20.000000000000014, 31.700000000000216], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 22.0, 0.0, 13.0, 17.0, 0.0, 41.0, 23.0, 9.0, 12.0, 7.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 18.0, 29.0, 15.0, 30.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 3.0, 10.0, 21.0, 0.0, 0.0, 0.0, 16.0, 9.0, 116.0, 0.0, 5.0, 7.0, 0.0, 0.0, 16.0, 32.0, 0.0, 3.0, 20.0, 9.0, 0.0, 0.0, 15.0, 16.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 2.0, 0.0, 1.0, 4.0, 13.0, 2.0, 0.0, 0.0, 8.0, 12.0, 6.0, 8.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 11.0, 8.0, 18.0, 0.0, 3.0, 0.0, 6.0, 18.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 10.0, 0.0, 0.0, 0.0, 15.0, 0.0, 4.0, 6.0, 16.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 16.0, 12.0, 16.0, 14.0, 0.0, 9.0, 7.0, 0.0, 1.0, 8.0, 0.0, 0.0, 1.0, 17.0, 16.0, 44.0, 0.0, 6.0, 0.0, 0.0, 3.0, 2.0, 8.0, 24.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 10.0, 0.0, 0.0, 9.0, 2.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5926665804662399, "mean_inference_ms": 1.8433221512600637, "mean_action_processing_ms": 0.2505713872589596, "mean_env_wait_ms": 0.1952279765974876, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012789011001586914, "StateBufferConnector_ms": 0.005228161811828613, "ViewRequirementAgentConnector_ms": 0.13226449489593506}, "num_episodes": 18, "episode_return_max": 84.39999999999898, "episode_return_min": -100.50000000000021, "episode_return_mean": 40.71300000000027, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 400.52345021837164, "num_env_steps_trained_throughput_per_sec": 400.52345021837164, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 10148.331, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10148.288, "sample_time_ms": 1378.574, "learn_time_ms": 8754.425, "learn_throughput": 456.912, "synch_weights_time_ms": 13.947}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "0b081_00000", "date": "2024-08-13_00-59-11", "timestamp": 1723525151, "time_this_iter_s": 9.999836921691895, "time_total_s": 730.9590799808502, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbed30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 730.9590799808502, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 29.67142857142857, "ram_util_percent": 83.20714285714284}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6040153909573164, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1828217203083335, "policy_loss": -0.002671772749877717, "vf_loss": 0.1853363591768328, "vf_explained_var": -0.03356339300751055, "kl": 0.013243236367251575, "entropy": 1.0698409733633516, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7517905090102759, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.27938682490808237, "policy_loss": -0.0026581562004697624, "vf_loss": 0.2816479434163147, "vf_explained_var": -0.10086908517060457, "kl": 0.015667684466217455, "entropy": 0.9318965019057037, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 84.39999999999898, "episode_reward_min": -100.50000000000021, "episode_reward_mean": 40.43500000000028, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -217.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.20000000000023, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 15.14750000000005, "predator_policy": 5.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.10000000000034, 32.70000000000019, 57.10000000000054, 40.0000000000003, 35.600000000000236, 60.800000000000466, 38.10000000000027, 40.0000000000003, 56.300000000000445, 30.400000000000162, 49.00000000000045, 49.40000000000047, -100.50000000000021, 84.39999999999898, 61.600000000000456, 23.50000000000005, 39.40000000000029, 8.100000000000131, 40.0000000000003, 2.0000000000001865, 57.100000000000485, 37.600000000000264, 27.70000000000011, 37.80000000000027, 50.7000000000005, 45.10000000000048, 61.60000000000051, 45.000000000000384, 34.50000000000022, 73.09999999999977, 40.0000000000003, 53.50000000000051, 60.30000000000042, 52.70000000000042, 33.7000000000002, 36.70000000000025, 15.69999999999992, 29.300000000000146, 49.30000000000045, 40.0000000000003, 79.59999999999938, 37.50000000000026, 47.00000000000041, 34.40000000000022, 45.4000000000004, 25.90000000000008, 39.800000000000296, 39.5000000000003, 39.00000000000029, 60.900000000000496, 58.00000000000051, 16.399999999999967, 24.400000000000055, 47.20000000000042, 32.30000000000016, 40.0000000000003, 53.50000000000048, 27.40000000000011, -18.799999999999564, 37.000000000000256, 58.90000000000047, 45.3000000000004, 16.799999999999944, 40.400000000000304, 43.60000000000035, 39.000000000000284, 48.00000000000045, 68.80000000000018, 44.900000000000375, 37.500000000000256, 54.30000000000045, 29.000000000000128, 40.0000000000003, 61.80000000000048, 38.90000000000028, 47.60000000000043, 55.30000000000054, 51.70000000000049, 46.600000000000406, 36.90000000000025, 29.800000000000146, 16.100000000000005, 40.0000000000003, 34.50000000000022, 58.9000000000005, 35.10000000000023, 40.0000000000003, 46.3000000000004, 41.30000000000032, 35.10000000000022, 40.0000000000003, 33.400000000000205, 41.800000000000324, 40.0000000000003, 39.000000000000284, 34.00000000000021, 50.80000000000045, 36.70000000000025, 40.0000000000003, 43.60000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [33.5000000000002, 32.60000000000023, 20.000000000000014, -1.2999999999999994, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 36.80000000000022, 20.000000000000014, 20.000000000000014, 13.099999999999966, 20.000000000000014, 20.000000000000014, 19.70000000000001, 23.60000000000008, -0.7000000000000134, 10.099999999999966, 29.000000000000163, 20.000000000000014, 20.000000000000014, 4.399999999999979, 0.7999999999999954, -217.30000000000007, 28.70000000000017, 43.70000000000022, 41.60000000000022, 20.000000000000014, 22.700000000000053, -47.19999999999977, 16.399999999999967, 20.000000000000014, -21.999999999999744, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -4.899999999999956, -24.099999999999753, 20.000000000000014, 37.100000000000236, 13.699999999999966, 20.90000000000003, 20.000000000000014, -4.299999999999947, 15.799999999999963, 20.000000000000014, 21.20000000000003, 24.50000000000008, 37.40000000000024, -7.2999999999999545, 21.80000000000004, 39.80000000000025, 3.1999999999999615, 21.800000000000054, 13.09999999999997, 7.399999999999965, 20.000000000000014, 43.10000000000019, 20.000000000000014, 20.000000000000014, 30.800000000000196, 22.700000000000053, 15.799999999999963, 33.500000000000206, 17.899999999999984, 15.799999999999962, -4.299999999999972, 20.000000000000014, 13.699999999999967, 20.000000000000014, -24.099999999999774, 15.799999999999963, -9.399999999999887, 22.700000000000056, 25.400000000000098, 11.899999999999975, 20.000000000000014, 20.000000000000014, 45.20000000000023, 34.40000000000026, 12.799999999999972, 7.699999999999967, 20.000000000000014, 26.00000000000011, 20.000000000000014, 4.399999999999968, 20.000000000000014, 25.400000000000112, 14.899999999999967, -3.9999999999999587, 9.79999999999997, 20.000000000000014, -3.699999999999987, 27.20000000000013, 21.800000000000047, 12.19999999999997, 19.400000000000006, 33.50000000000024, 20.000000000000014, 38.000000000000256, -6.399999999999926, -5.199999999999941, 25.400000000000098, -30.999999999999794, 18.199999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999981, 29.90000000000018, 1.0999999999999794, 20.000000000000014, 33.50000000000024, -10.59999999999985, 20.000000000000014, -72.40000000000069, -6.399999999999951, 10.999999999999966, 20.000000000000014, 38.900000000000226, 20.000000000000014, 23.900000000000112, 16.399999999999967, -21.399999999999764, 6.199999999999976, 13.399999999999968, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 13.999999999999966, -7.899999999999924, 32.90000000000023, 29.90000000000018, 38.900000000000254, 32.60000000000023, 5.299999999999969, 22.100000000000044, 7.399999999999968, 29.90000000000018, 10.399999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 20.000000000000014, 12.799999999999972, 38.000000000000234, 20.000000000000014, 17.899999999999988, 16.099999999999962, 24.50000000000008, 29.90000000000018, 25.400000000000098, 20.000000000000014, 31.700000000000216, 14.599999999999968, 20.000000000000014, 5.899999999999972, 20.000000000000014, 16.69999999999997, -1.8999999999999888, 9.499999999999964, -6.399999999999908, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 38.90000000000025, 20.000000000000014, 4.099999999999971, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.000000000000163, 5.299999999999967, 21.500000000000036, -6.399999999999936, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, 20.000000000000014, 1.9999999999999607, 20.000000000000014, 20.000000000000014, 30.800000000000207, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 3.0, 10.0, 21.0, 0.0, 0.0, 0.0, 16.0, 9.0, 116.0, 0.0, 5.0, 7.0, 0.0, 0.0, 16.0, 32.0, 0.0, 3.0, 20.0, 9.0, 0.0, 0.0, 15.0, 16.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 2.0, 0.0, 1.0, 4.0, 13.0, 2.0, 0.0, 0.0, 8.0, 12.0, 6.0, 8.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 11.0, 8.0, 18.0, 0.0, 3.0, 0.0, 6.0, 18.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 10.0, 0.0, 0.0, 0.0, 15.0, 0.0, 4.0, 6.0, 16.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 16.0, 12.0, 16.0, 14.0, 0.0, 9.0, 7.0, 0.0, 1.0, 8.0, 0.0, 0.0, 1.0, 17.0, 16.0, 44.0, 0.0, 6.0, 0.0, 0.0, 3.0, 2.0, 8.0, 24.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 10.0, 0.0, 0.0, 9.0, 2.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 0.0, 11.0, 13.0, 2.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 19.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5928988571957131, "mean_inference_ms": 1.8436678220632154, "mean_action_processing_ms": 0.2505122462622806, "mean_env_wait_ms": 0.19523003936882544, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012883663177490234, "StateBufferConnector_ms": 0.005284905433654785, "ViewRequirementAgentConnector_ms": 0.1315537691116333}, "num_episodes": 22, "episode_return_max": 84.39999999999898, "episode_return_min": -100.50000000000021, "episode_return_mean": 40.43500000000028, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.23963534777675, "num_env_steps_trained_throughput_per_sec": 388.23963534777675, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 10124.248, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10124.206, "sample_time_ms": 1363.414, "learn_time_ms": 8745.404, "learn_throughput": 457.383, "synch_weights_time_ms": 14.345}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "0b081_00000", "date": "2024-08-13_00-59-21", "timestamp": 1723525161, "time_this_iter_s": 10.329461812973022, "time_total_s": 741.2885417938232, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d579d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 741.2885417938232, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 31.686666666666664, "ram_util_percent": 83.46000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8100993268112973, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2782884796184522, "policy_loss": -0.0024769538427116696, "vf_loss": 0.28067100985661253, "vf_explained_var": 0.004946982860565186, "kl": 0.007957987947024032, "entropy": 1.015340598171981, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9278245400184046, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4828287330176435, "policy_loss": -0.0033379000076955117, "vf_loss": 0.4859188655855765, "vf_explained_var": 0.020683363758066974, "kl": 0.009777273979681542, "entropy": 0.8745396356103281, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 79.59999999999938, "episode_reward_min": -18.799999999999564, "episode_reward_mean": 41.47000000000029, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -72.40000000000069, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.20000000000023, "predator_policy": 44.0}, "policy_reward_mean": {"prey_policy": 16.550000000000047, "predator_policy": 4.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 50.7000000000005, 45.10000000000048, 61.60000000000051, 45.000000000000384, 34.50000000000022, 73.09999999999977, 40.0000000000003, 53.50000000000051, 60.30000000000042, 52.70000000000042, 33.7000000000002, 36.70000000000025, 15.69999999999992, 29.300000000000146, 49.30000000000045, 40.0000000000003, 79.59999999999938, 37.50000000000026, 47.00000000000041, 34.40000000000022, 45.4000000000004, 25.90000000000008, 39.800000000000296, 39.5000000000003, 39.00000000000029, 60.900000000000496, 58.00000000000051, 16.399999999999967, 24.400000000000055, 47.20000000000042, 32.30000000000016, 40.0000000000003, 53.50000000000048, 27.40000000000011, -18.799999999999564, 37.000000000000256, 58.90000000000047, 45.3000000000004, 16.799999999999944, 40.400000000000304, 43.60000000000035, 39.000000000000284, 48.00000000000045, 68.80000000000018, 44.900000000000375, 37.500000000000256, 54.30000000000045, 29.000000000000128, 40.0000000000003, 61.80000000000048, 38.90000000000028, 47.60000000000043, 55.30000000000054, 51.70000000000049, 46.600000000000406, 36.90000000000025, 29.800000000000146, 16.100000000000005, 40.0000000000003, 34.50000000000022, 58.9000000000005, 35.10000000000023, 40.0000000000003, 46.3000000000004, 41.30000000000032, 35.10000000000022, 40.0000000000003, 33.400000000000205, 41.800000000000324, 40.0000000000003, 39.000000000000284, 34.00000000000021, 50.80000000000045, 36.70000000000025, 40.0000000000003, 43.60000000000036, 38.90000000000028, 27.900000000000105, 58.00000000000052, 4.800000000000157, 46.300000000000395, 49.90000000000046, 45.800000000000395, 33.400000000000205, 33.400000000000205, 64.30000000000048, 57.300000000000516, 36.00000000000024, 44.50000000000036, 42.00000000000033, 40.0000000000003, 62.50000000000052, 30.20000000000015, 27.90000000000011, 35.600000000000236, 56.00000000000051, 39.00000000000028, 20.900000000000002, 45.300000000000395], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, 20.000000000000014, 21.20000000000003, 24.50000000000008, 37.40000000000024, -7.2999999999999545, 21.80000000000004, 39.80000000000025, 3.1999999999999615, 21.800000000000054, 13.09999999999997, 7.399999999999965, 20.000000000000014, 43.10000000000019, 20.000000000000014, 20.000000000000014, 30.800000000000196, 22.700000000000053, 15.799999999999963, 33.500000000000206, 17.899999999999984, 15.799999999999962, -4.299999999999972, 20.000000000000014, 13.699999999999967, 20.000000000000014, -24.099999999999774, 15.799999999999963, -9.399999999999887, 22.700000000000056, 25.400000000000098, 11.899999999999975, 20.000000000000014, 20.000000000000014, 45.20000000000023, 34.40000000000026, 12.799999999999972, 7.699999999999967, 20.000000000000014, 26.00000000000011, 20.000000000000014, 4.399999999999968, 20.000000000000014, 25.400000000000112, 14.899999999999967, -3.9999999999999587, 9.79999999999997, 20.000000000000014, -3.699999999999987, 27.20000000000013, 21.800000000000047, 12.19999999999997, 19.400000000000006, 33.50000000000024, 20.000000000000014, 38.000000000000256, -6.399999999999926, -5.199999999999941, 25.400000000000098, -30.999999999999794, 18.199999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999981, 29.90000000000018, 1.0999999999999794, 20.000000000000014, 33.50000000000024, -10.59999999999985, 20.000000000000014, -72.40000000000069, -6.399999999999951, 10.999999999999966, 20.000000000000014, 38.900000000000226, 20.000000000000014, 23.900000000000112, 16.399999999999967, -21.399999999999764, 6.199999999999976, 13.399999999999968, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 13.999999999999966, -7.899999999999924, 32.90000000000023, 29.90000000000018, 38.900000000000254, 32.60000000000023, 5.299999999999969, 22.100000000000044, 7.399999999999968, 29.90000000000018, 10.399999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 20.000000000000014, 12.799999999999972, 38.000000000000234, 20.000000000000014, 17.899999999999988, 16.099999999999962, 24.50000000000008, 29.90000000000018, 25.400000000000098, 20.000000000000014, 31.700000000000216, 14.599999999999968, 20.000000000000014, 5.899999999999972, 20.000000000000014, 16.69999999999997, -1.8999999999999888, 9.499999999999964, -6.399999999999908, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 38.90000000000025, 20.000000000000014, 4.099999999999971, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.000000000000163, 5.299999999999967, 21.500000000000036, -6.399999999999936, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, 20.000000000000014, 1.9999999999999607, 20.000000000000014, 20.000000000000014, 30.800000000000207, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 13.699999999999964, 38.000000000000256, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.90000000000018, 17.59999999999998, 21.20000000000003, 7.399999999999965, 20.000000000000018, 20.000000000000014, 7.399999999999965, 40.700000000000244, 23.60000000000007, 14.899999999999965, 34.40000000000026, 4.99999999999997, 20.000000000000014, 20.000000000000014, 24.50000000000008, 13.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.400000000000254, 28.100000000000147, 0.7999999999999865, 19.40000000000001, -3.099999999999958, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 35.000000000000256, -0.6999999999999993, 25.700000000000106, 23.60000000000007, -30.699999999999783, 20.000000000000014, 20.30000000000002], "policy_predator_policy_reward": [2.0, 0.0, 1.0, 4.0, 13.0, 2.0, 0.0, 0.0, 8.0, 12.0, 6.0, 8.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 11.0, 8.0, 18.0, 0.0, 3.0, 0.0, 6.0, 18.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 10.0, 0.0, 0.0, 0.0, 15.0, 0.0, 4.0, 6.0, 16.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 16.0, 12.0, 16.0, 14.0, 0.0, 9.0, 7.0, 0.0, 1.0, 8.0, 0.0, 0.0, 1.0, 17.0, 16.0, 44.0, 0.0, 6.0, 0.0, 0.0, 3.0, 2.0, 8.0, 24.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 10.0, 0.0, 0.0, 9.0, 2.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 0.0, 11.0, 13.0, 2.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 19.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 3.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 11.0, 0.0, 4.0, 0.0, 1.0, 14.0, 0.0, 20.0, 8.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5936286353924474, "mean_inference_ms": 1.8413127882752505, "mean_action_processing_ms": 0.25028178910812166, "mean_env_wait_ms": 0.1952820055986509, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012983560562133789, "StateBufferConnector_ms": 0.005379319190979004, "ViewRequirementAgentConnector_ms": 0.1329789161682129}, "num_episodes": 23, "episode_return_max": 79.59999999999938, "episode_return_min": -18.799999999999564, "episode_return_mean": 41.47000000000029, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 403.5395667291118, "num_env_steps_trained_throughput_per_sec": 403.5395667291118, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 10068.935, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10068.892, "sample_time_ms": 1355.31, "learn_time_ms": 8698.405, "learn_throughput": 459.854, "synch_weights_time_ms": 14.191}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "0b081_00000", "date": "2024-08-13_00-59-31", "timestamp": 1723525171, "time_this_iter_s": 9.916670083999634, "time_total_s": 751.2052118778229, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dca9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 751.2052118778229, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 30.199999999999996, "ram_util_percent": 83.33571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5749326113177828, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.27600350775337096, "policy_loss": -0.003330096221657066, "vf_loss": 0.279129416433381, "vf_explained_var": -0.006412129427390124, "kl": 0.01720882723906646, "entropy": 0.9774096208590048, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7617487064587376, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.38153562361218046, "policy_loss": -0.0027199042314249608, "vf_loss": 0.3838551120738937, "vf_explained_var": 0.013723360072998774, "kl": 0.01580100224648552, "entropy": 0.7848931934467699, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 68.80000000000018, "episode_reward_min": -18.799999999999564, "episode_reward_mean": 40.207000000000306, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -72.40000000000086, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.700000000000244, "predator_policy": 44.0}, "policy_reward_mean": {"prey_policy": 15.91850000000004, "predator_policy": 4.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.50000000000026, 47.00000000000041, 34.40000000000022, 45.4000000000004, 25.90000000000008, 39.800000000000296, 39.5000000000003, 39.00000000000029, 60.900000000000496, 58.00000000000051, 16.399999999999967, 24.400000000000055, 47.20000000000042, 32.30000000000016, 40.0000000000003, 53.50000000000048, 27.40000000000011, -18.799999999999564, 37.000000000000256, 58.90000000000047, 45.3000000000004, 16.799999999999944, 40.400000000000304, 43.60000000000035, 39.000000000000284, 48.00000000000045, 68.80000000000018, 44.900000000000375, 37.500000000000256, 54.30000000000045, 29.000000000000128, 40.0000000000003, 61.80000000000048, 38.90000000000028, 47.60000000000043, 55.30000000000054, 51.70000000000049, 46.600000000000406, 36.90000000000025, 29.800000000000146, 16.100000000000005, 40.0000000000003, 34.50000000000022, 58.9000000000005, 35.10000000000023, 40.0000000000003, 46.3000000000004, 41.30000000000032, 35.10000000000022, 40.0000000000003, 33.400000000000205, 41.800000000000324, 40.0000000000003, 39.000000000000284, 34.00000000000021, 50.80000000000045, 36.70000000000025, 40.0000000000003, 43.60000000000036, 38.90000000000028, 27.900000000000105, 58.00000000000052, 4.800000000000157, 46.300000000000395, 49.90000000000046, 45.800000000000395, 33.400000000000205, 33.400000000000205, 64.30000000000048, 57.300000000000516, 36.00000000000024, 44.50000000000036, 42.00000000000033, 40.0000000000003, 62.50000000000052, 30.20000000000015, 27.90000000000011, 35.600000000000236, 56.00000000000051, 39.00000000000028, 20.900000000000002, 45.300000000000395, 32.50000000000019, 32.40000000000019, 51.900000000000446, 40.0000000000003, 53.60000000000052, 35.600000000000236, 43.60000000000036, 34.70000000000022, 57.10000000000049, 6.900000000000068, 36.60000000000025, 27.10000000000011, 49.800000000000466, 53.500000000000504, 33.4000000000002, 40.0000000000003, 40.0000000000003, 43.60000000000035], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [12.799999999999972, 7.699999999999967, 20.000000000000014, 26.00000000000011, 20.000000000000014, 4.399999999999968, 20.000000000000014, 25.400000000000112, 14.899999999999967, -3.9999999999999587, 9.79999999999997, 20.000000000000014, -3.699999999999987, 27.20000000000013, 21.800000000000047, 12.19999999999997, 19.400000000000006, 33.50000000000024, 20.000000000000014, 38.000000000000256, -6.399999999999926, -5.199999999999941, 25.400000000000098, -30.999999999999794, 18.199999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999981, 29.90000000000018, 1.0999999999999794, 20.000000000000014, 33.50000000000024, -10.59999999999985, 20.000000000000014, -72.40000000000069, -6.399999999999951, 10.999999999999966, 20.000000000000014, 38.900000000000226, 20.000000000000014, 23.900000000000112, 16.399999999999967, -21.399999999999764, 6.199999999999976, 13.399999999999968, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 13.999999999999966, -7.899999999999924, 32.90000000000023, 29.90000000000018, 38.900000000000254, 32.60000000000023, 5.299999999999969, 22.100000000000044, 7.399999999999968, 29.90000000000018, 10.399999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 20.000000000000014, 12.799999999999972, 38.000000000000234, 20.000000000000014, 17.899999999999988, 16.099999999999962, 24.50000000000008, 29.90000000000018, 25.400000000000098, 20.000000000000014, 31.700000000000216, 14.599999999999968, 20.000000000000014, 5.899999999999972, 20.000000000000014, 16.69999999999997, -1.8999999999999888, 9.499999999999964, -6.399999999999908, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 38.90000000000025, 20.000000000000014, 4.099999999999971, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.000000000000163, 5.299999999999967, 21.500000000000036, -6.399999999999936, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, 20.000000000000014, 1.9999999999999607, 20.000000000000014, 20.000000000000014, 30.800000000000207, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 13.699999999999964, 38.000000000000256, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.90000000000018, 17.59999999999998, 21.20000000000003, 7.399999999999965, 20.000000000000018, 20.000000000000014, 7.399999999999965, 40.700000000000244, 23.60000000000007, 14.899999999999965, 34.40000000000026, 4.99999999999997, 20.000000000000014, 20.000000000000014, 24.50000000000008, 13.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.400000000000254, 28.100000000000147, 0.7999999999999865, 19.40000000000001, -3.099999999999958, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 35.000000000000256, -0.6999999999999993, 25.700000000000106, 23.60000000000007, -30.699999999999783, 20.000000000000014, 20.30000000000002, -10.599999999999836, 28.100000000000147, 9.499999999999975, 11.899999999999967, 20.000000000000014, 23.900000000000084, 20.000000000000014, 20.000000000000014, 33.20000000000024, 13.399999999999968, 11.599999999999964, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, -4.299999999999969, 37.10000000000024, 20.000000000000014, -72.40000000000086, 26.300000000000114, 8.299999999999965, 20.30000000000002, 18.19999999999999, -15.09999999999977, 9.499999999999964, 35.30000000000026, 33.50000000000025, 20.000000000000014, 20.000000000000014, -1.6000000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014], "policy_predator_policy_reward": [0.0, 17.0, 1.0, 0.0, 10.0, 0.0, 0.0, 0.0, 15.0, 0.0, 4.0, 6.0, 16.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 16.0, 12.0, 16.0, 14.0, 0.0, 9.0, 7.0, 0.0, 1.0, 8.0, 0.0, 0.0, 1.0, 17.0, 16.0, 44.0, 0.0, 6.0, 0.0, 0.0, 3.0, 2.0, 8.0, 24.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 10.0, 0.0, 0.0, 9.0, 2.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 0.0, 11.0, 13.0, 2.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 19.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 3.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 11.0, 0.0, 4.0, 0.0, 1.0, 14.0, 0.0, 20.0, 8.0, 5.0, 0.0, 13.0, 2.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 0.0, 0.0, 15.0, 4.0, 0.0, 0.0, 37.0, 16.0, 0.0, 8.0, 18.0, 6.0, 0.0, 5.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5927297148708743, "mean_inference_ms": 1.8441072970243853, "mean_action_processing_ms": 0.25029647708071096, "mean_env_wait_ms": 0.19513813245745878, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005687355995178223, "StateBufferConnector_ms": 0.003220796585083008, "ViewRequirementAgentConnector_ms": 0.09602475166320801}, "num_episodes": 18, "episode_return_max": 68.80000000000018, "episode_return_min": -18.799999999999564, "episode_return_mean": 40.207000000000306, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.3884259285303, "num_env_steps_trained_throughput_per_sec": 388.3884259285303, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 10095.053, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10095.011, "sample_time_ms": 1349.682, "learn_time_ms": 8730.293, "learn_throughput": 458.175, "synch_weights_time_ms": 13.864}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "0b081_00000", "date": "2024-08-13_00-59-41", "timestamp": 1723525181, "time_this_iter_s": 10.34567904472351, "time_total_s": 761.5508909225464, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d1a430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 761.5508909225464, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 32.300000000000004, "ram_util_percent": 83.21999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6970774292610783, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06628002614148143, "policy_loss": -0.003121417612280874, "vf_loss": 0.06926726677138408, "vf_explained_var": -0.08070707914059755, "kl": 0.011308423074712432, "entropy": 1.0225609405015512, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7417791050972131, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2215940444995044, "policy_loss": -0.0008873498238803001, "vf_loss": 0.22237908604700196, "vf_explained_var": 0.19435922471934525, "kl": 0.004037240978929097, "entropy": 0.7282641075590931, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 68.80000000000018, "episode_reward_min": 4.800000000000157, "episode_reward_mean": 41.58100000000032, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -72.40000000000086, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 37.0}, "policy_reward_mean": {"prey_policy": 17.535500000000045, "predator_policy": 3.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.000000000000256, 58.90000000000047, 45.3000000000004, 16.799999999999944, 40.400000000000304, 43.60000000000035, 39.000000000000284, 48.00000000000045, 68.80000000000018, 44.900000000000375, 37.500000000000256, 54.30000000000045, 29.000000000000128, 40.0000000000003, 61.80000000000048, 38.90000000000028, 47.60000000000043, 55.30000000000054, 51.70000000000049, 46.600000000000406, 36.90000000000025, 29.800000000000146, 16.100000000000005, 40.0000000000003, 34.50000000000022, 58.9000000000005, 35.10000000000023, 40.0000000000003, 46.3000000000004, 41.30000000000032, 35.10000000000022, 40.0000000000003, 33.400000000000205, 41.800000000000324, 40.0000000000003, 39.000000000000284, 34.00000000000021, 50.80000000000045, 36.70000000000025, 40.0000000000003, 43.60000000000036, 38.90000000000028, 27.900000000000105, 58.00000000000052, 4.800000000000157, 46.300000000000395, 49.90000000000046, 45.800000000000395, 33.400000000000205, 33.400000000000205, 64.30000000000048, 57.300000000000516, 36.00000000000024, 44.50000000000036, 42.00000000000033, 40.0000000000003, 62.50000000000052, 30.20000000000015, 27.90000000000011, 35.600000000000236, 56.00000000000051, 39.00000000000028, 20.900000000000002, 45.300000000000395, 32.50000000000019, 32.40000000000019, 51.900000000000446, 40.0000000000003, 53.60000000000052, 35.600000000000236, 43.60000000000036, 34.70000000000022, 57.10000000000049, 6.900000000000068, 36.60000000000025, 27.10000000000011, 49.800000000000466, 53.500000000000504, 33.4000000000002, 40.0000000000003, 40.0000000000003, 43.60000000000035, 36.300000000000246, 53.50000000000052, 41.800000000000324, 51.50000000000051, 31.100000000000165, 42.70000000000034, 40.0000000000003, 60.700000000000514, 35.600000000000236, 53.50000000000052, 40.90000000000031, 42.10000000000033, 40.0000000000003, 51.5000000000005, 53.5000000000005, 35.70000000000024, 23.300000000000054, 53.50000000000051], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [10.999999999999966, 20.000000000000014, 38.900000000000226, 20.000000000000014, 23.900000000000112, 16.399999999999967, -21.399999999999764, 6.199999999999976, 13.399999999999968, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 13.999999999999966, -7.899999999999924, 32.90000000000023, 29.90000000000018, 38.900000000000254, 32.60000000000023, 5.299999999999969, 22.100000000000044, 7.399999999999968, 29.90000000000018, 10.399999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 20.000000000000014, 12.799999999999972, 38.000000000000234, 20.000000000000014, 17.899999999999988, 16.099999999999962, 24.50000000000008, 29.90000000000018, 25.400000000000098, 20.000000000000014, 31.700000000000216, 14.599999999999968, 20.000000000000014, 5.899999999999972, 20.000000000000014, 16.69999999999997, -1.8999999999999888, 9.499999999999964, -6.399999999999908, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 38.90000000000025, 20.000000000000014, 4.099999999999971, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.000000000000163, 5.299999999999967, 21.500000000000036, -6.399999999999936, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, 20.000000000000014, 1.9999999999999607, 20.000000000000014, 20.000000000000014, 30.800000000000207, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 13.699999999999964, 38.000000000000256, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.90000000000018, 17.59999999999998, 21.20000000000003, 7.399999999999965, 20.000000000000018, 20.000000000000014, 7.399999999999965, 40.700000000000244, 23.60000000000007, 14.899999999999965, 34.40000000000026, 4.99999999999997, 20.000000000000014, 20.000000000000014, 24.50000000000008, 13.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.400000000000254, 28.100000000000147, 0.7999999999999865, 19.40000000000001, -3.099999999999958, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 35.000000000000256, -0.6999999999999993, 25.700000000000106, 23.60000000000007, -30.699999999999783, 20.000000000000014, 20.30000000000002, -10.599999999999836, 28.100000000000147, 9.499999999999975, 11.899999999999967, 20.000000000000014, 23.900000000000084, 20.000000000000014, 20.000000000000014, 33.20000000000024, 13.399999999999968, 11.599999999999964, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, -4.299999999999969, 37.10000000000024, 20.000000000000014, -72.40000000000086, 26.300000000000114, 8.299999999999965, 20.30000000000002, 18.19999999999999, -15.09999999999977, 9.499999999999964, 35.30000000000026, 33.50000000000025, 20.000000000000014, 20.000000000000014, -1.6000000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 11.299999999999965, 20.000000000000014, 33.50000000000024, 20.000000000000014, 21.80000000000004, 20.000000000000014, 30.50000000000022, 8.299999999999967, 15.799999999999963, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 15.799999999999962, 15.799999999999963, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.900000000000027, 25.400000000000098, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 20.000000000000014, 20.000000000000014, 33.50000000000025, 20.000000000000014, 7.699999999999967, -11.499999999999819, 6.799999999999976, 20.000000000000014, 33.50000000000024], "policy_predator_policy_reward": [0.0, 6.0, 0.0, 0.0, 3.0, 2.0, 8.0, 24.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 10.0, 0.0, 0.0, 9.0, 2.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 0.0, 11.0, 13.0, 2.0, 0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 19.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 3.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 11.0, 0.0, 4.0, 0.0, 1.0, 14.0, 0.0, 20.0, 8.0, 5.0, 0.0, 13.0, 2.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 0.0, 0.0, 15.0, 4.0, 0.0, 0.0, 37.0, 16.0, 0.0, 8.0, 18.0, 6.0, 0.0, 5.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 13.0, 15.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5922869468893364, "mean_inference_ms": 1.8437222167985101, "mean_action_processing_ms": 0.25009922325594686, "mean_env_wait_ms": 0.19497196489091806, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005099654197692871, "StateBufferConnector_ms": 0.0032095909118652344, "ViewRequirementAgentConnector_ms": 0.09422731399536133}, "num_episodes": 18, "episode_return_max": 68.80000000000018, "episode_return_min": 4.800000000000157, "episode_return_mean": 41.58100000000032, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 415.84994239225125, "num_env_steps_trained_throughput_per_sec": 415.84994239225125, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 10079.541, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10079.498, "sample_time_ms": 1354.585, "learn_time_ms": 8709.562, "learn_throughput": 459.265, "synch_weights_time_ms": 14.157}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "0b081_00000", "date": "2024-08-13_00-59-51", "timestamp": 1723525191, "time_this_iter_s": 9.624486207962036, "time_total_s": 771.1753771305084, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f21430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 771.1753771305084, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 30.092307692307692, "ram_util_percent": 83.44615384615386}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6096133744787602, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.37381269168995673, "policy_loss": -0.0049918670544804875, "vf_loss": 0.37858012334023855, "vf_explained_var": -0.007112700314748855, "kl": 0.018915456207013636, "entropy": 1.0145682046653102, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7209051648401237, "cur_kl_coeff": 0.012670540809631344, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5662326053962624, "policy_loss": -0.004458326253074187, "vf_loss": 0.5705893437663911, "vf_explained_var": -0.002956910171206035, "kl": 0.008017611306871732, "entropy": 0.7249287688227558, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 64.30000000000048, "episode_reward_min": -85.10000000000079, "episode_reward_mean": 39.43100000000031, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.4999999999988, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 296.0}, "policy_reward_mean": {"prey_policy": 15.395500000000043, "predator_policy": 4.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.100000000000005, 40.0000000000003, 34.50000000000022, 58.9000000000005, 35.10000000000023, 40.0000000000003, 46.3000000000004, 41.30000000000032, 35.10000000000022, 40.0000000000003, 33.400000000000205, 41.800000000000324, 40.0000000000003, 39.000000000000284, 34.00000000000021, 50.80000000000045, 36.70000000000025, 40.0000000000003, 43.60000000000036, 38.90000000000028, 27.900000000000105, 58.00000000000052, 4.800000000000157, 46.300000000000395, 49.90000000000046, 45.800000000000395, 33.400000000000205, 33.400000000000205, 64.30000000000048, 57.300000000000516, 36.00000000000024, 44.50000000000036, 42.00000000000033, 40.0000000000003, 62.50000000000052, 30.20000000000015, 27.90000000000011, 35.600000000000236, 56.00000000000051, 39.00000000000028, 20.900000000000002, 45.300000000000395, 32.50000000000019, 32.40000000000019, 51.900000000000446, 40.0000000000003, 53.60000000000052, 35.600000000000236, 43.60000000000036, 34.70000000000022, 57.10000000000049, 6.900000000000068, 36.60000000000025, 27.10000000000011, 49.800000000000466, 53.500000000000504, 33.4000000000002, 40.0000000000003, 40.0000000000003, 43.60000000000035, 36.300000000000246, 53.50000000000052, 41.800000000000324, 51.50000000000051, 31.100000000000165, 42.70000000000034, 40.0000000000003, 60.700000000000514, 35.600000000000236, 53.50000000000052, 40.90000000000031, 42.10000000000033, 40.0000000000003, 51.5000000000005, 53.5000000000005, 35.70000000000024, 23.300000000000054, 53.50000000000051, 37.80000000000027, 47.60000000000043, 51.7000000000005, 40.0000000000003, 40.0000000000003, 34.50000000000022, 35.20000000000023, 50.20000000000047, 50.80000000000048, 56.80000000000051, -85.10000000000079, 43.10000000000034, 45.00000000000038, 40.0000000000003, 40.0000000000003, 40.0000000000003, 35.80000000000024, 15.000000000000021, 14.700000000000047, 40.0000000000003, 40.0000000000003, 44.00000000000037], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999964, -6.399999999999908, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 38.90000000000025, 20.000000000000014, 4.099999999999971, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.000000000000163, 5.299999999999967, 21.500000000000036, -6.399999999999936, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, 20.000000000000014, 1.9999999999999607, 20.000000000000014, 20.000000000000014, 30.800000000000207, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 13.699999999999964, 38.000000000000256, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.90000000000018, 17.59999999999998, 21.20000000000003, 7.399999999999965, 20.000000000000018, 20.000000000000014, 7.399999999999965, 40.700000000000244, 23.60000000000007, 14.899999999999965, 34.40000000000026, 4.99999999999997, 20.000000000000014, 20.000000000000014, 24.50000000000008, 13.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.400000000000254, 28.100000000000147, 0.7999999999999865, 19.40000000000001, -3.099999999999958, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 35.000000000000256, -0.6999999999999993, 25.700000000000106, 23.60000000000007, -30.699999999999783, 20.000000000000014, 20.30000000000002, -10.599999999999836, 28.100000000000147, 9.499999999999975, 11.899999999999967, 20.000000000000014, 23.900000000000084, 20.000000000000014, 20.000000000000014, 33.20000000000024, 13.399999999999968, 11.599999999999964, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, -4.299999999999969, 37.10000000000024, 20.000000000000014, -72.40000000000086, 26.300000000000114, 8.299999999999965, 20.30000000000002, 18.19999999999999, -15.09999999999977, 9.499999999999964, 35.30000000000026, 33.50000000000025, 20.000000000000014, 20.000000000000014, -1.6000000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 11.299999999999965, 20.000000000000014, 33.50000000000024, 20.000000000000014, 21.80000000000004, 20.000000000000014, 30.50000000000022, 8.299999999999967, 15.799999999999963, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 15.799999999999962, 15.799999999999963, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.900000000000027, 25.400000000000098, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 20.000000000000014, 20.000000000000014, 33.50000000000025, 20.000000000000014, 7.699999999999967, -11.499999999999819, 6.799999999999976, 20.000000000000014, 33.50000000000024, 15.799999999999963, 20.000000000000014, 20.600000000000023, 20.000000000000014, 20.000000000000014, 31.700000000000216, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 9.19999999999997, 20.000000000000014, 20.000000000000014, 27.200000000000134, 21.80000000000004, 29.000000000000163, 13.699999999999967, 37.10000000000025, 13.399999999999965, -394.4999999999988, 5.299999999999965, 30.800000000000196, 23.000000000000057, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 12.199999999999969, 1.0999999999999865, 2.8999999999999613, 20.000000000000014, -28.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.999999999999975], "policy_predator_policy_reward": [0.0, 13.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 19.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 3.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 11.0, 0.0, 4.0, 0.0, 1.0, 14.0, 0.0, 20.0, 8.0, 5.0, 0.0, 13.0, 2.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 0.0, 0.0, 15.0, 4.0, 0.0, 0.0, 37.0, 16.0, 0.0, 8.0, 18.0, 6.0, 0.0, 5.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 13.0, 15.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 6.0, 296.0, 0.0, 1.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 11.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5917655236883664, "mean_inference_ms": 1.8431218537633254, "mean_action_processing_ms": 0.2498312385821891, "mean_env_wait_ms": 0.1947368741649344, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004473686218261719, "StateBufferConnector_ms": 0.003184080123901367, "ViewRequirementAgentConnector_ms": 0.09454333782196045}, "num_episodes": 22, "episode_return_max": 64.30000000000048, "episode_return_min": -85.10000000000079, "episode_return_mean": 39.43100000000031, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.065788298312, "num_env_steps_trained_throughput_per_sec": 404.065788298312, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 10072.408, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10072.366, "sample_time_ms": 1351.181, "learn_time_ms": 8705.741, "learn_throughput": 459.467, "synch_weights_time_ms": 14.259}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "0b081_00000", "date": "2024-08-13_01-00-01", "timestamp": 1723525201, "time_this_iter_s": 9.940544128417969, "time_total_s": 781.1159212589264, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f21dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 781.1159212589264, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 29.22000000000001, "ram_util_percent": 83.37333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6973249214016414, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.16875660197129325, "policy_loss": -0.006175814492371741, "vf_loss": 0.17462241650483862, "vf_explained_var": -0.044241876450795976, "kl": 0.026126747244164063, "entropy": 1.0379886968425973, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7520742583536991, "cur_kl_coeff": 0.012670540809631344, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.31210547412013284, "policy_loss": -0.0015859811905544823, "vf_loss": 0.3136237450431855, "vf_explained_var": 0.02903292425095089, "kl": 0.005343971837465981, "entropy": 0.7452060321651438, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 64.30000000000048, "episode_reward_min": -85.10000000000079, "episode_reward_mean": 39.775000000000304, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.4999999999988, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 296.0}, "policy_reward_mean": {"prey_policy": 15.662500000000044, "predator_policy": 4.225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [43.60000000000036, 38.90000000000028, 27.900000000000105, 58.00000000000052, 4.800000000000157, 46.300000000000395, 49.90000000000046, 45.800000000000395, 33.400000000000205, 33.400000000000205, 64.30000000000048, 57.300000000000516, 36.00000000000024, 44.50000000000036, 42.00000000000033, 40.0000000000003, 62.50000000000052, 30.20000000000015, 27.90000000000011, 35.600000000000236, 56.00000000000051, 39.00000000000028, 20.900000000000002, 45.300000000000395, 32.50000000000019, 32.40000000000019, 51.900000000000446, 40.0000000000003, 53.60000000000052, 35.600000000000236, 43.60000000000036, 34.70000000000022, 57.10000000000049, 6.900000000000068, 36.60000000000025, 27.10000000000011, 49.800000000000466, 53.500000000000504, 33.4000000000002, 40.0000000000003, 40.0000000000003, 43.60000000000035, 36.300000000000246, 53.50000000000052, 41.800000000000324, 51.50000000000051, 31.100000000000165, 42.70000000000034, 40.0000000000003, 60.700000000000514, 35.600000000000236, 53.50000000000052, 40.90000000000031, 42.10000000000033, 40.0000000000003, 51.5000000000005, 53.5000000000005, 35.70000000000024, 23.300000000000054, 53.50000000000051, 37.80000000000027, 47.60000000000043, 51.7000000000005, 40.0000000000003, 40.0000000000003, 34.50000000000022, 35.20000000000023, 50.20000000000047, 50.80000000000048, 56.80000000000051, -85.10000000000079, 43.10000000000034, 45.00000000000038, 40.0000000000003, 40.0000000000003, 40.0000000000003, 35.80000000000024, 15.000000000000021, 14.700000000000047, 40.0000000000003, 40.0000000000003, 44.00000000000037, 40.90000000000031, 59.8000000000005, 35.20000000000023, 37.40000000000026, 34.00000000000021, 53.5000000000005, 64.30000000000048, 32.000000000000185, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 28.500000000000117, 35.600000000000236, 46.300000000000395, 40.0000000000003, 30.100000000000147, 39.800000000000296], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.60000000000007, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 13.699999999999964, 38.000000000000256, 20.000000000000014, 20.000000000000014, -47.19999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 29.90000000000018, 17.59999999999998, 21.20000000000003, 7.399999999999965, 20.000000000000018, 20.000000000000014, 7.399999999999965, 40.700000000000244, 23.60000000000007, 14.899999999999965, 34.40000000000026, 4.99999999999997, 20.000000000000014, 20.000000000000014, 24.50000000000008, 13.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.400000000000254, 28.100000000000147, 0.7999999999999865, 19.40000000000001, -3.099999999999958, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 35.000000000000256, -0.6999999999999993, 25.700000000000106, 23.60000000000007, -30.699999999999783, 20.000000000000014, 20.30000000000002, -10.599999999999836, 28.100000000000147, 9.499999999999975, 11.899999999999967, 20.000000000000014, 23.900000000000084, 20.000000000000014, 20.000000000000014, 33.20000000000024, 13.399999999999968, 11.599999999999964, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, -4.299999999999969, 37.10000000000024, 20.000000000000014, -72.40000000000086, 26.300000000000114, 8.299999999999965, 20.30000000000002, 18.19999999999999, -15.09999999999977, 9.499999999999964, 35.30000000000026, 33.50000000000025, 20.000000000000014, 20.000000000000014, -1.6000000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 11.299999999999965, 20.000000000000014, 33.50000000000024, 20.000000000000014, 21.80000000000004, 20.000000000000014, 30.50000000000022, 8.299999999999967, 15.799999999999963, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 15.799999999999962, 15.799999999999963, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.900000000000027, 25.400000000000098, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 20.000000000000014, 20.000000000000014, 33.50000000000025, 20.000000000000014, 7.699999999999967, -11.499999999999819, 6.799999999999976, 20.000000000000014, 33.50000000000024, 15.799999999999963, 20.000000000000014, 20.600000000000023, 20.000000000000014, 20.000000000000014, 31.700000000000216, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 9.19999999999997, 20.000000000000014, 20.000000000000014, 27.200000000000134, 21.80000000000004, 29.000000000000163, 13.699999999999967, 37.10000000000025, 13.399999999999965, -394.4999999999988, 5.299999999999965, 30.800000000000196, 23.000000000000057, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 12.199999999999969, 1.0999999999999865, 2.8999999999999613, 20.000000000000014, -28.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.90000000000003, 20.000000000000014, 39.800000000000246, 16.099999999999962, 4.099999999999966, 3.1999999999999615, 21.20000000000003, 7.399999999999965, 20.600000000000023, 20.900000000000027, 32.60000000000023, 35.30000000000024, 29.000000000000163, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 10.999999999999966, 20.000000000000014, 11.599999999999964, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 18.799999999999997, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 1.0, 8.0, 3.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 11.0, 0.0, 4.0, 0.0, 1.0, 14.0, 0.0, 20.0, 8.0, 5.0, 0.0, 13.0, 2.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 0.0, 0.0, 15.0, 4.0, 0.0, 0.0, 37.0, 16.0, 0.0, 8.0, 18.0, 6.0, 0.0, 5.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 13.0, 15.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 6.0, 296.0, 0.0, 1.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 11.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 5.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5913080318186714, "mean_inference_ms": 1.842343876181654, "mean_action_processing_ms": 0.24957988642798945, "mean_env_wait_ms": 0.19459181310803253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041037797927856445, "StateBufferConnector_ms": 0.003113269805908203, "ViewRequirementAgentConnector_ms": 0.09248185157775879}, "num_episodes": 18, "episode_return_max": 64.30000000000048, "episode_return_min": -85.10000000000079, "episode_return_mean": 39.775000000000304, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 390.9067641004629, "num_env_steps_trained_throughput_per_sec": 390.9067641004629, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 10089.177, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10089.133, "sample_time_ms": 1353.103, "learn_time_ms": 8720.557, "learn_throughput": 458.686, "synch_weights_time_ms": 14.198}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "0b081_00000", "date": "2024-08-13_01-00-11", "timestamp": 1723525211, "time_this_iter_s": 10.238111972808838, "time_total_s": 791.3540332317352, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d1a430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 791.3540332317352, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 30.4, "ram_util_percent": 83.30714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8610068868727438, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.25997241560428863, "policy_loss": -0.002868017586805518, "vf_loss": 0.2626999214226897, "vf_explained_var": 0.019149357616586028, "kl": 0.007894894027914217, "entropy": 1.0227434199953835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7408366680150191, "cur_kl_coeff": 0.012670540809631344, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.36829186467007735, "policy_loss": -0.0010584209894110995, "vf_loss": 0.3692916410886461, "vf_explained_var": -0.13700637278102692, "kl": 0.004628418916229226, "entropy": 0.6881584367424092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 66.10000000000038, "episode_reward_min": -85.10000000000079, "episode_reward_mean": 40.24300000000031, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.4999999999988, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 296.0}, "policy_reward_mean": {"prey_policy": 15.971500000000043, "predator_policy": 4.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.300000000000395, 32.50000000000019, 32.40000000000019, 51.900000000000446, 40.0000000000003, 53.60000000000052, 35.600000000000236, 43.60000000000036, 34.70000000000022, 57.10000000000049, 6.900000000000068, 36.60000000000025, 27.10000000000011, 49.800000000000466, 53.500000000000504, 33.4000000000002, 40.0000000000003, 40.0000000000003, 43.60000000000035, 36.300000000000246, 53.50000000000052, 41.800000000000324, 51.50000000000051, 31.100000000000165, 42.70000000000034, 40.0000000000003, 60.700000000000514, 35.600000000000236, 53.50000000000052, 40.90000000000031, 42.10000000000033, 40.0000000000003, 51.5000000000005, 53.5000000000005, 35.70000000000024, 23.300000000000054, 53.50000000000051, 37.80000000000027, 47.60000000000043, 51.7000000000005, 40.0000000000003, 40.0000000000003, 34.50000000000022, 35.20000000000023, 50.20000000000047, 50.80000000000048, 56.80000000000051, -85.10000000000079, 43.10000000000034, 45.00000000000038, 40.0000000000003, 40.0000000000003, 40.0000000000003, 35.80000000000024, 15.000000000000021, 14.700000000000047, 40.0000000000003, 40.0000000000003, 44.00000000000037, 40.90000000000031, 59.8000000000005, 35.20000000000023, 37.40000000000026, 34.00000000000021, 53.5000000000005, 64.30000000000048, 32.000000000000185, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 28.500000000000117, 35.600000000000236, 46.300000000000395, 40.0000000000003, 30.100000000000147, 39.800000000000296, 33.70000000000019, 53.00000000000051, 38.90000000000028, 40.0000000000003, 47.200000000000415, 29.100000000000133, 23.30000000000003, 66.10000000000038, 59.800000000000516, 35.600000000000236, 52.000000000000504, 40.0000000000003, 57.100000000000506, 44.50000000000037, 46.80000000000041, 33.400000000000205, 35.90000000000024, 38.70000000000028, 50.5000000000005, 51.6000000000005, 37.600000000000264, 40.0000000000003, 30.200000000000152], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.30000000000002, -10.599999999999836, 28.100000000000147, 9.499999999999975, 11.899999999999967, 20.000000000000014, 23.900000000000084, 20.000000000000014, 20.000000000000014, 33.20000000000024, 13.399999999999968, 11.599999999999964, 20.000000000000014, 20.000000000000014, 23.60000000000007, 20.000000000000014, -4.299999999999969, 37.10000000000024, 20.000000000000014, -72.40000000000086, 26.300000000000114, 8.299999999999965, 20.30000000000002, 18.19999999999999, -15.09999999999977, 9.499999999999964, 35.30000000000026, 33.50000000000025, 20.000000000000014, 20.000000000000014, -1.6000000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 11.299999999999965, 20.000000000000014, 33.50000000000024, 20.000000000000014, 21.80000000000004, 20.000000000000014, 30.50000000000022, 8.299999999999967, 15.799999999999963, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 15.799999999999962, 15.799999999999963, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.900000000000027, 25.400000000000098, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 20.000000000000014, 20.000000000000014, 33.50000000000025, 20.000000000000014, 7.699999999999967, -11.499999999999819, 6.799999999999976, 20.000000000000014, 33.50000000000024, 15.799999999999963, 20.000000000000014, 20.600000000000023, 20.000000000000014, 20.000000000000014, 31.700000000000216, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 9.19999999999997, 20.000000000000014, 20.000000000000014, 27.200000000000134, 21.80000000000004, 29.000000000000163, 13.699999999999967, 37.10000000000025, 13.399999999999965, -394.4999999999988, 5.299999999999965, 30.800000000000196, 23.000000000000057, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 12.199999999999969, 1.0999999999999865, 2.8999999999999613, 20.000000000000014, -28.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.90000000000003, 20.000000000000014, 39.800000000000246, 16.099999999999962, 4.099999999999966, 3.1999999999999615, 21.20000000000003, 7.399999999999965, 20.600000000000023, 20.900000000000027, 32.60000000000023, 35.30000000000024, 29.000000000000163, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 10.999999999999966, 20.000000000000014, 11.599999999999964, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 18.799999999999997, 20.000000000000014, 33.50000000000024, -17.799999999999798, 21.80000000000004, 27.200000000000134, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000013, 11.599999999999964, -2.4999999999999716, 20.000000000000014, -12.6999999999998, 30.800000000000196, 35.30000000000026, 34.400000000000254, 25.400000000000098, 11.599999999999964, 20.000000000000014, 15.499999999999963, 30.500000000000192, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 24.500000000000085, 20.000000000000014, 29.000000000000163, 15.799999999999962, 7.399999999999972, 20.000000000000014, 20.000000000000014, -0.10000000000001702, 16.69999999999997, 20.000000000000014, 7.399999999999968, 25.100000000000097, 26.300000000000118, 20.30000000000002, 8.299999999999965, 17.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.799999999999972], "policy_predator_policy_reward": [5.0, 0.0, 13.0, 2.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 0.0, 0.0, 15.0, 4.0, 0.0, 0.0, 37.0, 16.0, 0.0, 8.0, 18.0, 6.0, 0.0, 5.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 13.0, 15.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 6.0, 296.0, 0.0, 1.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 11.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 5.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 0.0, 18.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 5.0, 11.0, 2.0, 0.0, 9.0, 9.0, 4.0, 1.0, 12.0, 0.0, 0.0, 0.0, 5.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5907984820906076, "mean_inference_ms": 1.8413314023676444, "mean_action_processing_ms": 0.2492944406838867, "mean_env_wait_ms": 0.19434342951397096, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038480758666992188, "StateBufferConnector_ms": 0.0030858516693115234, "ViewRequirementAgentConnector_ms": 0.0987691879272461}, "num_episodes": 23, "episode_return_max": 66.10000000000038, "episode_return_min": -85.10000000000079, "episode_return_mean": 40.24300000000031, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.7436397797714, "num_env_steps_trained_throughput_per_sec": 398.7436397797714, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 10082.281, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10082.237, "sample_time_ms": 1358.347, "learn_time_ms": 8708.904, "learn_throughput": 459.3, "synch_weights_time_ms": 13.831}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "0b081_00000", "date": "2024-08-13_01-00-21", "timestamp": 1723525221, "time_this_iter_s": 10.036176919937134, "time_total_s": 801.3902101516724, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dca280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 801.3902101516724, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 30.071428571428573, "ram_util_percent": 83.23571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7725655738323454, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.19471380701140753, "policy_loss": -0.004203183737844623, "vf_loss": 0.19868471164338872, "vf_explained_var": -0.02129386505752644, "kl": 0.013050932726472586, "entropy": 0.9768570006524444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7918801831603839, "cur_kl_coeff": 0.006335270404815672, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3354981687815525, "policy_loss": -0.0024813681555093912, "vf_loss": 0.3379322924146123, "vf_explained_var": 0.06229384670812617, "kl": 0.007457522596574698, "entropy": 0.6486498855409168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 66.10000000000038, "episode_reward_min": -85.10000000000079, "episode_reward_mean": 39.960000000000306, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.4999999999988, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 296.0}, "policy_reward_mean": {"prey_policy": 16.000000000000046, "predator_policy": 3.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [43.60000000000035, 36.300000000000246, 53.50000000000052, 41.800000000000324, 51.50000000000051, 31.100000000000165, 42.70000000000034, 40.0000000000003, 60.700000000000514, 35.600000000000236, 53.50000000000052, 40.90000000000031, 42.10000000000033, 40.0000000000003, 51.5000000000005, 53.5000000000005, 35.70000000000024, 23.300000000000054, 53.50000000000051, 37.80000000000027, 47.60000000000043, 51.7000000000005, 40.0000000000003, 40.0000000000003, 34.50000000000022, 35.20000000000023, 50.20000000000047, 50.80000000000048, 56.80000000000051, -85.10000000000079, 43.10000000000034, 45.00000000000038, 40.0000000000003, 40.0000000000003, 40.0000000000003, 35.80000000000024, 15.000000000000021, 14.700000000000047, 40.0000000000003, 40.0000000000003, 44.00000000000037, 40.90000000000031, 59.8000000000005, 35.20000000000023, 37.40000000000026, 34.00000000000021, 53.5000000000005, 64.30000000000048, 32.000000000000185, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 28.500000000000117, 35.600000000000236, 46.300000000000395, 40.0000000000003, 30.100000000000147, 39.800000000000296, 33.70000000000019, 53.00000000000051, 38.90000000000028, 40.0000000000003, 47.200000000000415, 29.100000000000133, 23.30000000000003, 66.10000000000038, 59.800000000000516, 35.600000000000236, 52.000000000000504, 40.0000000000003, 57.100000000000506, 44.50000000000037, 46.80000000000041, 33.400000000000205, 35.90000000000024, 38.70000000000028, 50.5000000000005, 51.6000000000005, 37.600000000000264, 40.0000000000003, 30.200000000000152, 58.900000000000524, 49.000000000000455, 41.30000000000032, 35.600000000000236, 33.400000000000205, 20.399999999999984, 29.000000000000128, 32.30000000000018, 40.0000000000003, 24.70000000000005, 40.0000000000003, 40.0000000000003, 32.50000000000019, 29.900000000000144, 25.700000000000067, 43.90000000000036, 45.40000000000038, 63.70000000000051], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.600000000000065, 20.000000000000014, 20.000000000000014, 11.299999999999965, 20.000000000000014, 33.50000000000024, 20.000000000000014, 21.80000000000004, 20.000000000000014, 30.50000000000022, 8.299999999999967, 15.799999999999963, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 15.799999999999962, 15.799999999999963, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.900000000000027, 25.400000000000098, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 20.000000000000014, 20.000000000000014, 33.50000000000025, 20.000000000000014, 7.699999999999967, -11.499999999999819, 6.799999999999976, 20.000000000000014, 33.50000000000024, 15.799999999999963, 20.000000000000014, 20.600000000000023, 20.000000000000014, 20.000000000000014, 31.700000000000216, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 9.19999999999997, 20.000000000000014, 20.000000000000014, 27.200000000000134, 21.80000000000004, 29.000000000000163, 13.699999999999967, 37.10000000000025, 13.399999999999965, -394.4999999999988, 5.299999999999965, 30.800000000000196, 23.000000000000057, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 12.199999999999969, 1.0999999999999865, 2.8999999999999613, 20.000000000000014, -28.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.90000000000003, 20.000000000000014, 39.800000000000246, 16.099999999999962, 4.099999999999966, 3.1999999999999615, 21.20000000000003, 7.399999999999965, 20.600000000000023, 20.900000000000027, 32.60000000000023, 35.30000000000024, 29.000000000000163, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 10.999999999999966, 20.000000000000014, 11.599999999999964, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 18.799999999999997, 20.000000000000014, 33.50000000000024, -17.799999999999798, 21.80000000000004, 27.200000000000134, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000013, 11.599999999999964, -2.4999999999999716, 20.000000000000014, -12.6999999999998, 30.800000000000196, 35.30000000000026, 34.400000000000254, 25.400000000000098, 11.599999999999964, 20.000000000000014, 15.499999999999963, 30.500000000000192, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 24.500000000000085, 20.000000000000014, 29.000000000000163, 15.799999999999962, 7.399999999999972, 20.000000000000014, 20.000000000000014, -0.10000000000001702, 16.69999999999997, 20.000000000000014, 7.399999999999968, 25.100000000000097, 26.300000000000118, 20.30000000000002, 8.299999999999965, 17.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.799999999999972, 29.000000000000163, 29.90000000000018, 32.60000000000023, -13.599999999999786, 14.299999999999969, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 7.399999999999965, 22.400000000000045, -21.999999999999744, -0.9999999999999846, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.399999999999967, 1.0999999999999865, 20.000000000000014, -0.10000000000000636, 17.899999999999988, -5.1999999999999265, 20.900000000000027, 20.000000000000014, 25.400000000000098, 20.000000000000014, 35.30000000000025, 25.4000000000001], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 13.0, 15.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 6.0, 296.0, 0.0, 1.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 11.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 5.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 0.0, 18.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 5.0, 11.0, 2.0, 0.0, 9.0, 9.0, 4.0, 1.0, 12.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 16.0, 14.0, 7.0, 0.0, 0.0, 4.0, 0.0, 6.0, 10.0, 10.0, 0.0, 10.0, 7.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 10.0, 0.0, 1.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5903726313495383, "mean_inference_ms": 1.8404290080101264, "mean_action_processing_ms": 0.2490482722694076, "mean_env_wait_ms": 0.1941369115636319, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038743019104003906, "StateBufferConnector_ms": 0.003008604049682617, "ViewRequirementAgentConnector_ms": 0.09860968589782715}, "num_episodes": 18, "episode_return_max": 66.10000000000038, "episode_return_min": -85.10000000000079, "episode_return_mean": 39.960000000000306, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 405.93393884628415, "num_env_steps_trained_throughput_per_sec": 405.93393884628415, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 10016.92, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10016.877, "sample_time_ms": 1319.425, "learn_time_ms": 8682.696, "learn_throughput": 460.686, "synch_weights_time_ms": 13.608}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "0b081_00000", "date": "2024-08-13_01-00-31", "timestamp": 1723525231, "time_this_iter_s": 9.85843014717102, "time_total_s": 811.2486402988434, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d57e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 811.2486402988434, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 28.27857142857142, "ram_util_percent": 83.35000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8647955845331862, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14497451885081655, "policy_loss": -0.004853857513862076, "vf_loss": 0.14960080876000345, "vf_explained_var": -0.025253693830399285, "kl": 0.012786229187035963, "entropy": 0.9313849085222476, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6213463375916478, "cur_kl_coeff": 0.006335270404815672, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.24017485986188394, "policy_loss": -0.001585485008126371, "vf_loss": 0.24171104729311077, "vf_explained_var": -0.10308949231470703, "kl": 0.007781415865786498, "entropy": 0.572387294920664, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 66.10000000000038, "episode_reward_min": -85.10000000000079, "episode_reward_mean": 38.921000000000284, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.4999999999988, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.800000000000246, "predator_policy": 296.0}, "policy_reward_mean": {"prey_policy": 15.260500000000047, "predator_policy": 4.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, 34.50000000000022, 35.20000000000023, 50.20000000000047, 50.80000000000048, 56.80000000000051, -85.10000000000079, 43.10000000000034, 45.00000000000038, 40.0000000000003, 40.0000000000003, 40.0000000000003, 35.80000000000024, 15.000000000000021, 14.700000000000047, 40.0000000000003, 40.0000000000003, 44.00000000000037, 40.90000000000031, 59.8000000000005, 35.20000000000023, 37.40000000000026, 34.00000000000021, 53.5000000000005, 64.30000000000048, 32.000000000000185, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 28.500000000000117, 35.600000000000236, 46.300000000000395, 40.0000000000003, 30.100000000000147, 39.800000000000296, 33.70000000000019, 53.00000000000051, 38.90000000000028, 40.0000000000003, 47.200000000000415, 29.100000000000133, 23.30000000000003, 66.10000000000038, 59.800000000000516, 35.600000000000236, 52.000000000000504, 40.0000000000003, 57.100000000000506, 44.50000000000037, 46.80000000000041, 33.400000000000205, 35.90000000000024, 38.70000000000028, 50.5000000000005, 51.6000000000005, 37.600000000000264, 40.0000000000003, 30.200000000000152, 58.900000000000524, 49.000000000000455, 41.30000000000032, 35.600000000000236, 33.400000000000205, 20.399999999999984, 29.000000000000128, 32.30000000000018, 40.0000000000003, 24.70000000000005, 40.0000000000003, 40.0000000000003, 32.50000000000019, 29.900000000000144, 25.700000000000067, 43.90000000000036, 45.40000000000038, 63.70000000000051, 48.800000000000445, 41.800000000000324, 40.0000000000003, 30.000000000000153, 11.500000000000027, 52.1000000000005, 46.300000000000395, 40.0000000000003, 44.30000000000036, 47.200000000000415, 40.500000000000306, 19.099999999999977, 39.30000000000029, 35.30000000000023, 52.60000000000051, 36.70000000000025, 37.50000000000026, 40.0000000000003, 50.60000000000048, 29.000000000000128, 41.40000000000031, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 9.19999999999997, 20.000000000000014, 20.000000000000014, 27.200000000000134, 21.80000000000004, 29.000000000000163, 13.699999999999967, 37.10000000000025, 13.399999999999965, -394.4999999999988, 5.299999999999965, 30.800000000000196, 23.000000000000057, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 12.199999999999969, 1.0999999999999865, 2.8999999999999613, 20.000000000000014, -28.299999999999947, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.90000000000003, 20.000000000000014, 39.800000000000246, 16.099999999999962, 4.099999999999966, 3.1999999999999615, 21.20000000000003, 7.399999999999965, 20.600000000000023, 20.900000000000027, 32.60000000000023, 35.30000000000024, 29.000000000000163, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 10.999999999999966, 20.000000000000014, 11.599999999999964, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 18.799999999999997, 20.000000000000014, 33.50000000000024, -17.799999999999798, 21.80000000000004, 27.200000000000134, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000013, 11.599999999999964, -2.4999999999999716, 20.000000000000014, -12.6999999999998, 30.800000000000196, 35.30000000000026, 34.400000000000254, 25.400000000000098, 11.599999999999964, 20.000000000000014, 15.499999999999963, 30.500000000000192, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 24.500000000000085, 20.000000000000014, 29.000000000000163, 15.799999999999962, 7.399999999999972, 20.000000000000014, 20.000000000000014, -0.10000000000001702, 16.69999999999997, 20.000000000000014, 7.399999999999968, 25.100000000000097, 26.300000000000118, 20.30000000000002, 8.299999999999965, 17.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.799999999999972, 29.000000000000163, 29.90000000000018, 32.60000000000023, -13.599999999999786, 14.299999999999969, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 7.399999999999965, 22.400000000000045, -21.999999999999744, -0.9999999999999846, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.399999999999967, 1.0999999999999865, 20.000000000000014, -0.10000000000000636, 17.899999999999988, -5.1999999999999265, 20.900000000000027, 20.000000000000014, 25.400000000000098, 20.000000000000014, 35.30000000000025, 25.4000000000001, 20.000000000000014, 27.800000000000143, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.499999999999972, 9.499999999999964, -7.299999999999912, 3.799999999999969, 32.60000000000023, 12.49999999999997, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.30000000000006, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.499999999999996, -19.899999999999743, 20.000000000000014, 38.00000000000024, -15.699999999999747, 13.699999999999966, 11.599999999999964, 32.60000000000023, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 17.899999999999988, 31.700000000000212, 20.000000000000014, -0.9999999999999881, 23.600000000000065, 15.799999999999962, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 6.0, 296.0, 0.0, 1.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 11.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 5.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 0.0, 18.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 5.0, 11.0, 2.0, 0.0, 9.0, 9.0, 4.0, 1.0, 12.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 16.0, 14.0, 7.0, 0.0, 0.0, 4.0, 0.0, 6.0, 10.0, 10.0, 0.0, 10.0, 7.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 10.0, 0.0, 1.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 0.0, 15.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 12.0, 0.0, 17.0, 7.0, 3.0, 0.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 2.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.589875770020616, "mean_inference_ms": 1.839519755618777, "mean_action_processing_ms": 0.248801521686129, "mean_env_wait_ms": 0.19387211160310208, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00379180908203125, "StateBufferConnector_ms": 0.0029562711715698242, "ViewRequirementAgentConnector_ms": 0.09636807441711426}, "num_episodes": 22, "episode_return_max": 66.10000000000038, "episode_return_min": -85.10000000000079, "episode_return_mean": 38.921000000000284, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 399.22498476125713, "num_env_steps_trained_throughput_per_sec": 399.22498476125713, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 10015.677, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10015.634, "sample_time_ms": 1310.041, "learn_time_ms": 8690.984, "learn_throughput": 460.247, "synch_weights_time_ms": 13.444}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "0b081_00000", "date": "2024-08-13_01-00-41", "timestamp": 1723525241, "time_this_iter_s": 10.067137956619263, "time_total_s": 821.3157782554626, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d16b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 821.3157782554626, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 30.659999999999993, "ram_util_percent": 83.14000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8924128148310556, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.26566627202604814, "policy_loss": -0.003982012340720132, "vf_loss": 0.26949723504512035, "vf_explained_var": 0.021691073910899895, "kl": 0.008486981761193379, "entropy": 0.886503887744177, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6571262338193794, "cur_kl_coeff": 0.006335270404815672, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.31491882560439605, "policy_loss": -0.0012379715620742116, "vf_loss": 0.3161240423445605, "vf_explained_var": -0.13220462442705871, "kl": 0.005170414185627038, "entropy": 0.49190981963639535, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 66.10000000000038, "episode_reward_min": 11.500000000000027, "episode_reward_mean": 40.0740000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -21.999999999999744, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.800000000000246, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 17.08700000000004, "predator_policy": 2.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.00000000000037, 40.90000000000031, 59.8000000000005, 35.20000000000023, 37.40000000000026, 34.00000000000021, 53.5000000000005, 64.30000000000048, 32.000000000000185, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 28.500000000000117, 35.600000000000236, 46.300000000000395, 40.0000000000003, 30.100000000000147, 39.800000000000296, 33.70000000000019, 53.00000000000051, 38.90000000000028, 40.0000000000003, 47.200000000000415, 29.100000000000133, 23.30000000000003, 66.10000000000038, 59.800000000000516, 35.600000000000236, 52.000000000000504, 40.0000000000003, 57.100000000000506, 44.50000000000037, 46.80000000000041, 33.400000000000205, 35.90000000000024, 38.70000000000028, 50.5000000000005, 51.6000000000005, 37.600000000000264, 40.0000000000003, 30.200000000000152, 58.900000000000524, 49.000000000000455, 41.30000000000032, 35.600000000000236, 33.400000000000205, 20.399999999999984, 29.000000000000128, 32.30000000000018, 40.0000000000003, 24.70000000000005, 40.0000000000003, 40.0000000000003, 32.50000000000019, 29.900000000000144, 25.700000000000067, 43.90000000000036, 45.40000000000038, 63.70000000000051, 48.800000000000445, 41.800000000000324, 40.0000000000003, 30.000000000000153, 11.500000000000027, 52.1000000000005, 46.300000000000395, 40.0000000000003, 44.30000000000036, 47.200000000000415, 40.500000000000306, 19.099999999999977, 39.30000000000029, 35.30000000000023, 52.60000000000051, 36.70000000000025, 37.50000000000026, 40.0000000000003, 50.60000000000048, 29.000000000000128, 41.40000000000031, 40.0000000000003, 34.60000000000022, 39.60000000000029, 34.50000000000022, 64.3000000000005, 39.60000000000029, 23.200000000000028, 26.800000000000097, 46.600000000000406, 30.100000000000147, 41.90000000000032, 27.90000000000011, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.70000000000031, 44.60000000000037, 42.40000000000034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 16.999999999999975, 20.000000000000014, 20.90000000000003, 20.000000000000014, 39.800000000000246, 16.099999999999962, 4.099999999999966, 3.1999999999999615, 21.20000000000003, 7.399999999999965, 20.600000000000023, 20.900000000000027, 32.60000000000023, 35.30000000000024, 29.000000000000163, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 10.999999999999966, 20.000000000000014, 11.599999999999964, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 18.799999999999997, 20.000000000000014, 33.50000000000024, -17.799999999999798, 21.80000000000004, 27.200000000000134, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000013, 11.599999999999964, -2.4999999999999716, 20.000000000000014, -12.6999999999998, 30.800000000000196, 35.30000000000026, 34.400000000000254, 25.400000000000098, 11.599999999999964, 20.000000000000014, 15.499999999999963, 30.500000000000192, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 24.500000000000085, 20.000000000000014, 29.000000000000163, 15.799999999999962, 7.399999999999972, 20.000000000000014, 20.000000000000014, -0.10000000000001702, 16.69999999999997, 20.000000000000014, 7.399999999999968, 25.100000000000097, 26.300000000000118, 20.30000000000002, 8.299999999999965, 17.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.799999999999972, 29.000000000000163, 29.90000000000018, 32.60000000000023, -13.599999999999786, 14.299999999999969, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 7.399999999999965, 22.400000000000045, -21.999999999999744, -0.9999999999999846, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.399999999999967, 1.0999999999999865, 20.000000000000014, -0.10000000000000636, 17.899999999999988, -5.1999999999999265, 20.900000000000027, 20.000000000000014, 25.400000000000098, 20.000000000000014, 35.30000000000025, 25.4000000000001, 20.000000000000014, 27.800000000000143, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.499999999999972, 9.499999999999964, -7.299999999999912, 3.799999999999969, 32.60000000000023, 12.49999999999997, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.30000000000006, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.499999999999996, -19.899999999999743, 20.000000000000014, 38.00000000000024, -15.699999999999747, 13.699999999999966, 11.599999999999964, 32.60000000000023, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 17.899999999999988, 31.700000000000212, 20.000000000000014, -0.9999999999999881, 23.600000000000065, 15.799999999999962, 20.000000000000014, 20.000000000000014, -0.39999999999999936, 20.000000000000014, 17.599999999999984, 20.000000000000014, 9.499999999999966, 20.000000000000014, 34.400000000000254, 29.90000000000018, 3.1999999999999615, 25.400000000000098, -3.099999999999972, 5.299999999999965, 3.199999999999967, 11.599999999999964, 23.60000000000007, 20.000000000000014, 6.1999999999999655, 14.899999999999967, 20.000000000000014, 11.899999999999967, 20.000000000000014, -3.099999999999958, 9.499999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 1.099999999999983, 33.50000000000024, 20.000000000000014, 16.399999999999967], "policy_predator_policy_reward": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 5.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 0.0, 18.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 5.0, 11.0, 2.0, 0.0, 9.0, 9.0, 4.0, 1.0, 12.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 16.0, 14.0, 7.0, 0.0, 0.0, 4.0, 0.0, 6.0, 10.0, 10.0, 0.0, 10.0, 7.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 10.0, 0.0, 1.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 0.0, 15.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 12.0, 0.0, 17.0, 7.0, 3.0, 0.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 2.0, 0.0, 0.0, 8.0, 7.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 4.0, 7.0, 8.0, 13.0, 8.0, 4.0, 0.0, 3.0, 0.0, 9.0, 5.0, 5.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 4.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5895743192111426, "mean_inference_ms": 1.8389845488026362, "mean_action_processing_ms": 0.24860686708338656, "mean_env_wait_ms": 0.1937576778547634, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038290023803710938, "StateBufferConnector_ms": 0.0029630661010742188, "ViewRequirementAgentConnector_ms": 0.09654974937438965}, "num_episodes": 18, "episode_return_max": 66.10000000000038, "episode_return_min": 11.500000000000027, "episode_return_mean": 40.0740000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.3869478880715, "num_env_steps_trained_throughput_per_sec": 391.3869478880715, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 10038.99, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10038.947, "sample_time_ms": 1321.108, "learn_time_ms": 8702.925, "learn_throughput": 459.616, "synch_weights_time_ms": 13.53}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "0b081_00000", "date": "2024-08-13_01-00-52", "timestamp": 1723525252, "time_this_iter_s": 10.293295860290527, "time_total_s": 831.6090741157532, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f4d550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 831.6090741157532, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 31.771428571428572, "ram_util_percent": 82.97857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7875067195051877, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.40132593982434145, "policy_loss": -0.007380932852842663, "vf_loss": 0.4085076444421368, "vf_explained_var": 0.0384467257393731, "kl": 0.011193926493117236, "entropy": 0.8685455972555454, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6099730085468206, "cur_kl_coeff": 0.006335270404815672, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4344697134226836, "policy_loss": -0.0008098384109202516, "vf_loss": 0.4352584330970545, "vf_explained_var": -0.08966445011436625, "kl": 0.0033336141950263383, "entropy": 0.4072594994275027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 66.10000000000038, "episode_reward_min": 0.40000000000015745, "episode_reward_mean": 38.39500000000027, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -55.600000000000236, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000024, "predator_policy": 34.0}, "policy_reward_mean": {"prey_policy": 15.627500000000031, "predator_policy": 3.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.200000000000415, 29.100000000000133, 23.30000000000003, 66.10000000000038, 59.800000000000516, 35.600000000000236, 52.000000000000504, 40.0000000000003, 57.100000000000506, 44.50000000000037, 46.80000000000041, 33.400000000000205, 35.90000000000024, 38.70000000000028, 50.5000000000005, 51.6000000000005, 37.600000000000264, 40.0000000000003, 30.200000000000152, 58.900000000000524, 49.000000000000455, 41.30000000000032, 35.600000000000236, 33.400000000000205, 20.399999999999984, 29.000000000000128, 32.30000000000018, 40.0000000000003, 24.70000000000005, 40.0000000000003, 40.0000000000003, 32.50000000000019, 29.900000000000144, 25.700000000000067, 43.90000000000036, 45.40000000000038, 63.70000000000051, 48.800000000000445, 41.800000000000324, 40.0000000000003, 30.000000000000153, 11.500000000000027, 52.1000000000005, 46.300000000000395, 40.0000000000003, 44.30000000000036, 47.200000000000415, 40.500000000000306, 19.099999999999977, 39.30000000000029, 35.30000000000023, 52.60000000000051, 36.70000000000025, 37.50000000000026, 40.0000000000003, 50.60000000000048, 29.000000000000128, 41.40000000000031, 40.0000000000003, 34.60000000000022, 39.60000000000029, 34.50000000000022, 64.3000000000005, 39.60000000000029, 23.200000000000028, 26.800000000000097, 46.600000000000406, 30.100000000000147, 41.90000000000032, 27.90000000000011, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.70000000000031, 44.60000000000037, 42.40000000000034, 33.2000000000002, 0.40000000000015745, 38.90000000000028, 35.20000000000023, 21.4, 40.0000000000003, 33.400000000000205, 39.50000000000029, 43.60000000000035, 46.300000000000395, 19.199999999999957, 26.80000000000009, 35.600000000000236, 40.0000000000003, 31.800000000000185, 40.0000000000003, 39.30000000000029, 36.900000000000254, 35.600000000000236, 47.30000000000042, 26.80000000000009, 23.700000000000042, 44.20000000000037], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 27.20000000000013, 11.599999999999964, -2.4999999999999716, 20.000000000000014, -12.6999999999998, 30.800000000000196, 35.30000000000026, 34.400000000000254, 25.400000000000098, 11.599999999999964, 20.000000000000014, 15.499999999999963, 30.500000000000192, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 24.500000000000085, 20.000000000000014, 29.000000000000163, 15.799999999999962, 7.399999999999972, 20.000000000000014, 20.000000000000014, -0.10000000000001702, 16.69999999999997, 20.000000000000014, 7.399999999999968, 25.100000000000097, 26.300000000000118, 20.30000000000002, 8.299999999999965, 17.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.799999999999972, 29.000000000000163, 29.90000000000018, 32.60000000000023, -13.599999999999786, 14.299999999999969, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 7.399999999999965, 22.400000000000045, -21.999999999999744, -0.9999999999999846, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.399999999999967, 1.0999999999999865, 20.000000000000014, -0.10000000000000636, 17.899999999999988, -5.1999999999999265, 20.900000000000027, 20.000000000000014, 25.400000000000098, 20.000000000000014, 35.30000000000025, 25.4000000000001, 20.000000000000014, 27.800000000000143, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.499999999999972, 9.499999999999964, -7.299999999999912, 3.799999999999969, 32.60000000000023, 12.49999999999997, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.30000000000006, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.499999999999996, -19.899999999999743, 20.000000000000014, 38.00000000000024, -15.699999999999747, 13.699999999999966, 11.599999999999964, 32.60000000000023, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 17.899999999999988, 31.700000000000212, 20.000000000000014, -0.9999999999999881, 23.600000000000065, 15.799999999999962, 20.000000000000014, 20.000000000000014, -0.39999999999999936, 20.000000000000014, 17.599999999999984, 20.000000000000014, 9.499999999999966, 20.000000000000014, 34.400000000000254, 29.90000000000018, 3.1999999999999615, 25.400000000000098, -3.099999999999972, 5.299999999999965, 3.199999999999967, 11.599999999999964, 23.60000000000007, 20.000000000000014, 6.1999999999999655, 14.899999999999967, 20.000000000000014, 11.899999999999967, 20.000000000000014, -3.099999999999958, 9.499999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 1.099999999999983, 33.50000000000024, 20.000000000000014, 16.399999999999967, 6.1999999999999655, 20.000000000000014, 20.000000000000014, -55.600000000000236, 20.000000000000014, 17.899999999999988, 20.000000000000014, 9.199999999999966, -11.499999999999826, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, -23.799999999999756, 5.299999999999965, 9.499999999999968, 20.000000000000014, 11.599999999999971, 20.000000000000014, 20.000000000000014, 10.399999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.799999999999967, 9.499999999999964, 5.89999999999997, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 23.300000000000068, -5.1999999999999265, 20.000000000000014, -5.799999999999931, 9.499999999999964, 20.000000000000014, 6.199999999999969], "policy_predator_policy_reward": [0.0, 0.0, 9.0, 11.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 5.0, 11.0, 2.0, 0.0, 9.0, 9.0, 4.0, 1.0, 12.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 16.0, 14.0, 7.0, 0.0, 0.0, 4.0, 0.0, 6.0, 10.0, 10.0, 0.0, 10.0, 7.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 10.0, 0.0, 1.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 0.0, 15.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 12.0, 0.0, 17.0, 7.0, 3.0, 0.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 2.0, 0.0, 0.0, 8.0, 7.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 4.0, 7.0, 8.0, 13.0, 8.0, 4.0, 0.0, 3.0, 0.0, 9.0, 5.0, 5.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 4.0, 6.0, 0.0, 7.0, 0.0, 2.0, 34.0, 1.0, 0.0, 4.0, 2.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 14.0, 9.0, 12.0, 0.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 11.0, 9.0, 0.0, 11.0, 0.0, 4.0, 0.0, 4.0, 0.0, 12.0, 10.0, 10.0, 8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5898603939481322, "mean_inference_ms": 1.8354762100346136, "mean_action_processing_ms": 0.2482539568762078, "mean_env_wait_ms": 0.19357776372945537, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003882169723510742, "StateBufferConnector_ms": 0.003159046173095703, "ViewRequirementAgentConnector_ms": 0.09588277339935303}, "num_episodes": 23, "episode_return_max": 66.10000000000038, "episode_return_min": 0.40000000000015745, "episode_return_mean": 38.39500000000027, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 396.8876479399946, "num_env_steps_trained_throughput_per_sec": 396.8876479399946, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 10016.54, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10016.498, "sample_time_ms": 1327.454, "learn_time_ms": 8674.597, "learn_throughput": 461.117, "synch_weights_time_ms": 13.097}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "0b081_00000", "date": "2024-08-13_01-01-02", "timestamp": 1723525262, "time_this_iter_s": 10.083548069000244, "time_total_s": 841.6926221847534, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f4dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 841.6926221847534, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 29.626666666666672, "ram_util_percent": 83.30666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0645130005857302, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18323590554021024, "policy_loss": -0.004510575054686458, "vf_loss": 0.18766047662128965, "vf_explained_var": 0.05083700563541796, "kl": 0.004832278563126539, "entropy": 0.865741205877728, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5883920232218409, "cur_kl_coeff": 0.003167635202407836, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.34680697344411066, "policy_loss": -0.0014411446497967792, "vf_loss": 0.3482368120442578, "vf_explained_var": -0.03976577236538842, "kl": 0.00356906686371377, "entropy": 0.47774637863434183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 69.7000000000001, "episode_reward_min": 0.40000000000015745, "episode_reward_mean": 37.15400000000026, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -55.600000000000236, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000024, "predator_policy": 34.0}, "policy_reward_mean": {"prey_policy": 14.852000000000032, "predator_policy": 3.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.200000000000152, 58.900000000000524, 49.000000000000455, 41.30000000000032, 35.600000000000236, 33.400000000000205, 20.399999999999984, 29.000000000000128, 32.30000000000018, 40.0000000000003, 24.70000000000005, 40.0000000000003, 40.0000000000003, 32.50000000000019, 29.900000000000144, 25.700000000000067, 43.90000000000036, 45.40000000000038, 63.70000000000051, 48.800000000000445, 41.800000000000324, 40.0000000000003, 30.000000000000153, 11.500000000000027, 52.1000000000005, 46.300000000000395, 40.0000000000003, 44.30000000000036, 47.200000000000415, 40.500000000000306, 19.099999999999977, 39.30000000000029, 35.30000000000023, 52.60000000000051, 36.70000000000025, 37.50000000000026, 40.0000000000003, 50.60000000000048, 29.000000000000128, 41.40000000000031, 40.0000000000003, 34.60000000000022, 39.60000000000029, 34.50000000000022, 64.3000000000005, 39.60000000000029, 23.200000000000028, 26.800000000000097, 46.600000000000406, 30.100000000000147, 41.90000000000032, 27.90000000000011, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.70000000000031, 44.60000000000037, 42.40000000000034, 33.2000000000002, 0.40000000000015745, 38.90000000000028, 35.20000000000023, 21.4, 40.0000000000003, 33.400000000000205, 39.50000000000029, 43.60000000000035, 46.300000000000395, 19.199999999999957, 26.80000000000009, 35.600000000000236, 40.0000000000003, 31.800000000000185, 40.0000000000003, 39.30000000000029, 36.900000000000254, 35.600000000000236, 47.30000000000042, 26.80000000000009, 23.700000000000042, 44.20000000000037, 1.6000000000002432, 44.60000000000037, 17.199999999999964, 28.100000000000115, 20.2, 55.3000000000005, 59.70000000000051, 52.20000000000049, 40.0000000000003, 69.7000000000001, 35.20000000000023, 40.90000000000031, 25.70000000000007, 26.100000000000072, 35.80000000000023, 40.0000000000003, 33.70000000000021, 39.100000000000286], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -2.799999999999972, 29.000000000000163, 29.90000000000018, 32.60000000000023, -13.599999999999786, 14.299999999999969, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 7.399999999999965, 22.400000000000045, -21.999999999999744, -0.9999999999999846, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.399999999999967, 1.0999999999999865, 20.000000000000014, -0.10000000000000636, 17.899999999999988, -5.1999999999999265, 20.900000000000027, 20.000000000000014, 25.400000000000098, 20.000000000000014, 35.30000000000025, 25.4000000000001, 20.000000000000014, 27.800000000000143, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.499999999999972, 9.499999999999964, -7.299999999999912, 3.799999999999969, 32.60000000000023, 12.49999999999997, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.30000000000006, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.499999999999996, -19.899999999999743, 20.000000000000014, 38.00000000000024, -15.699999999999747, 13.699999999999966, 11.599999999999964, 32.60000000000023, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 17.899999999999988, 31.700000000000212, 20.000000000000014, -0.9999999999999881, 23.600000000000065, 15.799999999999962, 20.000000000000014, 20.000000000000014, -0.39999999999999936, 20.000000000000014, 17.599999999999984, 20.000000000000014, 9.499999999999966, 20.000000000000014, 34.400000000000254, 29.90000000000018, 3.1999999999999615, 25.400000000000098, -3.099999999999972, 5.299999999999965, 3.199999999999967, 11.599999999999964, 23.60000000000007, 20.000000000000014, 6.1999999999999655, 14.899999999999967, 20.000000000000014, 11.899999999999967, 20.000000000000014, -3.099999999999958, 9.499999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 1.099999999999983, 33.50000000000024, 20.000000000000014, 16.399999999999967, 6.1999999999999655, 20.000000000000014, 20.000000000000014, -55.600000000000236, 20.000000000000014, 17.899999999999988, 20.000000000000014, 9.199999999999966, -11.499999999999826, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, -23.799999999999756, 5.299999999999965, 9.499999999999968, 20.000000000000014, 11.599999999999971, 20.000000000000014, 20.000000000000014, 10.399999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.799999999999967, 9.499999999999964, 5.89999999999997, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 23.300000000000068, -5.1999999999999265, 20.000000000000014, -5.799999999999931, 9.499999999999964, 20.000000000000014, 6.199999999999969, -5.1999999999999265, -5.1999999999999265, 20.600000000000023, 20.000000000000014, 4.0999999999999694, 1.0999999999999652, 13.699999999999967, 7.399999999999968, 7.399999999999965, -5.1999999999999265, 35.300000000000246, 20.000000000000014, 33.50000000000024, 15.199999999999964, 20.000000000000014, 30.200000000000188, 20.000000000000014, 20.000000000000014, 34.40000000000026, 35.300000000000246, 12.799999999999967, 7.399999999999968, 20.90000000000003, 20.000000000000014, -7.299999999999891, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, 3.799999999999969, 20.000000000000014, 20.000000000000014, 31.400000000000208, -15.699999999999754, 14.299999999999969, 15.799999999999963], "policy_predator_policy_reward": [5.0, 8.0, 0.0, 0.0, 16.0, 14.0, 7.0, 0.0, 0.0, 4.0, 0.0, 6.0, 10.0, 10.0, 0.0, 10.0, 7.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 10.0, 0.0, 1.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 0.0, 15.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 12.0, 0.0, 17.0, 7.0, 3.0, 0.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 2.0, 0.0, 0.0, 8.0, 7.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 4.0, 7.0, 8.0, 13.0, 8.0, 4.0, 0.0, 3.0, 0.0, 9.0, 5.0, 5.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 4.0, 6.0, 0.0, 7.0, 0.0, 2.0, 34.0, 1.0, 0.0, 4.0, 2.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 14.0, 9.0, 12.0, 0.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 11.0, 9.0, 0.0, 11.0, 0.0, 4.0, 0.0, 4.0, 0.0, 12.0, 10.0, 10.0, 8.0, 10.0, 12.0, 0.0, 0.0, 4.0, 4.0, 8.0, 0.0, 7.0, 12.0, 6.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 1.0, 17.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5889943720362555, "mean_inference_ms": 1.8380620704620012, "mean_action_processing_ms": 0.24818825427758548, "mean_env_wait_ms": 0.19338601563205757, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003674030303955078, "StateBufferConnector_ms": 0.0030530691146850586, "ViewRequirementAgentConnector_ms": 0.08738112449645996}, "num_episodes": 18, "episode_return_max": 69.7000000000001, "episode_return_min": 0.40000000000015745, "episode_return_mean": 37.15400000000026, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.50167271035167, "num_env_steps_trained_throughput_per_sec": 402.50167271035167, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 10019.096, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10019.054, "sample_time_ms": 1316.86, "learn_time_ms": 8687.207, "learn_throughput": 460.447, "synch_weights_time_ms": 13.614}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "0b081_00000", "date": "2024-08-13_01-01-12", "timestamp": 1723525272, "time_this_iter_s": 10.001566171646118, "time_total_s": 851.6941883563995, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d16040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 851.6941883563995, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 27.742857142857137, "ram_util_percent": 83.23571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8832380743036983, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14771340221718507, "policy_loss": -0.0051535621746172195, "vf_loss": 0.15277563155907153, "vf_explained_var": -0.06850946340611372, "kl": 0.010263370151451406, "entropy": 0.8471879534935826, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6163218447751312, "cur_kl_coeff": 0.001583817601203918, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3155442516569223, "policy_loss": -0.0007431386937953965, "vf_loss": 0.316279900413519, "vf_explained_var": 0.07576243874257203, "kl": 0.004728910123363131, "entropy": 0.5772732219052693, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 69.7000000000001, "episode_reward_min": 0.40000000000015745, "episode_reward_mean": 37.49200000000026, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -55.600000000000236, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000024, "predator_policy": 34.0}, "policy_reward_mean": {"prey_policy": 15.41600000000003, "predator_policy": 3.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [63.70000000000051, 48.800000000000445, 41.800000000000324, 40.0000000000003, 30.000000000000153, 11.500000000000027, 52.1000000000005, 46.300000000000395, 40.0000000000003, 44.30000000000036, 47.200000000000415, 40.500000000000306, 19.099999999999977, 39.30000000000029, 35.30000000000023, 52.60000000000051, 36.70000000000025, 37.50000000000026, 40.0000000000003, 50.60000000000048, 29.000000000000128, 41.40000000000031, 40.0000000000003, 34.60000000000022, 39.60000000000029, 34.50000000000022, 64.3000000000005, 39.60000000000029, 23.200000000000028, 26.800000000000097, 46.600000000000406, 30.100000000000147, 41.90000000000032, 27.90000000000011, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.70000000000031, 44.60000000000037, 42.40000000000034, 33.2000000000002, 0.40000000000015745, 38.90000000000028, 35.20000000000023, 21.4, 40.0000000000003, 33.400000000000205, 39.50000000000029, 43.60000000000035, 46.300000000000395, 19.199999999999957, 26.80000000000009, 35.600000000000236, 40.0000000000003, 31.800000000000185, 40.0000000000003, 39.30000000000029, 36.900000000000254, 35.600000000000236, 47.30000000000042, 26.80000000000009, 23.700000000000042, 44.20000000000037, 1.6000000000002432, 44.60000000000037, 17.199999999999964, 28.100000000000115, 20.2, 55.3000000000005, 59.70000000000051, 52.20000000000049, 40.0000000000003, 69.7000000000001, 35.20000000000023, 40.90000000000031, 25.70000000000007, 26.100000000000072, 35.80000000000023, 40.0000000000003, 33.70000000000021, 39.100000000000286, 28.700000000000124, 40.8000000000003, 48.10000000000043, 40.0000000000003, 36.70000000000025, 40.90000000000031, 40.0000000000003, 55.300000000000495, 19.200000000000006, 9.399999999999984, 35.500000000000234, 40.0000000000003, 36.70000000000025, 52.60000000000051, 44.50000000000036, 38.90000000000028, 38.70000000000027, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [35.30000000000025, 25.4000000000001, 20.000000000000014, 27.800000000000143, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.499999999999972, 9.499999999999964, -7.299999999999912, 3.799999999999969, 32.60000000000023, 12.49999999999997, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.30000000000006, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.499999999999996, -19.899999999999743, 20.000000000000014, 38.00000000000024, -15.699999999999747, 13.699999999999966, 11.599999999999964, 32.60000000000023, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 17.899999999999988, 31.700000000000212, 20.000000000000014, -0.9999999999999881, 23.600000000000065, 15.799999999999962, 20.000000000000014, 20.000000000000014, -0.39999999999999936, 20.000000000000014, 17.599999999999984, 20.000000000000014, 9.499999999999966, 20.000000000000014, 34.400000000000254, 29.90000000000018, 3.1999999999999615, 25.400000000000098, -3.099999999999972, 5.299999999999965, 3.199999999999967, 11.599999999999964, 23.60000000000007, 20.000000000000014, 6.1999999999999655, 14.899999999999967, 20.000000000000014, 11.899999999999967, 20.000000000000014, -3.099999999999958, 9.499999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 1.099999999999983, 33.50000000000024, 20.000000000000014, 16.399999999999967, 6.1999999999999655, 20.000000000000014, 20.000000000000014, -55.600000000000236, 20.000000000000014, 17.899999999999988, 20.000000000000014, 9.199999999999966, -11.499999999999826, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, -23.799999999999756, 5.299999999999965, 9.499999999999968, 20.000000000000014, 11.599999999999971, 20.000000000000014, 20.000000000000014, 10.399999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.799999999999967, 9.499999999999964, 5.89999999999997, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 23.300000000000068, -5.1999999999999265, 20.000000000000014, -5.799999999999931, 9.499999999999964, 20.000000000000014, 6.199999999999969, -5.1999999999999265, -5.1999999999999265, 20.600000000000023, 20.000000000000014, 4.0999999999999694, 1.0999999999999652, 13.699999999999967, 7.399999999999968, 7.399999999999965, -5.1999999999999265, 35.300000000000246, 20.000000000000014, 33.50000000000024, 15.199999999999964, 20.000000000000014, 30.200000000000188, 20.000000000000014, 20.000000000000014, 34.40000000000026, 35.300000000000246, 12.799999999999967, 7.399999999999968, 20.90000000000003, 20.000000000000014, -7.299999999999891, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, 3.799999999999969, 20.000000000000014, 20.000000000000014, 31.400000000000208, -15.699999999999754, 14.299999999999969, 15.799999999999963, 8.899999999999967, 12.799999999999967, 20.000000000000014, 15.799999999999962, 20.000000000000014, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 2.8999999999999613, 5.299999999999965, -2.200000000000048, -9.399999999999915, 6.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 32.60000000000023, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.199999999999967, 24.500000000000085, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 0.0, 15.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 12.0, 0.0, 17.0, 7.0, 3.0, 0.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 2.0, 0.0, 0.0, 8.0, 7.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 4.0, 7.0, 8.0, 13.0, 8.0, 4.0, 0.0, 3.0, 0.0, 9.0, 5.0, 5.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 4.0, 6.0, 0.0, 7.0, 0.0, 2.0, 34.0, 1.0, 0.0, 4.0, 2.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 14.0, 9.0, 12.0, 0.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 11.0, 9.0, 0.0, 11.0, 0.0, 4.0, 0.0, 4.0, 0.0, 12.0, 10.0, 10.0, 8.0, 10.0, 12.0, 0.0, 0.0, 4.0, 4.0, 8.0, 0.0, 7.0, 12.0, 6.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 1.0, 17.0, 9.0, 0.0, 7.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 14.0, 6.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 8.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5887150581727861, "mean_inference_ms": 1.8377814902860854, "mean_action_processing_ms": 0.2480113901690845, "mean_env_wait_ms": 0.19322805355519118, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038672685623168945, "StateBufferConnector_ms": 0.003118157386779785, "ViewRequirementAgentConnector_ms": 0.08939135074615479}, "num_episodes": 18, "episode_return_max": 69.7000000000001, "episode_return_min": 0.40000000000015745, "episode_return_mean": 37.49200000000026, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 387.40105865784267, "num_env_steps_trained_throughput_per_sec": 387.40105865784267, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 10021.721, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10021.68, "sample_time_ms": 1320.695, "learn_time_ms": 8686.229, "learn_throughput": 460.499, "synch_weights_time_ms": 13.608}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "0b081_00000", "date": "2024-08-13_01-01-22", "timestamp": 1723525282, "time_this_iter_s": 10.331010103225708, "time_total_s": 862.0251984596252, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d579d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 862.0251984596252, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 31.035714285714285, "ram_util_percent": 83.21428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1381603233082584, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4379455785666193, "policy_loss": -0.0023063451620853608, "vf_loss": 0.4401784899950067, "vf_explained_var": 0.02829470848911023, "kl": 0.008251930739574668, "entropy": 0.8522130040580003, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8195885758846998, "cur_kl_coeff": 0.000791908800601959, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5465788724035192, "policy_loss": -0.0008829441754930904, "vf_loss": 0.5474581374653749, "vf_explained_var": -0.04852362259355172, "kl": 0.00464383842564661, "entropy": 0.5736386124419157, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 69.7000000000001, "episode_reward_min": 0.40000000000015745, "episode_reward_mean": 37.196000000000254, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -55.600000000000236, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 34.0}, "policy_reward_mean": {"prey_policy": 15.083000000000025, "predator_policy": 3.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 34.60000000000022, 39.60000000000029, 34.50000000000022, 64.3000000000005, 39.60000000000029, 23.200000000000028, 26.800000000000097, 46.600000000000406, 30.100000000000147, 41.90000000000032, 27.90000000000011, 34.50000000000022, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.70000000000031, 44.60000000000037, 42.40000000000034, 33.2000000000002, 0.40000000000015745, 38.90000000000028, 35.20000000000023, 21.4, 40.0000000000003, 33.400000000000205, 39.50000000000029, 43.60000000000035, 46.300000000000395, 19.199999999999957, 26.80000000000009, 35.600000000000236, 40.0000000000003, 31.800000000000185, 40.0000000000003, 39.30000000000029, 36.900000000000254, 35.600000000000236, 47.30000000000042, 26.80000000000009, 23.700000000000042, 44.20000000000037, 1.6000000000002432, 44.60000000000037, 17.199999999999964, 28.100000000000115, 20.2, 55.3000000000005, 59.70000000000051, 52.20000000000049, 40.0000000000003, 69.7000000000001, 35.20000000000023, 40.90000000000031, 25.70000000000007, 26.100000000000072, 35.80000000000023, 40.0000000000003, 33.70000000000021, 39.100000000000286, 28.700000000000124, 40.8000000000003, 48.10000000000043, 40.0000000000003, 36.70000000000025, 40.90000000000031, 40.0000000000003, 55.300000000000495, 19.200000000000006, 9.399999999999984, 35.500000000000234, 40.0000000000003, 36.70000000000025, 52.60000000000051, 44.50000000000036, 38.90000000000028, 38.70000000000027, 40.0000000000003, 34.50000000000022, 42.10000000000033, 45.100000000000385, 40.0000000000003, 30.10000000000021, 34.50000000000022, 40.0000000000003, 46.20000000000041, 40.0000000000003, 44.10000000000037, 35.20000000000023, 28.700000000000134, 54.4000000000005, 31.300000000000168, 39.40000000000029, 37.20000000000026, 43.60000000000035, 43.60000000000035, 24.60000000000007, 41.400000000000325, 42.80000000000034, 39.30000000000029], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -0.39999999999999936, 20.000000000000014, 17.599999999999984, 20.000000000000014, 9.499999999999966, 20.000000000000014, 34.400000000000254, 29.90000000000018, 3.1999999999999615, 25.400000000000098, -3.099999999999972, 5.299999999999965, 3.199999999999967, 11.599999999999964, 23.60000000000007, 20.000000000000014, 6.1999999999999655, 14.899999999999967, 20.000000000000014, 11.899999999999967, 20.000000000000014, -3.099999999999958, 9.499999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 1.099999999999983, 33.50000000000024, 20.000000000000014, 16.399999999999967, 6.1999999999999655, 20.000000000000014, 20.000000000000014, -55.600000000000236, 20.000000000000014, 17.899999999999988, 20.000000000000014, 9.199999999999966, -11.499999999999826, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, -23.799999999999756, 5.299999999999965, 9.499999999999968, 20.000000000000014, 11.599999999999971, 20.000000000000014, 20.000000000000014, 10.399999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.799999999999967, 9.499999999999964, 5.89999999999997, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 23.300000000000068, -5.1999999999999265, 20.000000000000014, -5.799999999999931, 9.499999999999964, 20.000000000000014, 6.199999999999969, -5.1999999999999265, -5.1999999999999265, 20.600000000000023, 20.000000000000014, 4.0999999999999694, 1.0999999999999652, 13.699999999999967, 7.399999999999968, 7.399999999999965, -5.1999999999999265, 35.300000000000246, 20.000000000000014, 33.50000000000024, 15.199999999999964, 20.000000000000014, 30.200000000000188, 20.000000000000014, 20.000000000000014, 34.40000000000026, 35.300000000000246, 12.799999999999967, 7.399999999999968, 20.90000000000003, 20.000000000000014, -7.299999999999891, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, 3.799999999999969, 20.000000000000014, 20.000000000000014, 31.400000000000208, -15.699999999999754, 14.299999999999969, 15.799999999999963, 8.899999999999967, 12.799999999999967, 20.000000000000014, 15.799999999999962, 20.000000000000014, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 2.8999999999999613, 5.299999999999965, -2.200000000000048, -9.399999999999915, 6.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 32.60000000000023, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.199999999999967, 24.500000000000085, 20.000000000000014, 20.000000000000014, 0.49999999999998657, 20.000000000000014, -0.9999999999999846, 28.100000000000147, 20.000000000000014, 19.100000000000005, 20.000000000000014, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 36.20000000000025, 21.80000000000004, 7.399999999999967, 5.299999999999972, 7.39999999999997, 34.400000000000254, 20.000000000000014, 7.399999999999965, 17.899999999999988, -3.099999999999965, 30.500000000000192, 7.399999999999965, 21.80000000000004, 20.000000000000014, 23.600000000000065, 22.700000000000053, 20.90000000000003, 17.900000000000013, -7.299999999999891, 12.499999999999975, 17.899999999999988, 20.000000000000014, 18.799999999999997, 20.000000000000014, 11.299999999999969], "policy_predator_policy_reward": [0.0, 0.0, 8.0, 7.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 4.0, 7.0, 8.0, 13.0, 8.0, 4.0, 0.0, 3.0, 0.0, 9.0, 5.0, 5.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 4.0, 6.0, 0.0, 7.0, 0.0, 2.0, 34.0, 1.0, 0.0, 4.0, 2.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 14.0, 9.0, 12.0, 0.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 11.0, 9.0, 0.0, 11.0, 0.0, 4.0, 0.0, 4.0, 0.0, 12.0, 10.0, 10.0, 8.0, 10.0, 12.0, 0.0, 0.0, 4.0, 4.0, 8.0, 0.0, 7.0, 12.0, 6.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 1.0, 17.0, 9.0, 0.0, 7.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 14.0, 6.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 8.0, 0.0, 0.0, 7.0, 7.0, 10.0, 5.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 9.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 13.0, 4.0, 7.0, 0.0, 4.0, 0.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5883607914699834, "mean_inference_ms": 1.8373567818003205, "mean_action_processing_ms": 0.24778850933941393, "mean_env_wait_ms": 0.19302919720178394, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003879070281982422, "StateBufferConnector_ms": 0.003174424171447754, "ViewRequirementAgentConnector_ms": 0.09117770195007324}, "num_episodes": 22, "episode_return_max": 69.7000000000001, "episode_return_min": 0.40000000000015745, "episode_return_mean": 37.196000000000254, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 396.06618821265823, "num_env_steps_trained_throughput_per_sec": 396.06618821265823, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 10069.768, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10069.727, "sample_time_ms": 1312.441, "learn_time_ms": 8742.601, "learn_throughput": 457.53, "synch_weights_time_ms": 13.561}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "0b081_00000", "date": "2024-08-13_01-01-32", "timestamp": 1723525292, "time_this_iter_s": 10.104318857192993, "time_total_s": 872.1295173168182, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d1a3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 872.1295173168182, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 28.926666666666666, "ram_util_percent": 83.16666666666669}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3525259099940143, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0434813571985437, "policy_loss": -0.005601212229806358, "vf_loss": 1.049012351674693, "vf_explained_var": 0.015530902683419525, "kl": 0.007890173619697214, "entropy": 0.8149282716569446, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8905464661815179, "cur_kl_coeff": 0.0003959544003009795, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4142039035520857, "policy_loss": -0.0014086968689250253, "vf_loss": 1.415610878745084, "vf_explained_var": -0.004406065663332662, "kl": 0.004353083438673422, "entropy": 0.5759082785989872, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 69.7000000000001, "episode_reward_min": -123.49999999999982, "episode_reward_mean": 35.93000000000027, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -99.69999999999982, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 34.0}, "policy_reward_mean": {"prey_policy": 14.315000000000031, "predator_policy": 3.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.40000000000034, 33.2000000000002, 0.40000000000015745, 38.90000000000028, 35.20000000000023, 21.4, 40.0000000000003, 33.400000000000205, 39.50000000000029, 43.60000000000035, 46.300000000000395, 19.199999999999957, 26.80000000000009, 35.600000000000236, 40.0000000000003, 31.800000000000185, 40.0000000000003, 39.30000000000029, 36.900000000000254, 35.600000000000236, 47.30000000000042, 26.80000000000009, 23.700000000000042, 44.20000000000037, 1.6000000000002432, 44.60000000000037, 17.199999999999964, 28.100000000000115, 20.2, 55.3000000000005, 59.70000000000051, 52.20000000000049, 40.0000000000003, 69.7000000000001, 35.20000000000023, 40.90000000000031, 25.70000000000007, 26.100000000000072, 35.80000000000023, 40.0000000000003, 33.70000000000021, 39.100000000000286, 28.700000000000124, 40.8000000000003, 48.10000000000043, 40.0000000000003, 36.70000000000025, 40.90000000000031, 40.0000000000003, 55.300000000000495, 19.200000000000006, 9.399999999999984, 35.500000000000234, 40.0000000000003, 36.70000000000025, 52.60000000000051, 44.50000000000036, 38.90000000000028, 38.70000000000027, 40.0000000000003, 34.50000000000022, 42.10000000000033, 45.100000000000385, 40.0000000000003, 30.10000000000021, 34.50000000000022, 40.0000000000003, 46.20000000000041, 40.0000000000003, 44.10000000000037, 35.20000000000023, 28.700000000000134, 54.4000000000005, 31.300000000000168, 39.40000000000029, 37.20000000000026, 43.60000000000035, 43.60000000000035, 24.60000000000007, 41.400000000000325, 42.80000000000034, 39.30000000000029, 50.20000000000047, 40.0000000000003, 40.80000000000031, 40.0000000000003, 44.50000000000036, 47.500000000000426, 53.50000000000051, -123.49999999999982, 6.100000000000096, 40.0000000000003, 40.0000000000003, 47.90000000000049, 30.100000000000147, 37.000000000000455, 30.40000000000029, 41.60000000000032, 54.4000000000005, 41.800000000000324], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 16.399999999999967, 6.1999999999999655, 20.000000000000014, 20.000000000000014, -55.600000000000236, 20.000000000000014, 17.899999999999988, 20.000000000000014, 9.199999999999966, -11.499999999999826, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 20.000000000000014, 26.300000000000114, 20.000000000000014, -23.799999999999756, 5.299999999999965, 9.499999999999968, 20.000000000000014, 11.599999999999971, 20.000000000000014, 20.000000000000014, 10.399999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, 9.799999999999967, 9.499999999999964, 5.89999999999997, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 23.300000000000068, -5.1999999999999265, 20.000000000000014, -5.799999999999931, 9.499999999999964, 20.000000000000014, 6.199999999999969, -5.1999999999999265, -5.1999999999999265, 20.600000000000023, 20.000000000000014, 4.0999999999999694, 1.0999999999999652, 13.699999999999967, 7.399999999999968, 7.399999999999965, -5.1999999999999265, 35.300000000000246, 20.000000000000014, 33.50000000000024, 15.199999999999964, 20.000000000000014, 30.200000000000188, 20.000000000000014, 20.000000000000014, 34.40000000000026, 35.300000000000246, 12.799999999999967, 7.399999999999968, 20.90000000000003, 20.000000000000014, -7.299999999999891, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, 3.799999999999969, 20.000000000000014, 20.000000000000014, 31.400000000000208, -15.699999999999754, 14.299999999999969, 15.799999999999963, 8.899999999999967, 12.799999999999967, 20.000000000000014, 15.799999999999962, 20.000000000000014, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 2.8999999999999613, 5.299999999999965, -2.200000000000048, -9.399999999999915, 6.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 32.60000000000023, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.199999999999967, 24.500000000000085, 20.000000000000014, 20.000000000000014, 0.49999999999998657, 20.000000000000014, -0.9999999999999846, 28.100000000000147, 20.000000000000014, 19.100000000000005, 20.000000000000014, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 36.20000000000025, 21.80000000000004, 7.399999999999967, 5.299999999999972, 7.39999999999997, 34.400000000000254, 20.000000000000014, 7.399999999999965, 17.899999999999988, -3.099999999999965, 30.500000000000192, 7.399999999999965, 21.80000000000004, 20.000000000000014, 23.600000000000065, 22.700000000000053, 20.90000000000003, 17.900000000000013, -7.299999999999891, 12.499999999999975, 17.899999999999988, 20.000000000000014, 18.799999999999997, 20.000000000000014, 11.299999999999969, 27.200000000000134, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 20.90000000000003, 23.600000000000065, 24.50000000000009, 20.000000000000014, 20.000000000000014, 33.50000000000024, -99.69999999999982, -80.79999999999981, -21.999999999999766, -1.9000000000000141, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.299999999999965, 26.600000000000154, 20.000000000000014, 1.099999999999983, 29.600000000000176, -13.60000000000002, 13.70000000000001, 13.70000000000001, 17.899999999999984, 22.700000000000053, 34.40000000000025, 20.000000000000014, 20.000000000000014, 21.80000000000004], "policy_predator_policy_reward": [6.0, 0.0, 7.0, 0.0, 2.0, 34.0, 1.0, 0.0, 4.0, 2.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 14.0, 9.0, 12.0, 0.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 11.0, 9.0, 0.0, 11.0, 0.0, 4.0, 0.0, 4.0, 0.0, 12.0, 10.0, 10.0, 8.0, 10.0, 12.0, 0.0, 0.0, 4.0, 4.0, 8.0, 0.0, 7.0, 12.0, 6.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 1.0, 17.0, 9.0, 0.0, 7.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 14.0, 6.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 8.0, 0.0, 0.0, 7.0, 7.0, 10.0, 5.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 9.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 13.0, 4.0, 7.0, 0.0, 4.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 30.0, 27.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 9.0, 0.0, 5.0, 16.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5879629651036352, "mean_inference_ms": 1.8366605995227336, "mean_action_processing_ms": 0.2475645276907588, "mean_env_wait_ms": 0.19282884535710856, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003942370414733887, "StateBufferConnector_ms": 0.0032427310943603516, "ViewRequirementAgentConnector_ms": 0.09129095077514648}, "num_episodes": 18, "episode_return_max": 69.7000000000001, "episode_return_min": -123.49999999999982, "episode_return_mean": 35.93000000000027, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 396.33408097305534, "num_env_steps_trained_throughput_per_sec": 396.33408097305534, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 10089.08, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10089.039, "sample_time_ms": 1313.711, "learn_time_ms": 8760.914, "learn_throughput": 456.573, "synch_weights_time_ms": 13.319}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "0b081_00000", "date": "2024-08-13_01-01-43", "timestamp": 1723525303, "time_this_iter_s": 10.157829999923706, "time_total_s": 882.287347316742, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f21670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 882.287347316742, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 30.742857142857144, "ram_util_percent": 83.44285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.219700120034672, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.534933291817153, "policy_loss": -0.004742092892364968, "vf_loss": 0.5395445163445498, "vf_explained_var": 0.035659221366599755, "kl": 0.014706094120598917, "entropy": 0.7782710540231573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.879951875798759, "cur_kl_coeff": 0.00019797720015048975, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6725930959617019, "policy_loss": -0.001409904962090194, "vf_loss": 0.6740023229763936, "vf_explained_var": -0.010681948869947402, "kl": 0.0034225284341985593, "entropy": 0.5947040195818301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 69.7000000000001, "episode_reward_min": -123.49999999999982, "episode_reward_mean": 35.730000000000274, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -101.80000000000064, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": 13.790000000000028, "predator_policy": 4.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.20000000000037, 1.6000000000002432, 44.60000000000037, 17.199999999999964, 28.100000000000115, 20.2, 55.3000000000005, 59.70000000000051, 52.20000000000049, 40.0000000000003, 69.7000000000001, 35.20000000000023, 40.90000000000031, 25.70000000000007, 26.100000000000072, 35.80000000000023, 40.0000000000003, 33.70000000000021, 39.100000000000286, 28.700000000000124, 40.8000000000003, 48.10000000000043, 40.0000000000003, 36.70000000000025, 40.90000000000031, 40.0000000000003, 55.300000000000495, 19.200000000000006, 9.399999999999984, 35.500000000000234, 40.0000000000003, 36.70000000000025, 52.60000000000051, 44.50000000000036, 38.90000000000028, 38.70000000000027, 40.0000000000003, 34.50000000000022, 42.10000000000033, 45.100000000000385, 40.0000000000003, 30.10000000000021, 34.50000000000022, 40.0000000000003, 46.20000000000041, 40.0000000000003, 44.10000000000037, 35.20000000000023, 28.700000000000134, 54.4000000000005, 31.300000000000168, 39.40000000000029, 37.20000000000026, 43.60000000000035, 43.60000000000035, 24.60000000000007, 41.400000000000325, 42.80000000000034, 39.30000000000029, 50.20000000000047, 40.0000000000003, 40.80000000000031, 40.0000000000003, 44.50000000000036, 47.500000000000426, 53.50000000000051, -123.49999999999982, 6.100000000000096, 40.0000000000003, 40.0000000000003, 47.90000000000049, 30.100000000000147, 37.000000000000455, 30.40000000000029, 41.60000000000032, 54.4000000000005, 41.800000000000324, 45.9000000000004, -16.59999999999969, 20.899999999999988, 45.50000000000039, 26.20000000000008, 53.300000000000516, 34.30000000000022, 39.50000000000029, 39.600000000000286, 40.0000000000003, 44.00000000000036, 40.1000000000003, 40.80000000000031, 18.799999999999997, 20.2000000000003, 35.600000000000236, 24.90000000000008, 36.80000000000025, 52.60000000000051, 35.00000000000023, 3.600000000000117, 26.100000000000087, 50.20000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 6.199999999999969, -5.1999999999999265, -5.1999999999999265, 20.600000000000023, 20.000000000000014, 4.0999999999999694, 1.0999999999999652, 13.699999999999967, 7.399999999999968, 7.399999999999965, -5.1999999999999265, 35.300000000000246, 20.000000000000014, 33.50000000000024, 15.199999999999964, 20.000000000000014, 30.200000000000188, 20.000000000000014, 20.000000000000014, 34.40000000000026, 35.300000000000246, 12.799999999999967, 7.399999999999968, 20.90000000000003, 20.000000000000014, -7.299999999999891, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, 3.799999999999969, 20.000000000000014, 20.000000000000014, 31.400000000000208, -15.699999999999754, 14.299999999999969, 15.799999999999963, 8.899999999999967, 12.799999999999967, 20.000000000000014, 15.799999999999962, 20.000000000000014, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 2.8999999999999613, 5.299999999999965, -2.200000000000048, -9.399999999999915, 6.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 32.60000000000023, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.199999999999967, 24.500000000000085, 20.000000000000014, 20.000000000000014, 0.49999999999998657, 20.000000000000014, -0.9999999999999846, 28.100000000000147, 20.000000000000014, 19.100000000000005, 20.000000000000014, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 36.20000000000025, 21.80000000000004, 7.399999999999967, 5.299999999999972, 7.39999999999997, 34.400000000000254, 20.000000000000014, 7.399999999999965, 17.899999999999988, -3.099999999999965, 30.500000000000192, 7.399999999999965, 21.80000000000004, 20.000000000000014, 23.600000000000065, 22.700000000000053, 20.90000000000003, 17.900000000000013, -7.299999999999891, 12.499999999999975, 17.899999999999988, 20.000000000000014, 18.799999999999997, 20.000000000000014, 11.299999999999969, 27.200000000000134, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 20.90000000000003, 23.600000000000065, 24.50000000000009, 20.000000000000014, 20.000000000000014, 33.50000000000024, -99.69999999999982, -80.79999999999981, -21.999999999999766, -1.9000000000000141, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.299999999999965, 26.600000000000154, 20.000000000000014, 1.099999999999983, 29.600000000000176, -13.60000000000002, 13.70000000000001, 13.70000000000001, 17.899999999999984, 22.700000000000053, 34.40000000000025, 20.000000000000014, 20.000000000000014, 21.80000000000004, 23.000000000000057, 20.90000000000003, 27.20000000000013, -101.80000000000064, -9.699999999999989, 11.599999999999964, 21.500000000000036, 20.000000000000014, 20.000000000000014, -8.799999999999875, 20.000000000000014, 32.300000000000225, 8.299999999999965, 20.000000000000014, 12.499999999999972, 20.000000000000014, 17.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 11.599999999999968, 23.900000000000073, 6.199999999999969, 19.400000000000006, 19.400000000000006, -6.399999999999908, 9.199999999999966, -23.800000000000022, 20.000000000000014, 11.599999999999964, 20.000000000000014, -6.399999999999922, 5.299999999999965, 23.900000000000077, -3.0999999999999757, 20.000000000000014, 32.60000000000023, 9.199999999999969, 9.799999999999967, 25.400000000000098, -59.800000000000566, 1.9999999999999731, 4.099999999999971, 17.899999999999988, 29.30000000000017], "policy_predator_policy_reward": [8.0, 10.0, 12.0, 0.0, 0.0, 4.0, 4.0, 8.0, 0.0, 7.0, 12.0, 6.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 1.0, 17.0, 9.0, 0.0, 7.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 14.0, 6.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 8.0, 0.0, 0.0, 7.0, 7.0, 10.0, 5.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 9.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 13.0, 4.0, 7.0, 0.0, 4.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 30.0, 27.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 9.0, 0.0, 5.0, 16.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 52.0, 6.0, 5.0, 14.0, 4.0, 0.0, 5.0, 10.0, 1.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 2.0, 0.0, 10.0, 6.0, 8.0, 16.0, 0.0, 4.0, 13.0, 13.0, 5.0, 11.0, 0.0, 0.0, 7.0, 9.0, 38.0, 0.0, 4.0, 16.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5874486349933687, "mean_inference_ms": 1.8360774433589537, "mean_action_processing_ms": 0.24733339719557254, "mean_env_wait_ms": 0.1926697182102458, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003900766372680664, "StateBufferConnector_ms": 0.0030455589294433594, "ViewRequirementAgentConnector_ms": 0.09308195114135742}, "num_episodes": 23, "episode_return_max": 69.7000000000001, "episode_return_min": -123.49999999999982, "episode_return_mean": 35.730000000000274, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.33475092491676, "num_env_steps_trained_throughput_per_sec": 398.33475092491676, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 10069.998, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10069.959, "sample_time_ms": 1319.944, "learn_time_ms": 8735.482, "learn_throughput": 457.903, "synch_weights_time_ms": 13.481}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "0b081_00000", "date": "2024-08-13_01-01-53", "timestamp": 1723525313, "time_this_iter_s": 10.046837091445923, "time_total_s": 892.3341844081879, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d778b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 892.3341844081879, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 29.6, "ram_util_percent": 83.47333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.459479250486881, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.071967778918604, "policy_loss": -0.002596044250906854, "vf_loss": 2.0745084536138667, "vf_explained_var": 0.004754274326657492, "kl": 0.00622160991349119, "entropy": 0.7630400561466419, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6242469550578524, "cur_kl_coeff": 9.898860007524487e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7679980949434653, "policy_loss": -0.001496087659702257, "vf_loss": 1.7694934551993375, "vf_explained_var": 0.0005809590930030459, "kl": 0.007334482661375308, "entropy": 0.4915958672604233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 55.300000000000495, "episode_reward_min": -123.49999999999982, "episode_reward_mean": 32.95500000000028, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -135.4000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 69.0}, "policy_reward_mean": {"prey_policy": 10.452500000000022, "predator_policy": 6.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.100000000000286, 28.700000000000124, 40.8000000000003, 48.10000000000043, 40.0000000000003, 36.70000000000025, 40.90000000000031, 40.0000000000003, 55.300000000000495, 19.200000000000006, 9.399999999999984, 35.500000000000234, 40.0000000000003, 36.70000000000025, 52.60000000000051, 44.50000000000036, 38.90000000000028, 38.70000000000027, 40.0000000000003, 34.50000000000022, 42.10000000000033, 45.100000000000385, 40.0000000000003, 30.10000000000021, 34.50000000000022, 40.0000000000003, 46.20000000000041, 40.0000000000003, 44.10000000000037, 35.20000000000023, 28.700000000000134, 54.4000000000005, 31.300000000000168, 39.40000000000029, 37.20000000000026, 43.60000000000035, 43.60000000000035, 24.60000000000007, 41.400000000000325, 42.80000000000034, 39.30000000000029, 50.20000000000047, 40.0000000000003, 40.80000000000031, 40.0000000000003, 44.50000000000036, 47.500000000000426, 53.50000000000051, -123.49999999999982, 6.100000000000096, 40.0000000000003, 40.0000000000003, 47.90000000000049, 30.100000000000147, 37.000000000000455, 30.40000000000029, 41.60000000000032, 54.4000000000005, 41.800000000000324, 45.9000000000004, -16.59999999999969, 20.899999999999988, 45.50000000000039, 26.20000000000008, 53.300000000000516, 34.30000000000022, 39.50000000000029, 39.600000000000286, 40.0000000000003, 44.00000000000036, 40.1000000000003, 40.80000000000031, 18.799999999999997, 20.2000000000003, 35.600000000000236, 24.90000000000008, 36.80000000000025, 52.60000000000051, 35.00000000000023, 3.600000000000117, 26.100000000000087, 50.20000000000047, 49.500000000000455, 6.500000000000101, -18.00000000000002, 49.90000000000046, 32.30000000000018, -17.800000000000033, 49.30000000000046, 38.70000000000027, 38.800000000000345, 5.400000000000054, -5.400000000000089, 43.00000000000035, -16.30000000000004, 31.200000000000173, 52.20000000000051, -19.09999999999986, 40.0000000000003, 32.500000000000185], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [14.299999999999969, 15.799999999999963, 8.899999999999967, 12.799999999999967, 20.000000000000014, 15.799999999999962, 20.000000000000014, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 2.8999999999999613, 5.299999999999965, -2.200000000000048, -9.399999999999915, 6.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 32.60000000000023, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 17.899999999999988, 3.199999999999967, 24.500000000000085, 20.000000000000014, 20.000000000000014, 0.49999999999998657, 20.000000000000014, -0.9999999999999846, 28.100000000000147, 20.000000000000014, 19.100000000000005, 20.000000000000014, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 36.20000000000025, 21.80000000000004, 7.399999999999967, 5.299999999999972, 7.39999999999997, 34.400000000000254, 20.000000000000014, 7.399999999999965, 17.899999999999988, -3.099999999999965, 30.500000000000192, 7.399999999999965, 21.80000000000004, 20.000000000000014, 23.600000000000065, 22.700000000000053, 20.90000000000003, 17.900000000000013, -7.299999999999891, 12.499999999999975, 17.899999999999988, 20.000000000000014, 18.799999999999997, 20.000000000000014, 11.299999999999969, 27.200000000000134, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 20.90000000000003, 23.600000000000065, 24.50000000000009, 20.000000000000014, 20.000000000000014, 33.50000000000024, -99.69999999999982, -80.79999999999981, -21.999999999999766, -1.9000000000000141, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.299999999999965, 26.600000000000154, 20.000000000000014, 1.099999999999983, 29.600000000000176, -13.60000000000002, 13.70000000000001, 13.70000000000001, 17.899999999999984, 22.700000000000053, 34.40000000000025, 20.000000000000014, 20.000000000000014, 21.80000000000004, 23.000000000000057, 20.90000000000003, 27.20000000000013, -101.80000000000064, -9.699999999999989, 11.599999999999964, 21.500000000000036, 20.000000000000014, 20.000000000000014, -8.799999999999875, 20.000000000000014, 32.300000000000225, 8.299999999999965, 20.000000000000014, 12.499999999999972, 20.000000000000014, 17.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 11.599999999999968, 23.900000000000073, 6.199999999999969, 19.400000000000006, 19.400000000000006, -6.399999999999908, 9.199999999999966, -23.800000000000022, 20.000000000000014, 11.599999999999964, 20.000000000000014, -6.399999999999922, 5.299999999999965, 23.900000000000077, -3.0999999999999757, 20.000000000000014, 32.60000000000023, 9.199999999999969, 9.799999999999967, 25.400000000000098, -59.800000000000566, 1.9999999999999731, 4.099999999999971, 17.899999999999988, 29.30000000000017, 20.000000000000014, 27.50000000000014, 5.299999999999976, -17.799999999999763, -119.80000000000001, 21.80000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 5.299999999999965, -112.30000000000013, -11.499999999999819, 26.300000000000118, 20.000000000000014, 20.000000000000014, 7.699999999999971, 5.900000000000002, 17.899999999999988, -49.29999999999994, 16.69999999999997, 20.000000000000014, -135.4000000000003, 13.399999999999972, 17.59999999999998, -89.19999999999999, 20.90000000000003, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 30.200000000000188, -89.80000000000027, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.499999999999986], "policy_predator_policy_reward": [9.0, 0.0, 7.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 14.0, 6.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 8.0, 0.0, 0.0, 7.0, 7.0, 10.0, 5.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 9.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 13.0, 4.0, 7.0, 0.0, 4.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 30.0, 27.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 9.0, 0.0, 5.0, 16.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 52.0, 6.0, 5.0, 14.0, 4.0, 0.0, 5.0, 10.0, 1.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 2.0, 0.0, 10.0, 6.0, 8.0, 16.0, 0.0, 4.0, 13.0, 13.0, 5.0, 11.0, 0.0, 0.0, 7.0, 9.0, 38.0, 0.0, 4.0, 16.0, 2.0, 1.0, 2.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 7.0, 0.0, 44.0, 62.0, 3.0, 0.0, 0.0, 11.0, 14.0, 1.0, 5.0, 33.0, 41.0, 69.0, 0.0, 12.0, 44.0, 8.0, 3.0, 5.0, 2.0, 0.0, 54.0, 3.0, 0.0, 0.0, 0.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5870716633148969, "mean_inference_ms": 1.8356244645662831, "mean_action_processing_ms": 0.24716902766470528, "mean_env_wait_ms": 0.19256030374296845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003980040550231934, "StateBufferConnector_ms": 0.0030940771102905273, "ViewRequirementAgentConnector_ms": 0.09278619289398193}, "num_episodes": 18, "episode_return_max": 55.300000000000495, "episode_return_min": -123.49999999999982, "episode_return_mean": 32.95500000000028, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.4211385076235, "num_env_steps_trained_throughput_per_sec": 404.4211385076235, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 10055.915, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10055.876, "sample_time_ms": 1312.16, "learn_time_ms": 8728.996, "learn_throughput": 458.243, "synch_weights_time_ms": 13.516}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "0b081_00000", "date": "2024-08-13_01-02-03", "timestamp": 1723525323, "time_this_iter_s": 9.898833274841309, "time_total_s": 902.2330176830292, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f21b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 902.2330176830292, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 28.814285714285713, "ram_util_percent": 83.45714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5314963786453797, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5966879620123162, "policy_loss": -0.007526651017426971, "vf_loss": 1.6040694823656132, "vf_explained_var": 0.002876097941524768, "kl": 0.016308435392184725, "entropy": 0.7437047920845173, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7404837373998903, "cur_kl_coeff": 9.898860007524487e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5395699241016276, "policy_loss": -0.001372836080808488, "vf_loss": 1.540942533353649, "vf_explained_var": -0.00482923946683369, "kl": 0.0023241300301114274, "entropy": 0.5016349641892014, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 54.4000000000005, "episode_reward_min": -123.49999999999982, "episode_reward_mean": 29.697000000000266, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -238.30000000000015, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 123.0}, "policy_reward_mean": {"prey_policy": 7.0535000000000245, "predator_policy": 7.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 30.10000000000021, 34.50000000000022, 40.0000000000003, 46.20000000000041, 40.0000000000003, 44.10000000000037, 35.20000000000023, 28.700000000000134, 54.4000000000005, 31.300000000000168, 39.40000000000029, 37.20000000000026, 43.60000000000035, 43.60000000000035, 24.60000000000007, 41.400000000000325, 42.80000000000034, 39.30000000000029, 50.20000000000047, 40.0000000000003, 40.80000000000031, 40.0000000000003, 44.50000000000036, 47.500000000000426, 53.50000000000051, -123.49999999999982, 6.100000000000096, 40.0000000000003, 40.0000000000003, 47.90000000000049, 30.100000000000147, 37.000000000000455, 30.40000000000029, 41.60000000000032, 54.4000000000005, 41.800000000000324, 45.9000000000004, -16.59999999999969, 20.899999999999988, 45.50000000000039, 26.20000000000008, 53.300000000000516, 34.30000000000022, 39.50000000000029, 39.600000000000286, 40.0000000000003, 44.00000000000036, 40.1000000000003, 40.80000000000031, 18.799999999999997, 20.2000000000003, 35.600000000000236, 24.90000000000008, 36.80000000000025, 52.60000000000051, 35.00000000000023, 3.600000000000117, 26.100000000000087, 50.20000000000047, 49.500000000000455, 6.500000000000101, -18.00000000000002, 49.90000000000046, 32.30000000000018, -17.800000000000033, 49.30000000000046, 38.70000000000027, 38.800000000000345, 5.400000000000054, -5.400000000000089, 43.00000000000035, -16.30000000000004, 31.200000000000173, 52.20000000000051, -19.09999999999986, 40.0000000000003, 32.500000000000185, 24.600000000000048, 46.600000000000406, 22.400000000000322, 39.100000000000286, 40.0000000000003, 42.80000000000034, 40.0000000000003, 29.300000000000136, 53.50000000000051, -84.30000000000004, 32.40000000000019, 34.00000000000039, -3.300000000000056, 29.70000000000028, 47.200000000000415, 9.300000000000097, 51.00000000000049, 32.800000000000196, 31.200000000000166, -95.30000000000021, 50.80000000000048, 47.200000000000415], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, 21.20000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 36.20000000000025, 21.80000000000004, 7.399999999999967, 5.299999999999972, 7.39999999999997, 34.400000000000254, 20.000000000000014, 7.399999999999965, 17.899999999999988, -3.099999999999965, 30.500000000000192, 7.399999999999965, 21.80000000000004, 20.000000000000014, 23.600000000000065, 22.700000000000053, 20.90000000000003, 17.900000000000013, -7.299999999999891, 12.499999999999975, 17.899999999999988, 20.000000000000014, 18.799999999999997, 20.000000000000014, 11.299999999999969, 27.200000000000134, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 20.90000000000003, 23.600000000000065, 24.50000000000009, 20.000000000000014, 20.000000000000014, 33.50000000000024, -99.69999999999982, -80.79999999999981, -21.999999999999766, -1.9000000000000141, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.299999999999965, 26.600000000000154, 20.000000000000014, 1.099999999999983, 29.600000000000176, -13.60000000000002, 13.70000000000001, 13.70000000000001, 17.899999999999984, 22.700000000000053, 34.40000000000025, 20.000000000000014, 20.000000000000014, 21.80000000000004, 23.000000000000057, 20.90000000000003, 27.20000000000013, -101.80000000000064, -9.699999999999989, 11.599999999999964, 21.500000000000036, 20.000000000000014, 20.000000000000014, -8.799999999999875, 20.000000000000014, 32.300000000000225, 8.299999999999965, 20.000000000000014, 12.499999999999972, 20.000000000000014, 17.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 11.599999999999968, 23.900000000000073, 6.199999999999969, 19.400000000000006, 19.400000000000006, -6.399999999999908, 9.199999999999966, -23.800000000000022, 20.000000000000014, 11.599999999999964, 20.000000000000014, -6.399999999999922, 5.299999999999965, 23.900000000000077, -3.0999999999999757, 20.000000000000014, 32.60000000000023, 9.199999999999969, 9.799999999999967, 25.400000000000098, -59.800000000000566, 1.9999999999999731, 4.099999999999971, 17.899999999999988, 29.30000000000017, 20.000000000000014, 27.50000000000014, 5.299999999999976, -17.799999999999763, -119.80000000000001, 21.80000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 5.299999999999965, -112.30000000000013, -11.499999999999819, 26.300000000000118, 20.000000000000014, 20.000000000000014, 7.699999999999971, 5.900000000000002, 17.899999999999988, -49.29999999999994, 16.69999999999997, 20.000000000000014, -135.4000000000003, 13.399999999999972, 17.59999999999998, -89.19999999999999, 20.90000000000003, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 30.200000000000188, -89.80000000000027, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.499999999999986, 4.099999999999966, 9.499999999999964, 20.900000000000027, 22.700000000000053, -32.49999999999993, 29.90000000000018, 23.600000000000065, 6.499999999999968, 20.000000000000014, 20.000000000000014, 18.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 9.799999999999967, 33.50000000000024, 20.000000000000014, -160.60000000000005, -36.69999999999979, 1.3999999999999655, 20.000000000000014, -12.999999999999956, 20.000000000000014, -16.899999999999785, -51.40000000000002, -1.3000000000000331, 20.000000000000014, 27.20000000000013, 20.000000000000014, 7.699999999999967, -30.400000000000006, 9.499999999999968, 33.50000000000024, 3.7999999999999656, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -238.30000000000015, 20.000000000000014, 30.800000000000196, 22.700000000000053, 24.50000000000008], "policy_predator_policy_reward": [0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 9.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 13.0, 4.0, 7.0, 0.0, 4.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 30.0, 27.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 9.0, 0.0, 5.0, 16.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 52.0, 6.0, 5.0, 14.0, 4.0, 0.0, 5.0, 10.0, 1.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 2.0, 0.0, 10.0, 6.0, 8.0, 16.0, 0.0, 4.0, 13.0, 13.0, 5.0, 11.0, 0.0, 0.0, 7.0, 9.0, 38.0, 0.0, 4.0, 16.0, 2.0, 1.0, 2.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 7.0, 0.0, 44.0, 62.0, 3.0, 0.0, 0.0, 11.0, 14.0, 1.0, 5.0, 33.0, 41.0, 69.0, 0.0, 12.0, 44.0, 8.0, 3.0, 5.0, 2.0, 0.0, 54.0, 3.0, 0.0, 0.0, 0.0, 15.0, 3.0, 8.0, 3.0, 0.0, 23.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 86.0, 27.0, 6.0, 5.0, 18.0, 9.0, 30.0, 35.0, 9.0, 2.0, 0.0, 0.0, 13.0, 19.0, 0.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5867252198832731, "mean_inference_ms": 1.8353457788964145, "mean_action_processing_ms": 0.2470302135696302, "mean_env_wait_ms": 0.19242465031786424, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003986358642578125, "StateBufferConnector_ms": 0.0030792951583862305, "ViewRequirementAgentConnector_ms": 0.09425985813140869}, "num_episodes": 22, "episode_return_max": 54.4000000000005, "episode_return_min": -123.49999999999982, "episode_return_mean": 29.697000000000266, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 392.2134625555283, "num_env_steps_trained_throughput_per_sec": 392.2134625555283, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 10090.386, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10090.347, "sample_time_ms": 1322.464, "learn_time_ms": 8753.186, "learn_throughput": 456.976, "synch_weights_time_ms": 13.421}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "0b081_00000", "date": "2024-08-13_01-02-13", "timestamp": 1723525333, "time_this_iter_s": 10.209733247756958, "time_total_s": 912.4427509307861, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f21700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 912.4427509307861, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 29.142857142857142, "ram_util_percent": 83.19285714285716}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6351719185473428, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.105668360846383, "policy_loss": -0.004155188267705617, "vf_loss": 3.1097391392188096, "vf_explained_var": 0.0003667429326072572, "kl": 0.00948616818207185, "entropy": 0.7250224531958342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1826379396809787, "cur_kl_coeff": 4.949430003762244e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7817600963607667, "policy_loss": -0.002440998513281109, "vf_loss": 2.7842008872006936, "vf_explained_var": 0.0020660517707703605, "kl": 0.004264639289151149, "entropy": 0.5000826630012069, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 58.40000000000051, "episode_reward_min": -123.49999999999982, "episode_reward_mean": 25.30900000000025, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -238.30000000000015, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000025, "predator_policy": 123.0}, "policy_reward_mean": {"prey_policy": 2.1845000000000216, "predator_policy": 10.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.30000000000029, 50.20000000000047, 40.0000000000003, 40.80000000000031, 40.0000000000003, 44.50000000000036, 47.500000000000426, 53.50000000000051, -123.49999999999982, 6.100000000000096, 40.0000000000003, 40.0000000000003, 47.90000000000049, 30.100000000000147, 37.000000000000455, 30.40000000000029, 41.60000000000032, 54.4000000000005, 41.800000000000324, 45.9000000000004, -16.59999999999969, 20.899999999999988, 45.50000000000039, 26.20000000000008, 53.300000000000516, 34.30000000000022, 39.50000000000029, 39.600000000000286, 40.0000000000003, 44.00000000000036, 40.1000000000003, 40.80000000000031, 18.799999999999997, 20.2000000000003, 35.600000000000236, 24.90000000000008, 36.80000000000025, 52.60000000000051, 35.00000000000023, 3.600000000000117, 26.100000000000087, 50.20000000000047, 49.500000000000455, 6.500000000000101, -18.00000000000002, 49.90000000000046, 32.30000000000018, -17.800000000000033, 49.30000000000046, 38.70000000000027, 38.800000000000345, 5.400000000000054, -5.400000000000089, 43.00000000000035, -16.30000000000004, 31.200000000000173, 52.20000000000051, -19.09999999999986, 40.0000000000003, 32.500000000000185, 24.600000000000048, 46.600000000000406, 22.400000000000322, 39.100000000000286, 40.0000000000003, 42.80000000000034, 40.0000000000003, 29.300000000000136, 53.50000000000051, -84.30000000000004, 32.40000000000019, 34.00000000000039, -3.300000000000056, 29.70000000000028, 47.200000000000415, 9.300000000000097, 51.00000000000049, 32.800000000000196, 31.200000000000166, -95.30000000000021, 50.80000000000048, 47.200000000000415, 42.70000000000034, -22.899999999999768, -67.29999999999994, 47.80000000000043, 58.40000000000051, -37.69999999999994, 40.0000000000003, 53.50000000000051, 27.900000000000112, 26.80000000000009, 14.400000000000023, -41.39999999999988, 34.50000000000022, 20.200000000000273, 7.500000000000112, 16.10000000000022, 39.9000000000003, -2.0999999999999233], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 11.299999999999969, 27.200000000000134, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 20.90000000000003, 23.600000000000065, 24.50000000000009, 20.000000000000014, 20.000000000000014, 33.50000000000024, -99.69999999999982, -80.79999999999981, -21.999999999999766, -1.9000000000000141, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.299999999999965, 26.600000000000154, 20.000000000000014, 1.099999999999983, 29.600000000000176, -13.60000000000002, 13.70000000000001, 13.70000000000001, 17.899999999999984, 22.700000000000053, 34.40000000000025, 20.000000000000014, 20.000000000000014, 21.80000000000004, 23.000000000000057, 20.90000000000003, 27.20000000000013, -101.80000000000064, -9.699999999999989, 11.599999999999964, 21.500000000000036, 20.000000000000014, 20.000000000000014, -8.799999999999875, 20.000000000000014, 32.300000000000225, 8.299999999999965, 20.000000000000014, 12.499999999999972, 20.000000000000014, 17.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 11.599999999999968, 23.900000000000073, 6.199999999999969, 19.400000000000006, 19.400000000000006, -6.399999999999908, 9.199999999999966, -23.800000000000022, 20.000000000000014, 11.599999999999964, 20.000000000000014, -6.399999999999922, 5.299999999999965, 23.900000000000077, -3.0999999999999757, 20.000000000000014, 32.60000000000023, 9.199999999999969, 9.799999999999967, 25.400000000000098, -59.800000000000566, 1.9999999999999731, 4.099999999999971, 17.899999999999988, 29.30000000000017, 20.000000000000014, 27.50000000000014, 5.299999999999976, -17.799999999999763, -119.80000000000001, 21.80000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 5.299999999999965, -112.30000000000013, -11.499999999999819, 26.300000000000118, 20.000000000000014, 20.000000000000014, 7.699999999999971, 5.900000000000002, 17.899999999999988, -49.29999999999994, 16.69999999999997, 20.000000000000014, -135.4000000000003, 13.399999999999972, 17.59999999999998, -89.19999999999999, 20.90000000000003, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 30.200000000000188, -89.80000000000027, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.499999999999986, 4.099999999999966, 9.499999999999964, 20.900000000000027, 22.700000000000053, -32.49999999999993, 29.90000000000018, 23.600000000000065, 6.499999999999968, 20.000000000000014, 20.000000000000014, 18.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 9.799999999999967, 33.50000000000024, 20.000000000000014, -160.60000000000005, -36.69999999999979, 1.3999999999999655, 20.000000000000014, -12.999999999999956, 20.000000000000014, -16.899999999999785, -51.40000000000002, -1.3000000000000331, 20.000000000000014, 27.20000000000013, 20.000000000000014, 7.699999999999967, -30.400000000000006, 9.499999999999968, 33.50000000000024, 3.7999999999999656, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -238.30000000000015, 20.000000000000014, 30.800000000000196, 22.700000000000053, 24.50000000000008, 20.000000000000014, 22.700000000000053, -137.20000000000007, 29.30000000000018, -190.0000000000001, 7.699999999999967, 20.000000000000014, 24.80000000000009, 5.299999999999969, 37.10000000000025, 20.000000000000014, -141.70000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 9.499999999999968, 7.399999999999968, -5.1999999999999265, 20.000000000000014, 0.7999999999999865, -3.399999999999958, 20.000000000000014, -135.40000000000023, 9.499999999999964, 20.000000000000014, -23.200000000000024, 19.400000000000063, 20.000000000000014, -116.50000000000006, 2.000000000000224, -19.89999999999979, 20.000000000000014, 14.899999999999967, -61.89999999999999, 6.799999999999967], "policy_predator_policy_reward": [0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 30.0, 27.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 9.0, 0.0, 5.0, 16.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 52.0, 6.0, 5.0, 14.0, 4.0, 0.0, 5.0, 10.0, 1.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 2.0, 0.0, 10.0, 6.0, 8.0, 16.0, 0.0, 4.0, 13.0, 13.0, 5.0, 11.0, 0.0, 0.0, 7.0, 9.0, 38.0, 0.0, 4.0, 16.0, 2.0, 1.0, 2.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 7.0, 0.0, 44.0, 62.0, 3.0, 0.0, 0.0, 11.0, 14.0, 1.0, 5.0, 33.0, 41.0, 69.0, 0.0, 12.0, 44.0, 8.0, 3.0, 5.0, 2.0, 0.0, 54.0, 3.0, 0.0, 0.0, 0.0, 15.0, 3.0, 8.0, 3.0, 0.0, 23.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 86.0, 27.0, 6.0, 5.0, 18.0, 9.0, 30.0, 35.0, 9.0, 2.0, 0.0, 0.0, 13.0, 19.0, 0.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 68.0, 107.0, 8.0, 2.0, 1.0, 10.0, 6.0, 5.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 6.0, 11.0, 68.0, 6.0, 5.0, 0.0, 24.0, 0.0, 51.0, 53.0, 15.0, 19.0, 0.0, 5.0, 24.0, 29.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5864312156182807, "mean_inference_ms": 1.8350557958765454, "mean_action_processing_ms": 0.24689265898529836, "mean_env_wait_ms": 0.19239164490838465, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039539337158203125, "StateBufferConnector_ms": 0.003122568130493164, "ViewRequirementAgentConnector_ms": 0.09315657615661621}, "num_episodes": 18, "episode_return_max": 58.40000000000051, "episode_return_min": -123.49999999999982, "episode_return_mean": 25.30900000000025, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 401.4664715920962, "num_env_steps_trained_throughput_per_sec": 401.4664715920962, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 10084.792, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10084.753, "sample_time_ms": 1327.137, "learn_time_ms": 8742.946, "learn_throughput": 457.512, "synch_weights_time_ms": 13.399}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "0b081_00000", "date": "2024-08-13_01-02-23", "timestamp": 1723525343, "time_this_iter_s": 9.970568180084229, "time_total_s": 922.4133191108704, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbe4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 922.4133191108704, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 30.257142857142856, "ram_util_percent": 83.08571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7092169469074598, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.94561477363425, "policy_loss": -0.005553024508325117, "vf_loss": 6.95106695316456, "vf_explained_var": -0.00032341168040320986, "kl": 0.01133267707478187, "entropy": 0.7173347913714313, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.70721789748265, "cur_kl_coeff": 2.474715001881122e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.042321634040308, "policy_loss": -0.00239235422569056, "vf_loss": 5.04471398825368, "vf_explained_var": -0.0010615123958183975, "kl": 0.0038369727456130875, "entropy": 0.5276537650161319, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 63.40000000000052, "episode_reward_min": -319.2999999999997, "episode_reward_mean": 5.965000000000236, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000025, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -20.71249999999999, "predator_policy": 23.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.20000000000008, 53.300000000000516, 34.30000000000022, 39.50000000000029, 39.600000000000286, 40.0000000000003, 44.00000000000036, 40.1000000000003, 40.80000000000031, 18.799999999999997, 20.2000000000003, 35.600000000000236, 24.90000000000008, 36.80000000000025, 52.60000000000051, 35.00000000000023, 3.600000000000117, 26.100000000000087, 50.20000000000047, 49.500000000000455, 6.500000000000101, -18.00000000000002, 49.90000000000046, 32.30000000000018, -17.800000000000033, 49.30000000000046, 38.70000000000027, 38.800000000000345, 5.400000000000054, -5.400000000000089, 43.00000000000035, -16.30000000000004, 31.200000000000173, 52.20000000000051, -19.09999999999986, 40.0000000000003, 32.500000000000185, 24.600000000000048, 46.600000000000406, 22.400000000000322, 39.100000000000286, 40.0000000000003, 42.80000000000034, 40.0000000000003, 29.300000000000136, 53.50000000000051, -84.30000000000004, 32.40000000000019, 34.00000000000039, -3.300000000000056, 29.70000000000028, 47.200000000000415, 9.300000000000097, 51.00000000000049, 32.800000000000196, 31.200000000000166, -95.30000000000021, 50.80000000000048, 47.200000000000415, 42.70000000000034, -22.899999999999768, -67.29999999999994, 47.80000000000043, 58.40000000000051, -37.69999999999994, 40.0000000000003, 53.50000000000051, 27.900000000000112, 26.80000000000009, 14.400000000000023, -41.39999999999988, 34.50000000000022, 20.200000000000273, 7.500000000000112, 16.10000000000022, 39.9000000000003, -2.0999999999999233, 16.70000000000017, -15.20000000000006, 63.40000000000052, 40.0000000000003, -288.89999999999816, -319.2999999999997, -1.300000000000047, -34.399999999999864, 25.300000000000452, -26.099999999999866, 45.40000000000038, -40.19999999999984, -79.29999999999987, -174.60000000000028, 29.60000000000033, -234.0, 38.400000000000276, -3.199999999999826, -29.799999999999947, -51.7999999999998, 41.800000000000324, -196.0, -43.59999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -8.799999999999875, 20.000000000000014, 32.300000000000225, 8.299999999999965, 20.000000000000014, 12.499999999999972, 20.000000000000014, 17.599999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 11.599999999999968, 23.900000000000073, 6.199999999999969, 19.400000000000006, 19.400000000000006, -6.399999999999908, 9.199999999999966, -23.800000000000022, 20.000000000000014, 11.599999999999964, 20.000000000000014, -6.399999999999922, 5.299999999999965, 23.900000000000077, -3.0999999999999757, 20.000000000000014, 32.60000000000023, 9.199999999999969, 9.799999999999967, 25.400000000000098, -59.800000000000566, 1.9999999999999731, 4.099999999999971, 17.899999999999988, 29.30000000000017, 20.000000000000014, 27.50000000000014, 5.299999999999976, -17.799999999999763, -119.80000000000001, 21.80000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 5.299999999999965, -112.30000000000013, -11.499999999999819, 26.300000000000118, 20.000000000000014, 20.000000000000014, 7.699999999999971, 5.900000000000002, 17.899999999999988, -49.29999999999994, 16.69999999999997, 20.000000000000014, -135.4000000000003, 13.399999999999972, 17.59999999999998, -89.19999999999999, 20.90000000000003, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 30.200000000000188, -89.80000000000027, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.499999999999986, 4.099999999999966, 9.499999999999964, 20.900000000000027, 22.700000000000053, -32.49999999999993, 29.90000000000018, 23.600000000000065, 6.499999999999968, 20.000000000000014, 20.000000000000014, 18.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 9.799999999999967, 33.50000000000024, 20.000000000000014, -160.60000000000005, -36.69999999999979, 1.3999999999999655, 20.000000000000014, -12.999999999999956, 20.000000000000014, -16.899999999999785, -51.40000000000002, -1.3000000000000331, 20.000000000000014, 27.20000000000013, 20.000000000000014, 7.699999999999967, -30.400000000000006, 9.499999999999968, 33.50000000000024, 3.7999999999999656, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -238.30000000000015, 20.000000000000014, 30.800000000000196, 22.700000000000053, 24.50000000000008, 20.000000000000014, 22.700000000000053, -137.20000000000007, 29.30000000000018, -190.0000000000001, 7.699999999999967, 20.000000000000014, 24.80000000000009, 5.299999999999969, 37.10000000000025, 20.000000000000014, -141.70000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 9.499999999999968, 7.399999999999968, -5.1999999999999265, 20.000000000000014, 0.7999999999999865, -3.399999999999958, 20.000000000000014, -135.40000000000023, 9.499999999999964, 20.000000000000014, -23.200000000000024, 19.400000000000063, 20.000000000000014, -116.50000000000006, 2.000000000000224, -19.89999999999979, 20.000000000000014, 14.899999999999967, -61.89999999999999, 6.799999999999967, 32.60000000000023, -226.9, -99.70000000000007, 6.499999999999968, 33.50000000000024, 29.90000000000018, 20.000000000000014, 20.000000000000014, -160.60000000000056, -280.30000000000007, -305.19999999999993, -271.1, 20.000000000000014, -124.29999999999995, -240.40000000000006, 20.000000000000014, 31.400000000000208, -66.10000000000004, -171.1000000000001, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -244.20000000000005, -72.40000000000089, -145.90000000000003, -379.0999999999999, -65.49999999999997, -7.30000000000004, 17.899999999999984, -190.00000000000003, -190.00000000000003, 20.000000000000014, 10.399999999999968, -68.20000000000002, 20.000000000000014, 11.599999999999968, -219.39999999999998, -327.7999999999999, 20.000000000000014, 20.000000000000014, 21.80000000000004, -271.9000000000001, -168.09999999999997, -280.6, 20.000000000000014], "policy_predator_policy_reward": [5.0, 10.0, 1.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 2.0, 0.0, 10.0, 6.0, 8.0, 16.0, 0.0, 4.0, 13.0, 13.0, 5.0, 11.0, 0.0, 0.0, 7.0, 9.0, 38.0, 0.0, 4.0, 16.0, 2.0, 1.0, 2.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 7.0, 0.0, 44.0, 62.0, 3.0, 0.0, 0.0, 11.0, 14.0, 1.0, 5.0, 33.0, 41.0, 69.0, 0.0, 12.0, 44.0, 8.0, 3.0, 5.0, 2.0, 0.0, 54.0, 3.0, 0.0, 0.0, 0.0, 15.0, 3.0, 8.0, 3.0, 0.0, 23.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 86.0, 27.0, 6.0, 5.0, 18.0, 9.0, 30.0, 35.0, 9.0, 2.0, 0.0, 0.0, 13.0, 19.0, 0.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 68.0, 107.0, 8.0, 2.0, 1.0, 10.0, 6.0, 5.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 6.0, 11.0, 68.0, 6.0, 5.0, 0.0, 24.0, 0.0, 51.0, 53.0, 15.0, 19.0, 0.0, 5.0, 24.0, 29.0, 110.0, 101.0, 59.0, 19.0, 0.0, 0.0, 0.0, 0.0, 142.0, 10.0, 166.0, 91.0, 43.0, 60.0, 65.0, 121.0, 30.0, 30.0, 83.0, 42.0, 0.0, 0.0, 66.0, 118.0, 60.0, 79.0, 195.0, 75.0, 12.0, 7.0, 99.0, 47.0, 8.0, 0.0, 42.0, 3.0, 82.0, 96.0, 161.0, 95.0, 0.0, 0.0, 114.0, 130.0, 91.0, 126.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5867448542048762, "mean_inference_ms": 1.8321056604546055, "mean_action_processing_ms": 0.24666246697419322, "mean_env_wait_ms": 0.19232994134863182, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005585670471191406, "StateBufferConnector_ms": 0.0032415390014648438, "ViewRequirementAgentConnector_ms": 0.09787547588348389}, "num_episodes": 23, "episode_return_max": 63.40000000000052, "episode_return_min": -319.2999999999997, "episode_return_mean": 5.965000000000236, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.0106225264327, "num_env_steps_trained_throughput_per_sec": 398.0106225264327, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 10067.786, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10067.739, "sample_time_ms": 1325.154, "learn_time_ms": 8728.32, "learn_throughput": 458.278, "synch_weights_time_ms": 13.218}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "0b081_00000", "date": "2024-08-13_01-02-33", "timestamp": 1723525353, "time_this_iter_s": 10.055531978607178, "time_total_s": 932.4688510894775, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d16c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 932.4688510894775, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 29.353333333333328, "ram_util_percent": 83.47999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7093069307663769, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.726983189456677, "policy_loss": -0.0033130914034450024, "vf_loss": 2.7302243198667253, "vf_explained_var": -0.0007275391192663284, "kl": 0.008085624182557604, "entropy": 0.7222593180086246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6378108171302648, "cur_kl_coeff": 1.237357500940561e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9540702577621218, "policy_loss": -0.0013238610099833557, "vf_loss": 1.9553941257416256, "vf_explained_var": 0.0009969125664423383, "kl": 0.0025916235144545635, "entropy": 0.4772360416316481, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 63.40000000000052, "episode_reward_min": -319.2999999999997, "episode_reward_mean": 3.2190000000002352, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000025, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -25.695499999999985, "predator_policy": 27.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.20000000000047, 49.500000000000455, 6.500000000000101, -18.00000000000002, 49.90000000000046, 32.30000000000018, -17.800000000000033, 49.30000000000046, 38.70000000000027, 38.800000000000345, 5.400000000000054, -5.400000000000089, 43.00000000000035, -16.30000000000004, 31.200000000000173, 52.20000000000051, -19.09999999999986, 40.0000000000003, 32.500000000000185, 24.600000000000048, 46.600000000000406, 22.400000000000322, 39.100000000000286, 40.0000000000003, 42.80000000000034, 40.0000000000003, 29.300000000000136, 53.50000000000051, -84.30000000000004, 32.40000000000019, 34.00000000000039, -3.300000000000056, 29.70000000000028, 47.200000000000415, 9.300000000000097, 51.00000000000049, 32.800000000000196, 31.200000000000166, -95.30000000000021, 50.80000000000048, 47.200000000000415, 42.70000000000034, -22.899999999999768, -67.29999999999994, 47.80000000000043, 58.40000000000051, -37.69999999999994, 40.0000000000003, 53.50000000000051, 27.900000000000112, 26.80000000000009, 14.400000000000023, -41.39999999999988, 34.50000000000022, 20.200000000000273, 7.500000000000112, 16.10000000000022, 39.9000000000003, -2.0999999999999233, 16.70000000000017, -15.20000000000006, 63.40000000000052, 40.0000000000003, -288.89999999999816, -319.2999999999997, -1.300000000000047, -34.399999999999864, 25.300000000000452, -26.099999999999866, 45.40000000000038, -40.19999999999984, -79.29999999999987, -174.60000000000028, 29.60000000000033, -234.0, 38.400000000000276, -3.199999999999826, -29.799999999999947, -51.7999999999998, 41.800000000000324, -196.0, -43.59999999999985, 1.299999999999966, 40.0000000000003, -54.09999999999987, 44.50000000000036, 40.0000000000003, 39.20000000000028, -41.09999999999993, 56.200000000000536, -5.599999999999719, 40.0000000000003, 40.0000000000003, -50.19999999999987, 13.099999999999959, -1.9000000000000639, 46.600000000000406, 40.0000000000003, 50.400000000000475, 38.40000000000029], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, 29.30000000000017, 20.000000000000014, 27.50000000000014, 5.299999999999976, -17.799999999999763, -119.80000000000001, 21.80000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 5.299999999999965, -112.30000000000013, -11.499999999999819, 26.300000000000118, 20.000000000000014, 20.000000000000014, 7.699999999999971, 5.900000000000002, 17.899999999999988, -49.29999999999994, 16.69999999999997, 20.000000000000014, -135.4000000000003, 13.399999999999972, 17.59999999999998, -89.19999999999999, 20.90000000000003, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 30.200000000000188, -89.80000000000027, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -2.499999999999986, 4.099999999999966, 9.499999999999964, 20.900000000000027, 22.700000000000053, -32.49999999999993, 29.90000000000018, 23.600000000000065, 6.499999999999968, 20.000000000000014, 20.000000000000014, 18.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 9.799999999999967, 33.50000000000024, 20.000000000000014, -160.60000000000005, -36.69999999999979, 1.3999999999999655, 20.000000000000014, -12.999999999999956, 20.000000000000014, -16.899999999999785, -51.40000000000002, -1.3000000000000331, 20.000000000000014, 27.20000000000013, 20.000000000000014, 7.699999999999967, -30.400000000000006, 9.499999999999968, 33.50000000000024, 3.7999999999999656, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -238.30000000000015, 20.000000000000014, 30.800000000000196, 22.700000000000053, 24.50000000000008, 20.000000000000014, 22.700000000000053, -137.20000000000007, 29.30000000000018, -190.0000000000001, 7.699999999999967, 20.000000000000014, 24.80000000000009, 5.299999999999969, 37.10000000000025, 20.000000000000014, -141.70000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 9.499999999999968, 7.399999999999968, -5.1999999999999265, 20.000000000000014, 0.7999999999999865, -3.399999999999958, 20.000000000000014, -135.40000000000023, 9.499999999999964, 20.000000000000014, -23.200000000000024, 19.400000000000063, 20.000000000000014, -116.50000000000006, 2.000000000000224, -19.89999999999979, 20.000000000000014, 14.899999999999967, -61.89999999999999, 6.799999999999967, 32.60000000000023, -226.9, -99.70000000000007, 6.499999999999968, 33.50000000000024, 29.90000000000018, 20.000000000000014, 20.000000000000014, -160.60000000000056, -280.30000000000007, -305.19999999999993, -271.1, 20.000000000000014, -124.29999999999995, -240.40000000000006, 20.000000000000014, 31.400000000000208, -66.10000000000004, -171.1000000000001, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -244.20000000000005, -72.40000000000089, -145.90000000000003, -379.0999999999999, -65.49999999999997, -7.30000000000004, 17.899999999999984, -190.00000000000003, -190.00000000000003, 20.000000000000014, 10.399999999999968, -68.20000000000002, 20.000000000000014, 11.599999999999968, -219.39999999999998, -327.7999999999999, 20.000000000000014, 20.000000000000014, 21.80000000000004, -271.9000000000001, -168.09999999999997, -280.6, 20.000000000000014, -21.999999999999744, -57.70000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.10000000000005, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 6.199999999999973, 20.000000000000014, 20.000000000000014, -234.10000000000002, 26.300000000000114, 29.90000000000018, -3.0999999999999934, -32.49999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -244.60000000000002, -13.59999999999989, 13.099999999999966, -22.00000000000003, 13.699999999999964, -244.60000000000002, 29.90000000000018, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 17.899999999999988, 20.000000000000014, 7.39999999999996], "policy_predator_policy_reward": [2.0, 1.0, 2.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 7.0, 0.0, 44.0, 62.0, 3.0, 0.0, 0.0, 11.0, 14.0, 1.0, 5.0, 33.0, 41.0, 69.0, 0.0, 12.0, 44.0, 8.0, 3.0, 5.0, 2.0, 0.0, 54.0, 3.0, 0.0, 0.0, 0.0, 15.0, 3.0, 8.0, 3.0, 0.0, 23.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 86.0, 27.0, 6.0, 5.0, 18.0, 9.0, 30.0, 35.0, 9.0, 2.0, 0.0, 0.0, 13.0, 19.0, 0.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 68.0, 107.0, 8.0, 2.0, 1.0, 10.0, 6.0, 5.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 6.0, 11.0, 68.0, 6.0, 5.0, 0.0, 24.0, 0.0, 51.0, 53.0, 15.0, 19.0, 0.0, 5.0, 24.0, 29.0, 110.0, 101.0, 59.0, 19.0, 0.0, 0.0, 0.0, 0.0, 142.0, 10.0, 166.0, 91.0, 43.0, 60.0, 65.0, 121.0, 30.0, 30.0, 83.0, 42.0, 0.0, 0.0, 66.0, 118.0, 60.0, 79.0, 195.0, 75.0, 12.0, 7.0, 99.0, 47.0, 8.0, 0.0, 42.0, 3.0, 82.0, 96.0, 161.0, 95.0, 0.0, 0.0, 114.0, 130.0, 91.0, 126.0, 56.0, 25.0, 0.0, 0.0, 51.0, 109.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 113.0, 60.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 107.0, 101.0, 1.0, 21.0, 114.0, 115.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5859532067740267, "mean_inference_ms": 1.8351389567254683, "mean_action_processing_ms": 0.246738982888036, "mean_env_wait_ms": 0.19222987472671108, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006053924560546875, "StateBufferConnector_ms": 0.0032553672790527344, "ViewRequirementAgentConnector_ms": 0.09818363189697266}, "num_episodes": 18, "episode_return_max": 63.40000000000052, "episode_return_min": -319.2999999999997, "episode_return_mean": 3.2190000000002352, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 387.9642222830396, "num_env_steps_trained_throughput_per_sec": 387.9642222830396, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 10090.967, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10090.919, "sample_time_ms": 1322.301, "learn_time_ms": 8754.133, "learn_throughput": 456.927, "synch_weights_time_ms": 13.37}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "0b081_00000", "date": "2024-08-13_01-02-43", "timestamp": 1723525363, "time_this_iter_s": 10.357763051986694, "time_total_s": 942.8266141414642, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d62280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 942.8266141414642, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 31.192857142857143, "ram_util_percent": 83.34285714285716}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7480901254074914, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3009554020311467, "policy_loss": -0.0022211048811201064, "vf_loss": 2.303125837997154, "vf_explained_var": -0.0003966547824718334, "kl": 0.0056937711648883385, "entropy": 0.711830224688091, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6342227632288264, "cur_kl_coeff": 6.186787504702805e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9236054141685446, "policy_loss": -0.0009125846184336792, "vf_loss": 1.9245179994081063, "vf_explained_var": -0.0005627371016002836, "kl": 0.0025972942652508248, "entropy": 0.5120102499527907, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 63.40000000000052, "episode_reward_min": -440.4, "episode_reward_mean": -0.663999999999774, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000025, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -28.80199999999998, "predator_policy": 28.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.500000000000185, 24.600000000000048, 46.600000000000406, 22.400000000000322, 39.100000000000286, 40.0000000000003, 42.80000000000034, 40.0000000000003, 29.300000000000136, 53.50000000000051, -84.30000000000004, 32.40000000000019, 34.00000000000039, -3.300000000000056, 29.70000000000028, 47.200000000000415, 9.300000000000097, 51.00000000000049, 32.800000000000196, 31.200000000000166, -95.30000000000021, 50.80000000000048, 47.200000000000415, 42.70000000000034, -22.899999999999768, -67.29999999999994, 47.80000000000043, 58.40000000000051, -37.69999999999994, 40.0000000000003, 53.50000000000051, 27.900000000000112, 26.80000000000009, 14.400000000000023, -41.39999999999988, 34.50000000000022, 20.200000000000273, 7.500000000000112, 16.10000000000022, 39.9000000000003, -2.0999999999999233, 16.70000000000017, -15.20000000000006, 63.40000000000052, 40.0000000000003, -288.89999999999816, -319.2999999999997, -1.300000000000047, -34.399999999999864, 25.300000000000452, -26.099999999999866, 45.40000000000038, -40.19999999999984, -79.29999999999987, -174.60000000000028, 29.60000000000033, -234.0, 38.400000000000276, -3.199999999999826, -29.799999999999947, -51.7999999999998, 41.800000000000324, -196.0, -43.59999999999985, 1.299999999999966, 40.0000000000003, -54.09999999999987, 44.50000000000036, 40.0000000000003, 39.20000000000028, -41.09999999999993, 56.200000000000536, -5.599999999999719, 40.0000000000003, 40.0000000000003, -50.19999999999987, 13.099999999999959, -1.9000000000000639, 46.600000000000406, 40.0000000000003, 50.400000000000475, 38.40000000000029, -29.599999999999895, 45.40000000000038, 21.099999999999994, 16.69999999999993, 15.699999999999921, 38.90000000000028, 46.2000000000004, 31.200000000000166, 16.799999999999926, 55.10000000000049, -11.100000000000023, 40.0000000000003, 34.50000000000022, -440.4, 17.399999999999963, 50.80000000000048, 40.0000000000003, 33.400000000000205], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -2.499999999999986, 4.099999999999966, 9.499999999999964, 20.900000000000027, 22.700000000000053, -32.49999999999993, 29.90000000000018, 23.600000000000065, 6.499999999999968, 20.000000000000014, 20.000000000000014, 18.799999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 9.799999999999967, 33.50000000000024, 20.000000000000014, -160.60000000000005, -36.69999999999979, 1.3999999999999655, 20.000000000000014, -12.999999999999956, 20.000000000000014, -16.899999999999785, -51.40000000000002, -1.3000000000000331, 20.000000000000014, 27.20000000000013, 20.000000000000014, 7.699999999999967, -30.400000000000006, 9.499999999999968, 33.50000000000024, 3.7999999999999656, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -238.30000000000015, 20.000000000000014, 30.800000000000196, 22.700000000000053, 24.50000000000008, 20.000000000000014, 22.700000000000053, -137.20000000000007, 29.30000000000018, -190.0000000000001, 7.699999999999967, 20.000000000000014, 24.80000000000009, 5.299999999999969, 37.10000000000025, 20.000000000000014, -141.70000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 9.499999999999968, 7.399999999999968, -5.1999999999999265, 20.000000000000014, 0.7999999999999865, -3.399999999999958, 20.000000000000014, -135.40000000000023, 9.499999999999964, 20.000000000000014, -23.200000000000024, 19.400000000000063, 20.000000000000014, -116.50000000000006, 2.000000000000224, -19.89999999999979, 20.000000000000014, 14.899999999999967, -61.89999999999999, 6.799999999999967, 32.60000000000023, -226.9, -99.70000000000007, 6.499999999999968, 33.50000000000024, 29.90000000000018, 20.000000000000014, 20.000000000000014, -160.60000000000056, -280.30000000000007, -305.19999999999993, -271.1, 20.000000000000014, -124.29999999999995, -240.40000000000006, 20.000000000000014, 31.400000000000208, -66.10000000000004, -171.1000000000001, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -244.20000000000005, -72.40000000000089, -145.90000000000003, -379.0999999999999, -65.49999999999997, -7.30000000000004, 17.899999999999984, -190.00000000000003, -190.00000000000003, 20.000000000000014, 10.399999999999968, -68.20000000000002, 20.000000000000014, 11.599999999999968, -219.39999999999998, -327.7999999999999, 20.000000000000014, 20.000000000000014, 21.80000000000004, -271.9000000000001, -168.09999999999997, -280.6, 20.000000000000014, -21.999999999999744, -57.70000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.10000000000005, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 6.199999999999973, 20.000000000000014, 20.000000000000014, -234.10000000000002, 26.300000000000114, 29.90000000000018, -3.0999999999999934, -32.49999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -244.60000000000002, -13.59999999999989, 13.099999999999966, -22.00000000000003, 13.699999999999964, -244.60000000000002, 29.90000000000018, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 17.899999999999988, 20.000000000000014, 7.39999999999996, 20.000000000000014, -223.59999999999994, 25.400000000000098, 20.000000000000014, 5.299999999999969, 3.7999999999999656, -45.09999999999977, 30.800000000000196, -16.89999999999978, 11.599999999999975, 20.000000000000014, 17.899999999999988, 18.499999999999993, 22.700000000000053, 3.1999999999999615, 20.000000000000014, 11.599999999999971, -17.79999999999977, 20.000000000000014, 34.10000000000024, -192.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, -371.5, -355.9, -5.200000000000053, -0.4000000000000472, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999966], "policy_predator_policy_reward": [0.0, 15.0, 3.0, 8.0, 3.0, 0.0, 23.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 86.0, 27.0, 6.0, 5.0, 18.0, 9.0, 30.0, 35.0, 9.0, 2.0, 0.0, 0.0, 13.0, 19.0, 0.0, 8.0, 9.0, 0.0, 8.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 68.0, 107.0, 8.0, 2.0, 1.0, 10.0, 6.0, 5.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 6.0, 11.0, 68.0, 6.0, 5.0, 0.0, 24.0, 0.0, 51.0, 53.0, 15.0, 19.0, 0.0, 5.0, 24.0, 29.0, 110.0, 101.0, 59.0, 19.0, 0.0, 0.0, 0.0, 0.0, 142.0, 10.0, 166.0, 91.0, 43.0, 60.0, 65.0, 121.0, 30.0, 30.0, 83.0, 42.0, 0.0, 0.0, 66.0, 118.0, 60.0, 79.0, 195.0, 75.0, 12.0, 7.0, 99.0, 47.0, 8.0, 0.0, 42.0, 3.0, 82.0, 96.0, 161.0, 95.0, 0.0, 0.0, 114.0, 130.0, 91.0, 126.0, 56.0, 25.0, 0.0, 0.0, 51.0, 109.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 113.0, 60.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 107.0, 101.0, 1.0, 21.0, 114.0, 115.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 6.0, 85.0, 89.0, 0.0, 0.0, 6.0, 6.0, 31.0, 0.0, 8.0, 13.0, 1.0, 0.0, 0.0, 5.0, 8.0, 0.0, 1.0, 22.0, 1.0, 0.0, 64.0, 97.0, 0.0, 0.0, 0.0, 5.0, 94.0, 193.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5858810179896659, "mean_inference_ms": 1.8357028165970937, "mean_action_processing_ms": 0.24671075443194782, "mean_env_wait_ms": 0.19221621874589995, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007013559341430664, "StateBufferConnector_ms": 0.0032750368118286133, "ViewRequirementAgentConnector_ms": 0.10017061233520508}, "num_episodes": 18, "episode_return_max": 63.40000000000052, "episode_return_min": -440.4, "episode_return_mean": -0.663999999999774, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 393.64174815323696, "num_env_steps_trained_throughput_per_sec": 393.64174815323696, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 10113.335, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10113.287, "sample_time_ms": 1344.444, "learn_time_ms": 8755.082, "learn_throughput": 456.878, "synch_weights_time_ms": 12.661}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "0b081_00000", "date": "2024-08-13_01-02-53", "timestamp": 1723525373, "time_this_iter_s": 10.167975902557373, "time_total_s": 952.9945900440216, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d62c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 952.9945900440216, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 30.473333333333336, "ram_util_percent": 83.57333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6906075243912047, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.498885371855327, "policy_loss": -0.004380882688842359, "vf_loss": 1.5031680576385014, "vf_explained_var": 0.0011717892197704819, "kl": 0.01103482471685073, "entropy": 0.6960153822230284, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8006423162877875, "cur_kl_coeff": 3.0933937523514023e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2194767829365831, "policy_loss": -0.0016304975890470718, "vf_loss": 1.221107282556554, "vf_explained_var": 0.0019080911994611145, "kl": 0.0038266714882752052, "entropy": 0.5448164901247731, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 63.40000000000052, "episode_reward_min": -440.4, "episode_reward_mean": -0.32299999999977547, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000025, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -30.066499999999984, "predator_policy": 29.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.200000000000415, 42.70000000000034, -22.899999999999768, -67.29999999999994, 47.80000000000043, 58.40000000000051, -37.69999999999994, 40.0000000000003, 53.50000000000051, 27.900000000000112, 26.80000000000009, 14.400000000000023, -41.39999999999988, 34.50000000000022, 20.200000000000273, 7.500000000000112, 16.10000000000022, 39.9000000000003, -2.0999999999999233, 16.70000000000017, -15.20000000000006, 63.40000000000052, 40.0000000000003, -288.89999999999816, -319.2999999999997, -1.300000000000047, -34.399999999999864, 25.300000000000452, -26.099999999999866, 45.40000000000038, -40.19999999999984, -79.29999999999987, -174.60000000000028, 29.60000000000033, -234.0, 38.400000000000276, -3.199999999999826, -29.799999999999947, -51.7999999999998, 41.800000000000324, -196.0, -43.59999999999985, 1.299999999999966, 40.0000000000003, -54.09999999999987, 44.50000000000036, 40.0000000000003, 39.20000000000028, -41.09999999999993, 56.200000000000536, -5.599999999999719, 40.0000000000003, 40.0000000000003, -50.19999999999987, 13.099999999999959, -1.9000000000000639, 46.600000000000406, 40.0000000000003, 50.400000000000475, 38.40000000000029, -29.599999999999895, 45.40000000000038, 21.099999999999994, 16.69999999999993, 15.699999999999921, 38.90000000000028, 46.2000000000004, 31.200000000000166, 16.799999999999926, 55.10000000000049, -11.100000000000023, 40.0000000000003, 34.50000000000022, -440.4, 17.399999999999963, 50.80000000000048, 40.0000000000003, 33.400000000000205, -17.199999999999818, 17.399999999999974, 40.0000000000003, -21.29999999999974, 21.599999999999998, 52.60000000000051, 29.80000000000014, 54.400000000000546, 35.600000000000236, 5.000000000000025, 53.50000000000052, 32.30000000000018, 22.40000000000003, 45.20000000000039, -26.39999999999992, 62.500000000000504, -6.900000000000061, 33.400000000000205, 30.300000000000157, 38.300000000000274, -17.39999999999978, 55.30000000000051], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [22.700000000000053, 24.50000000000008, 20.000000000000014, 22.700000000000053, -137.20000000000007, 29.30000000000018, -190.0000000000001, 7.699999999999967, 20.000000000000014, 24.80000000000009, 5.299999999999969, 37.10000000000025, 20.000000000000014, -141.70000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 9.499999999999968, 7.399999999999968, -5.1999999999999265, 20.000000000000014, 0.7999999999999865, -3.399999999999958, 20.000000000000014, -135.40000000000023, 9.499999999999964, 20.000000000000014, -23.200000000000024, 19.400000000000063, 20.000000000000014, -116.50000000000006, 2.000000000000224, -19.89999999999979, 20.000000000000014, 14.899999999999967, -61.89999999999999, 6.799999999999967, 32.60000000000023, -226.9, -99.70000000000007, 6.499999999999968, 33.50000000000024, 29.90000000000018, 20.000000000000014, 20.000000000000014, -160.60000000000056, -280.30000000000007, -305.19999999999993, -271.1, 20.000000000000014, -124.29999999999995, -240.40000000000006, 20.000000000000014, 31.400000000000208, -66.10000000000004, -171.1000000000001, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -244.20000000000005, -72.40000000000089, -145.90000000000003, -379.0999999999999, -65.49999999999997, -7.30000000000004, 17.899999999999984, -190.00000000000003, -190.00000000000003, 20.000000000000014, 10.399999999999968, -68.20000000000002, 20.000000000000014, 11.599999999999968, -219.39999999999998, -327.7999999999999, 20.000000000000014, 20.000000000000014, 21.80000000000004, -271.9000000000001, -168.09999999999997, -280.6, 20.000000000000014, -21.999999999999744, -57.70000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.10000000000005, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 6.199999999999973, 20.000000000000014, 20.000000000000014, -234.10000000000002, 26.300000000000114, 29.90000000000018, -3.0999999999999934, -32.49999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -244.60000000000002, -13.59999999999989, 13.099999999999966, -22.00000000000003, 13.699999999999964, -244.60000000000002, 29.90000000000018, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 17.899999999999988, 20.000000000000014, 7.39999999999996, 20.000000000000014, -223.59999999999994, 25.400000000000098, 20.000000000000014, 5.299999999999969, 3.7999999999999656, -45.09999999999977, 30.800000000000196, -16.89999999999978, 11.599999999999975, 20.000000000000014, 17.899999999999988, 18.499999999999993, 22.700000000000053, 3.1999999999999615, 20.000000000000014, 11.599999999999971, -17.79999999999977, 20.000000000000014, 34.10000000000024, -192.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, -371.5, -355.9, -5.200000000000053, -0.4000000000000472, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999966, 20.000000000000014, -89.20000000000037, -4.5999999999999535, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -15.699999999999896, -34.599999999999866, -51.39999999999986, 13.99999999999997, 20.000000000000014, 32.60000000000023, 11.599999999999964, 12.199999999999966, 28.100000000000147, 26.300000000000114, 20.000000000000014, 11.599999999999968, 14.899999999999965, -40.899999999999764, 20.000000000000014, 33.50000000000024, 5.299999999999965, 20.000000000000014, -13.599999999999826, 20.000000000000014, 27.50000000000014, 7.699999999999967, 20.000000000000014, -198.4, 27.20000000000013, 35.300000000000246, -166.90000000000026, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.99999999999997, 20.000000000000014, 2.2999999999999607, -240.4000000000002, 20.000000000000014, 20.000000000000014, 35.30000000000025], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 17.0, 68.0, 107.0, 8.0, 2.0, 1.0, 10.0, 6.0, 5.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 6.0, 11.0, 68.0, 6.0, 5.0, 0.0, 24.0, 0.0, 51.0, 53.0, 15.0, 19.0, 0.0, 5.0, 24.0, 29.0, 110.0, 101.0, 59.0, 19.0, 0.0, 0.0, 0.0, 0.0, 142.0, 10.0, 166.0, 91.0, 43.0, 60.0, 65.0, 121.0, 30.0, 30.0, 83.0, 42.0, 0.0, 0.0, 66.0, 118.0, 60.0, 79.0, 195.0, 75.0, 12.0, 7.0, 99.0, 47.0, 8.0, 0.0, 42.0, 3.0, 82.0, 96.0, 161.0, 95.0, 0.0, 0.0, 114.0, 130.0, 91.0, 126.0, 56.0, 25.0, 0.0, 0.0, 51.0, 109.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 113.0, 60.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 107.0, 101.0, 1.0, 21.0, 114.0, 115.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 6.0, 85.0, 89.0, 0.0, 0.0, 6.0, 6.0, 31.0, 0.0, 8.0, 13.0, 1.0, 0.0, 0.0, 5.0, 8.0, 0.0, 1.0, 22.0, 1.0, 0.0, 64.0, 97.0, 0.0, 0.0, 0.0, 5.0, 94.0, 193.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 52.0, 16.0, 7.0, 0.0, 0.0, 19.0, 10.0, 25.0, 34.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 29.0, 2.0, 0.0, 0.0, 7.0, 0.0, 16.0, 0.0, 0.0, 10.0, 103.0, 49.0, 0.0, 0.0, 76.0, 64.0, 6.0, 0.0, 6.0, 11.0, 11.0, 5.0, 117.0, 86.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5857578669706544, "mean_inference_ms": 1.8361824908236262, "mean_action_processing_ms": 0.24665052753067948, "mean_env_wait_ms": 0.1921788515502528, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007361054420471191, "StateBufferConnector_ms": 0.0032334327697753906, "ViewRequirementAgentConnector_ms": 0.09861290454864502}, "num_episodes": 22, "episode_return_max": 63.40000000000052, "episode_return_min": -440.4, "episode_return_mean": -0.32299999999977547, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 395.3631803672765, "num_env_steps_trained_throughput_per_sec": 395.3631803672765, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 10092.541, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10092.494, "sample_time_ms": 1343.37, "learn_time_ms": 8735.719, "learn_throughput": 457.89, "synch_weights_time_ms": 12.278}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "0b081_00000", "date": "2024-08-13_01-03-04", "timestamp": 1723525384, "time_this_iter_s": 10.122502088546753, "time_total_s": 963.1170921325684, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f21310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 963.1170921325684, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 30.76428571428571, "ram_util_percent": 83.42857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8034469662677675, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4003337303797405, "policy_loss": -0.002209455898603198, "vf_loss": 2.4024938729074266, "vf_explained_var": 0.003581961469044761, "kl": 0.00554133035517735, "entropy": 0.6970591289341135, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7048012983980317, "cur_kl_coeff": 1.5466968761757012e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1599750521321774, "policy_loss": -0.002410739352532401, "vf_loss": 2.1623857899317667, "vf_explained_var": -0.0034899104524541784, "kl": 0.004621933176473354, "entropy": 0.6010482795024045, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 63.40000000000052, "episode_reward_min": -440.4, "episode_reward_mean": -1.6139999999997954, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000025, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -31.921999999999993, "predator_policy": 31.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.0999999999999233, 16.70000000000017, -15.20000000000006, 63.40000000000052, 40.0000000000003, -288.89999999999816, -319.2999999999997, -1.300000000000047, -34.399999999999864, 25.300000000000452, -26.099999999999866, 45.40000000000038, -40.19999999999984, -79.29999999999987, -174.60000000000028, 29.60000000000033, -234.0, 38.400000000000276, -3.199999999999826, -29.799999999999947, -51.7999999999998, 41.800000000000324, -196.0, -43.59999999999985, 1.299999999999966, 40.0000000000003, -54.09999999999987, 44.50000000000036, 40.0000000000003, 39.20000000000028, -41.09999999999993, 56.200000000000536, -5.599999999999719, 40.0000000000003, 40.0000000000003, -50.19999999999987, 13.099999999999959, -1.9000000000000639, 46.600000000000406, 40.0000000000003, 50.400000000000475, 38.40000000000029, -29.599999999999895, 45.40000000000038, 21.099999999999994, 16.69999999999993, 15.699999999999921, 38.90000000000028, 46.2000000000004, 31.200000000000166, 16.799999999999926, 55.10000000000049, -11.100000000000023, 40.0000000000003, 34.50000000000022, -440.4, 17.399999999999963, 50.80000000000048, 40.0000000000003, 33.400000000000205, -17.199999999999818, 17.399999999999974, 40.0000000000003, -21.29999999999974, 21.599999999999998, 52.60000000000051, 29.80000000000014, 54.400000000000546, 35.600000000000236, 5.000000000000025, 53.50000000000052, 32.30000000000018, 22.40000000000003, 45.20000000000039, -26.39999999999992, 62.500000000000504, -6.900000000000061, 33.400000000000205, 30.300000000000157, 38.300000000000274, -17.39999999999978, 55.30000000000051, -31.49999999999963, 49.30000000000046, 35.80000000000024, -35.499999999999595, 32.400000000000226, 25.70000000000007, 6.999999999999922, 47.80000000000043, 44.50000000000036, 51.70000000000049, 5.100000000000156, 9.19999999999994, 33.1000000000002, -67.80000000000148, 7.199999999999973, -9.499999999999861, -27.29999999999975, 1.2999999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-61.89999999999999, 6.799999999999967, 32.60000000000023, -226.9, -99.70000000000007, 6.499999999999968, 33.50000000000024, 29.90000000000018, 20.000000000000014, 20.000000000000014, -160.60000000000056, -280.30000000000007, -305.19999999999993, -271.1, 20.000000000000014, -124.29999999999995, -240.40000000000006, 20.000000000000014, 31.400000000000208, -66.10000000000004, -171.1000000000001, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -244.20000000000005, -72.40000000000089, -145.90000000000003, -379.0999999999999, -65.49999999999997, -7.30000000000004, 17.899999999999984, -190.00000000000003, -190.00000000000003, 20.000000000000014, 10.399999999999968, -68.20000000000002, 20.000000000000014, 11.599999999999968, -219.39999999999998, -327.7999999999999, 20.000000000000014, 20.000000000000014, 21.80000000000004, -271.9000000000001, -168.09999999999997, -280.6, 20.000000000000014, -21.999999999999744, -57.70000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.10000000000005, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 6.199999999999973, 20.000000000000014, 20.000000000000014, -234.10000000000002, 26.300000000000114, 29.90000000000018, -3.0999999999999934, -32.49999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -244.60000000000002, -13.59999999999989, 13.099999999999966, -22.00000000000003, 13.699999999999964, -244.60000000000002, 29.90000000000018, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 17.899999999999988, 20.000000000000014, 7.39999999999996, 20.000000000000014, -223.59999999999994, 25.400000000000098, 20.000000000000014, 5.299999999999969, 3.7999999999999656, -45.09999999999977, 30.800000000000196, -16.89999999999978, 11.599999999999975, 20.000000000000014, 17.899999999999988, 18.499999999999993, 22.700000000000053, 3.1999999999999615, 20.000000000000014, 11.599999999999971, -17.79999999999977, 20.000000000000014, 34.10000000000024, -192.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, -371.5, -355.9, -5.200000000000053, -0.4000000000000472, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999966, 20.000000000000014, -89.20000000000037, -4.5999999999999535, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -15.699999999999896, -34.599999999999866, -51.39999999999986, 13.99999999999997, 20.000000000000014, 32.60000000000023, 11.599999999999964, 12.199999999999966, 28.100000000000147, 26.300000000000114, 20.000000000000014, 11.599999999999968, 14.899999999999965, -40.899999999999764, 20.000000000000014, 33.50000000000024, 5.299999999999965, 20.000000000000014, -13.599999999999826, 20.000000000000014, 27.50000000000014, 7.699999999999967, 20.000000000000014, -198.4, 27.20000000000013, 35.300000000000246, -166.90000000000026, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.99999999999997, 20.000000000000014, 2.2999999999999607, -240.4000000000002, 20.000000000000014, 20.000000000000014, 35.30000000000025, -116.50000000000063, 20.000000000000014, 20.000000000000014, 26.300000000000118, 1.0999999999999723, 22.700000000000053, -49.2999999999998, -29.199999999999797, 24.50000000000008, -3.100000000000047, -7.299999999999891, 20.000000000000014, -42.999999999999865, 20.000000000000014, 7.399999999999965, 34.40000000000026, 20.000000000000014, 24.50000000000008, 31.700000000000212, 20.000000000000014, 13.099999999999966, -42.99999999999976, 8.299999999999972, -108.10000000000039, 1.0999999999999723, 20.000000000000007, -80.80000000000061, -85.0000000000008, -290.8, 20.000000000000014, -61.90000000000034, 7.39999999999997, -29.799999999999862, -32.49999999999987, -40.89999999999986, 6.1999999999999655], "policy_predator_policy_reward": [24.0, 29.0, 110.0, 101.0, 59.0, 19.0, 0.0, 0.0, 0.0, 0.0, 142.0, 10.0, 166.0, 91.0, 43.0, 60.0, 65.0, 121.0, 30.0, 30.0, 83.0, 42.0, 0.0, 0.0, 66.0, 118.0, 60.0, 79.0, 195.0, 75.0, 12.0, 7.0, 99.0, 47.0, 8.0, 0.0, 42.0, 3.0, 82.0, 96.0, 161.0, 95.0, 0.0, 0.0, 114.0, 130.0, 91.0, 126.0, 56.0, 25.0, 0.0, 0.0, 51.0, 109.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 113.0, 60.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 107.0, 101.0, 1.0, 21.0, 114.0, 115.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 6.0, 85.0, 89.0, 0.0, 0.0, 6.0, 6.0, 31.0, 0.0, 8.0, 13.0, 1.0, 0.0, 0.0, 5.0, 8.0, 0.0, 1.0, 22.0, 1.0, 0.0, 64.0, 97.0, 0.0, 0.0, 0.0, 5.0, 94.0, 193.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 52.0, 16.0, 7.0, 0.0, 0.0, 19.0, 10.0, 25.0, 34.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 29.0, 2.0, 0.0, 0.0, 7.0, 0.0, 16.0, 0.0, 0.0, 10.0, 103.0, 49.0, 0.0, 0.0, 76.0, 64.0, 6.0, 0.0, 6.0, 11.0, 11.0, 5.0, 117.0, 86.0, 0.0, 0.0, 0.0, 65.0, 0.0, 3.0, 0.0, 12.0, 43.0, 0.0, 11.0, 0.0, 13.0, 0.0, 30.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 30.0, 50.0, 59.0, 12.0, 0.0, 40.0, 58.0, 139.0, 139.0, 2.0, 43.0, 35.0, 0.0, 14.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.585689850587961, "mean_inference_ms": 1.8363761898998208, "mean_action_processing_ms": 0.2466000852733035, "mean_env_wait_ms": 0.19214910512107097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0077588558197021484, "StateBufferConnector_ms": 0.003184795379638672, "ViewRequirementAgentConnector_ms": 0.10069036483764648}, "num_episodes": 18, "episode_return_max": 63.40000000000052, "episode_return_min": -440.4, "episode_return_mean": -1.6139999999997954, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 410.1516218883444, "num_env_steps_trained_throughput_per_sec": 410.1516218883444, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 10057.858, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10057.811, "sample_time_ms": 1346.778, "learn_time_ms": 8697.81, "learn_throughput": 459.886, "synch_weights_time_ms": 12.012}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "0b081_00000", "date": "2024-08-13_01-03-13", "timestamp": 1723525393, "time_this_iter_s": 9.75714111328125, "time_total_s": 972.8742332458496, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f211f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 972.8742332458496, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 29.278571428571432, "ram_util_percent": 83.42142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6385490462932952, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7322030429644559, "policy_loss": -0.0035278183124742655, "vf_loss": 0.7356425611824585, "vf_explained_var": 0.0037696137314751034, "kl": 0.009922293711851287, "entropy": 0.7523611984871051, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0807992847153434, "cur_kl_coeff": 7.733484380878506e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8541958946434082, "policy_loss": -0.003113824377950064, "vf_loss": 0.8573097164747576, "vf_explained_var": 0.002635985770553508, "kl": 0.004585791796566274, "entropy": 0.646538179860544, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 70.60000000000002, "episode_reward_min": -440.4, "episode_reward_mean": 13.85300000000017, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -371.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000025, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -14.318499999999986, "predator_policy": 21.245}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.59999999999985, 1.299999999999966, 40.0000000000003, -54.09999999999987, 44.50000000000036, 40.0000000000003, 39.20000000000028, -41.09999999999993, 56.200000000000536, -5.599999999999719, 40.0000000000003, 40.0000000000003, -50.19999999999987, 13.099999999999959, -1.9000000000000639, 46.600000000000406, 40.0000000000003, 50.400000000000475, 38.40000000000029, -29.599999999999895, 45.40000000000038, 21.099999999999994, 16.69999999999993, 15.699999999999921, 38.90000000000028, 46.2000000000004, 31.200000000000166, 16.799999999999926, 55.10000000000049, -11.100000000000023, 40.0000000000003, 34.50000000000022, -440.4, 17.399999999999963, 50.80000000000048, 40.0000000000003, 33.400000000000205, -17.199999999999818, 17.399999999999974, 40.0000000000003, -21.29999999999974, 21.599999999999998, 52.60000000000051, 29.80000000000014, 54.400000000000546, 35.600000000000236, 5.000000000000025, 53.50000000000052, 32.30000000000018, 22.40000000000003, 45.20000000000039, -26.39999999999992, 62.500000000000504, -6.900000000000061, 33.400000000000205, 30.300000000000157, 38.300000000000274, -17.39999999999978, 55.30000000000051, -31.49999999999963, 49.30000000000046, 35.80000000000024, -35.499999999999595, 32.400000000000226, 25.70000000000007, 6.999999999999922, 47.80000000000043, 44.50000000000036, 51.70000000000049, 5.100000000000156, 9.19999999999994, 33.1000000000002, -67.80000000000148, 7.199999999999973, -9.499999999999861, -27.29999999999975, 1.2999999999999974, 34.5000000000002, 40.0000000000003, 8.500000000000009, 70.60000000000002, 32.20000000000018, 13.999999999999913, -13.999999999999956, 41.800000000000324, -7.699999999999726, -52.40000000000052, 40.0000000000003, 50.70000000000048, 16.899999999999974, 13.200000000000006, -178.4000000000005, 40.0000000000003, 12.499999999999924, 35.900000000000226, 37.80000000000026, 24.60000000000008, 12.599999999999932, 40.0000000000003, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-280.6, 20.000000000000014, -21.999999999999744, -57.70000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.10000000000005, 20.000000000000014, 24.50000000000008, 20.000000000000014, 20.000000000000014, 6.199999999999973, 20.000000000000014, 20.000000000000014, -234.10000000000002, 26.300000000000114, 29.90000000000018, -3.0999999999999934, -32.49999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -244.60000000000002, -13.59999999999989, 13.099999999999966, -22.00000000000003, 13.699999999999964, -244.60000000000002, 29.90000000000018, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.500000000000192, 17.899999999999988, 20.000000000000014, 7.39999999999996, 20.000000000000014, -223.59999999999994, 25.400000000000098, 20.000000000000014, 5.299999999999969, 3.7999999999999656, -45.09999999999977, 30.800000000000196, -16.89999999999978, 11.599999999999975, 20.000000000000014, 17.899999999999988, 18.499999999999993, 22.700000000000053, 3.1999999999999615, 20.000000000000014, 11.599999999999971, -17.79999999999977, 20.000000000000014, 34.10000000000024, -192.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, -371.5, -355.9, -5.200000000000053, -0.4000000000000472, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999966, 20.000000000000014, -89.20000000000037, -4.5999999999999535, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -15.699999999999896, -34.599999999999866, -51.39999999999986, 13.99999999999997, 20.000000000000014, 32.60000000000023, 11.599999999999964, 12.199999999999966, 28.100000000000147, 26.300000000000114, 20.000000000000014, 11.599999999999968, 14.899999999999965, -40.899999999999764, 20.000000000000014, 33.50000000000024, 5.299999999999965, 20.000000000000014, -13.599999999999826, 20.000000000000014, 27.50000000000014, 7.699999999999967, 20.000000000000014, -198.4, 27.20000000000013, 35.300000000000246, -166.90000000000026, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.99999999999997, 20.000000000000014, 2.2999999999999607, -240.4000000000002, 20.000000000000014, 20.000000000000014, 35.30000000000025, -116.50000000000063, 20.000000000000014, 20.000000000000014, 26.300000000000118, 1.0999999999999723, 22.700000000000053, -49.2999999999998, -29.199999999999797, 24.50000000000008, -3.100000000000047, -7.299999999999891, 20.000000000000014, -42.999999999999865, 20.000000000000014, 7.399999999999965, 34.40000000000026, 20.000000000000014, 24.50000000000008, 31.700000000000212, 20.000000000000014, 13.099999999999966, -42.99999999999976, 8.299999999999972, -108.10000000000039, 1.0999999999999723, 20.000000000000007, -80.80000000000061, -85.0000000000008, -290.8, 20.000000000000014, -61.90000000000034, 7.39999999999997, -29.799999999999862, -32.49999999999987, -40.89999999999986, 6.1999999999999655, 9.49999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999979, 11.29999999999997, 35.300000000000246, 35.300000000000246, 20.000000000000014, 3.1999999999999615, -36.99999999999981, 20.000000000000014, -129.10000000000028, 4.099999999999966, 21.80000000000004, 20.000000000000014, -47.19999999999976, -20.499999999999787, 3.199999999999967, -139.6000000000007, 20.000000000000014, 20.000000000000014, 34.40000000000026, 11.299999999999965, -24.099999999999746, 20.000000000000014, 17.899999999999988, -30.699999999999754, -133.30000000000035, -234.10000000000008, 20.000000000000014, 20.000000000000014, 20.900000000000027, -54.40000000000009, 5.299999999999981, 14.599999999999968, 15.799999999999946, 20.000000000000014, 20.000000000000014, -9.399999999999944, 27.20000000000013, -97.60000000000082, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014], "policy_predator_policy_reward": [91.0, 126.0, 56.0, 25.0, 0.0, 0.0, 51.0, 109.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 113.0, 60.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 107.0, 101.0, 1.0, 21.0, 114.0, 115.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 6.0, 85.0, 89.0, 0.0, 0.0, 6.0, 6.0, 31.0, 0.0, 8.0, 13.0, 1.0, 0.0, 0.0, 5.0, 8.0, 0.0, 1.0, 22.0, 1.0, 0.0, 64.0, 97.0, 0.0, 0.0, 0.0, 5.0, 94.0, 193.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 52.0, 16.0, 7.0, 0.0, 0.0, 19.0, 10.0, 25.0, 34.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 29.0, 2.0, 0.0, 0.0, 7.0, 0.0, 16.0, 0.0, 0.0, 10.0, 103.0, 49.0, 0.0, 0.0, 76.0, 64.0, 6.0, 0.0, 6.0, 11.0, 11.0, 5.0, 117.0, 86.0, 0.0, 0.0, 0.0, 65.0, 0.0, 3.0, 0.0, 12.0, 43.0, 0.0, 11.0, 0.0, 13.0, 0.0, 30.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 30.0, 50.0, 59.0, 12.0, 0.0, 40.0, 58.0, 139.0, 139.0, 2.0, 43.0, 35.0, 0.0, 14.0, 22.0, 0.0, 5.0, 0.0, 0.0, 8.0, 28.0, 0.0, 0.0, 3.0, 6.0, 0.0, 31.0, 71.0, 40.0, 0.0, 0.0, 35.0, 25.0, 58.0, 26.0, 0.0, 0.0, 0.0, 5.0, 0.0, 21.0, 24.0, 2.0, 117.0, 72.0, 0.0, 0.0, 41.0, 5.0, 4.0, 12.0, 0.0, 2.0, 7.0, 7.0, 56.0, 27.0, 0.0, 0.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5854765610607372, "mean_inference_ms": 1.8361750523352098, "mean_action_processing_ms": 0.24649384471963173, "mean_env_wait_ms": 0.1920711743362185, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007990717887878418, "StateBufferConnector_ms": 0.0034254789352416992, "ViewRequirementAgentConnector_ms": 0.09674072265625}, "num_episodes": 23, "episode_return_max": 70.60000000000002, "episode_return_min": -440.4, "episode_return_mean": 13.85300000000017, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.99347491416535, "num_env_steps_trained_throughput_per_sec": 402.99347491416535, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 10041.18, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10041.128, "sample_time_ms": 1347.007, "learn_time_ms": 8680.889, "learn_throughput": 460.782, "synch_weights_time_ms": 11.994}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "0b081_00000", "date": "2024-08-13_01-03-23", "timestamp": 1723525403, "time_this_iter_s": 9.945900201797485, "time_total_s": 982.8201334476471, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d62b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 982.8201334476471, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 29.857142857142858, "ram_util_percent": 83.41428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5866310427428554, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.711255100574443, "policy_loss": -0.004038600096227749, "vf_loss": 1.7152015713156847, "vf_explained_var": 0.009996998909289245, "kl": 0.010352409791753272, "entropy": 0.7268068953165933, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6861657675158568, "cur_kl_coeff": 3.866742190439253e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7395745035517152, "policy_loss": -0.0015606129643009612, "vf_loss": 1.7411351155982446, "vf_explained_var": -0.004958795460443648, "kl": 0.0036116489180039396, "entropy": 0.6893496268640751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 70.60000000000002, "episode_reward_min": -440.4, "episode_reward_mean": 17.082000000000193, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -371.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -8.418999999999986, "predator_policy": 16.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.40000000000029, -29.599999999999895, 45.40000000000038, 21.099999999999994, 16.69999999999993, 15.699999999999921, 38.90000000000028, 46.2000000000004, 31.200000000000166, 16.799999999999926, 55.10000000000049, -11.100000000000023, 40.0000000000003, 34.50000000000022, -440.4, 17.399999999999963, 50.80000000000048, 40.0000000000003, 33.400000000000205, -17.199999999999818, 17.399999999999974, 40.0000000000003, -21.29999999999974, 21.599999999999998, 52.60000000000051, 29.80000000000014, 54.400000000000546, 35.600000000000236, 5.000000000000025, 53.50000000000052, 32.30000000000018, 22.40000000000003, 45.20000000000039, -26.39999999999992, 62.500000000000504, -6.900000000000061, 33.400000000000205, 30.300000000000157, 38.300000000000274, -17.39999999999978, 55.30000000000051, -31.49999999999963, 49.30000000000046, 35.80000000000024, -35.499999999999595, 32.400000000000226, 25.70000000000007, 6.999999999999922, 47.80000000000043, 44.50000000000036, 51.70000000000049, 5.100000000000156, 9.19999999999994, 33.1000000000002, -67.80000000000148, 7.199999999999973, -9.499999999999861, -27.29999999999975, 1.2999999999999974, 34.5000000000002, 40.0000000000003, 8.500000000000009, 70.60000000000002, 32.20000000000018, 13.999999999999913, -13.999999999999956, 41.800000000000324, -7.699999999999726, -52.40000000000052, 40.0000000000003, 50.70000000000048, 16.899999999999974, 13.200000000000006, -178.4000000000005, 40.0000000000003, 12.499999999999924, 35.900000000000226, 37.80000000000026, 24.60000000000008, 12.599999999999932, 40.0000000000003, 37.80000000000027, 56.20000000000051, -18.49999999999966, 31.70000000000018, 47.00000000000042, 40.0000000000003, 50.80000000000048, 53.5000000000005, -27.899999999999608, 43.500000000000355, 36.300000000000246, 45.40000000000039, 34.50000000000022, 44.600000000000435, 68.80000000000017, 32.90000000000021, 29.800000000000146, -27.59999999999954, 36.70000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 7.39999999999996, 20.000000000000014, -223.59999999999994, 25.400000000000098, 20.000000000000014, 5.299999999999969, 3.7999999999999656, -45.09999999999977, 30.800000000000196, -16.89999999999978, 11.599999999999975, 20.000000000000014, 17.899999999999988, 18.499999999999993, 22.700000000000053, 3.1999999999999615, 20.000000000000014, 11.599999999999971, -17.79999999999977, 20.000000000000014, 34.10000000000024, -192.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, -371.5, -355.9, -5.200000000000053, -0.4000000000000472, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999966, 20.000000000000014, -89.20000000000037, -4.5999999999999535, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -15.699999999999896, -34.599999999999866, -51.39999999999986, 13.99999999999997, 20.000000000000014, 32.60000000000023, 11.599999999999964, 12.199999999999966, 28.100000000000147, 26.300000000000114, 20.000000000000014, 11.599999999999968, 14.899999999999965, -40.899999999999764, 20.000000000000014, 33.50000000000024, 5.299999999999965, 20.000000000000014, -13.599999999999826, 20.000000000000014, 27.50000000000014, 7.699999999999967, 20.000000000000014, -198.4, 27.20000000000013, 35.300000000000246, -166.90000000000026, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.99999999999997, 20.000000000000014, 2.2999999999999607, -240.4000000000002, 20.000000000000014, 20.000000000000014, 35.30000000000025, -116.50000000000063, 20.000000000000014, 20.000000000000014, 26.300000000000118, 1.0999999999999723, 22.700000000000053, -49.2999999999998, -29.199999999999797, 24.50000000000008, -3.100000000000047, -7.299999999999891, 20.000000000000014, -42.999999999999865, 20.000000000000014, 7.399999999999965, 34.40000000000026, 20.000000000000014, 24.50000000000008, 31.700000000000212, 20.000000000000014, 13.099999999999966, -42.99999999999976, 8.299999999999972, -108.10000000000039, 1.0999999999999723, 20.000000000000007, -80.80000000000061, -85.0000000000008, -290.8, 20.000000000000014, -61.90000000000034, 7.39999999999997, -29.799999999999862, -32.49999999999987, -40.89999999999986, 6.1999999999999655, 9.49999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999979, 11.29999999999997, 35.300000000000246, 35.300000000000246, 20.000000000000014, 3.1999999999999615, -36.99999999999981, 20.000000000000014, -129.10000000000028, 4.099999999999966, 21.80000000000004, 20.000000000000014, -47.19999999999976, -20.499999999999787, 3.199999999999967, -139.6000000000007, 20.000000000000014, 20.000000000000014, 34.40000000000026, 11.299999999999965, -24.099999999999746, 20.000000000000014, 17.899999999999988, -30.699999999999754, -133.30000000000035, -234.10000000000008, 20.000000000000014, 20.000000000000014, 20.900000000000027, -54.40000000000009, 5.299999999999981, 14.599999999999968, 15.799999999999946, 20.000000000000014, 20.000000000000014, -9.399999999999944, 27.20000000000013, -97.60000000000082, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 36.20000000000025, -57.40000000000016, -24.099999999999746, 20.000000000000014, 1.6999999999999729, 8.899999999999967, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, 20.000000000000014, 33.50000000000025, -36.69999999999984, -47.1999999999998, 18.499999999999993, 20.000000000000014, 20.90000000000003, 10.399999999999965, 20.000000000000014, 25.4000000000001, 20.000000000000014, 9.499999999999964, 20.900000000000027, -7.3000000000000504, 35.300000000000246, 33.50000000000024, -15.999999999999774, 20.900000000000027, 15.199999999999964, -0.39999999999999936, -64.00000000000091, -13.59999999999983, 20.000000000000014, 13.699999999999964], "policy_predator_policy_reward": [5.0, 6.0, 85.0, 89.0, 0.0, 0.0, 6.0, 6.0, 31.0, 0.0, 8.0, 13.0, 1.0, 0.0, 0.0, 5.0, 8.0, 0.0, 1.0, 22.0, 1.0, 0.0, 64.0, 97.0, 0.0, 0.0, 0.0, 5.0, 94.0, 193.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 52.0, 16.0, 7.0, 0.0, 0.0, 19.0, 10.0, 25.0, 34.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 29.0, 2.0, 0.0, 0.0, 7.0, 0.0, 16.0, 0.0, 0.0, 10.0, 103.0, 49.0, 0.0, 0.0, 76.0, 64.0, 6.0, 0.0, 6.0, 11.0, 11.0, 5.0, 117.0, 86.0, 0.0, 0.0, 0.0, 65.0, 0.0, 3.0, 0.0, 12.0, 43.0, 0.0, 11.0, 0.0, 13.0, 0.0, 30.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 30.0, 50.0, 59.0, 12.0, 0.0, 40.0, 58.0, 139.0, 139.0, 2.0, 43.0, 35.0, 0.0, 14.0, 22.0, 0.0, 5.0, 0.0, 0.0, 8.0, 28.0, 0.0, 0.0, 3.0, 6.0, 0.0, 31.0, 71.0, 40.0, 0.0, 0.0, 35.0, 25.0, 58.0, 26.0, 0.0, 0.0, 0.0, 5.0, 0.0, 21.0, 24.0, 2.0, 117.0, 72.0, 0.0, 0.0, 41.0, 5.0, 4.0, 12.0, 0.0, 2.0, 7.0, 7.0, 56.0, 27.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 9.0, 54.0, 10.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 6.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 12.0, 0.0, 0.0, 28.0, 0.0, 15.0, 0.0, 0.0, 50.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5852787462277321, "mean_inference_ms": 1.8360230847352101, "mean_action_processing_ms": 0.24639627965238722, "mean_env_wait_ms": 0.1919999409388815, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007507681846618652, "StateBufferConnector_ms": 0.0034214258193969727, "ViewRequirementAgentConnector_ms": 0.09644103050231934}, "num_episodes": 18, "episode_return_max": 70.60000000000002, "episode_return_min": -440.4, "episode_return_mean": 17.082000000000193, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 403.1002060044507, "num_env_steps_trained_throughput_per_sec": 403.1002060044507, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 10029.309, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10029.257, "sample_time_ms": 1336.526, "learn_time_ms": 8679.455, "learn_throughput": 460.858, "synch_weights_time_ms": 12.061}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "0b081_00000", "date": "2024-08-13_01-03-33", "timestamp": 1723525413, "time_this_iter_s": 9.928673028945923, "time_total_s": 992.748806476593, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d77c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 992.748806476593, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 28.400000000000006, "ram_util_percent": 83.22142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7215643400553042, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0850588665437446, "policy_loss": -0.003154138384495305, "vf_loss": 1.0881130374613261, "vf_explained_var": 0.006554144400137442, "kl": 0.011233509405706076, "entropy": 0.6975893843741644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7832287084468931, "cur_kl_coeff": 1.9333710952196264e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1662663164179004, "policy_loss": -0.003148313372016505, "vf_loss": 1.1694146288292748, "vf_explained_var": -0.017383264927637008, "kl": 0.009243636063315838, "entropy": 0.7920012947743532, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 70.60000000000002, "episode_reward_min": -178.4000000000005, "episode_reward_mean": 18.37000000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.80000000000024, "predator_policy": 139.0}, "policy_reward_mean": {"prey_policy": -7.299999999999988, "predator_policy": 16.485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-21.29999999999974, 21.599999999999998, 52.60000000000051, 29.80000000000014, 54.400000000000546, 35.600000000000236, 5.000000000000025, 53.50000000000052, 32.30000000000018, 22.40000000000003, 45.20000000000039, -26.39999999999992, 62.500000000000504, -6.900000000000061, 33.400000000000205, 30.300000000000157, 38.300000000000274, -17.39999999999978, 55.30000000000051, -31.49999999999963, 49.30000000000046, 35.80000000000024, -35.499999999999595, 32.400000000000226, 25.70000000000007, 6.999999999999922, 47.80000000000043, 44.50000000000036, 51.70000000000049, 5.100000000000156, 9.19999999999994, 33.1000000000002, -67.80000000000148, 7.199999999999973, -9.499999999999861, -27.29999999999975, 1.2999999999999974, 34.5000000000002, 40.0000000000003, 8.500000000000009, 70.60000000000002, 32.20000000000018, 13.999999999999913, -13.999999999999956, 41.800000000000324, -7.699999999999726, -52.40000000000052, 40.0000000000003, 50.70000000000048, 16.899999999999974, 13.200000000000006, -178.4000000000005, 40.0000000000003, 12.499999999999924, 35.900000000000226, 37.80000000000026, 24.60000000000008, 12.599999999999932, 40.0000000000003, 37.80000000000027, 56.20000000000051, -18.49999999999966, 31.70000000000018, 47.00000000000042, 40.0000000000003, 50.80000000000048, 53.5000000000005, -27.899999999999608, 43.500000000000355, 36.300000000000246, 45.40000000000039, 34.50000000000022, 44.600000000000435, 68.80000000000017, 32.90000000000021, 29.800000000000146, -27.59999999999954, 36.70000000000025, 10.699999999999939, 40.0000000000003, 55.600000000000485, -4.5000000000000995, -7.199999999999678, 49.00000000000045, -45.29999999999993, 5.900000000000089, -54.400000000000304, -34.899999999999736, -24.39999999999953, 36.90000000000025, 57.80000000000049, 37.80000000000027, 40.0000000000003, 23.500000000000032, -61.00000000000078, 41.60000000000032, 16.899999999999938, -36.399999999999615, 28.600000000000115, 53.300000000000516], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999896, -34.599999999999866, -51.39999999999986, 13.99999999999997, 20.000000000000014, 32.60000000000023, 11.599999999999964, 12.199999999999966, 28.100000000000147, 26.300000000000114, 20.000000000000014, 11.599999999999968, 14.899999999999965, -40.899999999999764, 20.000000000000014, 33.50000000000024, 5.299999999999965, 20.000000000000014, -13.599999999999826, 20.000000000000014, 27.50000000000014, 7.699999999999967, 20.000000000000014, -198.4, 27.20000000000013, 35.300000000000246, -166.90000000000026, 20.000000000000014, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.99999999999997, 20.000000000000014, 2.2999999999999607, -240.4000000000002, 20.000000000000014, 20.000000000000014, 35.30000000000025, -116.50000000000063, 20.000000000000014, 20.000000000000014, 26.300000000000118, 1.0999999999999723, 22.700000000000053, -49.2999999999998, -29.199999999999797, 24.50000000000008, -3.100000000000047, -7.299999999999891, 20.000000000000014, -42.999999999999865, 20.000000000000014, 7.399999999999965, 34.40000000000026, 20.000000000000014, 24.50000000000008, 31.700000000000212, 20.000000000000014, 13.099999999999966, -42.99999999999976, 8.299999999999972, -108.10000000000039, 1.0999999999999723, 20.000000000000007, -80.80000000000061, -85.0000000000008, -290.8, 20.000000000000014, -61.90000000000034, 7.39999999999997, -29.799999999999862, -32.49999999999987, -40.89999999999986, 6.1999999999999655, 9.49999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999979, 11.29999999999997, 35.300000000000246, 35.300000000000246, 20.000000000000014, 3.1999999999999615, -36.99999999999981, 20.000000000000014, -129.10000000000028, 4.099999999999966, 21.80000000000004, 20.000000000000014, -47.19999999999976, -20.499999999999787, 3.199999999999967, -139.6000000000007, 20.000000000000014, 20.000000000000014, 34.40000000000026, 11.299999999999965, -24.099999999999746, 20.000000000000014, 17.899999999999988, -30.699999999999754, -133.30000000000035, -234.10000000000008, 20.000000000000014, 20.000000000000014, 20.900000000000027, -54.40000000000009, 5.299999999999981, 14.599999999999968, 15.799999999999946, 20.000000000000014, 20.000000000000014, -9.399999999999944, 27.20000000000013, -97.60000000000082, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 36.20000000000025, -57.40000000000016, -24.099999999999746, 20.000000000000014, 1.6999999999999729, 8.899999999999967, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, 20.000000000000014, 33.50000000000025, -36.69999999999984, -47.1999999999998, 18.499999999999993, 20.000000000000014, 20.90000000000003, 10.399999999999965, 20.000000000000014, 25.4000000000001, 20.000000000000014, 9.499999999999964, 20.900000000000027, -7.3000000000000504, 35.300000000000246, 33.50000000000024, -15.999999999999774, 20.900000000000027, 15.199999999999964, -0.39999999999999936, -64.00000000000091, -13.59999999999983, 20.000000000000014, 13.699999999999964, 20.000000000000014, -40.29999999999977, 20.000000000000014, 20.000000000000014, 29.00000000000017, 23.600000000000065, -45.09999999999995, -51.39999999999987, -14.19999999999978, -33.99999999999977, 23.600000000000065, 25.400000000000098, -34.59999999999979, -120.70000000000059, -9.399999999999897, -15.699999999999775, -47.499999999999886, -46.89999999999987, -97.60000000000045, -7.299999999999933, -76.60000000000085, -2.7999999999999754, 5.89999999999997, 20.000000000000014, 20.000000000000014, 36.80000000000024, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999819, -82.90000000000049, -45.09999999999988, 20.600000000000026, 20.000000000000014, -24.09999999999979, 20.000000000000014, -152.20000000000059, 15.799999999999963, -53.49999999999991, 25.100000000000094, 20.000000000000014, 32.300000000000225], "policy_predator_policy_reward": [19.0, 10.0, 25.0, 34.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 29.0, 2.0, 0.0, 0.0, 7.0, 0.0, 16.0, 0.0, 0.0, 10.0, 103.0, 49.0, 0.0, 0.0, 76.0, 64.0, 6.0, 0.0, 6.0, 11.0, 11.0, 5.0, 117.0, 86.0, 0.0, 0.0, 0.0, 65.0, 0.0, 3.0, 0.0, 12.0, 43.0, 0.0, 11.0, 0.0, 13.0, 0.0, 30.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 30.0, 50.0, 59.0, 12.0, 0.0, 40.0, 58.0, 139.0, 139.0, 2.0, 43.0, 35.0, 0.0, 14.0, 22.0, 0.0, 5.0, 0.0, 0.0, 8.0, 28.0, 0.0, 0.0, 3.0, 6.0, 0.0, 31.0, 71.0, 40.0, 0.0, 0.0, 35.0, 25.0, 58.0, 26.0, 0.0, 0.0, 0.0, 5.0, 0.0, 21.0, 24.0, 2.0, 117.0, 72.0, 0.0, 0.0, 41.0, 5.0, 4.0, 12.0, 0.0, 2.0, 7.0, 7.0, 56.0, 27.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 9.0, 54.0, 10.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 6.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 12.0, 0.0, 0.0, 28.0, 0.0, 15.0, 0.0, 0.0, 50.0, 0.0, 3.0, 6.0, 25.0, 0.0, 0.0, 0.0, 3.0, 61.0, 31.0, 14.0, 27.0, 0.0, 0.0, 66.0, 44.0, 0.0, 31.0, 7.0, 33.0, 56.0, 14.0, 9.0, 46.0, 0.0, 11.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 15.0, 36.0, 31.0, 1.0, 0.0, 0.0, 21.0, 39.0, 61.0, 35.0, 22.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5849462839273689, "mean_inference_ms": 1.8356726265188898, "mean_action_processing_ms": 0.2462667024185933, "mean_env_wait_ms": 0.19181142946445395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006487607955932617, "StateBufferConnector_ms": 0.003603219985961914, "ViewRequirementAgentConnector_ms": 0.09622228145599365}, "num_episodes": 22, "episode_return_max": 70.60000000000002, "episode_return_min": -178.4000000000005, "episode_return_mean": 18.37000000000019, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 384.5960370040031, "num_env_steps_trained_throughput_per_sec": 384.5960370040031, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 10080.294, "restore_workers_time_ms": 0.019, "training_step_time_ms": 10080.24, "sample_time_ms": 1346.201, "learn_time_ms": 8720.688, "learn_throughput": 458.679, "synch_weights_time_ms": 12.241}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "0b081_00000", "date": "2024-08-13_01-03-44", "timestamp": 1723525424, "time_this_iter_s": 10.480633020401001, "time_total_s": 1003.229439496994, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d1a430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1003.229439496994, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 31.273333333333326, "ram_util_percent": 82.97333333333336}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4987939354702436, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1809490630077937, "policy_loss": -0.0016962664953319641, "vf_loss": 1.1825381177443046, "vf_explained_var": 0.0008830400371046924, "kl": 0.012048210259088322, "entropy": 0.655724562475921, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8941360387221846, "cur_kl_coeff": 1.9333710952196264e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7858387697941411, "policy_loss": -0.0011078392557070528, "vf_loss": 1.7869466152456073, "vf_explained_var": -0.00021967619815200726, "kl": 0.009889069622181945, "entropy": 0.8877362355668709, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 70.60000000000002, "episode_reward_min": -178.4000000000005, "episode_reward_mean": 19.208000000000197, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.80000000000024, "predator_policy": 231.0}, "policy_reward_mean": {"prey_policy": -6.080999999999994, "predator_policy": 15.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.30000000000051, -31.49999999999963, 49.30000000000046, 35.80000000000024, -35.499999999999595, 32.400000000000226, 25.70000000000007, 6.999999999999922, 47.80000000000043, 44.50000000000036, 51.70000000000049, 5.100000000000156, 9.19999999999994, 33.1000000000002, -67.80000000000148, 7.199999999999973, -9.499999999999861, -27.29999999999975, 1.2999999999999974, 34.5000000000002, 40.0000000000003, 8.500000000000009, 70.60000000000002, 32.20000000000018, 13.999999999999913, -13.999999999999956, 41.800000000000324, -7.699999999999726, -52.40000000000052, 40.0000000000003, 50.70000000000048, 16.899999999999974, 13.200000000000006, -178.4000000000005, 40.0000000000003, 12.499999999999924, 35.900000000000226, 37.80000000000026, 24.60000000000008, 12.599999999999932, 40.0000000000003, 37.80000000000027, 56.20000000000051, -18.49999999999966, 31.70000000000018, 47.00000000000042, 40.0000000000003, 50.80000000000048, 53.5000000000005, -27.899999999999608, 43.500000000000355, 36.300000000000246, 45.40000000000039, 34.50000000000022, 44.600000000000435, 68.80000000000017, 32.90000000000021, 29.800000000000146, -27.59999999999954, 36.70000000000025, 10.699999999999939, 40.0000000000003, 55.600000000000485, -4.5000000000000995, -7.199999999999678, 49.00000000000045, -45.29999999999993, 5.900000000000089, -54.400000000000304, -34.899999999999736, -24.39999999999953, 36.90000000000025, 57.80000000000049, 37.80000000000027, 40.0000000000003, 23.500000000000032, -61.00000000000078, 41.60000000000032, 16.899999999999938, -36.399999999999615, 28.600000000000115, 53.300000000000516, 46.300000000000395, 43.60000000000035, -63.29999999999981, 40.0000000000003, 40.1000000000003, 34.700000000000216, 24.900000000000066, 39.800000000000296, 24.600000000000048, 40.0000000000003, -13.79999999999959, 52.60000000000051, 10.299999999999946, 50.60000000000048, 42.40000000000033, 20.599999999999998, 40.0000000000003, 55.30000000000052], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 35.30000000000025, -116.50000000000063, 20.000000000000014, 20.000000000000014, 26.300000000000118, 1.0999999999999723, 22.700000000000053, -49.2999999999998, -29.199999999999797, 24.50000000000008, -3.100000000000047, -7.299999999999891, 20.000000000000014, -42.999999999999865, 20.000000000000014, 7.399999999999965, 34.40000000000026, 20.000000000000014, 24.50000000000008, 31.700000000000212, 20.000000000000014, 13.099999999999966, -42.99999999999976, 8.299999999999972, -108.10000000000039, 1.0999999999999723, 20.000000000000007, -80.80000000000061, -85.0000000000008, -290.8, 20.000000000000014, -61.90000000000034, 7.39999999999997, -29.799999999999862, -32.49999999999987, -40.89999999999986, 6.1999999999999655, 9.49999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999979, 11.29999999999997, 35.300000000000246, 35.300000000000246, 20.000000000000014, 3.1999999999999615, -36.99999999999981, 20.000000000000014, -129.10000000000028, 4.099999999999966, 21.80000000000004, 20.000000000000014, -47.19999999999976, -20.499999999999787, 3.199999999999967, -139.6000000000007, 20.000000000000014, 20.000000000000014, 34.40000000000026, 11.299999999999965, -24.099999999999746, 20.000000000000014, 17.899999999999988, -30.699999999999754, -133.30000000000035, -234.10000000000008, 20.000000000000014, 20.000000000000014, 20.900000000000027, -54.40000000000009, 5.299999999999981, 14.599999999999968, 15.799999999999946, 20.000000000000014, 20.000000000000014, -9.399999999999944, 27.20000000000013, -97.60000000000082, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 36.20000000000025, -57.40000000000016, -24.099999999999746, 20.000000000000014, 1.6999999999999729, 8.899999999999967, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, 20.000000000000014, 33.50000000000025, -36.69999999999984, -47.1999999999998, 18.499999999999993, 20.000000000000014, 20.90000000000003, 10.399999999999965, 20.000000000000014, 25.4000000000001, 20.000000000000014, 9.499999999999964, 20.900000000000027, -7.3000000000000504, 35.300000000000246, 33.50000000000024, -15.999999999999774, 20.900000000000027, 15.199999999999964, -0.39999999999999936, -64.00000000000091, -13.59999999999983, 20.000000000000014, 13.699999999999964, 20.000000000000014, -40.29999999999977, 20.000000000000014, 20.000000000000014, 29.00000000000017, 23.600000000000065, -45.09999999999995, -51.39999999999987, -14.19999999999978, -33.99999999999977, 23.600000000000065, 25.400000000000098, -34.59999999999979, -120.70000000000059, -9.399999999999897, -15.699999999999775, -47.499999999999886, -46.89999999999987, -97.60000000000045, -7.299999999999933, -76.60000000000085, -2.7999999999999754, 5.89999999999997, 20.000000000000014, 20.000000000000014, 36.80000000000024, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999819, -82.90000000000049, -45.09999999999988, 20.600000000000026, 20.000000000000014, -24.09999999999979, 20.000000000000014, -152.20000000000059, 15.799999999999963, -53.49999999999991, 25.100000000000094, 20.000000000000014, 32.300000000000225, 20.000000000000014, 26.300000000000114, 23.600000000000065, 20.000000000000014, -19.900000000000013, -274.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.099999999999962, 20.000000000000014, 1.6999999999999622, -13.599999999999797, 21.500000000000036, 17.89999999999998, 20.90000000000003, 13.699999999999966, -0.09999999999999937, 20.000000000000014, 20.000000000000014, -52.90000000000011, -16.8999999999998, 32.60000000000023, 20.000000000000014, 20.000000000000014, -78.70000000000063, 29.600000000000176, 20.000000000000014, 16.399999999999967, 20.000000000000014, 18.499999999999993, -124.90000000000057, 20.000000000000014, 20.000000000000014, 35.30000000000026, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 65.0, 0.0, 3.0, 0.0, 12.0, 43.0, 0.0, 11.0, 0.0, 13.0, 0.0, 30.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 30.0, 50.0, 59.0, 12.0, 0.0, 40.0, 58.0, 139.0, 139.0, 2.0, 43.0, 35.0, 0.0, 14.0, 22.0, 0.0, 5.0, 0.0, 0.0, 8.0, 28.0, 0.0, 0.0, 3.0, 6.0, 0.0, 31.0, 71.0, 40.0, 0.0, 0.0, 35.0, 25.0, 58.0, 26.0, 0.0, 0.0, 0.0, 5.0, 0.0, 21.0, 24.0, 2.0, 117.0, 72.0, 0.0, 0.0, 41.0, 5.0, 4.0, 12.0, 0.0, 2.0, 7.0, 7.0, 56.0, 27.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 9.0, 54.0, 10.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 6.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 12.0, 0.0, 0.0, 28.0, 0.0, 15.0, 0.0, 0.0, 50.0, 0.0, 3.0, 6.0, 25.0, 0.0, 0.0, 0.0, 3.0, 61.0, 31.0, 14.0, 27.0, 0.0, 0.0, 66.0, 44.0, 0.0, 31.0, 7.0, 33.0, 56.0, 14.0, 9.0, 46.0, 0.0, 11.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 15.0, 36.0, 31.0, 1.0, 0.0, 0.0, 21.0, 39.0, 61.0, 35.0, 22.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 231.0, 0.0, 0.0, 0.0, 4.0, 13.0, 0.0, 10.0, 7.0, 0.0, 1.0, 11.0, 0.0, 0.0, 0.0, 43.0, 13.0, 0.0, 0.0, 34.0, 35.0, 1.0, 0.0, 0.0, 6.0, 69.0, 58.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5846510555606146, "mean_inference_ms": 1.8349869629713753, "mean_action_processing_ms": 0.24610093607051098, "mean_env_wait_ms": 0.191743334785618, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006177544593811035, "StateBufferConnector_ms": 0.0037556886672973633, "ViewRequirementAgentConnector_ms": 0.09825050830841064}, "num_episodes": 18, "episode_return_max": 70.60000000000002, "episode_return_min": -178.4000000000005, "episode_return_mean": 19.208000000000197, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.0818004976943, "num_env_steps_trained_throughput_per_sec": 398.0818004976943, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 10065.259, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10065.207, "sample_time_ms": 1337.682, "learn_time_ms": 8714.229, "learn_throughput": 459.019, "synch_weights_time_ms": 12.207}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "0b081_00000", "date": "2024-08-13_01-03-54", "timestamp": 1723525434, "time_this_iter_s": 10.053783178329468, "time_total_s": 1013.2832226753235, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x327e69d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1013.2832226753235, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 29.85714285714286, "ram_util_percent": 83.15714285714284}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6423808955444545, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.366172000340053, "policy_loss": -0.0021720570183196473, "vf_loss": 2.368215290705363, "vf_explained_var": 0.0008995492622335121, "kl": 0.014469914018828123, "entropy": 0.717650804002449, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8440747349488514, "cur_kl_coeff": 1.9333710952196264e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.996515287924065, "policy_loss": -0.0009943860307059906, "vf_loss": 2.9975096698791264, "vf_explained_var": -0.00013482223742853396, "kl": 0.008083687061026024, "entropy": 0.9430972092681461, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 68.80000000000017, "episode_reward_min": -500.79999999999995, "episode_reward_mean": 3.1740000000001545, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1084.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.80000000000024, "predator_policy": 1060.0}, "policy_reward_mean": {"prey_policy": -27.53800000000002, "predator_policy": 29.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.20000000000018, 13.999999999999913, -13.999999999999956, 41.800000000000324, -7.699999999999726, -52.40000000000052, 40.0000000000003, 50.70000000000048, 16.899999999999974, 13.200000000000006, -178.4000000000005, 40.0000000000003, 12.499999999999924, 35.900000000000226, 37.80000000000026, 24.60000000000008, 12.599999999999932, 40.0000000000003, 37.80000000000027, 56.20000000000051, -18.49999999999966, 31.70000000000018, 47.00000000000042, 40.0000000000003, 50.80000000000048, 53.5000000000005, -27.899999999999608, 43.500000000000355, 36.300000000000246, 45.40000000000039, 34.50000000000022, 44.600000000000435, 68.80000000000017, 32.90000000000021, 29.800000000000146, -27.59999999999954, 36.70000000000025, 10.699999999999939, 40.0000000000003, 55.600000000000485, -4.5000000000000995, -7.199999999999678, 49.00000000000045, -45.29999999999993, 5.900000000000089, -54.400000000000304, -34.899999999999736, -24.39999999999953, 36.90000000000025, 57.80000000000049, 37.80000000000027, 40.0000000000003, 23.500000000000032, -61.00000000000078, 41.60000000000032, 16.899999999999938, -36.399999999999615, 28.600000000000115, 53.300000000000516, 46.300000000000395, 43.60000000000035, -63.29999999999981, 40.0000000000003, 40.1000000000003, 34.700000000000216, 24.900000000000066, 39.800000000000296, 24.600000000000048, 40.0000000000003, -13.79999999999959, 52.60000000000051, 10.299999999999946, 50.60000000000048, 42.40000000000033, 20.599999999999998, 40.0000000000003, 55.30000000000052, 39.60000000000029, -40.99999999999966, -66.70000000000141, 38.50000000000027, 24.800000000000058, 20.200000000000006, 62.10000000000051, -478.1, -52.49999999999998, 0.4000000000002143, -52.49999999999995, 40.0000000000003, 34.60000000000022, 49.00000000000045, -24.599999999999696, -60.09999999999998, -62.900000000001235, 40.0000000000003, -56.499999999999886, -62.40000000000069, -500.79999999999995, -123.30000000000118, 16.199999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 3.1999999999999615, -36.99999999999981, 20.000000000000014, -129.10000000000028, 4.099999999999966, 21.80000000000004, 20.000000000000014, -47.19999999999976, -20.499999999999787, 3.199999999999967, -139.6000000000007, 20.000000000000014, 20.000000000000014, 34.40000000000026, 11.299999999999965, -24.099999999999746, 20.000000000000014, 17.899999999999988, -30.699999999999754, -133.30000000000035, -234.10000000000008, 20.000000000000014, 20.000000000000014, 20.900000000000027, -54.40000000000009, 5.299999999999981, 14.599999999999968, 15.799999999999946, 20.000000000000014, 20.000000000000014, -9.399999999999944, 27.20000000000013, -97.60000000000082, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 36.20000000000025, -57.40000000000016, -24.099999999999746, 20.000000000000014, 1.6999999999999729, 8.899999999999967, 28.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, 20.000000000000014, 33.50000000000025, -36.69999999999984, -47.1999999999998, 18.499999999999993, 20.000000000000014, 20.90000000000003, 10.399999999999965, 20.000000000000014, 25.4000000000001, 20.000000000000014, 9.499999999999964, 20.900000000000027, -7.3000000000000504, 35.300000000000246, 33.50000000000024, -15.999999999999774, 20.900000000000027, 15.199999999999964, -0.39999999999999936, -64.00000000000091, -13.59999999999983, 20.000000000000014, 13.699999999999964, 20.000000000000014, -40.29999999999977, 20.000000000000014, 20.000000000000014, 29.00000000000017, 23.600000000000065, -45.09999999999995, -51.39999999999987, -14.19999999999978, -33.99999999999977, 23.600000000000065, 25.400000000000098, -34.59999999999979, -120.70000000000059, -9.399999999999897, -15.699999999999775, -47.499999999999886, -46.89999999999987, -97.60000000000045, -7.299999999999933, -76.60000000000085, -2.7999999999999754, 5.89999999999997, 20.000000000000014, 20.000000000000014, 36.80000000000024, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.499999999999819, -82.90000000000049, -45.09999999999988, 20.600000000000026, 20.000000000000014, -24.09999999999979, 20.000000000000014, -152.20000000000059, 15.799999999999963, -53.49999999999991, 25.100000000000094, 20.000000000000014, 32.300000000000225, 20.000000000000014, 26.300000000000114, 23.600000000000065, 20.000000000000014, -19.900000000000013, -274.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.099999999999962, 20.000000000000014, 1.6999999999999622, -13.599999999999797, 21.500000000000036, 17.89999999999998, 20.90000000000003, 13.699999999999966, -0.09999999999999937, 20.000000000000014, 20.000000000000014, -52.90000000000011, -16.8999999999998, 32.60000000000023, 20.000000000000014, 20.000000000000014, -78.70000000000063, 29.600000000000176, 20.000000000000014, 16.399999999999967, 20.000000000000014, 18.499999999999993, -124.90000000000057, 20.000000000000014, 20.000000000000014, 35.30000000000026, 20.000000000000014, 7.099999999999973, 6.499999999999968, -114.40000000000077, -67.6000000000005, -154.30000000000064, -9.399999999999855, 19.70000000000001, 15.79999999999996, -0.9999999999999917, 15.799999999999962, 6.1999999999999655, 4.999999999999966, 26.300000000000114, 33.80000000000025, -577.8, -736.3, -49.299999999999805, -68.2000000000006, -55.600000000000335, 20.000000000000014, -39.69999999999991, -122.80000000000072, 20.000000000000014, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, 29.000000000000163, -57.40000000000019, -20.199999999999847, -145.90000000000003, -5.200000000000008, -77.8000000000007, -57.100000000000115, 20.000000000000014, 20.000000000000014, -698.1, -9.400000000000029, -45.09999999999979, -115.30000000000037, -1084.7, -507.09999999999997, -72.4000000000007, -187.90000000000046, -32.79999999999977, 20.000000000000014], "policy_predator_policy_reward": [3.0, 6.0, 0.0, 31.0, 71.0, 40.0, 0.0, 0.0, 35.0, 25.0, 58.0, 26.0, 0.0, 0.0, 0.0, 5.0, 0.0, 21.0, 24.0, 2.0, 117.0, 72.0, 0.0, 0.0, 41.0, 5.0, 4.0, 12.0, 0.0, 2.0, 7.0, 7.0, 56.0, 27.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 9.0, 54.0, 10.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 6.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 12.0, 0.0, 0.0, 28.0, 0.0, 15.0, 0.0, 0.0, 50.0, 0.0, 3.0, 6.0, 25.0, 0.0, 0.0, 0.0, 3.0, 61.0, 31.0, 14.0, 27.0, 0.0, 0.0, 66.0, 44.0, 0.0, 31.0, 7.0, 33.0, 56.0, 14.0, 9.0, 46.0, 0.0, 11.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 15.0, 36.0, 31.0, 1.0, 0.0, 0.0, 21.0, 39.0, 61.0, 35.0, 22.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 231.0, 0.0, 0.0, 0.0, 4.0, 13.0, 0.0, 10.0, 7.0, 0.0, 1.0, 11.0, 0.0, 0.0, 0.0, 43.0, 13.0, 0.0, 0.0, 34.0, 35.0, 1.0, 0.0, 0.0, 6.0, 69.0, 58.0, 0.0, 0.0, 0.0, 0.0, 16.0, 10.0, 60.0, 81.0, 75.0, 22.0, 1.0, 2.0, 10.0, 0.0, 9.0, 0.0, 2.0, 0.0, 832.0, 4.0, 58.0, 7.0, 36.0, 0.0, 13.0, 97.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 44.0, 9.0, 12.0, 79.0, 58.0, 14.0, 0.0, 0.0, 643.0, 8.0, 65.0, 33.0, 31.0, 1060.0, 86.0, 51.0, 10.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5847542578422236, "mean_inference_ms": 1.8312584688893034, "mean_action_processing_ms": 0.24577824989421773, "mean_env_wait_ms": 0.19162851741838322, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038411617279052734, "StateBufferConnector_ms": 0.0037289857864379883, "ViewRequirementAgentConnector_ms": 0.09613144397735596}, "num_episodes": 23, "episode_return_max": 68.80000000000017, "episode_return_min": -500.79999999999995, "episode_return_mean": 3.1740000000001545, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 394.7297237301599, "num_env_steps_trained_throughput_per_sec": 394.7297237301599, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 10082.264, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10082.212, "sample_time_ms": 1330.322, "learn_time_ms": 8738.431, "learn_throughput": 457.748, "synch_weights_time_ms": 12.381}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "0b081_00000", "date": "2024-08-13_01-04-04", "timestamp": 1723525444, "time_this_iter_s": 10.138845920562744, "time_total_s": 1023.4220685958862, "pid": 4055, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f4d670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1023.4220685958862, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 83.11428571428573}}
