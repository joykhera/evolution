{"num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.2532281510935, "num_env_steps_trained_throughput_per_sec": 154.2532281510935, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "training_iteration": 100, "timestamp": 1724384951, "time_this_iter_s": 25.985648155212402, "time_total_s": 2664.4588696956635, "time_since_restore": 2664.4588696956635, "iterations_since_restore": 100, "info/num_env_steps_sampled": 400000, "info/num_env_steps_trained": 400000, "info/num_agent_steps_sampled": 1600000, "info/num_agent_steps_trained": 1600000, "env_runners/episode_reward_max": 904.6061760126963, "env_runners/episode_reward_min": -220.61916463042445, "env_runners/episode_reward_mean": 218.96120171953123, "env_runners/episode_len_mean": 400.0, "env_runners/episodes_timesteps_total": 40000, "env_runners/num_faulty_episodes": 0, "env_runners/num_episodes": 10, "env_runners/episode_return_max": 904.6061760126963, "env_runners/episode_return_min": -220.61916463042445, "env_runners/episode_return_mean": 218.96120171953123, "env_runners/episodes_this_iter": 10, "timers/training_iteration_time_ms": 26345.946, "timers/restore_workers_time_ms": 0.028, "timers/training_step_time_ms": 26345.68, "timers/sample_time_ms": 2529.964, "timers/learn_time_ms": 23793.528, "timers/learn_throughput": 168.113, "timers/synch_weights_time_ms": 18.159, "counters/num_env_steps_sampled": 400000, "counters/num_env_steps_trained": 400000, "counters/num_agent_steps_sampled": 1600000, "counters/num_agent_steps_trained": 1600000, "perf/cpu_util_percent": 33.14324324324325, "perf/ram_util_percent": 82.75675675675674, "info/learner/predator_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/predator_policy/num_grad_updates_lifetime": 94028.0, "info/learner/predator_policy/diff_num_grad_updates_vs_sampler_policy": 472.0, "info/learner/prey_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/prey_policy/num_grad_updates_lifetime": 94028.0, "info/learner/prey_policy/diff_num_grad_updates_vs_sampler_policy": 472.0, "info/learner/predator_policy/learner_stats/allreduce_latency": 0.0, "info/learner/predator_policy/learner_stats/grad_gnorm": 25.924275920504616, "info/learner/predator_policy/learner_stats/cur_kl_coeff": 0.05, "info/learner/predator_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/predator_policy/learner_stats/total_loss": 7.399900440942673, "info/learner/predator_policy/learner_stats/policy_loss": -0.01021080955582124, "info/learner/predator_policy/learner_stats/vf_loss": 7.409630722469753, "info/learner/predator_policy/learner_stats/vf_explained_var": 0.18937447222452314, "info/learner/predator_policy/learner_stats/kl": 0.009610134523076118, "info/learner/predator_policy/learner_stats/entropy": 0.2992710204351516, "info/learner/predator_policy/learner_stats/entropy_coeff": 0.0, "info/learner/prey_policy/learner_stats/allreduce_latency": 0.0, "info/learner/prey_policy/learner_stats/grad_gnorm": 40.29337134033284, "info/learner/prey_policy/learner_stats/cur_kl_coeff": 0.1, "info/learner/prey_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/prey_policy/learner_stats/total_loss": 7.579345659730295, "info/learner/prey_policy/learner_stats/policy_loss": -0.010147059253027672, "info/learner/prey_policy/learner_stats/vf_loss": 7.5884414990743005, "info/learner/prey_policy/learner_stats/vf_explained_var": 0.5080432779574521, "info/learner/prey_policy/learner_stats/kl": 0.010512177690016056, "info/learner/prey_policy/learner_stats/entropy": 0.5204430336043948, "info/learner/prey_policy/learner_stats/entropy_coeff": 0.0, "_timestamp": 1724384951.5867362, "_runtime": 2662.385014295578, "_step": 99, "env_runners/policy_reward_min/prey_policy": -944.7435441797094, "env_runners/policy_reward_min/predator_policy": 0.0, "env_runners/policy_reward_max/prey_policy": 371.9845303571001, "env_runners/policy_reward_max/predator_policy": 1018.2780995349988, "env_runners/policy_reward_mean/prey_policy": -533.1037977100469, "env_runners/policy_reward_mean/predator_policy": 642.584398569813, "env_runners/sampler_perf/mean_raw_obs_processing_ms": 5.558663736804412, "env_runners/sampler_perf/mean_inference_ms": 4.862423413349645, "env_runners/sampler_perf/mean_action_processing_ms": 1.772369731620998, "env_runners/sampler_perf/mean_env_wait_ms": 13.196437913049422, "env_runners/sampler_perf/mean_env_render_ms": 0.0, "env_runners/connector_metrics/ObsPreprocessorConnector_ms": 0.00428164005279541, "env_runners/connector_metrics/StateBufferConnector_ms": 0.005433440208435059, "env_runners/connector_metrics/ViewRequirementAgentConnector_ms": 0.18219029903411865}